<bugrepository name="pulsar">
    <bug id="5585" opendate="2019-11-07 00:00:00" fixdate="2019-11-11 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>Non-persistent topic's replication has a deadlock.
            </summary>
            <description>NonPersistentReplicator disable batching. If there is batch message,producer will acquire
                one,but release num in message's meta when process ack.
                // When publishing during replication, we need to set the correct number of message in batch
                // This is only used in tracking the publish rate stats
                int numMessages = msg.getMessageBuilder().hasNumMessagesInBatch()
                ? msg.getMessageBuilder().getNumMessagesInBatch()
                : 1;
                ByteBufPair cmd = sendMessage(producerId, sequenceId, numMessages, msgMetadata, encryptedPayload);
                msgMetadataBuilder.recycle();
                msgMetadata.recycle();

                final OpSendMsg op = OpSendMsg.create(msg, cmd, sequenceId, callback);
                op.setNumMessagesInBatch(numMessages);
                op.setBatchSizeByte(encryptedPayload.readableBytes());
                pendingMessages.put(op);
                lastSendFuture = callback.getFuture();

                So the ProducerImpl's semaphore no longer has any effect, the ProducerImpl's sendAsync method maybe
                blocked in pendingMessages's put method .
                There may be a deadlock between ackReceived and sendAsync .
                The deadlock is between pulsar-io-22-8 and pulsar-io-22-12 in jstack log.
                broker jstack log
            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.pulsar.client.impl.ProducerSemaphoreTest.java</file>
            <file type="M">org.apache.pulsar.client.impl.ProducerImpl.java</file>
        </fixedFiles>
    </bug>
    <bug id="4707" opendate="2019-07-11 00:00:00" fixdate="2019-08-28 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>PulsarKafkaProducer is not thread safe.
            </summary>
            <description>Is your feature request related to a problem? Please describe.
                I replaced kafka client with pulsar-client-kafka, referring to this document.
                http://pulsar.apache.org/docs/en/adaptors-kafka/
                Then, sending messages to multiple topics at the same time caused an exception(NullPointerException).
                This exception does not occur in version 2.2.1, but does occur in version 2.3.2 and later.
                I think that the change made in this PR is the cause.
                Each time you send a message to a new topic, the cluster object is regenerated.
                https://github.com/apache/pulsar/blob/v2.3.2/pulsar-client-kafka-compat/pulsar-client-kafka/src/main/java/org/apache/kafka/clients/producer/PulsarKafkaProducer.java#L229
                The javadoc states that KafkaProducer is thread safe.
                https://kafka.apache.org/20/javadoc/org/apache/kafka/clients/producer/KafkaProducer.html
                I want to use pulsar-client-kafka without modifying the code that used Kafka client.
                To Reproduce
                # build.gradle
                dependencies {
                testCompile group: 'junit', name: 'junit', version: '4.12'
                compile (group: 'org.apache.pulsar', name: 'pulsar-client-kafka-original', version: '2.3.2')
                compile (group: 'org.apache.pulsar', name: 'pulsar-client-auth-athenz', version: '2.3.2')
                }

                public static void main(String[] args) throws Exception {

                Properties properties = new Properties();
                properties.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "pulsar+ssl://server:6651");
                properties.setProperty(ProducerConfig.RETRIES_CONFIG, "5");
                properties.setProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
                properties.setProperty(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

                properties.setProperty(PulsarClientKafkaConfig.USE_TLS, "true");
                properties.setProperty(PulsarClientKafkaConfig.TLS_TRUST_CERTS_FILE_PATH, filePath("trust", ".crt",
                CERT));
                properties.setProperty(PulsarClientKafkaConfig.AUTHENTICATION_CLASS,
                AuthenticationAthenz.class.getName());
                properties.setProperty(PulsarClientKafkaConfig.AUTHENTICATION_PARAMS_STRING, authParams());

                properties.setProperty("security-protocol", "PLAINTEXT");

                properties.setProperty(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG, "30000");
                properties.setProperty(ProducerConfig.ACKS_CONFIG, "1");
                properties.setProperty(ProducerConfig.METADATA_MAX_AGE_CONFIG, "15000");
                producer = new PulsarKafkaProducer(properties, new StringSerializer(), new StringSerializer());

                Thread thread1 = new Thread(() -> {
                String topic1 = "persistent://topic1";
                ProducerRecord#String, String> record1 = new ProducerRecord#(topic1, "Hello");
                producer.send(record1, (recordMetadata, e) -> {
                System.out.println(recordMetadata);
                });
                });

                Thread thread2 = new Thread(() -> {
                String topic2 = "persistent://topic2";
                ProducerRecord#String, String> record2 = new ProducerRecord#(topic2, "Hello");
                producer.send(record2, (recordMetadata, e) -> {
                System.out.println(recordMetadata);
                });
                });

                thread1.start();
                thread2.start();
                }

                Exception in thread "Thread-2" java.lang.NullPointerException
                at org.apache.kafka.clients.producer.internals.DefaultPartitioner.partition(DefaultPartitioner.java:56)
                at org.apache.kafka.clients.producer.PulsarKafkaProducer.buildMessage(PulsarKafkaProducer.java:270)
                at org.apache.kafka.clients.producer.PulsarKafkaProducer.send(PulsarKafkaProducer.java:172)
                at Main.lambda$main$3(Main.java:156)
                at java.lang.Thread.run(Thread.java:748)

            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.kafka.clients.producer.PulsarKafkaProducer.java</file>
            <file type="M">org.apache.pulsar.tests.integration.compat.kafka.PulsarKafkaProducerThreadSafeTest.java</file>
        </fixedFiles>
    </bug>
    <bug id="10235" opendate="2021-04-14 00:00:00" fixdate="2021-05-11 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>Deadlock on Monitoring thread ... LeaderService.isLeader().
            </summary>
            <description>Describe the bug
                When checking dashboards, we found that the pulsar summary board showed that 33% of brokers were
                running. However kubernetes showed that all of the brokers were running. We traced this back to problems
                with the metrics queries not returning "wget http://localhost:8080/metrics" and this was indeed
                returning a Gateway timeout. We checked the logs and found no errors in the logs to indicate that a
                exception occurred during the processing of the metrics query. So we proceeded to take heap dumps and
                stack traces from the java process. While it continued to process data through many of the queues.
                Review of the stack traces showed that the prometheus-stats thread was hung waiting on a Lock that was
                held by another thread (pulsar-external-listener). However the other thread was waiting on additional
                locks. I suspect that there is a deadlock condition somewhere but I could not find the other lock that
                it was waiting upon. I believe the problem could be that the scope of what is executed in
                becameInactive() is too wide.
                threaddump_itomdipulsar-broker-7865b7ff5d-zg42s_150421-004920.log
                threaddump_itomdipulsar-broker-7865b7ff5d-gcs4n_150421-004920.log
                threaddump_itomdipulsar-broker-7865b7ff5d-8rglm_150421-004920.log
                itomdipulsar-broker-7865b7ff5d-zg42s.log
                itomdipulsar-broker-7865b7ff5d-gcs4n.log
                itomdipulsar-broker-7865b7ff5d-8rglm.log
            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.pulsar.functions.worker.ClusterServiceCoordinator.java</file>
            <file type="M">org.apache.pulsar.functions.worker.PulsarWorkerService.java</file>
            <file type="M">org.apache.pulsar.functions.worker.WorkerStatsManager.java</file>
            <file type="M">org.apache.pulsar.functions.worker.ClusterServiceCoordinatorTest.java</file>
        </fixedFiles>
    </bug>
    <bug id="13923" opendate="2022-01-24 00:00:00" fixdate="2022-02-08 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>[Proxy] Race condition in Pulsar Proxy that causes UnsupportedOperationExceptions in Proxy logs.
            </summary>
            <description>Describe the bug
                It is common that UnsupportedOperationExceptions appear on the Proxy logs. This particular issue was
                reproduced very often when Geo-replication was configured between 2 clusters.
                16:57:50.305 [pulsar-proxy-io-2-3] INFO org.apache.pulsar.proxy.server.ProxyConnection -
                [/10.34.1.169:47600] New connection opened
                16:57:50.329 [pulsar-proxy-io-2-3] INFO org.apache.pulsar.proxy.server.ProxyConnection -
                [/10.34.1.169:47600] complete connection, init proxy handler. authenticated with token role superuser,
                hasProxyToBrokerUrl: false
                16:57:50.331 [pulsar-proxy-io-2-3] WARN io.netty.channel.DefaultChannelPipeline - An exceptionCaught()
                event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the
                pipeline did not handle the exception.
                java.lang.UnsupportedOperationException: null
                at org.apache.pulsar.common.protocol.PulsarDecoder.handleProducer(PulsarDecoder.java:479)
                at org.apache.pulsar.common.protocol.PulsarDecoder.channelRead(PulsarDecoder.java:193)
                at org.apache.pulsar.proxy.server.ProxyConnection.channelRead(ProxyConnection.java:193)
                at
                io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
                [io.netty-netty-transport-4.1.72.Final.jar:4.1.72.Fi
                nal]
                at
                io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
                [io.netty-netty-transport-4.1.72.Final.jar:4.1.72.Fi
                nal]
                at
                io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
                [io.netty-netty-transport-4.1.72.Final.jar:4.1.72.Fina
                l]
                at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:324)
                [io.netty-netty-codec-4.1.72.Final.jar:4.1.72.Final]
                at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:296)
                [io.netty-netty-codec-4.1.72.Final.jar:4.1.72.Final]
                at
                io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
                [io.netty-netty-transport-4.1.72.Final.jar:4.1.72.Fi
                nal]
                at
                io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
                [io.netty-netty-transport-4.1.72.Final.jar:4.1.72.Fi
                nal]
                at
                io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
                [io.netty-netty-transport-4.1.72.Final.jar:4.1.72.Fina
                l]
                at io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1371)
                [io.netty-netty-handler-4.1.72.Final.jar:4.1.72.Final]
                at io.netty.handler.ssl.SslHandler.decodeNonJdkCompatible(SslHandler.java:1245)
                [io.netty-netty-handler-4.1.72.Final.jar:4.1.72.Final]
                at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1285)
                [io.netty-netty-handler-4.1.72.Final.jar:4.1.72.Final]
                at
                io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:507)
                [io.netty-netty-codec-4.1.72.Final.jar:4.1.72.Final
                ]
                at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:446)
                [io.netty-netty-codec-4.1.72.Final.jar:4.1.72.Final]
                at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276)
                [io.netty-netty-codec-4.1.72.Final.jar:4.1.72.Final]
                at
                io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
                [io.netty-netty-transport-4.1.72.Final.jar:4.1.72.Fi
                nal]
                at
                io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
                [io.netty-netty-transport-4.1.72.Final.jar:4.1.72.Fi
                nal]
                at
                io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
                [io.netty-netty-transport-4.1.72.Final.jar:4.1.72.Fina
                l]
                at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
                [io.netty-netty-transport-4.1.72.Final.jar:4.1.72.Final]
                at
                io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
                [io.netty-netty-transport-4.1.72.Final.jar:4.1.72.Fi
                nal]
                at
                io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
                [io.netty-netty-transport-4.1.72.Final.jar:4.1.72.Fi
                nal]
                at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
                [io.netty-netty-transport-4.1.72.Final.jar:4.1.72.Final]
                at
                io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:795)
                [io.netty-netty-transport-classes-epoll
                -4.1.72.Final.jar:4.1.72.Final]
                at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:480)
                [io.netty-netty-transport-classes-epoll-4.1.72.Final.jar:4.1.72.Final]
                at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:378)
                [io.netty-netty-transport-classes-epoll-4.1.72.Final.jar:4.1.72.Final]
                at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
                [io.netty-netty-common-4.1.72.Final.jar:4.1.72.Final]
                at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
                [io.netty-netty-common-4.1.72.Final.jar:4.1.72.Final]
                at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
                [io.netty-netty-common-4.1.72.Final.jar:4.1.72.Final]
                at java.lang.Thread.run(Thread.java:829) [?:?]

                To Reproduce
                Steps to reproduce the behavior:

                Setup 2 Pulsar clusters and enable geo-replication in a namespace that is shared across the clusters.
                Create a topic with 200 partitions in the replicated namespace.
                Restart all brokers in one cluster to get the geo-replication connections to re-initialize untill you
                have reproduced the issue in the Pulsar Proxy logs.

                Expected behavior
                The race conditions should be handled in Pulsar Proxy
            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.pulsar.broker.authentication.ProxySaslAuthenticationTest.java</file>
            <file type="M">org.apache.pulsar.common.protocol.PulsarHandler.java</file>
            <file type="M">org.apache.pulsar.proxy.server.BrokerProxyValidator.java</file>
            <file type="M">org.apache.pulsar.proxy.server.DirectProxyHandler.java</file>
            <file type="M">org.apache.pulsar.proxy.server.ProxyConfiguration.java</file>
            <file type="M">org.apache.pulsar.proxy.server.ProxyConnection.java</file>
            <file type="M">org.apache.pulsar.proxy.server.ProxyService.java</file>
            <file type="M">org.apache.pulsar.proxy.server.ServiceChannelInitializer.java</file>
            <file type="M">org.apache.pulsar.proxy.server.TargetAddressDeniedException.java</file>
            <file type="M">org.apache.pulsar.proxy.server.AuthedAdminProxyHandlerTest.java</file>
            <file type="M">org.apache.pulsar.proxy.server.BrokerProxyValidatorTest.java</file>
            <file type="M">org.apache.pulsar.proxy.server.ProxyAdditionalServletTest.java</file>
            <file type="M">org.apache.pulsar.proxy.server.ProxyAuthenticatedProducerConsumerTest.java</file>
            <file type="M">org.apache.pulsar.proxy.server.ProxyAuthenticationTest.java</file>
            <file type="M">org.apache.pulsar.proxy.server.ProxyConnectionTest.java</file>
            <file type="M">org.apache.pulsar.proxy.server.ProxyEnableHAProxyProtocolTest.java</file>
            <file type="M">org.apache.pulsar.proxy.server.ProxyKeyStoreTlsTestWithoutAuth.java</file>
            <file type="M">org.apache.pulsar.proxy.server.ProxyTlsTestWithAuth.java</file>
            <file type="M">org.apache.pulsar.proxy.server.ProxyWithAuthorizationTest.java</file>
        </fixedFiles>
    </bug>
    <bug id="11689" opendate="2021-08-17 00:00:00" fixdate="2021-08-23 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>Java consumer can block forever on batchReceive.
            </summary>
            <description>Describe the bug
                When Consumer.batchReceive() is called concurrently by different threads there exists a race condition
                in ConsumerBase.java which when triggered causes a CompletableFuture in the queue pendingBatchReceives
                to be removed from the queue but not completed, causing the consumer to block forever.
                The issue is that there are concurrent calls to peek and poll in peekNextBatchReceive and the code is
                only correct when what is peeked is polled. If another thread calls poll between a peek and poll then
                this bug occurs. There is an error message when this occurs Bug: Removed entry wasn't the expected one.
                To Reproduce

                Create a consumer
                On many threads, repeatedly call batchReceive
                Wait potentially a very long time, but eventually it will block forever.

                I added a Thread sleep between the peek and poll of peekNextBatchReceive to make it trigger faster.
                Expected behavior
                batchReceive should never block forever.
                I have a fix on the way.
            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.pulsar.client.impl.ConsumerBase.java</file>
            <file type="M">org.apache.pulsar.client.impl.ConsumerImpl.java</file>
            <file type="M">org.apache.pulsar.client.impl.MultiTopicsConsumerImpl.java</file>
            <file type="M">org.apache.pulsar.client.impl.ZeroQueueConsumerImpl.java</file>
            <file type="M">org.apache.pulsar.client.impl.ClientTestFixtures.java</file>
            <file type="M">org.apache.pulsar.client.impl.ConsumerImplTest.java</file>
            <file type="M">org.apache.pulsar.client.impl.MultiTopicsConsumerImplTest.java</file>
            <file type="M">org.apache.pulsar.client.impl.ReaderImplTest.java</file>
        </fixedFiles>
    </bug>
    <bug id="62" opendate="2016-10-14 00:00:00" fixdate="2022-04-12 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>SimpleDateFormat is not thread safe.
            </summary>
            <description>
                https://github.com/yahoo/pulsar/blob/1304d4b44d/pulsar-broker/src/main/java/com/yahoo/pulsar/broker/admin/PersistentTopics.java#L105
                https://github.com/yahoo/pulsar/blob/1304d4b44d/pulsar-broker/src/main/java/com/yahoo/pulsar/broker/service/persistent/PersistentTopic.java#L121
                https://github.com/yahoo/pulsar/blob/1304d4b44d/pulsar-client/src/main/java/com/yahoo/pulsar/client/impl/ProducerImpl.java#L1094
                https://github.com/yahoo/pulsar/blob/1304d4b44d/pulsar-websocket/src/main/java/com/yahoo/pulsar/websocket/ConsumerHandler.java#L195

            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">com.yahoo.pulsar.broker.admin.PersistentTopics.java</file>
            <file type="M">com.yahoo.pulsar.broker.service.Consumer.java</file>
            <file type="M">com.yahoo.pulsar.broker.service.Producer.java</file>
            <file type="M">com.yahoo.pulsar.broker.service.persistent.PersistentTopic.java</file>
            <file type="M">com.yahoo.pulsar.client.impl.ProducerImpl.java</file>
            <file type="M">com.yahoo.pulsar.websocket.ConsumerHandler.java</file>
        </fixedFiles>
    </bug>
    <bug id="11605" opendate="2021-08-09 00:00:00" fixdate="2022-03-18 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>Race condition in concurrent schema deletion.
            </summary>
            <description>Describe the bug
                In some scenarios, we deleted topics concurrently, which may trigger some race condition in deleting the
                same topic schema. For example, in org.apache.pulsar.broker.service.AbstractTopic#deleteSchema we will
                firstly perform schemaRegistryService#getSchema(read from bookkeeper) then
                schemaRegistryService#deleteSchemaStorage(delete its corresponding ledgers in bookkeeper). Therefore,
                when we delete a schema concurrently in two threads, it may happen that one thread has already deleted
                the ledger, and the other thread has just started executing and throws a "no such ledger" exception.
                To Reproduce
                Steps to reproduce the behavior:

                start a cluster with at least two brokers
                create a partitioned topic 'A' with multiple partitions
                concurrently delete the non-partitioned topics within topic 'A' with the schema
                then you will sporadically see 'No such ledger exists on Bookies' or 'NoNode for /schemas/XX/YY/ZZ'
                (Note that this phenomenon does not happen every time)

                Expected behavior
                Broker service can handle these scenarios correctly.
            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.pulsar.broker.service.AbstractTopic.java</file>
            <file type="M">org.apache.pulsar.broker.service.schema.BookkeeperSchemaStorage.java</file>
            <file type="M">org.apache.pulsar.broker.service.PersistentTopicE2ETest.java</file>
        </fixedFiles>
    </bug>
    <bug id="9109" opendate="2021-01-03 00:00:00" fixdate="2021-03-02 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>pulsar-timer thread blocked at redeliverUnacknowledgedMessages.
            </summary>
            <description>Describe the bug
                After broker crash and restart, consumers got blocked, consumer rateOut decrease to 0, can't auto
                recover without restart consumer process.
                To Reproduce
                Steps to reproduce the behavior:

                Run reproduce code below

                public class PulsarConsumerTest {

                private static final Logger LOG = LoggerFactory.getLogger(PulsarConsumerTest.class);

                private PulsarClient pulsarClient;
                private Consumer#byte[]> consumer;

                @Before
                public void setUp() throws Exception {
                pulsarClient = PulsarClient.builder()
                .serviceUrl("pulsar://#broker>:6650")
                .build();
                String topic = "persistent://sample/ns1/topic1";
                String subscriptionName = "test";
                DeadLetterPolicy deadLetterPolicy = DeadLetterPolicy.builder()
                .deadLetterTopic(String.format("%s-%s-DLQ", topic, subscriptionName))
                .maxRedeliverCount(3)
                .build();
                consumer = pulsarClient.newConsumer()
                .topic(topic)
                .deadLetterPolicy(deadLetterPolicy)
                .ackTimeout(5, TimeUnit.SECONDS)
                .acknowledgmentGroupTime(0, TimeUnit.MILLISECONDS)
                .subscriptionName(subscriptionName)
                .subscriptionType(SubscriptionType.Shared)
                .subscribe();
                }

                @After
                public void tearDown() throws Exception {
                pulsarClient.close();
                }

                @Test
                public void test() throws PulsarClientException {
                while (true) {
                Message#byte[]> message = consumer.receive();
                MessageId messageId = message.getMessageId();
                LOG.info("received message with messageId: {}", messageId);
                try {
                consume(message);
                } catch (Exception e) {
                LOG.error("consume message exception with messageId: {}", messageId, e);
                }
                }
                }

                private void consume(Message#byte[]> message) {
                throw new IllegalStateException("mock consume fails");
                }
                }

                Send 1000 messages to topic persistent://sample/ns1/topic1
                Wait about 10-15s(time to redeliver), kill and restart broker process
                Look into the thread pulsar-timer-4-1's stack, check whether it's blocked or not
                If the problem doesn't appear, try step 2-4 a few more times

                Expected behavior
                The thread pulsar-timer-4-1 blocked at producer.send forever, and the method consumer.receive may
                blocked at UnAckedMessageTracker#add method due to acquire a writeLock inside UnAckedMessageTracker.
                "pulsar-timer-4-1" #37 prio=5 os_prio=0 tid=0x00007efe584c0000 nid=0x62 waiting on condition
                [0x00007efe30aec000]
                java.lang.Thread.State: WAITING (parking)
                at sun.misc.Unsafe.park(Native Method)
                - parking to wait for#0x00000000af9bbee8> (a java.util.concurrent.CompletableFuture$Signaller)
                at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
                at java.util.concurrent.CompletableFuture$Signaller.block(CompletableFuture.java:1693)
                at java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3323)
                at java.util.concurrent.CompletableFuture.waitingGet(CompletableFuture.java:1729)
                at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1895)
                at org.apache.pulsar.client.impl.ProducerBase.send(ProducerBase.java:115)
                at org.apache.pulsar.client.impl.TypedMessageBuilderImpl.send(TypedMessageBuilderImpl.java:89)
                at org.apache.pulsar.client.impl.ConsumerImpl.processPossibleToDLQ(ConsumerImpl.java:1452)
                at org.apache.pulsar.client.impl.ConsumerImpl.lambda$null$12(ConsumerImpl.java:1390)
                at org.apache.pulsar.client.impl.ConsumerImpl$$Lambda$811/717118161.test(Unknown Source)
                at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:174)
                at java.util.Iterator.forEachRemaining(Iterator.java:116)
                at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
                at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481)
                at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)
                at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)
                at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
                at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499)
                at
                org.apache.pulsar.client.impl.ConsumerImpl.lambda$redeliverUnacknowledgedMessages$14(ConsumerImpl.java:1396)
                at org.apache.pulsar.client.impl.ConsumerImpl$$Lambda$810/1511392410.accept(Unknown Source)
                at java.lang.Iterable.forEach(Iterable.java:75)
                at org.apache.pulsar.client.impl.ConsumerImpl.redeliverUnacknowledgedMessages(ConsumerImpl.java:1388)
                at
                org.apache.pulsar.client.impl.MultiTopicsConsumerImpl.lambda$redeliverUnacknowledgedMessages$20(MultiTopicsConsumerImpl.java:621)
                at org.apache.pulsar.client.impl.MultiTopicsConsumerImpl$$Lambda$807/636669140.accept(Unknown Source)
                at java.util.HashMap.forEach(HashMap.java:1289)
                at
                org.apache.pulsar.client.impl.MultiTopicsConsumerImpl.redeliverUnacknowledgedMessages(MultiTopicsConsumerImpl.java:619)
                at org.apache.pulsar.client.impl.UnAckedMessageTracker$2.run(UnAckedMessageTracker.java:144)
                at
                org.apache.pulsar.shade.io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:672)
                at
                org.apache.pulsar.shade.io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:747)
                at org.apache.pulsar.shade.io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:472)
                at
                org.apache.pulsar.shade.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
                at java.lang.Thread.run(Thread.java:748)
                Locked ownable synchronizers:
                -#0x00000000a9dab610> (a java.util.concurrent.locks.ReentrantReadWriteLock$NonfairSync)

                Screenshots
                The consumer thread got blocked in our production.

                Additional context
                Broker version: 2.4.0
                pulsar-client version: 2.5.2
            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.pulsar.client.impl.UnAckedMessageTracker.java</file>
            <file type="M">org.apache.pulsar.client.impl.ConsumerImpl.java</file>
            <file type="M">org.apache.pulsar.client.api.DeadLetterTopicTest.java</file>
        </fixedFiles>
    </bug>
    <bug id="13004" opendate="2021-11-28 00:00:00" fixdate="2021-11-29 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>[metadata] Race condition in ResourceLockImpl#revalidate.
            </summary>
            <description>Describe the bug
                Current unit test org.apache.pulsar.metadata.LockManagerTest#updateValueWhenKeyDisappears have a small
                chance that will fails with following exception:

                java.util.concurrent.CompletionException:
                org.apache.pulsar.metadata.api.MetadataStoreException$LockBusyException: Resource at /my/path/1 is
                already locked
                at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
                at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:346)
                at java.base/java.util.concurrent.CompletableFuture$UniRun.tryFire(CompletableFuture.java:777)
                at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
                at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088)
                at
                org.apache.pulsar.metadata.coordination.impl.ResourceLockImpl.lambda$acquireWithNoRevalidation$7(ResourceLockImpl.java:167)
                at java.base/java.util.concurrent.CompletableFuture.uniExceptionally(CompletableFuture.java:986)
                at java.base/java.util.concurrent.CompletableFuture$UniExceptionally.tryFire(CompletableFuture.java:970)
                at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
                at java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2073)
                at
                org.apache.pulsar.metadata.impl.DelayInjectionMetadataStore.lambda$getRandomDelayStage$0(DelayInjectionMetadataStore.java:83)
                at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
                at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
                at
                java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
                at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
                at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
                at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
                at java.base/java.lang.Thread.run(Thread.java:829)

                Caused by: org.apache.pulsar.metadata.api.MetadataStoreException$LockBusyException: Resource at
                /my/path/1 is already locked
                ... 13 more

                It fails on the line here:


                pulsar/pulsar-metadata/src/test/java/org/apache/pulsar/metadata/LockManagerTest.java


                Line 198
                in
                693a066


                lock.updateValue("value-2").join();


                After some digging, I found that it's because there is a race condition of method
                org.apache.pulsar.metadata.coordination.impl.ResourceLockImpl#revalidate.
                Call stack A:

                store.delete("/my/path/1", Optional.empty()).join();
                Node Delete Event
                LockManagerImpl#handleDataNotification
                ResourceLockImpl#lockWasInvalidated
                ResourceLockImpl#revalidate

                Call stack B:

                lock.updateValue("value-2").join();
                org.apache.pulsar.metadata.coordination.impl.ResourceLockImpl#acquire
                ResourceLockImpl#acquireWithNoRevalidation fails with LockBusyException
                ResourceLockImpl#revalidate , See:


                pulsar/pulsar-metadata/src/main/java/org/apache/pulsar/metadata/coordination/impl/ResourceLockImpl.java


                Line 130
                in
                693a066


                revalidate(newValue)


                Once the node is deleted and two ResourceLockImpl#revalidate are called at the same time, one of them is
                going to fail.
                So in the case above lock.updateValue is failed.
                To Reproduce
                Steps to reproduce the behavior:

                It's easier to reproduce this when we add a 5ms delay in MetadataStore#get or use
                DelayInjectionMetadataStore in [metadata] add DelayInjectionMetadataStore #13005
                Run updateValueWhenKeyDisappears a few times
                See error.

                Expected behavior
                lock.updateValue should always success in this case.
                Screenshots
                NA
                Desktop (please complete the following information):

                OS: [e.g. iOS]

                Additional context
                NA
            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.pulsar.metadata.coordination.impl.ResourceLockImpl.java</file>
        </fixedFiles>
    </bug>
    <bug id="13986" opendate="2022-01-27 00:00:00" fixdate="2022-01-27 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>[Transactiion] Performance bottleneck of TransactionBufferHandler.
            </summary>
            <description>Is your enhancement request related to a problem? Please describe.
                The synchronization lock added due to timeout will cause the performance bottleneck of
                TransactionBufferHandler
                Describe the solution you'd like

                Do not use the run method for timeout processing
                Do not use sync locks

            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.pulsar.broker.transaction.buffer.impl.TransactionBufferHandlerImpl.java</file>
        </fixedFiles>
    </bug>
    <bug id="12723" opendate="2021-11-10 00:00:00" fixdate="2021-12-20 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>Race condition in PersistentTopic#addReplicationCluster.
            </summary>
            <description>Describe the bug
                In class org.apache.pulsar.broker.service.persistent.PersistentTopic, we have field replicators of class
                ConcurrentOpenHashMap. There is a race condiftion in method addReplicationCluster.
                replicators.computeIfAbsent(remoteCluster, r -> {
                try {
                return new PersistentReplicator(PersistentTopic.this, cursor, localCluster,
                remoteCluster, brokerService, (PulsarClientImpl) replicationClient);
                } catch (PulsarServerException e) {
                log.error("[{}] Replicator startup failed {}", topic, remoteCluster, e);
                }
                return null;
                });

                // clean up replicator if startup is failed
                if (replicators.containsKey(remoteCluster) ## replicators.get(remoteCluster) == null) {
                replicators.remove(remoteCluster);
                }

                It's clear that there is a race condition if multi threads would run in this code. For example
                Thread A is just about to execute replicators.remove, Thread B inserts a non-null PersistentReplicator.
                Then thread A will delete the PersistentReplicator which thread B just created.
                And there is no other thread safe measures applied to these code.
                Expected behavior
                It should be thead safe.
                Screenshots
                Not applicable.
                Desktop (please complete the following information):

                OS: mac

                Additional context
                Nop
            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.pulsar.broker.service.persistent.PersistentTopic.java</file>
            <file type="M">org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap.java</file>
            <file type="M">org.apache.pulsar.common.util.collections.ConcurrentOpenHashMapTest.java</file>
        </fixedFiles>
    </bug>
    <bug id="12929" opendate="2021-11-22 00:00:00" fixdate="2021-12-06 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>Deadlock in internalDeleteSubscription in metadata-store callback thread.
            </summary>
            <description>Describe the bug
                When doing certain topic operations (for e.g., delete-subscription), it can result in a deadlock
                metadata-store callback thread. Please see the stack trace below.
                "metadata-store-6-1" #43 prio=5 os_prio=0 cpu=380.47ms elapsed=797.76s tid=0x00007f6ffc026800 nid=0x74
                waiting on condition [0x00007f7001ce1000]
                java.lang.Thread.State: WAITING (parking)
                at jdk.internal.misc.Unsafe.park(java.base@11.0.12/Native Method)
                - parking to wait for#0x00000000ffe95e98> (a java.util.concurrent.CompletableFuture$Signaller)
                at java.util.concurrent.locks.LockSupport.park(java.base@11.0.12/LockSupport.java:194)
                at java.util.concurrent.CompletableFuture$Signaller.block(java.base@11.0.12/CompletableFuture.java:1796)
                at java.util.concurrent.ForkJoinPool.managedBlock(java.base@11.0.12/ForkJoinPool.java:3128)
                at java.util.concurrent.CompletableFuture.waitingGet(java.base@11.0.12/CompletableFuture.java:1823)
                at java.util.concurrent.CompletableFuture.get(java.base@11.0.12/CompletableFuture.java:1998)
                at
                org.apache.pulsar.broker.admin.impl.PersistentTopicsBase.internalDeleteSubscriptionForNonPartitionedTopic(PersistentTopicsBase.java:1454)
                at
                org.apache.pulsar.broker.admin.impl.PersistentTopicsBase.lambda$internalDeleteSubscription$69(PersistentTopicsBase.java:1431)
                at
                org.apache.pulsar.broker.admin.impl.PersistentTopicsBase$$Lambda$1126/0x000000084080a840.accept(Unknown
                Source)
                at
                java.util.concurrent.CompletableFuture$UniAccept.tryFire(java.base@11.0.12/CompletableFuture.java:714)
                at java.util.concurrent.CompletableFuture.postComplete(java.base@11.0.12/CompletableFuture.java:506)
                at java.util.concurrent.CompletableFuture.complete(java.base@11.0.12/CompletableFuture.java:2073)
                at org.apache.pulsar.metadata.impl.ZKMetadataStore.lambda$null$7(ZKMetadataStore.java:158)
                at org.apache.pulsar.metadata.impl.ZKMetadataStore$$Lambda$220/0x000000084033bc40.run(Unknown Source)
                at java.util.concurrent.ThreadPoolExecutor.runWorker(java.base@11.0.12/ThreadPoolExecutor.java:1128)
                at java.util.concurrent.ThreadPoolExecutor$Worker.run(java.base@11.0.12/ThreadPoolExecutor.java:628)
                at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
                at java.lang.Thread.run(java.base@11.0.12/Thread.java:829)
                The issue is similar to: #12726
                To Reproduce
                This is a race condition, I have not been able to come up with a reliable way to reproduce this. But it
                is easily reproducible inin a 3-node broker setup, creating and deleting topic consumers.
                Expected behavior
                The metadata-store callback thread should not deadlock.
                Screenshots
                If applicable, add screenshots to help explain your problem.
                Desktop (please complete the following information):

                OS: [e.g. iOS]

                Additional context
                Add any other context about the problem here.
            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.pulsar.broker.admin.impl.PersistentTopicsBase.java</file>
        </fixedFiles>
    </bug>
    <bug id="3768" opendate="2019-03-06 00:00:00" fixdate="2022-12-07 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>[pulsar-function] intermittent test failure due to deadlock.
            </summary>
            <description>org.apache.pulsar.functions.worker.PulsarWorkerAssignmentTest.shutdown() has intermittent
                failure due to deadlock into function-worker. Disabling this for now and we have to enable back once
                deadlock issue is fixed at function-worker.
                Error Message
                Method org.apache.pulsar.functions.worker.PulsarWorkerAssignmentTest.shutdown() didn't finish within the
                time-out 60000
                Stacktrace
                org.testng.internal.thread.ThreadTimeoutException: Method
                org.apache.pulsar.functions.worker.PulsarWorkerAssignmentTest.shutdown() didn't finish within the
                time-out 60000
                at io.netty.channel.epoll.Native.eventFdWrite(Native Method)
                at io.netty.channel.epoll.EpollEventLoop.wakeup(EpollEventLoop.java:169)
                at io.netty.util.concurrent.SingleThreadEventExecutor.execute(SingleThreadEventExecutor.java:799)
                at io.netty.channel.AbstractChannelHandlerContext.safeExecute(AbstractChannelHandlerContext.java:1013)
                at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:825)
                at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:794)
                at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:837)
                at org.apache.pulsar.client.impl.ClientCnx.sendRequestWithId(ClientCnx.java:685)
                at org.apache.pulsar.client.impl.ProducerImpl.closeAsync(ProducerImpl.java:609)
                at org.apache.pulsar.functions.sink.PulsarSink$PulsarSinkProcessorBase.close(PulsarSink.java:130)
                at org.apache.pulsar.functions.sink.PulsarSink.close(PulsarSink.java:306)
                at org.apache.pulsar.functions.instance.JavaInstanceRunnable.close(JavaInstanceRunnable.java:482)
                at org.apache.pulsar.functions.runtime.ThreadRuntime.stop(ThreadRuntime.java:128)
                at org.apache.pulsar.functions.runtime.RuntimeSpawner.close(RuntimeSpawner.java:151)
                at org.apache.pulsar.functions.worker.FunctionActioner.stopFunction(FunctionActioner.java:243)
                at
                org.apache.pulsar.functions.worker.FunctionRuntimeManager.conditionallyStopFunction(FunctionRuntimeManager.java:868)
                at
                org.apache.pulsar.functions.worker.FunctionRuntimeManager.stopFunction(FunctionRuntimeManager.java:441)
                at
                org.apache.pulsar.functions.worker.FunctionRuntimeManager.lambda$stopAllOwnedFunctions$1(FunctionRuntimeManager.java:429)
                at org.apache.pulsar.functions.worker.FunctionRuntimeManager$$Lambda$795/1890737615.accept(Unknown
                Source)
                at java.util.HashMap$Values.forEach(HashMap.java:981)
                at
                org.apache.pulsar.functions.worker.FunctionRuntimeManager.stopAllOwnedFunctions(FunctionRuntimeManager.java:426)
                at org.apache.pulsar.functions.worker.FunctionRuntimeManager.close(FunctionRuntimeManager.java:813)
                at org.apache.pulsar.functions.worker.WorkerService.stop(WorkerService.java:218)
                at
                org.apache.pulsar.functions.worker.PulsarWorkerAssignmentTest.shutdown(PulsarWorkerAssignmentTest.java:135)
                at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
                at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
                at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
                at java.lang.reflect.Method.invoke(Method.java:498)
                at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:124)
                at org.testng.internal.InvokeMethodRunnable.runOne(InvokeMethodRunnable.java:54)
                at org.testng.internal.InvokeMethodRunnable.run(InvokeMethodRunnable.java:44)
                at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
                at java.util.concurrent.FutureTask.run(FutureTask.java:266)
                at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
                at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
                at java.lang.Thread.run(Thread.java:748)

            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.pulsar.client.api.BrokerServiceLookupTest.java</file>
            <file type="M">org.apache.pulsar.functions.worker.PulsarWorkerAssignmentTest.java</file>
        </fixedFiles>
    </bug>
    <bug id="14633" opendate="2022-03-10 00:00:00" fixdate="2022-03-15 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>setupTopicPublishRateLimiterMonitor() can block forever, causing deadlock for metadata store
                operations.
            </summary>
            <description>Describe the bug
                (


                pulsar/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java


                Line 594
                in
                2b3e8ae


                public synchronized void setupTopicPublishRateLimiterMonitor() {


                )
                This can block forever, causing metadata operations to deadlock.
                "metadata-store-6-1" #61 prio=5 os_prio=0 cpu=139825.70ms elapsed=81027.01s tid=0x00007f1598001000
                nid=0x8b waiting for monitor entry [0x00007f15a7805000]
                java.lang.Thread.State: BLOCKED (on object monitor)
                at
                org.apache.pulsar.broker.service.BrokerService.setupTopicPublishRateLimiterMonitor(BrokerService.java:562)
                - waiting to lock#0x00000003018b1c30> (a org.apache.pulsar.broker.service.BrokerService)
                at org.apache.pulsar.broker.service.AbstractTopic.updatePublishDispatcher(AbstractTopic.java:920)
                at org.apache.pulsar.broker.service.AbstractTopic.updatePublishDispatcher(AbstractTopic.java:807)
                at org.apache.pulsar.broker.service.AbstractTopic.updateMaxPublishRate(AbstractTopic.java:770)
                at
                org.apache.pulsar.broker.service.persistent.PersistentTopic.onPoliciesUpdate(PersistentTopic.java:2424)
                at org.apache.pulsar.broker.service.BrokerService.lambda$null$81(BrokerService.java:1807)
                at org.apache.pulsar.broker.service.BrokerService$$Lambda$1326/0x00000008408bc440.accept(Unknown Source)
                at java.util.Optional.ifPresent(java.base@11.0.13/Optional.java:183)
                at org.apache.pulsar.broker.service.BrokerService.lambda$null$82(BrokerService.java:1807)
                at org.apache.pulsar.broker.service.BrokerService$$Lambda$1325/0x00000008408bc040.accept(Unknown Source)
                at java.util.concurrent.CompletableFuture.uniAcceptNow(java.base@11.0.13/CompletableFuture.java:753)
                at java.util.concurrent.CompletableFuture.uniAcceptStage(java.base@11.0.13/CompletableFuture.java:731)
                at java.util.concurrent.CompletableFuture.thenAccept(java.base@11.0.13/CompletableFuture.java:2108)
                at org.apache.pulsar.broker.service.BrokerService.lambda$null$83(BrokerService.java:1802)
                at org.apache.pulsar.broker.service.BrokerService$$Lambda$678/0x0000000840655840.accept(Unknown Source)
                at
                org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap$Section.forEach(ConcurrentOpenHashMap.java:387)
                at
                org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap.forEach(ConcurrentOpenHashMap.java:159)
                at
                org.apache.pulsar.broker.service.BrokerService.lambda$handlePoliciesUpdates$84(BrokerService.java:1798)
                at org.apache.pulsar.broker.service.BrokerService$$Lambda$677/0x0000000840655440.accept(Unknown Source)
                at
                java.util.concurrent.CompletableFuture$UniAccept.tryFire(java.base@11.0.13/CompletableFuture.java:714)
                at java.util.concurrent.CompletableFuture.postComplete(java.base@11.0.13/CompletableFuture.java:506)
                at java.util.concurrent.CompletableFuture.complete(java.base@11.0.13/CompletableFuture.java:2073)
                at org.apache.pulsar.metadata.impl.ZKMetadataStore.lambda$null$7(ZKMetadataStore.java:139)
                at org.apache.pulsar.metadata.impl.ZKMetadataStore$$Lambda$226/0x000000084034fc40.run(Unknown Source)
                at org.apache.pulsar.metadata.impl.AbstractMetadataStore$TaskWrapper.run(AbstractMetadataStore.java:99)
                at java.util.concurrent.Executors$RunnableAdapter.call(java.base@11.0.13/Executors.java:515)
                at java.util.concurrent.FutureTask.run(java.base@11.0.13/FutureTask.java:264)
                at java.util.concurrent.ThreadPoolExecutor.runWorker(java.base@11.0.13/ThreadPoolExecutor.java:1128)
                at java.util.concurrent.ThreadPoolExecutor$Worker.run(java.base@11.0.13/ThreadPoolExecutor.java:628)
                at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
                at java.lang.Thread.run(java.base@11.0.13/Thread.java:829)
                To Reproduce
                No reliable way to reproduce the problem, though we have seen this in production deployment.
                Expected behavior
                This method should not block.
            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.pulsar.broker.admin.impl.BrokersBase.java</file>
            <file type="M">org.apache.pulsar.broker.service.BrokerService.java</file>
        </fixedFiles>
    </bug>
    <bug id="18196" opendate="2022-10-26 00:00:00" fixdate="2022-10-27 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>[Bug] locallyAcquiredLocks leak in OwnershipCache.
            </summary>
            <description>Search before asking

                I searched in the issues and found nothing similar.

                Version
                master
                Minimal reproduce step
                review the code

                34M
                What did you expect to see?
                public CompletableFuture
                #Void>
                removeOwnership(NamespaceBundle bundle) {
                ResourceLock
                #NamespaceEphemeralData>
                lock = locallyAcquiredLocks.get(bundle);
                if (lock == null) {
                // We don't own the specified bundle anymore
                return CompletableFuture.completedFuture(null);
                }

                return lock.release();
                }

                should be locallyAcquiredLocks.remove(bundle)
                What did you see instead?
                leak
                Anything else?
                No response
                Are you willing to submit a PR?

                I'm willing to submit a PR!

            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.pulsar.broker.namespace.OwnershipCache.java</file>
            <file type="M">org.apache.pulsar.broker.service.persistent.SimpleProducerConsumerTestStreamingDispatcherTest.java</file>
        </fixedFiles>
    </bug>
    <bug id="18988" opendate="2022-12-19 00:00:00" fixdate="2022-12-20 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>[Bug] Deadlock pulsar-io and metadata-store if transactions enabled.
            </summary>
            <description>Search before asking

                I searched in the issues and found nothing similar.

                Version
                Seen in 2.10, believe the issue still exists in current master, not able to reproduce
                Minimal reproduce step
                Not able to reproduce it programatically
                What did you expect to see?
                To not get deadlock
                What did you see instead?
                Metadata store
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911460259Z stdout F     at
                java.base@11.0.17/java.lang.Thread.run(Thread.java:829)
                -- | --
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911454155Z stdout F     at
                app//io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911448097Z stdout F     at
                java.base@11.0.17/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911442099Z stdout F     at
                java.base@11.0.17/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911435811Z stdout F     at
                java.base@11.0.17/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911429439Z stdout F     at
                java.base@11.0.17/java.util.concurrent.FutureTask.run(FutureTask.java:264)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911423083Z stdout F     at
                java.base@11.0.17/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911415954Z stdout F     at
                app//org.apache.pulsar.metadata.impl.ZKMetadataStore$Lambda$350/0x00000008404b5840.run(Unknown Source)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911409602Z stdout F     at
                app//org.apache.pulsar.metadata.impl.ZKMetadataStore.lambda$existsFromStore$9(ZKMetadataStore.java:320)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911395777Z stdout F     at
                java.base@11.0.17/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2073)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911389631Z stdout F     at
                java.base@11.0.17/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911377548Z stdout F     at
                java.base@11.0.17/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:714)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911371189Z stdout F     at
                app//org.apache.pulsar.broker.transaction.pendingack.impl.PendingAckHandleImpl$Lambda$1033/0x000000084092d440.accept(Unknown
                Source)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911364888Z stdout F     at
                app//org.apache.pulsar.broker.transaction.pendingack.impl.PendingAckHandleImpl.lambda$new$0(PendingAckHandleImpl.java:148)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911356003Z stdout F       - locked
                org.apache.pulsar.broker.transaction.pendingack.impl.PendingAckHandleImpl@1289d850
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911346505Z stdout F     at
                app//org.apache.pulsar.broker.transaction.pendingack.impl.PendingAckHandleImpl.completeHandleFuture(PendingAckHandleImpl.java:904)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911340386Z stdout F     at
                java.base@11.0.17/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2073)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911334424Z stdout F     at
                java.base@11.0.17/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911328294Z stdout F     at
                java.base@11.0.17/java.util.concurrent.CompletableFuture$UniCompose.tryFire(CompletableFuture.java:1072)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911322147Z stdout F     at
                app//org.apache.pulsar.broker.service.persistent.PersistentSubscription$Lambda$1032/0x000000084092d040.apply(Unknown
                Source)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911315581Z stdout F     at
                app//org.apache.pulsar.broker.service.persistent.PersistentSubscription.lambda$addConsumer$2(PersistentSubscription.java:214)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911309219Z stdout F      owned by pulsar-io-12-16
                Id=161
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911302363Z stdout F "metadata-store-18-1" Id=16 in
                BLOCKED on lock=org.apache.pulsar.broker.service.persistent.PersistentSubscription@981a97c

                and pulsar-io

                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911735597Z stdout F     at
                app//io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:346)
                -- | --
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911729568Z stdout F     at
                app//io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911723289Z stdout F     at
                app//io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911716847Z stdout F     at
                app//io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.91171054Z stdout F     at
                app//org.apache.pulsar.common.protocol.PulsarDecoder.channelRead(PulsarDecoder.java:177)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911704302Z stdout F     at
                app//org.apache.pulsar.client.impl.ClientCnx.handleError(ClientCnx.java:716)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911698102Z stdout F     at
                java.base@11.0.17/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911691782Z stdout F     at
                java.base@11.0.17/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911685096Z stdout F     at
                java.base@11.0.17/java.util.concurrent.CompletableFuture$UniExceptionally.tryFire(CompletableFuture.java:970)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911676176Z stdout F     at
                java.base@11.0.17/java.util.concurrent.CompletableFuture.uniExceptionally(CompletableFuture.java:986)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911669334Z stdout F     at
                app//org.apache.pulsar.client.impl.ProducerImpl$Lambda$886/0x00000008408bbc40.apply(Unknown Source)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911662942Z stdout F     at
                app//org.apache.pulsar.client.impl.ProducerImpl.lambda$connectionOpened$17(ProducerImpl.java:1724)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911656632Z stdout F     at
                java.base@11.0.17/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911650516Z stdout F     at
                java.base@11.0.17/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911644463Z stdout F     at
                java.base@11.0.17/java.util.concurrent.CompletableFuture$UniExceptionally.tryFire(CompletableFuture.java:970)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911638403Z stdout F     at
                java.base@11.0.17/java.util.concurrent.CompletableFuture.uniExceptionally(CompletableFuture.java:986)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911632203Z stdout F     at
                app//org.apache.pulsar.broker.transaction.buffer.impl.TopicTransactionBuffer$TopicTransactionBufferRecover$Lambda$807/0x000000084086f040.apply(Unknown
                Source)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911625601Z stdout F     at
                app//org.apache.pulsar.broker.transaction.buffer.impl.TopicTransactionBuffer$TopicTransactionBufferRecover.lambda$run$3(TopicTransactionBuffer.java:690)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911614336Z stdout F     at
                app//org.apache.pulsar.broker.transaction.buffer.impl.TopicTransactionBuffer$1.recoverExceptionally(TopicTransactionBuffer.java:213)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911608156Z stdout F     at
                app//org.apache.pulsar.broker.service.persistent.PersistentTopic.close(PersistentTopic.java:1284)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911602161Z stdout F     at
                app//org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap.forEach(ConcurrentOpenHashMap.java:272)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911596056Z stdout F     at
                app//org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap$Section.forEach(ConcurrentOpenHashMap.java:544)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911586921Z stdout F     at
                app//org.apache.pulsar.broker.service.persistent.PersistentTopic$Lambda$1754/0x0000000840724c40.accept(Unknown
                Source)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911580879Z stdout F     at
                app//org.apache.pulsar.broker.service.persistent.PersistentTopic.lambda$close$35(PersistentTopic.java:1284)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911574831Z stdout F       - locked
                org.apache.pulsar.broker.service.persistent.PersistentSubscription@981a97c
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911568496Z stdout F     at
                app//org.apache.pulsar.broker.service.persistent.PersistentSubscription.disconnect(PersistentSubscription.java:899)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911562385Z stdout F     at
                java.base@11.0.17/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2235)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.9115553Z stdout F     at
                java.base@11.0.17/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1106)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911549267Z stdout F     at
                app//org.apache.pulsar.broker.service.persistent.PersistentSubscription$Lambda$1764/0x00000008405ab040.apply(Unknown
                Source)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911543136Z stdout F     at
                app//org.apache.pulsar.broker.service.persistent.PersistentSubscription.lambda$disconnect$13(PersistentSubscription.java:899)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911536996Z stdout F       - locked
                org.apache.pulsar.broker.service.persistent.PersistentSubscription@981a97c
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911530821Z stdout F     at
                app//org.apache.pulsar.broker.service.persistent.PersistentSubscription.close(PersistentSubscription.java:879)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911524639Z stdout F     at
                app//org.apache.pulsar.broker.transaction.pendingack.impl.PendingAckHandleImpl.close(PendingAckHandleImpl.java:938)
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911518203Z stdout F      owned by metadata-store-18-1
                Id=16
                2022-12-19T08:36:33.404+0000 | 2022-12-19T08:36:30.911507882Z stdout F "pulsar-io-12-16" Id=161 in
                BLOCKED on lock=org.apache.pulsar.broker.transaction.pendingack.impl.PendingAckHandleImpl@1289d850


                Anything else?
                No response
                Are you willing to submit a PR?

                I'm willing to submit a PR!

            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.pulsar.broker.transaction.pendingack.impl.PendingAckHandleImpl.java</file>
        </fixedFiles>
    </bug>
    <bug id="17446" opendate="2022-09-03 00:00:00" fixdate="2022-10-12 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>[Bug] Producer may be permanently blocked by chunking messages when blockIfQueueFull is enabled.
            </summary>
            <description>Search before asking

                I searched in the issues and found nothing similar.

                Version
                Pulsar 2.11
                Minimal reproduce step
                It can be reproduced simply by following.
                @Test
                public void testMiniChunkingBlockIfQueueFull() throws Exception {
                this.conf.setMaxMessageSize(1000);

                final String topicName = "persistent://my-property/my-ns/testChunkingWithOrderingKey";

                final ExecutorService exec = Executors.newFixedThreadPool(1);

                @Cleanup
                Producer#byte[]> producer = pulsarClient.newProducer().topic(topicName).enableChunking(true)
                .chunkMaxMessageSize(1)
                .blockIfQueueFull(true)
                .maxPendingMessages(1000)
                .enableBatching(false).create();

                byte[] data = RandomUtils.nextBytes(1001);
                producer.newMessage().value(data).send();
                }

                What did you expect to see?
                The reason for this bug is how the chunk message semaphore is obtained.


                pulsar/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ProducerImpl.java


                Lines 520 to 527
                in
                359cfa7


                // chunked message also sent individually so, try to acquire send-permits


                for (int i = 0; i
                (totalChunks - 1); i++) {


                if (!canEnqueueRequest(callback, message.getSequenceId(), 0 /* The memory was already reserved */)) {


                client.getMemoryLimitController().releaseMemory(uncompressedSize);


                semaphoreRelease(i + 1);


                return;


                }


                }


                When a large message is split into a large number of chunks (i.e. the message is too big or the
                chunkMaxMessageSize is set too small), all the remaining semaphores will be acquired. The sending
                (send() and sendAsync()) of large message will be blocked by itself forever.
                By the way, once blockIfQueueFull/maxPendingMessages/chunking are enabled at the same time, this risk of
                deadlock exists even if the number of chunks of a single message is not very large.
                What did you see instead?
                //
                Anything else?
                No response
                Are you willing to submit a PR?

                I'm willing to submit a PR!

            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.pulsar.client.impl.MessageChunkingTest.java</file>
            <file type="M">org.apache.pulsar.client.impl.ProducerImpl.java</file>
        </fixedFiles>
    </bug>
    <bug id="12885" opendate="2021-11-19 00:00:00" fixdate="2022-02-03 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>[Bug] Unordered consuming case in Key_Shared subscription.
            </summary>
            <description>Describe the bug
                It's a previous flaky test in
                org.apache.pulsar.client.api.KeySharedSubscriptionTest#testRemoveFirstConsumer
                See #11426
                There is a race condition in PersistentDispatcherMultipleConsumers when previous client closed with
                unack messaages.
                Detailed Explanation:
                Here is the core steps of this case.

                produce 10 messages: m0~m9
                wait unitl c1 got all the 10 message.
                create c2 with same setting as c1.
                produce 10 messages: m10~m19
                c2 will not be able to receive any messages until c1 is done processing whatever he got prefetched.
                c1.close();
                Call c2.receive() now, It should receive m0. But there is some chance it will return m10.

                The race condition happens after step6.
                Just before step6, there is a retry loop going on for this consumer.
                Thread 1:
                1.1 PersistentDispatcherMultipleConsumers#readMoreEntries //synchronized
                1.2 calculateToRead() return (10,xxx)
                1.3 getMessagesToReplayNow() return m10-m14
                1.4 havePendingReplayRead = true
                1.5 asyncReplayEntriesInOrder(m10-m14) --> cursor.asyncReplayEntries() --> will callback
                readEntriesComplete async.

                Thread 2:
                2.1 PersistentDispatcherMultipleConsumers#readEntriesComplete //synchronized
                2.2 havePendingReplayRead = false;
                2.3 PersistentStickyKeyDispatcherMultipleConsumers#sendMessagesToConsumers(m10-m14)
                2.4 //DEBUG Log: select consumer c1 with messages num 0, read type is Replay
                Can not send to c1 because it runs out of permits.
                2.5 //DEBUG Log: select consumer c2 with messages num 0, read type is Replay
                Can not send to c2 because it should wait c1 to complete unacked messages.
                2.6 Finally, no consumer to send message. So it schedule call readMoreEntries() in 100ms.

                After we close c1, PersistentDispatcherMultipleConsumers#removeConsumer will be called like this.
                Thread3
                3.1PersistentDispatcherMultipleConsumers#removeConsumer
                3.2 consumer.getPendingAcks().forEach : addMessageToReplay m0-m9
                3.3 calls readMoreEntries.

                If Thread3 happens after Thread2, everything is ok, and this is most of the real cases. As time between
                Thread1 and Thread2 is quite small.
                But if it does happens in the order of Thread1 --> Thread3 --> Thread2. The disorder occurs.
                In the readMoreEntries of 3.3 , calculateToRead return -1,-1 because havePendingReplayRead is true in
                1.2 of Thread1. So the readMoreEntries will just returns without further actions.
                Then in Thread2, previous reading ended, and we got m10-m14 to dispatch. now we can select consumer c2
                because we have no more c1 for waiting. So the client c2 got m10 instead of m0.
                To Reproduce
                Steps to reproduce the behavior:

                It easier to reproduce this in local environment by changing the 100ms to 1ms here.


                pulsar/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentStickyKeyDispatcherMultipleConsumers.java


                Line 294
                in
                5523604


                }, 100, TimeUnit.MILLISECONDS);


                Run Test on org.apache.pulsar.client.api.KeySharedSubscriptionTest#testRemoveFirstConsumer. It will hit
                the race condition in a few retries.

                Expected behavior
                As the case designed in testRemoveFirstConsumer. The consuming order should be right.
                Screenshots
                Nop
                Desktop (please complete the following information):

                OS: macOS

                Additional context
                NO
            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.pulsar.broker.service.persistent.PersistentDispatcherMultipleConsumers.java</file>
            <file type="M">org.apache.pulsar.broker.service.persistent.PersistentStickyKeyDispatcherMultipleConsumers.java</file>
        </fixedFiles>
    </bug>
    <bug id="13964" opendate="2022-01-26 00:00:00" fixdate="2022-12-22 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>Flaky-tests: PulsarClientImpl.close hangs forever.
            </summary>
            <description>PulsarClientImpl.close sometimes hangs forever. Example from
                ClientDeduplicationFailureTest.shutdown .
                example failure
                "main" #1 prio=5 os_prio=0 cpu=287708.03ms elapsed=6747.96s tid=0x00007f46e0028000 nid=0xc9a waiting on
                condition [0x00007f46e549e000]
                java.lang.Thread.State: WAITING (parking)
                at jdk.internal.misc.Unsafe.park(java.base@11.0.13/Native Method)
                - parking to wait for#0x00000000dde38ad0> (a java.util.concurrent.CompletableFuture$Signaller)
                at java.util.concurrent.locks.LockSupport.park(java.base@11.0.13/LockSupport.java:194)
                at java.util.concurrent.CompletableFuture$Signaller.block(java.base@11.0.13/CompletableFuture.java:1796)
                at java.util.concurrent.ForkJoinPool.managedBlock(java.base@11.0.13/ForkJoinPool.java:3128)
                at java.util.concurrent.CompletableFuture.waitingGet(java.base@11.0.13/CompletableFuture.java:1823)
                at java.util.concurrent.CompletableFuture.get(java.base@11.0.13/CompletableFuture.java:1998)
                at org.apache.pulsar.client.impl.PulsarClientImpl.close(PulsarClientImpl.java:685)
                at
                org.apache.pulsar.client.api.ClientDeduplicationFailureTest.shutdown(ClientDeduplicationFailureTest.java:131)

                pulsar-client-shutdown-threadawaiting notification
                pulsar-client-shutdown-threadawaiting notification
                at java.lang.Object.wait(java.base@11.0.13/Native Method)
                at java.lang.Object.wait(java.base@11.0.13/Object.java:328)
                at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:253)
                at io.netty.util.concurrent.DefaultPromise.get(DefaultPromise.java:337)
                at org.apache.pulsar.client.impl.PulsarClientImpl.shutdownEventLoopGroup(PulsarClientImpl.java:811)
                at org.apache.pulsar.client.impl.PulsarClientImpl.shutdown(PulsarClientImpl.java:757)
                at org.apache.pulsar.client.impl.PulsarClientImpl.lambda$closeAsync$20(PulsarClientImpl.java:719)
                at org.apache.pulsar.client.impl.PulsarClientImpl$$Lambda$943/0x00000001009c3040.run(Unknown Source)
                at java.lang.Thread.run(java.base@11.0.13/Thread.java:829)

                There's a possible deadlock.
            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.pulsar.client.impl.PulsarClientImpl.java</file>
        </fixedFiles>
    </bug>
    <bug id="4635" opendate="2019-06-28 00:00:00" fixdate="2020-11-17 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>Bookie down causes deadlock in broker.
            </summary>
            <description>One of multiple bookie servers in our cluster went down due to a hardware failure. At the same
                time, the broker server went down. Messages that the broker could not connect to ZK were output to its
                log. I think this is due to a deadlock.
                19:38:55.846 [pulsar-zk-session-watcher-5-1] WARN o.a.p.z.ZooKeeperSessionWatcher - zoo keeper
                disconnected, waiting to reconnect, time remaining = 25 seconds
                19:38:57.846 [pulsar-zk-session-watcher-5-1] WARN o.a.p.z.ZooKeeperSessionWatcher - zoo keeper
                disconnected, waiting to reconnect, time remaining = 23 seconds
                19:38:59.847 [pulsar-zk-session-watcher-5-1] WARN o.a.p.z.ZooKeeperSessionWatcher - zoo keeper
                disconnected, waiting to reconnect, time remaining = 21 seconds
                19:39:01.847 [pulsar-zk-session-watcher-5-1] WARN o.a.p.z.ZooKeeperSessionWatcher - zoo keeper
                disconnected, waiting to reconnect, time remaining = 19 seconds
                19:39:03.847 [pulsar-zk-session-watcher-5-1] WARN o.a.p.z.ZooKeeperSessionWatcher - zoo keeper
                disconnected, waiting to reconnect, time remaining = 16 seconds
                19:39:05.847 [pulsar-zk-session-watcher-5-1] WARN o.a.p.z.ZooKeeperSessionWatcher - zoo keeper
                disconnected, waiting to reconnect, time remaining = 14 seconds
                19:39:07.848 [pulsar-zk-session-watcher-5-1] WARN o.a.p.z.ZooKeeperSessionWatcher - zoo keeper
                disconnected, waiting to reconnect, time remaining = 12 seconds
                19:39:09.848 [pulsar-zk-session-watcher-5-1] WARN o.a.p.z.ZooKeeperSessionWatcher - zoo keeper
                disconnected, waiting to reconnect, time remaining = 10 seconds
                19:39:11.848 [pulsar-zk-session-watcher-5-1] WARN o.a.p.z.ZooKeeperSessionWatcher - zoo keeper
                disconnected, waiting to reconnect, time remaining = 8 seconds
                19:39:13.849 [pulsar-zk-session-watcher-5-1] WARN o.a.p.z.ZooKeeperSessionWatcher - zoo keeper
                disconnected, waiting to reconnect, time remaining = 6 seconds
                19:39:15.849 [pulsar-zk-session-watcher-5-1] WARN o.a.p.z.ZooKeeperSessionWatcher - zoo keeper
                disconnected, waiting to reconnect, time remaining = 4 seconds
                19:39:17.849 [pulsar-zk-session-watcher-5-1] WARN o.a.p.z.ZooKeeperSessionWatcher - zoo keeper
                disconnected, waiting to reconnect, time remaining = 2 seconds
                19:39:19.849 [pulsar-zk-session-watcher-5-1] WARN o.a.p.z.ZooKeeperSessionWatcher - zoo keeper
                disconnected, waiting to reconnect, time remaining = 0 seconds
                19:39:21.850 [pulsar-zk-session-watcher-5-1] ERROR o.a.p.z.ZooKeeperSessionWatcher - timeout expired for
                reconnecting, invoking shutdown service

                Below is a thread dump just before the broker shuts down.
                broker_threaddump
                This phenomenon is similar to #3566. However the Pulsar version of the broker is 2.3.2, and the previous
                bug should have already been fixed.
            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.pulsar.broker.namespace.NamespaceService.java</file>
        </fixedFiles>
    </bug>
    <bug id="14438" opendate="2022-02-24 00:00:00" fixdate="2022-08-01 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>sometimes internalDeleteTopicForcefully will block forever.
            </summary>
            <description>


                pulsar/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/PersistentTopicsBase.java


                Line 312
                in
                d1fb88a


                pulsar().getBrokerService().deleteTopic(topicName.toString(), true, deleteSchema).get();


                "pulsar-web-44-4" #148 prio=5 os_prio=0 tid=0x00007fcbf7f89000 nid=0x6d97 waiting on condition
                [0x00007fcabc99e000]
                java.lang.Thread.State: WAITING (parking)
                at sun.misc.Unsafe.park(Native Method)
                - parking to wait for#0x000000073d14e618> (a java.util.concurrent.CompletableFuture$Signaller)
                at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
                at java.util.concurrent.CompletableFuture$Signaller.block(CompletableFuture.java:1693)
                at java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3323)
                at java.util.concurrent.CompletableFuture.waitingGet(CompletableFuture.java:1729)
                at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1895)
                at
                org.apache.pulsar.broker.admin.impl.PersistentTopicsBase.internalDeleteTopicForcefully(PersistentTopicsBase.java:379)
                at
                org.apache.pulsar.broker.admin.impl.PersistentTopicsBase.internalDeleteTopic(PersistentTopicsBase.java:961)
                at org.apache.pulsar.broker.admin.v2.PersistentTopics.deleteTopic(PersistentTopics.java:889)
                at sun.reflect.GeneratedMethodAccessor241.invoke(Unknown Source)
                at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
                at java.lang.reflect.Method.invoke(Method.java:498)
                at
                org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
                at
                org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory$$Lambda$419/1877964230.invoke(Unknown
                Source)
                at
                org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
                at
                org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
                at
                org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$VoidOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:159)
                at
                org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
                at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
                at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
                at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
                at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
                at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
                at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
                at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
                at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
                at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
                at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
                at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
                at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
                at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
                at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
                at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
                at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
                at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
                at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
                at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1631)
                at org.apache.pulsar.broker.web.VpcLookupFilter.doFilter(VpcLookupFilter.java:148)
                at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
                at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
                at org.apache.pulsar.broker.web.ResponseHandlerFilter.doFilter(ResponseHandlerFilter.java:66)
                at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
                at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
                at org.apache.pulsar.broker.web.AuthenticationFilter.doFilter(AuthenticationFilter.java:82)
                at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
                at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
                at org.apache.pulsar.broker.web.PreInterceptFilter.doFilter(PreInterceptFilter.java:68)
                at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
                at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
                at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
                at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
                at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
                at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
                at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
                at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
                at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
                at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
                at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
                at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
                at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
                at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)
                at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
                at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:179)
                at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
                at org.eclipse.jetty.server.Server.handle(Server.java:516)
                at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:400)
                at org.eclipse.jetty.server.HttpChannel$$Lambda$537/2098987772.dispatch(Unknown Source)
                at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:645)
                at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:392)
                at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
                at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
                at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
                at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
                at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
                at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
                at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
                at java.lang.Thread.run(Thread.java:748)

                in our scene, when we dump the thread many times , we can see this will wait forever
            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.pulsar.broker.service.persistent.PersistentTopic.java</file>
            <file type="M">org.apache.pulsar.broker.service.PersistentTopicE2ETest.java</file>
        </fixedFiles>
    </bug>
    <bug id="14362" opendate="2022-02-17 00:00:00" fixdate="2022-04-20 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>Broker Healthcheck Endpoint Exposes Race Conditions.
            </summary>
            <description>Describe the bug
                There appears to be a few race conditions in the /brokers/health endpoint. I verified this is in 2.9.1
                and it looks like it is probably present in master.
                There are several issues exposed by this behavior and the resulting stack traces.

                One call to that endpoint can force another to fail.
                There is a chance for an NPE here:


                pulsar/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentTopic.java


                Lines 1051 to 1057
                in
                f7f8619


                void removeSubscription(String subscriptionName) {


                PersistentSubscription sub = subscriptions.remove(subscriptionName);


                // preserve accumulative stats form removed subscription


                SubscriptionStatsImpl stats = sub.getStats(false, false, false);


                bytesOutFromRemovedSubscriptions.add(stats.bytesOutCounter);


                msgOutFromRemovedSubscriptions.add(stats.msgOutCounter);


                }


                Also relevant for the above code is that because it is called outside of a lock on the subscription, it
                could possibly remove the wrong subscription.
                This method is blocking a pulsar thread without any obvious reason:


                pulsar/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java


                Lines 1008 to 1037
                in
                f7f8619


                public void deleteCursor(String name) throws InterruptedException, ManagedLedgerException {


                final CountDownLatch counter = new CountDownLatch(1);


                class Result {


                ManagedLedgerException exception = null;


                }


                final Result result = new Result();


                asyncDeleteCursor(name, new DeleteCursorCallback() {


                @Override


                public void deleteCursorComplete(Object ctx) {


                counter.countDown();


                }


                @Override


                public void deleteCursorFailed(ManagedLedgerException exception, Object ctx) {


                result.exception = exception;


                counter.countDown();


                }


                }, null);


                if (!counter.await(AsyncOperationTimeoutSeconds, TimeUnit.SECONDS)) {


                throw new ManagedLedgerException("Timeout during delete-cursors operation");


                }


                if (result.exception != null) {


                log.error("Deleting cursor", result.exception);


                throw result.exception;


                }


                }


                It's obvious to me how we should fix the endpoint to make it work for concurrent calls. I am going to
                start by focusing on the other calls.
                To Reproduce
                Steps to reproduce the behavior:

                Deploy a 2.9.1 broker.
                Run curl -s --fail http://localhost:8080/admin/v2/brokers/health $ #  sleep 0.05 ; curl -s --fail
                http://localhost:8080/admin/v2/brokers/health
                Observer logs.
                It's possible that you'll need to rerun step 2 several times. Given that it is a race in the endpoint,
                it is not guaranteed to trigger every time.

                Resulting stack trace:
                2022-02-17T23:29:45,090+0000 [pulsar-web-36-2] INFO org.apache.pulsar.broker.admin.impl.BrokersBase -
                Running healthCheck with topic=persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck
                2022-02-17T23:29:45,094+0000 [pulsar-io-4-3] INFO org.apache.pulsar.client.impl.ProducerImpl -
                [persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck] [null] Creating producer on cnx [id:
                0x8bb88ae1, L:/172.17.0.13:34648 - R:172.17.0.13/172.17.0.13:6650]
                2022-02-17T23:29:45,094+0000 [pulsar-io-4-4] INFO org.apache.pulsar.broker.service.ServerCnx -
                [/172.17.0.13:34648][persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck] Creating producer.
                producerId=124
                2022-02-17T23:29:45,095+0000 [pulsar-io-4-3] INFO org.apache.pulsar.client.impl.ConsumerImpl -
                [persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck][reader-b624a86dcd] Subscribing to topic on cnx
                [id: 0x8bb88ae1, L:/172.17.0.13:34648 - R:172.17.0.13/172.17.0.13:6650], consumerId 124
                2022-02-17T23:29:45,096+0000 [pulsar-io-4-4] INFO org.apache.pulsar.broker.service.ServerCnx -
                [/172.17.0.13:34648] Subscribing on topic persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck /
                reader-b624a86dcd
                2022-02-17T23:29:45,105+0000 [BookKeeperClientWorker-OrderedExecutor-3-0] INFO
                org.apache.pulsar.broker.service.ServerCnx - [/172.17.0.13:34648] Created new producer:
                Producer{topic=PersistentTopic{topic=persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck},
                client=/172.17.0.13:34648, producerName=pulsar-0-171, producerId=124}
                2022-02-17T23:29:45,106+0000 [pulsar-io-4-3] INFO org.apache.pulsar.client.impl.ProducerImpl -
                [persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck] [pulsar-0-171] Created producer on cnx [id:
                0x8bb88ae1, L:/172.17.0.13:34648 - R:172.17.0.13/172.17.0.13:6650]
                2022-02-17T23:29:45,124+0000 [ForkJoinPool.commonPool-worker-7] INFO
                org.apache.pulsar.broker.service.persistent.PersistentTopic -
                [persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck][reader-b624a86dcd] Creating non-durable
                subscription at msg id 9223372036854775807:9223372036854775807:-1:-1
                2022-02-17T23:29:45,125+0000 [ForkJoinPool.commonPool-worker-7] INFO
                org.apache.bookkeeper.mledger.impl.NonDurableCursorImpl -
                [pulsar/pulsar/172.17.0.13:8080/persistent/healthcheck] Created non-durable cursor read-position=0:124
                mark-delete-position=0:123
                2022-02-17T23:29:45,125+0000 [ForkJoinPool.commonPool-worker-7] INFO
                org.apache.bookkeeper.mledger.impl.ManagedLedgerImpl -
                [pulsar/pulsar/172.17.0.13:8080/persistent/healthcheck] Opened new cursor:
                NonDurableCursorImpl{ledger=pulsar/pulsar/172.17.0.13:8080/persistent/healthcheck, ackPos=0:123,
                readPos=0:124}
                2022-02-17T23:29:45,125+0000 [ForkJoinPool.commonPool-worker-7] INFO
                org.apache.bookkeeper.mledger.impl.ManagedCursorImpl -
                [pulsar/pulsar/172.17.0.13:8080/persistent/healthcheck-reader-b624a86dcd] Rewind from 0:124 to 0:124
                2022-02-17T23:29:45,125+0000 [ForkJoinPool.commonPool-worker-7] INFO
                org.apache.pulsar.broker.service.persistent.PersistentTopic -
                [persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck] There are no replicated subscriptions on the
                topic
                2022-02-17T23:29:45,125+0000 [ForkJoinPool.commonPool-worker-7] INFO
                org.apache.pulsar.broker.service.persistent.PersistentTopic -
                [persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck][reader-b624a86dcd] Created new subscription
                for 124
                2022-02-17T23:29:45,125+0000 [ForkJoinPool.commonPool-worker-7] INFO
                org.apache.pulsar.broker.service.ServerCnx - [/172.17.0.13:34648] Created subscription on topic
                persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck / reader-b624a86dcd
                2022-02-17T23:29:45,126+0000 [pulsar-io-4-3] INFO org.apache.pulsar.client.impl.ConsumerImpl -
                [persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck][reader-b624a86dcd] Subscribed to topic on
                172.17.0.13/172.17.0.13:6650 -- consumer: 124
                2022-02-17T23:29:45,144+0000 [pulsar-client-internal-39-1] INFO org.eclipse.jetty.server.RequestLog -
                127.0.0.1 - - [17/Feb/2022:23:29:45 +0000] "GET /admin/v2/brokers/health HTTP/1.1" 200 2 "-"
                "curl/7.68.0" 56
                2022-02-17T23:29:45,143+0000 [pulsar-web-36-5] INFO org.apache.pulsar.broker.admin.impl.BrokersBase -
                Running healthCheck with topic=persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck
                2022-02-17T23:29:45,145+0000 [pulsar-web-36-5] INFO
                org.apache.pulsar.broker.service.persistent.PersistentSubscription -
                [persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck][reader-b624a86dcd] Unsubscribing
                2022-02-17T23:29:45,149+0000 [pulsar-web-36-5] INFO org.apache.pulsar.broker.service.Consumer -
                Disconnecting consumer:
                Consumer{subscription=PersistentSubscription{topic=persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck,
                name=reader-b624a86dcd}, consumerId=124, consumerName=30cb0, address=/172.17.0.13:34648}
                2022-02-17T23:29:45,150+0000 [pulsar-web-36-5] INFO
                org.apache.pulsar.broker.service.AbstractDispatcherSingleActiveConsumer - Removing consumer
                Consumer{subscription=PersistentSubscription{topic=persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck,
                name=reader-b624a86dcd}, consumerId=124, consumerName=30cb0, address=/172.17.0.13:34648}
                2022-02-17T23:29:45,151+0000 [pulsar-web-36-5] INFO
                org.apache.pulsar.broker.service.persistent.PersistentSubscription -
                [persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck][reader-b624a86dcd] Successfully closed
                subscription [NonDurableCursorImpl{ledger=pulsar/pulsar/172.17.0.13:8080/persistent/healthcheck,
                ackPos=0:123, readPos=0:125}]
                2022-02-17T23:29:45,151+0000 [pulsar-web-36-5] INFO
                org.apache.pulsar.broker.service.persistent.PersistentSubscription -
                [persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck][reader-b624a86dcd] Successfully closed
                dispatcher for reader
                2022-02-17T23:29:45,151+0000 [pulsar-io-4-4] INFO org.apache.pulsar.broker.service.ServerCnx -
                [PersistentTopic{topic=persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck}][pulsar-0-171] Closing
                producer on cnx /172.17.0.13:34648. producerId=124
                2022-02-17T23:29:45,152+0000 [pulsar-web-36-5] INFO
                org.apache.pulsar.broker.service.persistent.PersistentSubscription -
                [persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck][reader-b624a86dcd] Successfully closed
                subscription [NonDurableCursorImpl{ledger=pulsar/pulsar/172.17.0.13:8080/persistent/healthcheck,
                ackPos=0:123, readPos=0:125}]
                2022-02-17T23:29:45,152+0000 [pulsar-web-36-5] INFO
                org.apache.pulsar.broker.service.persistent.PersistentSubscription -
                [persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck][reader-b624a86dcd] Successfully disconnected
                and closed subscription
                2022-02-17T23:29:45,152+0000 [pulsar-io-4-4] INFO org.apache.pulsar.broker.service.ServerCnx -
                [PersistentTopic{topic=persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck}][pulsar-0-171] Closed
                producer on cnx /172.17.0.13:34648. producerId=124
                2022-02-17T23:29:45,152+0000 [pulsar-io-4-4] INFO org.apache.pulsar.broker.service.ServerCnx -
                [/172.17.0.13:34648] Closing consumer: consumerId=124
                2022-02-17T23:29:45,152+0000 [pulsar-io-4-3] INFO org.apache.pulsar.client.impl.ProducerImpl -
                [persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck] [pulsar-0-171] Closed Producer
                2022-02-17T23:29:45,153+0000 [pulsar-io-4-3] INFO org.apache.pulsar.client.impl.ClientCnx -
                [172.17.0.13/172.17.0.13:6650] Broker notification of Closed consumer: 124
                2022-02-17T23:29:45,153+0000 [pulsar-io-4-4] WARN org.apache.pulsar.broker.service.ServerCnx -
                [/172.17.0.13:34648] Consumer was not registered on the connection: consumerId=124
                2022-02-17T23:29:45,153+0000 [pulsar-io-4-3] INFO org.apache.pulsar.client.impl.ConnectionHandler -
                [persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck] [reader-b624a86dcd] Ignoring reconnection
                request (state: Closing)
                2022-02-17T23:29:45,153+0000 [pulsar-io-4-3] WARN org.apache.pulsar.client.impl.ClientCnx - [id:
                0x8bb88ae1, L:/172.17.0.13:34648 - R:172.17.0.13/172.17.0.13:6650] Received error from server: Consumer
                not found
                2022-02-17T23:29:45,155+0000 [pulsar-io-4-3] INFO org.apache.pulsar.client.impl.ConsumerImpl -
                [persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck] [reader-b624a86dcd] Closed consumer
                2022-02-17T23:29:45,158+0000 [bookkeeper-ml-scheduler-OrderedScheduler-0-0] ERROR
                org.apache.pulsar.broker.service.persistent.PersistentSubscription -
                [persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck][reader-b624a86dcd] Error deleting subscription
                java.util.concurrent.CompletionException:
                org.apache.pulsar.broker.service.BrokerServiceException$PersistenceException:
                org.apache.bookkeeper.mledger.ManagedLedgerException$CursorNotFoundException: ManagedCursor not found:
                reader-b624a86dcd
                at java.util.concurrent.CompletableFuture.encodeRelay(CompletableFuture.java:367) ~[?:?]
                at java.util.concurrent.CompletableFuture.completeRelay(CompletableFuture.java:376) ~[?:?]
                at java.util.concurrent.CompletableFuture$UniRelay.tryFire(CompletableFuture.java:1019) ~[?:?]
                at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506) ~[?:?]
                at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088) ~[?:?]
                at
                org.apache.pulsar.broker.service.persistent.PersistentTopic$5.deleteCursorFailed(PersistentTopic.java:1025)
                ~[org.apache.pulsar-pulsar-broker-2.9.1.jar:2.9.1]
                at org.apache.bookkeeper.mledger.impl.ManagedLedgerImpl.asyncDeleteCursor(ManagedLedgerImpl.java:950)
                ~[org.apache.pulsar-managed-ledger-2.9.1.jar:2.9.1]
                at
                org.apache.pulsar.broker.service.persistent.PersistentTopic.asyncDeleteCursor(PersistentTopic.java:1008)
                ~[org.apache.pulsar-pulsar-broker-2.9.1.jar:2.9.1]
                at org.apache.pulsar.broker.service.persistent.PersistentTopic.access$600(PersistentTopic.java:164)
                ~[org.apache.pulsar-pulsar-broker-2.9.1.jar:2.9.1]
                at
                org.apache.pulsar.broker.service.persistent.PersistentTopic$4.deleteLedgerFailed(PersistentTopic.java:994)
                ~[org.apache.pulsar-pulsar-broker-2.9.1.jar:2.9.1]
                at
                org.apache.bookkeeper.mledger.impl.ManagedLedgerFactoryImpl$9.getInfoFailed(ManagedLedgerFactoryImpl.java:876)
                ~[org.apache.pulsar-managed-ledger-2.9.1.jar:2.9.1]
                at
                org.apache.bookkeeper.mledger.impl.ManagedLedgerFactoryImpl$7.operationFailed(ManagedLedgerFactoryImpl.java:803)
                ~[org.apache.pulsar-managed-ledger-2.9.1.jar:2.9.1]
                at
                org.apache.bookkeeper.mledger.impl.MetaStoreImpl.lambda$getManagedLedgerInfo$2(MetaStoreImpl.java:118)
                ~[org.apache.pulsar-managed-ledger-2.9.1.jar:2.9.1]
                at java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:714) [?:?]
                at java.util.concurrent.CompletableFuture$Completion.run(CompletableFuture.java:478) [?:?]
                at org.apache.bookkeeper.common.util.OrderedExecutor$TimedRunnable.run(OrderedExecutor.java:203)
                [org.apache.bookkeeper-bookkeeper-common-4.14.2.jar:4.14.2]
                at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
                at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
                at
                java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
                [?:?]
                at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
                at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
                at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
                [io.netty-netty-common-4.1.72.Final.jar:4.1.72.Final]
                at java.lang.Thread.run(Thread.java:829) [?:?]
                Caused by: org.apache.pulsar.broker.service.BrokerServiceException$PersistenceException:
                org.apache.bookkeeper.mledger.ManagedLedgerException$CursorNotFoundException: ManagedCursor not found:
                reader-b624a86dcd
                ... 18 more
                Caused by: org.apache.bookkeeper.mledger.ManagedLedgerException$CursorNotFoundException: ManagedCursor
                not found: reader-b624a86dcd
                2022-02-17T23:29:45,163+0000 [pulsar-io-4-3] WARN org.apache.pulsar.broker.admin.impl.BrokersBase -
                Error closing reader for healthcheck
                org.apache.pulsar.client.api.PulsarClientException$BrokerMetadataException: {"errorMsg":"Consumer not
                found","reqId":2585972327142211972, "remote":"172.17.0.13/172.17.0.13:6650",
                "local":"/172.17.0.13:34648"}
                at org.apache.pulsar.client.impl.ClientCnx.getPulsarClientException(ClientCnx.java:1150)
                ~[org.apache.pulsar-pulsar-client-original-2.9.1.jar:2.9.1]
                at org.apache.pulsar.client.impl.ClientCnx.handleError(ClientCnx.java:710)
                [org.apache.pulsar-pulsar-client-original-2.9.1.jar:2.9.1]
                at org.apache.pulsar.common.protocol.PulsarDecoder.channelRead(PulsarDecoder.java:177)
                [org.apache.pulsar-pulsar-common-2.9.1.jar:2.9.1]
                at
                io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
                [io.netty-netty-transport-4.1.72.Final.jar:4.1.72.Final]
                at
                io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
                [io.netty-netty-transport-4.1.72.Final.jar:4.1.72.Final]
                at
                io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
                [io.netty-netty-transport-4.1.72.Final.jar:4.1.72.Final]
                at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:324)
                [io.netty-netty-codec-4.1.72.Final.jar:4.1.72.Final]
                at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:296)
                [io.netty-netty-codec-4.1.72.Final.jar:4.1.72.Final]
                at
                io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
                [io.netty-netty-transport-4.1.72.Final.jar:4.1.72.Final]
                at
                io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
                [io.netty-netty-transport-4.1.72.Final.jar:4.1.72.Final]
                at
                io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
                [io.netty-netty-transport-4.1.72.Final.jar:4.1.72.Final]
                at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
                [io.netty-netty-transport-4.1.72.Final.jar:4.1.72.Final]
                at
                io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
                [io.netty-netty-transport-4.1.72.Final.jar:4.1.72.Final]
                at
                io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
                [io.netty-netty-transport-4.1.72.Final.jar:4.1.72.Final]
                at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
                [io.netty-netty-transport-4.1.72.Final.jar:4.1.72.Final]
                at
                io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:795)
                [io.netty-netty-transport-classes-epoll-4.1.72.Final.jar:4.1.72.Final]
                at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:480)
                [io.netty-netty-transport-classes-epoll-4.1.72.Final.jar:4.1.72.Final]
                at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:378)
                [io.netty-netty-transport-classes-epoll-4.1.72.Final.jar:4.1.72.Final]
                at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
                [io.netty-netty-common-4.1.72.Final.jar:4.1.72.Final]
                at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
                [io.netty-netty-common-4.1.72.Final.jar:4.1.72.Final]
                at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
                [io.netty-netty-common-4.1.72.Final.jar:4.1.72.Final]
                at java.lang.Thread.run(Thread.java:829) [?:?]
                2022-02-17T23:29:45,170+0000 [pulsar-io-4-3] INFO org.apache.pulsar.client.impl.ProducerImpl -
                [persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck] [null] Creating producer on cnx [id:
                0x8bb88ae1, L:/172.17.0.13:34648 - R:172.17.0.13/172.17.0.13:6650]
                2022-02-17T23:29:45,175+0000 [pulsar-io-4-4] INFO org.apache.pulsar.broker.service.ServerCnx -
                [/172.17.0.13:34648][persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck] Creating producer.
                producerId=125
                2022-02-17T23:29:45,175+0000 [pulsar-io-4-3] INFO org.apache.pulsar.client.impl.ConsumerImpl -
                [persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck][reader-37f6b60cd2] Subscribing to topic on cnx
                [id: 0x8bb88ae1, L:/172.17.0.13:34648 - R:172.17.0.13/172.17.0.13:6650], consumerId 125
                2022-02-17T23:29:45,177+0000 [pulsar-io-4-4] INFO org.apache.pulsar.broker.service.ServerCnx -
                [/172.17.0.13:34648] Subscribing on topic persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck /
                reader-37f6b60cd2
                2022-02-17T23:29:45,181+0000 [BookKeeperClientWorker-OrderedExecutor-2-0] INFO
                org.apache.pulsar.broker.service.ServerCnx - [/172.17.0.13:34648] Created new producer:
                Producer{topic=PersistentTopic{topic=persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck},
                client=/172.17.0.13:34648, producerName=pulsar-0-172, producerId=125}
                2022-02-17T23:29:45,182+0000 [pulsar-io-4-3] INFO org.apache.pulsar.client.impl.ProducerImpl -
                [persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck] [pulsar-0-172] Created producer on cnx [id:
                0x8bb88ae1, L:/172.17.0.13:34648 - R:172.17.0.13/172.17.0.13:6650]
                2022-02-17T23:29:45,192+0000 [ForkJoinPool.commonPool-worker-7] INFO
                org.apache.pulsar.broker.service.persistent.PersistentTopic -
                [persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck][reader-37f6b60cd2] Creating non-durable
                subscription at msg id 9223372036854775807:9223372036854775807:-1:-1
                2022-02-17T23:29:45,192+0000 [ForkJoinPool.commonPool-worker-7] INFO
                org.apache.bookkeeper.mledger.impl.NonDurableCursorImpl -
                [pulsar/pulsar/172.17.0.13:8080/persistent/healthcheck] Created non-durable cursor read-position=0:125
                mark-delete-position=0:124
                2022-02-17T23:29:45,192+0000 [ForkJoinPool.commonPool-worker-7] INFO
                org.apache.bookkeeper.mledger.impl.ManagedLedgerImpl -
                [pulsar/pulsar/172.17.0.13:8080/persistent/healthcheck] Opened new cursor:
                NonDurableCursorImpl{ledger=pulsar/pulsar/172.17.0.13:8080/persistent/healthcheck, ackPos=0:124,
                readPos=0:125}
                2022-02-17T23:29:45,193+0000 [ForkJoinPool.commonPool-worker-7] INFO
                org.apache.bookkeeper.mledger.impl.ManagedCursorImpl -
                [pulsar/pulsar/172.17.0.13:8080/persistent/healthcheck-reader-37f6b60cd2] Rewind from 0:125 to 0:125
                2022-02-17T23:29:45,193+0000 [ForkJoinPool.commonPool-worker-7] INFO
                org.apache.pulsar.broker.service.persistent.PersistentTopic -
                [persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck] There are no replicated subscriptions on the
                topic
                2022-02-17T23:29:45,193+0000 [ForkJoinPool.commonPool-worker-7] INFO
                org.apache.pulsar.broker.service.persistent.PersistentTopic -
                [persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck][reader-37f6b60cd2] Created new subscription
                for 125
                2022-02-17T23:29:45,193+0000 [ForkJoinPool.commonPool-worker-7] INFO
                org.apache.pulsar.broker.service.ServerCnx - [/172.17.0.13:34648] Created subscription on topic
                persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck / reader-37f6b60cd2
                2022-02-17T23:29:45,194+0000 [pulsar-io-4-3] INFO org.apache.pulsar.client.impl.ConsumerImpl -
                [persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck][reader-37f6b60cd2] Subscribed to topic on
                172.17.0.13/172.17.0.13:6650 -- consumer: 125
                2022-02-17T23:29:45,209+0000 [pulsar-io-4-4] INFO org.apache.pulsar.broker.service.ServerCnx -
                [PersistentTopic{topic=persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck}][pulsar-0-172] Closing
                producer on cnx /172.17.0.13:34648. producerId=125
                2022-02-17T23:29:45,209+0000 [pulsar-io-4-4] INFO org.apache.pulsar.broker.service.ServerCnx -
                [PersistentTopic{topic=persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck}][pulsar-0-172] Closed
                producer on cnx /172.17.0.13:34648. producerId=125
                2022-02-17T23:29:45,210+0000 [pulsar-io-4-3] INFO org.apache.pulsar.client.impl.ProducerImpl -
                [persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck] [pulsar-0-172] Closed Producer
                2022-02-17T23:29:45,210+0000 [pulsar-io-4-4] INFO org.apache.pulsar.broker.service.ServerCnx -
                [/172.17.0.13:34648] Closing consumer: consumerId=125
                2022-02-17T23:29:45,212+0000 [pulsar-io-4-4] INFO
                org.apache.pulsar.broker.service.AbstractDispatcherSingleActiveConsumer - Removing consumer
                Consumer{subscription=PersistentSubscription{topic=persistent://pulsar/pulsar/172.17.0.13:8080/healthcheck,
                name=reader-37f6b60cd2}, consumerId=125, consumerName=796c6, address=/172.17.0.13:34648}

                Another time, I got the below stack trace. In this case, I was using a custom build of Pulsar, so the
                line numbers are a bit off, but the NPEs are relevant and should be addressed.
                15:11:12.170 [pulsar-web-40-6] ERROR org.apache.pulsar.broker.service.persistent.PersistentSubscription
                - [persistent://pulsar/pulsar/10.16.1.52:8080/healthcheck][reader-6a02552209] Error deleting
                subscription
                java.util.concurrent.CompletionException: java.lang.NullPointerException
                at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:314) ~[?:?]
                at java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1113) ~[?:?]
                at java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2235) ~[?:?]
                at
                org.apache.pulsar.broker.service.persistent.PersistentSubscription.delete(PersistentSubscription.java:917)
                ~[com.datastax.oss-pulsar-broker-2.8.0.1.1.22.jar:2.8.0.1.1.22]
                at
                org.apache.pulsar.broker.service.persistent.PersistentSubscription.deleteForcefully(PersistentSubscription.java:880)
                ~[com.datastax.oss-pulsar-broker-2.8.0.1.1.22.jar:2.8.0.1.1.22]
                at org.apache.pulsar.broker.admin.impl.BrokersBase.lambda$healthcheck$4(BrokersBase.java:323)
                ~[com.datastax.oss-pulsar-broker-2.8.0.1.1.22.jar:2.8.0.1.1.22]
                at
                org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap$Section.forEach(ConcurrentOpenHashMap.java:413)
                ~[com.datastax.oss-pulsar-common-2.8.0.1.1.22.jar:2.8.0.1.1.22]
                at
                org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap.forEach(ConcurrentOpenHashMap.java:185)
                ~[com.datastax.oss-pulsar-common-2.8.0.1.1.22.jar:2.8.0.1.1.22]
                at org.apache.pulsar.broker.admin.impl.BrokersBase.lambda$healthcheck$5(BrokersBase.java:321)
                ~[com.datastax.oss-pulsar-broker-2.8.0.1.1.22.jar:2.8.0.1.1.22]
                at java.util.Optional.ifPresent(Optional.java:183) ~[?:?]
                at org.apache.pulsar.broker.admin.impl.BrokersBase.healthcheck(BrokersBase.java:320)
                ~[com.datastax.oss-pulsar-broker-2.8.0.1.1.22.jar:2.8.0.1.1.22]
                at jdk.internal.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
                at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
                at java.lang.reflect.Method.invoke(Method.java:566) ~[?:?]
                at
                org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
                ~[org.glassfish.jersey.core-jersey-server-2.34.jar:?]
                at
                org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
                ~[org.glassfish.jersey.core-jersey-server-2.34.jar:?]
                at
                org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
                ~[org.glassfish.jersey.core-jersey-server-2.34.jar:?]
                at
                org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$VoidOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:159)
                ~[org.glassfish.jersey.core-jersey-server-2.34.jar:?]
                at
                org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
                ~[org.glassfish.jersey.core-jersey-server-2.34.jar:?]
                at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
                ~[org.glassfish.jersey.core-jersey-server-2.34.jar:?]
                at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
                ~[org.glassfish.jersey.core-jersey-server-2.34.jar:?]
                at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
                ~[org.glassfish.jersey.core-jersey-server-2.34.jar:?]
                at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
                ~[org.glassfish.jersey.core-jersey-server-2.34.jar:?]
                at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
                ~[org.glassfish.jersey.core-jersey-common-2.34.jar:?]
                at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
                ~[org.glassfish.jersey.core-jersey-common-2.34.jar:?]
                at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
                ~[org.glassfish.jersey.core-jersey-common-2.34.jar:?]
                at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
                ~[org.glassfish.jersey.core-jersey-common-2.34.jar:?]
                at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
                ~[org.glassfish.jersey.core-jersey-common-2.34.jar:?]
                at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
                ~[org.glassfish.jersey.core-jersey-common-2.34.jar:?]
                at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
                ~[org.glassfish.jersey.core-jersey-server-2.34.jar:?]
                at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
                ~[org.glassfish.jersey.core-jersey-server-2.34.jar:?]
                at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
                ~[org.glassfish.jersey.containers-jersey-container-servlet-core-2.34.jar:?]
                at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
                ~[org.glassfish.jersey.containers-jersey-container-servlet-core-2.34.jar:?]
                at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
                ~[org.glassfish.jersey.containers-jersey-container-servlet-core-2.34.jar:?]
                at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
                ~[org.glassfish.jersey.containers-jersey-container-servlet-core-2.34.jar:?]
                at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
                ~[org.glassfish.jersey.containers-jersey-container-servlet-core-2.34.jar:?]
                at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
                ~[org.eclipse.jetty-jetty-servlet-9.4.44.v20210927.jar:9.4.44.v20210927]
                at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1631)
                ~[org.eclipse.jetty-jetty-servlet-9.4.44.v20210927.jar:9.4.44.v20210927]
                at org.apache.pulsar.broker.web.ResponseHandlerFilter.doFilter(ResponseHandlerFilter.java:65)
                ~[com.datastax.oss-pulsar-broker-2.8.0.1.1.22.jar:2.8.0.1.1.22]
                at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
                ~[org.eclipse.jetty-jetty-servlet-9.4.44.v20210927.jar:9.4.44.v20210927]
                at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
                ~[org.eclipse.jetty-jetty-servlet-9.4.44.v20210927.jar:9.4.44.v20210927]
                at org.apache.pulsar.broker.web.AuthenticationFilter.doFilter(AuthenticationFilter.java:84)
                ~[com.datastax.oss-pulsar-broker-common-2.8.0.1.1.22.jar:2.8.0.1.1.22]
                at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
                ~[org.eclipse.jetty-jetty-servlet-9.4.44.v20210927.jar:9.4.44.v20210927]
                at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
                ~[org.eclipse.jetty-jetty-servlet-9.4.44.v20210927.jar:9.4.44.v20210927]
                at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
                ~[org.eclipse.jetty-jetty-servlet-9.4.44.v20210927.jar:9.4.44.v20210927]
                at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
                ~[org.eclipse.jetty-jetty-server-9.4.44.v20210927.jar:9.4.44.v20210927]
                at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
                ~[org.eclipse.jetty-jetty-server-9.4.44.v20210927.jar:9.4.44.v20210927]
                at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
                ~[org.eclipse.jetty-jetty-server-9.4.44.v20210927.jar:9.4.44.v20210927]
                at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
                ~[org.eclipse.jetty-jetty-server-9.4.44.v20210927.jar:9.4.44.v20210927]
                at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
                ~[org.eclipse.jetty-jetty-server-9.4.44.v20210927.jar:9.4.44.v20210927]
                at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
                ~[org.eclipse.jetty-jetty-servlet-9.4.44.v20210927.jar:9.4.44.v20210927]
                at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
                ~[org.eclipse.jetty-jetty-server-9.4.44.v20210927.jar:9.4.44.v20210927]
                at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
                ~[org.eclipse.jetty-jetty-server-9.4.44.v20210927.jar:9.4.44.v20210927]
                at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
                ~[org.eclipse.jetty-jetty-server-9.4.44.v20210927.jar:9.4.44.v20210927]
                at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
                ~[org.eclipse.jetty-jetty-server-9.4.44.v20210927.jar:9.4.44.v20210927]
                at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)
                ~[org.eclipse.jetty-jetty-server-9.4.44.v20210927.jar:9.4.44.v20210927]
                at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
                ~[org.eclipse.jetty-jetty-server-9.4.44.v20210927.jar:9.4.44.v20210927]
                at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:179)
                ~[org.eclipse.jetty-jetty-server-9.4.44.v20210927.jar:9.4.44.v20210927]
                at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
                ~[org.eclipse.jetty-jetty-server-9.4.44.v20210927.jar:9.4.44.v20210927]
                at org.eclipse.jetty.server.Server.handle(Server.java:516)
                ~[org.eclipse.jetty-jetty-server-9.4.44.v20210927.jar:9.4.44.v20210927]
                at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:400)
                ~[org.eclipse.jetty-jetty-server-9.4.44.v20210927.jar:9.4.44.v20210927]
                at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:645)
                [org.eclipse.jetty-jetty-server-9.4.44.v20210927.jar:9.4.44.v20210927]
                at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:392)
                [org.eclipse.jetty-jetty-server-9.4.44.v20210927.jar:9.4.44.v20210927]
                at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
                [org.eclipse.jetty-jetty-server-9.4.44.v20210927.jar:9.4.44.v20210927]
                at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
                [org.eclipse.jetty-jetty-io-9.4.44.v20210927.jar:9.4.44.v20210927]
                at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
                [org.eclipse.jetty-jetty-io-9.4.44.v20210927.jar:9.4.44.v20210927]
                at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
                [org.eclipse.jetty-jetty-io-9.4.44.v20210927.jar:9.4.44.v20210927]
                at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
                [org.eclipse.jetty-jetty-util-9.4.44.v20210927.jar:9.4.44.v20210927]
                at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
                [org.eclipse.jetty-jetty-util-9.4.44.v20210927.jar:9.4.44.v20210927]
                at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
                [org.eclipse.jetty-jetty-util-9.4.44.v20210927.jar:9.4.44.v20210927]
                at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
                [org.eclipse.jetty-jetty-util-9.4.44.v20210927.jar:9.4.44.v20210927]
                at
                org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
                [org.eclipse.jetty-jetty-util-9.4.44.v20210927.jar:9.4.44.v20210927]
                at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
                at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
                at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
                [io.netty-netty-common-4.1.73.Final.jar:4.1.73.Final]
                at java.lang.Thread.run(Thread.java:829) [?:?]
                Caused by: java.lang.NullPointerException
                at
                org.apache.pulsar.broker.service.persistent.PersistentTopic.removeSubscription(PersistentTopic.java:987)
                ~[com.datastax.oss-pulsar-broker-2.8.0.1.1.22.jar:2.8.0.1.1.22]
                at
                org.apache.pulsar.broker.service.persistent.PersistentTopic$4.deleteCursorComplete(PersistentTopic.java:967)
                ~[com.datastax.oss-pulsar-broker-2.8.0.1.1.22.jar:2.8.0.1.1.22]
                at org.apache.bookkeeper.mledger.impl.ManagedLedgerImpl.asyncDeleteCursor(ManagedLedgerImpl.java:953)
                ~[com.datastax.oss-managed-ledger-2.8.0.1.1.22.jar:2.8.0.1.1.22]
                at org.apache.pulsar.broker.service.persistent.PersistentTopic.unsubscribe(PersistentTopic.java:961)
                ~[com.datastax.oss-pulsar-broker-2.8.0.1.1.22.jar:2.8.0.1.1.22]
                at
                org.apache.pulsar.broker.service.persistent.PersistentSubscription.lambda$delete$19(PersistentSubscription.java:917)
                ~[com.datastax.oss-pulsar-broker-2.8.0.1.1.22.jar:2.8.0.1.1.22]
                at java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1106) ~[?:?]
                ... 74 more

                Expected behavior
                I would expect the health check endpoint to work correctly for concurrent calls.
            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.pulsar.common.util.FutureUtil.java</file>
            <file type="M">org.apache.pulsar.broker.admin.AdminApiHealthCheckTest.java</file>
            <file type="M">org.apache.pulsar.broker.web.PulsarWebResource.java</file>
            <file type="M">org.apache.pulsar.broker.service.persistent.PersistentTopic.java</file>
            <file type="M">org.apache.pulsar.broker.service.nonpersistent.NonPersistentTopic.java</file>
            <file type="M">org.apache.pulsar.broker.admin.impl.BrokersBase.java</file>
            <file type="M">org.apache.pulsar.broker.PulsarService.java</file>
        </fixedFiles>
    </bug>
    <bug id="14413" opendate="2022-02-22 00:00:00" fixdate="2022-03-09 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>ConsumerBuilderImpl.subscribeAsync blocks calling thread.
            </summary>
            <description>Describe the bug
                When Retry topics are enabled, ConsumerBuilderImpl performs a backwards-compatibility check to look for
                DLQ or Retry topics that were created on previous version of Pulsar using a different naming scheme.
                It does this by calling getPartitionedTopicMetadata and then using .get() to block while waiting for the
                results
                if (client.getPartitionedTopicMetadata(oldRetryLetterTopic)
                .get(client.conf.getOperationTimeoutMs(), TimeUnit.MILLISECONDS).partitions > 0) {
                retryLetterTopic = oldRetryLetterTopic;
                }
                if (client.getPartitionedTopicMetadata(oldDeadLetterTopic)
                .get(client.conf.getOperationTimeoutMs(), TimeUnit.MILLISECONDS).partitions > 0) {
                deadLetterTopic = oldDeadLetterTopic;
                }
                This was implemented in #10129
                A partial fix to add a Timeout was implemented in #11597
                However this fix does still block the calling thread during the lookup.
                This can be an issue for code that attempt to call subscribeAsync on a non-blocking Pool (such as when
                using Netty). The signature of subscribeAsync implies that it's non-blocking. (And it seems somewhat
                pointless to have subscribeAsync if it blocks anyway)
                Note that this is an undocumented breaking change in behavior. Up until 2.9, it was safe to call this
                from a non-blocking pool.
                In our case, we were running a custom SLF4J log exporter on the same thread pool, which resulted in a
                deadlock when the number of concurrent subscribeAsync calls exceeded the pool size. (This is probably an
                extreme example and a poor decision on our part, but perhaps a good example of why unexpected blocking
                can be dangerous)
                Note that blocking call is still made even if the retry and DLQ names are explicitly specified in
                DeadLetterPolicy. In that scenario the check should not be needed. Aside from blocking the calling
                Thread, this also results in unneeded lookup requests.
                To Reproduce
                Call .subscribeAsync with enableRetry(true). The calling thread will be blocked until the metadata
                lookup is complete.
                Expected behavior
                .subscribeAsync should return a CompletableFuture immediately without performing any IO.
                Proposed Fix

                Restructure subscribeAsync to chain the getPartitionedTopicMetadata calls rather than blocking
                Don't perform the metadata lookup if the DLQ/Retry topic names are already specified
                Add a flag to disable the compatibility check for projects that don't need it.

                If the project maintainer are happy with this proposal, I'm happy to raise a PR myself with the above
                change.
            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.pulsar.client.impl.ConsumerBuilderImpl.java</file>
        </fixedFiles>
    </bug>
    <bug id="11966" opendate="2021-09-08 00:00:00" fixdate="2021-10-06 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>[Proxy] Proxied /admin endpoint connections might remain blocked forever.
            </summary>
            <description>Describe the bug
                Proxied /admin endpoint connections might remain blocked forever.
                Example stacktrace
                "pulsar-external-web-6-7" #43 prio=5 os_prio=0 cpu=134724.23ms elapsed=519507.47s tid=0x00007fd7b586a800
                nid=0x5a in Object.wait() [0x00007fd71adef000]
                java.lang.Thread.State: WAITING (on object monitor)
                at java.lang.Object.wait(java.base@11.0.11/Native Method)
                - waiting on
                #no object reference available>
                at java.lang.Object.wait(java.base@11.0.11/Object.java:328)
                at org.eclipse.jetty.server.HttpInput.blockForContent(HttpInput.java:584)
                at org.eclipse.jetty.server.HttpInput$1.blockForContent(HttpInput.java:1164)
                at org.eclipse.jetty.server.HttpInput.read(HttpInput.java:330)
                - waiting to re-lock in wait()#0x00000000d3269c28> (a java.util.ArrayDeque)
                at java.io.InputStream.read(java.base@11.0.11/InputStream.java:205)
                at
                org.eclipse.jetty.client.util.InputStreamContentProvider$InputStreamContentProviderIterator.hasNext(InputStreamContentProvider.java:176)
                at org.eclipse.jetty.client.HttpContent.advance(HttpContent.java:157)
                at org.eclipse.jetty.client.HttpContent.advance(HttpContent.java:149)
                at org.eclipse.jetty.client.http.HttpSenderOverHTTP$HeadersCallback.#init>(HttpSenderOverHTTP.java:206)
                at org.eclipse.jetty.client.http.HttpSenderOverHTTP.sendHeaders(HttpSenderOverHTTP.java:65)
                at org.eclipse.jetty.client.HttpSender.send(HttpSender.java:212)
                at org.eclipse.jetty.client.http.HttpChannelOverHTTP.send(HttpChannelOverHTTP.java:84)
                at org.eclipse.jetty.client.HttpChannel.send(HttpChannel.java:125)
                at org.eclipse.jetty.client.HttpConnection.send(HttpConnection.java:241)
                at org.eclipse.jetty.client.http.HttpConnectionOverHTTP$Delegate.send(HttpConnectionOverHTTP.java:269)
                at org.eclipse.jetty.client.http.HttpConnectionOverHTTP.send(HttpConnectionOverHTTP.java:125)
                at org.eclipse.jetty.client.http.HttpDestinationOverHTTP.send(HttpDestinationOverHTTP.java:38)
                at org.eclipse.jetty.client.HttpDestination.process(HttpDestination.java:377)
                at org.eclipse.jetty.client.HttpDestination.process(HttpDestination.java:332)
                at org.eclipse.jetty.client.HttpDestination.send(HttpDestination.java:311)
                at org.eclipse.jetty.client.HttpDestination.send(HttpDestination.java:305)
                at org.eclipse.jetty.client.HttpDestination.send(HttpDestination.java:282)
                at org.eclipse.jetty.client.HttpDestination.send(HttpDestination.java:262)
                at org.eclipse.jetty.client.HttpClient.send(HttpClient.java:600)
                at org.eclipse.jetty.client.HttpRequest$$Lambda$373/0x0000000840538c40.accept(Unknown Source)
                at org.eclipse.jetty.client.HttpRequest.sendAsync(HttpRequest.java:778)
                at org.eclipse.jetty.client.HttpRequest.send(HttpRequest.java:765)
                at org.eclipse.jetty.proxy.AbstractProxyServlet.sendProxyRequest(AbstractProxyServlet.java:618)
                at org.eclipse.jetty.proxy.ProxyServlet.service(ProxyServlet.java:114)
                at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)
                at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
                at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
                at org.apache.pulsar.broker.web.AuthenticationFilter.doFilter(AuthenticationFilter.java:82)
                at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
                at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
                at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
                at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
                at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
                at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
                at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
                at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
                at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
                at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
                at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
                at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
                at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
                at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)
                at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
                at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:179)
                at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
                at org.eclipse.jetty.server.Server.handle(Server.java:516)
                at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
                at org.eclipse.jetty.server.HttpChannel$$Lambda$337/0x0000000840465840.dispatch(Unknown Source)
                at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
                at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
                at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
                at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
                at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
                at org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)
                at org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)
                at org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)
                at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
                at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
                at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
                at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
                at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
                at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
                at
                org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:383)
                at java.util.concurrent.ThreadPoolExecutor.runWorker(java.base@11.0.11/ThreadPoolExecutor.java:1128)
                at java.util.concurrent.ThreadPoolExecutor$Worker.run(java.base@11.0.11/ThreadPoolExecutor.java:628)
                at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
                at java.lang.Thread.run(java.base@11.0.11/Thread.java:829)

                Expected behavior
                There should be a timeout in place which prevents threads to hang forever in this state.
                When investigating the issue and code, it can be seen that the timeout isn't set for proxied requests.
                The call to super.setTimeout method is missing in AdminProxyHandler. The base method is overridden and
                that's why it doesn't get set to any value. this is the code in the base class method which sets the
                timeout:
                https://github.com/eclipse/jetty.project/blob/526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8/jetty-proxy/src/main/java/org/eclipse/jetty/proxy/AbstractProxyServlet.java#L321-L324
                Another observation from that code is that it has been copy-pasted from the Jetty code. There's no use
                of using the ServletConfig for getting the configuration values. This code need some cleanup too.
            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.pulsar.proxy.server.AdminProxyHandler.java</file>
            <file type="M">org.apache.pulsar.proxy.server.ProxyConfiguration.java</file>
        </fixedFiles>
    </bug>
    <bug id="17913" opendate="2022-10-03 00:00:00" fixdate="2022-10-13 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>[Bug] Deadlock while reading Schema from BookKeeper.
            </summary>
            <description>Search before asking

                I searched in the issues and found nothing similar.

                Version
                2.10.2rc
                Minimal reproduce step
                There is a combination of facts in which you can end up in a stuck broker with the main ZK client thread
                stuck like this:
                "main-EventThread" #18 daemon prio=5 os_prio=0 cpu=858.10ms elapsed=2757.17s tid=0x00007f32461ad800
                nid=0x1f6db1 waiting on condition [0x00007f3213fb8000]
                java.lang.Thread.State: WAITING (parking)
                at jdk.internal.misc.Unsafe.park(java.base@11.0.15.0.1/Native Method)
                - parking to wait for#0x00000007f28a3860> (a java.util.concurrent.CompletableFuture$Signaller)
                at java.util.concurrent.locks.LockSupport.park(java.base@11.0.15.0.1/LockSupport.java:194)
                at
                java.util.concurrent.CompletableFuture$Signaller.block(java.base@11.0.15.0.1/CompletableFuture.java:1796)
                at java.util.concurrent.ForkJoinPool.managedBlock(java.base@11.0.15.0.1/ForkJoinPool.java:3128)
                at java.util.concurrent.CompletableFuture.waitingGet(java.base@11.0.15.0.1/CompletableFuture.java:1823)
                at java.util.concurrent.CompletableFuture.get(java.base@11.0.15.0.1/CompletableFuture.java:1998)
                at org.apache.bookkeeper.common.concurrent.FutureUtils.result(FutureUtils.java:72)
                at org.apache.bookkeeper.common.concurrent.FutureUtils.result(FutureUtils.java:61)
                at
                org.apache.bookkeeper.client.DefaultBookieAddressResolver.resolve(DefaultBookieAddressResolver.java:43)
                at org.apache.bookkeeper.proto.PerChannelBookieClient.connect(PerChannelBookieClient.java:532)
                at
                org.apache.bookkeeper.proto.PerChannelBookieClient.connectIfNeededAndDoOp(PerChannelBookieClient.java:658)
                at
                org.apache.bookkeeper.proto.DefaultPerChannelBookieClientPool.initialize(DefaultPerChannelBookieClientPool.java:92)
                at org.apache.bookkeeper.proto.BookieClientImpl.lookupClient(BookieClientImpl.java:217)
                at org.apache.bookkeeper.proto.BookieClientImpl.isWritable(BookieClientImpl.java:170)
                at org.apache.bookkeeper.client.LedgerHandle.isWriteSetWritable(LedgerHandle.java:1227)
                at org.apache.bookkeeper.client.LedgerHandle.waitForWritable(LedgerHandle.java:1249)
                at org.apache.bookkeeper.client.LedgerHandle.readEntriesInternalAsync(LedgerHandle.java:883)
                at org.apache.bookkeeper.client.LedgerHandle.asyncReadEntriesInternal(LedgerHandle.java:800)
                at org.apache.bookkeeper.client.LedgerHandle.asyncReadEntries(LedgerHandle.java:694)
                at
                org.apache.pulsar.broker.service.schema.BookkeeperSchemaStorage$Functions.getLedgerEntry(BookkeeperSchemaStorage.java:646)
                at
                org.apache.pulsar.broker.service.schema.BookkeeperSchemaStorage.lambda$readSchemaEntry$33(BookkeeperSchemaStorage.java:524)
                at
                org.apache.pulsar.broker.service.schema.BookkeeperSchemaStorage$$Lambda$820/0x00000008007e5840.apply(Unknown
                Source)
                at
                java.util.concurrent.CompletableFuture$UniCompose.tryFire(java.base@11.0.15.0.1/CompletableFuture.java:1072)
                at java.util.concurrent.CompletableFuture.postComplete(java.base@11.0.15.0.1/CompletableFuture.java:506)
                at java.util.concurrent.CompletableFuture.complete(java.base@11.0.15.0.1/CompletableFuture.java:2073)
                at
                org.apache.pulsar.broker.service.schema.BookkeeperSchemaStorage.lambda$openLedger$40(BookkeeperSchemaStorage.java:601)
                at
                org.apache.pulsar.broker.service.schema.BookkeeperSchemaStorage$$Lambda$819/0x00000008007e5440.openComplete(Unknown
                Source)
                at org.apache.bookkeeper.client.LedgerOpenOp.openComplete(LedgerOpenOp.java:248)
                at org.apache.bookkeeper.client.LedgerOpenOp.openWithMetadata(LedgerOpenOp.java:201)
                at org.apache.bookkeeper.client.LedgerOpenOp.lambda$initiate$0(LedgerOpenOp.java:119)
                at org.apache.bookkeeper.client.LedgerOpenOp$$Lambda$621/0x0000000800715040.accept(Unknown Source)
                at
                java.util.concurrent.CompletableFuture.uniWhenComplete(java.base@11.0.15.0.1/CompletableFuture.java:859)
                at
                java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(java.base@11.0.15.0.1/CompletableFuture.java:837)
                at java.util.concurrent.CompletableFuture.postComplete(java.base@11.0.15.0.1/CompletableFuture.java:506)
                at java.util.concurrent.CompletableFuture.complete(java.base@11.0.15.0.1/CompletableFuture.java:2073)
                at
                org.apache.pulsar.metadata.bookkeeper.PulsarLedgerManager.lambda$readLedgerMetadata$2(PulsarLedgerManager.java:215)
                at
                org.apache.pulsar.metadata.bookkeeper.PulsarLedgerManager$$Lambda$615/0x0000000800717c40.accept(Unknown
                Source)
                at
                java.util.concurrent.CompletableFuture$UniAccept.tryFire(java.base@11.0.15.0.1/CompletableFuture.java:714)
                at java.util.concurrent.CompletableFuture.postComplete(java.base@11.0.15.0.1/CompletableFuture.java:506)
                at java.util.concurrent.CompletableFuture.complete(java.base@11.0.15.0.1/CompletableFuture.java:2073)
                at org.apache.pulsar.metadata.impl.ZKMetadataStore.handleGetResult(ZKMetadataStore.java:244)
                at org.apache.pulsar.metadata.impl.ZKMetadataStore.lambda$batchOperation$6(ZKMetadataStore.java:188)
                at org.apache.pulsar.metadata.impl.ZKMetadataStore$$Lambda$164/0x000000080033b840.processResult(Unknown
                Source)
                at
                org.apache.pulsar.metadata.impl.PulsarZooKeeperClient$3$1.processResult(PulsarZooKeeperClient.java:490)
                at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:712)
                at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:553)

                What did you expect to see?
                the broker works
                What did you see instead?
                the broker is stuck
                Anything else?
                It is a consequence of #17762
                The main problem here is that with PulsarRegistrationClient even if we use the MetadataCache there is
                still a chance that we load the value with a blocking call to ZK.
                https://github.com/datastax/pulsar/blob/3738257bd5be07f317aa68c2217aececf28c1761/p[…]apache/pulsar/metadata/bookkeeper/PulsarRegistrationClient.java
                in BookKeeper Zk Registration Driver we never perform reads in that method
                https://github.com/datastax/bookkeeper/blob/034ef8566ad037937a4d58a28f70631175744f[…]n/java/org/apache/bookkeeper/discover/ZKRegistrationClient.java
                Are you willing to submit a PR?

                I'm willing to submit a PR!

            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.pulsar.metadata.bookkeeper.BookieServiceInfoSerde.java</file>
            <file type="M">org.apache.pulsar.metadata.bookkeeper.PulsarRegistrationClient.java</file>
            <file type="M">org.apache.pulsar.metadata.bookkeeper.PulsarRegistrationClientTest.java</file>
        </fixedFiles>
    </bug>
    <bug id="11379" opendate="2021-07-20 00:00:00" fixdate="2022-03-18 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>Directory facing race condition on NarUnpacker.
            </summary>
            <description>Describe the bug
                This issue is an extension for #11340. When users create functions with parallelism larger than the
                number of functions-worker, the directory race condition can be observed.
                Exception in thread "main" java.lang.reflect.InvocationTargetException
                at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
                at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
                at
                java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
                at java.base/java.lang.reflect.Method.invoke(Method.java:566)
                at org.apache.pulsar.functions.instance.JavaInstanceMain.main(JavaInstanceMain.java:100)
                Caused by: java.io.IOException: Unable to delete
                /tmp/pulsar-nar/pulsar-java-functions-pojo-parse-1.0-SNAPSHOT.jar-unpacked/META-INF/maven
                at org.apache.pulsar.common.nar.FileUtils.deleteFile(FileUtils.java:213)
                at org.apache.pulsar.common.nar.FileUtils.deleteFiles(FileUtils.java:202)
                at org.apache.pulsar.common.nar.FileUtils.deleteFile(FileUtils.java:209)
                at org.apache.pulsar.common.nar.FileUtils.deleteFiles(FileUtils.java:202)
                at org.apache.pulsar.common.nar.FileUtils.deleteFile(FileUtils.java:209)
                at org.apache.pulsar.common.nar.NarUnpacker.unpackNar(NarUnpacker.java:72)
                at org.apache.pulsar.common.nar.NarClassLoader.getFromArchive(NarClassLoader.java:159)
                at org.apache.pulsar.functions.utils.functioncache.FunctionCacheEntry.#init>(FunctionCacheEntry.java:73)
                at
                org.apache.pulsar.functions.utils.functioncache.FunctionCacheManagerImpl.registerFunctionInstanceWithArchive(FunctionCacheManagerImpl.java:129)
                at org.apache.pulsar.functions.runtime.thread.ThreadRuntime.loadJars(ThreadRuntime.java:134)
                at
                org.apache.pulsar.functions.runtime.thread.ThreadRuntime.getFunctionClassLoader(ThreadRuntime.java:119)
                at org.apache.pulsar.functions.runtime.thread.ThreadRuntime.start(ThreadRuntime.java:165)
                at org.apache.pulsar.functions.runtime.RuntimeSpawner.start(RuntimeSpawner.java:80)
                at org.apache.pulsar.functions.runtime.JavaInstanceStarter.start(JavaInstanceStarter.java:232)
                ... 5 more

                Above exception from a single node broker + functions worker, with a sample function parallelism=3. The
                exception shows that it is unable to delete
                /tmp/pulsar-nar/pulsar-java-functions-pojo-parse-1.0-SNAPSHOT.jar-unpacked/META-INF/maven, which has
                already been deleted by another instance of the sample function. This exception raised my attention and
                lead me to #11340.
                To Reproduce
                Steps to reproduce the behavior:

                Have a single node cluster on K8S by https://github.com/streamnative/charts, I have created a sample
                values file as gist and can be found here
                build a sample function, you can take my example
                https://github.com/freeznet/pulsar-java-functions-pojo-parse and build with mvn
                create function with the sample package with parallelism>1, it is easier to reproduce with larger
                parallelism.
                normally you can observe the issue first with pulsar-admin functions status with some of the instances
                are not running.
                for some instances you can observe the above exception from the broker's log, this is because the race
                condition happens when multiple threads trying to delete the same file.
                for some instances you can observe the exception described in Extracted Pulsar Function jar file content
                in /tmp/pulsar-nar directory gets corrupted or overridden by different content #11340, this is because
                the race condition happens when some threads deleted the extracted nar package by the extracting thread,
                and the extracting thread is still loading the classes.

            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.pulsar.common.nar.NarUnpacker.java</file>
            <file type="M">org.apache.pulsar.common.nar.NarUnpackerTest.java</file>
        </fixedFiles>
    </bug>
    <bug id="11690" opendate="2021-08-17 00:00:00" fixdate="2022-03-18 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>Flaky-test: LockManagerTest.revalidateLockOnDifferentSession.
            </summary>
            <description>LockManagerTest is flaky. The revalidateLockOnDifferentSession test method fails sporadically.
                example failure
                Error: Tests run: 12, Failures: 1, Errors: 0, Skipped: 7, Time elapsed: 1.52 s
                FAILURE! - in org.apache.pulsar.metadata.LockManagerTest
                Error: revalidateLockOnDifferentSession(org.apache.pulsar.metadata.LockManagerTest) Time elapsed: 0.264
                s
                FAILURE!
                java.util.NoSuchElementException: No value present
                at java.base/java.util.Optional.get(Optional.java:148)
                at org.apache.pulsar.metadata.LockManagerTest.revalidateLockOnDifferentSession(LockManagerTest.java:229)
                at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
                at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
                at
                java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
                at java.base/java.lang.reflect.Method.invoke(Method.java:566)
                at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:132)
                at org.testng.internal.InvokeMethodRunnable.runOne(InvokeMethodRunnable.java:45)
                at org.testng.internal.InvokeMethodRunnable.call(InvokeMethodRunnable.java:73)
                at org.testng.internal.InvokeMethodRunnable.call(InvokeMethodRunnable.java:11)
                at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
                at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
                at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
                at java.base/java.lang.Thread.run(Thread.java:829)

            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.bookkeeper.mledger.impl.ManagedLedgerTest.java</file>
            <file type="M">org.apache.pulsar.metadata.coordination.impl.LockManagerImpl.java</file>
            <file type="M">org.apache.pulsar.metadata.coordination.impl.ResourceLockImpl.java</file>
            <file type="M">org.apache.pulsar.metadata.impl.AbstractMetadataStore.java</file>
            <file type="M">org.apache.pulsar.metadata.impl.LocalMemoryMetadataStore.java</file>
            <file type="M">org.apache.pulsar.metadata.impl.ZKMetadataStore.java</file>
            <file type="M">org.apache.pulsar.metadata.impl.ZKSessionWatcher.java</file>
            <file type="M">org.apache.pulsar.metadata.LockManagerTest.java</file>
            <file type="M">org.apache.pulsar.metadata.ZKSessionTest.java</file>
        </fixedFiles>
    </bug>
    <bug id="4447" opendate="2019-06-03 00:00:00" fixdate="2019-06-13 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>Broker gets stuck when getting partitioned stats.
            </summary>
            <description>Describe the bug
                Brokers in our cluster get stuck when executing internalGetPartitionedStats:

                pulsar/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/PersistentTopicsBase.java


                Lines 609 to 610
                in
                3cfa812


                TopicStats partitionStats = pulsar().getAdminClient().topics()


                .getStats(topicName.getPartition(i).toString());


                thread dump:
                https://gist.github.com/nkurihar/5d90ce683802390cdec2d9fb65cc0297
                "pulsar-web-28-32" #531 prio=5 os_prio=0 tid=0x00007f31a4001000 nid=0x3b69 waiting on condition
                [0x00007f30db1c6000]
                java.lang.Thread.State: WAITING (parking)
                at sun.misc.Unsafe.park(Native Method)
                - parking to wait for#0x00007f512c8e2d80> (a java.util.concurrent.CompletableFuture$Signaller)
                at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
                at java.util.concurrent.CompletableFuture$Signaller.block(CompletableFuture.java:1693)
                at java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3323)
                at java.util.concurrent.CompletableFuture.waitingGet(CompletableFuture.java:1729)
                at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1895)
                at org.apache.pulsar.client.admin.internal.TopicsImpl.getStats(TopicsImpl.java:380)
                at
                org.apache.pulsar.broker.admin.impl.PersistentTopicsBase.internalGetPartitionedStats(PersistentTopicsBase.java:610)
                at org.apache.pulsar.broker.admin.v1.PersistentTopics.getPartitionedStats(PersistentTopics.java:279)
                at sun.reflect.GeneratedMethodAccessor56.invoke(Unknown Source)
                at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
                at java.lang.reflect.Method.invoke(Method.java:498)
                at
                org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory$1.invoke(ResourceMethodInvocationHandlerFactory.java:81)
                at
                org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:144)
                at
                org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:161)
                at
                org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$TypeOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:205)
                at
                org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:99)
                at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:389)
                at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:347)
                at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:102)
                at org.glassfish.jersey.server.ServerRuntime$2.run(ServerRuntime.java:326)
                at org.glassfish.jersey.internal.Errors$1.call(Errors.java:271)
                at org.glassfish.jersey.internal.Errors$1.call(Errors.java:267)
                at org.glassfish.jersey.internal.Errors.process(Errors.java:315)
                at org.glassfish.jersey.internal.Errors.process(Errors.java:297)
                at org.glassfish.jersey.internal.Errors.process(Errors.java:267)
                at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:317)
                at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:305)
                at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:1154)
                at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:473)
                at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:427)
                at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:388)
                at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:341)
                at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:228)
                at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:845)
                at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1689)
                at org.apache.pulsar.broker.web.ResponseHandlerFilter.doFilter(ResponseHandlerFilter.java:53)
                at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1676)
                at org.apache.pulsar.broker.web.AuthenticationFilter.doFilter(AuthenticationFilter.java:74)
                at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1676)
                at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:581)
                at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:224)
                at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
                at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:511)
                at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
                at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
                at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
                at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
                at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
                at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
                at org.eclipse.jetty.server.Server.handle(Server.java:524)
                at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:319)
                at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:253)
                at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:273)
                at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:95)
                at org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:202)
                at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:273)
                at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:95)
                at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
                at
                org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
                at
                org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
                at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
                at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
                at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
                at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
                at java.lang.Thread.run(Thread.java:748)

                To Reproduce
                We haven't found the way to reproduce yet.
                Additional context
                Broker OS: CentOS Linux release 7.6.1810
                Broker version: 2.2.1
                Broker spec: Real server / 2.10GHz / 2CPU / 256GBMEM / SATA SSD 240GB x1 / 10G Base-T*2port
            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.pulsar.broker.PulsarService.java</file>
            <file type="M">org.apache.pulsar.client.admin.PulsarAdmin.java</file>
            <file type="M">org.apache.pulsar.client.admin.PulsarAdminException.java</file>
            <file type="M">org.apache.pulsar.client.admin.internal.BaseResource.java</file>
            <file type="M">org.apache.pulsar.client.admin.internal.BookiesImpl.java</file>
            <file type="M">org.apache.pulsar.client.admin.internal.BrokerStatsImpl.java</file>
            <file type="M">org.apache.pulsar.client.admin.internal.BrokersImpl.java</file>
            <file type="M">org.apache.pulsar.client.admin.internal.ClustersImpl.java</file>
            <file type="M">org.apache.pulsar.client.admin.internal.ComponentResource.java</file>
            <file type="M">org.apache.pulsar.client.admin.internal.FunctionsImpl.java</file>
            <file type="M">org.apache.pulsar.client.admin.internal.LookupImpl.java</file>
            <file type="M">org.apache.pulsar.client.admin.internal.NamespacesImpl.java</file>
            <file type="M">org.apache.pulsar.client.admin.internal.NonPersistentTopicsImpl.java</file>
            <file type="M">org.apache.pulsar.client.admin.internal.ResourceQuotasImpl.java</file>
            <file type="M">org.apache.pulsar.client.admin.internal.SchemasImpl.java</file>
            <file type="M">org.apache.pulsar.client.admin.internal.SinksImpl.java</file>
            <file type="M">org.apache.pulsar.client.admin.internal.SourcesImpl.java</file>
            <file type="M">org.apache.pulsar.client.admin.internal.TenantsImpl.java</file>
            <file type="M">org.apache.pulsar.client.admin.internal.TopicsImpl.java</file>
            <file type="M">org.apache.pulsar.client.admin.internal.WorkerImpl.java</file>
        </fixedFiles>
    </bug>
    <bug id="10767" opendate="2021-06-01 00:00:00" fixdate="2021-06-01 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>[Java client] Deadlock in Pulsar Client when running ConsumerBatchReceiveTest.
            </summary>
            <description>There's a deadlock issue in Pulsar Client in master branch. A PR test run had stalled and the
                thread dump detected this deadlock issue:
                Found one Java-level deadlock:
                =============================
                "pulsar-timer-462-1":
                waiting to lock monitor 0x00007fce080ad180 (object 0x00000000c6094a00, a
                org.apache.pulsar.client.impl.ConsumerImpl),
                which is held by "pulsar-client-internal-459-1"
                "pulsar-client-internal-459-1":
                waiting for ownable synchronizer 0x00000000c6094bf0, (a
                java.util.concurrent.locks.ReentrantReadWriteLock$NonfairSync),
                which is held by "pulsar-timer-462-1"

                Java stack information for the threads listed above:
                ===================================================
                "pulsar-timer-462-1":
                at org.apache.pulsar.client.impl.ConsumerImpl.redeliverUnacknowledgedMessages(ConsumerImpl.java:1578)
                - waiting to lock#0x00000000c6094a00> (a org.apache.pulsar.client.impl.ConsumerImpl)
                at org.apache.pulsar.client.impl.ConsumerImpl.redeliverUnacknowledgedMessages(ConsumerImpl.java:1619)
                at org.apache.pulsar.client.impl.UnAckedMessageTracker$2.run(UnAckedMessageTracker.java:145)
                at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:672)
                at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:747)
                at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:472)
                at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
                at java.lang.Thread.run(java.base@11.0.11/Thread.java:829)
                "pulsar-client-internal-459-1":
                at jdk.internal.misc.Unsafe.park(java.base@11.0.11/Native Method)
                - parking to wait for#0x00000000c6094bf0> (a
                java.util.concurrent.locks.ReentrantReadWriteLock$NonfairSync)
                at java.util.concurrent.locks.LockSupport.park(java.base@11.0.11/LockSupport.java:194)
                at
                java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(java.base@11.0.11/AbstractQueuedSynchronizer.java:885)
                at
                java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(java.base@11.0.11/AbstractQueuedSynchronizer.java:917)
                at
                java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(java.base@11.0.11/AbstractQueuedSynchronizer.java:1240)
                at
                java.util.concurrent.locks.ReentrantReadWriteLock$WriteLock.lock(java.base@11.0.11/ReentrantReadWriteLock.java:959)
                at org.apache.pulsar.client.impl.UnAckedMessageTracker.add(UnAckedMessageTracker.java:180)
                at org.apache.pulsar.client.impl.ConsumerImpl.trackMessage(ConsumerImpl.java:1385)
                at org.apache.pulsar.client.impl.ConsumerImpl.trackMessage(ConsumerImpl.java:1369)
                at org.apache.pulsar.client.impl.ConsumerImpl.messageProcessed(ConsumerImpl.java:1362)
                - locked#0x00000000c6094a00> (a org.apache.pulsar.client.impl.ConsumerImpl)
                at org.apache.pulsar.client.impl.ConsumerImpl.lambda$internalBatchReceiveAsync$5(ConsumerImpl.java:483)
                at org.apache.pulsar.client.impl.ConsumerImpl$$Lambda$1271/0x0000000100ac0c40.run(Unknown Source)
                at java.util.concurrent.Executors$RunnableAdapter.call(java.base@11.0.11/Executors.java:515)
                at java.util.concurrent.FutureTask.run(java.base@11.0.11/FutureTask.java:264)
                at
                java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(java.base@11.0.11/ScheduledThreadPoolExecutor.java:304)
                at java.util.concurrent.ThreadPoolExecutor.runWorker(java.base@11.0.11/ThreadPoolExecutor.java:1128)
                at java.util.concurrent.ThreadPoolExecutor$Worker.run(java.base@11.0.11/ThreadPoolExecutor.java:628)
                at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
                at java.lang.Thread.run(java.base@11.0.11/Thread.java:829)

                Found 1 deadlock.

                Full thread dump: https://gist.github.com/lhotari/1bbcc43e850bd7d62891ba7fe3724b0b
                thread dump in jstack.review UI:
                https://jstack.review/?https://gist.github.com/lhotari/1bbcc43e850bd7d62891ba7fe3724b0b#tda_1_dump
                The test that was executing was ConsumerBatchReceiveTest:
                "main" #1 prio=5 os_prio=0 cpu=13468.61ms elapsed=6534.24s tid=0x00007fce64027800 nid=0xca9 in
                Object.wait() [0x00007fce6a11e000]
                java.lang.Thread.State: TIMED_WAITING (on object monitor)
                at java.lang.Object.wait(java.base@11.0.11/Native Method)
                - waiting on
                no object reference available>
                at java.lang.Thread.join(java.base@11.0.11/Thread.java:1308)
                - waiting to re-lock in wait()#0x00000000c4246738> (a io.netty.util.concurrent.FastThreadLocalThread)
                at io.netty.util.HashedWheelTimer.stop(HashedWheelTimer.java:383)
                at org.apache.pulsar.client.impl.PulsarClientImpl.shutdown(PulsarClientImpl.java:730)
                at
                org.apache.pulsar.broker.auth.MockedPulsarServiceBaseTest.internalCleanup(MockedPulsarServiceBaseTest.java:192)
                at org.apache.pulsar.client.api.ConsumerBatchReceiveTest.cleanup(ConsumerBatchReceiveTest.java:48)
                at org.apache.pulsar.tests.TestRetrySupport.stateCheck(TestRetrySupport.java:52)
                at jdk.internal.reflect.GeneratedMethodAccessor129.invoke(Unknown Source)
                at
                jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(java.base@11.0.11/DelegatingMethodAccessorImpl.java:43)
                at java.lang.reflect.Method.invoke(java.base@11.0.11/Method.java:566)
                at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:132)
                at
                org.testng.internal.MethodInvocationHelper.invokeMethodConsideringTimeout(MethodInvocationHelper.java:61)
                at org.testng.internal.ConfigInvoker.invokeConfigurationMethod(ConfigInvoker.java:366)
                at org.testng.internal.ConfigInvoker.invokeConfigurations(ConfigInvoker.java:320)
                at org.testng.internal.TestInvoker.runConfigMethods(TestInvoker.java:701)
                at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:527)
                at org.testng.internal.TestInvoker.retryFailed(TestInvoker.java:214)
                at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:58)
                at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:822)
                at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:147)
                at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146)
                at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128)
                at org.testng.TestRunner$$Lambda$219/0x0000000100448c40.accept(Unknown Source)
                at java.util.ArrayList.forEach(java.base@11.0.11/ArrayList.java:1541)
                at org.testng.TestRunner.privateRun(TestRunner.java:764)
                at org.testng.TestRunner.run(TestRunner.java:585)
                at org.testng.SuiteRunner.runTest(SuiteRunner.java:384)
                at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:378)
                at org.testng.SuiteRunner.privateRun(SuiteRunner.java:337)
                at org.testng.SuiteRunner.run(SuiteRunner.java:286)
                at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53)
                at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96)
                at org.testng.TestNG.runSuitesSequentially(TestNG.java:1218)
                at org.testng.TestNG.runSuitesLocally(TestNG.java:1140)
                at org.testng.TestNG.runSuites(TestNG.java:1069)
                at org.testng.TestNG.run(TestNG.java:1037)
                at org.apache.maven.surefire.testng.TestNGExecutor.run(TestNGExecutor.java:135)
                at
                org.apache.maven.surefire.testng.TestNGDirectoryTestSuite.executeSingleClass(TestNGDirectoryTestSuite.java:112)
                at
                org.apache.maven.surefire.testng.TestNGDirectoryTestSuite.executeLazy(TestNGDirectoryTestSuite.java:123)
                at org.apache.maven.surefire.testng.TestNGDirectoryTestSuite.execute(TestNGDirectoryTestSuite.java:90)
                at org.apache.maven.surefire.testng.TestNGProvider.invoke(TestNGProvider.java:146)
                at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
                at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
                at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
                at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

                Expected behavior
                Pulsar Client shouldn't deadlock.
            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.pulsar.client.impl.UnAckedMessageTracker.java</file>
        </fixedFiles>
    </bug>
    <bug id="2141" opendate="2018-07-12 00:00:00" fixdate="2018-07-17 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>Race condition in reconnection after managed ledger is fenced.
            </summary>
            <description>While checking the intermittent failures for SequenceIdWithErrorTest, I've seen that the test
                is failing due to a race condition involving both producer and consumer reconnecting to the broker after
                the topic was fenced (in the case of the test, the fencing error is purposely inject).
            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.pulsar.client.impl.SequenceIdWithErrorTest.java</file>
        </fixedFiles>
    </bug>
    <bug id="8050" opendate="2020-09-13 00:00:00" fixdate="2020-10-03 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>Replace map with set.
            </summary>
            <description>In PulsarClientImpl, we use IdentityHashMap to hold the reference of producers/consumers like
                below:
                producers.put(producer, Boolean.TRUE);

                It's better to use List, for value is never used but stored.
                But Pulsar pursues performance, so looks good to use thread safe set -- Collections.newSetFromMap(new
                ConcurrentHashMap#()) .
            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.pulsar.client.impl.BrokerClientIntegrationTest.java</file>
            <file type="M">org.apache.pulsar.client.impl.PulsarClientImpl.java</file>
        </fixedFiles>
    </bug>
    <bug id="1117" opendate="2018-01-26 00:00:00" fixdate="2022-05-05 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>Exception during namespace bundle split.
            </summary>
            <description>This particular exception was reported. It was during an automatically initiated bundle split.
                2018-01-26 00:38:08,489 - ERROR - [pulsar-web-61-28:PulsarWebResource@381] - [null] Failed to validate
                namespace bundle netflix/prod/ns1/0x84000000_0x86000000
                java.lang.IllegalArgumentException: Invalid upper boundary for bundle
                at com.google.common.base.Preconditions.checkArgument(Preconditions.java:122)
                at org.apache.pulsar.common.naming.NamespaceBundles.validateBundle(NamespaceBundles.java:110)
                at
                org.apache.pulsar.broker.web.PulsarWebResource.validateNamespaceBundleRange(PulsarWebResource.java:378)
                at
                org.apache.pulsar.broker.web.PulsarWebResource.validateNamespaceBundleOwnership(PulsarWebResource.java:404)
                at org.apache.pulsar.broker.admin.Namespaces.splitNamespaceBundle(Namespaces.java:876)
                at sun.reflect.GeneratedMethodAccessor127.invoke(Unknown Source)
                at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
                at java.lang.reflect.Method.invoke(Method.java:498)
                at
                org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory$1.invoke(ResourceMethodInvocationHandlerFactory.java:81)
                at
                org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:144)
                at
                org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:161)
                at
                org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$VoidOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:143)
                at
                org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:99)
                at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:389)
                at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:347)
                at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:102)
                at org.glassfish.jersey.server.ServerRuntime$2.run(ServerRuntime.java:326)
                I think that the race condition is happening since all 4 initial bundles are getting split around the
                same time and the bundle cache gets updated while the new bundle split is being processed.
                The result doesn't cause any particular issue, just that the bundle split fails with invalid bundle
                range, but the current bundle will continue to run unaffacted until the next split will take place.
            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.pulsar.broker.cache.LocalZooKeeperCacheService.java</file>
            <file type="M">org.apache.pulsar.broker.namespace.NamespaceService.java</file>
            <file type="M">org.apache.pulsar.common.naming.NamespaceBundleFactory.java</file>
            <file type="M">org.apache.pulsar.broker.admin.AdminApiTest.java</file>
            <file type="M">org.apache.pulsar.broker.namespace.NamespaceServiceTest.java</file>
            <file type="M">org.apache.pulsar.zookeeper.ZooKeeperDataCache.java</file>
        </fixedFiles>
    </bug>
    <bug id="10170" opendate="2021-04-08 00:00:00" fixdate="2021-04-27 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>Optimize the lock in AuthenticationAthenz.
            </summary>
            <description>Describe the bug
                The use of the lock in AuthenticationAthenz will reduce the efficiency of AuthenticationAthenz. Hope it
                can be optimized.

                Error: Medium: Inconsistent synchronization of
                org.apache.pulsar.client.impl.auth.AuthenticationAthenz.roleToken; locked 57% of time
                [org.apache.pulsar.client.impl.auth.AuthenticationAthenz,
                org.apache.pulsar.client.impl.auth.AuthenticationAthenz,
                org.apache.pulsar.client.impl.auth.AuthenticationAthenz,
                org.apache.pulsar.client.impl.auth.AuthenticationAthenz,
                org.apache.pulsar.client.impl.auth.AuthenticationAthenz,
                org.apache.pulsar.client.impl.auth.AuthenticationAthenz,
                org.apache.pulsar.client.impl.auth.AuthenticationAthenz] Unsynchronized access at
                AuthenticationAthenz.java:[line 51]Unsynchronized access at AuthenticationAthenz.java:[line
                51]Unsynchronized access at AuthenticationAthenz.java:[line 51]Synchronized access at
                AuthenticationAthenz.java:[line 88]Synchronized access at AuthenticationAthenz.java:[line
                98]Synchronized access at AuthenticationAthenz.java:[line 100]Synchronized access at
                AuthenticationAthenz.java:[line 107] IS2_INCONSISTENT_SYNC

                To Reproduce
                For more information, please see #8980 CI logs
                Expected behavior
                A clear and concise description of what you expected to happen.
                Screenshots
                If applicable, add screenshots to help explain your problem.
                Desktop (please complete the following information):

                OS: [e.g. iOS]

                Additional context
                Add any other context about the problem here.
            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.pulsar.client.impl.auth.AuthenticationAthenz.java</file>
        </fixedFiles>
    </bug>
    <bug id="8293" opendate="2020-10-19 00:00:00" fixdate="2020-10-19 00:00:00" resolution="Fixed">
        <buginformation>
            <summary>Race condition in updating ManagedCursorImpl.readPosition.
            </summary>
            <description>Describe the bug
                #8229 seems to have been caused by a race condition in updating ManagedCursorImpl.readPosition
                To Reproduce
                Since this is a concurrency issue, it's hard to reproduce and there isn't yet a publicly shared way to
                reproduce.
                Expected behavior
                Updates to ManagedCursorImpl.readPosition field should not lead to inconsistent state. It's not clear
                without understanding the code how concurrent updates should be handled.
                Additional context
                Please refer to #8229 for additional context. There's a link to a Slack thread for more discussions.
                There's a fix for #8229 which prevents the infinite loop: #8284 . This fix doesn't specifically address
                the race condition that happens in updating the ManagedCursorImpl.readPosition field.
                There seems to be quite a few past issues where a race condition in updating readPosition has been an
                issue. For example #1478 , #3015 # #287 .
                There is also a change #6606 which adds READ_POSITION_UPDATER for ManagedCursorImpl.readPosition.
                Regarding the race condition in #8229, it seems that ManagedCursorImpl.readPosition could get out of
                sync from OpReadEntry.readPosition if ManagedCursorImpl.readPosition gets updated after the OpReadEntry
                has been created since OpReadEntry's readPosition gets initialized from ManagedCursorImpl.readPosition.
                The race condition seems to happen in this code in the setAcknowledgePosition method:


                pulsar/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedCursorImpl.java


                Lines 1512 to 1523
                in
                825fdd4


                if (readPosition.compareTo(newMarkDeletePosition)= 0) {


                // If the position that is mark-deleted is past the read position, it


                // means that the client has skipped some entries. We need to move


                // read position forward


                PositionImpl oldReadPosition = readPosition;


                readPosition = ledger.getNextValidPosition(newMarkDeletePosition);


                if (log.isDebugEnabled()) {


                log.debug("[{}] Moved read position from: {} to: {}, and new mark-delete position {}", ledger.getName(),


                oldReadPosition, readPosition, markDeletePosition);


                }


                }


                Clarification, possible solution
                The problem isn't about synchronization or a missing lock. It's a race condition which cannot be
                resolved by simply adding a lock or synchronization.
                It should be possible to detect if another thread has modified the state and then have some code to do
                "conflict resolution". For example, when readPosition gets updated in setAcknowledgePosition method, it
                most likely shouldn't move the readPosition "backwards".
                There's already code in setReadPosition to take the markDeletePosition into account when updating
                readPosition. Similarly in setAcknowledgePosition, it should most likely take the previous state of
                readPosition into account when updating the value so that readPosition doesn't "jump backwards" in a
                race condition.
            </description>
            <version>1.1.0</version>
            <fixedVersion>1.1.0</fixedVersion>
            <type>Bug</type>
        </buginformation>
        <fixedFiles>
            <file type="M">org.apache.bookkeeper.mledger.impl.ManagedCursorImpl.java</file>
        </fixedFiles>
    </bug>
</bugrepository>