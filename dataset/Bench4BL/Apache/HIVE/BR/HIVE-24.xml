<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sat Dec 03 00:45:18 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HIVE-24/HIVE-24.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HIVE-24] support for reading binary data from flat files</title>
                <link>https://issues.apache.org/jira/browse/HIVE-24</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;like textinputformat - looking for a concrete implementation to read binary records from a flat file (that may be compressed).&lt;/p&gt;

&lt;p&gt;it&apos;s assumed that hadoop can&apos;t split such a file. so the inputformat can set splittable to false.&lt;/p&gt;

&lt;p&gt;tricky aspects are:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;how to know what class the file contains (has to be in a configuration somewhere).&lt;/li&gt;
	&lt;li&gt;how to determine EOF (would be nice if hadoop can determine EOF and not have the deserializer throw an exception  (which is hard to distinguish from a exception due to corruptions?)). this is easy for non-compressed streams - for compressed streams - DecompressorStream has a useful looking getAvailable() call - except the class is marked package private.&lt;/li&gt;
&lt;/ul&gt;

</description>
                <environment></environment>
        <key id="12403646">HIVE-24</key>
            <summary>support for reading binary data from flat files</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="jsensarma">Joydeep Sen Sarma</reporter>
                        <labels>
                    </labels>
                <created>Wed, 3 Sep 2008 22:55:33 +0000</created>
                <updated>Sat, 17 Dec 2011 00:09:05 +0000</updated>
                            <resolved>Mon, 17 Nov 2008 01:30:48 +0000</resolved>
                                                    <fixVersion>0.3.0</fixVersion>
                                    <component>Serializers/Deserializers</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>11</watches>
                                                                <comments>
                            <comment id="12628192" author="jsensarma" created="Wed, 3 Sep 2008 22:56:09 +0000"  >&lt;p&gt;see &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-4065&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HADOOP-4065&lt;/a&gt; as well.&lt;/p&gt;</comment>
                            <comment id="12628484" author="owen.omalley" created="Thu, 4 Sep 2008 22:18:02 +0000"  >&lt;p&gt;How are you going to define/find record boundaries? Is it going to be key/value or single blob? How is it different from KeyValueInputFormat?&lt;/p&gt;</comment>
                            <comment id="12628526" author="wyckoff" created="Thu, 4 Sep 2008 23:51:42 +0000"  >&lt;p&gt;I think what he means is that file format and record boundary finding could be decoupled, and the latter made into some kind of interface that may be related to the deserializer. He&apos;s talking about binary data for which only really the deserializer can figure out record boundaries. &lt;/p&gt;</comment>
                            <comment id="12628530" author="wyckoff" created="Fri, 5 Sep 2008 01:22:02 +0000"  >&lt;p&gt;It would be nice to also take care of the case where the file is self describing like sequence files. If we had a FlatFileRecordReader(conf, split, serializerFactory) where the serializerFactory could be initialized with the conf, split and the input stream, it could optionally read the self describing data from the inputstream. Then regardless, it could be used to implement getKey and getValue which it could do from the self described data or as you said based on the path. Or it could just instantiate the factory from a conf variable.&lt;/p&gt;

&lt;p&gt;Then the user is free to implement the serializer lookup however they want much like most of the rest of the system.&lt;/p&gt;

&lt;p&gt;This means the serializer lookup is very low in the stack, but since one must implement next and as Joy points out, you can&apos;t do that without the serializer??&lt;/p&gt;

&lt;p&gt;This solves this case, but also the case of self describing thrift TRecordStream since the serializer class info would be in the header itself.&lt;/p&gt;

&lt;p&gt;It would also be nice if the underlying input stream could actually be an interface because sometimes there&apos;s a flat file, but other times it may be compressed or some other format, but that format is capable of producing a stream of bytes. &lt;/p&gt;

&lt;p&gt;So, I guess I&apos;m advocating for flexibility in defining the serializer lookup logic as well as how to read from the file.&lt;/p&gt;
</comment>
                            <comment id="12628658" author="owen.omalley" created="Fri, 5 Sep 2008 15:50:46 +0000"  >&lt;p&gt;Ok, a dispatching FileInputFormat could make sense. Where it looked at the&lt;br/&gt;
filenames or header of the files and picked the appropriate reader. At that&lt;br/&gt;
point, it isn&apos;t about binary files, because you&apos;d want it to work for text&lt;br/&gt;
files also. What would be the approach? Filenames like we do with the&lt;br/&gt;
compression of text files? Or sampling the first 80 bytes looking for a&lt;br/&gt;
header?&lt;/p&gt;

&lt;p&gt;&amp;#8211; Owen&lt;/p&gt;</comment>
                            <comment id="12628679" author="wyckoff" created="Fri, 5 Sep 2008 17:29:55 +0000"  >&lt;p&gt;I think in Joy&apos;s case, it would be the filename and/or with some configuration info in the jobconf.  In the TRecordStream case, we would need to use some code from TFixedFrameTransport to read the frame headers - TFixedFrameTransport is splittable. (TRS is a thin layer on top of TFFT).&lt;/p&gt;

&lt;p&gt;Joy or I can post a proposed API.&lt;/p&gt;

&lt;p&gt;good point, we should make it general and not just for binary.&lt;/p&gt;

&lt;p&gt;pete&lt;/p&gt;
</comment>
                            <comment id="12628806" author="wyckoff" created="Sat, 6 Sep 2008 00:45:43 +0000"  >&lt;p&gt;I propose we re-use the code from SequenceFileRecordReader by making it depend on a SplittableTypedFile interace (below) which conveniently is already implemented by SequenceFile.  Then we&apos;re basically done. &lt;/p&gt;

&lt;p&gt;I am not super-familiar with this code and the devil is probably in the details, but looking at SequenceFileRecordReader, there is basically only about 5 methods it uses from SequenceFile and those are all well defined and seem needed for any implementation of a self describing file that is splittable.&lt;/p&gt;

&lt;p&gt;We could also not touch SequenceFileRecordReader, but it seems we&apos;d just be duplicating all of its code.&lt;/p&gt;


&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;&quot;&gt;&lt;b&gt;TypedFile Interfaces&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;

                                                                                                                                                                                      &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;interface&lt;/span&gt; TypedFile  {                                                                                                                                                         
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void initialize(Configuration conf, InputStream in);                                                                                                                         
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt; getKeyClass();                                                                                                                                                         
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt; getValueClass();                                                                                                                                                       
                                                                                                                                                                                      
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; next(Writable key);                                                                                                                                                  
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; next(Writable key, Writable value);                                                                                                                                  
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; Writable getCurrentValue();                                                                                                                                                  
}                                                                                                                                                                                     
                                                                                                                                                                                      
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;interface&lt;/span&gt; SplittableTypedFile &lt;span class=&quot;code-keyword&quot;&gt;implements&lt;/span&gt; TypedFile {                                                                                                                           
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; syncSeen(); &lt;span class=&quot;code-comment&quot;&gt;// i.e., atEOF()                                                                                                                                         
&lt;/span&gt;  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; sync(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;); &lt;span class=&quot;code-comment&quot;&gt;// skip to past last frame boundary                                                                                                                      
&lt;/span&gt;}                                                                                                                                                                                     
                                                                                                                                                                                      
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;&quot;&gt;&lt;b&gt;TypedSplittableRecordReader&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;

&lt;span class=&quot;code-comment&quot;&gt;// This is almost a complete cut-n-paste of existing SequenceFileRecordReader - which would be removed
&lt;/span&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; class TypedSplittableRecordReader&amp;lt;K, V&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;implements&lt;/span&gt; RecordReader&amp;lt;K,V&amp;gt; {                                                                                                         
  SplittableTypedFile in;                                                                                                                                                             
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; TypedRecordReader(Configuration conf, FileSplit split, SplittableTypedFileFactory&amp;lt;K,V&amp;gt; fileFactory) {                                                                        
    &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.in = fileFactory.getFileReader(fs, path, conf);                                                                                                                              
  }                                                                                                                                                                                   
  &lt;span class=&quot;code-comment&quot;&gt;// the &lt;span class=&quot;code-keyword&quot;&gt;rest&lt;/span&gt; is exactly like the current sequence file implementation basically.                                                                                                     
&lt;/span&gt;}                                                                                                                                                                                     
                                                                                                                                                                                      
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;&quot;&gt;&lt;b&gt;SequenceFile&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;

-&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; class SequenceFile {
+&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; class SequenceFile &lt;span class=&quot;code-keyword&quot;&gt;implements&lt;/span&gt; SplittableTypedFile {                                                                                                                                  
                                                                                                                                                                                      
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;&quot;&gt;&lt;b&gt;SequenceFileInputFormat&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;                                                                                                                                                                                      

&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; class SequenceFileInputFormat&amp;lt;K, V&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; FileInputFormat&amp;lt;K, V&amp;gt; {                                                                                                            
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; RecordReader&amp;lt;K,V&amp;gt; getRecordReader() {                                                                                                                                        
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; TypedSplittableRecordReader&amp;lt;K, V&amp;gt;(job, split, &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SequenceFileFactory&amp;lt;K,V&amp;gt;());                                                                                             
  }                                                                                                                                                                                   
}                            

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;&quot;&gt;&lt;b&gt;SelfDescribingFileExample&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; class TFixedFrameTransportInputFormat &lt;span class=&quot;code-keyword&quot;&gt;implements&lt;/span&gt; SplittableTypedFile {                                                                                                         
  &lt;span class=&quot;code-comment&quot;&gt;// implementing all the above should be straightforward                                                                                                                             
&lt;/span&gt;}                                                                                                                                                                                     

&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; class TFixedFrameTransportFileInputFormat&amp;lt;K, V&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; FileInputFormat&amp;lt;K, V&amp;gt; {                                                                                                
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; RecordReader&amp;lt;K,V&amp;gt; getRecordReader() {                                                                                                                                        
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; TypedSplittableRecordReader&amp;lt;K, V&amp;gt;(job, split, &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; TFixedFrameFileFactory&amp;lt;K,V&amp;gt;());                                                                                          
  }                                                                                                                                                                                   
}                                                                                                                                                                                     

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;One problem is for non-splittable files, I have to create another record reader with almost the same code. Maybe better to put everything in one interface and add boolean isSplittable and have sync just do a seek(0) and syncSeen just look at EOF.&lt;/p&gt;

</comment>
                            <comment id="12629296" author="wyckoff" created="Mon, 8 Sep 2008 21:22:44 +0000"  >&lt;p&gt;I just wanted to post pseudo-code for this design that actually addresses this JIRA &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; and not only self describing files like SequenceFile and Thrift&apos;s TRecordStream.&lt;/p&gt;

&lt;p&gt;In the case for this JIRA, the file&apos;s metadata is stored in some external store or dictionary or something.  The only way to lookup the file would be through the filename/path, so I think it&apos;s fair that on job submission, the mapping is put in the JobConf.&lt;/p&gt;

&lt;p&gt;Given this use case, and looking at line 43 of SequenceFileRecordReader (   this.in = new SequenceFile.Reader(fs, path, conf); ), the TypeFile        interface should be changed:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void initialize(Configuration conf, InputStream in);&lt;br/&gt;
+ public void initialize(FileSystem, Path, Configuration);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Obviously it has top open the inputstream anyway ( &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; ).  &lt;/p&gt;

&lt;p&gt;And a typo SequenceFile would not implement SplittableTypedFile, SequenceFile.Reader would.&lt;/p&gt;



</comment>
                            <comment id="12629298" author="mahadev" created="Mon, 8 Sep 2008 21:32:10 +0000"  >&lt;p&gt;we at yahoo have been working on similar kind of files where data is just stored as binary data and is splittable. &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://issues.apache.org/jira/browse/HADOOP-3315&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/browse/HADOOP-3315&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;the  spec is old and needs to be updated. TFile is meant to be a sequence file replacement.&lt;/p&gt;


&lt;p&gt;  A TFile is a container of key-value pairs. Both keys and values are type-less&lt;br/&gt;
  byte arrays. Keys can be up to 64KB, value length is not restricted. TFile&lt;br/&gt;
  further provides the following features:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Block Compression.&lt;/li&gt;
	&lt;li&gt;Named meta data blocks.&lt;/li&gt;
	&lt;li&gt;Sorted or unsorted keys.&lt;/li&gt;
	&lt;li&gt;Seek by key or by file offset.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;We will update the specs on &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-3315&quot; title=&quot;New binary file format&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-3315&quot;&gt;&lt;del&gt;HADOOP-3315&lt;/del&gt;&lt;/a&gt; by the end of this week. &lt;/p&gt;
</comment>
                            <comment id="12629305" author="wyckoff" created="Mon, 8 Sep 2008 21:46:41 +0000"  >&lt;p&gt;Nice. Will the TFileRecordReader fit into this paradigm?  How were you going to implement the TFileRecordReader?&lt;/p&gt;

&lt;p&gt;TFile is very similar to TRecordStream - but more full featured - sorted and seek by key. But, TRecordStream is meant to be readable/writable in many languages (first cut c++, java, python and perl). It&apos;s primary use case is non-hadoop - just a robust way of logging data, but secondarily, there&apos;s no reason not to enable directly reading/writing to one from Hadoop as it&apos;s a waste to open one, read it and write it out as a TFile or SF if one doesn&apos;t need the richer functionality that sequence file and tfile support.&lt;/p&gt;



&lt;p&gt;&amp;#8211; pete&lt;/p&gt;
</comment>
                            <comment id="12629315" author="mahadev" created="Mon, 8 Sep 2008 22:22:00 +0000"  >&lt;p&gt;the tfilerecordreader would just return raw bytes for keys and values and its up to the application to convert the raw bytes to types. Though as far as our implementation goes right now &amp;#8211; we dont have a map reduce interface for Tfiles. We intend to provide one.&lt;/p&gt;

&lt;p&gt;The TFile is also supposed to be readable/writable in  other languages with the spec being clear enough on how to read and write Tfiles. We intend to provide just java implementation of Tfiles though. &lt;/p&gt;</comment>
                            <comment id="12629339" author="wyckoff" created="Mon, 8 Sep 2008 23:56:19 +0000"  >&lt;p&gt;Actual interface&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;&quot;&gt;&lt;b&gt;TypedSplittableFile.java&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;

&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;interface&lt;/span&gt; TypedSplittableFile {                                                                                                                                                                         
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void initialize(FileSystem fileSys, Path path, Configuration conf) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException;                                                                                                                
                                                                                                                                                                                                               
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt; getKeyClass() ;                                                                                                                                                                                 
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt; getValueClass();                                                                                                                                                                                
                                                                                                                                                                                                               
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; next(&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; key) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException;                                                                                                                                                           
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; getCurrentValue(&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; val) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException ;                                                                                                                                               
                                                                                                                                                                                                               
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; syncSeen(); &lt;span class=&quot;code-comment&quot;&gt;// i.e., atEOF()                                                                                                                                                                  
&lt;/span&gt;  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void sync(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; position) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException; &lt;span class=&quot;code-comment&quot;&gt;// skip to past last frame boundary                                                                                                                      
&lt;/span&gt;  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; getPosition() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException;                                                                                                                                                                
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void seek(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; position) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException;                                                                                                                                                          
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void close() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException;                                                                                                                                                                      
                                                                                                                                                                                                               
}    
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12629342" author="wyckoff" created="Tue, 9 Sep 2008 00:06:42 +0000"  >&lt;blockquote&gt;&lt;p&gt;The TFile is also supposed to be readable/writable in other languages with the spec being clear enough on how to read and write Tfiles. We intend to provide just java implementation of Tfiles though.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Fair enough. If we had TFile in a number of languages it could probably be put in as a thrift transport. TRS is much simpler though and thus much easier to write in other languages.&lt;/p&gt;</comment>
                            <comment id="12629359" author="wyckoff" created="Tue, 9 Sep 2008 01:35:34 +0000"  >&lt;p&gt;This is what the proposal would look like. It:&lt;/p&gt;

&lt;p&gt;1. adds the TypedSplittableFile interface&lt;br/&gt;
2. changes SequenceFile.Reader to implement TypedSplittableFile and adds an initialize method and an empty constructor&lt;br/&gt;
3. implements TypedSplittableFileRecordReader - just copied the code from SequenceFileRecordReader and changed the constructor only&lt;br/&gt;
4. change SequenceFileRecordReader to extend TypedSplittableFileRecordReader and have its constructor just construct the parent class.&lt;/p&gt;

&lt;p&gt;Still a work in progress, but this kind of shows the API and the changes to SequenceFileRecordReader.&lt;/p&gt;
</comment>
                            <comment id="12629360" author="wyckoff" created="Tue, 9 Sep 2008 01:42:37 +0000"  >&lt;p&gt;psuedo-esque code that implements Thrift in FlatFiles where the filename is used as the key to get the thrift class from the configuration.  Implements &amp;lt;LongWritable, ThriftWritable&amp;gt;;&lt;/p&gt;

&lt;p&gt;Of course, it may be that we want to use the serialization classes.&lt;/p&gt;</comment>
                            <comment id="12629362" author="jsensarma" created="Tue, 9 Sep 2008 01:46:08 +0000"  >&lt;p&gt;@Pete - i am still trying to understand the proposed interface. in my case - the data is not splitable (so maybe there&apos;s a different base class - UnsplittableFileInputFormat). The factory approach for getting a record reader sounds interesting - but on second thoughts - since the getRR() already takes in a Configuration object - we don&apos;t need a new interface for this i think. (Meaning that we could write a ConfigurableRecordReader that could look at the config and instantiate the right record reader and then redirect all RR api calls to the contained record reader.)&lt;/p&gt;

&lt;p&gt;the main motivation i had for filing this bug was to extract out the common parts for dealing with compressed, non-splitable binary data into a base class (and most of this functionality is in the record reader) and make it easy to handle new kinds of binary data with minimal code. Binary files don&apos;t have keys and values - they just have rows of data. So one part is to supply some default key (like record number). The remaining part is to get the class of the row and the deserialization method. Appropriately - it would be nice to have a deserializerFactory that takes in a Configuration object (which is i think one of the key missing parts of hadoop-1986). that way - the deserializer can be configured by application - instead of hadoop maintaining a mapping from class -&amp;gt; Deserializer.&lt;/p&gt;

&lt;p&gt;so my proposal would be something like this (admittedly - i am not being very ambitious here - just want to cover the issue mentioned in this jira):&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
/**
  * forced to make &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; class since maprunner tries to use same object &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; all next() calls.
  * This way we can swap out the actual &apos;row&apos; object on each call to next()
  */
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; class RowContainer {
   &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; row;
}

/**
 * Application can &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; right deserializer based on configuration
 */
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;interface&lt;/span&gt; RowSource {
   &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; Deserializer&amp;lt;?&amp;gt; getDeserializer(Configuration conf) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException;
   &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;&amp;lt;?&amp;gt; getClass();
}

/**
 * Reads a non-splitable binary flat file.
 */
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; class RowSourceFileInputFormat &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; FileInputFormat&amp;lt;LongWritable, RowContainer&amp;gt; {
  &lt;span class=&quot;code-keyword&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; isSplitable(FileSystem fs, Path file) { &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;; }
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; RecordReader&amp;lt;LongWritable, RowContainer&amp;gt; getRecordReader(InputSplit genericSplit, JobConf job,
                                                                      Reporter reporter)
    &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
    reporter.setStatus(genericSplit.toString());
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; RowSourceRecordReader(job, (FileSplit) genericSplit);
  }
}

/**
 * Reads one row at a time. The key is the row number and the actual row is returned inside the RowContainer
 */
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; class RowSourceRecordReader &lt;span class=&quot;code-keyword&quot;&gt;implements&lt;/span&gt; RecordReader&amp;lt;LongWritable, RowContainer&amp;gt; {
    &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; rnum;
    &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; DataInput in;
    &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; DecompressorStream dcin;
    &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; FSDataInputStream fsin;
    &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; end;
    &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Deserializer deserializer;

    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; RowSourceRecordReader(Configuration job,
                                FileSplit split) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {

      &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Path file = split.getPath();
      CompressionCodecFactory compressionCodecs = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; CompressionCodecFactory(job);
      &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; CompressionCodec codec = compressionCodecs.getCodec(file);
      FileSystem fs = file.getFileSystem(job);
      fsin = fs.open(split.getPath());

      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt;(codec != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
        dcin = (DecompressorStream)codec.createInputStream(fsin);
        in = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; DataInputStream(dcin);
      } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
        dcin = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
        in = fsin;
      }
      rnum = 0;
      end = split.getLength();

      deserializer=(ReflectionUtils.newInstance(job.getClass(&lt;span class=&quot;code-quote&quot;&gt;&quot;mapred.input.rowsource&quot;&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, RowSource.class)).getDeserializer(job);
      deserializer.open(in);
    }

    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; LongWritable createKey() {
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; LongWritable();
    }

    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; RowContainer createValue() {
       &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; RowContainer();
    }

    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; next(LongWritable key, RowContainer value) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt;(dcin != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (dcin.available() == 0) {
          &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;
        }
      } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt;(fsin.getPos() &amp;gt;= end) {
          &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;
        }
      }
      key.set(rnum++);
      &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; row = deserializer.deserialize(value.row);
      value.row = row;
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
    }

    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;float&lt;/span&gt; getProgress() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
      &lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; assumes no splitting                                                                                               
&lt;/span&gt;      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (end == 0) {
        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; 0.0f;
      } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
        &lt;span class=&quot;code-comment&quot;&gt;// gives progress over uncompressed stream                                                                               
&lt;/span&gt;        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Math&lt;/span&gt;.min(1.0f, fsin.getPos()/(&lt;span class=&quot;code-object&quot;&gt;float&lt;/span&gt;)(end));


    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; getPos() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
      &lt;span class=&quot;code-comment&quot;&gt;// position over uncompressed stream. not sure what                                                                        
&lt;/span&gt;      &lt;span class=&quot;code-comment&quot;&gt;// effect &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; has on stats about job                                                                                      
&lt;/span&gt;      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; fsin.getPos();
    }

    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt; void close() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
       &lt;span class=&quot;code-comment&quot;&gt;// assuming that &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; closes the underlying streams
&lt;/span&gt;       deserializer.close();
    }
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12629366" author="jsensarma" created="Tue, 9 Sep 2008 02:05:51 +0000"  >&lt;p&gt;oh - and my code does not work without a change to DecompressorStream class to make that a public class (it&apos;s marked package private right now). Truthfully - that forced me to file this bug &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="12629398" author="wyckoff" created="Tue, 9 Sep 2008 05:44:45 +0000"  >&lt;p&gt;It looks like we posted complimentary patches &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; I think we should keep my RecordReader, but use your implementation of the TypedFileTransport as it&apos;s more general since it uses the serialization framework.&lt;/p&gt;

&lt;p&gt;This would address the use case of files whose serializers are set in the config file and self describing files like sequence files and TRecordStream and I would guess, TFile but I haven&apos;t looked at it.&lt;/p&gt;

&lt;p&gt;&amp;#8211; pete&lt;/p&gt;</comment>
                            <comment id="12629652" author="owen.omalley" created="Tue, 9 Sep 2008 23:12:56 +0000"  >&lt;p&gt;I think this is too complicated. What is the justification for these new interfaces? We already have RecordReader that already &lt;br/&gt;
expresses these concepts.&lt;/p&gt;

&lt;p&gt;Once the TFile stuff is ready, I think it would make a lot of sense to build an ObjectFile that uses the pluggable serializer&lt;br/&gt;
framework to save any objects. At that point, it becomes a potential replacement for SequenceFile. By using the serializer&lt;br/&gt;
framework, it should work fine with Java serialization, Thrift, or Protocol Buffers. I don&apos;t think having a Thrift file format is very&lt;br/&gt;
compelling at that point.&lt;/p&gt;</comment>
                            <comment id="12629654" author="wyckoff" created="Tue, 9 Sep 2008 23:19:16 +0000"  >&lt;p&gt;Yes, good point.&lt;/p&gt;

&lt;p&gt;I will change it to DeserializerTypedFile.&lt;/p&gt;

&lt;p&gt;But, the SequenceFileRecordReader is re-usable for all these.  From the reader of a file that does its own deserializing of its types, it&apos;s all the same.&lt;/p&gt;

&lt;p&gt;With this interface, the SequenceFileRecordReader can read SequenceFiles, DeserializerTypedFiles (thrift, proto buffers, record io whatever) and any other self describing typed files; sequencefile&apos;s being one example of these.&lt;/p&gt;

&lt;p&gt;Otherwise, I don&apos;t see how not to be re-implementing the current SequenceFileRecordReader functionality for all these use cases??&lt;/p&gt;

&lt;p&gt;&amp;#8211; pete&lt;/p&gt;</comment>
                            <comment id="12629659" author="wyckoff" created="Tue, 9 Sep 2008 23:42:24 +0000"  >&lt;p&gt;I will submit a patch with its own RecordReader so we don&apos;t need to change SequenceFileRR. I&lt;/p&gt;</comment>
                            <comment id="12629661" author="cutting" created="Tue, 9 Sep 2008 23:50:53 +0000"  >&lt;p&gt;&amp;gt; With this interface, the SequenceFileRecordReader can read SequenceFiles, DeserializerTypedFiles (thrift, proto buffers, record io whatever) and any other self describing typed files; sequencefile&apos;s being one example of these.&lt;/p&gt;

&lt;p&gt;I&apos;m all for reducing code duplication.  So if SequenceFileRecordReader can mostly be replaced with code that&apos;s shared by other file format&apos;s that&apos;d be great.  But we need those file formats to exist before we perform this factoring.  Is there a splittable thrift or protocol-buffer input file format implementation yet that can share code with SequenceFileInputFormat?  Let&apos;s not refactor until we have these.&lt;/p&gt;</comment>
                            <comment id="12631184" author="wyckoff" created="Mon, 15 Sep 2008 23:22:36 +0000"  >&lt;p&gt;This patch implements: FlatFileDeserializerRecordReader (and input format), which reads rows of any kind of data using a Deserializer that is given in the JobConf.&lt;/p&gt;

&lt;p&gt;For the current test case, I created a simple deserializer for \n separated plain text as a thin wrapper around LineRecordReader.LineReader to show what LineRecordReader would look like using FlatFileDeserializerRecordReader.&lt;/p&gt;

&lt;p&gt;One thing is this is my first foray into Java generics, so I would appreciate an experienced generics person looking at the code.&lt;/p&gt;

&lt;p&gt;&amp;#8211; pete&lt;/p&gt;

&lt;p&gt;I want to also implement a thrift or record io test case.&lt;/p&gt;</comment>
                            <comment id="12631187" author="wyckoff" created="Mon, 15 Sep 2008 23:26:38 +0000"  >
&lt;p&gt;Should also mention we could put this in contrib as it is self contained.&lt;/p&gt;</comment>
                            <comment id="12631544" author="cutting" created="Tue, 16 Sep 2008 20:52:58 +0000"  >&lt;p&gt;Please don&apos;t edit descriptions.  It&apos;s very difficult to tell what&apos;s changed.  The description should describe the problem.  The discussion below should present solutions.  Editing descriptions and comments makes it very hard to follow an issue.  This is discussed in the &quot;Jira Guidlines&quot; section of &lt;a href=&quot;http://wiki.apache.org/hadoop/HowToContribute&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/hadoop/HowToContribute&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="12631555" author="wyckoff" created="Tue, 16 Sep 2008 21:18:28 +0000"  >&lt;p&gt;reverting to original description &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="12631913" author="wyckoff" created="Wed, 17 Sep 2008 20:12:16 +0000"  >&lt;p&gt;proposal (which does not touch any existing code):&lt;/p&gt;

&lt;p&gt;1. extend Deserializer with an interface that requires returning the actual type being deserialized&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;&quot;&gt;&lt;b&gt;ParameterizedDeserializer.java&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;interface&lt;/span&gt; ParameterizedDeserializer&amp;lt;T&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; Deserializer&amp;lt;T&amp;gt; {
  &lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;&amp;lt;? &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; T&amp;gt; getRealClass() ;
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;2. create a Serialization implementation which gets the Serializer/Deserializer from the JobConf - e.g.,&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
   &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; ParameterizedDeserializer&amp;lt;R&amp;gt; getDeserializer(&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;&amp;lt;R&amp;gt; c) {                                                                                                                                        
     &lt;span class=&quot;code-comment&quot;&gt;// ignore c. doesn&apos;t matter, it is coming from the configuration                                                                                                                                        
&lt;/span&gt;      &lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;&amp;lt;? &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; ParameterizedDeserializer&amp;gt; t = conf.getClass(&lt;span class=&quot;code-quote&quot;&gt;&quot;mapred.input.io.deserializer&quot;&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, ParameterizedDeserializer.class);                                                                      
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; ReflectionUtils.newInstance(t, conf);                                                                                                                                                           
    } 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;3. Parameterized deserializers will (typically) get the specific class (? extends T - e.g., T= Record) they are implementing from the JobConf. e.g.,&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.recordClass = conf.getClass(&lt;span class=&quot;code-quote&quot;&gt;&quot;mapred.input.io.record_class&quot;&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, Record.class);                                                                                                                   
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;4. RecordReader.getValueClass looks like:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; R createValue() {                                                                                                                                                                     
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; (R)ReflectionUtils.newInstance(deserializer.getRealClass(),conf);                                                                                                                                              
  }                    
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;5. Setting up the JobConf:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
      job.setClass(&lt;span class=&quot;code-quote&quot;&gt;&quot;mapred.input.io.deserializer&quot;&lt;/span&gt;, .serializer.RecordIOSerialization.RecordIODeserializer.class, serializer.ParameterizedDeserializer.class);          
                                                                                                                                                                                                             
      &lt;span class=&quot;code-comment&quot;&gt;// Set &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; so the RecordIO Deserializer knows the specific Record class in the file                                                                                                                   
&lt;/span&gt;      job.setClass(&lt;span class=&quot;code-quote&quot;&gt;&quot;mapred.input.io.recordio_class&quot;&lt;/span&gt;, FlatFileDeserializerTestObj.class, record.Record.class);             
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;These classes could all go into a contrib directory devoted to contributing Serialization implementations.  Or it could be in core and mapred.&lt;/p&gt;

&lt;p&gt;Issues - why not get the  deserialization specific class in Serialization.getDeserializer (and implement getRealClass in this Serialization implementation - no need for any new interface) and pass that in to any normal Deserializer?  This would make things more uniform and also mean the Deserializer is any old deserializer.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;&amp;lt;? &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; R&amp;gt; realClass = conf.getClass(&lt;span class=&quot;code-quote&quot;&gt;&quot;mapred.input.io.deserializer.class&quot;&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;&amp;lt;R&amp;gt;);                                                                                                                   
&lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; ReflectionUtils.newInstance(conf.getClass(&lt;span class=&quot;code-quote&quot;&gt;&quot;mapred.input.deserializer&quot;&lt;/span&gt;,&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;,Deserializer.class));
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;And then we can construct an instance of realClass and pass that into any Deserializer.deserialize(T t).&lt;/p&gt;

&lt;p&gt;I am just learning generics and it doesn&apos;t seem conf.getClass(&quot;mapred.input.io.deserializer.class&quot;, null, Class&amp;lt;R&amp;gt;);  is possible because it doesn&apos;t accept Class&amp;lt;R&amp;gt;. It wants something more like Record.class, forcing us into doing this in the deserizlier.&lt;/p&gt;
</comment>
                            <comment id="12631938" author="owen.omalley" created="Wed, 17 Sep 2008 20:42:35 +0000"  >&lt;p&gt;I&apos;ve lost the motivation for this. It complicates the public interfaces a lot and doesn&apos;t have any payback.&lt;/p&gt;

&lt;p&gt;In our experience, given a file format, the code is pretty independent, but it is tied to the fragment splitting. &lt;/p&gt;

&lt;p&gt;Is the goal of this jira to:&lt;br/&gt;
  1. Make a generic / self-detecting format?&lt;br/&gt;
  2. A generic file format?&lt;/p&gt;

&lt;p&gt;In either case, changes to the serialization framework seems like serious overkill.&lt;/p&gt;</comment>
                            <comment id="12632058" author="jsensarma" created="Thu, 18 Sep 2008 02:11:17 +0000"  >&lt;p&gt;Hi Owen - the motivation was based on different families of binary (or even non binary) data embedded within flat files (by which i mean they are unsplittable and not self-describing (except for compression).&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;We should be able to write one concrete implementation that covers no-splits and compression related code&lt;/li&gt;
	&lt;li&gt;One should be able to plug in different deserializers for different binary formats&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The desire was that once this is written out - different deserializers can be plugged in easily. In that sense - this does not follow the general pattern that you observed of having to write custom code to deal with splitting (since there&apos;s no splitting here). Existing interfaces should not have to be changed (although things got pretty complicated in the intermediate discussion) - and i don&apos;t think they are although i am going to send back feedback on the code separately. The code should be really simple i would think.&lt;/p&gt;

&lt;p&gt;Do you think this is a reasonable thing to add?&lt;/p&gt;</comment>
                            <comment id="12632067" author="wyckoff" created="Thu, 18 Sep 2008 02:50:30 +0000"  >&lt;blockquote&gt;&lt;p&gt;In either case, changes to the serialization framework seems like serious overkill.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;you are right - I don&apos;t know why I went that direction. It should be exactly the oppostite of the way I coded it up.&lt;/p&gt;

&lt;p&gt;All one needs is some way of getting SerializationContext information (to instantiate the right Serialization Object and then the actual subclass we want to deserialize; e.g., Record/MyRecordObj). &lt;span class=&quot;error&quot;&gt;&amp;#91;this was called RowSource in joy&amp;#39;s code example&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;And then a simple record reader that uses that info to instantiate a deserializer and done.&lt;/p&gt;

&lt;p&gt;No changes to the serialization framework.&lt;/p&gt;

&lt;p&gt;I actually have that with unit tests and just need to clean up the documentation and such.&lt;/p&gt;

&lt;p&gt;&amp;#8211; pete&lt;/p&gt;</comment>
                            <comment id="12632072" author="wyckoff" created="Thu, 18 Sep 2008 03:09:37 +0000"  >&lt;p&gt;this is all this is - don&apos;t know why i went the other way &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="12632089" author="wyckoff" created="Thu, 18 Sep 2008 04:46:22 +0000"  >&lt;p&gt;Here&apos;s the simple patch and in contrib/serialization/readers. No build file with this yet as will coordinate with Tom White on that.&lt;/p&gt;

&lt;p&gt;Although the unit test is only for Java now, I did have it with Thrift and RecordIO, but since neither of those are checked in yet, i didn&apos;t include those tests.&lt;/p&gt;
</comment>
                            <comment id="12632217" author="tomwhite" created="Thu, 18 Sep 2008 14:03:19 +0000"  >&lt;p&gt;A few comments:&lt;/p&gt;

&lt;p&gt;Could the types be called FlatFileInputFormat and FlatFileRecordReader?&lt;/p&gt;

&lt;p&gt;Is a SerializationContext class needed? The Serialization can be got from the SerializationFactory. It just needs to know the base class (Writable, TBase etc). A second configuration parameter is needed to specify the concrete class, but I don&apos;t see why the FlatFileDeserializerRecordReader can&apos;t just get these two classes from the Configuration itself.&lt;/p&gt;

&lt;p&gt;Can the classes go in the org.apache.hadoop.contrib.serialization.mapred package to echo the main mapred package? When &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-1230&quot; title=&quot;Replace parameters with context objects in Mapper, Reducer, Partitioner, InputFormat, and OutputFormat classes&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-1230&quot;&gt;&lt;del&gt;HADOOP-1230&lt;/del&gt;&lt;/a&gt; is done an equivalent could then go in the mapreduce package.&lt;/p&gt;

&lt;p&gt;I agree it would be good to have tests for Writable, Java Serialization and Thrift to test the abstraction.&lt;/p&gt;

&lt;p&gt;Shouldn&apos;t keys be file offsets, similar to TextInputFormat? The row numbers you have are actually the row number within the split, which might be confusing (and they&apos;re not unique per file).&lt;/p&gt;</comment>
                            <comment id="12632309" author="wyckoff" created="Thu, 18 Sep 2008 17:43:56 +0000"  >&lt;blockquote&gt;&lt;p&gt;Could the types be called FlatFileInputFormat and FlatFileRecordReader?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, better names.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Is a SerializationContext class needed?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;If the Serialization is in contrib, one would need to use ReflectionUtils to instantiate it and it wouldn&apos;t be in any Factory, would it?  So, in this case, it needs to know the name of the Class to instantiate it, no?  &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;an&apos;t just get these two classes from the Configuration itself.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;wanted to make it extensible so it could some from the configuration or maybe some place else - the name of the file or some external store or something depending on the application. Of course, in that case, one could argue a higher level is setting that up anyway, so why don&apos;t they just do the lookup and store the info in the configuration. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Shouldn&apos;t keys be file offsets, similar to TextInputFormat? The row numbers you have are actually the row number within the split, which might be confusing (and they&apos;re not unique per file).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Are the file offsets useful anywhere?  Maybe we should just always return the same instance of some dummy Writable for performance if the key isn&apos;t used anyway??&lt;/p&gt;</comment>
                            <comment id="12632451" author="jsensarma" created="Thu, 18 Sep 2008 23:41:10 +0000"  >&lt;p&gt;couple of comments on the code:&lt;/p&gt;

&lt;p&gt;SerializationContext&amp;lt;R&amp;gt; sinfo = (SerializationContext&amp;lt;R&amp;gt;)ReflectionUtils.newInstance(sinfoClass, conf);&lt;br/&gt;
sinfo.setConf(conf);&lt;/p&gt;

&lt;p&gt;the setConf call is redundant since SerializationContext is configurable&lt;/p&gt;

&lt;p&gt;key.set(rnum++);&lt;br/&gt;
if (key == null)&lt;br/&gt;
    key = createKey();&lt;/p&gt;

&lt;p&gt;switch order? (or maybe the createKey()/createValue() is not required?)&lt;/p&gt;

&lt;p&gt;otherwise looks good.&lt;/p&gt;

&lt;p&gt;wrt some of Tom&apos;s comments:&lt;/p&gt;

&lt;p&gt;&amp;gt; The row numbers you have are actually the row number within the split, which might be confusing&lt;br/&gt;
the inputformat is not splittable - so we are safe here&lt;/p&gt;

&lt;p&gt;&amp;gt; Is a SerializationContext class needed? &lt;/p&gt;

&lt;p&gt;Very much so. Let me walk through the Hive use case:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Hive knows the deserialization class for each file. However - it knows this through metadata about the &lt;em&gt;file&lt;/em&gt;.  (The file belongs to a table that has some metadata). This metadata is passed to mappers through the configuration.&lt;/li&gt;
	&lt;li&gt;In this case the mapping is not from a class -&amp;gt; deserializer but from a file -&amp;gt; deserializer - and the ability to bootstrap the serialization factory from the configuration is critical (the configuration has both the file name and the metadata about the file name)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;This also seems to be the hadoop style of doing things (all implementations can be configurable) - and i think if it covers the hive case - it would help others as well. In fact - i think we should try to make this (configurable serialization factory pattern) a more fundamental part of the infrastructure. it seems more general than the class-&amp;gt;serialization way of bootstrapping (de)serialization.&lt;/p&gt;





</comment>
                            <comment id="12632475" author="wyckoff" created="Fri, 19 Sep 2008 00:54:25 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/MAPREDUCE-376&quot; title=&quot;Add serialization for Thrift&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAPREDUCE-376&quot;&gt;&lt;del&gt;HADOOP-3787&lt;/del&gt;&lt;/a&gt; includes the build file changes and such for creating src/contrib/serialization, so will need to wait for its commit.&lt;/p&gt;
</comment>
                            <comment id="12632501" author="owen.omalley" created="Fri, 19 Sep 2008 04:06:56 +0000"  >&lt;p&gt;I&apos;m still not convinced about the utility of this class outside of Hive. What is the advantage of storing the data this way?&lt;br/&gt;
If you put it in a sequence file or t-file, a single bug in the serialization code for the application type doesn&apos;t destroy&lt;br/&gt;
your entire file. With this format, that is exactly what will happen. Furthermore, since the types have to be configured,&lt;br/&gt;
you can&apos;t use multiple ones in different contexts.&lt;/p&gt;

&lt;p&gt;Maybe we should just put this into Hive?&lt;/p&gt;</comment>
                            <comment id="12632529" author="jsensarma" created="Fri, 19 Sep 2008 05:59:33 +0000"  >&lt;p&gt;yes - given that this has no dependency on core hadoop now - i really don&apos;t care - we can put this into Hive. The generic ThriftDeserializer is trivial - we could duplicate the code for now and then remove it once 3787 provides those classes as well.&lt;/p&gt;

&lt;p&gt;btw - we also don&apos;t store data in this manner. agree with all your observations. however &lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;this requested originated from outside Hive/Facebook. I get the impression (perhaps wrong) that quite a few people just dump thrift logs into a flat file (just like people dump apache logs into a flat file). This is also because Thrift does not have (so far) a good framed file format.&lt;/li&gt;
	&lt;li&gt;the same counter argument can be made for TextFileInputFormat. The general observation is that data originates outside the hadoop ecosystem and the general format it originates in is flat files. We should strive the easiest way to absorb this data and transform it into a better one (like Sequencefile).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;That is the general effort with Hive at least. We expect users to create temporary tables by pointing to flat files. And then quickly do some transformations (using sql and potentially scripts) and load it into tables in sequencefile (like) format (for longer term storage).  Being able to point to thrift flat files(and potentially other binary files)  is part of the data integration story.&lt;/p&gt;

&lt;p&gt;&amp;gt; Furthermore, since the types have to be configured, you can&apos;t use multiple ones in different contexts. &lt;/p&gt;

&lt;p&gt;not sure what u mean - but this is not true. the deserializer is obtained from a combination of file name and file name-&amp;gt;deserializer metadata from an external source. Different files can be read using different deserializers and then operated on in the same map-reduce program (the application logic has logic to deal with different classes based on the file name).  we will only be too happy to demonstrate a join of two different thrift classes (in different files/tables) using Hive and a generic flat file reader like this.&lt;/p&gt;</comment>
                            <comment id="12632752" author="wyckoff" created="Fri, 19 Sep 2008 17:36:31 +0000"  >&lt;blockquote&gt;&lt;p&gt;I&apos;m still not convinced about the utility of this class outside of Hive. What is the advantage of storing the data this way?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;1. You don&apos;t need a loader.  &lt;br/&gt;
2. Tools outside of hadoop can use the data - python, perl, c++, ...&lt;br/&gt;
3. There are other file formats that are splittable and self or non self-describing. Hadoop is generally pretty pluggable, but not at the file level. Would be nice to have generic file interfaces that one can implement to get &lt;b&gt;First Class&lt;/b&gt; hadoop treatment for any file format.&lt;/p&gt;

&lt;p&gt;To be clear, Hive writes and reads binary data to sequence files only now. We load all binary data into sequence files.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;i really don&apos;t care - we can put this into Hive. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;-1&lt;/p&gt;

&lt;p&gt;This is a general FlatFileRecordReader - &lt;a href=&quot;https://issues.apache.org/jira/browse/MAPREDUCE-252&quot; title=&quot;Create an InputFormat for reading lines of text as Java Strings&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAPREDUCE-252&quot;&gt;&lt;del&gt;HADOOP-3566&lt;/del&gt;&lt;/a&gt; seems to be a non-general version of this? (with the issue of that being &amp;lt;String, Void&amp;gt;)&lt;/p&gt;

&lt;p&gt;And note my intention is to put this in contrib/serialization&lt;/p&gt;



</comment>
                            <comment id="12632760" author="wyckoff" created="Fri, 19 Sep 2008 18:28:48 +0000"  >&lt;blockquote&gt;&lt;p&gt;And note my intention is to put this in contrib/serialization&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sorry, I meant. my intention was (not is) to put this in contrib/serialization, but if there is objection, i can change the patch to contrib/hive.&lt;/p&gt;
</comment>
                            <comment id="12632806" author="wyckoff" created="Fri, 19 Sep 2008 20:26:13 +0000"  >&lt;p&gt;RE: FlatFileRecordReader&apos;s signature.&lt;/p&gt;

&lt;p&gt;What would the implications be of changing the signature to &amp;lt;T, Void&amp;gt; ? Owen points out on &lt;a href=&quot;https://issues.apache.org/jira/browse/MAPREDUCE-252&quot; title=&quot;Create an InputFormat for reading lines of text as Java Strings&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAPREDUCE-252&quot;&gt;&lt;del&gt;HADOOP-3566&lt;/del&gt;&lt;/a&gt; there can be benefits to this viz sorting but that JIRA is for Strings, whereas here T could be anything.&lt;/p&gt;

&lt;p&gt;(Assuming for a moment that &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-1230&quot; title=&quot;Replace parameters with context objects in Mapper, Reducer, Partitioner, InputFormat, and OutputFormat classes&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-1230&quot;&gt;&lt;del&gt;HADOOP-1230&lt;/del&gt;&lt;/a&gt; is implemented. Now it would be &amp;lt;RowContainer&amp;lt;T&amp;gt;, Void&amp;gt;)&lt;/p&gt;

&lt;p&gt;thanks, pete&lt;/p&gt;</comment>
                            <comment id="12633082" author="wyckoff" created="Sun, 21 Sep 2008 17:33:28 +0000"  >&lt;p&gt;if there are implications, why not make the signature &amp;lt;Void, T&amp;gt; and when someone wants the sorting, have them use the InverseMapper instead of the IdentityMapper?&lt;/p&gt;</comment>
                            <comment id="12633566" author="wyckoff" created="Mon, 22 Sep 2008 23:46:13 +0000"  >&lt;p&gt;This is what &lt;a href=&quot;https://issues.apache.org/jira/browse/MAPREDUCE-252&quot; title=&quot;Create an InputFormat for reading lines of text as Java Strings&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAPREDUCE-252&quot;&gt;&lt;del&gt;HADOOP-3566&lt;/del&gt;&lt;/a&gt; looks like as an instance of a FlatFileRecordReader (with signature &amp;lt;Void, String&amp;gt;, not &amp;lt;String, Void&amp;gt;).  This assumes there is a StringSerialization implementation (based on LineRecordReader) and that &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-1230&quot; title=&quot;Replace parameters with context objects in Mapper, Reducer, Partitioner, InputFormat, and OutputFormat classes&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-1230&quot;&gt;&lt;del&gt;HADOOP-1230&lt;/del&gt;&lt;/a&gt; is implemented. But, it should hopefully demonstrate that FlatFileRecordReader can be used for non binary records.  Although,  without this, it can still be be used for anything that implements the Serialization interface.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;&quot;&gt;&lt;b&gt;StringInputFormat.java&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; class StringInputFormat &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; FileInputFormat&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Void&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;implements&lt;/span&gt; JobConfigurable {                                                     
  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; CompressionCodecFactory compressionCodecs = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;                                                                                           
                                                                                                                                                      
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void configure(JobConf conf) {                                                                                                               
    compressionCodecs = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; CompressionCodecFactory(conf);                                                                                            
  }                                                                                                                                                   
                                                                                                                                                      
  &lt;span class=&quot;code-keyword&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; isSplittable(FileSystem fs, Path file) {                                                                                          
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; compressionCodecs.getCodec(file) == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;                                                                     
  }                                                                                                                                                   
                                                                                                                                                      
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; RecordReader&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Void&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; getRecordReader(InputSplit split,                                                                                 
                                                    JobConf job, Reporter reporter)                                                                   
    &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {                                                                                                                              
                                                                                                                                                      
    reporter.setStatus(split.toString());                                                                                                             
                                                                                                                                                      
    &lt;span class=&quot;code-comment&quot;&gt;//                                                                                                                                                
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;// Set &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; so the SerializerFromConf can lookup our deserializer.                                                                                
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;//                                                                                                                                                
&lt;/span&gt;    job.setClass(FlatFileRecordReader.SerializationContextFromConf.SerializationImplKey,                                                              
                 org.apache.hadoop.contrib.serialization.string.StringSerialization.class,                                                            
                 org.apache.hadoop.io.Serialization.class);                                                                                           
                                                                                                                                                      
    job.setClass(FlatFileRecordReader.SerializationContextFromConf.SerializationSubclassKey,                                                          
                 java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;.class, java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;.class);                                                                                     
                                                                                                                                                      
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; FlatFileRecordReader&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt;(job, (FileSplit) split);                                                                                  
  }                                                                                                                                                   
}                                                                                                                                                     
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12633822" author="cutting" created="Tue, 23 Sep 2008 17:47:15 +0000"  >&lt;p&gt;&amp;gt; my intention was to put this in contrib/serialization, but if there is objection, i can change the patch to contrib/hive.&lt;/p&gt;

&lt;p&gt;+1 I&apos;d rather not have contrib/serialization just become a grab-bag of io-related stuff.  If this is needed by Hive only, then it belongs in contrib/hive.  If we decide (subsequently, perhaps) that it has wide utility as a generic API for access to files in a variety of formats for a variety of applications, then perhaps it could be moved to mapred.  But that doesn&apos;t yet sound like the consensus, so contrib/hive is probably best for now.&lt;/p&gt;</comment>
                            <comment id="12633949" author="wyckoff" created="Tue, 23 Sep 2008 22:45:03 +0000"  >&lt;p&gt;namespaced into hive and also brought back the RowContainer so it will work without &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-1230&quot; title=&quot;Replace parameters with context objects in Mapper, Reducer, Partitioner, InputFormat, and OutputFormat classes&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-1230&quot;&gt;&lt;del&gt;HADOOP-1230&lt;/del&gt;&lt;/a&gt; being fixed.  &lt;/p&gt;

&lt;p&gt;The testcase uses JavaSerialization, WritableSerialization (Record) and ThriftSerialization.&lt;/p&gt;</comment>
                            <comment id="12634030" author="hadoopqa" created="Wed, 24 Sep 2008 05:54:01 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12390798/HADOOP-4065.2.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12390798/HADOOP-4065.2.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision 698385.&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 9 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    +1 findbugs.  The patch does not introduce any new Findbugs warnings.&lt;/p&gt;

&lt;p&gt;    +1 core tests.  The patch passed core unit tests.&lt;/p&gt;

&lt;p&gt;    -1 contrib tests.  The patch failed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3358/testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3358/testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3358/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3358/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle results: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3358/artifact/trunk/build/test/checkstyle-errors.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3358/artifact/trunk/build/test/checkstyle-errors.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3358/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3358/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="12634337" author="wyckoff" created="Wed, 24 Sep 2008 23:03:52 +0000"  >&lt;p&gt;hudson -1 contrib i think this wasn&apos;t due to this patch.&lt;/p&gt;</comment>
                            <comment id="12634338" author="wyckoff" created="Wed, 24 Sep 2008 23:04:08 +0000"  >&lt;p&gt;re-submitting for hudson.&lt;/p&gt;</comment>
                            <comment id="12634394" author="hadoopqa" created="Thu, 25 Sep 2008 07:20:14 +0000"  >&lt;p&gt;+1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12390798/HADOOP-4065.2.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12390798/HADOOP-4065.2.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision 698721.&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 9 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    +1 findbugs.  The patch does not introduce any new Findbugs warnings.&lt;/p&gt;

&lt;p&gt;    +1 Eclipse classpath. The patch retains Eclipse classpath integrity.&lt;/p&gt;

&lt;p&gt;    +1 core tests.  The patch passed core unit tests.&lt;/p&gt;

&lt;p&gt;    +1 contrib tests.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3367/testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3367/testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3367/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3367/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle results: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3367/artifact/trunk/build/test/checkstyle-errors.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3367/artifact/trunk/build/test/checkstyle-errors.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3367/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3367/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="12642527" author="jsensarma" created="Fri, 24 Oct 2008 19:37:16 +0000"  >&lt;p&gt;+1. &lt;/p&gt;</comment>
                            <comment id="12647312" author="athusoo" created="Thu, 13 Nov 2008 15:01:20 +0000"  >&lt;p&gt;I think this patch is already commited. Is there anything else needed on this. Can we mark this as resolved?&lt;/p&gt;</comment>
                            <comment id="12648059" author="wyckoff" created="Mon, 17 Nov 2008 01:30:47 +0000"  >&lt;p&gt;yes, already committed.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12403645">HIVE-20</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12404460">HADOOP-4192</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12400531">MAPREDUCE-376</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12390331" name="FlatFileReader.java" size="10334" author="wyckoff" created="Thu, 18 Sep 2008 03:09:37 +0000"/>
                            <attachment id="12389715" name="HADOOP-4065.0.txt" size="13182" author="wyckoff" created="Tue, 9 Sep 2008 01:35:34 +0000"/>
                            <attachment id="12390340" name="HADOOP-4065.1.txt" size="18429" author="wyckoff" created="Thu, 18 Sep 2008 04:46:22 +0000"/>
                            <attachment id="12390145" name="HADOOP-4065.1.txt" size="16198" author="wyckoff" created="Mon, 15 Sep 2008 23:22:36 +0000"/>
                            <attachment id="12390798" name="HADOOP-4065.2.txt" size="34840" author="wyckoff" created="Tue, 23 Sep 2008 22:45:03 +0000"/>
                            <attachment id="12389716" name="ThriftFlatFile.java" size="2515" author="wyckoff" created="Tue, 9 Sep 2008 01:42:37 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>6.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 4 Sep 2008 22:18:02 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>73827</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 3 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0iuin:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>108038</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>