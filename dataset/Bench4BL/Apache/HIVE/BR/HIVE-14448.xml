<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 02 05:10:58 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HIVE-14448/HIVE-14448.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HIVE-14448] Queries with predicate fail when ETL split strategy is chosen for ACID tables</title>
                <link>https://issues.apache.org/jira/browse/HIVE-14448</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;When ETL split strategy is applied to ACID tables with predicate pushdown (SARG enabled), split generation fails for ACID. This bug will be usually exposed when working with data at scale, because in most otherwise cases only BI split strategy is chosen. My guess is that this is happening because the correct readerSchema is not being picked up when we try to extract SARG column names.&lt;/p&gt;

&lt;p&gt;Quickest way to reproduce is to add the following unit test to ql/src/test/org/apache/hadoop/hive/ql/TestTxnCommands2.java&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-style: solid;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;border-bottom-style: solid;&quot;&gt;&lt;b&gt;ql/src/test/org/apache/hadoop/hive/ql/TestTxnCommands2.java&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 @Test
&#8194;&#8194;&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void testETLSplitStrategyForACID() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; Exception {
&#8194;&#8194;&#8194;&#8194;hiveConf.setVar(HiveConf.ConfVars.HIVE_ORC_SPLIT_STRATEGY, &lt;span class=&quot;code-quote&quot;&gt;&quot;ETL&quot;&lt;/span&gt;);
&#8194;&#8194;&#8194;&#8194;hiveConf.setBoolVar(HiveConf.ConfVars.HIVEOPTINDEXFILTER, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;);
&#8194;&#8194;&#8194;&#8194;runStatementOnDriver(&lt;span class=&quot;code-quote&quot;&gt;&quot;insert into &quot;&lt;/span&gt; + Table.ACIDTBL + &lt;span class=&quot;code-quote&quot;&gt;&quot; values(1,2)&quot;&lt;/span&gt;);
&#8194;&#8194;&#8194;&#8194;runStatementOnDriver(&lt;span class=&quot;code-quote&quot;&gt;&quot;alter table &quot;&lt;/span&gt; + Table.ACIDTBL + &lt;span class=&quot;code-quote&quot;&gt;&quot; compact &apos;MAJOR&apos;&quot;&lt;/span&gt;);
&#8194;&#8194;&#8194;&#8194;runWorker(hiveConf);
&#8194;&#8194;&#8194;&#8194;List&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; rs = runStatementOnDriver(&lt;span class=&quot;code-quote&quot;&gt;&quot;select * from &quot;&lt;/span&gt; +&#8194;&#8194;Table.ACIDTBL&#8194;&#8194;+ &lt;span class=&quot;code-quote&quot;&gt;&quot; where a = 1&quot;&lt;/span&gt;);
&#8194;&#8194;&#8194;&#8194;&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;[][] resultData = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;[][] {{1,2}};
&#8194;&#8194;&#8194;&#8194;Assert.assertEquals(stringifyValues(resultData), rs);
&#8194;&#8194;}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Back-trace for this failed test is as follows:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
exec.Task: Job Submission failed with exception &apos;java.lang.RuntimeException(ORC split generation failed with exception: java.lang.NegativeArraySizeException)&apos;
java.lang.RuntimeException: ORC split generation failed with exception: java.lang.NegativeArraySizeException
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.generateSplitsInfo(OrcInputFormat.java:1570)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getSplits(OrcInputFormat.java:1656)
	at org.apache.hadoop.hive.ql.io.HiveInputFormat.addSplitsForGroup(HiveInputFormat.java:370)
	at org.apache.hadoop.hive.ql.io.HiveInputFormat.getSplits(HiveInputFormat.java:488)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeOldSplits(JobSubmitter.java:329)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:321)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:197)
	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1297)
	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1294)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1656)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1294)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:557)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1656)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:557)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:548)
	at org.apache.hadoop.hive.ql.exec.mr.ExecDriver.execute(ExecDriver.java:417)
	at org.apache.hadoop.hive.ql.exec.mr.MapRedTask.execute(MapRedTask.java:141)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:197)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:100)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1962)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1653)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1389)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1131)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1119)
	at org.apache.hadoop.hive.ql.TestTxnCommands2.runStatementOnDriver(TestTxnCommands2.java:1292)
	at org.apache.hadoop.hive.ql.TestTxnCommands2.testETLSplitStrategyForACID(TestTxnCommands2.java:280)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:254)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:149)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:200)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:153)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:103)
Caused by: java.util.concurrent.ExecutionException: java.lang.NegativeArraySizeException
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.generateSplitsInfo(OrcInputFormat.java:1560)
	... 57 more
Caused by: java.lang.NegativeArraySizeException
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getSargColumnNames(OrcInputFormat.java:378)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.extractNeededColNames(OrcInputFormat.java:444)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.extractNeededColNames(OrcInputFormat.java:439)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.access$2800(OrcInputFormat.java:146)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$SplitGenerator.callInternal(OrcInputFormat.java:1274)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$SplitGenerator.access$2600(OrcInputFormat.java:1068)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$SplitGenerator$1.run(OrcInputFormat.java:1248)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$SplitGenerator$1.run(OrcInputFormat.java:1245)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1656)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$SplitGenerator.call(OrcInputFormat.java:1245)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$ETLSplitStrategy.runGetSplitsSync(OrcInputFormat.java:883)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$ETLSplitStrategy.access$1300(OrcInputFormat.java:700)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$ETLSplitStrategy$1.run(OrcInputFormat.java:857)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$ETLSplitStrategy$1.run(OrcInputFormat.java:854)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1656)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$ETLSplitStrategy.call(OrcInputFormat.java:854)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$ETLSplitStrategy.call(OrcInputFormat.java:700)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12995389">HIVE-14448</key>
            <summary>Queries with predicate fail when ETL split strategy is chosen for ACID tables</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="mmccline">Matt McCline</assignee>
                                    <reporter username="saketj">Saket Saurabh</reporter>
                        <labels>
                    </labels>
                <created>Fri, 5 Aug 2016 23:50:04 +0000</created>
                <updated>Mon, 22 Aug 2016 23:06:18 +0000</updated>
                            <resolved>Sat, 13 Aug 2016 06:24:05 +0000</resolved>
                                    <version>2.2.0</version>
                                    <fixVersion>2.2.0</fixVersion>
                    <fixVersion>2.1.1</fixVersion>
                                    <component>Transactions</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="15412409" author="sershe" created="Mon, 8 Aug 2016 20:28:56 +0000"  >&lt;p&gt;Was changed as part of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-14310&quot; title=&quot;ORC schema evolution should not completely disable PPD&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-14310&quot;&gt;&lt;del&gt;HIVE-14310&lt;/del&gt;&lt;/a&gt;. The offset calculation takes into account ACID, however in this case the code now passes the reader types instead of file types; the reader types for ACID are different from file types and don&apos;t include ACID structures, so the root column is invalid for them. &lt;br/&gt;
There&apos;s no schema evolution involved.  However, what if there ACID and also schema evolution? We could pass isOriginal as true if we pass readerTypes, but that seems hacky.&lt;/p&gt;</comment>
                            <comment id="15412453" author="sershe" created="Mon, 8 Aug 2016 20:56:45 +0000"  >&lt;p&gt;Let&apos;s see if this works... as per comment in getSargColumnNames that I added some time ago after understanding how it works, that code is brittle... oh well.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=prasanth_j&quot; class=&quot;user-hover&quot; rel=&quot;prasanth_j&quot;&gt;Prasanth Jayachandran&lt;/a&gt; can you take a look?&lt;/p&gt;</comment>
                            <comment id="15412460" author="prasanth_j" created="Mon, 8 Aug 2016 21:02:01 +0000"  >&lt;p&gt;Mostly looks good. Can you add another test that evolves the schema and run queries on it? If schema is not evolved it will use readerSchema = fileSchema. &lt;/p&gt;</comment>
                            <comment id="15412479" author="sershe" created="Mon, 8 Aug 2016 21:11:12 +0000"  >&lt;p&gt;Hmm... you mean evolves the schema with ACID? In this case the schema is not evolved, yet the schemas (objects) are different as per the comment&lt;/p&gt;</comment>
                            <comment id="15412507" author="ekoifman" created="Mon, 8 Aug 2016 21:22:48 +0000"  >&lt;p&gt;Acid may involve files that represent delete events in which case it&apos;s just the metadata columns in the file - the user portion is NULL.  So you have different schema w/o evolution&lt;/p&gt;</comment>
                            <comment id="15412781" author="prasanth_j" created="Tue, 9 Aug 2016 01:12:49 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="15412791" author="sershe" created="Tue, 9 Aug 2016 01:18:38 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ekoifman&quot; class=&quot;user-hover&quot; rel=&quot;ekoifman&quot;&gt;Eugene Koifman&lt;/a&gt; the difference in this case is that fileSchema has the actual file schema, with acid cols and user portion, whereas readerSchema only has the user portion. So it would always be different (assuming the code passing this in is consistent...). See the test in the description that triggers this condition. &lt;/p&gt;</comment>
                            <comment id="15413948" author="sershe" created="Tue, 9 Aug 2016 18:20:04 +0000"  >&lt;p&gt;Forgot to submit patch... grr&lt;/p&gt;</comment>
                            <comment id="15414106" author="saketj" created="Tue, 9 Aug 2016 19:39:12 +0000"  >&lt;p&gt;While I was investigating test failures for some other scenarios, I realized that schema evolution also breaks when ETL strategy is chosen, which I believe might be related to this JIRA.  I think it would be good to add another test that evolves the schema, as &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=prasanth_j&quot; class=&quot;user-hover&quot; rel=&quot;prasanth_j&quot;&gt;Prasanth Jayachandran&lt;/a&gt; suggested.&lt;/p&gt;

&lt;p&gt;Even with the current patch, the following schema evolution test still fails with IndexOutOfBoundsException:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-style: solid;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;border-bottom-style: solid;&quot;&gt;&lt;b&gt;ql/src/test/org/apache/hadoop/hive/ql/TestTxnCommands2.java&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
@Test
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void testAcidWithSchemaEvolution() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; Exception {
    hiveConf.setVar(HiveConf.ConfVars.HIVE_ORC_SPLIT_STRATEGY, &lt;span class=&quot;code-quote&quot;&gt;&quot;ETL&quot;&lt;/span&gt;);
    &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; tblName = &lt;span class=&quot;code-quote&quot;&gt;&quot;acidTblWithSchemaEvol&quot;&lt;/span&gt;;
    runStatementOnDriver(&lt;span class=&quot;code-quote&quot;&gt;&quot;drop table &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; exists &quot;&lt;/span&gt; + tblName);
    runStatementOnDriver(&lt;span class=&quot;code-quote&quot;&gt;&quot;CREATE TABLE &quot;&lt;/span&gt; + tblName + &lt;span class=&quot;code-quote&quot;&gt;&quot;(a INT, b STRING) &quot;&lt;/span&gt; +
      &lt;span class=&quot;code-quote&quot;&gt;&quot; CLUSTERED BY(a) INTO 2 BUCKETS&quot;&lt;/span&gt; + &lt;span class=&quot;code-comment&quot;&gt;//currently ACID requires table to be bucketed
&lt;/span&gt;      &lt;span class=&quot;code-quote&quot;&gt;&quot; STORED AS ORC TBLPROPERTIES (&apos;transactional&apos;=&apos;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&apos;)&quot;&lt;/span&gt;);

    runStatementOnDriver(&lt;span class=&quot;code-quote&quot;&gt;&quot;INSERT INTO &quot;&lt;/span&gt; + tblName + &lt;span class=&quot;code-quote&quot;&gt;&quot; VALUES (1, &apos;foo&apos;), (2, &apos;bar&apos;)&quot;&lt;/span&gt;);

    &lt;span class=&quot;code-comment&quot;&gt;// Major compact to create a base that has ACID schema.
&lt;/span&gt;    runStatementOnDriver(&lt;span class=&quot;code-quote&quot;&gt;&quot;ALTER TABLE &quot;&lt;/span&gt; + tblName + &lt;span class=&quot;code-quote&quot;&gt;&quot; COMPACT &apos;MAJOR&apos;&quot;&lt;/span&gt;);
    runWorker(hiveConf);

    &lt;span class=&quot;code-comment&quot;&gt;// Alter table &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; perform schema evolution.
&lt;/span&gt;    runStatementOnDriver(&lt;span class=&quot;code-quote&quot;&gt;&quot;ALTER TABLE &quot;&lt;/span&gt; + tblName + &lt;span class=&quot;code-quote&quot;&gt;&quot; ADD COLUMNS(c &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;)&quot;&lt;/span&gt;);

    &lt;span class=&quot;code-comment&quot;&gt;// Validate there is an added NULL &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; column c.
&lt;/span&gt;    List&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; rs = runStatementOnDriver(&lt;span class=&quot;code-quote&quot;&gt;&quot;SELECT * FROM &quot;&lt;/span&gt; + tblName + &lt;span class=&quot;code-quote&quot;&gt;&quot; ORDER BY a&quot;&lt;/span&gt;);
    &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;[] expectedResult = { &lt;span class=&quot;code-quote&quot;&gt;&quot;1\tfoo\tNULL&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;2\tbar\tNULL&quot;&lt;/span&gt; };
    Assert.assertEquals(Arrays.asList(expectedResult), rs);
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here is the back-trace for the failed test:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
exec.Task: Job Submission failed with exception &apos;java.lang.RuntimeException(ORC split generation failed with exception: java.lang.IndexOutOfBoundsException: Index: 9, Size: 9)&apos;
java.lang.RuntimeException: ORC split generation failed with exception: java.lang.IndexOutOfBoundsException: Index: 9, Size: 9
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.generateSplitsInfo(OrcInputFormat.java:1576)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getSplits(OrcInputFormat.java:1662)
	at org.apache.hadoop.hive.ql.io.HiveInputFormat.addSplitsForGroup(HiveInputFormat.java:370)
	at org.apache.hadoop.hive.ql.io.HiveInputFormat.getSplits(HiveInputFormat.java:488)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeOldSplits(JobSubmitter.java:329)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:321)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:197)
	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1297)
	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1294)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1656)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1294)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:557)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1656)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:557)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:548)
	at org.apache.hadoop.hive.ql.exec.mr.ExecDriver.execute(ExecDriver.java:417)
	at org.apache.hadoop.hive.ql.exec.mr.MapRedTask.execute(MapRedTask.java:141)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:197)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:100)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1983)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1674)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1410)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1134)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1122)
	at org.apache.hadoop.hive.ql.TestTxnCommands2.runStatementOnDriver(TestTxnCommands2.java:1315)
	at org.apache.hadoop.hive.ql.TestTxnCommands2.testAcidWithSchemaEvolution(TestTxnCommands2.java:177)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:254)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:149)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:200)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:153)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:103)
Caused by: java.util.concurrent.ExecutionException: java.lang.IndexOutOfBoundsException: Index: 9, Size: 9
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.generateSplitsInfo(OrcInputFormat.java:1566)
	... 57 more
Caused by: java.lang.IndexOutOfBoundsException: Index: 9, Size: 9
	at java.util.ArrayList.rangeCheck(ArrayList.java:653)
	at java.util.ArrayList.get(ArrayList.java:429)
	at java.util.Collections$UnmodifiableList.get(Collections.java:1309)
	at org.apache.orc.impl.ReaderImpl.getRawDataSizeOfColumn(ReaderImpl.java:618)
	at org.apache.orc.impl.ReaderImpl.getRawDataSizeFromColIndices(ReaderImpl.java:611)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$SplitGenerator.computeProjectionSize(OrcInputFormat.java:1449)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$SplitGenerator.populateAndCacheStripeDetails(OrcInputFormat.java:1431)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$SplitGenerator.callInternal(OrcInputFormat.java:1268)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$SplitGenerator.access$2600(OrcInputFormat.java:1068)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$SplitGenerator$1.run(OrcInputFormat.java:1248)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$SplitGenerator$1.run(OrcInputFormat.java:1245)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1656)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$SplitGenerator.call(OrcInputFormat.java:1245)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$ETLSplitStrategy.runGetSplitsSync(OrcInputFormat.java:883)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$ETLSplitStrategy.access$1300(OrcInputFormat.java:700)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$ETLSplitStrategy$1.run(OrcInputFormat.java:857)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$ETLSplitStrategy$1.run(OrcInputFormat.java:854)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1656)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$ETLSplitStrategy.call(OrcInputFormat.java:854)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$ETLSplitStrategy.call(OrcInputFormat.java:700)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15414583" author="ekoifman" created="Wed, 10 Aug 2016 01:46:39 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sershe&quot; class=&quot;user-hover&quot; rel=&quot;sershe&quot;&gt;Sergey Shelukhin&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=prasanth_j&quot; class=&quot;user-hover&quot; rel=&quot;prasanth_j&quot;&gt;Prasanth Jayachandran&lt;/a&gt;, is the issue related to schema evolution something you can address here as well?  It&apos;s blocking some cases related to &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-14035&quot; title=&quot;Enable predicate pushdown to delta files created by ACID Transactions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-14035&quot;&gt;&lt;del&gt;HIVE-14035&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15414595" author="sershe" created="Wed, 10 Aug 2016 02:02:50 +0000"  >&lt;p&gt;Grrr... this code now is a total confusion. reader schema has 3 user cols but file schema has 6 acid and 2 user cols. The code that tries to map that to get fileIncluded basically creates some completely bogus mapping. I&apos;d like to read the code there more to clean up what is where and make it more explicit, rather than trying another band aid fix. I wonder why reader schema for ACID is like that; and if it should indeed be like that, one would need to check if SchemaEvolution class is correct there, and if it&apos;s being used correctly by split generation.&lt;/p&gt;</comment>
                            <comment id="15414611" author="ekoifman" created="Wed, 10 Aug 2016 02:39:17 +0000"  >&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mmccline&quot; class=&quot;user-hover&quot; rel=&quot;mmccline&quot;&gt;Matt McCline&lt;/a&gt;  Matt probably knows most about this&lt;/p&gt;</comment>
                            <comment id="15414674" author="hiveqa" created="Wed, 10 Aug 2016 04:17:22 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12822658/HIVE-14448.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12822658/HIVE-14448.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 1 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 4 failed/errored test(s), 10460 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestMsgBusConnection - did not produce a TEST-*.xml file
TestQueryLifeTimeHook - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_orc_llap_counters
org.apache.hive.jdbc.TestJdbcWithMiniHS2.testAddJarConstructorUnCaching
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/835/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/835/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/835/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/835/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-204-236-174-241.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-MASTER-Build-835/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-204-236-174-241.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-MASTER-Build-835/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12822658 - PreCommit-HIVE-MASTER-Build&lt;/p&gt;</comment>
                            <comment id="15415220" author="mmccline" created="Wed, 10 Aug 2016 12:47:05 +0000"  >&lt;p&gt;This is the area I was struggling with for &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-14214&quot; title=&quot;ORC Schema Evolution and Predicate Push Down do not work together (no rows returned)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-14214&quot;&gt;&lt;del&gt;HIVE-14214&lt;/del&gt;&lt;/a&gt;: ORC Schema Evolution and Predicate Push Down do not work together (no rows returned)&lt;br/&gt;
I&apos;ll take this over.&lt;/p&gt;</comment>
                            <comment id="15416077" author="mmccline" created="Wed, 10 Aug 2016 21:48:41 +0000"  >&lt;p&gt;Submitted new approach.&lt;/p&gt;</comment>
                            <comment id="15416108" author="sershe" created="Wed, 10 Aug 2016 22:07:14 +0000"  >&lt;p&gt;+1 pending tests&lt;/p&gt;</comment>
                            <comment id="15416890" author="hiveqa" created="Thu, 11 Aug 2016 08:46:24 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12823137/HIVE-14448.01.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12823137/HIVE-14448.01.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 1 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 13 failed/errored test(s), 10408 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestMsgBusConnection - did not produce a TEST-*.xml file
TestQueryLifeTimeHook - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_orc_llap_counters
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_explainuser_1
org.apache.hadoop.hive.ql.TestTxnCommands2.testAcidWithSchemaEvolution
org.apache.hadoop.hive.ql.TestTxnCommands2.testETLSplitStrategyForACID
org.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion2
org.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion3
org.apache.hadoop.hive.ql.TestTxnCommands2.testOriginalFileReaderWhenNonAcidConvertedToAcid
org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testVectorizationWithAcid
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderIncompleteDelta
org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.testRecordReaderNewBaseAndDelta
org.apache.hive.jdbc.TestJdbcWithMiniHS2.testAddJarConstructorUnCaching
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/849/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/849/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/849/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/849/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-204-236-174-241.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-MASTER-Build-849/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-204-236-174-241.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-MASTER-Build-849/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 13 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12823137 - PreCommit-HIVE-MASTER-Build&lt;/p&gt;</comment>
                            <comment id="15417743" author="sershe" created="Thu, 11 Aug 2016 18:49:41 +0000"  >&lt;p&gt;Test failures are related...&lt;/p&gt;</comment>
                            <comment id="15417970" author="ekoifman" created="Thu, 11 Aug 2016 21:30:55 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-14035&quot; title=&quot;Enable predicate pushdown to delta files created by ACID Transactions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-14035&quot;&gt;&lt;del&gt;HIVE-14035&lt;/del&gt;&lt;/a&gt; has TestTxnCommands2WithSplitUpdate.testOrcPPD() and testOrcNoPPD() both of which have a special case specifically because of this bug.  The special casing should be removed as part of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-14448&quot; title=&quot;Queries with predicate fail when ETL split strategy is chosen for ACID tables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-14448&quot;&gt;&lt;del&gt;HIVE-14448&lt;/del&gt;&lt;/a&gt; - it will also provide additional testing.&lt;/p&gt;</comment>
                            <comment id="15417973" author="mmccline" created="Thu, 11 Aug 2016 21:31:26 +0000"  >&lt;p&gt;Let&apos;s wait until a successful run before more code review.&lt;/p&gt;</comment>
                            <comment id="15418429" author="mmccline" created="Fri, 12 Aug 2016 06:47:51 +0000"  >&lt;p&gt;Baffling &amp;#8211; why didn&apos;t patch #2 build on Hive QA???&lt;/p&gt;</comment>
                            <comment id="15418438" author="mmccline" created="Fri, 12 Aug 2016 06:56:03 +0000"  >&lt;p&gt;Patch #3 ought to be #864&lt;/p&gt;</comment>
                            <comment id="15419112" author="hiveqa" created="Fri, 12 Aug 2016 16:53:26 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12823416/HIVE-14448.03.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12823416/HIVE-14448.03.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 1 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 7 failed/errored test(s), 10421 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestQueryLifeTimeHook - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_orc_llap_counters
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_explainuser_1
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_load_dyn_part1
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_tez_join_hash
org.apache.hive.hcatalog.listener.TestMsgBusConnection.testConnection
org.apache.hive.jdbc.TestJdbcWithMiniHS2.testAddJarConstructorUnCaching
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/864/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/864/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/864/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/864/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-204-236-174-241.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-MASTER-Build-864/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-204-236-174-241.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-MASTER-Build-864/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 7 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12823416 - PreCommit-HIVE-MASTER-Build&lt;/p&gt;</comment>
                            <comment id="15419291" author="mmccline" created="Fri, 12 Aug 2016 18:47:04 +0000"  >&lt;p&gt;Test failures are not related.  Ready for final code review &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sershe&quot; class=&quot;user-hover&quot; rel=&quot;sershe&quot;&gt;Sergey Shelukhin&lt;/a&gt;.  Thanks&lt;/p&gt;</comment>
                            <comment id="15419312" author="sershe" created="Fri, 12 Aug 2016 19:00:13 +0000"  >&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;+      // File included has ACID columns, so always pass true for isOriginal.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;What is the logic behind this? Original is used to determine root column IIRC... so if ACID always pretends to be original (which it isn&apos;t), causing rootColumn to become 0, this argument becomes useless... is it used for any other purpose? I wonder if these methods should just take root column at the top to avoid confusion.&lt;/p&gt;</comment>
                            <comment id="15419377" author="ekoifman" created="Fri, 12 Aug 2016 20:03:10 +0000"  >&lt;p&gt;usually &quot;isOriginal&quot; means that the base file in the split is from before the table was converted to acid.  This means that the file itself doesn&apos;t have any ACID meta columns and they need to be injected on the fly.&lt;/p&gt;</comment>
                            <comment id="15419386" author="mmccline" created="Fri, 12 Aug 2016 20:10:43 +0000"  >&lt;p&gt;Ok, more review comment changes.&lt;/p&gt;

&lt;p&gt;ALSO NOTE: For general style improvements there is &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-14354&quot; title=&quot;Cleanup ORC reader interfaces and redundant metadata objects&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-14354&quot;&gt;HIVE-14354&lt;/a&gt; &quot;Cleanup ORC reader interfaces and redundant metadata objects&quot;, too.&lt;/p&gt;</comment>
                            <comment id="15419694" author="sershe" created="Fri, 12 Aug 2016 23:44:01 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="15419697" author="mmccline" created="Fri, 12 Aug 2016 23:49:28 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sershe&quot; class=&quot;user-hover&quot; rel=&quot;sershe&quot;&gt;Sergey Shelukhin&lt;/a&gt; Thank you very much for your code reviewing.&lt;/p&gt;</comment>
                            <comment id="15419796" author="hiveqa" created="Sat, 13 Aug 2016 04:05:05 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12823528/HIVE-14448.04.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12823528/HIVE-14448.04.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 1 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 8 failed/errored test(s), 10470 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[index_auto_mult_tables_compact]
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_1]
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_2]
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[load_dyn_part1]
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[tez_join_hash]
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[transform_ppr1]
org.apache.hive.hcatalog.listener.TestMsgBusConnection.testConnection
org.apache.hive.jdbc.TestJdbcWithMiniHS2.testAddJarConstructorUnCaching
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/872/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/872/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/872/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-MASTER-Build/872/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-204-236-174-241.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-MASTER-Build-872/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-204-236-174-241.us-west-1.compute.amazonaws.com/logs/PreCommit-HIVE-MASTER-Build-872/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 8 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12823528 - PreCommit-HIVE-MASTER-Build&lt;/p&gt;</comment>
                            <comment id="15419818" author="mmccline" created="Sat, 13 Aug 2016 05:51:16 +0000"  >&lt;p&gt;Test failures are unrelated.&lt;/p&gt;</comment>
                            <comment id="15419826" author="mmccline" created="Sat, 13 Aug 2016 06:23:46 +0000"  >&lt;p&gt;Committed to master and branch-2.1&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12979916">HIVE-14035</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="12310040">
                    <name>Required</name>
                                                                <inwardlinks description="is required by">
                                        <issuelink>
            <issuekey id="12999046">HIVE-14607</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12823137" name="HIVE-14448.01.patch" size="4151" author="mmccline" created="Wed, 10 Aug 2016 21:47:57 +0000"/>
                            <attachment id="12823348" name="HIVE-14448.02.patch" size="4576" author="mmccline" created="Thu, 11 Aug 2016 21:30:59 +0000"/>
                            <attachment id="12823416" name="HIVE-14448.03.patch" size="4576" author="mmccline" created="Fri, 12 Aug 2016 06:50:46 +0000"/>
                            <attachment id="12823528" name="HIVE-14448.04.patch" size="4933" author="mmccline" created="Fri, 12 Aug 2016 20:11:14 +0000"/>
                            <attachment id="12822658" name="HIVE-14448.patch" size="4273" author="sershe" created="Mon, 8 Aug 2016 20:56:45 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 8 Aug 2016 20:28:56 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            15 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i31zr3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12335837</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>