<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 02 11:25:19 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HIVE-13432/HIVE-13432.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HIVE-13432] ACID ORC CompactorMR job throws java.lang.ArrayIndexOutOfBoundsException: 7</title>
                <link>https://issues.apache.org/jira/browse/HIVE-13432</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;After initiating HIVE ACID ORC table compaction, the CompactorMR job throws exception:&lt;/p&gt;

&lt;p&gt;Error: java.lang.ArrayIndexOutOfBoundsException: 7&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.TreeReaderFactory$StructTreeReader.&amp;lt;init&amp;gt;(TreeReaderFactory.java:1968)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.TreeReaderFactory.createTreeReader(TreeReaderFactory.java:2368)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.TreeReaderFactory$StructTreeReader.&amp;lt;init&amp;gt;(TreeReaderFactory.java:1969)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.TreeReaderFactory.createTreeReader(TreeReaderFactory.java:2368)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.RecordReaderFactory.createTreeReader(RecordReaderFactory.java:69)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl.&amp;lt;init&amp;gt;(RecordReaderImpl.java:202)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.rowsOptions(ReaderImpl.java:539)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger$ReaderPair.&amp;lt;init&amp;gt;(OrcRawRecordMerger.java:183)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.&amp;lt;init&amp;gt;(OrcRawRecordMerger.java:466)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRawReader(OrcInputFormat.java:1308)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:512)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:491)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1656)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)&lt;/p&gt;

&lt;p&gt;As a result, we see hadoop exception stack,&lt;/p&gt;

&lt;p&gt;297 failed with state FAILED due to: Task failed task_1458819387386_11297_m_000008&lt;br/&gt;
Job failed as tasks failed. failedMaps:1 failedReduces:0&lt;/p&gt;

&lt;p&gt;2016-04-06 11:30:57,891 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;dn209006-27&amp;#93;&lt;/span&gt;: mapreduce.Job (Job.java:monitorAndPrintJob(1392)) - Counters: 14&lt;br/&gt;
  Job Counters &lt;br/&gt;
    Failed map tasks=16&lt;br/&gt;
    Killed map tasks=7&lt;br/&gt;
    Launched map tasks=23&lt;br/&gt;
    Other local map tasks=13&lt;br/&gt;
    Data-local map tasks=6&lt;br/&gt;
    Rack-local map tasks=4&lt;br/&gt;
    Total time spent by all maps in occupied slots (ms)=412592&lt;br/&gt;
    Total time spent by all reduces in occupied slots (ms)=0&lt;br/&gt;
    Total time spent by all map tasks (ms)=206296&lt;br/&gt;
    Total vcore-seconds taken by all map tasks=206296&lt;br/&gt;
    Total megabyte-seconds taken by all map tasks=422494208&lt;br/&gt;
  Map-Reduce Framework&lt;br/&gt;
    CPU time spent (ms)=0&lt;br/&gt;
    Physical memory (bytes) snapshot=0&lt;br/&gt;
    Virtual memory (bytes) snapshot=0&lt;br/&gt;
2016-04-06 11:30:57,891 ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;dn209006-27&amp;#93;&lt;/span&gt;: compactor.Worker (Worker.java:run(176)) - Caught exception while trying to compact lqz.my_orc_acid_table.  Marking clean to avoid repeated failures, java.io.IOException: Job failed!&lt;br/&gt;
  at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:836)&lt;br/&gt;
  at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR.run(CompactorMR.java:186)&lt;br/&gt;
  at org.apache.hadoop.hive.ql.txn.compactor.Worker.run(Worker.java:162)&lt;/p&gt;

&lt;p&gt;2016-04-06 11:30:57,894 ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;dn209006-27&amp;#93;&lt;/span&gt;: txn.CompactionTxnHandler (CompactionTxnHandler.java:markCleaned(327)) - Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!&lt;/p&gt;</description>
                <environment>&lt;p&gt;Hadoop 2.6.2+Hive 1.2.1&lt;/p&gt;</environment>
        <key id="12956375">HIVE-13432</key>
            <summary>ACID ORC CompactorMR job throws java.lang.ArrayIndexOutOfBoundsException: 7</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="mmccline">Matt McCline</assignee>
                                    <reporter username="qiuzhuang.lian">Qiuzhuang Lian</reporter>
                        <labels>
                    </labels>
                <created>Wed, 6 Apr 2016 03:50:07 +0000</created>
                <updated>Mon, 13 Jun 2016 17:52:32 +0000</updated>
                            <resolved>Sat, 11 Jun 2016 06:43:15 +0000</resolved>
                                    <version>1.2.1</version>
                                                    <component>ORC</component>
                    <component>Transactions</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="15227974" author="qiuzhuang.lian" created="Wed, 6 Apr 2016 08:55:54 +0000"  >&lt;p&gt;Can someone confirm that this is related to issue of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-11981?&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-11981?&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="15233975" author="mmccline" created="Sun, 10 Apr 2016 08:04:34 +0000"  >&lt;p&gt;I ported a number of commits from master to branch-2.0, including:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-12894&quot; title=&quot;Detect whether ORC is reading from ACID table correctly for Schema Evolution&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-12894&quot;&gt;&lt;del&gt;HIVE-12894&lt;/del&gt;&lt;/a&gt; Detect whether ORC is reading from ACID table correctly for Schema Evolution (Matt McCline, reviewed by Prasanth J and Eugene Koifman)&lt;/p&gt;

&lt;p&gt;which may fix this issue.&lt;/p&gt;</comment>
                            <comment id="15234424" author="qiuzhuang.lian" created="Mon, 11 Apr 2016 02:33:13 +0000"  >&lt;p&gt;I will build hive 2.1/2.0.1 and let you know to see if it works. Many thanks.&lt;/p&gt;</comment>
                            <comment id="15234463" author="qiuzhuang.lian" created="Mon, 11 Apr 2016 03:56:54 +0000"  >&lt;p&gt;Hi Matt, &lt;/p&gt;

&lt;p&gt;I build hive from hive git branch 2.0 and see patch of 12984, I try compaction again on the same ACID table but still see the same error,&lt;/p&gt;

&lt;p&gt;, kind: TIMESTAMP&lt;br/&gt;
, kind: INT&lt;br/&gt;
] innerStructSubtype -1&lt;br/&gt;
  at org.apache.hadoop.hive.ql.io.orc.TreeReaderFactory$StructTreeReader.&amp;lt;init&amp;gt;(TreeReaderFactory.java:2092)&lt;br/&gt;
  at org.apache.hadoop.hive.ql.io.orc.TreeReaderFactory.createTreeReader(TreeReaderFactory.java:2518)&lt;br/&gt;
  at org.apache.hadoop.hive.ql.io.orc.TreeReaderFactory$StructTreeReader.&amp;lt;init&amp;gt;(TreeReaderFactory.java:2098)&lt;br/&gt;
  at org.apache.hadoop.hive.ql.io.orc.TreeReaderFactory.createTreeReader(TreeReaderFactory.java:2518)&lt;br/&gt;
  at org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl.&amp;lt;init&amp;gt;(RecordReaderImpl.java:210)&lt;br/&gt;
  at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.rowsOptions(ReaderImpl.java:662)&lt;br/&gt;
  at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger$ReaderPair.&amp;lt;init&amp;gt;(OrcRawRecordMerger.java:212)&lt;br/&gt;
  at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.&amp;lt;init&amp;gt;(OrcRawRecordMerger.java:512)&lt;br/&gt;
  at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRawReader(OrcInputFormat.java:1870)&lt;br/&gt;
  at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:575)&lt;br/&gt;
  at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:554)&lt;br/&gt;
  at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)&lt;br/&gt;
  at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)&lt;br/&gt;
  at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)&lt;br/&gt;
  at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)&lt;br/&gt;
  at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
  at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
  at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1656)&lt;br/&gt;
  at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)&lt;/p&gt;

&lt;p&gt;16/04/11 11:54:21 INFO mapreduce.Job:  map 100% reduce 0%&lt;br/&gt;
16/04/11 11:54:21 INFO mapreduce.Job: Job job_1458819387386_23797 failed with state FAILED due to: Task failed task_1458819387386_23797_m_000001&lt;br/&gt;
Job failed as tasks failed. failedMaps:1 failedReduces:0&lt;/p&gt;

&lt;p&gt;16/04/11 11:54:21 INFO mapreduce.Job: Counters: 14&lt;br/&gt;
  Job Counters &lt;br/&gt;
    Failed map tasks=9&lt;br/&gt;
    Killed map tasks=9&lt;br/&gt;
    Launched map tasks=18&lt;br/&gt;
    Other local map tasks=8&lt;br/&gt;
    Data-local map tasks=4&lt;br/&gt;
    Rack-local map tasks=6&lt;br/&gt;
    Total time spent by all maps in occupied slots (ms)=405068&lt;br/&gt;
    Total time spent by all reduces in occupied slots (ms)=0&lt;br/&gt;
    Total time spent by all map tasks (ms)=202534&lt;br/&gt;
    Total vcore-seconds taken by all map tasks=202534&lt;br/&gt;
    Total megabyte-seconds taken by all map tasks=414789632&lt;br/&gt;
  Map-Reduce Framework&lt;br/&gt;
    CPU time spent (ms)=0&lt;br/&gt;
    Physical memory (bytes) snapshot=0&lt;br/&gt;
    Virtual memory (bytes) snapshot=0&lt;br/&gt;
16/04/11 11:54:21 ERROR compactor.Worker: Caught exception while trying to compact id:80,dbname:lqz,tableName:my_acid_orc_table,partName:null,state:,type:MAJOR,runAs:null,tooManyAborts:false,highestTxnId:0.  Marking clean to avoid repeated failures, java.io.IOException: Job failed!&lt;br/&gt;
  at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:836)&lt;br/&gt;
  at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR.launchCompactionJob(CompactorMR.java:247)&lt;br/&gt;
  at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR.run(CompactorMR.java:213)&lt;br/&gt;
  at org.apache.hadoop.hive.ql.txn.compactor.Worker.run(Worker.java:164)&lt;/p&gt;

&lt;p&gt;16/04/11 11:54:34 INFO txn.AcidCompactionHistoryService: History reaper reaper ran for 0seconds.  isAliveCounter=-2147483642&lt;/p&gt;

&lt;p&gt;Please let me know if you need more info for this issue. &lt;/p&gt;

&lt;p&gt;Regards,&lt;br/&gt;
Qiuzhuang&lt;/p&gt;</comment>
                            <comment id="15234480" author="qiuzhuang.lian" created="Mon, 11 Apr 2016 04:40:11 +0000"  >&lt;p&gt;For more info, I also see the regression to the ACID feature for delete statement,&lt;/p&gt;

&lt;p&gt;16/04/11 12:38:43 WARN shims.HadoopShimsSecure: Can&apos;t fetch tasklog: TaskLogServlet is not supported in MR2 mode.&lt;/p&gt;

&lt;p&gt;Task with the most failures(4): &lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Task ID:&lt;br/&gt;
  task_1458819387386_23814_r_000003&lt;/p&gt;

&lt;p&gt;URL:&lt;br/&gt;
  &lt;a href=&quot;http://nn209003:8088/taskdetails.jsp?jobid=job_1458819387386_23814&amp;amp;tipid=task_1458819387386_23814_r_000003&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://nn209003:8088/taskdetails.jsp?jobid=job_1458819387386_23814&amp;amp;tipid=task_1458819387386_23814_r_000003&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Diagnostic Messages for this Task:&lt;br/&gt;
Error: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {&quot;key&quot;:{&quot;reducesinkkey0&quot;:{&quot;transactionid&quot;:0,&quot;bucketid&quot;:43,&quot;rowid&quot;:0}},&quot;value&quot;:null}&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.mr.ExecReducer.reduce(ExecReducer.java:257)&lt;br/&gt;
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:444)&lt;br/&gt;
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1656)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)&lt;br/&gt;
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {&quot;key&quot;:{&quot;reducesinkkey0&quot;:{&quot;transactionid&quot;:0,&quot;bucketid&quot;:43,&quot;rowid&quot;:0}},&quot;value&quot;:null}&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.mr.ExecReducer.reduce(ExecReducer.java:245)&lt;br/&gt;
	... 7 more&lt;br/&gt;
Caused by: java.lang.ArrayIndexOutOfBoundsException: 1&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:759)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:837)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:97)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.mr.ExecReducer.reduce(ExecReducer.java:236)&lt;br/&gt;
	... 7 more&lt;/p&gt;


&lt;p&gt;16/04/11 12:38:43 ERROR exec.Task: &lt;br/&gt;
Task with the most failures(4): &lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Task ID:&lt;br/&gt;
  task_1458819387386_23814_r_000003&lt;/p&gt;

&lt;p&gt;URL:&lt;br/&gt;
  &lt;a href=&quot;http://nn209003:8088/taskdetails.jsp?jobid=job_1458819387386_23814&amp;amp;tipid=task_1458819387386_23814_r_000003&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://nn209003:8088/taskdetails.jsp?jobid=job_1458819387386_23814&amp;amp;tipid=task_1458819387386_23814_r_000003&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Diagnostic Messages for this Task:&lt;br/&gt;
Error: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {&quot;key&quot;:{&quot;reducesinkkey0&quot;:{&quot;transactionid&quot;:0,&quot;bucketid&quot;:43,&quot;rowid&quot;:0}},&quot;value&quot;:null}&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.mr.ExecReducer.reduce(ExecReducer.java:257)&lt;br/&gt;
	at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:444)&lt;br/&gt;
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:415)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1656)&lt;br/&gt;
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)&lt;br/&gt;
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {&quot;key&quot;:{&quot;reducesinkkey0&quot;:{&quot;transactionid&quot;:0,&quot;bucketid&quot;:43,&quot;rowid&quot;:0}},&quot;value&quot;:null}&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.mr.ExecReducer.reduce(ExecReducer.java:245)&lt;br/&gt;
	... 7 more&lt;br/&gt;
Caused by: java.lang.ArrayIndexOutOfBoundsException: 1&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:759)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:837)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:97)&lt;br/&gt;
	at org.apache.hadoop.hive.ql.exec.mr.ExecReducer.reduce(ExecReducer.java:236)&lt;/p&gt;</comment>
                            <comment id="15303470" author="qiuzhuang.lian" created="Fri, 27 May 2016 04:40:22 +0000"  >&lt;p&gt;Hi Matt,&lt;/p&gt;

&lt;p&gt;Since we are blocked by this issue, can you please help take a look at this?&lt;/p&gt;

&lt;p&gt;Many thanks.&lt;/p&gt;</comment>
                            <comment id="15316134" author="mmccline" created="Mon, 6 Jun 2016 02:31:02 +0000"  >&lt;p&gt;In order to help, I need a repro.&lt;/p&gt;

&lt;p&gt;I need a &lt;b&gt;small self-contained test case&lt;/b&gt;.  DLL for test input files, small amount of data, and the queries to run.  In particular, if any schema changes like adding a column would be critical.  The stack traces provided are insufficient for me to make progress.&lt;/p&gt;

&lt;p&gt;The ACID code has undergone a huge amount of change in the last year.  Also, there has been a lot of change for Schema Evolution.&lt;/p&gt;

&lt;p&gt;There is a new Hive-2 branch (branch-2.1) being readied.  RC0 as created and a new RC1 is in progress.  It has very recent ACID and Schema Evolution changes.&lt;/p&gt;
</comment>
                            <comment id="15323485" author="mmccline" created="Thu, 9 Jun 2016 22:18:51 +0000"  >&lt;p&gt;We might have a clue of what is causing this problem.&lt;/p&gt;

&lt;p&gt;We have one test case where &quot;minor&quot; compaction fails when hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat but succeeds when that environment variable is org.apache.hadoop.hive.ql.io.HiveInputFormat&lt;/p&gt;</comment>
                            <comment id="15323902" author="qiuzhuang.lian" created="Fri, 10 Jun 2016 05:31:38 +0000"  >&lt;p&gt;Sorry for delay response. Yes, our hive-site.xml uses CombineHiveInputFormat. I should have sent you our hive-site.xml. Please check the attached to see if any more clue.&lt;/p&gt;</comment>
                            <comment id="15324302" author="mmccline" created="Fri, 10 Jun 2016 11:12:18 +0000"  >&lt;p&gt;At the moment, the repro seems to involve deletions and minor compact.  Investigating.&lt;/p&gt;</comment>
                            <comment id="15325752" author="mmccline" created="Sat, 11 Jun 2016 06:43:15 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-13974&quot; title=&quot;ORC Schema Evolution doesn&amp;#39;t support add columns to non-last STRUCT columns&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-13974&quot;&gt;&lt;del&gt;HIVE-13974&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(ACID Delete Events have slight different schema than other ACID records)&lt;/p&gt;</comment>
                            <comment id="15326232" author="qiuzhuang.lian" created="Sun, 12 Jun 2016 07:14:43 +0000"  >&lt;p&gt;I remove this configuration when running compactorMR job and it looks ok now. BTW, is this CombineHiveInputFormat issue related to the recent fix of &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-13968&quot; title=&quot;CombineHiveInputFormat does not honor InputFormat that implements AvoidSplitCombination&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-13968&quot;&gt;&lt;del&gt;HIVE-13968&lt;/del&gt;&lt;/a&gt;?&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12978242">HIVE-14004</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12809364" name="orc_hive-site.xml" size="7907" author="qiuzhuang.lian" created="Fri, 10 Jun 2016 05:37:19 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sun, 10 Apr 2016 08:04:34 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            24 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2vp87:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>