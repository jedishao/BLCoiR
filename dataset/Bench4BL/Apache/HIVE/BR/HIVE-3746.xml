<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sat Dec 03 23:54:44 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HIVE-3746/HIVE-3746.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HIVE-3746] Fix HS2 ResultSet Serialization Performance Regression</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3746</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description></description>
                <environment></environment>
        <key id="12617683">HIVE-3746</key>
            <summary>Fix HS2 ResultSet Serialization Performance Regression</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12550255">HIVE-2935</parent>
                                    <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="navis">Navis</assignee>
                                    <reporter username="cwsteinbach">Carl Steinbach</reporter>
                        <labels>
                            <label>HiveServer2</label>
                            <label>jdbc</label>
                            <label>thrift</label>
                    </labels>
                <created>Mon, 26 Nov 2012 20:59:43 +0000</created>
                <updated>Sun, 16 Mar 2014 16:07:42 +0000</updated>
                            <resolved>Fri, 3 Jan 2014 01:34:35 +0000</resolved>
                                                    <fixVersion>0.13.0</fixVersion>
                                    <component>HiveServer2</component>
                    <component>Server Infrastructure</component>
                        <due></due>
                            <votes>3</votes>
                                    <watches>22</watches>
                                                                <comments>
                            <comment id="13504103" author="cwsteinbach" created="Mon, 26 Nov 2012 21:13:35 +0000"  >&lt;p&gt;Currently HS2 uses the following Thrift structures to represent a resultset:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;// Represents a rowset
struct TRowSet {
  // The starting row offset of this rowset.
  1: required i64 startRowOffset
  2: required list&amp;lt;TRow&amp;gt; rows
}

// Represents a row in a rowset.
struct TRow {
  1: required list&amp;lt;TColumnValue&amp;gt; colVals
}

union TColumnValue {
  1: TBoolValue   boolVal      // BOOLEAN
  2: TByteValue   byteVal      // TINYINT
  3: TI16Value    i16Val       // SMALLINT
  4: TI32Value    i32Val       // INT
  5: TI64Value    i64Val       // BIGINT, TIMESTAMP
  6: TDoubleValue doubleVal    // FLOAT, DOUBLE
  7: TStringValue stringVal    // STRING, LIST, MAP, STRUCT, UNIONTYPE, BINARY
}

// A Boolean column value.
struct TBoolValue {
  // NULL if value is unset.
  1: optional bool value
}

...

struct TStringValue {
  1: optional string value
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This problem with this approach is that Thrift unions are not very efficient, and we pay this cost on a per-field basis. Instead, we should make the result set structure column-oriented as follows:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;// Represents a rowset
struct TRowSet {
  // The starting row offset of this rowset.
  1: required i64 startRowOffset
  2: required list&amp;lt;TColumn&amp;gt; columns
}

union TColumn {
  1: list&amp;lt;TBoolValue&amp;gt; boolColumn
  2: list&amp;lt;TByteValue&amp;gt; byteColumn
  3: list&amp;lt;TI16Value&amp;gt; i16Column
  4: list&amp;lt;TI32Value&amp;gt; i32Column
  5: list&amp;lt;TI64Value&amp;gt; i64Column
  6: list&amp;lt;TDoubleValue&amp;gt; doubleColumn
  7: list&amp;lt;TStringValue&amp;gt; stringColumn
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
</comment>
                            <comment id="13504126" author="cwsteinbach" created="Mon, 26 Nov 2012 21:43:11 +0000"  >&lt;p&gt;This would probably be more efficient:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;// Represents a rowset
struct TRowSet {
  // The starting row offset of this rowset.
  1: required i64 startRowOffset
  2: required list&amp;lt;TColumn&amp;gt; columns
}

struct TColumn {
  1: required list&amp;lt;i32&amp;gt; nullOffsets
  2: required TColumnData columnData
}

union TColumnData {
  1: list&amp;lt;bool&amp;gt; boolColumn
  2: list&amp;lt;byte&amp;gt; byteColumn
  3: list&amp;lt;i16&amp;gt; i16Column
  4: list&amp;lt;i32&amp;gt; i32Column
  5: list&amp;lt;i64&amp;gt; i64Column
  6: list&amp;lt;double&amp;gt; doubleColumn
  7: list&amp;lt;string&amp;gt; stringColumn
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We may be able to make this even more compact by using a run-length encoding scheme for the nullOffset vector (and possibly the ColumnData list too).&lt;/p&gt;</comment>
                            <comment id="13504959" author="pprudich" created="Tue, 27 Nov 2012 21:24:37 +0000"  >&lt;p&gt;To make sure I&apos;m reading the new thrift definitions correctly &amp;#8211; does this mean that all rows&apos; column 1 values will come first on the wire, and then be followed by all rows&apos; values for column 2, and so on?  I clearly see how this would save bytes on the wire.&lt;/p&gt;

&lt;p&gt;However, any client trying to return rows one-at-a-time to an application would be required to read, process, and buffer almost an entire reply-worth of data before being able to return the first complete row.&lt;/p&gt;

&lt;p&gt;I&apos;m unfamiliar with the server code; but similar buffering may be needed there as well.&lt;/p&gt;

&lt;p&gt;Is my understanding of the issue correct?&lt;/p&gt;</comment>
                            <comment id="13600342" author="cwsteinbach" created="Tue, 12 Mar 2013 19:01:36 +0000"  >&lt;blockquote&gt;&lt;p&gt;However, any client trying to return rows one-at-a-time to an application would be required to read, process, and buffer almost an entire reply-worth of data before being able to return the first complete row.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The client is able to specify the maximum number of rows that should be returned in each fetch request. This is true regardless of whether we use a column-major or row-major format for the row data. Please refer to the definition of TFetchResultsReq in TCLIService.thrift for more information.&lt;/p&gt;</comment>
                            <comment id="13601584" author="pprudich" created="Wed, 13 Mar 2013 20:14:26 +0000"  >&lt;blockquote&gt;&lt;p&gt;The client is able to specify the maximum number of rows that should be returned in each fetch request.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right &amp;#8211; that&apos;s specifically the case I&apos;m concerned with.  If an application has requested a single row, and the client has requested &lt;em&gt;n&lt;/em&gt; rows from the server in an effort to reduce round trips, then &lt;em&gt;n&lt;/em&gt;-1 intervening values from the first column must be cached off somewhere before the first value for the second column can be accessed.&lt;/p&gt;

&lt;p&gt;Trying to address this by setting the row limit to 1 would also negatively impact performance by requiring a round trip per row.&lt;/p&gt;

&lt;p&gt;Without an intimate knowledge of the server code, I could see row orientation as an optional argument to TFetchResultsReq, but would encourage that the row-oriented behavior remain an option.&lt;/p&gt;</comment>
                            <comment id="13648667" author="cwsteinbach" created="Fri, 3 May 2013 18:40:32 +0000"  >&lt;blockquote&gt;&lt;p&gt;If an application has requested a single row, and the client has requested n rows from the server in an effort to reduce round trips, then n-1 intervening values from the first column must be cached off somewhere before the first value for the second column can be accessed.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;If the fetch size is n, then the client is going to end up storing n rows in memory regardless of whether the result set is represented in a row-major or column-major format. Put another way, the unit of data transfer between the server and client is a variable sized resultset. The client has the option of setting the result size very low in order to achieve lower latency, or making it very large in order to get higher overall throughput. However, the key limitation is that the client is not able to provide access to any of the rows contained in a resultset until the entire resultset has been transferred from the server to the client. This limitation is a consequence of the fact that we&apos;re using a message oriented RPC layer (Thrift) to handle communication and data transfer between the client and server.&lt;/p&gt;</comment>
                            <comment id="13652978" author="pprudich" created="Thu, 9 May 2013 14:06:55 +0000"  >&lt;blockquote&gt;&lt;p&gt;This limitation is a consequence of the fact that we&apos;re using a message oriented RPC layer (Thrift) to handle communication and data transfer between the client and server.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This limitation is only present for a client that is linked to the Thrift library.  A client that is coded directly to the protocol itself is freed to leave outstanding data on the wire while it returns the initial results.&lt;/p&gt;</comment>
                            <comment id="13695865" author="cwsteinbach" created="Fri, 28 Jun 2013 22:20:32 +0000"  >&lt;p&gt;Updating the summary of this ticket and removing myself as the assignee since I won&apos;t be working on it anytime soon.&lt;/p&gt;</comment>
                            <comment id="13695870" author="cwsteinbach" created="Fri, 28 Jun 2013 22:24:28 +0000"  >&lt;p&gt;I also want to add that the HS2 API is capable of supporting multiple resultset serialization formats. Clearly the original resultset serialization format is a failure and needs to be deprecated in favor of something else. I outlined one alternative format in the comments above, but it probably makes more sense to first add support for the serialization format used by HS1.&lt;/p&gt;</comment>
                            <comment id="13840912" author="qwert" created="Fri, 6 Dec 2013 03:16:41 +0000"  >
&lt;p&gt;hiveserver2 is much slower than hiveserver1?&lt;/p&gt;


&lt;p&gt;we are building ms sql cube by linkedserver connectiong hiveserver with Cloudera&apos;s ODBC driver.&lt;/p&gt;

&lt;p&gt;There are two test results:&lt;/p&gt;

&lt;p&gt;1. hiveserver1 running on 2CPUs, 8G mem, took about 8 hours&lt;br/&gt;
2. hiveserver2 running on 4CPUs, 16 mem, took about 13 hours and 27min (never successful on machine with 2CPUs, 8G mem)&lt;/p&gt;


&lt;p&gt;Although on both cases, almost all CPUs are busy when building cube.&lt;/p&gt;

&lt;p&gt;But I cannot understand why hiveserver2 is much slower than hiveserver1, because from doc, hs2 support concurrency, it should be faster than hs1, isn&apos;t it?&lt;/p&gt;



&lt;p&gt;CDH4.3 on CentOS6.&lt;/p&gt;</comment>
                            <comment id="13840917" author="navis" created="Fri, 6 Dec 2013 03:28:53 +0000"  >&lt;p&gt;I have a patch similar to this one based on hive-0.11.0. I&apos;ll check if it&apos;s possible to be rebased on trunk.&lt;/p&gt;</comment>
                            <comment id="13841130" author="hiveqa" created="Fri, 6 Dec 2013 09:39:04 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12617332/HIVE-3746.1.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12617332/HIVE-3746.1.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 4458 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/548/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/548/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/548/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/548/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12617332&lt;/p&gt;</comment>
                            <comment id="13848756" author="navis" created="Mon, 16 Dec 2013 02:04:05 +0000"  >&lt;p&gt;Rebased to trunk&lt;/p&gt;</comment>
                            <comment id="13848797" author="hiveqa" created="Mon, 16 Dec 2013 03:56:42 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 at least one tests failed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12618843/HIVE-3746.2.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12618843/HIVE-3746.2.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 1 failed/errored test(s), 4785 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hive.jdbc.TestJdbcDriver2.testDataTypes
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/645/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/645/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/645/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/645/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 1 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12618843&lt;/p&gt;</comment>
                            <comment id="13848838" author="cwsteinbach" created="Mon, 16 Dec 2013 05:38:59 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=navis&quot; class=&quot;user-hover&quot; rel=&quot;navis&quot;&gt;Navis&lt;/a&gt; Thanks for working on this! I added some comments on RB. My main concern with the current patch is that it breaks backward compatibility with older clients.&lt;/p&gt;</comment>
                            <comment id="13848849" author="overcoil" created="Mon, 16 Dec 2013 06:09:16 +0000"  >&lt;p&gt;My team noticed the breaking change too but the protocol version indicator is available to at least detect this.&lt;/p&gt;</comment>
                            <comment id="13848858" author="hiveqa" created="Mon, 16 Dec 2013 06:33:21 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12618851/HIVE-3746.3.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12618851/HIVE-3746.3.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 4785 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/647/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/647/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/647/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/647/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12618851&lt;/p&gt;</comment>
                            <comment id="13851271" author="navis" created="Wed, 18 Dec 2013 02:05:22 +0000"  >&lt;p&gt;Running test&lt;/p&gt;</comment>
                            <comment id="13851386" author="hiveqa" created="Wed, 18 Dec 2013 05:29:52 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12619227/HIVE-3746.4.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12619227/HIVE-3746.4.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/680/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/680/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/680/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/680/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Tests exited with: NonZeroExitCodeException
Command &apos;bash /data/hive-ptest/working/scratch/source-prep.sh&apos; failed with exit status 1 and output &apos;+ [[ -n &apos;&apos; ]]
+ export &apos;ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m &apos;
+ ANT_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m &apos;
+ export &apos;M2_OPTS=-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ M2_OPTS=&apos;-Xmx1g -XX:MaxPermSize=256m -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128&apos;
+ cd /data/hive-ptest/working/
+ tee /data/hive-ptest/logs/PreCommit-HIVE-Build-680/source-prep.txt
+ [[ false == \t\r\u\e ]]
+ mkdir -p maven ivy
+ [[ svn = \s\v\n ]]
+ [[ -n &apos;&apos; ]]
+ [[ -d apache-svn-trunk-source ]]
+ [[ ! -d apache-svn-trunk-source/.svn ]]
+ [[ ! -d apache-svn-trunk-source ]]
+ cd apache-svn-trunk-source
+ svn revert -R .
++ awk &apos;{print $2}&apos;
++ egrep -v &apos;^X|^Performing status on external&apos;
++ svn status --no-ignore
+ rm -rf target datanucleus.log ant/target shims/target shims/0.20/target shims/assembly/target shims/0.20S/target shims/0.23/target shims/common/target shims/common-secure/target packaging/target hbase-handler/target testutils/target jdbc/target metastore/target itests/target itests/hcatalog-unit/target itests/test-serde/target itests/qtest/target itests/hive-unit/target itests/custom-serde/target itests/util/target hcatalog/target hcatalog/storage-handlers/hbase/target hcatalog/server-extensions/target hcatalog/core/target hcatalog/webhcat/svr/target hcatalog/webhcat/java-client/target hcatalog/hcatalog-pig-adapter/target hwi/target common/target common/src/gen contrib/target service/target serde/target beeline/target odbc/target cli/target ql/dependency-reduced-pom.xml ql/target
+ svn update

Fetching external item into &apos;hcatalog/src/test/e2e/harness&apos;
External at revision 1551852.

At revision 1551852.
+ patchCommandPath=/data/hive-ptest/working/scratch/smart-apply-patch.sh
+ patchFilePath=/data/hive-ptest/working/scratch/build.patch
+ [[ -f /data/hive-ptest/working/scratch/build.patch ]]
+ chmod +x /data/hive-ptest/working/scratch/smart-apply-patch.sh
+ /data/hive-ptest/working/scratch/smart-apply-patch.sh /data/hive-ptest/working/scratch/build.patch
The patch does not appear to apply with p0, p1, or p2
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12619227&lt;/p&gt;</comment>
                            <comment id="13851454" author="navis" created="Wed, 18 Dec 2013 07:02:00 +0000"  >&lt;p&gt;Rebased to trunk&lt;/p&gt;</comment>
                            <comment id="13851493" author="hiveqa" created="Wed, 18 Dec 2013 08:12:03 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12619267/HIVE-3746.5.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12619267/HIVE-3746.5.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/685/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/685/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/685/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/685/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;**** This message was trimmed, see log for full details ****
[INFO] Including org.json:json:jar:20090211 in the shaded jar.
[INFO] Excluding stax:stax-api:jar:1.0.1 from the shaded jar.
[INFO] Excluding org.apache.hadoop:hadoop-core:jar:1.2.1 from the shaded jar.
[INFO] Excluding xmlenc:xmlenc:jar:0.52 from the shaded jar.
[INFO] Excluding com.sun.jersey:jersey-core:jar:1.14 from the shaded jar.
[INFO] Excluding com.sun.jersey:jersey-json:jar:1.14 from the shaded jar.
[INFO] Excluding org.codehaus.jettison:jettison:jar:1.1 from the shaded jar.
[INFO] Excluding com.sun.xml.bind:jaxb-impl:jar:2.2.3-1 from the shaded jar.
[INFO] Excluding javax.xml.bind:jaxb-api:jar:2.2.2 from the shaded jar.
[INFO] Excluding javax.xml.stream:stax-api:jar:1.0-2 from the shaded jar.
[INFO] Excluding javax.activation:activation:jar:1.1 from the shaded jar.
[INFO] Excluding org.codehaus.jackson:jackson-jaxrs:jar:1.9.2 from the shaded jar.
[INFO] Excluding org.codehaus.jackson:jackson-xc:jar:1.9.2 from the shaded jar.
[INFO] Excluding com.sun.jersey:jersey-server:jar:1.14 from the shaded jar.
[INFO] Excluding asm:asm:jar:3.1 from the shaded jar.
[INFO] Excluding org.apache.commons:commons-math:jar:2.1 from the shaded jar.
[INFO] Excluding commons-configuration:commons-configuration:jar:1.6 from the shaded jar.
[INFO] Excluding commons-digester:commons-digester:jar:1.8 from the shaded jar.
[INFO] Excluding commons-beanutils:commons-beanutils:jar:1.7.0 from the shaded jar.
[INFO] Excluding commons-beanutils:commons-beanutils-core:jar:1.8.0 from the shaded jar.
[INFO] Excluding commons-net:commons-net:jar:1.4.1 from the shaded jar.
[INFO] Excluding org.mortbay.jetty:jetty:jar:6.1.26 from the shaded jar.
[INFO] Excluding org.mortbay.jetty:jetty-util:jar:6.1.26 from the shaded jar.
[INFO] Excluding tomcat:jasper-runtime:jar:5.5.12 from the shaded jar.
[INFO] Excluding tomcat:jasper-compiler:jar:5.5.12 from the shaded jar.
[INFO] Excluding org.mortbay.jetty:jsp-api-2.1:jar:6.1.14 from the shaded jar.
[INFO] Excluding org.mortbay.jetty:servlet-api-2.5:jar:6.1.14 from the shaded jar.
[INFO] Excluding org.mortbay.jetty:jsp-2.1:jar:6.1.14 from the shaded jar.
[INFO] Excluding ant:ant:jar:1.6.5 from the shaded jar.
[INFO] Excluding commons-el:commons-el:jar:1.0 from the shaded jar.
[INFO] Excluding net.java.dev.jets3t:jets3t:jar:0.6.1 from the shaded jar.
[INFO] Excluding hsqldb:hsqldb:jar:1.8.0.10 from the shaded jar.
[INFO] Excluding oro:oro:jar:2.0.8 from the shaded jar.
[INFO] Excluding org.eclipse.jdt:core:jar:3.1.1 from the shaded jar.
[INFO] Excluding org.slf4j:slf4j-api:jar:1.7.5 from the shaded jar.
[INFO] Excluding org.slf4j:slf4j-log4j12:jar:1.7.5 from the shaded jar.
[INFO] Replacing original artifact with shaded artifact.
[INFO] Replacing /data/hive-ptest/working/apache-svn-trunk-source/ql/target/hive-exec-0.13.0-SNAPSHOT.jar with /data/hive-ptest/working/apache-svn-trunk-source/ql/target/hive-exec-0.13.0-SNAPSHOT-shaded.jar
[INFO] Dependency-reduced POM written at: /data/hive-ptest/working/apache-svn-trunk-source/ql/dependency-reduced-pom.xml
[INFO] Dependency-reduced POM written at: /data/hive-ptest/working/apache-svn-trunk-source/ql/dependency-reduced-pom.xml
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-exec ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/ql/target/hive-exec-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-exec/0.13.0-SNAPSHOT/hive-exec-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/ql/dependency-reduced-pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-exec/0.13.0-SNAPSHOT/hive-exec-0.13.0-SNAPSHOT.pom
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/ql/target/hive-exec-0.13.0-SNAPSHOT-tests.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-exec/0.13.0-SNAPSHOT/hive-exec-0.13.0-SNAPSHOT-tests.jar
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Service 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-service ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/service (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-service ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/service/src/model added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/service/src/gen/thrift/gen-javabean added.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-service ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/service/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-service ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-service ---
[INFO] Compiling 165 source files to /data/hive-ptest/working/apache-svn-trunk-source/service/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-service ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/service/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-service ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/service/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/service/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/service/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/service/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-service ---
[INFO] Compiling 7 source files to /data/hive-ptest/working/apache-svn-trunk-source/service/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-service ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-service ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/service/target/hive-service-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-jar-plugin:2.2:test-jar (default) @ hive-service ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/service/target/hive-service-0.13.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-service ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/service/target/hive-service-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-service/0.13.0-SNAPSHOT/hive-service-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/service/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-service/0.13.0-SNAPSHOT/hive-service-0.13.0-SNAPSHOT.pom
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/service/target/hive-service-0.13.0-SNAPSHOT-tests.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-service/0.13.0-SNAPSHOT/hive-service-0.13.0-SNAPSHOT-tests.jar
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive JDBC 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-jdbc ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/jdbc (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-jdbc ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/jdbc/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-jdbc ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-jdbc ---
[INFO] Compiling 30 source files to /data/hive-ptest/working/apache-svn-trunk-source/jdbc/target/classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 4 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/jdbc/src/java/org/apache/hive/jdbc/HiveMetaDataResultSet.java:[34,5] cannot find symbol
symbol  : constructor HiveBaseResultSet(org.apache.hive.service.cli.thrift.TProtocolVersion)
location: class org.apache.hive.jdbc.HiveBaseResultSet
[INFO] 1 error
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [4.733s]
[INFO] Hive Ant Utilities ................................ SUCCESS [7.838s]
[INFO] Hive Shims Common ................................. SUCCESS [3.038s]
[INFO] Hive Shims 0.20 ................................... SUCCESS [1.840s]
[INFO] Hive Shims Secure Common .......................... SUCCESS [2.807s]
[INFO] Hive Shims 0.20S .................................. SUCCESS [1.428s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [3.298s]
[INFO] Hive Shims ........................................ SUCCESS [3.872s]
[INFO] Hive Common ....................................... SUCCESS [14.402s]
[INFO] Hive Serde ........................................ SUCCESS [16.462s]
[INFO] Hive Metastore .................................... SUCCESS [25.901s]
[INFO] Hive Query Language ............................... SUCCESS [55.551s]
[INFO] Hive Service ...................................... SUCCESS [4.094s]
[INFO] Hive JDBC ......................................... FAILURE [1.269s]
[INFO] Hive Beeline ...................................... SKIPPED
[INFO] Hive CLI .......................................... SKIPPED
[INFO] Hive Contrib ...................................... SKIPPED
[INFO] Hive HBase Handler ................................ SKIPPED
[INFO] Hive HCatalog ..................................... SKIPPED
[INFO] Hive HCatalog Core ................................ SKIPPED
[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED
[INFO] Hive HCatalog Server Extensions ................... SKIPPED
[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED
[INFO] Hive HCatalog Webhcat ............................. SKIPPED
[INFO] Hive HCatalog HBase Storage Handler ............... SKIPPED
[INFO] Hive HWI .......................................... SKIPPED
[INFO] Hive ODBC ......................................... SKIPPED
[INFO] Hive Shims Aggregator ............................. SKIPPED
[INFO] Hive TestUtils .................................... SKIPPED
[INFO] Hive Packaging .................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 2:29.486s
[INFO] Finished at: Wed Dec 18 03:12:01 EST 2013
[INFO] Final Memory: 68M/512M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-jdbc: Compilation failure
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/jdbc/src/java/org/apache/hive/jdbc/HiveMetaDataResultSet.java:[34,5] cannot find symbol
[ERROR] symbol  : constructor HiveBaseResultSet(org.apache.hive.service.cli.thrift.TProtocolVersion)
[ERROR] location: class org.apache.hive.jdbc.HiveBaseResultSet
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-jdbc
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12619267&lt;/p&gt;</comment>
                            <comment id="13851500" author="hiveqa" created="Wed, 18 Dec 2013 08:44:31 +0000"  >

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;Overall&lt;/font&gt;: -1 no tests executed&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12619276/HIVE-3746.6.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12619276/HIVE-3746.6.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/686/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/686/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/686/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/686/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;**** This message was trimmed, see log for full details ****
[INFO] Including org.json:json:jar:20090211 in the shaded jar.
[INFO] Excluding stax:stax-api:jar:1.0.1 from the shaded jar.
[INFO] Excluding org.apache.hadoop:hadoop-core:jar:1.2.1 from the shaded jar.
[INFO] Excluding xmlenc:xmlenc:jar:0.52 from the shaded jar.
[INFO] Excluding com.sun.jersey:jersey-core:jar:1.14 from the shaded jar.
[INFO] Excluding com.sun.jersey:jersey-json:jar:1.14 from the shaded jar.
[INFO] Excluding org.codehaus.jettison:jettison:jar:1.1 from the shaded jar.
[INFO] Excluding com.sun.xml.bind:jaxb-impl:jar:2.2.3-1 from the shaded jar.
[INFO] Excluding javax.xml.bind:jaxb-api:jar:2.2.2 from the shaded jar.
[INFO] Excluding javax.xml.stream:stax-api:jar:1.0-2 from the shaded jar.
[INFO] Excluding javax.activation:activation:jar:1.1 from the shaded jar.
[INFO] Excluding org.codehaus.jackson:jackson-jaxrs:jar:1.9.2 from the shaded jar.
[INFO] Excluding org.codehaus.jackson:jackson-xc:jar:1.9.2 from the shaded jar.
[INFO] Excluding com.sun.jersey:jersey-server:jar:1.14 from the shaded jar.
[INFO] Excluding asm:asm:jar:3.1 from the shaded jar.
[INFO] Excluding org.apache.commons:commons-math:jar:2.1 from the shaded jar.
[INFO] Excluding commons-configuration:commons-configuration:jar:1.6 from the shaded jar.
[INFO] Excluding commons-digester:commons-digester:jar:1.8 from the shaded jar.
[INFO] Excluding commons-beanutils:commons-beanutils:jar:1.7.0 from the shaded jar.
[INFO] Excluding commons-beanutils:commons-beanutils-core:jar:1.8.0 from the shaded jar.
[INFO] Excluding commons-net:commons-net:jar:1.4.1 from the shaded jar.
[INFO] Excluding org.mortbay.jetty:jetty:jar:6.1.26 from the shaded jar.
[INFO] Excluding org.mortbay.jetty:jetty-util:jar:6.1.26 from the shaded jar.
[INFO] Excluding tomcat:jasper-runtime:jar:5.5.12 from the shaded jar.
[INFO] Excluding tomcat:jasper-compiler:jar:5.5.12 from the shaded jar.
[INFO] Excluding org.mortbay.jetty:jsp-api-2.1:jar:6.1.14 from the shaded jar.
[INFO] Excluding org.mortbay.jetty:servlet-api-2.5:jar:6.1.14 from the shaded jar.
[INFO] Excluding org.mortbay.jetty:jsp-2.1:jar:6.1.14 from the shaded jar.
[INFO] Excluding ant:ant:jar:1.6.5 from the shaded jar.
[INFO] Excluding commons-el:commons-el:jar:1.0 from the shaded jar.
[INFO] Excluding net.java.dev.jets3t:jets3t:jar:0.6.1 from the shaded jar.
[INFO] Excluding hsqldb:hsqldb:jar:1.8.0.10 from the shaded jar.
[INFO] Excluding oro:oro:jar:2.0.8 from the shaded jar.
[INFO] Excluding org.eclipse.jdt:core:jar:3.1.1 from the shaded jar.
[INFO] Excluding org.slf4j:slf4j-api:jar:1.7.5 from the shaded jar.
[INFO] Excluding org.slf4j:slf4j-log4j12:jar:1.7.5 from the shaded jar.
[INFO] Replacing original artifact with shaded artifact.
[INFO] Replacing /data/hive-ptest/working/apache-svn-trunk-source/ql/target/hive-exec-0.13.0-SNAPSHOT.jar with /data/hive-ptest/working/apache-svn-trunk-source/ql/target/hive-exec-0.13.0-SNAPSHOT-shaded.jar
[INFO] Dependency-reduced POM written at: /data/hive-ptest/working/apache-svn-trunk-source/ql/dependency-reduced-pom.xml
[INFO] Dependency-reduced POM written at: /data/hive-ptest/working/apache-svn-trunk-source/ql/dependency-reduced-pom.xml
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-exec ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/ql/target/hive-exec-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-exec/0.13.0-SNAPSHOT/hive-exec-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/ql/dependency-reduced-pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-exec/0.13.0-SNAPSHOT/hive-exec-0.13.0-SNAPSHOT.pom
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/ql/target/hive-exec-0.13.0-SNAPSHOT-tests.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-exec/0.13.0-SNAPSHOT/hive-exec-0.13.0-SNAPSHOT-tests.jar
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Service 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-service ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/service (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-service ---
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/service/src/model added.
[INFO] Source directory: /data/hive-ptest/working/apache-svn-trunk-source/service/src/gen/thrift/gen-javabean added.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-service ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/service/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-service ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-service ---
[INFO] Compiling 165 source files to /data/hive-ptest/working/apache-svn-trunk-source/service/target/classes
[WARNING] Note: /data/hive-ptest/working/apache-svn-trunk-source/service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java uses or overrides a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ hive-service ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/service/src/test/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-service ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/service/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/service/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-svn-trunk-source/service/target/tmp/conf
     [copy] Copying 4 files to /data/hive-ptest/working/apache-svn-trunk-source/service/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-service ---
[INFO] Compiling 7 source files to /data/hive-ptest/working/apache-svn-trunk-source/service/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-service ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-service ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/service/target/hive-service-0.13.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-jar-plugin:2.2:test-jar (default) @ hive-service ---
[INFO] Building jar: /data/hive-ptest/working/apache-svn-trunk-source/service/target/hive-service-0.13.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-service ---
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/service/target/hive-service-0.13.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-service/0.13.0-SNAPSHOT/hive-service-0.13.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/service/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-service/0.13.0-SNAPSHOT/hive-service-0.13.0-SNAPSHOT.pom
[INFO] Installing /data/hive-ptest/working/apache-svn-trunk-source/service/target/hive-service-0.13.0-SNAPSHOT-tests.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-service/0.13.0-SNAPSHOT/hive-service-0.13.0-SNAPSHOT-tests.jar
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive JDBC 0.13.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-jdbc ---
[INFO] Deleting /data/hive-ptest/working/apache-svn-trunk-source/jdbc (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ hive-jdbc ---
[debug] execute contextualize
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-svn-trunk-source/jdbc/src/main/resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-jdbc ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-jdbc ---
[INFO] Compiling 30 source files to /data/hive-ptest/working/apache-svn-trunk-source/jdbc/target/classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] Note: Some input files use or override a deprecated API.
[WARNING] Note: Recompile with -Xlint:deprecation for details.
[WARNING] Note: Some input files use unchecked or unsafe operations.
[WARNING] Note: Recompile with -Xlint:unchecked for details.
[INFO] 4 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/jdbc/src/java/org/apache/hive/jdbc/HiveMetaDataResultSet.java:[34,5] cannot find symbol
symbol  : constructor HiveBaseResultSet(org.apache.hive.service.cli.thrift.TProtocolVersion)
location: class org.apache.hive.jdbc.HiveBaseResultSet
[INFO] 1 error
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [4.652s]
[INFO] Hive Ant Utilities ................................ SUCCESS [7.207s]
[INFO] Hive Shims Common ................................. SUCCESS [2.862s]
[INFO] Hive Shims 0.20 ................................... SUCCESS [2.002s]
[INFO] Hive Shims Secure Common .......................... SUCCESS [2.749s]
[INFO] Hive Shims 0.20S .................................. SUCCESS [1.416s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [3.131s]
[INFO] Hive Shims ........................................ SUCCESS [3.813s]
[INFO] Hive Common ....................................... SUCCESS [8.180s]
[INFO] Hive Serde ........................................ SUCCESS [11.959s]
[INFO] Hive Metastore .................................... SUCCESS [26.266s]
[INFO] Hive Query Language ............................... SUCCESS [56.032s]
[INFO] Hive Service ...................................... SUCCESS [5.523s]
[INFO] Hive JDBC ......................................... FAILURE [1.268s]
[INFO] Hive Beeline ...................................... SKIPPED
[INFO] Hive CLI .......................................... SKIPPED
[INFO] Hive Contrib ...................................... SKIPPED
[INFO] Hive HBase Handler ................................ SKIPPED
[INFO] Hive HCatalog ..................................... SKIPPED
[INFO] Hive HCatalog Core ................................ SKIPPED
[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED
[INFO] Hive HCatalog Server Extensions ................... SKIPPED
[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED
[INFO] Hive HCatalog Webhcat ............................. SKIPPED
[INFO] Hive HCatalog HBase Storage Handler ............... SKIPPED
[INFO] Hive HWI .......................................... SKIPPED
[INFO] Hive ODBC ......................................... SKIPPED
[INFO] Hive Shims Aggregator ............................. SKIPPED
[INFO] Hive TestUtils .................................... SKIPPED
[INFO] Hive Packaging .................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 2:20.084s
[INFO] Finished at: Wed Dec 18 03:44:29 EST 2013
[INFO] Final Memory: 50M/466M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-jdbc: Compilation failure
[ERROR] /data/hive-ptest/working/apache-svn-trunk-source/jdbc/src/java/org/apache/hive/jdbc/HiveMetaDataResultSet.java:[34,5] cannot find symbol
[ERROR] symbol  : constructor HiveBaseResultSet(org.apache.hive.service.cli.thrift.TProtocolVersion)
[ERROR] location: class org.apache.hive.jdbc.HiveBaseResultSet
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-jdbc
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12619276&lt;/p&gt;</comment>
                            <comment id="13858684" author="hiveqa" created="Mon, 30 Dec 2013 09:50:39 +0000"  >

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;Overall&lt;/font&gt;: +1 all checks pass&lt;/p&gt;

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12620811/HIVE-3746.7.patch.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12620811/HIVE-3746.7.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 4818 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/770/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/770/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/770/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bigtop01.cloudera.org:8080/job/PreCommit-HIVE-Build/770/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12620811&lt;/p&gt;</comment>
                            <comment id="13858974" author="brocknoland" created="Mon, 30 Dec 2013 18:34:59 +0000"  >&lt;p&gt;Hey guys, this patch is a huge improvement over the existing RS serialization and is a big page so we don&apos;t want to have Navis continually rebasing. I think we should have a follow on JIRA to:&lt;/p&gt;

&lt;p&gt;1) test backwards compatibility with the older driver and fix any outstanding issues&lt;br/&gt;
2) remove the debug stuff that is included (printStackTrace and System.out)&lt;/p&gt;

&lt;p&gt;Brock&lt;/p&gt;</comment>
                            <comment id="13859755" author="cwsteinbach" created="Tue, 31 Dec 2013 22:42:02 +0000"  >&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;I&apos;m fine with committing the patch in its current state, but there&apos;s one thing I think we definitely need to fix ASAP in a followup patch. Up to this point we have managed to avoid polluting the client and service class interfaces ( i.e. CLIService and CLIServiceClient) with direct references to the Thrift serialization layer. This patch breaks that rule by exposing TProtocolVersion in the public methods of CliService. Only ThriftCLIService should need to know that the client is using a specific version of the Thrift serialization layer.&lt;/p&gt;</comment>
                            <comment id="13860959" author="vgumashta" created="Thu, 2 Jan 2014 23:46:53 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cwsteinbach&quot; class=&quot;user-hover&quot; rel=&quot;cwsteinbach&quot;&gt;Carl Steinbach&lt;/a&gt; I can take a stab at what you pointed out (CLIService referencing Thrift). Otherwise, the patch looks good!&lt;/p&gt;</comment>
                            <comment id="13861034" author="cwsteinbach" created="Fri, 3 Jan 2014 00:51:41 +0000"  >&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;~vaibhavgumashta&amp;#93;&lt;/span&gt; Cool!&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=navis&quot; class=&quot;user-hover&quot; rel=&quot;navis&quot;&gt;Navis&lt;/a&gt; Thanks again for putting this patch together! I&apos;m in the process of committing it now.&lt;/p&gt;</comment>
                            <comment id="13861080" author="cwsteinbach" created="Fri, 3 Jan 2014 01:34:35 +0000"  >&lt;p&gt;Committed to trunk. Thanks Navis!&lt;/p&gt;</comment>
                            <comment id="13862918" author="vgumashta" created="Mon, 6 Jan 2014 11:07:32 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=navis&quot; class=&quot;user-hover&quot; rel=&quot;navis&quot;&gt;Navis&lt;/a&gt; Thanks so much for the patch! I was also curious if there was any performance instrumentation done on your side?&lt;/p&gt;</comment>
                            <comment id="13864891" author="simba_jayb" created="Wed, 8 Jan 2014 00:03:11 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brocknoland&quot; class=&quot;user-hover&quot; rel=&quot;brocknoland&quot;&gt;Brock Noland&lt;/a&gt; Follow-on JIRA has been created (&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-6160&quot; title=&quot;Follow-on to HS2 ResultSet Serialization Performance Regression&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-6160&quot;&gt;HIVE-6160&lt;/a&gt;)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;~vaibhavgumashta&amp;#93;&lt;/span&gt; We have run some preliminary performance numbers, it looks to be at least x2.5 improvement for fetch time. Stay tuned for more detailed results.&lt;/p&gt;</comment>
                            <comment id="13865120" author="navis" created="Wed, 8 Jan 2014 06:04:10 +0000"  >&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;~vaibhavgumashta&amp;#93;&lt;/span&gt; This is rather new patch and not applied even to our product version, so I don&apos;t have any numbers on performance. Sorry. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=simba_jayb&quot; class=&quot;user-hover&quot; rel=&quot;simba_jayb&quot;&gt;Jay Bennett&lt;/a&gt; Thanks for the reassuring comment.&lt;/p&gt;</comment>
                            <comment id="13865122" author="brodym" created="Wed, 8 Jan 2014 06:08:55 +0000"  >&lt;p&gt;I&apos;m currently out of the office but will be checking email.  I&apos;ll be back in the office on Monday, January 13th.  For any urgent issues, please contact Jim Silhavy.&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
Brody&lt;/p&gt;</comment>
                            <comment id="13937195" author="zhuyu4839" created="Sun, 16 Mar 2014 16:07:42 +0000"  >&lt;p&gt;how to solve it?&lt;br/&gt;
main:&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Executed tasks&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; &lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; &amp;#8212; maven-compiler-plugin:3.1:compile (default-compile) @ hive-exec &amp;#8212;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Compiling 7 source files to /mnt/public/workspace/linux/hive-0.13/ql/target/classes&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt;                                                                         &lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; ------------------------------------------------------------------------&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Building Hive Service 0.13.0&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; ------------------------------------------------------------------------&lt;br/&gt;
Downloading: &lt;a href=&quot;http://www.datanucleus.org/downloads/maven2/org/apache/hive/hive-exec/0.13.0/hive-exec-0.13.0-tests.jar&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.datanucleus.org/downloads/maven2/org/apache/hive/hive-exec/0.13.0/hive-exec-0.13.0-tests.jar&lt;/a&gt;&lt;br/&gt;
Downloading: &lt;a href=&quot;http://repo.maven.apache.org/maven2/org/apache/hive/hive-exec/0.13.0/hive-exec-0.13.0-tests.jar&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://repo.maven.apache.org/maven2/org/apache/hive/hive-exec/0.13.0/hive-exec-0.13.0-tests.jar&lt;/a&gt;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; ------------------------------------------------------------------------&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Reactor Summary:&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; &lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Hive .............................................. SUCCESS &lt;span class=&quot;error&quot;&gt;&amp;#91;2.648s&amp;#93;&lt;/span&gt;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Hive Ant Utilities ................................ SUCCESS &lt;span class=&quot;error&quot;&gt;&amp;#91;1.184s&amp;#93;&lt;/span&gt;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Hive Shims Common ................................. SUCCESS &lt;span class=&quot;error&quot;&gt;&amp;#91;1.419s&amp;#93;&lt;/span&gt;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Hive Shims 0.20 ................................... SUCCESS &lt;span class=&quot;error&quot;&gt;&amp;#91;0.739s&amp;#93;&lt;/span&gt;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Hive Shims Secure Common .......................... SUCCESS &lt;span class=&quot;error&quot;&gt;&amp;#91;1.021s&amp;#93;&lt;/span&gt;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Hive Shims 0.20S .................................. SUCCESS &lt;span class=&quot;error&quot;&gt;&amp;#91;0.796s&amp;#93;&lt;/span&gt;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Hive Shims 0.23 ................................... SUCCESS &lt;span class=&quot;error&quot;&gt;&amp;#91;2.539s&amp;#93;&lt;/span&gt;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Hive Shims ........................................ SUCCESS &lt;span class=&quot;error&quot;&gt;&amp;#91;0.415s&amp;#93;&lt;/span&gt;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Hive Common ....................................... SUCCESS &lt;span class=&quot;error&quot;&gt;&amp;#91;4.014s&amp;#93;&lt;/span&gt;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Hive Serde ........................................ SUCCESS &lt;span class=&quot;error&quot;&gt;&amp;#91;1.722s&amp;#93;&lt;/span&gt;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Hive Metastore .................................... SUCCESS &lt;span class=&quot;error&quot;&gt;&amp;#91;2.513s&amp;#93;&lt;/span&gt;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Hive Query Language ............................... SUCCESS &lt;span class=&quot;error&quot;&gt;&amp;#91;7.495s&amp;#93;&lt;/span&gt;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Hive Service ...................................... FAILURE &lt;span class=&quot;error&quot;&gt;&amp;#91;2.921s&amp;#93;&lt;/span&gt;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Hive JDBC ......................................... SKIPPED&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Hive Beeline ...................................... SKIPPED&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Hive CLI .......................................... SKIPPED&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Hive Contrib ...................................... SKIPPED&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Hive HBase Handler ................................ SKIPPED&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Hive HCatalog ..................................... SKIPPED&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Hive HCatalog Core ................................ SKIPPED&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Hive HCatalog Pig Adapter ......................... SKIPPED&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Hive HCatalog Server Extensions ................... SKIPPED&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Hive HCatalog Webhcat Java Client ................. SKIPPED&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Hive HCatalog Webhcat ............................. SKIPPED&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Hive HCatalog HBase Storage Handler ............... SKIPPED&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Hive HWI .......................................... SKIPPED&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Hive ODBC ......................................... SKIPPED&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Hive Shims Aggregator ............................. SKIPPED&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Hive TestUtils .................................... SKIPPED&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Hive Packaging .................................... SKIPPED&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; ------------------------------------------------------------------------&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; BUILD FAILURE&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; ------------------------------------------------------------------------&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Total time: 31.330s&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Finished at: Mon Mar 17 00:05:57 HKT 2014&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Final Memory: 41M/236M&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; ------------------------------------------------------------------------&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; Failed to execute goal on project hive-service: Could not resolve dependencies for project org.apache.hive:hive-service:jar:0.13.0: Could not find artifact org.apache.hive:hive-exec:jar:tests:0.13.0 in datanucleus (&lt;a href=&quot;http://www.datanucleus.org/downloads/maven2&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www.datanucleus.org/downloads/maven2&lt;/a&gt;) -&amp;gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Help 1&amp;#93;&lt;/span&gt;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; &lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; To see the full stack trace of the errors, re-run Maven with the -e switch.&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; Re-run Maven using the -X switch to enable full debug logging.&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; &lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; For more information about the errors and possible solutions, please read the following articles:&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Help 1&amp;#93;&lt;/span&gt; &lt;a href=&quot;http://cwiki.apache.org/confluence/display/MAVEN/DependencyResolutionException&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://cwiki.apache.org/confluence/display/MAVEN/DependencyResolutionException&lt;/a&gt;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; &lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt; After correcting the problems, you can resume the build with the command&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;ERROR&amp;#93;&lt;/span&gt;   mvn &amp;lt;goals&amp;gt; -rf :hive-service&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12683047">HIVE-5972</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12661224">HIVE-4977</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12687767">HIVE-6160</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12617332" name="HIVE-3746.1.patch.txt" size="416858" author="navis" created="Fri, 6 Dec 2013 04:20:33 +0000"/>
                            <attachment id="12618843" name="HIVE-3746.2.patch.txt" size="417402" author="navis" created="Mon, 16 Dec 2013 02:03:51 +0000"/>
                            <attachment id="12618851" name="HIVE-3746.3.patch.txt" size="418287" author="navis" created="Mon, 16 Dec 2013 04:45:53 +0000"/>
                            <attachment id="12619227" name="HIVE-3746.4.patch.txt" size="517688" author="navis" created="Wed, 18 Dec 2013 02:02:45 +0000"/>
                            <attachment id="12619267" name="HIVE-3746.5.patch.txt" size="440651" author="navis" created="Wed, 18 Dec 2013 07:01:26 +0000"/>
                            <attachment id="12619276" name="HIVE-3746.6.patch.txt" size="440651" author="navis" created="Wed, 18 Dec 2013 08:37:55 +0000"/>
                            <attachment id="12620811" name="HIVE-3746.7.patch.txt" size="439835" author="navis" created="Mon, 30 Dec 2013 06:51:27 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>7.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 27 Nov 2012 21:24:37 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>292197</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 37 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0rsh3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>160257</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>