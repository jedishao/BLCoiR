<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sat Dec 03 01:10:51 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HIVE-578/HIVE-578.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HIVE-578] Refactor partition pruning code as an optimizer transformation</title>
                <link>https://issues.apache.org/jira/browse/HIVE-578</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Some bugs with partition pruning have been reported and the correct fix for many of them is to rewrite the partition pruning code as an optimizer transformation which gets kicked in after the predicate pushdown code. This refactor also uses the graph walker framework so that the partition pruning code gets consolidated well with the frameworks and does not work on the query block but rather works on the operator tree.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12428788">HIVE-578</key>
            <summary>Refactor partition pruning code as an optimizer transformation</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="athusoo">Ashish Thusoo</assignee>
                                    <reporter username="athusoo">Ashish Thusoo</reporter>
                        <labels>
                    </labels>
                <created>Wed, 24 Jun 2009 15:29:41 +0000</created>
                <updated>Sat, 17 Dec 2011 00:07:21 +0000</updated>
                            <resolved>Tue, 11 Aug 2009 02:06:50 +0000</resolved>
                                    <version>0.3.0</version>
                                    <fixVersion>0.4.0</fixVersion>
                                    <component>Query Processor</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="12723603" author="athusoo" created="Wed, 24 Jun 2009 15:32:29 +0000"  >&lt;p&gt;This a preliminary code patch. I have not yet plugged this into the SemanticAnalyzer phase but comments are welcome in order to catch any early omissions. This introduces test diffs which I will upload with the final patch.&lt;/p&gt;</comment>
                            <comment id="12723804" author="namit" created="Wed, 24 Jun 2009 23:45:08 +0000"  >&lt;p&gt;Some high-level comments:&lt;/p&gt;

&lt;p&gt;1. Can you share some expression walker code from Predicate Pushdown ? seems like a lot of common stuff.&lt;br/&gt;
2. Can you always assume that the predicate to be filtered will always be after the tablescan ? &lt;/p&gt;

&lt;p&gt;     Currently, all optimizations are independent of each other, and can be turned off - this way, &lt;br/&gt;
     you are dependent on a new feature &amp;#8211; may have stability issues.&lt;/p&gt;

&lt;p&gt;     I don&apos;t remember exactly how does predicate pushdown work - if a filter is already present immediately after the table&lt;br/&gt;
     scan, will the pushed up filter be merged. Is it pushed across user defined mappers/reducers ? Cant these things change&lt;br/&gt;
     in the future ?&lt;/p&gt;

&lt;p&gt;     It might be a good idea to look for TS*FIL, and then keep some mapping - or probably use the same mapping that Predicate&lt;br/&gt;
     pushdown has to figure out whether the filter is for the table under consideration.&lt;/p&gt;</comment>
                            <comment id="12724786" author="athusoo" created="Sat, 27 Jun 2009 01:31:06 +0000"  >&lt;p&gt;Actually the walker is already shared. However, the actions encapsulated in the ExprProcFactory etc. are by definition different from predicate pushdown and partition pruning so there is no sharing there.&lt;/p&gt;

&lt;p&gt;For 2 I checked with Prasad, and this assumption is correct. Also if there are multiple filter predicates after TS, there are all merged together and a new filter predicate is generated under the TS node, so looking for TS%FIL% should be sufficient.&lt;/p&gt;

&lt;p&gt;Regarding the optimization, I will keep the old pruning code around and toggle this new functionality only when predicate pushdown in enabled. Also I am going to add a number of tests to this before it goes in.&lt;/p&gt;
</comment>
                            <comment id="12731540" author="rsm" created="Wed, 15 Jul 2009 16:19:59 +0000"  >&lt;p&gt;I am trying to make similar changes to input pruning for sampling. &lt;/p&gt;

&lt;p&gt;A few questions:&lt;/p&gt;

&lt;p&gt;How come we have both tableDesc and tableScanDesc? I see that tableDesc is used in FetchWork and tableScanDesc in TableScanOperator. Does it make sense to make FetchWork use TableScanOperator (FetchOperator is not really an operator)? Then, merge tableDesc and tableScanDesc? This will also allow us to have the same code path for select * queries as well. Right now it looks like FetchOperator is duplicating some code. Also, sample pruning can use the merged tableScanDesc object to store the sampling information.&lt;/p&gt;</comment>
                            <comment id="12731564" author="athusoo" created="Wed, 15 Jul 2009 17:14:09 +0000"  >&lt;p&gt;yes that makes sense. In fact that needs to be done to make pruning work with select * from T where T.part = xyz kind of queries and I ran into that a few days back. I have punted that for the first stage and still rely on the old pruning stuff for such queries and when predicate pushdown is switched off. I have it mostly passing the tests except for sampling tests where in the predicate pushdown code seems not to be merging the two filter operators and I have made that assumption in my code. Will update today with the version sans the new tests and some cleanup. That way we can see how sampling stuff can work with this as well.&lt;/p&gt;</comment>
                            <comment id="12731696" author="athusoo" created="Wed, 15 Jul 2009 21:20:05 +0000"  >&lt;p&gt;Actually semantics with table sampling is a bit tricky in case the sampling function is non deterministic e.g (rand()). In that case there are two possibilities:&lt;/p&gt;

&lt;p&gt;1. The sampling is done on the whole table and then the predicate is applied which implies no partition pruning.&lt;br/&gt;
or&lt;br/&gt;
2. The sampling is done after the partition predicate is applied ie. it is done after pruning.&lt;/p&gt;

&lt;p&gt;2 is what we do today - I am ok with keeping that, but just wanted to call that out as a special case in the partition pruning code.&lt;/p&gt;</comment>
                            <comment id="12734421" author="athusoo" created="Thu, 23 Jul 2009 01:48:43 +0000"  >&lt;p&gt;New patch. This is now passing all the tests. I am going to add some more tests and refactor some of the state from ParseContext to tableScanDesc.&lt;/p&gt;</comment>
                            <comment id="12734428" author="prasadc" created="Thu, 23 Jul 2009 02:15:56 +0000"  >&lt;p&gt;Some comments.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;for(String partName: Hive.get().getPartitionNames(MetaStoreUtils.DEFAULT_DATABASE_NAME, tab.getName(), (short) -1))&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;1. should use tab.getDbName() instead.&lt;/p&gt;

&lt;p&gt;2. PartitionPruner::prune() should return partSpecs or partNames instead of partition objects and avoid calling getPartition() on all partNames. this would lower the unnecessary load on metastore. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (HiveConf.getBoolVar(hiveConf, HiveConf.ConfVars.HIVEOPTPPD)) {
       transformations.add(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; PredicatePushDown());
+      transformations.add(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; PartitionPruner());
     }

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;3. you should add new config param instead of piggybacking on PPD.&lt;/p&gt;

&lt;p&gt;4. isn&apos;t ColumnInfo.internalName unique among all tables? is tableName an additional information that is needed? Can&apos;t you get this info from RowResolver? Same question on exprNodeColDesc.&lt;/p&gt;

&lt;p&gt;5. don&apos;t understand the change in DefaultGraphWalker.java&lt;/p&gt;

&lt;p&gt;6. can&apos;t most of the functionality from ql/parse/PartitionPruner.java class can&apos;t be moved to the new class. atleast change the name so that it is not confusing as which pruner is doing what.&lt;/p&gt;

&lt;p&gt;7. import org.apache.hadoop.hive.ql.ppd.PredicatePushDown; is not needed in SemanticAnalyzer.java&lt;/p&gt;

&lt;p&gt;8. &lt;/p&gt;
</comment>
                            <comment id="12734800" author="namit" created="Thu, 23 Jul 2009 21:37:25 +0000"  >&lt;p&gt;Some more comments:&lt;/p&gt;

&lt;p&gt;1. Add lots of new tests&lt;br/&gt;
2. Wrong comments in OpProcFactory:&lt;/p&gt;

&lt;p&gt;      // If fop2 exists (i.e this is not the top level filter and fop2 is not&lt;br/&gt;
      // a sampling filter t1ehen we ignore the current filter&lt;br/&gt;
      if (fop2 != null &amp;amp;&amp;amp; !fop2.getConf().getIsSamplingPred())&lt;br/&gt;
        return null;&lt;/p&gt;

&lt;p&gt;      // ignore the predicate in case it is not a sampling predicate&lt;br/&gt;
      if (fop.getConf().getIsSamplingPred()) &lt;/p&gt;
{
        return null;
      }&lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
should be:&lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
      // If fop2 exists (i.e this is not the top level filter and fop2 is not&lt;br/&gt;
      // a sampling filter then we ignore the current filter&lt;br/&gt;
      if (fop2 != null &amp;amp;&amp;amp; !fop2.getConf().getIsSamplingPred())&lt;br/&gt;
        return null;&lt;br/&gt;
      &lt;br/&gt;
      // ignore the predicate in case it is a sampling predicate&lt;br/&gt;
      if (fop.getConf().getIsSamplingPred()) {
        return null;
      }


&lt;p&gt;3. ExprProcFactory.java:&lt;/p&gt;

&lt;p&gt;wrong parameters doc:&lt;br/&gt;
  /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Extracts pushdown predicates from the given list of predicate expression&lt;/li&gt;
	&lt;li&gt;@param opContext operator context used for resolving column references&lt;/li&gt;
	&lt;li&gt;@param op operator of the predicates being processed&lt;/li&gt;
	&lt;li&gt;@param preds&lt;/li&gt;
	&lt;li&gt;@return hasNonPartCols returns true/false depending upon whether this pred has a non partition column&lt;/li&gt;
	&lt;li&gt;@throws SemanticException&lt;br/&gt;
   */&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;4. ExprProcFactory: 104/146/182&lt;br/&gt;
shouldnt you check for exprNodeNullDesc also&lt;/p&gt;


&lt;p&gt;5. wrong comment: 63&lt;br/&gt;
    /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Converts the reference from child row resolver to current row resolver&lt;br/&gt;
     */&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12739946" author="athusoo" created="Thu, 6 Aug 2009 09:03:04 +0000"  >&lt;p&gt;@Namit&lt;br/&gt;
1. I have added a bunch of tests with the new patch.&lt;br/&gt;
2/3/5. Fixed the typos and wrong comments and javadocs&lt;br/&gt;
4. I don&apos;t think I have to check for exprNodeNullDesc. The unknown value of an operand is denoted by a null value in exprNodeConstantDesc. exprNodeNullDesc is used to denote the liternal NULL which should be treated as is for predicate pruning expression. e.g. if(ISNULL(NULL), 1, 0) should evaluate to 1 instead of unknown. So I think it is correct to not check the exprNodeNullDesc for the function processors. Thoughts?&lt;/p&gt;

&lt;p&gt;@Prasad&lt;br/&gt;
3. I have used the ppd parameter because I cannot do partition pruning without ppd. So even if I have a separate parameter it would still have to be checked along with ppd. At that point, it seems having a separate parameter for ppd does not add much value. Thoughts?&lt;br/&gt;
7. Removed&lt;br/&gt;
6. I have changed the name ot ASTPartitionPruner&lt;br/&gt;
5. This fixes a bug in DefaultGraphWalker. Due to this bug the operation stack would always get popped when you exited this call. As a result the stack would actually just contain the last node and not all the nodes on the path leading to the last node.&lt;br/&gt;
4. Which particular code file are you talking about here?&lt;br/&gt;
2. Not sure how that is different from what we were doing before?&lt;br/&gt;
1. Made the change&lt;/p&gt;
</comment>
                            <comment id="12739947" author="athusoo" created="Thu, 6 Aug 2009 09:05:09 +0000"  >&lt;p&gt;New patch with tests and changes.&lt;/p&gt;</comment>
                            <comment id="12740181" author="zshao" created="Thu, 6 Aug 2009 18:17:40 +0000"  >&lt;p&gt;We should add a separate parameter to enable the new partition pruner.&lt;/p&gt;

&lt;p&gt;Since the new partition pruner works only when ppd is enabled, we should have 3 possible modes instead of 4.&lt;br/&gt;
hive.opt.ppd=false, hive.partition.pruner=ast&lt;br/&gt;
hive.opt.ppd=true, hive.partition.pruner=ast&lt;br/&gt;
hive.opt.ppd=true, hive.partition.pruner=opt&lt;/p&gt;</comment>
                            <comment id="12740297" author="athusoo" created="Thu, 6 Aug 2009 22:56:13 +0000"  >&lt;p&gt;New patch where the ppr is controlled by a boolean parameter. It kicks in only if ppd and ppr are both true. If any one of them are not true the AST based approach is used.&lt;/p&gt;</comment>
                            <comment id="12741553" author="namit" created="Mon, 10 Aug 2009 21:09:25 +0000"  >&lt;p&gt;atching file ql/src/java/org/apache/hadoop/hive/ql/parse/PartitionPruner.java&lt;br/&gt;
(Stripping trailing CRs from patch.)&lt;br/&gt;
can&apos;t find file to patch at input line 27070&lt;br/&gt;
Perhaps you used the wrong -p or --strip option?&lt;br/&gt;
The text leading up to this was:&lt;br/&gt;
--------------------------&lt;/p&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;Index: ql/src/java/org/apache/hadoop/hive/ql/parse/ASTPartitionPruner.java&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;===================================================================&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;#8212; ql/src/java/org/apache/hadoop/hive/ql/parse/ASTPartitionPruner.java	(revision 801363)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+++ ql/src/java/org/apache/hadoop/hive/ql/parse/ASTPartitionPruner.java	(working copy)&lt;br/&gt;
--------------------------&lt;br/&gt;
File to patch: &lt;br/&gt;
Skip this patch? &lt;span class=&quot;error&quot;&gt;&amp;#91;y&amp;#93;&lt;/span&gt; &lt;br/&gt;
Skipping patch.&lt;br/&gt;
5 out of 5 hunks ignored&lt;br/&gt;
(Stripping trailing CRs from patch.)&lt;br/&gt;
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/TypeCheckProcFactory.java&lt;br/&gt;
(Stripping trailing CRs from patch.)&lt;br/&gt;
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java&lt;br/&gt;
(Stripping trailing CRs from patch.)&lt;br/&gt;
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/ParseContext.java&lt;br/&gt;
(Stripping trailing CRs from patch.)&lt;br/&gt;
patching file ql/src/java/org/apache/hadoop/hive/ql/parse/PrunedPartitionList.java&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;



&lt;p&gt;Problems in applying the patch - can you generate the patch again ?&lt;/p&gt;</comment>
                            <comment id="12741588" author="athusoo" created="Mon, 10 Aug 2009 22:10:08 +0000"  >&lt;p&gt;I think the patch is correct. Before applying the patch just do an svn mv on the old PartitionPruner.java to ASTPartitionPruner.java. Actually change the class name in eclipse and then apply the patch. That should work.&lt;/p&gt;</comment>
                            <comment id="12741660" author="namit" created="Tue, 11 Aug 2009 01:34:10 +0000"  >&lt;p&gt;Done - running tests right now&lt;/p&gt;</comment>
                            <comment id="12741663" author="namit" created="Tue, 11 Aug 2009 02:06:50 +0000"  >&lt;p&gt;Committed. Thanks Ashish&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12411888">HIVE-218</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12411658" name="patch-578.txt" size="69953" author="athusoo" created="Wed, 24 Jun 2009 15:32:29 +0000"/>
                            <attachment id="12414294" name="patch-578_1.txt" size="1079411" author="athusoo" created="Thu, 23 Jul 2009 01:48:43 +0000"/>
                            <attachment id="12415714" name="patch-578_2.txt" size="1283160" author="athusoo" created="Thu, 6 Aug 2009 09:05:09 +0000"/>
                            <attachment id="12415789" name="patch-578_3.txt" size="1311693" author="athusoo" created="Thu, 6 Aug 2009 22:56:13 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 24 Jun 2009 23:45:08 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>73434</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 17 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0lalj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>122367</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>