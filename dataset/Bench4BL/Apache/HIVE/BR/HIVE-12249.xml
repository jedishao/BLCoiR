<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sat Dec 03 22:50:46 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HIVE-12249/HIVE-12249.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HIVE-12249] Improve logging with tez</title>
                <link>https://issues.apache.org/jira/browse/HIVE-12249</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;We need to improve logging across the board. &lt;a href=&quot;https://issues.apache.org/jira/browse/TEZ-2851&quot; title=&quot;Support a way for upstream applications to pass in a caller context to Tez&quot; class=&quot;issue-link&quot; data-issue-key=&quot;TEZ-2851&quot;&gt;&lt;del&gt;TEZ-2851&lt;/del&gt;&lt;/a&gt; added a caller context so that one can correlate logs with the application. This jira adds a new configuration for users that can be used to correlate the logs.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12907548">HIVE-12249</key>
            <summary>Improve logging with tez</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="vikram.dixit">Vikram Dixit K</assignee>
                                    <reporter username="vikram.dixit">Vikram Dixit K</reporter>
                        <labels>
                            <label>TODOC2.0</label>
                    </labels>
                <created>Fri, 23 Oct 2015 20:56:25 +0000</created>
                <updated>Wed, 22 Jun 2016 01:10:37 +0000</updated>
                            <resolved>Fri, 30 Oct 2015 22:05:35 +0000</resolved>
                                    <version>1.2.1</version>
                                    <fixVersion>2.0.0</fixVersion>
                                    <component>Tez</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="14971875" author="sershe" created="Fri, 23 Oct 2015 21:23:45 +0000"  >&lt;p&gt;SHould there be spaces when concatenating the new thread id? Can you post RB?&lt;br/&gt;
Can you also show an example of how logs change? I skimmed the patch and didn&apos;t quite understand - does user have to set an ID in config to track logs?&lt;/p&gt;</comment>
                            <comment id="14972085" author="vikram.dixit" created="Fri, 23 Oct 2015 23:17:44 +0000"  >&lt;p&gt;Update with a test.&lt;/p&gt;

&lt;p&gt;Sample output&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
vikram$ grep -r mrrTest * | grep syslog
target/hive/hive-logDir-nm-0_3/application_1445638125157_0001/container_1445638125157_0001_01_000001/syslog:2015-10-23T15:10:22,104 INFO [IPC Server handler 0 on 56693] app.DAGAppMaster: Running DAG: vikram_20151023151021_35b01963-5cf6-4dcc-b6ef-5279fb08e2a9:32, callerContext=context=HIVE, callerType=HIVE_QUERY_ID, callerId=mrrTestmainvikram_20151023151021_35b01963-5cf6-4dcc-b6ef-5279fb08e2a9, blob=
target/hive/hive-logDir-nm-0_3/application_1445638125157_0001/container_1445638125157_0001_01_000001/syslog:2015-10-23T15:10:28,274 INFO [IPC Server handler 0 on 56693] app.DAGAppMaster: Running DAG: vikram_20151023151028_024fa54e-2d53-4c20-8d82-f282cd438955:34, callerContext=context=HIVE, callerType=HIVE_QUERY_ID, callerId=mrrTestmainvikram_20151023151028_024fa54e-2d53-4c20-8d82-f282cd438955, blob=
target/hive/hive-logDir-nm-0_3/application_1445638125157_0001/container_1445638125157_0001_01_000001/syslog:2015-10-23T15:10:30,430 INFO [IPC Server handler 0 on 56693] app.DAGAppMaster: Running DAG: vikram_20151023151030_2c0cd0e9-3174-42f3-8258-205b480bde3f:36, callerContext=context=HIVE, callerType=HIVE_QUERY_ID, callerId=mrrTestmainvikram_20151023151030_2c0cd0e9-3174-42f3-8258-205b480bde3f, blob=
target/hive/hive-logDir-nm-0_3/application_1445638125157_0001/container_1445638125157_0001_01_000001/syslog:2015-10-23T15:10:32,802 INFO [IPC Server handler 0 on 56693] app.DAGAppMaster: Running DAG: vikram_20151023151032_2c6065c2-d54b-47f1-921f-f44e678bb942:38, callerContext=context=HIVE, callerType=HIVE_QUERY_ID, callerId=mrrTestmainvikram_20151023151032_2c6065c2-d54b-47f1-921f-f44e678bb942, blob=
vikram$ grep -r Test2 * | grep syslog
target/hive/hive-logDir-nm-0_3/application_1445638125157_0001/container_1445638125157_0001_01_000001/syslog:2015-10-23T15:10:34,545 INFO [IPC Server handler 0 on 56693] app.DAGAppMaster: Running DAG: vikram_20151023151034_0db3180c-4ccc-4076-81ba-217da09a4eb9:40, callerContext=context=HIVE, callerType=HIVE_QUERY_ID, callerId=Test2mainvikram_20151023151034_0db3180c-4ccc-4076-81ba-217da09a4eb9, blob=
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In the client logs:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2015-10-23T15:10:34,278 INFO  [Test2main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(117)) - &amp;lt;PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver&amp;gt;
2015-10-23T15:10:34,278 DEBUG [Test2main]: hbase.HBaseReadWrite (HBaseReadWrite.java:flushCatalogCache(1909)) - Dumping metric: table cache hits 5
2015-10-23T15:10:34,278 DEBUG [Test2main]: hbase.HBaseReadWrite (HBaseReadWrite.java:flushCatalogCache(1909)) - Dumping metric: table cache misses 1
2015-10-23T15:10:34,278 DEBUG [Test2main]: hbase.HBaseReadWrite (HBaseReadWrite.java:flushCatalogCache(1909)) - Dumping metric: table cache overflows 0
2015-10-23T15:10:34,278 DEBUG [Test2main]: hbase.HBaseReadWrite (HBaseReadWrite.java:flushCatalogCache(1909)) - Dumping metric: partition cache hits 0
2015-10-23T15:10:34,278 DEBUG [Test2main]: hbase.HBaseReadWrite (HBaseReadWrite.java:flushCatalogCache(1909)) - Dumping metric: partition cache misses 0
2015-10-23T15:10:34,278 DEBUG [Test2main]: hbase.HBaseReadWrite (HBaseReadWrite.java:flushCatalogCache(1909)) - Dumping metric: partition cache overflows 0
2015-10-23T15:10:34,279 DEBUG [Test2main]: hbase.HBaseReadWrite (HBaseReadWrite.java:flushCatalogCache(1909)) - Dumping metric: storage descriptor cache hits 0
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14972111" author="vikram.dixit" created="Fri, 23 Oct 2015 23:32:02 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sershe&quot; class=&quot;user-hover&quot; rel=&quot;sershe&quot;&gt;Sergey Shelukhin&lt;/a&gt; I think the addition of a space may be a good idea.&lt;/p&gt;

&lt;p&gt;Yes. The user needs to set an id for tracking. I can maybe include the session id as a default in the absence of an id. Any other defaults that you can think of?&lt;/p&gt;</comment>
                            <comment id="14972139" author="sershe" created="Fri, 23 Oct 2015 23:57:28 +0000"  >&lt;p&gt;What is the usage pattern? You specify set ...id = blah on CLI and you get it in query logs?&lt;br/&gt;
I assume it is only helpful for HS2 use case where Tez AMs can be reused? Otherwise all the logs are your logs anyway.&lt;/p&gt;

&lt;p&gt;Also is it possible to post RB?&lt;/p&gt;</comment>
                            <comment id="14972158" author="vikram.dixit" created="Sat, 24 Oct 2015 00:11:46 +0000"  >&lt;p&gt;Yes. The expectation is that a client such as Oozie would also be logging with the same id and when hive uses the same as well, we can correlate all the logs.&lt;/p&gt;

&lt;p&gt;This is also helpful for the oozie use case where there may be multiple workflows for which a user can configure different ids. &lt;/p&gt;</comment>
                            <comment id="14973105" author="vikram.dixit" created="Sun, 25 Oct 2015 07:04:27 +0000"  >&lt;p&gt;Address Sergey&apos;s comments.&lt;/p&gt;</comment>
                            <comment id="14973574" author="sershe" created="Mon, 26 Oct 2015 02:39:24 +0000"  >&lt;p&gt;It appears not all comments are addressed. My main question is whether this logic should run at all (e.g. set context) if the id is not set. The rest are nits about adding spaces and stuff&lt;/p&gt;</comment>
                            <comment id="14973594" author="vikram.dixit" created="Mon, 26 Oct 2015 03:19:21 +0000"  >&lt;p&gt;I think we should set a context regardless of whether the user configures it or not. If the user has setup one we use it else we use the session id.&lt;/p&gt;</comment>
                            <comment id="14974404" author="hiveqa" created="Mon, 26 Oct 2015 15:39:40 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12768682/HIVE-12249.5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12768682/HIVE-12249.5.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to build exiting with an error&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5795/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5795/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5795/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5795/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5795/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5795/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;**** This message was trimmed, see log for full details ****

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-shims ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-shims ---
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/shims/aggregator/src/test/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-shims ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/shims/aggregator/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/shims/aggregator/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/shims/aggregator/target/tmp/conf
     [copy] Copying 14 files to /data/hive-ptest/working/apache-github-source-source/shims/aggregator/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-shims ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-shims ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-shims ---
[INFO] Building jar: /data/hive-ptest/working/apache-github-source-source/shims/aggregator/target/hive-shims-2.0.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-shims ---
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-shims ---
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/shims/aggregator/target/hive-shims-2.0.0-SNAPSHOT.jar to /home/hiveptest/.m2/repository/org/apache/hive/hive-shims/2.0.0-SNAPSHOT/hive-shims-2.0.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/shims/aggregator/pom.xml to /home/hiveptest/.m2/repository/org/apache/hive/hive-shims/2.0.0-SNAPSHOT/hive-shims-2.0.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Storage API 2.0.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-storage-api ---
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/storage-api/target
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/storage-api (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ hive-storage-api ---
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-storage-api ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-storage-api ---
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/storage-api/src/main/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-storage-api ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-storage-api ---
[INFO] Compiling 25 source files to /data/hive-ptest/working/apache-github-source-source/storage-api/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-storage-api ---
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /data/hive-ptest/working/apache-github-source-source/storage-api/src/test/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-storage-api ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/storage-api/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/storage-api/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/storage-api/target/tmp/conf
     [copy] Copying 14 files to /data/hive-ptest/working/apache-github-source-source/storage-api/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-storage-api ---
[INFO] Compiling 4 source files to /data/hive-ptest/working/apache-github-source-source/storage-api/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-storage-api ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-storage-api ---
[INFO] Building jar: /data/hive-ptest/working/apache-github-source-source/storage-api/target/hive-storage-api-2.0.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-storage-api ---
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-storage-api ---
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/storage-api/target/hive-storage-api-2.0.0-SNAPSHOT.jar to /home/hiveptest/.m2/repository/org/apache/hive/hive-storage-api/2.0.0-SNAPSHOT/hive-storage-api-2.0.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/storage-api/pom.xml to /home/hiveptest/.m2/repository/org/apache/hive/hive-storage-api/2.0.0-SNAPSHOT/hive-storage-api-2.0.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Common 2.0.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-common ---
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/common/target
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/common (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ hive-common ---
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (generate-version-annotation) @ hive-common ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-common ---
[INFO] Source directory: /data/hive-ptest/working/apache-github-source-source/common/src/gen added.
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-common ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-common ---
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-common ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-common ---
[INFO] Compiling 81 source files to /data/hive-ptest/working/apache-github-source-source/common/target/classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] /data/hive-ptest/working/apache-github-source-source/common/src/java/org/apache/hadoop/hive/common/JvmPauseMonitor.java: /data/hive-ptest/working/apache-github-source-source/common/src/java/org/apache/hadoop/hive/common/JvmPauseMonitor.java uses or overrides a deprecated API.
[WARNING] /data/hive-ptest/working/apache-github-source-source/common/src/java/org/apache/hadoop/hive/common/JvmPauseMonitor.java: Recompile with -Xlint:deprecation for details.
[WARNING] /data/hive-ptest/working/apache-github-source-source/common/src/java/org/apache/hadoop/hive/common/ObjectPair.java: Some input files use unchecked or unsafe operations.
[WARNING] /data/hive-ptest/working/apache-github-source-source/common/src/java/org/apache/hadoop/hive/common/ObjectPair.java: Recompile with -Xlint:unchecked for details.
[INFO] 4 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-github-source-source/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java:[2386,109] non-static variable LOG_PREFIX_LENGTH cannot be referenced from a static context
[INFO] 1 error
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [13.243s]
[INFO] Hive Shims Common ................................. SUCCESS [14.363s]
[INFO] Hive Shims 0.20S .................................. SUCCESS [3.682s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [11.965s]
[INFO] Hive Shims Scheduler .............................. SUCCESS [2.375s]
[INFO] Hive Shims ........................................ SUCCESS [3.604s]
[INFO] Hive Storage API .................................. SUCCESS [4.493s]
[INFO] Hive Common ....................................... FAILURE [19.913s]
[INFO] Hive Serde ........................................ SKIPPED
[INFO] Hive Metastore .................................... SKIPPED
[INFO] Hive Ant Utilities ................................ SKIPPED
[INFO] Hive Llap Client .................................. SKIPPED
[INFO] Spark Remote Client ............................... SKIPPED
[INFO] Hive Query Language ............................... SKIPPED
[INFO] Hive Service ...................................... SKIPPED
[INFO] Hive Accumulo Handler ............................. SKIPPED
[INFO] Hive JDBC ......................................... SKIPPED
[INFO] Hive Beeline ...................................... SKIPPED
[INFO] Hive CLI .......................................... SKIPPED
[INFO] Hive Contrib ...................................... SKIPPED
[INFO] Hive HBase Handler ................................ SKIPPED
[INFO] Hive HCatalog ..................................... SKIPPED
[INFO] Hive HCatalog Core ................................ SKIPPED
[INFO] Hive HCatalog Pig Adapter ......................... SKIPPED
[INFO] Hive HCatalog Server Extensions ................... SKIPPED
[INFO] Hive HCatalog Webhcat Java Client ................. SKIPPED
[INFO] Hive HCatalog Webhcat ............................. SKIPPED
[INFO] Hive HCatalog Streaming ........................... SKIPPED
[INFO] Hive HPL/SQL ...................................... SKIPPED
[INFO] Hive HWI .......................................... SKIPPED
[INFO] Hive ODBC ......................................... SKIPPED
[INFO] Hive Shims Aggregator ............................. SKIPPED
[INFO] Hive TestUtils .................................... SKIPPED
[INFO] Hive Packaging .................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 1:16.983s
[INFO] Finished at: Mon Oct 26 11:39:39 EDT 2015
[INFO] Final Memory: 50M/158M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hive-common: Compilation failure
[ERROR] /data/hive-ptest/working/apache-github-source-source/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java:[2386,109] non-static variable LOG_PREFIX_LENGTH cannot be referenced from a static context
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-common
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12768682 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14974683" author="hagleitn" created="Mon, 26 Oct 2015 18:03:31 +0000"  >&lt;p&gt;fix compile issue in latest patch (make LENGTH static).&lt;/p&gt;</comment>
                            <comment id="14975290" author="sershe" created="Mon, 26 Oct 2015 22:57:52 +0000"  >&lt;p&gt;+1 based on latest RB, pending tests&lt;/p&gt;</comment>
                            <comment id="14975712" author="hiveqa" created="Tue, 27 Oct 2015 04:30:48 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12768840/HIVE-12249.7.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12768840/HIVE-12249.7.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 1 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 69 failed/errored test(s), 9630 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_alter_merge_2_orc
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_alter_merge_orc
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_alter_merge_stats_orc
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_create_merge_compressed
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_explainuser_1
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_orc_merge5
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_orc_merge6
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_orc_merge7
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_orc_merge8
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_orc_merge9
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_orc_merge_incompat1
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_orc_merge_incompat2
org.apache.hadoop.hive.hwi.TestHWISessionManager.testHiveDriver
org.apache.hadoop.hive.ql.io.orc.TestJsonFileDump.testJsonDump
org.apache.hive.beeline.TestBeeLineWithArgs.org.apache.hive.beeline.TestBeeLineWithArgs
org.apache.hive.jdbc.TestJdbcWithLocalClusterSpark.org.apache.hive.jdbc.TestJdbcWithLocalClusterSpark
org.apache.hive.jdbc.TestJdbcWithMiniHS2.org.apache.hive.jdbc.TestJdbcWithMiniHS2
org.apache.hive.jdbc.TestJdbcWithMiniMr.org.apache.hive.jdbc.TestJdbcWithMiniMr
org.apache.hive.jdbc.TestMultiSessionsHS2WithLocalClusterSpark.org.apache.hive.jdbc.TestMultiSessionsHS2WithLocalClusterSpark
org.apache.hive.jdbc.TestNoSaslAuth.org.apache.hive.jdbc.TestNoSaslAuth
org.apache.hive.jdbc.TestSSL.testConnectionMismatch
org.apache.hive.jdbc.TestSSL.testInvalidConfig
org.apache.hive.jdbc.TestSSL.testSSLConnectionWithProperty
org.apache.hive.jdbc.TestSSL.testSSLConnectionWithURL
org.apache.hive.jdbc.TestSSL.testSSLFetch
org.apache.hive.jdbc.TestSSL.testSSLFetchHttp
org.apache.hive.jdbc.TestSSL.testSSLVersion
org.apache.hive.jdbc.TestSchedulerQueue.testFairSchedulerPrimaryQueueMapping
org.apache.hive.jdbc.TestSchedulerQueue.testFairSchedulerQueueMapping
org.apache.hive.jdbc.TestSchedulerQueue.testFairSchedulerSecondaryQueueMapping
org.apache.hive.jdbc.TestSchedulerQueue.testQueueMappingCheckDisabled
org.apache.hive.jdbc.authorization.TestHS2AuthzContext.org.apache.hive.jdbc.authorization.TestHS2AuthzContext
org.apache.hive.jdbc.authorization.TestHS2AuthzSessionContext.org.apache.hive.jdbc.authorization.TestHS2AuthzSessionContext
org.apache.hive.jdbc.authorization.TestJdbcMetadataApiAuth.org.apache.hive.jdbc.authorization.TestJdbcMetadataApiAuth
org.apache.hive.jdbc.authorization.TestJdbcWithSQLAuthUDFBlacklist.testBlackListedUdfUsage
org.apache.hive.jdbc.authorization.TestJdbcWithSQLAuthorization.org.apache.hive.jdbc.authorization.TestJdbcWithSQLAuthorization
org.apache.hive.jdbc.miniHS2.TestHiveServer2.org.apache.hive.jdbc.miniHS2.TestHiveServer2
org.apache.hive.jdbc.miniHS2.TestHiveServer2SessionTimeout.testConnection
org.apache.hive.jdbc.miniHS2.TestMiniHS2.testConfInSession
org.apache.hive.minikdc.TestHs2HooksWithMiniKdc.org.apache.hive.minikdc.TestHs2HooksWithMiniKdc
org.apache.hive.minikdc.TestJdbcWithMiniKdc.org.apache.hive.minikdc.TestJdbcWithMiniKdc
org.apache.hive.minikdc.TestJdbcWithMiniKdcCookie.org.apache.hive.minikdc.TestJdbcWithMiniKdcCookie
org.apache.hive.minikdc.TestJdbcWithMiniKdcSQLAuthBinary.org.apache.hive.minikdc.TestJdbcWithMiniKdcSQLAuthBinary
org.apache.hive.minikdc.TestJdbcWithMiniKdcSQLAuthHttp.org.apache.hive.minikdc.TestJdbcWithMiniKdcSQLAuthHttp
org.apache.hive.service.TestHS2ImpersonationWithRemoteMS.org.apache.hive.service.TestHS2ImpersonationWithRemoteMS
org.apache.hive.service.cli.TestEmbeddedThriftBinaryCLIService.testConfOverlay
org.apache.hive.service.cli.TestEmbeddedThriftBinaryCLIService.testExecuteStatement
org.apache.hive.service.cli.TestEmbeddedThriftBinaryCLIService.testExecuteStatementAsync
org.apache.hive.service.cli.TestEmbeddedThriftBinaryCLIService.testExecuteStatementParallel
org.apache.hive.service.cli.TestEmbeddedThriftBinaryCLIService.testGetFunctions
org.apache.hive.service.cli.TestEmbeddedThriftBinaryCLIService.testGetInfo
org.apache.hive.service.cli.TestEmbeddedThriftBinaryCLIService.testOpenSession
org.apache.hive.service.cli.operation.TestOperationLoggingAPIWithMr.org.apache.hive.service.cli.operation.TestOperationLoggingAPIWithMr
org.apache.hive.service.cli.operation.TestOperationLoggingAPIWithTez.org.apache.hive.service.cli.operation.TestOperationLoggingAPIWithTez
org.apache.hive.service.cli.operation.TestOperationLoggingLayout.org.apache.hive.service.cli.operation.TestOperationLoggingLayout
org.apache.hive.service.cli.session.TestSessionGlobalInitFile.testSessionGlobalInitDir
org.apache.hive.service.cli.session.TestSessionGlobalInitFile.testSessionGlobalInitFile
org.apache.hive.service.cli.session.TestSessionGlobalInitFile.testSessionGlobalInitFileAndConfOverlay
org.apache.hive.service.cli.session.TestSessionGlobalInitFile.testSessionGlobalInitFileWithUser
org.apache.hive.service.cli.session.TestSessionHooks.testProxyUser
org.apache.hive.service.cli.session.TestSessionHooks.testSessionHook
org.apache.hive.service.cli.thrift.TestThriftBinaryCLIService.testExecuteStatement
org.apache.hive.service.cli.thrift.TestThriftBinaryCLIService.testExecuteStatementAsync
org.apache.hive.service.cli.thrift.TestThriftBinaryCLIService.testGetFunctions
org.apache.hive.service.cli.thrift.TestThriftBinaryCLIService.testOpenSession
org.apache.hive.service.cli.thrift.TestThriftHttpCLIService.testExecuteStatement
org.apache.hive.service.cli.thrift.TestThriftHttpCLIService.testExecuteStatementAsync
org.apache.hive.service.cli.thrift.TestThriftHttpCLIService.testGetFunctions
org.apache.hive.service.cli.thrift.TestThriftHttpCLIService.testOpenSession
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5804/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5804/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5804/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5804/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5804/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5804/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 69 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12768840 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14975800" author="vikram.dixit" created="Tue, 27 Oct 2015 06:25:18 +0000"  >&lt;p&gt;Fix for unit test failures.&lt;/p&gt;</comment>
                            <comment id="14977725" author="hiveqa" created="Wed, 28 Oct 2015 04:55:14 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12768949/HIVE-12249.10.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12768949/HIVE-12249.10.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 1 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 4 failed/errored test(s), 9711 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_index_bitmap_auto_partitioned
org.apache.hadoop.hive.hwi.TestHWISessionManager.testHiveDriver
org.apache.hadoop.hive.ql.io.orc.TestJsonFileDump.testJsonDump
org.apache.hive.jdbc.TestSSL.testSSLVersion
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5821/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5821/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5821/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/5821/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5821/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-5821/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12768949 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="14979111" author="vikram.dixit" created="Wed, 28 Oct 2015 19:43:43 +0000"  >&lt;p&gt;Test failures unrelated.&lt;/p&gt;</comment>
                            <comment id="14983876" author="lefty@hortonworks.com" created="Sat, 31 Oct 2015 07:06:17 +0000"  >&lt;p&gt;Doc note:  This adds configuration parameter &lt;b&gt;hive.log.trace.id&lt;/b&gt; to HiveConf.java, so it needs to be documented in the wiki for release 2.0.0.&lt;/p&gt;

&lt;p&gt;Should it go in the Tez section of Configuration Properties, or in the general section?  If it belongs with Tez, it could go either at the end of the section or after &lt;b&gt;hive.tez.log.level&lt;/b&gt;.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-QueryandDDLExecution&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Configuration Properties &amp;#8211; Query and DDL Execution &lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-Tez&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Configuration Properties &amp;#8211; Tez &lt;/a&gt;
	&lt;ul&gt;
		&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.tez.log.level&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;hive.tez.log.level &lt;/a&gt;&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;

</comment>
                            <comment id="15001396" author="vikram.dixit" created="Thu, 12 Nov 2015 00:23:24 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=leftylev&quot; class=&quot;user-hover&quot; rel=&quot;leftylev&quot;&gt;Lefty Leverenz&lt;/a&gt; This configuration is a general one. It can be used by any upstream project such as Oozie or templeton to configure hive to set the logging. The config helps us track the entire flow - from oozie to hive to hdfs/yarn/tez. This combined with &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-12254&quot; title=&quot;Improve logging with yarn/hdfs&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-12254&quot;&gt;HIVE-12254&lt;/a&gt; makes it generic.&lt;/p&gt;</comment>
                            <comment id="15001772" author="lefty@hortonworks.com" created="Thu, 12 Nov 2015 07:00:38 +0000"  >&lt;p&gt;Thanks Vikram!&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12901752">HDFS-9184</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12913417">HIVE-12419</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12768403" name="HIVE-12249.1.patch" size="10227" author="vikram.dixit" created="Fri, 23 Oct 2015 20:57:08 +0000"/>
                            <attachment id="12768949" name="HIVE-12249.10.patch" size="11852" author="vikram.dixit" created="Tue, 27 Oct 2015 10:46:06 +0000"/>
                            <attachment id="12768406" name="HIVE-12249.2.patch" size="10127" author="vikram.dixit" created="Fri, 23 Oct 2015 21:02:44 +0000"/>
                            <attachment id="12768441" name="HIVE-12249.3.patch" size="10730" author="vikram.dixit" created="Fri, 23 Oct 2015 23:17:44 +0000"/>
                            <attachment id="12768588" name="HIVE-12249.4.patch" size="11423" author="vikram.dixit" created="Sun, 25 Oct 2015 07:04:27 +0000"/>
                            <attachment id="12768682" name="HIVE-12249.5.patch" size="11452" author="vikram.dixit" created="Mon, 26 Oct 2015 09:26:43 +0000"/>
                            <attachment id="12768772" name="HIVE-12249.6.patch" size="11459" author="hagleitn" created="Mon, 26 Oct 2015 18:02:58 +0000"/>
                            <attachment id="12768840" name="HIVE-12249.7.patch" size="11578" author="vikram.dixit" created="Mon, 26 Oct 2015 22:03:36 +0000"/>
                            <attachment id="12768910" name="HIVE-12249.8.patch" size="11652" author="vikram.dixit" created="Tue, 27 Oct 2015 06:25:18 +0000"/>
                            <attachment id="12768927" name="HIVE-12249.9.patch" size="11772" author="vikram.dixit" created="Tue, 27 Oct 2015 08:22:19 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>10.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 23 Oct 2015 21:23:45 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 3 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2ngkn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>