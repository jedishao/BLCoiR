<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 02 06:09:25 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HIVE-13395/HIVE-13395.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HIVE-13395] Lost Update problem in ACID</title>
                <link>https://issues.apache.org/jira/browse/HIVE-13395</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;ACID users can run into Lost Update problem.&lt;br/&gt;
In Hive 1.2, Driver.recordValidTxns() (which records the snapshot to use for the query) is called in Driver.compile().&lt;/p&gt;

&lt;p&gt;Now suppose to concurrent &quot;update T set x = x + 1&quot; are executed.  (for simplicity assume there is exactly 1 row in T)&lt;/p&gt;

&lt;p&gt;What can happen is that both compile at the same time (more precisely before acquireLocksAndOpenTxn() in runInternal() is called) and thus will lock in the same snapshot, say the value of x = 7 in this snapshot.&lt;/p&gt;

&lt;p&gt;Now 1 will get the lock on the row, the second will block.  &lt;br/&gt;
Now 1, makes x = 8 and commits.&lt;br/&gt;
Now 2 proceeds and makes x = 8 again since in it&apos;s snapshot x is still 7.&lt;/p&gt;

&lt;p&gt;This specific issue is solved in Hive 1.3/2.0 (&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-11077&quot; title=&quot;Add support in parser and wire up to txn manager&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-11077&quot;&gt;&lt;del&gt;HIVE-11077&lt;/del&gt;&lt;/a&gt; which is a large patch that deals with multi-statement txns) by moving recordValidTxns() after locks are acquired which reduces the likelihood of this but doesn&apos;t eliminate the problem.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Even in 1.3 version of the code, you could have the same issue.  Assume the same 2 queries:&lt;br/&gt;
Both start a txn, say txnid 9 and 10.  Say 10 gets the lock first, 9 blocks.&lt;br/&gt;
10 updates the row (so x = 8) and thus ReaderKey.currentTransactionId=10.&lt;br/&gt;
10 commits.&lt;br/&gt;
Now 9 can proceed and it will get a snapshot that includes 10, i.e. it will see x = 8 and it will write x = 9, but it will set ReaderKey.currentTransactionId = 9.  Thus when merge logic runs, it will see x = 8 is the later version of this row, i.e. lost update.&lt;/p&gt;

&lt;p&gt;The problem is that locks alone are insufficient for MVCC architecture.  &lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;At lower level Row ID has (originalTransactionId, rowid, bucket id, currentTransactionId) and since on update/delete we do a table scan, we could check that we are about to write a row with currentTransactionId &amp;lt; (currentTransactionId of row we&apos;ve read) and fail the query.  Currently, currentTransactionId is not surfaced at higher level where this check can be made.&lt;/p&gt;

&lt;p&gt;This would not work (efficiently) longer term where we want to support fast update on user defined PK vis streaming ingest.&lt;/p&gt;

&lt;p&gt;Also, this would not work with multi statement txns since in that case we&apos;d lock in the snapshot at the start of the txn, but then 2nd, 3rd etc queries would use the same snapshot and the locks for these queries would be acquired after the snapshot is locked in so this would be the same situation as pre &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-11077&quot; title=&quot;Add support in parser and wire up to txn manager&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-11077&quot;&gt;&lt;del&gt;HIVE-11077&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;A more robust solution (commonly used with MVCC) is to keep track of start and commit time (logical counter) or each transaction to detect if two txns overlap.  The 2nd part is to keep track of write-set, i.e. which data (rows, partitions, whatever appropriate level of granularity is) were modified by any txn and if 2 txns overlap in time and wrote the same element, abort later one.  This is called first-committer-wins rule.  This requires a MS DB schema change&lt;/p&gt;

&lt;p&gt;It would be most convenient to use the same sequence for txnId, start and commit time (in which case txnid=start time).  In this case we&apos;d need to add 1 filed to TXNS table.  The complication here is that we&apos;ll be using elements of the sequence faster and they are used as part of file name of delta and base dir and currently limited to 7 digits which can be exceeded.  So this would require some thought to handling upgrade/migration.&lt;/p&gt;

&lt;p&gt;Also, write-set tracking requires either additional metastore table or keeping info in HIVE_LOCKS around longer with new state.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;In the short term, on SQL side of things we could (in auto commit mode only)&lt;br/&gt;
acquire the locks first and then open the txn AND update these locks with txn id.&lt;br/&gt;
This implies another Thrift change to pass in lockId to openTxn.&lt;/p&gt;

&lt;p&gt;The same would not work for Streaming API since it opens several txns at once and then acquires locks for each.&lt;br/&gt;
(Not sure if that&apos;s is an issue or not since Streaming only does Insert).&lt;/p&gt;

&lt;p&gt;Either way this feels hacky.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Here is one simple example why we need Write-Set tracking for multi-statement txns&lt;/p&gt;

&lt;p&gt;Consider transactions T &lt;sub&gt;1&lt;/sub&gt; and T &lt;sub&gt;2&lt;/sub&gt;:&lt;br/&gt;
T &lt;sub&gt;1&lt;/sub&gt;: r &lt;sub&gt;1&lt;/sub&gt;[x] -&amp;gt; w &lt;sub&gt;1&lt;/sub&gt;[y] -&amp;gt; c &lt;sub&gt;1&lt;/sub&gt; &lt;br/&gt;
T &lt;sub&gt;2&lt;/sub&gt;: w &lt;sub&gt;2&lt;/sub&gt;[x] -&amp;gt; w &lt;sub&gt;2&lt;/sub&gt;[y] -&amp;gt; c &lt;sub&gt;2&lt;/sub&gt;  &lt;/p&gt;

&lt;p&gt;Suppose the order of operations is r &lt;sub&gt;1&lt;/sub&gt;[x] w &lt;sub&gt;2&lt;/sub&gt;[x].... then a conventional R/W lock manager w/o MVCSS will block the write from T &lt;sub&gt;2&lt;/sub&gt; &lt;/p&gt;

&lt;p&gt;With MVCC we don&apos;t want readers to interfere with writers and so the following schedule is possible (because Hive&apos;s semi-shared (write) don&apos;t conflict with shared (read) locks) in Hive&apos;s current implementation.&lt;/p&gt;

&lt;p&gt;r &lt;sub&gt;1&lt;/sub&gt;[x] w &lt;sub&gt;2&lt;/sub&gt;[x] w &lt;sub&gt;2&lt;/sub&gt;[y] c &lt;sub&gt;2&lt;/sub&gt; w &lt;sub&gt;1&lt;/sub&gt;[y] c &lt;sub&gt;1&lt;/sub&gt;&lt;/p&gt;

&lt;p&gt;By the time w &lt;sub&gt;1&lt;/sub&gt;[y] happens, T &lt;sub&gt;2&lt;/sub&gt; has committed and released it&apos;s locks.  But this is a lost update if c &lt;sub&gt;1&lt;/sub&gt; is allowed to commit.  That&apos;s where write-set tracking comes in.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12954819">HIVE-13395</key>
            <summary>Lost Update problem in ACID</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ekoifman">Eugene Koifman</assignee>
                                    <reporter username="ekoifman">Eugene Koifman</reporter>
                        <labels>
                    </labels>
                <created>Thu, 31 Mar 2016 00:57:49 +0000</created>
                <updated>Sun, 21 Aug 2016 07:59:06 +0000</updated>
                            <resolved>Thu, 5 May 2016 22:29:55 +0000</resolved>
                                    <version>1.2.0</version>
                    <version>2.0.0</version>
                                    <fixVersion>1.3.0</fixVersion>
                    <fixVersion>2.1.0</fixVersion>
                                    <component>Transactions</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                <comments>
                            <comment id="15242131" author="hiveqa" created="Thu, 14 Apr 2016 23:34:52 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12798855/HIVE-13395.6.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12798855/HIVE-13395.6.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to no test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 4 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-METASTORE-Test/139/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-METASTORE-Test/139/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-METASTORE-Test/139/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-METASTORE-Test/139/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-METASTORE-Test-139/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-METASTORE-Test-139/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;LXC derby found.
LXC derby is not started. Starting container...
Container started.
Preparing derby container...
Container prepared.
Calling /hive/testutils/metastore/dbs/derby/prepare.sh ...
Server prepared.
Calling /hive/testutils/metastore/dbs/derby/execute.sh ...
Tests executed.
LXC mysql found.
LXC mysql is not started. Starting container...
Container started.
Preparing mysql container...
Container prepared.
Calling /hive/testutils/metastore/dbs/mysql/prepare.sh ...
Server prepared.
Calling /hive/testutils/metastore/dbs/mysql/execute.sh ...
Tests executed.
LXC oracle found.
LXC oracle is not started. Starting container...
Container started.
Preparing oracle container...
Container prepared.
Calling /hive/testutils/metastore/dbs/oracle/prepare.sh ...
Server prepared.
Calling /hive/testutils/metastore/dbs/oracle/execute.sh ...
Tests executed.
LXC postgres found.
LXC postgres is not started. Starting container...
Container started.
Preparing postgres container...
Container prepared.
Calling /hive/testutils/metastore/dbs/postgres/prepare.sh ...
Server prepared.
Calling /hive/testutils/metastore/dbs/postgres/execute.sh ...
Tests executed.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12798855 - PreCommit-HIVE-METASTORE-Test&lt;/p&gt;</comment>
                            <comment id="15242216" author="hiveqa" created="Fri, 15 Apr 2016 00:25:07 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12798870/HIVE-13395.7.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12798870/HIVE-13395.7.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to no test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 4 tests passed&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-METASTORE-Test/140/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-METASTORE-Test/140/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-METASTORE-Test/140/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-METASTORE-Test/140/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-METASTORE-Test-140/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-METASTORE-Test-140/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;LXC derby found.
LXC derby is not started. Starting container...
Container started.
Preparing derby container...
Container prepared.
Calling /hive/testutils/metastore/dbs/derby/prepare.sh ...
Server prepared.
Calling /hive/testutils/metastore/dbs/derby/execute.sh ...
Tests executed.
LXC mysql found.
LXC mysql is not started. Starting container...
Container started.
Preparing mysql container...
Container prepared.
Calling /hive/testutils/metastore/dbs/mysql/prepare.sh ...
Server prepared.
Calling /hive/testutils/metastore/dbs/mysql/execute.sh ...
Tests executed.
LXC oracle found.
LXC oracle is not started. Starting container...
Container started.
Preparing oracle container...
Container prepared.
Calling /hive/testutils/metastore/dbs/oracle/prepare.sh ...
Server prepared.
Calling /hive/testutils/metastore/dbs/oracle/execute.sh ...
Tests executed.
LXC postgres found.
LXC postgres is not started. Starting container...
Container started.
Preparing postgres container...
Container prepared.
Calling /hive/testutils/metastore/dbs/postgres/prepare.sh ...
Server prepared.
Calling /hive/testutils/metastore/dbs/postgres/execute.sh ...
Tests executed.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12798870 - PreCommit-HIVE-METASTORE-Test&lt;/p&gt;</comment>
                            <comment id="15243901" author="ekoifman" created="Sat, 16 Apr 2016 00:35:30 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=alangates&quot; class=&quot;user-hover&quot; rel=&quot;alangates&quot;&gt;Alan Gates&lt;/a&gt; could you review please?&lt;/p&gt;</comment>
                            <comment id="15244666" author="hiveqa" created="Sun, 17 Apr 2016 13:51:41 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12798870/HIVE-13395.7.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12798870/HIVE-13395.7.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 6 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 13 failed/errored test(s), 9990 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_partition_coltype_literals
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_index_bitmap3
org.apache.hadoop.hive.llap.tezplugins.TestLlapTaskSchedulerService.testForcedLocalityPreemption
org.apache.hadoop.hive.metastore.TestHiveMetaStoreTxns.testLocks
org.apache.hadoop.hive.ql.security.TestMultiAuthorizationPreEventListener.org.apache.hadoop.hive.ql.security.TestMultiAuthorizationPreEventListener
org.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationProviderWithACL.testSimplePrivileges
org.apache.hadoop.hive.thrift.TestHadoopAuthBridge23.testDelegationTokenSharedStore
org.apache.hadoop.hive.thrift.TestHadoopAuthBridge23.testMetastoreProxyUser
org.apache.hadoop.hive.thrift.TestHadoopAuthBridge23.testSaslWithHiveMetaStore
org.apache.hive.hcatalog.mapreduce.TestHCatMultiOutputFormat.org.apache.hive.hcatalog.mapreduce.TestHCatMultiOutputFormat
org.apache.hive.hcatalog.mapreduce.TestHCatPartitionPublish.testPartitionPublish
org.apache.hive.service.TestHS2ImpersonationWithRemoteMS.org.apache.hive.service.TestHS2ImpersonationWithRemoteMS
org.apache.hive.spark.client.TestSparkClient.testSyncRpc
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/7628/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/7628/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/7628/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/7628/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-7628/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-7628/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 13 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12798870 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="15248872" author="alangates" created="Tue, 19 Apr 2016 23:10:58 +0000"  >&lt;p&gt;This is not a complete review but I have a few high level questions/comments.  Answering these will help me finish the rest of the review.&lt;/p&gt;

&lt;p&gt;The description presents several possible courses of action.  Some comments on which one you chose and why would be good.&lt;/p&gt;

&lt;p&gt;Why add a new WRITE_SET table?  Doesn&apos;t the TXN_COMPONENTS table have everything you need, since it tracks partitions/tables that were written to?  &lt;/p&gt;

&lt;p&gt;Why the double check for a write conflict in commitTxn?  You&apos;re already checking the conflict when you acquire the shared-write lock.  Since the writer holds the lock no-one could possibly update that partition.  If we want to someday shift to let shared-write locks proceed together and do true first commit wins then checking in commitTxn makes sense.  Is that your plan?&lt;/p&gt;</comment>
                            <comment id="15249040" author="ekoifman" created="Wed, 20 Apr 2016 00:36:54 +0000"  >&lt;p&gt;This implements that idea that if 2 concurrent transactions have a Write/Write conflict, one must be aborted and First-Committer-Wins rule is used to decide which.&lt;/p&gt;

&lt;p&gt;It&apos;s implemented using Write-Set tracking so that it can be extended to multi-statement txns in the future.   The check on lock acquisition is an optimization, while commitTxn() logic is the ultimate authority.  ( It also makes the logic cleaner in particular around properly mutexing operations, which have to be using RDBMS.  I started with your idea to check the latest writers txn id vs currently committing one but it ended up more difficult using a DB)&lt;/p&gt;

&lt;p&gt;TXN_COMPONENTS/COMPLETED_TXN_COMPONENTS have different retention policies.  These are governed by compaction rather than transaction &quot;liveness&quot; which don&apos;t necessarily match.&lt;/p&gt;</comment>
                            <comment id="15250354" author="alangates" created="Wed, 20 Apr 2016 17:44:19 +0000"  >&lt;blockquote&gt;&lt;p&gt;TXN_COMPONENTS/COMPLETED_TXN_COMPONENTS have different retention policies &lt;span class=&quot;error&quot;&gt;&amp;#91;then WRITE_SET&amp;#93;&lt;/span&gt;. These are governed by compaction rather than transaction &quot;liveness&quot; which don&apos;t necessarily match.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Agreed, but the retention of TXN_COMPONENTS/COMPLETED_TXN_COMPONENTS &amp;gt; WRITE_SET (because you can&apos;t clean the compaction until all the readers are done).  I know in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-13497&quot; title=&quot;eliminate TXN_COMPONENTS&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-13497&quot;&gt;&lt;del&gt;HIVE-13497&lt;/del&gt;&lt;/a&gt; you propose to eliminate TXN_COMPONENTS.  So is your plan to have WRITE_SET and COMPLETED_TXN_COMPONENTS as the two tables?  That seems fine, as long as the upgrade path isn&apos;t hard on users.&lt;/p&gt;</comment>
                            <comment id="15250391" author="ekoifman" created="Wed, 20 Apr 2016 18:03:03 +0000"  >&lt;p&gt;I wanted to have a solution that can be extended to multi-statement transactions.&lt;br/&gt;
In the general, you have to keep WriteSet info post transaction commit which means it can be cleaned.&lt;br/&gt;
For example, T&lt;span class=&quot;error&quot;&gt;&amp;#91;10,70&amp;#93;&lt;/span&gt; and S&lt;span class=&quot;error&quot;&gt;&amp;#91;35,36&amp;#93;&lt;/span&gt;.  If T decides to write X after S commits, you still need to know if S wrote X.&lt;/p&gt;</comment>
                            <comment id="15250422" author="alangates" created="Wed, 20 Apr 2016 18:14:14 +0000"  >&lt;p&gt;I agree we need something that works with multi-statement transaction.  But I think we&apos;ll find in that case that we cannot clean until all open transactions that could potentially see a set of changes (not just the txns with read locks) have closed.  That is, if I have a partition with base_10 and delta_11_20 and then compact so that I now have base_20 I can&apos;t clean that compaction until all transactions &amp;lt; 20 have committed or aborted.  Otherwise one of those transactions could try to read this partition and get the wrong version.  Since you have to remember all this I think this will force us to keep the necessary information in COMPLETED_TXN_COMPONENTS long enough.&lt;/p&gt;

&lt;p&gt;AFAICT you have a different way of remembering all the same information, which is completely fine.  As long as we agree on what has to be remembered for how long I&apos;m fine with doing it in a new WRITE_SET table and dropping the TXN_COMPONENTS table.&lt;/p&gt;
</comment>
                            <comment id="15252761" author="ekoifman" created="Thu, 21 Apr 2016 21:18:12 +0000"  >&lt;p&gt;patch 8 is just a rebase of 7&lt;/p&gt;</comment>
                            <comment id="15259289" author="ekoifman" created="Wed, 27 Apr 2016 01:02:40 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-13622&quot; title=&quot;WriteSet tracking optimizations&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-13622&quot;&gt;&lt;del&gt;HIVE-13622&lt;/del&gt;&lt;/a&gt; covers some optimizations for this&lt;/p&gt;</comment>
                            <comment id="15259305" author="ekoifman" created="Wed, 27 Apr 2016 01:15:31 +0000"  >&lt;p&gt;patch 11 (not final) reworks the implementation to get WriteSet information from TxnHandler.addDynamicPartitions() call rather than lock information (where applicable).  The later knows exactly which partitions have been written to. This increases concurrency dramatically.&lt;br/&gt;
For example &quot;update T set a = 7 where b = 17&quot;.  Suppose b is not a partition column and the table has 10K partitions.  Suppose further that only 5 partitions match &quot;b=17&quot;.  We&apos;ll currently lock all the existing partitions but a true WriteSet is the 5 partitions actually modified.&lt;/p&gt;

&lt;p&gt;Further optimizations in &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-13622&quot; title=&quot;WriteSet tracking optimizations&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-13622&quot;&gt;&lt;del&gt;HIVE-13622&lt;/del&gt;&lt;/a&gt; are useful but not absolutely required.&lt;/p&gt;</comment>
                            <comment id="15260977" author="ekoifman" created="Wed, 27 Apr 2016 21:20:40 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=alangates&quot; class=&quot;user-hover&quot; rel=&quot;alangates&quot;&gt;Alan Gates&lt;/a&gt; could you review patch 12 please&lt;/p&gt;</comment>
                            <comment id="15262597" author="ekoifman" created="Thu, 28 Apr 2016 17:40:02 +0000"  >&lt;p&gt;patch 13 is the same as 12&lt;/p&gt;</comment>
                            <comment id="15269933" author="ekoifman" created="Wed, 4 May 2016 00:39:08 +0000"  >&lt;p&gt;fix typo&lt;/p&gt;</comment>
                            <comment id="15269936" author="ekoifman" created="Wed, 4 May 2016 00:40:15 +0000"  >&lt;p&gt;patch 14 fixes a typo in patch 13&lt;/p&gt;</comment>
                            <comment id="15271161" author="ekoifman" created="Wed, 4 May 2016 18:39:35 +0000"  >&lt;p&gt;patch 15 fixes a couple of tests due to &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-13213&quot; title=&quot;make DbLockManger work for non-acid resources&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-13213&quot;&gt;&lt;del&gt;HIVE-13213&lt;/del&gt;&lt;/a&gt; - no code changes&lt;/p&gt;</comment>
                            <comment id="15271712" author="alangates" created="Thu, 5 May 2016 00:43:14 +0000"  >&lt;p&gt;TxnHandler.java in OperationType:  it seems odd to create a new enum with a deprecated method.&lt;/p&gt;

&lt;p&gt;In TxnHandler.commitTxn, would it make sense to rearrange this so that the check is made whether there are any operations that could conflict before the mutex is obtained and the transaction id checked?  If there&apos;s nothing to record in the write sets I don&apos;t see why you need to hold the mutex or even record a commit txn id.&lt;/p&gt;

&lt;p&gt;TxnHandler.addDynamicPartitions we should fix this so that the operations is carried in the dynamic partition message now rather than fetched from components table.  We can do it in a separate JIRA but we should do it quickly.  Fetching back another row to answer that question is bogus.&lt;/p&gt;

&lt;p&gt;TxnHandler.checkLock IIUC the if (!writeSet.isEmpty()) (line 2176) will never be triggered right now.  I&apos;m not a fan of blocks of dead code.  When do you plan to alter checkLock so that it knows whether the requesting locker is dynamic or static?&lt;/p&gt;

&lt;p&gt;TxnHandler lines 2229 through 2290 should be indented to match the following lines.  Right now they are 1 stop too far to the left.&lt;/p&gt;</comment>
                            <comment id="15271723" author="ekoifman" created="Thu, 5 May 2016 00:51:09 +0000"  >&lt;p&gt;I have a followup &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-13622&quot; title=&quot;WriteSet tracking optimizations&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-13622&quot;&gt;&lt;del&gt;HIVE-13622&lt;/del&gt;&lt;/a&gt; which I hope to get to get shortly - I believe it covers all your concerns (except for the indentation).  Let me know if you disagree.&lt;/p&gt;</comment>
                            <comment id="15271728" author="alangates" created="Thu, 5 May 2016 00:54:44 +0000"  >&lt;p&gt;Looks good.  If you fix the indentation on this I&apos;m +1 on it.&lt;/p&gt;</comment>
                            <comment id="15272891" author="ekoifman" created="Thu, 5 May 2016 19:13:07 +0000"  >&lt;p&gt;patch 16 only changes indentation/comments&lt;/p&gt;</comment>
                            <comment id="15272892" author="ekoifman" created="Thu, 5 May 2016 19:13:20 +0000"  >&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Test Name Duration Age
 org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join32	6.6 sec	1
 org.apache.hadoop.hive.thrift.TestHadoopAuthBridge23.testSaslWithHiveMetaStore	1 min 9 sec	1
 org.apache.hadoop.hive.llap.tezplugins.TestLlapTaskSchedulerService.testDelayedLocalityNodeCommErrorImmediateAllocation	10 sec	1
 org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver_encryption_select_read_only_encrypted_tbl	1 min 26 sec	2
 org.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.testAddPartitions	3 sec	3
 org.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure	4.8 sec	11
 org.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.testFetchingPartitionsWithDifferentSchemas	3 sec	24
 org.apache.hadoop.hive.metastore.TestHiveMetaStoreGetMetaConf.testGetMetaConfDefault	10 sec	25
 org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver_encryption_insert_partition_static	1 min 57 sec	26
 org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_selectindate	13 sec	30
 org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_avrocountemptytbl	9.6 sec	30
 org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_order_null	35 sec	30
 org.apache.hive.hcatalog.api.repl.commands.TestCommands.org.apache.hive.hcatalog.api.repl.commands.TestCommands	20 sec	30
 org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver_encryption_join_with_different_encryption_keys	1 min 32 sec	30
 org.apache.hive.minikdc.TestHiveAuthFactory.testStartTokenManagerForMemoryTokenStore	1.3 sec	30
 org.apache.hive.minikdc.TestHiveAuthFactory.testStartTokenManagerForDBTokenStore	0.38 sec	30
 org.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.testGetPartitionSpecs_WithAndWithoutPartitionGrouping	3.3 sec	30
 org.apache.hive.minikdc.TestMiniHiveKdc.testLogin	1 min 27 sec	30
 org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_index_bitmap3	9.1 sec	30
 org.apache.hadoop.hive.cli.TestMinimrCliDriver.org.apache.hadoop.hive.cli.TestMinimrCliDriver	1 min 30 sec	30
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;test failures are not related&lt;/p&gt;</comment>
                            <comment id="15273231" author="ekoifman" created="Thu, 5 May 2016 22:28:04 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-13395&quot; title=&quot;Lost Update problem in ACID&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-13395&quot;&gt;&lt;del&gt;HIVE-13395&lt;/del&gt;&lt;/a&gt;.addendum.patch - obligatory forgotten file&lt;/p&gt;</comment>
                            <comment id="15273236" author="ekoifman" created="Thu, 5 May 2016 22:29:55 +0000"  >&lt;p&gt;committed to branch-1 and master&lt;/p&gt;

&lt;p&gt;thanks Alan for the review&lt;/p&gt;</comment>
                            <comment id="15273422" author="lefty@hortonworks.com" created="Fri, 6 May 2016 01:00:42 +0000"  >&lt;p&gt;Doc note:  This adds &lt;b&gt;hive.writeset.reaper.interval&lt;/b&gt; to HiveConf.java, so it will need to be documented in the wiki for releases 1.3.0 and 2.1.0.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-QueryandDDLExecution&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Configuration Properties &amp;#8211; Query and DDL Execution &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Added TODOC1.3 and TODOC2.1 labels.&lt;/p&gt;</comment>
                            <comment id="15277442" author="prasanth_j" created="Tue, 10 May 2016 01:32:30 +0000"  >&lt;p&gt;the typo fix looks good to me, +1&lt;/p&gt;</comment>
                            <comment id="15336515" author="thejas" created="Fri, 17 Jun 2016 17:26:42 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ekoifman&quot; class=&quot;user-hover&quot; rel=&quot;ekoifman&quot;&gt;Eugene Koifman&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=alangates&quot; class=&quot;user-hover&quot; rel=&quot;alangates&quot;&gt;Alan Gates&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I think the WRITE_SET table should some columns in the primary key. I expect most databases to organize the data in a b-tree with primary key as the index (or have an option to do so). That should help in reducing the search space for your prominent queries. As long as columns in the where clause match the prefix of the index, it should greatly reduce the search space.&lt;/p&gt;

&lt;p&gt;You can add a autoincrement column to keep it unique if necessary. MySQL (innodb) anyway ends up organizing data on an autoincrement column, which is useless for the queries (see &lt;a href=&quot;https://blog.jcole.us/2013/05/02/how-does-innodb-behave-without-a-primary-key/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;post&lt;/a&gt; ).&lt;/p&gt;</comment>
                            <comment id="15336530" author="thejas" created="Fri, 17 Jun 2016 17:36:17 +0000"  >&lt;p&gt;Created a follow up jira for the PK addition - &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-14047&quot; title=&quot;add primary key on WRITE_SET&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-14047&quot;&gt;HIVE-14047&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15429630" author="lefty@hortonworks.com" created="Sun, 21 Aug 2016 07:59:06 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wzheng&quot; class=&quot;user-hover&quot; rel=&quot;wzheng&quot;&gt;Wei Zheng&lt;/a&gt; documented &lt;b&gt;hive.writeset.reaper.interval&lt;/b&gt; in the wiki so I removed the TODOC1.3 and TODOC 2.1 labels.  Thanks, Wei!&lt;/p&gt;

&lt;p&gt;Here&apos;s the link:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.writeset.reaper.interval&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Configuration Properties &amp;#8211; hive.writeset.reaper.interval &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12962847">HIVE-13622</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12953297">HIVE-13354</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12964162">HIVE-13664</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12980253">HIVE-14047</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12839733">HIVE-11077</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12800928" name="HIVE-13395.11.patch" size="143176" author="ekoifman" created="Wed, 27 Apr 2016 01:15:31 +0000"/>
                            <attachment id="12801118" name="HIVE-13395.12.patch" size="143627" author="ekoifman" created="Wed, 27 Apr 2016 21:20:40 +0000"/>
                            <attachment id="12801285" name="HIVE-13395.13.patch" size="143627" author="ekoifman" created="Thu, 28 Apr 2016 17:40:02 +0000"/>
                            <attachment id="12802084" name="HIVE-13395.14.patch" size="143644" author="ekoifman" created="Wed, 4 May 2016 00:39:08 +0000"/>
                            <attachment id="12802258" name="HIVE-13395.15.patch" size="145507" author="ekoifman" created="Wed, 4 May 2016 18:39:35 +0000"/>
                            <attachment id="12802497" name="HIVE-13395.16.patch" size="148291" author="ekoifman" created="Thu, 5 May 2016 19:13:07 +0000"/>
                            <attachment id="12798855" name="HIVE-13395.6.patch" size="103480" author="ekoifman" created="Thu, 14 Apr 2016 23:25:12 +0000"/>
                            <attachment id="12798870" name="HIVE-13395.7.patch" size="103480" author="ekoifman" created="Fri, 15 Apr 2016 00:15:48 +0000"/>
                            <attachment id="12800086" name="HIVE-13395.8.patch" size="103833" author="ekoifman" created="Thu, 21 Apr 2016 21:18:12 +0000"/>
                            <attachment id="12802548" name="HIVE-13395.addendum.patch" size="974" author="ekoifman" created="Thu, 5 May 2016 22:28:04 +0000"/>
                            <attachment id="12803129" name="HIVE-13395.addendum2.patch" size="675" author="ekoifman" created="Tue, 10 May 2016 01:31:10 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>11.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 14 Apr 2016 23:34:52 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            14 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2vfn3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12332154</customfieldvalue>
    <customfieldvalue>12334255</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>