<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 02 06:19:55 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HIVE-12577/HIVE-12577.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HIVE-12577] NPE in LlapTaskCommunicator when unregistering containers</title>
                <link>https://issues.apache.org/jira/browse/HIVE-12577</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2015-12-02 13:29:00,160 [ERROR] [Dispatcher thread {Central}] |common.AsyncDispatcher|: Error in dispatcher thread
java.lang.NullPointerException
        at org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator$EntityTracker.unregisterContainer(LlapTaskCommunicator.java:586)
        at org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.registerContainerEnd(LlapTaskCommunicator.java:188)
        at org.apache.tez.dag.app.TaskCommunicatorManager.unregisterRunningContainer(TaskCommunicatorManager.java:389)
        at org.apache.tez.dag.app.rm.container.AMContainerImpl.unregisterFromTAListener(AMContainerImpl.java:1121)
        at org.apache.tez.dag.app.rm.container.AMContainerImpl$StopRequestAtLaunchingTransition.transition(AMContainerImpl.java:699)
        at org.apache.tez.dag.app.rm.container.AMContainerImpl$StopRequestAtIdleTransition.transition(AMContainerImpl.java:805)
        at org.apache.tez.dag.app.rm.container.AMContainerImpl$StopRequestAtRunningTransition.transition(AMContainerImpl.java:892)
        at org.apache.tez.dag.app.rm.container.AMContainerImpl$StopRequestAtRunningTransition.transition(AMContainerImpl.java:887)
        at org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:362)
        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)
        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)
        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)
        at org.apache.tez.dag.app.rm.container.AMContainerImpl.handle(AMContainerImpl.java:415)
        at org.apache.tez.dag.app.rm.container.AMContainerImpl.handle(AMContainerImpl.java:72)
        at org.apache.tez.dag.app.rm.container.AMContainerMap.handle(AMContainerMap.java:60)
        at org.apache.tez.dag.app.rm.container.AMContainerMap.handle(AMContainerMap.java:36)
        at org.apache.tez.common.AsyncDispatcher.dispatch(AsyncDispatcher.java:183)
        at org.apache.tez.common.AsyncDispatcher$1.run(AsyncDispatcher.java:114)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
2015-12-02 13:29:00,167 [ERROR] [Dispatcher thread {Central}] |common.AsyncDispatcher|: Error in dispatcher thread
java.lang.NullPointerException
        at org.apache.tez.dag.app.TaskCommunicatorManager.unregisterRunningContainer(TaskCommunicatorManager.java:386)
        at org.apache.tez.dag.app.rm.container.AMContainerImpl.unregisterFromTAListener(AMContainerImpl.java:1121)
        at org.apache.tez.dag.app.rm.container.AMContainerImpl$StopRequestAtLaunchingTransition.transition(AMContainerImpl.java:699)
        at org.apache.tez.dag.app.rm.container.AMContainerImpl$StopRequestAtIdleTransition.transition(AMContainerImpl.java:805)
        at org.apache.tez.dag.app.rm.container.AMContainerImpl$StopRequestAtRunningTransition.transition(AMContainerImpl.java:892)
        at org.apache.tez.dag.app.rm.container.AMContainerImpl$StopRequestAtRunningTransition.transition(AMContainerImpl.java:887)
        at org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:362)
        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)
        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)
        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)
        at org.apache.tez.dag.app.rm.container.AMContainerImpl.handle(AMContainerImpl.java:415)
        at org.apache.tez.dag.app.rm.container.AMContainerImpl.handle(AMContainerImpl.java:72)
        at org.apache.tez.dag.app.rm.container.AMContainerMap.handle(AMContainerMap.java:60)
        at org.apache.tez.dag.app.rm.container.AMContainerMap.handle(AMContainerMap.java:36)
        at org.apache.tez.common.AsyncDispatcher.dispatch(AsyncDispatcher.java:183)
        at org.apache.tez.common.AsyncDispatcher$1.run(AsyncDispatcher.java:114)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12917776">HIVE-12577</key>
            <summary>NPE in LlapTaskCommunicator when unregistering containers</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="sseth">Siddharth Seth</assignee>
                                    <reporter username="sseth">Siddharth Seth</reporter>
                        <labels>
                    </labels>
                <created>Wed, 2 Dec 2015 22:42:10 +0000</created>
                <updated>Tue, 16 Feb 2016 23:51:05 +0000</updated>
                            <resolved>Wed, 23 Dec 2015 19:25:44 +0000</resolved>
                                    <version>2.0.0</version>
                                    <fixVersion>2.0.0</fixVersion>
                                    <component>llap</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="15036819" author="sseth" created="Wed, 2 Dec 2015 22:50:33 +0000"  >&lt;p&gt;Work in progress patch. &lt;/p&gt;</comment>
                            <comment id="15053887" author="sseth" created="Sat, 12 Dec 2015 01:03:08 +0000"  >&lt;p&gt;In addition to the fix, the patch renames one class. TaskCommunicator to LlapDaemonClientProcy. TaskCOmmunicator was too similar to LlapTaskCommunicator, and gets confusing.&lt;br/&gt;
Attaching two patches. One generated with git diff -M - to show the actual changes - so that the rename does not get in the way.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sershe&quot; class=&quot;user-hover&quot; rel=&quot;sershe&quot;&gt;Sergey Shelukhin&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=prasanth_j&quot; class=&quot;user-hover&quot; rel=&quot;prasanth_j&quot;&gt;Prasanth Jayachandran&lt;/a&gt; - please review.&lt;/p&gt;</comment>
                            <comment id="15053888" author="sseth" created="Sat, 12 Dec 2015 01:03:23 +0000"  >&lt;p&gt;Patch for jenkins.&lt;/p&gt;</comment>
                            <comment id="15053918" author="sershe" created="Sat, 12 Dec 2015 01:27:23 +0000"  >&lt;p&gt;Can you add some comments? I don&apos;t quite understand what the patch is actually doing.&lt;/p&gt;</comment>
                            <comment id="15056438" author="sseth" created="Mon, 14 Dec 2015 18:31:07 +0000"  >&lt;p&gt;EntityTracker tracks the relationship between containers and tasks, along with the nodes they run on. This is used for various bits of accounting - including telling unknown fragments to die, processing heartbeats for fragments which are in the wait queue of an llap instance.&lt;/p&gt;

&lt;p&gt;There were some discrepancies in this tracking, the most important one being the null check which causes the exception. The patch fixes these and adds some unit tests for verification.&lt;/p&gt;</comment>
                            <comment id="15057199" author="sershe" created="Tue, 15 Dec 2015 02:20:35 +0000"  >&lt;p&gt;Tracking time using the currentMilliseconds call is fraught with peril, machine clock can move and cause weird behavior.&lt;/p&gt;

&lt;p&gt;Nits: The caller of BiMap&amp;lt;ContainerId, TezTaskAttemptID&amp;gt; getContainerAttemptMapForNode(String hostname, int port)  creates an nodeid but passes name and port to the method which also creates an id; getContext() is called twice; there appear to be some indentation issues.&lt;/p&gt;
</comment>
                            <comment id="15059121" author="sseth" created="Tue, 15 Dec 2015 23:45:37 +0000"  >&lt;p&gt;Patch for review.&lt;/p&gt;

&lt;p&gt;Addresses the comments, except getContext() being used twice - that&apos;s the way it is used throughout the file and is cheap.&lt;/p&gt;

&lt;p&gt;Also adds some additional tracking for future debugging of some timeouts which have been seen at times - which are related to this tracking and nodes sending in heartbeats.&lt;/p&gt;</comment>
                            <comment id="15064731" author="sershe" created="Fri, 18 Dec 2015 20:43:40 +0000"  >&lt;p&gt;+1 pending test run&lt;/p&gt;</comment>
                            <comment id="15064733" author="sershe" created="Fri, 18 Dec 2015 20:44:37 +0000"  >&lt;p&gt;The same patch for HiveQA&lt;/p&gt;</comment>
                            <comment id="15065335" author="hiveqa" created="Sat, 19 Dec 2015 10:53:41 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12778581/HIVE-12577.03.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12778581/HIVE-12577.03.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to build exiting with an error&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6406/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6406/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6406/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6406/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6406/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6406/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;**** This message was trimmed, see log for full details ****
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/hwi/target/tmp/conf
     [copy] Copying 16 files to /data/hive-ptest/working/apache-github-source-source/hwi/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-hwi ---
[INFO] Compiling 2 source files to /data/hive-ptest/working/apache-github-source-source/hwi/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.16:test (default-test) @ hive-hwi ---
[INFO] Tests are skipped.
[INFO] 
[INFO] --- maven-jar-plugin:2.2:jar (default-jar) @ hive-hwi ---
[INFO] Building jar: /data/hive-ptest/working/apache-github-source-source/hwi/target/hive-hwi-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-hwi ---
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-hwi ---
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/hwi/target/hive-hwi-2.1.0-SNAPSHOT.jar to /data/hive-ptest/working/maven/org/apache/hive/hive-hwi/2.1.0-SNAPSHOT/hive-hwi-2.1.0-SNAPSHOT.jar
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/hwi/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-hwi/2.1.0-SNAPSHOT/hive-hwi-2.1.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive ODBC 2.1.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-odbc ---
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/odbc/target
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/odbc (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ hive-odbc ---
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-odbc ---
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-odbc ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-odbc ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/odbc/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/odbc/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/odbc/target/tmp/conf
     [copy] Copying 16 files to /data/hive-ptest/working/apache-github-source-source/odbc/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-site-plugin:3.3:attach-descriptor (attach-descriptor) @ hive-odbc ---
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hive-odbc ---
[INFO] Installing /data/hive-ptest/working/apache-github-source-source/odbc/pom.xml to /data/hive-ptest/working/maven/org/apache/hive/hive-odbc/2.1.0-SNAPSHOT/hive-odbc-2.1.0-SNAPSHOT.pom
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive Llap Server 2.1.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hive-llap-server ---
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/llap-server/target
[INFO] Deleting /data/hive-ptest/working/apache-github-source-source/llap-server (includes = [datanucleus.log, derby.log], excludes = [])
[INFO] 
[INFO] --- maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) @ hive-llap-server ---
[INFO] 
[INFO] --- build-helper-maven-plugin:1.8:add-source (add-source) @ hive-llap-server ---
[INFO] Source directory: /data/hive-ptest/working/apache-github-source-source/llap-server/src/gen/protobuf/gen-java added.
[INFO] Source directory: /data/hive-ptest/working/apache-github-source-source/llap-server/src/gen/thrift/gen-javabean added.
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ hive-llap-server ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hive-llap-server ---
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 4 resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (define-classpath) @ hive-llap-server ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ hive-llap-server ---
[INFO] Compiling 99 source files to /data/hive-ptest/working/apache-github-source-source/llap-server/target/classes
[WARNING] /data/hive-ptest/working/apache-github-source-source/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/TaskRunnerCallable.java: /data/hive-ptest/working/apache-github-source-source/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/TaskRunnerCallable.java uses or overrides a deprecated API.
[WARNING] /data/hive-ptest/working/apache-github-source-source/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/TaskRunnerCallable.java: Recompile with -Xlint:deprecation for details.
[WARNING] /data/hive-ptest/working/apache-github-source-source/llap-server/src/java/org/apache/hadoop/hive/llap/shufflehandler/DirWatcher.java: Some input files use unchecked or unsafe operations.
[WARNING] /data/hive-ptest/working/apache-github-source-source/llap-server/src/java/org/apache/hadoop/hive/llap/shufflehandler/DirWatcher.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hive-llap-server ---
[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.
[INFO] Copying 4 resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (setup-test-dirs) @ hive-llap-server ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/llap-server/target/tmp
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/llap-server/target/warehouse
    [mkdir] Created dir: /data/hive-ptest/working/apache-github-source-source/llap-server/target/tmp/conf
     [copy] Copying 16 files to /data/hive-ptest/working/apache-github-source-source/llap-server/target/tmp/conf
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ hive-llap-server ---
[INFO] Compiling 14 source files to /data/hive-ptest/working/apache-github-source-source/llap-server/target/test-classes
[INFO] -------------------------------------------------------------
[WARNING] COMPILATION WARNING : 
[INFO] -------------------------------------------------------------
[WARNING] /data/hive-ptest/working/apache-github-source-source/llap-server/src/test/org/apache/hadoop/hive/llap/tezplugins/TestLlapTaskCommunicator.java: /data/hive-ptest/working/apache-github-source-source/llap-server/src/test/org/apache/hadoop/hive/llap/tezplugins/TestLlapTaskCommunicator.java uses or overrides a deprecated API.
[WARNING] /data/hive-ptest/working/apache-github-source-source/llap-server/src/test/org/apache/hadoop/hive/llap/tezplugins/TestLlapTaskCommunicator.java: Recompile with -Xlint:deprecation for details.
[WARNING] /data/hive-ptest/working/apache-github-source-source/llap-server/src/test/org/apache/hadoop/hive/llap/tezplugins/TestLlapDaemonProtocolClientProxy.java: Some input files use unchecked or unsafe operations.
[WARNING] /data/hive-ptest/working/apache-github-source-source/llap-server/src/test/org/apache/hadoop/hive/llap/tezplugins/TestLlapDaemonProtocolClientProxy.java: Recompile with -Xlint:unchecked for details.
[INFO] 4 warnings 
[INFO] -------------------------------------------------------------
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR : 
[INFO] -------------------------------------------------------------
[ERROR] /data/hive-ptest/working/apache-github-source-source/llap-server/src/test/org/apache/hadoop/hive/llap/tezplugins/TestLlapTaskCommunicator.java:[46,29] method getContainerAttemptMapForNode in class org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.EntityTracker cannot be applied to given types;
  required: org.apache.hadoop.hive.llap.LlapNodeId
  found: java.lang.String,int
  reason: actual and formal argument lists differ in length
[ERROR] /data/hive-ptest/working/apache-github-source-source/llap-server/src/test/org/apache/hadoop/hive/llap/tezplugins/TestLlapTaskCommunicator.java:[61,29] method getContainerAttemptMapForNode in class org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.EntityTracker cannot be applied to given types;
  required: org.apache.hadoop.hive.llap.LlapNodeId
  found: java.lang.String,int
  reason: actual and formal argument lists differ in length
[ERROR] /data/hive-ptest/working/apache-github-source-source/llap-server/src/test/org/apache/hadoop/hive/llap/tezplugins/TestLlapTaskCommunicator.java:[76,29] method getContainerAttemptMapForNode in class org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.EntityTracker cannot be applied to given types;
  required: org.apache.hadoop.hive.llap.LlapNodeId
  found: java.lang.String,int
  reason: actual and formal argument lists differ in length
[INFO] 3 errors 
[INFO] -------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Hive .............................................. SUCCESS [13.781s]
[INFO] Hive Shims Common ................................. SUCCESS [16.412s]
[INFO] Hive Shims 0.23 ................................... SUCCESS [12.553s]
[INFO] Hive Shims Scheduler .............................. SUCCESS [3.725s]
[INFO] Hive Shims ........................................ SUCCESS [2.470s]
[INFO] Hive Storage API .................................. SUCCESS [5.212s]
[INFO] Hive ORC .......................................... SUCCESS [12.867s]
[INFO] Hive Common ....................................... SUCCESS [23.997s]
[INFO] Hive Serde ........................................ SUCCESS [18.928s]
[INFO] Hive Metastore .................................... SUCCESS [52.081s]
[INFO] Hive Ant Utilities ................................ SUCCESS [1.755s]
[INFO] Hive Llap Client .................................. SUCCESS [12.113s]
[INFO] Spark Remote Client ............................... SUCCESS [29.037s]
[INFO] Hive Query Language ............................... SUCCESS [2:43.155s]
[INFO] Hive Service ...................................... SUCCESS [14.208s]
[INFO] Hive Accumulo Handler ............................. SUCCESS [10.996s]
[INFO] Hive JDBC ......................................... SUCCESS [16.846s]
[INFO] Hive Beeline ...................................... SUCCESS [2.911s]
[INFO] Hive CLI .......................................... SUCCESS [2.971s]
[INFO] Hive Contrib ...................................... SUCCESS [2.376s]
[INFO] Hive HBase Handler ................................ SUCCESS [6.392s]
[INFO] Hive HCatalog ..................................... SUCCESS [0.923s]
[INFO] Hive HCatalog Core ................................ SUCCESS [5.995s]
[INFO] Hive HCatalog Pig Adapter ......................... SUCCESS [3.464s]
[INFO] Hive HCatalog Server Extensions ................... SUCCESS [3.704s]
[INFO] Hive HCatalog Webhcat Java Client ................. SUCCESS [3.474s]
[INFO] Hive HCatalog Webhcat ............................. SUCCESS [15.317s]
[INFO] Hive HCatalog Streaming ........................... SUCCESS [3.244s]
[INFO] Hive HPL/SQL ...................................... SUCCESS [17.081s]
[INFO] Hive HWI .......................................... SUCCESS [1.723s]
[INFO] Hive ODBC ......................................... SUCCESS [1.885s]
[INFO] Hive Llap Server .................................. FAILURE [5.935s]
[INFO] Hive Shims Aggregator ............................. SKIPPED
[INFO] Hive TestUtils .................................... SKIPPED
[INFO] Hive Packaging .................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 8:10.867s
[INFO] Finished at: Sat Dec 19 05:53:39 EST 2015
[INFO] Final Memory: 216M/1083M
[INFO] ------------------------------------------------------------------------
[WARNING] The requested profile &quot;hadoop-2&quot; could not be activated because it does not exist.
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:testCompile (default-testCompile) on project hive-llap-server: Compilation failure: Compilation failure:
[ERROR] /data/hive-ptest/working/apache-github-source-source/llap-server/src/test/org/apache/hadoop/hive/llap/tezplugins/TestLlapTaskCommunicator.java:[46,29] method getContainerAttemptMapForNode in class org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.EntityTracker cannot be applied to given types;
[ERROR] required: org.apache.hadoop.hive.llap.LlapNodeId
[ERROR] found: java.lang.String,int
[ERROR] reason: actual and formal argument lists differ in length
[ERROR] /data/hive-ptest/working/apache-github-source-source/llap-server/src/test/org/apache/hadoop/hive/llap/tezplugins/TestLlapTaskCommunicator.java:[61,29] method getContainerAttemptMapForNode in class org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.EntityTracker cannot be applied to given types;
[ERROR] required: org.apache.hadoop.hive.llap.LlapNodeId
[ERROR] found: java.lang.String,int
[ERROR] reason: actual and formal argument lists differ in length
[ERROR] /data/hive-ptest/working/apache-github-source-source/llap-server/src/test/org/apache/hadoop/hive/llap/tezplugins/TestLlapTaskCommunicator.java:[76,29] method getContainerAttemptMapForNode in class org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.EntityTracker cannot be applied to given types;
[ERROR] required: org.apache.hadoop.hive.llap.LlapNodeId
[ERROR] found: java.lang.String,int
[ERROR] reason: actual and formal argument lists differ in length
[ERROR] -&amp;gt; [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &amp;lt;goals&amp;gt; -rf :hive-llap-server
+ exit 1
&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12778581 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="15065894" author="sseth" created="Sun, 20 Dec 2015 20:44:10 +0000"  >&lt;p&gt;Patch with the unit test compile failure fixed.&lt;/p&gt;</comment>
                            <comment id="15068664" author="hagleitn" created="Tue, 22 Dec 2015 20:13:18 +0000"  >&lt;p&gt;reupload for hive qa&lt;/p&gt;</comment>
                            <comment id="15069929" author="hiveqa" created="Wed, 23 Dec 2015 17:43:57 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12779119/HIVE-12577.4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12779119/HIVE-12577.4.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 2 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 18 failed/errored test(s), 9962 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestHWISessionManager - did not produce a TEST-*.xml file
TestSparkCliDriver-timestamp_lazy.q-bucketsortoptimize_insert_4.q-date_udf.q-and-12-more - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_auto_join_stats2
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver_encryption_insert_partition_dynamic
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_columnstats_partlvl_multiple_part_clause
org.apache.hadoop.hive.ql.exec.spark.session.TestSparkSessionManagerImpl.testMultiSessionMultipleUse
org.apache.hadoop.hive.ql.exec.spark.session.TestSparkSessionManagerImpl.testSingleSessionMultipleUse
org.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveOperationType.checkHiveOperationTypeMatch
org.apache.hive.jdbc.TestSSL.testSSLVersion
org.apache.hive.spark.client.TestSparkClient.testAddJarsAndFiles
org.apache.hive.spark.client.TestSparkClient.testCounters
org.apache.hive.spark.client.TestSparkClient.testErrorJob
org.apache.hive.spark.client.TestSparkClient.testJobSubmission
org.apache.hive.spark.client.TestSparkClient.testMetricsCollection
org.apache.hive.spark.client.TestSparkClient.testRemoteClient
org.apache.hive.spark.client.TestSparkClient.testSimpleSparkJob
org.apache.hive.spark.client.TestSparkClient.testSyncRpc
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6458/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6458/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6458/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6458/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6458/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6458/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 18 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12779119 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="15070069" author="hagleitn" created="Wed, 23 Dec 2015 19:25:44 +0000"  >&lt;p&gt;Committed to master and branch-2.0&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12778581" name="HIVE-12577.03.patch" size="73499" author="sershe" created="Fri, 18 Dec 2015 20:44:37 +0000"/>
                            <attachment id="12777220" name="HIVE-12577.1.review.txt" size="23504" author="sseth" created="Sat, 12 Dec 2015 01:03:08 +0000"/>
                            <attachment id="12777221" name="HIVE-12577.1.txt" size="70412" author="sseth" created="Sat, 12 Dec 2015 01:03:23 +0000"/>
                            <attachment id="12775422" name="HIVE-12577.1.wip.txt" size="3582" author="sseth" created="Wed, 2 Dec 2015 22:50:33 +0000"/>
                            <attachment id="12777856" name="HIVE-12577.2.review.txt" size="26591" author="sseth" created="Tue, 15 Dec 2015 23:45:37 +0000"/>
                            <attachment id="12777857" name="HIVE-12577.2.txt" size="73499" author="sseth" created="Tue, 15 Dec 2015 23:45:51 +0000"/>
                            <attachment id="12779117" name="HIVE-12577.3.patch" size="73739" author="hagleitn" created="Tue, 22 Dec 2015 20:13:18 +0000"/>
                            <attachment id="12778751" name="HIVE-12577.3.txt" size="73739" author="sseth" created="Sun, 20 Dec 2015 20:44:10 +0000"/>
                            <attachment id="12779119" name="HIVE-12577.4.patch" size="73739" author="hagleitn" created="Tue, 22 Dec 2015 20:14:09 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sat, 12 Dec 2015 01:27:23 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            49 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2p7fr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue>12332641</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>