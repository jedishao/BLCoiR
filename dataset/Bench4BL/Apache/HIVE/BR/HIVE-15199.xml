<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 02 05:19:07 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HIVE-15199/HIVE-15199.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HIVE-15199] INSERT INTO data on S3 is replacing the old rows with the new ones</title>
                <link>https://issues.apache.org/jira/browse/HIVE-15199</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Any INSERT INTO statement run on S3 tables and when the scratch directory is saved on S3 is deleting old rows of the table.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;hive&amp;gt; set hive.blobstore.use.blobstore.as.scratchdir=true;

hive&amp;gt; create table t1 (id int, name string) location &apos;s3a://spena-bucket/t1&apos;;

hive&amp;gt; insert into table t1 values (1,&apos;name1&apos;);

hive&amp;gt; select * from t1;
1       name1

hive&amp;gt; insert into table t1 values (2,&apos;name2&apos;);

hive&amp;gt; select * from t1;
2       name2
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13020602">HIVE-15199</key>
            <summary>INSERT INTO data on S3 is replacing the old rows with the new ones</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="spena">Sergio Pe&#241;a</assignee>
                                    <reporter username="spena">Sergio Pe&#241;a</reporter>
                        <labels>
                    </labels>
                <created>Mon, 14 Nov 2016 20:31:36 +0000</created>
                <updated>Thu, 24 Nov 2016 01:48:21 +0000</updated>
                            <resolved>Wed, 23 Nov 2016 18:45:34 +0000</resolved>
                                                    <fixVersion>2.2.0</fixVersion>
                                    <component>Hive</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                <comments>
                            <comment id="15665000" author="spena" created="Mon, 14 Nov 2016 20:59:37 +0000"  >&lt;p&gt;This issue is happening on the following code (Hive.java):&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;private static void copyFiles(...) {
...
  if (renameNonLocal) {
      for (int counter = 1; !destFs.rename(srcP,destPath); counter++) {
           destPath = new Path(destf, name + (&quot;_copy_&quot; + counter) + filetype);
       }
  } else {
       destPath = mvFile(conf, srcP, destPath, isSrcLocal, srcFs, destFs, name, filetype);
  }
...
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Even if the file already exists on S3, the &lt;tt&gt;destFs.rename()&lt;/tt&gt; call is renaming the file. &lt;br/&gt;
This does not happen with HDFS. If the file exists on HDFS, then the rename will fail, and the &lt;em&gt;copy&lt;/em&gt; string will be appended to the filename, and retry the rename.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stevel%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;stevel@apache.org&quot;&gt;Steve Loughran&lt;/a&gt; Do you know if this is a known bug on the Hadoop side?&lt;/p&gt;</comment>
                            <comment id="15666900" author="rajesh.balamohan" created="Tue, 15 Nov 2016 11:30:29 +0000"  >&lt;p&gt;This is covered in test cases in branch-2 for S3 &lt;a href=&quot;https://github.com/apache/hadoop/blob/branch-2/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AFileSystemContract.java#L103&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/hadoop/blob/branch-2/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AFileSystemContract.java#L103&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Need to change Hive to make use of &lt;tt&gt;destFs.exists&lt;/tt&gt; and do a rename.&lt;/p&gt;</comment>
                            <comment id="15667531" author="yalovyyi" created="Tue, 15 Nov 2016 16:10:15 +0000"  >&lt;p&gt;destFs.exists will require another call to S3, that could affect performance. I think it should be addressed in s3a implementation. It should provide consistent behavior with HDFS.&lt;/p&gt;</comment>
                            <comment id="15667862" author="stakiar" created="Tue, 15 Nov 2016 18:21:02 +0000"  >&lt;p&gt;The code block Sergio posted looks like it could have some major inefficiencies, even for HDFS. If my understanding is correct, the code basically tries to rename the data with the suffix &lt;tt&gt;... + &quot;&lt;em&gt;copy&lt;/em&gt;&quot; + counter&lt;/tt&gt;, if it fails (because the files already exists), it increments the counter and then tries again. This doesn&apos;t sound like a scalable solution, what happens if there are 1000 files under the directory, any insert will require explicitly checking for the existence of files from &lt;tt&gt;... + &quot;_copy_0&quot;&lt;/tt&gt; to &lt;tt&gt;... + &quot;_copy_1000&quot;&lt;/tt&gt;. On HDFS, and especially on S3, this doesn&apos;t seem to be a very efficient approach (would be good to confirm this behavior).&lt;/p&gt;

&lt;p&gt;If the logic above is indeed what happens, there could be a few different ways to fix this.&lt;/p&gt;

&lt;p&gt;1: Append an UUID to the end of the file name rather than using a counter, since UUID are globally unique there should be no chance of conflict&lt;br/&gt;
2: Append the query_id + a synchronized counter (&lt;tt&gt;private synchronized long counter&lt;/tt&gt;) to the file name&lt;/p&gt;</comment>
                            <comment id="15667931" author="stevel@apache.org" created="Tue, 15 Nov 2016 18:50:41 +0000"  >&lt;p&gt;sounds related to &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-13402&quot; title=&quot;S3A should allow renaming to a pre-existing destination directory to move the source path under that directory, similar to HDFS.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-13402&quot;&gt;HADOOP-13402&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I am not going to express any opinion about what is &quot;the correct&quot; behaviour we should expect from rename, as I don&apos;t think anyone knows that. If you look at the &lt;a href=&quot;https://hadoop.apache.org/docs/stable2/hadoop-project-dist/hadoop-common/filesystem/filesystem.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;FS Specification&lt;/a&gt; we&apos;re pretty explicit that rename is hard, and that there are different behaviours by different filesystems are.&lt;/p&gt;

&lt;p&gt;I&apos;m not defending S3A here, just noting I&apos;m not 100% sure of what HDFS does itself here, and how that compares to the semantics of posix&apos;s rename call (which is different from the unix command line &lt;tt&gt;mv&lt;/tt&gt; operation).&lt;/p&gt;</comment>
                            <comment id="15671136" author="spena" created="Wed, 16 Nov 2016 17:55:46 +0000"  >&lt;p&gt;Guys, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ashutoshc&quot; class=&quot;user-hover&quot; rel=&quot;ashutoshc&quot;&gt;Ashutosh Chauhan&lt;/a&gt;, could you help me review the patch?&lt;/p&gt;

&lt;p&gt;What it does is to use the alternative condition &lt;tt&gt;mvFile&lt;/tt&gt; when the destination filesystem is a blobstore. And, because this &lt;tt&gt;mvFile&lt;/tt&gt; was calling &lt;tt&gt;destFs.exists()&lt;/tt&gt; for every file on S3, then I changed it to get a list of files, and check whether the &lt;tt&gt;destf&lt;/tt&gt; exists or not on that list.&lt;/p&gt;</comment>
                            <comment id="15671234" author="stakiar" created="Wed, 16 Nov 2016 18:34:31 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=spena&quot; class=&quot;user-hover&quot; rel=&quot;spena&quot;&gt;Sergio Pe&#241;a&lt;/a&gt; a few comments:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;It may be better to take a hybrid of the list files approach + the exists approach; for blobstores like S3 listfiles is only eventually consistent; this means listfiles may not return all the files that are actually there. One way to get around this is to first do the listfiles, and then checks if the targetFilename exists or not. This has the advantage of the perf gains of using listfiles, but avoids the consistency problems&lt;/li&gt;
	&lt;li&gt;I remember we discussed offline about concerns w.r.t multiple INSERT INTO queries running against the same table, but I just remembered that Hive Locking (&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Locking&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://cwiki.apache.org/confluence/display/Hive/Locking&lt;/a&gt;) should prevent that from ever happening, correct?&lt;/li&gt;
	&lt;li&gt;It would be nice (although not necessary) if we changed the name of &lt;tt&gt;renameNonLocal&lt;/tt&gt; to something more descriptive&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15671431" author="spena" created="Wed, 16 Nov 2016 19:53:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stakiar&quot; class=&quot;user-hover&quot; rel=&quot;stakiar&quot;&gt;Sahil Takiar&lt;/a&gt; Thanks. I updated the patch with:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Using an hybrid solution that checks if a file exists on the list status or if exists on the FS.&lt;/li&gt;
	&lt;li&gt;Change the renameNonLocal to renameIsAllowed&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;For the Hive lock, yes, Hive should have a lock to avoid another client inserts data on the same table.&lt;/p&gt;</comment>
                            <comment id="15671747" author="hiveqa" created="Wed, 16 Nov 2016 21:50:22 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12839221/HIVE-15199.2.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12839221/HIVE-15199.2.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to no test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 209 failed/errored test(s), 10664 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=109)
	[enforce_order.q,ppd_join2.q,smb_mapjoin_21.q,load_dyn_part15.q,udf_min.q,groupby_resolution.q,mapjoin_memcheck.q,subquery_exists.q,join27.q,alter_merge_stats_orc.q,union_remove_2.q,vector_orderby_5.q,groupby6_map_skew.q,join12.q,union9.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=128)
	[union_remove_15.q,bucket_map_join_tez1.q,groupby7_noskew.q,bucketmapjoin1.q,subquery_multiinsert.q,auto_join8.q,auto_join6.q,groupby2_map_skew.q,lateral_view_explode2.q,join28.q,load_dyn_part1.q,skewjoinopt17.q,skewjoin_union_remove_1.q,union_remove_20.q,bucketmapjoin5.q]
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[add_part_multiple] (batchId=62)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[alter_merge_2_orc] (batchId=67)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[alter_partition_coltype] (batchId=23)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[alter_table_add_partition] (batchId=16)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[alter_table_update_status] (batchId=71)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[array_map_access_nonconstant] (batchId=20)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_3] (batchId=50)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[autoColumnStats_5] (batchId=37)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[avro_add_column2] (batchId=80)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[avrocountemptytbl] (batchId=73)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[ba_table_udfs] (batchId=22)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[cbo_rp_insert] (batchId=10)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[columnStatsUpdateForStatsOptimizer_2] (batchId=27)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[column_names_with_leading_and_trailing_spaces] (batchId=21)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[complex_alias] (batchId=15)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[concat_op] (batchId=66)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[constantPropWhen] (batchId=31)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[constantfolding] (batchId=67)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[constprog_when_case] (batchId=52)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[create_merge_compressed] (batchId=38)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[cte_5] (batchId=30)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[cte_7] (batchId=23)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[cte_mat_5] (batchId=2)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[dbtxnmgr_query1] (batchId=65)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[decimal_precision] (batchId=47)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[distinct_stats] (batchId=64)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[except_all] (batchId=41)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[exim_01_nonpart] (batchId=48)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[exim_03_nonpart_over_compat] (batchId=5)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[exim_08_nonpart_rename] (batchId=55)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[exim_10_external_managed] (batchId=62)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[exim_12_external_location] (batchId=49)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[exim_13_managed_location] (batchId=35)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[exim_14_managed_location_over_existing] (batchId=48)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[exim_22_import_exist_authsuccess] (batchId=17)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[exim_24_import_nonexist_authsuccess] (batchId=17)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[folder_predicate] (batchId=4)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[groupby_distinct_samekey] (batchId=51)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[groupby_grouping_window] (batchId=29)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[groupby_nullvalues] (batchId=72)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[implicit_decimal] (batchId=61)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert0] (batchId=4)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert1] (batchId=22)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert2] (batchId=77)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_acid_not_bucketed] (batchId=62)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_compressed] (batchId=73)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_into1] (batchId=19)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_into2] (batchId=79)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_into3] (batchId=24)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_into4] (batchId=16)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_into5] (batchId=29)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_into_with_schema2] (batchId=34)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_nonacid_from_acid] (batchId=66)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_acid_not_bucketed] (batchId=16)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_nonascii] (batchId=42)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=56)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insertoverwrite_bucket] (batchId=61)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insertvalues_espchars] (batchId=63)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[join42] (batchId=22)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[join43] (batchId=5)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[join_cond_pushdown_unqual5] (batchId=60)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[join_on_varchar] (batchId=41)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[json_serde1] (batchId=31)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[llap_uncompressed] (batchId=52)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[load_orc] (batchId=70)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[macro_1] (batchId=45)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[macro_duplicate] (batchId=36)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[mapjoin2] (batchId=9)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[mapjoin_memcheck] (batchId=37)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[mapjoin_test_outer] (batchId=1)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[materialized_view_authorization_sqlstd] (batchId=42)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[materialized_view_create] (batchId=64)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[materialized_view_describe] (batchId=61)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[multi_insert_with_join2] (batchId=70)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[multi_insert_with_join] (batchId=59)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[nonreserved_keywords_insert_into1] (batchId=24)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[orc_merge11] (batchId=35)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[orc_merge8] (batchId=75)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[orc_merge9] (batchId=24)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[orc_merge_incompat1] (batchId=60)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[orc_merge_incompat2] (batchId=75)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[orc_ppd_schema_evol_1b] (batchId=30)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[orc_ppd_schema_evol_2b] (batchId=14)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[orc_ppd_str_conversion] (batchId=28)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[orc_schema_evolution_float] (batchId=30)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[orc_vectorization_ppd] (batchId=36)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[orc_wide_table] (batchId=77)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_array_map_emptynullvals] (batchId=30)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_ctas] (batchId=60)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_join2] (batchId=9)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_join] (batchId=18)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_ppd_partition] (batchId=7)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_schema_evolution] (batchId=67)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_type_promotion] (batchId=75)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[partition_coltype_literals] (batchId=12)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[ppd_join5] (batchId=32)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[ptfgroupbyjoin] (batchId=76)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[quotedid_basic] (batchId=54)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[rename_table_update_column_stats] (batchId=33)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[selectindate] (batchId=56)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[setop_no_distinct] (batchId=72)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[skewjoin_onesideskew] (batchId=64)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[smb_join_partition_key] (batchId=12)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[stats16] (batchId=4)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[statsfs] (batchId=41)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[tez_join_hash] (batchId=47)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[truncate_column_merge] (batchId=55)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[udf_folder_constants] (batchId=46)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[udtf_replicate_rows] (batchId=75)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[union37] (batchId=64)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[union_date_trim] (batchId=70)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[union_paren] (batchId=42)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[unionall_join_nullconstant] (batchId=35)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[unionall_unbalancedppd] (batchId=2)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_aggregate_9] (batchId=35)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_aggregate_without_gby] (batchId=47)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_binary_join_groupby] (batchId=73)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_bround] (batchId=30)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_bucket] (batchId=23)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_cast_constant] (batchId=8)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_char_4] (batchId=79)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_char_cast] (batchId=59)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_char_simple] (batchId=41)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_coalesce_2] (batchId=64)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_custom_udf_configure] (batchId=59)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_data_types] (batchId=68)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_date_1] (batchId=19)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_decimal_mapjoin] (batchId=50)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_decimal_round] (batchId=32)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_decimal_round_2] (batchId=21)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_distinct_2] (batchId=46)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_groupby_3] (batchId=58)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_interval_1] (batchId=14)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_left_outer_join2] (batchId=58)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_null_projection] (batchId=8)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_orderby_5] (batchId=37)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_outer_join0] (batchId=55)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_reduce1] (batchId=25)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_reduce2] (batchId=35)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_reduce3] (batchId=25)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_string_concat] (batchId=29)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_string_decimal] (batchId=2)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_struct_in] (batchId=41)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_varchar_4] (batchId=27)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_varchar_simple] (batchId=68)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_when_case_null] (batchId=32)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vectorized_bucketmapjoin1] (batchId=22)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vectorized_date_funcs] (batchId=68)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vectorized_distinct_gby] (batchId=67)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vectorized_timestamp] (batchId=69)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vectorized_timestamp_funcs] (batchId=27)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[view_alias] (batchId=74)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[windowing_windowspec4] (batchId=59)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[transform_ppr2] (batchId=133)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[join_acid_non_acid] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union_fast_stats] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=91)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_4] (batchId=91)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[delete_non_acid_table] (batchId=83)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[insert_into5] (batchId=83)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[materialized_view_authorization_create_no_grant] (batchId=83)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[materialized_view_authorization_create_no_select_perm] (batchId=83)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[materialized_view_authorization_drop_other] (batchId=83)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[materialized_view_authorization_no_select_perm] (batchId=83)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[materialized_view_drop2] (batchId=83)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[materialized_view_drop] (batchId=83)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[materialized_view_replace_with_view] (batchId=83)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[partition_column_names_with_leading_and_trailing_spaces] (batchId=83)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[update_non_acid_table] (batchId=83)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[add_part_multiple] (batchId=121)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[alter_merge_orc] (batchId=119)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[create_merge_compressed] (batchId=110)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[insert_into1] (batchId=101)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[insert_into2] (batchId=130)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[insert_into3] (batchId=104)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[mapjoin_decimal] (batchId=121)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[mapjoin_test_outer] (batchId=92)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[multi_insert_with_join] (batchId=120)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[parquet_join] (batchId=100)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[ppd_join5] (batchId=107)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[stats16] (batchId=93)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[statsfs] (batchId=111)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_date_trim] (batchId=126)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_top_level] (batchId=118)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vector_cast_constant] (batchId=96)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vector_char_4] (batchId=130)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vector_data_types] (batchId=125)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vector_decimal_mapjoin] (batchId=115)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vector_distinct_2] (batchId=114)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vector_groupby_3] (batchId=119)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vector_string_concat] (batchId=106)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vector_varchar_4] (batchId=105)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vectorization_short_regress] (batchId=112)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vectorized_ptf] (batchId=119)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[vectorized_timestamp_funcs] (batchId=105)
org.apache.hadoop.hive.metastore.hbase.TestHBaseMetastoreSql.insertIntoTable (batchId=191)
org.apache.hadoop.hive.metastore.hbase.TestHBaseMetastoreSql.partitionedTable (batchId=191)
org.apache.hadoop.hive.metastore.hbase.TestHBaseMetastoreSql.table (batchId=191)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testCompletedTxnComponents (batchId=268)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMerge3Way01 (batchId=268)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMerge3Way02 (batchId=268)
org.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testMultiInsert (batchId=268)
org.apache.hive.hcatalog.listener.TestDbNotificationListener.sqlCTAS (batchId=217)
org.apache.hive.hcatalog.listener.TestDbNotificationListener.sqlInsertPartition (batchId=217)
org.apache.hive.hcatalog.listener.TestDbNotificationListener.sqlInsertTable (batchId=217)
org.apache.hive.jdbc.TestJdbcDriver2.testNullResultSet (batchId=211)
org.apache.hive.jdbc.TestJdbcDriver2.testSerializedExecution (batchId=211)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/2156/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/2156/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/2156/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/2156/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-2156/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-2156/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 209 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12839221 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="15672593" author="stakiar" created="Thu, 17 Nov 2016 03:40:10 +0000"  >&lt;ul&gt;
	&lt;li&gt;Is the goal to trigger mvFile when the destination file is a blobstore? I don&apos;t think thats the right approach because a &lt;tt&gt;FileUtils.copy&lt;/tt&gt; will do a client-side copy when running on S3, data will be downloaded from HDFS to HS2 and then uploaded to S3; the target should be to do a server-side copy (happens internally on S3). A server side copy can only be triggered by called &lt;tt&gt;FileSystem.rename&lt;/tt&gt;.&lt;/li&gt;
	&lt;li&gt;The listing optimization can be applied to HDFS too, right? It should increase perf when running on HDFS too.&lt;/li&gt;
	&lt;li&gt;A bit orthogonal to this JIRA, but &lt;tt&gt;mvFile&lt;/tt&gt; should probably be called copyFile because it always copies data.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15673317" author="stevel@apache.org" created="Thu, 17 Nov 2016 10:13:33 +0000"  >&lt;ol&gt;
	&lt;li&gt;as sahil notes, blobstore copy calls must be in object store to get internal bandwidth &lt;b&gt;and avoid download costs&lt;/b&gt;.&lt;/li&gt;
	&lt;li&gt;that can currently only be done in rename(); if we ever added a copy() command to the FS API, your life would be better&lt;/li&gt;
	&lt;li&gt;the fact that rename returns &quot;false&quot; without details makes things worse. FWIW I&apos;m modifying spark&apos;s inner rename to throw exceptions &#8212;but as as that isn&apos;t the public FS API, it&apos;s of no use here. Though I could add an option to s3a to always throw those exceptions (a subclass of IOE) if the caller needed it. Would that help? it&apos;d only be broadly useful if HDFS &amp;amp;c also did that&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Now, what is needed to be done here? &lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;handle the situation where a list of an object store path can be out of sync with the actual contents, something that surfaces in S3 and swift. the exists/getFileStatus() call is more robust there.&lt;/li&gt;
	&lt;li&gt;handle the situation where rename(src, dest), src is a file and dest is a file, will copy src onto dest.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Short term: check the destination. I know some people will worry about the cost of the existence check, but remember this is going to trigger a copy operation, which is O(data) at about 6-8 MB/s: if you are committing large files, things will be slow.&lt;/p&gt;

&lt;p&gt;Looking at the rename semantics as tested in &lt;tt&gt;AbstractContractRenameTest&lt;/tt&gt;, the test &lt;tt&gt;testRenameFileOverExistingFile&lt;/tt&gt; has the comment &quot;handles filesystems that will overwrite the destination as well as those that do not (i.e. HDFS).&quot;. It&apos;s not just s3a which lets you rename over a test, so apparently does local &lt;a href=&quot;file://&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;file://&lt;/a&gt;. Interestingly: azure wasb:// doesn&apos;t, nor does s3n.&lt;/p&gt;


&lt;p&gt;I think we can consider the fact that s3a lets you overwrite an existing destination to be a bug, based on its inconsistency with HDFS, Azure, s3n, etc. Indeed, the difference between s3a and s3n makes it harder to say &quot;s3a is a drop-in replacement for s3n&quot;. Created &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-13823&quot; title=&quot;s3a rename: fail if dest file exists&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-13823&quot;&gt;&lt;del&gt;HADOOP-13823&lt;/del&gt;&lt;/a&gt; for you.&lt;/p&gt;</comment>
                            <comment id="15673914" author="spena" created="Thu, 17 Nov 2016 14:53:13 +0000"  >&lt;p&gt;You&apos;re right, I will do the change to use a rename() instead. This should be used on HDFS as well.&lt;/p&gt;

&lt;p&gt;The &lt;tt&gt;mvFile&lt;/tt&gt; method name is good I think, Hive is moving the file from source to target by copy and delete the file from source. &lt;/p&gt;</comment>
                            <comment id="15674461" author="spena" created="Thu, 17 Nov 2016 18:31:09 +0000"  >&lt;p&gt;Attached a new patch that addresses feedback comments. This patch will call listFiles() whatever the filesystem is, HDFS or S3, and it will call the rename() method on S3 as well to take advantage of the server-side copy.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=steve_l&quot; class=&quot;user-hover&quot; rel=&quot;steve_l&quot;&gt;Steve Loughran&lt;/a&gt; Thanks for creating the bug on HADOOP. Your suggestion about the exception, when will that happen? When the destination file already exists? Isn&apos;t going to be inconsistent with the HDFS rename() that it doesn&apos;t throw the exception?&lt;/p&gt;</comment>
                            <comment id="15674563" author="hiveqa" created="Thu, 17 Nov 2016 19:17:08 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12839415/HIVE-15199.4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12839415/HIVE-15199.4.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to no test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 5 failed/errored test(s), 10695 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[transform_ppr2] (batchId=133)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[join_acid_non_acid] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union_fast_stats] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_1] (batchId=90)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=91)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/2170/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/2170/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/2170/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/2170/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-2170/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-2170/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 5 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12839415 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="15674630" author="stakiar" created="Thu, 17 Nov 2016 19:47:42 +0000"  >&lt;ul&gt;
	&lt;li&gt;The patch does a &lt;tt&gt;listStatus&lt;/tt&gt; for each file it needs to rename, is that necessary? It may be more efficient if only one &lt;tt&gt;listStatus&lt;/tt&gt; is done outside the for loop in &lt;tt&gt;copyFiles&lt;/tt&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I would suggest modifying the following code block:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    fs.listStatus(dirPath, &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; PathFilter() {
      @Override
      &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; accept(Path path) {
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (path.getName().startsWith(filename)) {
          fileSet.add(path);
        }

        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;
      }
    });
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Is the use of the &lt;tt&gt;PathFilter&lt;/tt&gt; necessary, a &lt;tt&gt;PathFilter&lt;/tt&gt; is typically used to filter out certain files from a &lt;tt&gt;listStatus&lt;/tt&gt; call, but here is it being used to populate the &lt;tt&gt;fileSet&lt;/tt&gt; object; we should be able to accomplish the same thing without using the &lt;tt&gt;PathFilter&lt;/tt&gt;.&lt;/p&gt;</comment>
                            <comment id="15674822" author="spena" created="Thu, 17 Nov 2016 21:08:39 +0000"  >&lt;p&gt;Yeah, doing the listSTatus() once will be better. I&apos;ll try that.&lt;/p&gt;

&lt;p&gt;About the PathFilter, I used it to fill the Set&amp;lt;&amp;gt; during the listStatus(), and avoid listStatus() to create the FileStatus[] array, and then me walking through the array to push the elements to the Set&amp;lt;&amp;gt; again. I just need the path, and that way I avoid creating FileStatus objects on memory. Regarding using a Set&amp;lt;&amp;gt;, I see this is faster by walking to the different &lt;em&gt;copy&lt;/em&gt; files and check if they&apos;re contained on the Set ( O(N) ) than walking through the FileStatus[] once per every new &lt;em&gt;copy&lt;/em&gt; file ( O(N*N) ).&lt;/p&gt;</comment>
                            <comment id="15677502" author="spena" created="Fri, 18 Nov 2016 19:16:55 +0000"  >&lt;p&gt;All tests fail due to this error:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.19.1:test (default-test) on project hive-it-qfile: Unable to generate classpath: org.apache.maven.artifact.resolver.ArtifactResolutionException: Unable to get dependency information for org.apache.maven.surefire:surefire-junit4:jar:2.19.1: Failed to retrieve POM for org.apache.maven.surefire:surefire-junit4:jar:2.19.1: Could not transfer artifact org.apache.maven.surefire:surefire-junit4:pom:2.19.1 from/to central (https://repo.maven.apache.org/maven2): hostname in certificate didn&apos;t match: &amp;lt;repo.maven.apache.org&amp;gt; != &amp;lt;repo1.maven.org&amp;gt; OR &amp;lt;repo1.maven.org&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This is not related to the patch, but there&apos;s no way to validate it. I&apos;ll wait until the problem goes away.&lt;/p&gt;</comment>
                            <comment id="15677959" author="stakiar" created="Fri, 18 Nov 2016 22:27:16 +0000"  >&lt;p&gt;In &lt;tt&gt;mvFile&lt;/tt&gt; should &lt;tt&gt;while (!destFs.rename(sourcePath, destFilePath))&lt;/tt&gt; be changed to &lt;tt&gt;while (!destFs.exists(destFilePath) &amp;amp;&amp;amp; !destFs.rename(sourcePath, destFilePath))&lt;/tt&gt; this way we always check if the file exists before renaming. While slightly less performant on HDFS, its much safer for S3 since &lt;tt&gt;listFiles&lt;/tt&gt; may not return the entire contents of the directory (since its an eventually consistent operation).&lt;/p&gt;

&lt;p&gt;Other than that +1 assuming Hive QA comes back normally.&lt;/p&gt;</comment>
                            <comment id="15678226" author="hiveqa" created="Sat, 19 Nov 2016 00:35:02 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12839599/HIVE-15199.5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12839599/HIVE-15199.5.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 1 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 13 failed/errored test(s), 10668 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=108)
	[tez_joins_explain.q,transform2.q,groupby5.q,cbo_semijoin.q,bucketmapjoin13.q,union_remove_6_subq.q,groupby2_map_multi_distinct.q,load_dyn_part9.q,multi_insert_gby2.q,vectorization_11.q,groupby_position.q,avro_compression_enabled_native.q,smb_mapjoin_8.q,join21.q,auto_join16.q]
TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=118)
	[stats12.q,groupby4.q,union_top_level.q,groupby10.q,subquery_in.q,mapjoin_filter_on_outerjoin.q,auto_sortmerge_join_4.q,limit_partition_metadataonly.q,load_dyn_part4.q,union3.q,groupby_multi_single_reducer.q,smb_mapjoin_14.q,groupby3_noskew_multi_distinct.q,stats18.q,union_remove_21.q]
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[transform_ppr2] (batchId=133)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[join_acid_non_acid] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union_fast_stats] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_3] (batchId=90)
org.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=94)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[escape_sortby1] (batchId=111)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[groupby_multi_single_reducer3] (batchId=111)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[join29] (batchId=111)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[leftsemijoin] (batchId=111)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[statsfs] (batchId=111)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_6] (batchId=111)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/2202/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/2202/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/2202/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/2202/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-2202/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-2202/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 13 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12839599 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="15679190" author="stevel@apache.org" created="Sat, 19 Nov 2016 12:35:00 +0000"  >&lt;p&gt;if you do listStatus(path, recursive=true) you don&apos;t get back a filestatus array, you get an interator back; on s3a branch 2.8+ this goes through the results of the list, triggering new listing requests on demand: &lt;a href=&quot;https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/Listing.java#L171&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/Listing.java#L171&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To make effective use of this feature, you do have to list through the results, otherwise it won&apos;t do the listing operation...you may as well build the set up from that iteration&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;

RemoteIterator&amp;lt;FileStatus&amp;gt; it = fs.listStatus(path, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;)
&lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (it.hasNext()) {
  FileStatus s = it.next()
 &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!fileSet.contains(s)) {
   fileSet.add(s);
 }
}

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;On other filesystems listStatus does a recursive treewalk, no more/less expensive than doing it in your own code&lt;/p&gt;</comment>
                            <comment id="15682094" author="spena" created="Mon, 21 Nov 2016 00:18:53 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stevel%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;stevel@apache.org&quot;&gt;Steve Loughran&lt;/a&gt; What call is better to use, listStatus() or listFiles()? I&apos;ve heard listFiles() would be better if I want to get files recursively. I&apos;m using listFiles() in the patch instead. Is that ok?&lt;/p&gt;</comment>
                            <comment id="15682107" author="spena" created="Mon, 21 Nov 2016 00:27:34 +0000"  >&lt;p&gt;Seems all tests are flaky and no related to this patch. I&apos;m attaching a new one that contains one little change to include the &lt;tt&gt;destFs.exists()&lt;/tt&gt; call. This will also check if those flaky tests are not failing anymore.&lt;/p&gt;</comment>
                            <comment id="15682195" author="hiveqa" created="Mon, 21 Nov 2016 01:34:18 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12839735/HIVE-15199.6.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12839735/HIVE-15199.6.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 1 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 19 failed/errored test(s), 10728 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[auto_sortmerge_join_2] (batchId=43)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[transform_ppr2] (batchId=133)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[join_acid_non_acid] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union_fast_stats] (batchId=145)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[bucket_map_join_spark2] (batchId=93)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[bucketmapjoin2] (batchId=93)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[cbo_udf_udaf] (batchId=93)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[groupby_cube1] (batchId=93)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[join13] (batchId=93)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[join_vc] (batchId=93)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[ptf_decimal] (batchId=93)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[sample3] (batchId=93)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[smb_mapjoin_19] (batchId=93)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[stats16] (batchId=93)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union23] (batchId=93)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union31] (batchId=93)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union] (batchId=93)
org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[union_remove_7] (batchId=93)
org.apache.hive.spark.client.TestSparkClient.testJobSubmission (batchId=272)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/2220/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/2220/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/2220/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/2220/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-2220/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-2220/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 19 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12839735 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="15684089" author="spena" created="Mon, 21 Nov 2016 16:58:05 +0000"  >&lt;p&gt;All those tests are passing on my local machine. I&apos;ll rerun the tests on HiveQA as I see other JIRAs are not failing anymore. They might have already fixed.&lt;/p&gt;</comment>
                            <comment id="15684283" author="stevel@apache.org" created="Mon, 21 Nov 2016 18:10:45 +0000"  >&lt;p&gt;you are right, I am wrong: serves me right for commenting without staring at the code. you should be calling; I got confused by naming.&lt;/p&gt;

&lt;p&gt;you should be invoking&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
RemoteIterator&amp;lt;LocatedFileStatus&amp;gt; listFiles(Path f,  &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; recursive) 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;with recursive = true.&lt;/p&gt;

&lt;p&gt;this defaults to a standard recursive treewalk; on object stores we can do an O(1) listing of all child files, irrespective of directory depth and width. For anything other than a flat directory, this is a significant speedup&lt;/p&gt;</comment>
                            <comment id="15684424" author="hiveqa" created="Mon, 21 Nov 2016 19:00:05 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12839839/HIVE-15199.7.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12839839/HIVE-15199.7.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 1 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 5 failed/errored test(s), 10729 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[transform_ppr2] (batchId=133)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[join_acid_non_acid] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union_fast_stats] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=91)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_4] (batchId=91)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/2228/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/2228/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/2228/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/2228/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-2228/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-2228/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 5 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12839839 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="15684448" author="spena" created="Mon, 21 Nov 2016 19:11:26 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=aihuaxu&quot; class=&quot;user-hover&quot; rel=&quot;aihuaxu&quot;&gt;Aihua Xu&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ashutoshc&quot; class=&quot;user-hover&quot; rel=&quot;ashutoshc&quot;&gt;Ashutosh Chauhan&lt;/a&gt; Could any of you help me review this patch or if you can refer me anyone with knowledge of this code? It was already reviewed by the folks on this JIRA. Tests are passing, and the S3 tests passed to. I just need a committer do a +1 before commit it.&lt;/p&gt;</comment>
                            <comment id="15684931" author="yalovyyi" created="Mon, 21 Nov 2016 22:24:18 +0000"  >&lt;p&gt;I really like having query_id as part of the name. It helps a lot with many problems. For s3 in particular eventual consistency is one of them.&lt;/p&gt;</comment>
                            <comment id="15684935" author="yalovyyi" created="Mon, 21 Nov 2016 22:26:01 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=spena&quot; class=&quot;user-hover&quot; rel=&quot;spena&quot;&gt;Sergio Pe&#241;a&lt;/a&gt;, I would love to take a look at this patch, but I don&apos;t see a link to a review board. Did I miss it?&lt;/p&gt;</comment>
                            <comment id="15684948" author="spena" created="Mon, 21 Nov 2016 22:30:54 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yalovyyi&quot; class=&quot;user-hover&quot; rel=&quot;yalovyyi&quot;&gt;Illya Yalovyy&lt;/a&gt; I just linked the RB to the jira. &lt;a href=&quot;https://reviews.apache.org/r/53966/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/53966/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15684955" author="spena" created="Mon, 21 Nov 2016 22:34:25 +0000"  >&lt;p&gt;That would be really helpful. I don&apos;t know how hard or easy that would be as I&apos;ve seen Hive uses the &lt;em&gt;copy&lt;/em&gt;# in other parts of the code. We could try to solve that in another jira as a good supportability item for S3.&lt;/p&gt;</comment>
                            <comment id="15685151" author="spena" created="Mon, 21 Nov 2016 23:53:31 +0000"  >&lt;p&gt;Attach a new patch that do not call &lt;tt&gt;destFs.exists&lt;/tt&gt; when HDFS is used. This is to avoid performance penalties when HDFS Is used.&lt;/p&gt;</comment>
                            <comment id="15685334" author="hiveqa" created="Tue, 22 Nov 2016 01:24:17 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12839914/HIVE-15199.8.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12839914/HIVE-15199.8.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 1 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 5 failed/errored test(s), 10716 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=108)
	[tez_joins_explain.q,transform2.q,groupby5.q,cbo_semijoin.q,bucketmapjoin13.q,union_remove_6_subq.q,groupby2_map_multi_distinct.q,load_dyn_part9.q,multi_insert_gby2.q,vectorization_11.q,groupby_position.q,avro_compression_enabled_native.q,smb_mapjoin_8.q,join21.q,auto_join16.q]
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_schema_evol_3a] (batchId=133)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[transform_ppr2] (batchId=133)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[join_acid_non_acid] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union_fast_stats] (batchId=145)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/2234/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/2234/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/2234/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/2234/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-2234/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-2234/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 5 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12839914 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="15687108" author="stevel@apache.org" created="Tue, 22 Nov 2016 15:58:52 +0000"  >&lt;p&gt;I do think I&apos;d rather fix this in s3, because it is adding 2 GET calls and a LIST before each rename, calls which take place in the rename itself. And of course, when Hadoop 2.8 or derivatives change s3a&apos;s rename to == HDFS, the check will be superfluous. Similarly, once you have a consistent FS view (s3guard, etc),  you are less likely to see a mismatch between listing and stat-ing. If you are, it means something else is writing to the same dir, putting you in trouble.&lt;/p&gt;

&lt;p&gt;Would it be possible to set this up to make it easy to turn off in future. For example: create the JIRA on stripping the exists check out?&lt;/p&gt;</comment>
                            <comment id="15687154" author="spena" created="Tue, 22 Nov 2016 16:17:52 +0000"  >&lt;p&gt;I moved the listFiles() to the beginning of the method to avoid calling it for each new rename. However, we still have the 2 GET calls on each rename (exists &amp;amp;&amp;amp; rename), I added a validation to do this on S3 only, and leave only the rename call on HDFS.&lt;/p&gt;

&lt;p&gt;As you mentioned, when S3Guard is released, this would help us a lot on consistency, and we could remove the exists() call. I think the listFiles() is still beneficial so Hive can figure out the next filename to use when renaming the file.&lt;/p&gt;

&lt;p&gt;The code change is pretty easy, so I can create a Jira to remove it in the future.&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;+      boolean isBlobStoragePath = BlobStorageUtils.isBlobStoragePath(conf, destDirPath);
+      while ((isBlobStoragePath &amp;amp;&amp;amp; destFs.exists(destFilePath)) || !destFs.rename(sourcePath, destFilePath)) {
+        destFilePath = createCopyFilePath(destDirPath, name, type, ++counter);
+      }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Is the S3Guard going to be released on Hadoop 2.8?&lt;/p&gt;</comment>
                            <comment id="15687764" author="gopalv" created="Tue, 22 Nov 2016 20:12:58 +0000"  >&lt;p&gt;The &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-14535&quot; title=&quot;add micromanaged tables to Hive (metastore keeps track of the files)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-14535&quot;&gt;HIVE-14535&lt;/a&gt; branch might be interesting to compare, since it prevents multiple queries from using the same path.&lt;/p&gt;</comment>
                            <comment id="15687962" author="yalovyyi" created="Tue, 22 Nov 2016 21:32:10 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=spena&quot; class=&quot;user-hover&quot; rel=&quot;spena&quot;&gt;Sergio Pe&#241;a&lt;/a&gt; Thank you for the CR link. I have added some comments.&lt;/p&gt;</comment>
                            <comment id="15687963" author="stakiar" created="Tue, 22 Nov 2016 21:32:36 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yalovyyi&quot; class=&quot;user-hover&quot; rel=&quot;yalovyyi&quot;&gt;Illya Yalovyy&lt;/a&gt; what other problems with S3 do you think this would help with? In what way would this help with eventual consistency? I agree having the query-id in the file name is good, but I do agree with Sergio that we need to be careful and see what other parts of the code rely on the file name. We should also be wary if any external clients rely on these file names.&lt;/p&gt;</comment>
                            <comment id="15688151" author="spena" created="Tue, 22 Nov 2016 22:37:01 +0000"  >&lt;p&gt;Addressed issues from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yalovyyi&quot; class=&quot;user-hover&quot; rel=&quot;yalovyyi&quot;&gt;Illya Yalovyy&lt;/a&gt; on the RB.&lt;/p&gt;

&lt;p&gt;Also, I&apos;ll keep to the if (!exists || !rename) condition on S3, and not using the listFiles() to avoid OOM issues with concurrent HS2 requests. We can design a better performance approach in a different JIRA.&lt;/p&gt;</comment>
                            <comment id="15688250" author="ychena" created="Tue, 22 Nov 2016 23:15:11 +0000"  >&lt;p&gt;+1 for 9th patch pending tests&lt;/p&gt;</comment>
                            <comment id="15688635" author="hiveqa" created="Wed, 23 Nov 2016 02:19:54 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12840142/HIVE-15199.9.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12840142/HIVE-15199.9.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 1 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 29 failed/errored test(s), 10717 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=118)
	[stats12.q,groupby4.q,union_top_level.q,groupby10.q,subquery_in.q,mapjoin_filter_on_outerjoin.q,auto_sortmerge_join_4.q,limit_partition_metadataonly.q,load_dyn_part4.q,union3.q,groupby_multi_single_reducer.q,smb_mapjoin_14.q,groupby3_noskew_multi_distinct.q,stats18.q,union_remove_21.q]
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[annotate_stats_deep_filters] (batchId=80)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[dynamic_partition_insert] (batchId=50)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[input43] (batchId=2)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[load_orc] (batchId=70)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[load_orc_part] (batchId=13)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[orc_merge11] (batchId=36)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[orc_merge12] (batchId=56)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[orc_merge9] (batchId=24)
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[orc_merge_incompat3] (batchId=8)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[global_limit] (batchId=133)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_llap_counters1] (batchId=131)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_llap_counters] (batchId=135)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=131)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_schema_evol_3a] (batchId=133)
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[transform_ppr2] (batchId=133)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[join_acid_non_acid] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[orc_merge11] (batchId=143)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[orc_merge9] (batchId=140)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[orc_merge_incompat3] (batchId=137)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union_fast_stats] (batchId=145)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[orc_merge9] (batchId=156)
org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[parallel_orderby] (batchId=157)
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[orc_merge12] (batchId=90)
org.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver[parallel_orderby] (batchId=81)
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[load_orc_negative_part] (batchId=83)
org.apache.hive.hcatalog.pig.TestSequenceFileHCatStorer.testWriteDecimal (batchId=170)
org.apache.hive.hcatalog.pig.TestSequenceFileHCatStorer.testWriteDecimalXY (batchId=170)
org.apache.hive.spark.client.TestSparkClient.testJobSubmission (batchId=272)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/2250/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/2250/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/2250/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/2250/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-2250/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-2250/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 29 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12840142 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="15691000" author="hiveqa" created="Wed, 23 Nov 2016 18:42:32 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12840269/HIVE-15199.10.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12840269/HIVE-15199.10.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 1 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 4 failed/errored test(s), 10718 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=107)
	[groupby_grouping_id2.q,input17.q,bucketmapjoin12.q,ppd_gby_join.q,auto_join10.q,ptf_rcfile.q,vectorized_rcfile_columnar.q,vector_elt.q,ppd_join5.q,ppd_join.q,join_filters_overlap.q,join_cond_pushdown_1.q,timestamp_3.q,load_dyn_part6.q,stats_noscan_2.q]
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[transform_ppr2] (batchId=133)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[join_acid_non_acid] (batchId=150)
org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union_fast_stats] (batchId=145)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/2263/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/2263/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HIVE-Build/2263/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HIVE-Build/2263/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://104.198.109.242/logs/PreCommit-HIVE-Build-2263/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://104.198.109.242/logs/PreCommit-HIVE-Build-2263/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 4 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12840269 - PreCommit-HIVE-Build&lt;/p&gt;</comment>
                            <comment id="15691008" author="spena" created="Wed, 23 Nov 2016 18:45:35 +0000"  >&lt;p&gt;Thanks all for the code review. I committed this to master.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13021416">HADOOP-13823</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12936219">HIVE-12988</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="12310050">
                    <name>Regression</name>
                                            <outwardlinks description="breaks">
                                        <issuelink>
            <issuekey id="13023066">HIVE-15280</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12840269" name="HIVE-15199.10.patch" size="16260" author="spena" created="Wed, 23 Nov 2016 15:53:35 +0000"/>
                            <attachment id="12839914" name="HIVE-15199.8.patch" size="20147" author="spena" created="Mon, 21 Nov 2016 23:53:31 +0000"/>
                            <attachment id="12840142" name="HIVE-15199.9.patch" size="16104" author="spena" created="Tue, 22 Nov 2016 22:37:01 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 15 Nov 2016 11:30:29 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 week, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i36b2n:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>