<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sun Dec 04 00:11:27 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HIVE-3420/HIVE-3420.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HIVE-3420] Inefficiency in hbase handler when process query including rowkey range scan</title>
                <link>https://issues.apache.org/jira/browse/HIVE-3420</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;When query hive with hbase rowkey range, hive map tasks do not leverage startrow, endrow information in tablesplit. For example, if the rowkeys fit into 5 hbase files, then where will be 5 map tasks. Ideally, each task will process 1 file. But in current implementation, each task processes 5 files repeatedly. The behavior not only waste network bandwidth, but also worse the lock contention in HBase block cache as each task have to access the same block. The problem code is in HiveHBaseTableInputFormat.convertFilte as below:&lt;br/&gt;
&#8230;&#8230;&lt;br/&gt;
    if (tableSplit != null) &lt;/p&gt;
{
      tableSplit = new TableSplit(
        tableSplit.getTableName(),
        startRow,
        stopRow,
        tableSplit.getRegionLocation());
    }
&lt;p&gt;    scan.setStartRow(startRow);&lt;br/&gt;
    scan.setStopRow(stopRow);&lt;br/&gt;
&#8230;&#8230;&lt;br/&gt;
As tableSplit already include startRow, endRow information of file, the better implementation will be:&lt;/p&gt;

&lt;p&gt;        &#8230;&#8230;&lt;br/&gt;
        byte[] splitStart = startRow;&lt;br/&gt;
        byte[] splitStop = stopRow;&lt;br/&gt;
    if (tableSplit != null) {&lt;/p&gt;

&lt;p&gt;           if(tableSplit.getStartRow() != null)&lt;/p&gt;
{
                        splitStart = startRow.length == 0 ||
          Bytes.compareTo(tableSplit.getStartRow(), startRow) &amp;gt;= 0 ?
            tableSplit.getStartRow() : startRow;
                }
&lt;p&gt;                if(tableSplit.getEndRow() != null)&lt;/p&gt;
{
                        splitStop = (stopRow.length == 0 ||
          Bytes.compareTo(tableSplit.getEndRow(), stopRow) &amp;lt;= 0) &amp;amp;&amp;amp;
          tableSplit.getEndRow().length &amp;gt; 0 ?
            tableSplit.getEndRow() : stopRow;
                }
&lt;p&gt;                       &lt;br/&gt;
      tableSplit = new TableSplit(&lt;br/&gt;
        tableSplit.getTableName(),&lt;br/&gt;
        splitStart,&lt;br/&gt;
        splitStop,&lt;br/&gt;
        tableSplit.getRegionLocation());&lt;br/&gt;
    }&lt;br/&gt;
    scan.setStartRow(splitStart);&lt;br/&gt;
    scan.setStopRow(splitStop);&lt;br/&gt;
        &#8230;&#8230;&lt;br/&gt;
In my test, the changed code will improve performance more than 30%.&lt;/p&gt;</description>
                <environment>&lt;p&gt;Hive-0.9.0 + HBase-0.94.1&lt;/p&gt;</environment>
        <key id="12605650">HIVE-3420</key>
            <summary>Inefficiency in hbase handler when process query including rowkey range scan</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="navis">Navis</assignee>
                                    <reporter username="gang">Gang Deng</reporter>
                        <labels>
                    </labels>
                <created>Fri, 31 Aug 2012 07:10:55 +0000</created>
                <updated>Sun, 11 Oct 2015 07:22:57 +0000</updated>
                            <resolved>Sun, 22 Sep 2013 08:17:06 +0000</resolved>
                                                    <fixVersion>0.13.0</fixVersion>
                                    <component>HBase Handler</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>9</watches>
                                    <timeoriginalestimate seconds="7200">2h</timeoriginalestimate>
                            <timeestimate seconds="7200">2h</timeestimate>
                                        <comments>
                            <comment id="13482075" author="lianhuiwang" created="Tue, 23 Oct 2012 03:12:21 +0000"  >&lt;p&gt;@Gong Deng&lt;br/&gt;
yes,i agree with you.in InputFormat getRecordReader()&lt;br/&gt;
tableSplit = convertFilter(jobConf, scan, tableSplit, iKey,&lt;br/&gt;
      getStorageFormatOfKey(columnsMapping.get(iKey).mappingSpec,&lt;br/&gt;
      jobConf.get(HBaseSerDe.HBASE_TABLE_DEFAULT_STORAGE_TYPE, &quot;string&quot;)));&lt;br/&gt;
it have done&lt;br/&gt;
tableSplit = new TableSplit(&lt;br/&gt;
        tableSplit.getTableName(),&lt;br/&gt;
        startRow,&lt;br/&gt;
        stopRow,&lt;br/&gt;
        tableSplit.getRegionLocation(),&lt;br/&gt;
	tableSplit.getConf());&lt;br/&gt;
also in getplits(),a tableSplit lead to a regionLocation task.now that splits have not any effect. &lt;br/&gt;
so startRow,stopRow in tableSplit is inside the region row ranges in tableSplit.&lt;/p&gt;

&lt;p&gt;IMO,the convertFilter() logic code used in many places.for example:&lt;br/&gt;
HBaseStorageHandler.decomposePredicate()&lt;br/&gt;
HiveHBaseTableInputFormat.getSplits()&lt;br/&gt;
HiveHBaseTableInputFormat.getRecordReader()&lt;/p&gt;

&lt;p&gt;i think there need one place to use it. in HBaseStorageHandler.decomposePredicate().and that can store row key ranges.&lt;br/&gt;
and then HiveHBaseTableInputFormat.getSplits(),HiveHBaseTableInputFormat.getRecordReader() according to table&apos;s regioninfo split the key ranges tasks.&lt;/p&gt;

&lt;p&gt;other have ideas?thx.&lt;/p&gt;
</comment>
                            <comment id="13529641" author="navis" created="Wed, 12 Dec 2012 05:52:37 +0000"  >&lt;p&gt;@Gang Deng &lt;br/&gt;
This is pretty important issue. I&apos;ll make a patch for a review.&lt;/p&gt;</comment>
                            <comment id="13529688" author="phabricator@reviews.facebook.net" created="Wed, 12 Dec 2012 07:05:20 +0000"  >&lt;p&gt;navis requested code review of &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3420&quot; title=&quot;Inefficiency in hbase handler when process query including rowkey range scan&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3420&quot;&gt;&lt;del&gt;HIVE-3420&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Inefficiency in hbase handler when process query including rowkey range scan&quot;.&lt;br/&gt;
Reviewers: JIRA&lt;/p&gt;

&lt;p&gt;  DPAL-1943 Inefficiency in hbase handler when process query including rowkey range scan&lt;/p&gt;

&lt;p&gt;  When query hive with hbase rowkey range, hive map tasks do not leverage startrow, endrow information in tablesplit. For example, if the rowkeys fit into 5 hbase files, then where will be 5 map tasks. Ideally, each task will process 1 file. But in current implementation, each task processes 5 files repeatedly. The behavior not only waste network bandwidth, but also worse the lock contention in HBase block cache as each task have to access the same block. The problem code is in HiveHBaseTableInputFormat.convertFilte as below:&lt;br/&gt;
  &#8230;&#8230;&lt;br/&gt;
      if (tableSplit != null)&lt;/p&gt;
  {
        tableSplit = new TableSplit(
          tableSplit.getTableName(),
          startRow,
          stopRow,
          tableSplit.getRegionLocation());
      }
&lt;p&gt;      scan.setStartRow(startRow);&lt;br/&gt;
      scan.setStopRow(stopRow);&lt;br/&gt;
  &#8230;&#8230;&lt;br/&gt;
  As tableSplit already include startRow, endRow information of file, the better implementation will be:&lt;/p&gt;

&lt;p&gt;          &#8230;&#8230;&lt;br/&gt;
          byte[] splitStart = startRow;&lt;br/&gt;
          byte[] splitStop = stopRow;&lt;br/&gt;
      if (tableSplit != null) {&lt;/p&gt;

&lt;p&gt;             if(tableSplit.getStartRow() != null)&lt;/p&gt;
  {
                          splitStart = startRow.length == 0 ||
            Bytes.compareTo(tableSplit.getStartRow(), startRow) &amp;gt;= 0 ?
              tableSplit.getStartRow() : startRow;
                  }
&lt;p&gt;                  if(tableSplit.getEndRow() != null)&lt;/p&gt;
  {
                          splitStop = (stopRow.length == 0 ||
            Bytes.compareTo(tableSplit.getEndRow(), stopRow) &amp;lt;= 0) &amp;amp;&amp;amp;
            tableSplit.getEndRow().length &amp;gt; 0 ?
              tableSplit.getEndRow() : stopRow;
                  }

&lt;p&gt;        tableSplit = new TableSplit(&lt;br/&gt;
          tableSplit.getTableName(),&lt;br/&gt;
          splitStart,&lt;br/&gt;
          splitStop,&lt;br/&gt;
          tableSplit.getRegionLocation());&lt;br/&gt;
      }&lt;br/&gt;
      scan.setStartRow(splitStart);&lt;br/&gt;
      scan.setStopRow(splitStop);&lt;br/&gt;
          &#8230;&#8230;&lt;br/&gt;
  In my test, the changed code will improve performance more than 30%.&lt;/p&gt;

&lt;p&gt;TEST PLAN&lt;br/&gt;
  EMPTY&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D7311&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D7311&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AFFECTED FILES&lt;br/&gt;
  hbase-handler/src/java/org/apache/hadoop/hive/hbase/HiveHBaseTableInputFormat.java&lt;/p&gt;

&lt;p&gt;MANAGE HERALD DIFFERENTIAL RULES&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/view/differential/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/view/differential/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WHY DID I GET THIS EMAIL?&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/herald/transcript/17415/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/herald/transcript/17415/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To: JIRA, navis&lt;/p&gt;</comment>
                            <comment id="13685109" author="navis" created="Mon, 17 Jun 2013 08:59:09 +0000"  >&lt;p&gt;For a table with two region, executed simple query with PPD-able predicates,&lt;br/&gt;
input rows (without patch) : 2,472 rows &lt;br/&gt;
input rows (with patch) : 1,236 rows&lt;/p&gt;

&lt;p&gt;For large hbase table, it can make a big difference.&lt;/p&gt;</comment>
                            <comment id="13773917" author="phabricator@reviews.facebook.net" created="Sat, 21 Sep 2013 22:12:52 +0000"  >&lt;p&gt;ashutoshc has accepted the revision &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3420&quot; title=&quot;Inefficiency in hbase handler when process query including rowkey range scan&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3420&quot;&gt;&lt;del&gt;HIVE-3420&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Inefficiency in hbase handler when process query including rowkey range scan&quot;.&lt;/p&gt;

&lt;p&gt;  +1&lt;/p&gt;

&lt;p&gt;REVISION DETAIL&lt;br/&gt;
  &lt;a href=&quot;https://reviews.facebook.net/D7311&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.facebook.net/D7311&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BRANCH&lt;br/&gt;
  DPAL-1943&lt;/p&gt;

&lt;p&gt;ARCANIST PROJECT&lt;br/&gt;
  hive&lt;/p&gt;

&lt;p&gt;To: JIRA, ashutoshc, navis&lt;/p&gt;</comment>
                            <comment id="13773988" author="ashutoshc" created="Sun, 22 Sep 2013 08:17:06 +0000"  >&lt;p&gt;Committed to trunk. Thanks, Navis!&lt;/p&gt;</comment>
                            <comment id="13773996" author="hudson" created="Sun, 22 Sep 2013 09:43:54 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-h0.21 #2350 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-h0.21/2350/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-h0.21/2350/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3420&quot; title=&quot;Inefficiency in hbase handler when process query including rowkey range scan&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3420&quot;&gt;&lt;del&gt;HIVE-3420&lt;/del&gt;&lt;/a&gt; : Inefficiency in hbase handler when process query including rowkey range scan (Navis via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1525329&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1525329&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HiveHBaseTableInputFormat.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13774003" author="hudson" created="Sun, 22 Sep 2013 11:38:42 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hive-trunk-hadoop1-ptest #179 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/179/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/179/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3420&quot; title=&quot;Inefficiency in hbase handler when process query including rowkey range scan&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3420&quot;&gt;&lt;del&gt;HIVE-3420&lt;/del&gt;&lt;/a&gt; : Inefficiency in hbase handler when process query including rowkey range scan (Navis via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1525329&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1525329&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HiveHBaseTableInputFormat.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13774096" author="hudson" created="Sun, 22 Sep 2013 21:32:56 +0000"  >&lt;p&gt;FAILURE: Integrated in Hive-trunk-hadoop2 #451 (See &lt;a href=&quot;https://builds.apache.org/job/Hive-trunk-hadoop2/451/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/Hive-trunk-hadoop2/451/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-3420&quot; title=&quot;Inefficiency in hbase handler when process query including rowkey range scan&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-3420&quot;&gt;&lt;del&gt;HIVE-3420&lt;/del&gt;&lt;/a&gt; : Inefficiency in hbase handler when process query including rowkey range scan (Navis via Ashutosh Chauhan) (hashutosh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1525329&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1525329&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hive/trunk/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HiveHBaseTableInputFormat.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12639670">HIVE-4247</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12857415">HIVE-11609</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12560520" name="HIVE-3420.D7311.1.patch" size="4748" author="phabricator@reviews.facebook.net" created="Wed, 12 Dec 2012 07:05:20 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 23 Oct 2012 03:12:21 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>240708</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 10 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i014tz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4552</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>