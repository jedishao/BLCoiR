<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 02 05:48:20 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HIVE-12538/HIVE-12538.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HIVE-12538] After set spark related config, SparkSession never get reused</title>
                <link>https://issues.apache.org/jira/browse/HIVE-12538</link>
                <project id="12310843" key="HIVE">Hive</project>
                    <description>&lt;p&gt;Hive on Spark yarn-cluster mode.&lt;br/&gt;
After setting &quot;set spark.yarn.queue=QueueA;&quot; ,&lt;br/&gt;
run the query &quot;select count&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/star_yellow.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; from test&quot;  3 times and you will find  3 different yarn applications.&lt;br/&gt;
Two of the yarn applications in FINISHED &amp;amp; SUCCEEDED state,and one in RUNNING &amp;amp; UNDEFINED state waiting for next work.&lt;br/&gt;
And if you submit one more &quot;select count&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/star_yellow.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; from test&quot; ,the third one will be in FINISHED &amp;amp; SUCCEEDED state and a new yarn application will start up.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12916710">HIVE-12538</key>
            <summary>After set spark related config, SparkSession never get reused</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="nemon">Nemon Lou</assignee>
                                    <reporter username="nemon">Nemon Lou</reporter>
                        <labels>
                    </labels>
                <created>Sat, 28 Nov 2015 04:47:27 +0000</created>
                <updated>Tue, 21 Jun 2016 15:52:31 +0000</updated>
                            <resolved>Wed, 16 Dec 2015 16:54:30 +0000</resolved>
                                    <version>1.3.0</version>
                                    <fixVersion>2.1.0</fixVersion>
                                    <component>Spark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="15030396" author="xuefuz" created="Sat, 28 Nov 2015 06:05:55 +0000"  >&lt;p&gt;I tried but wasn&apos;t able to reproduce.&lt;/p&gt;</comment>
                            <comment id="15030405" author="nemon" created="Sat, 28 Nov 2015 06:27:47 +0000"  >&lt;p&gt;After debugging ,i find the problem is that ,the operation conf object SparkUtilities used to detect configuration change is different from session conf.&lt;br/&gt;
And the session conf object &apos;s getSparkConfigUpdated method always return true after setting spark related config.&lt;br/&gt;
The code path where SQLOperation copy a new conf object from session conf:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/hive/blob/spark/service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java#L467&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/hive/blob/spark/service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java#L467&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
/**
   * If there are query specific settings to overlay, then create a copy of config
   * There are two cases we need to clone the session config that&apos;s being passed to hive driver
   * 1. Async query -
   *    If the client changes a config setting, that shouldn&apos;t reflect in the execution already underway
   * 2. confOverlay -
   *    The query specific settings should only be applied to the query config and not session
   * @&lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; configuration
   * @&lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; HiveSQLException
   */
  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; HiveConf getConfigForOperation() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; HiveSQLException {
    HiveConf sqlOperationConf = getParentSession().getHiveConf();
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!getConfOverlay().isEmpty() || shouldRunAsync()) {
      &lt;span class=&quot;code-comment&quot;&gt;// clone the partent session config &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; query
&lt;/span&gt;      sqlOperationConf = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; HiveConf(sqlOperationConf);

      &lt;span class=&quot;code-comment&quot;&gt;// apply overlay query specific settings, &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; any
&lt;/span&gt;      &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (Map.Entry&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; confEntry : getConfOverlay().entrySet()) {
        &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
          sqlOperationConf.verifyAndSet(confEntry.getKey(), confEntry.getValue());
        } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (IllegalArgumentException e) {
          &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; HiveSQLException(&lt;span class=&quot;code-quote&quot;&gt;&quot;Error applying statement specific settings&quot;&lt;/span&gt;, e);
        }
      }
    }
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; sqlOperationConf;
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The code path where SparkUtilities detect the change and close the spark session :&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/hive/blob/spark/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkUtilities.java#L122&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/apache/hive/blob/spark/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkUtilities.java#L122&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; SparkSession getSparkSession(HiveConf conf,
      SparkSessionManager sparkSessionManager) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; HiveException {
    SparkSession sparkSession = SessionState.get().getSparkSession();

    &lt;span class=&quot;code-comment&quot;&gt;// Spark configurations are updated close the existing session
&lt;/span&gt;    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (conf.getSparkConfigUpdated()) {
      sparkSessionManager.closeSession(sparkSession);
      sparkSession =  &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
      conf.setSparkConfigUpdated(&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;);
    }
    sparkSession = sparkSessionManager.getSession(sparkSession, conf, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;);
    SessionState.get().setSparkSession(sparkSession);
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; sparkSession;
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It shoud be easy to reproduce, i will dig more.&lt;/p&gt;
</comment>
                            <comment id="15030446" author="nemon" created="Sat, 28 Nov 2015 10:01:26 +0000"  >&lt;p&gt;A way to reproduce:&lt;br/&gt;
1, open beeline&lt;br/&gt;
2, run the following SQL:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;create table if not exists test(id int);
set hive.execution.engine=spark;
set spark.yarn.queue=QueueA;
select count(*) from test;
select count(*) from test;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;3,check yarn UI,and there will be two yarn applications .&lt;/p&gt;

&lt;p&gt;Howerver,changing orders in step 2(the last setting command before actual query is not a spark related parameter),the problem will be gone:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;create table if not exists test(id int);
set spark.yarn.queue=QueueA;
set hive.execution.engine=spark;
select count(*) from test;
select count(*) from test;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
</comment>
                            <comment id="15030451" author="nemon" created="Sat, 28 Nov 2015 10:15:39 +0000"  >&lt;p&gt;Actually,there are two bugs:&lt;br/&gt;
1, Property isSparkConfigUpdated of HiveConf.java always get updated when setting values from client side(beeline).&lt;br/&gt;
    set spark.yarn.queue=QueueA; ---&amp;gt; isSparkConfigUpdated =true&lt;br/&gt;
    set hive.execution.engine=spark; ---&amp;gt; isSparkConfigUpdated =false&lt;br/&gt;
2, SparkTask uses an operation level conf object other than session level conf.&lt;br/&gt;
That makes &quot;conf.setSparkConfigUpdated(false);&quot; in SparkUtilities meaningless from session&apos;s view.&lt;/p&gt;</comment>
                            <comment id="15030662" author="xuefuz" created="Sat, 28 Nov 2015 21:00:21 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jxiang&quot; class=&quot;user-hover&quot; rel=&quot;jxiang&quot;&gt;Jimmy Xiang&lt;/a&gt;, could you please check and verify if there are bugs on this? Thanks.&lt;/p&gt;</comment>
                            <comment id="15031109" author="jxiang" created="Sun, 29 Nov 2015 18:13:56 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nemon&quot; class=&quot;user-hover&quot; rel=&quot;nemon&quot;&gt;Nemon Lou&lt;/a&gt;, good findings. Do you want to post a patch? Otherwise, I can do it. Thanks.&lt;/p&gt;</comment>
                            <comment id="15031277" author="nemon" created="Mon, 30 Nov 2015 03:06:48 +0000"  >&lt;p&gt;1,Fixing the bug : &quot; isSparkConfigUpdated = isSparkRelatedConfig(name)&quot;&lt;br/&gt;
2,Setting &quot;isSparkConfigUpdated =false &quot; at session level&lt;br/&gt;
3,Taking concurrency into consideration by adding a session level conf lock.As multiple queries can run in a single session.&lt;/p&gt;</comment>
                            <comment id="15032702" author="jxiang" created="Mon, 30 Nov 2015 23:21:02 +0000"  >&lt;blockquote&gt;&lt;p&gt;1,Fixing the bug : &quot; isSparkConfigUpdated = isSparkRelatedConfig(name)&quot;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The fix to HiveConf.java is good.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;2,Setting &quot;isSparkConfigUpdated =false &quot; at session level&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;That means we reset the flag once we copy the hiveconf to the operation level. This may not work in some cases, right? For example, the first query has the flag set, and the second query has the flag not set, if the second query happens to create the spark session earlier, it will not create a new spark session.&lt;/p&gt;

&lt;p&gt;I think it is better to fix SparkUtilities to use the session level conf in checking if a new spark session should be created, and use the operation level conf to create the speark session. What do you think?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;3,Taking concurrency into consideration by adding a session level conf lock.As multiple queries can run in a single session.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Multiple queries can run in a single session asynchronously, right? If so, each one should has its own copy of conf object. If we are going to fix SparkUtilities, we may just need to synchronized the specific area of method SparkUtilities#getSparkSession().&lt;/p&gt;
</comment>
                            <comment id="15032988" author="nemon" created="Tue, 1 Dec 2015 03:01:51 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jxiang&quot; class=&quot;user-hover&quot; rel=&quot;jxiang&quot;&gt;Jimmy Xiang&lt;/a&gt; ,thanks for review.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;That means we reset the flag once we copy the hiveconf to the operation level. This may not work in some cases, right? For example, the first query has the flag set, and the second query has the flag not set, if the second query happens to create the spark session earlier, it will not create a new spark session.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Aggreed&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I think it is better to fix SparkUtilities to use the session level conf in checking if a new spark session should be created, &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Aggreed&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;and use the operation level conf to create the spark session. &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Not quite follow.Is there anything special in operation conf for SparkSession? And when to set &quot;isSparkConfigUpdated =false &quot; ? &lt;br/&gt;
Since each hive session only has one related spark session,i think it&apos;s should be fine to use session conf to start spark session.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Multiple queries can run in a single session asynchronously, right? If so, each one should has its own copy of conf object. If we are going to fix SparkUtilities, we may just need to synchronized the specific area of method SparkUtilities#getSparkSession().&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This depend on the question above : when to set &quot;isSparkConfigUpdated =false &quot;? Client may set another spark related parameter during SparkUtilities#getSparkSession(),that makes session level lock still needed.&lt;/p&gt;</comment>
                            <comment id="15033606" author="nemon" created="Tue, 1 Dec 2015 12:31:28 +0000"  >&lt;p&gt;Uploading a new patch that only set session level&apos;s isSparkConfigUpdated to false in SparkUtilities#getSparkSession().&lt;br/&gt;
The problem with using the operation level conf to create the speark session is that,it may ignore some spark related parameters from client which are set after creation of operation level conf and before setting session level&apos;s isSparkConfigUpdated to false.&lt;/p&gt;</comment>
                            <comment id="15034578" author="jxiang" created="Tue, 1 Dec 2015 21:10:00 +0000"  >&lt;blockquote&gt;&lt;p&gt;Not quite follow.Is there anything special in operation conf for SparkSession? And when to set &quot;isSparkConfigUpdated =false &quot; ?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;We can set it to false for the session level conf only. So this flag in the operation level is totaly ignored, all the time.&lt;br/&gt;
Things are a little tricky actually. If we use the session level conf, we could miss some non-spark-related settings in the operation level conf.&lt;br/&gt;
If we use the operation level conf, we could miss some spark-related settings in the session level conf.&lt;br/&gt;
Instead of just maintaining a isSparkConfigUpdated flag, probably, we should have a separate map to store such changed spark-related settings temporarily.&lt;br/&gt;
This map can be reset upon SparkUtilities#getSparkSession() is invoked.&lt;/p&gt;</comment>
                            <comment id="15035391" author="nemon" created="Wed, 2 Dec 2015 07:03:01 +0000"  >&lt;p&gt;Addressing issues mentioned in comments.&lt;/p&gt;</comment>
                            <comment id="15035428" author="nemon" created="Wed, 2 Dec 2015 07:55:25 +0000"  >&lt;p&gt;Using ConcurrentHashMap instead of HashMap.&lt;/p&gt;</comment>
                            <comment id="15036440" author="jxiang" created="Wed, 2 Dec 2015 19:37:06 +0000"  >&lt;p&gt;Patch v2 looks good to me. No need to use ConcurrentHashMap since you use synchronized already, right?&lt;br/&gt;
For SparkUtilities#getSparkSession(), probably we just need to synchronize on the session level conf.&lt;/p&gt;</comment>
                            <comment id="15037141" author="nemon" created="Thu, 3 Dec 2015 02:46:32 +0000"  >&lt;p&gt;Changing to session level spark session lock.&lt;br/&gt;
Changing back to HashMap.&lt;/p&gt;
</comment>
                            <comment id="15037648" author="hiveqa" created="Thu, 3 Dec 2015 10:45:39 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12775471/HIVE-12538.4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12775471/HIVE-12538.4.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to no test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 10 failed/errored test(s), 9885 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestHWISessionManager - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_acid_globallimit
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_cbo_udf_max
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_dynamic_partition_pruning
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_vectorized_dynamic_partition_pruning
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_acid_globallimit
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_mergejoin
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import
org.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.testGetPartitionSpecs_WithAndWithoutPartitionGrouping
org.apache.hive.jdbc.TestSSL.testSSLVersion
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6211/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6211/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6211/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6211/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6211/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6211/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 10 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12775471 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="15038206" author="jxiang" created="Thu, 3 Dec 2015 17:55:54 +0000"  >&lt;p&gt;Patch v4 looks good to me. +1&lt;/p&gt;</comment>
                            <comment id="15038373" author="jxiang" created="Thu, 3 Dec 2015 19:12:12 +0000"  >&lt;p&gt;Thought about it again, and chatted with Xuefu too. It seems to me there is no good fix for this issue. Due to asynchronous, if a query is going on, if someone changes the spark setting then submits another query, the previous query could be killed. Not sure how we can avoid such thing properly.&lt;/p&gt;

&lt;p&gt;One solution is to prevent any spark related setting changes once an async query is already submitted in a session. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xuefuz&quot; class=&quot;user-hover&quot; rel=&quot;xuefuz&quot;&gt;Xuefu Zhang&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=szehon&quot; class=&quot;user-hover&quot; rel=&quot;szehon&quot;&gt;Szehon Ho&lt;/a&gt;, what do you think?&lt;/p&gt;</comment>
                            <comment id="15038609" author="xuefuz" created="Thu, 3 Dec 2015 21:17:47 +0000"  >&lt;p&gt;My understanding is that a hive session may &quot;own&quot; more than one spark session in case of asynchronous queries. If a spark session is live (used to run a spark job), that spark session will not be used to run the next job. Therefore, whenever whenever a spark configuration change is detected in Hive session, we need to mark all the live Spark sessions as outdated.  When we are getting a session from the pool and check if the flag is set, then we destroy it and get a new one. Hope this will simply things a bit. &lt;/p&gt;</comment>
                            <comment id="15038725" author="jxiang" created="Thu, 3 Dec 2015 22:27:06 +0000"  >&lt;p&gt;Currently, each hive session can have just one spark session. Yeah, if a hive session is allowed to have more than one spark session, this should work.&lt;/p&gt;</comment>
                            <comment id="15041360" author="nemon" created="Fri, 4 Dec 2015 09:53:14 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jxiang&quot; class=&quot;user-hover&quot; rel=&quot;jxiang&quot;&gt;Jimmy Xiang&lt;/a&gt;  Please feel free to take it over if you plan to support more than one spark session. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
And here is my considerations:&lt;br/&gt;
I think it&apos;s bad practice to use one single hive connection for multiple threads on client side,&lt;br/&gt;
when each thread set different session level parameters and then submit queries separately.&lt;br/&gt;
Users shall be encouraged to set session level parameters serially.&lt;br/&gt;
For asynchronous queries submitted from a single thread and from a single hive connection,there is no &lt;br/&gt;
mechanism to promise their query parameters does not influence each other(,unless these parameters &lt;br/&gt;
are set by confOverlay?).I haven&apos;t seen this use case for now.&lt;/p&gt;</comment>
                            <comment id="15047896" author="jxiang" created="Wed, 9 Dec 2015 02:29:19 +0000"  >&lt;p&gt;I agree. I am wondering if we need to support running just one query at a time for a session. If so, the fix could be different. If we need to support multiple concurrent queries in one session, we need to come up a different fix. There may be clients already running several queries with the same session.&lt;/p&gt;</comment>
                            <comment id="15047910" author="nemon" created="Wed, 9 Dec 2015 02:48:17 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-9223&quot; title=&quot;HiveServer2 on Tez doesn&amp;#39;t support concurrent queries within one session&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-9223&quot;&gt;HIVE-9223&lt;/a&gt;  seems that Hive on Tez has the same problem.&lt;/p&gt;</comment>
                            <comment id="15049828" author="nemon" created="Thu, 10 Dec 2015 01:32:37 +0000"  >&lt;p&gt;Shall I provide a patch only fix issues mentioned here and keep track of supporting multiple concurrent queries in one session from a separate jira ?&lt;/p&gt;</comment>
                            <comment id="15050091" author="xuefuz" created="Thu, 10 Dec 2015 05:19:17 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nemon&quot; class=&quot;user-hover&quot; rel=&quot;nemon&quot;&gt;Nemon Lou&lt;/a&gt;, I think it&apos;s fine to solve one issue at a time. If you like to submit a patch, please specify the problem that you&apos;re trying to fix and then I can review it. Thanks.&lt;/p&gt;</comment>
                            <comment id="15050240" author="nemon" created="Thu, 10 Dec 2015 07:24:05 +0000"  >&lt;p&gt;Uploading a patch addressing the following issues :&lt;br/&gt;
1, Property isSparkConfigUpdated of HiveConf has not been maintained properly , as shown in the unit test added by this patch .  &lt;br/&gt;
2, In case of a asynchronous query, isSparkConfigUpdated should be set from session level instead of operation level .&lt;br/&gt;
The second issue is hard to add a test case .&lt;/p&gt;</comment>
                            <comment id="15052712" author="hiveqa" created="Fri, 11 Dec 2015 12:50:46 +0000"  >

&lt;p&gt;Here are the results of testing the latest attachment:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12776744/HIVE-12538.5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12776744/HIVE-12538.5.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;green&quot;&gt;SUCCESS:&lt;/font&gt; +1 due to 1 test(s) being added or modified.&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;red&quot;&gt;ERROR:&lt;/font&gt; -1 due to 13 failed/errored test(s), 9895 tests executed&lt;br/&gt;
&lt;b&gt;Failed tests:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TestHWISessionManager - did not produce a TEST-*.xml file
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_cbo_udf_max
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_order2
org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union9
org.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver_encryption_insert_partition_dynamic
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_dynamic_partition_pruning
org.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver_vectorized_dynamic_partition_pruning
org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_mergejoin
org.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import
org.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.testGetPartitionSpecs_WithAndWithoutPartitionGrouping
org.apache.hive.jdbc.TestMultiSessionsHS2WithLocalClusterSpark.testSparkQuery
org.apache.hive.jdbc.TestSSL.testSSLVersion
org.apache.hive.jdbc.miniHS2.TestHs2Metrics.testMetrics
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6318/testReport&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6318/testReport&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6318/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/jenkins/job/PreCommit-HIVE-TRUNK-Build/6318/console&lt;/a&gt;&lt;br/&gt;
Test logs: &lt;a href=&quot;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6318/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-6318/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Messages:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Executing org.apache.hive.ptest.execution.TestCheckPhase
Executing org.apache.hive.ptest.execution.PrepPhase
Executing org.apache.hive.ptest.execution.ExecutionPhase
Executing org.apache.hive.ptest.execution.ReportingPhase
Tests exited with: TestsFailedException: 13 tests failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;

&lt;p&gt;ATTACHMENT ID: 12776744 - PreCommit-HIVE-TRUNK-Build&lt;/p&gt;</comment>
                            <comment id="15052727" author="xuefuz" created="Fri, 11 Dec 2015 13:13:04 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="15059568" author="nemon" created="Wed, 16 Dec 2015 06:20:48 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xuefuz&quot; class=&quot;user-hover&quot; rel=&quot;xuefuz&quot;&gt;Xuefu Zhang&lt;/a&gt; Thanks for review. I have created &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-12689&quot; title=&quot;Support multiple spark sessions in one Hive Session&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HIVE-12689&quot;&gt;HIVE-12689&lt;/a&gt; to keep track of the concurrent issue discussed here.&lt;/p&gt;</comment>
                            <comment id="15060288" author="xuefuz" created="Wed, 16 Dec 2015 16:54:30 +0000"  >&lt;p&gt;Committed to master. Thanks, Nemon!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12775012" name="HIVE-12538.1.patch" size="3887" author="nemon" created="Tue, 1 Dec 2015 12:08:15 +0000"/>
                            <attachment id="12775228" name="HIVE-12538.2.patch" size="4075" author="nemon" created="Wed, 2 Dec 2015 07:03:01 +0000"/>
                            <attachment id="12775235" name="HIVE-12538.3.patch" size="4408" author="nemon" created="Wed, 2 Dec 2015 07:55:25 +0000"/>
                            <attachment id="12775471" name="HIVE-12538.4.patch" size="5412" author="nemon" created="Thu, 3 Dec 2015 02:46:32 +0000"/>
                            <attachment id="12776744" name="HIVE-12538.5.patch" size="3044" author="nemon" created="Thu, 10 Dec 2015 07:24:05 +0000"/>
                            <attachment id="12774767" name="HIVE-12538.patch" size="4888" author="nemon" created="Mon, 30 Nov 2015 03:06:48 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>6.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sat, 28 Nov 2015 06:05:55 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            50 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2p0uv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>