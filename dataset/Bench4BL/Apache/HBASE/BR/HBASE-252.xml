<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 02 18:39:53 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-252/HBASE-252.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-252] Random reads in mapfile are ~40% slower in TRUNK than they are in 0.15.x</title>
                <link>https://issues.apache.org/jira/browse/HBASE-252</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Opening a mapfile on hdfs and then doing 100k random reads inside the open file takes 3 times longer to complete in TRUNK than same test run on 0.15.x.&lt;/p&gt;

&lt;p&gt;Random read performance is important to hbase.&lt;/p&gt;

&lt;p&gt;Serial reads and writes perform about the same in TRUNK and 0.15.x.&lt;/p&gt;

&lt;p&gt;Below are 3 runs done against 0.15 of the mapfile test that can be found in hbase followed by 2 runs done against TRUNK:&lt;/p&gt;

&lt;p&gt;0.15 branch&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[stack@aa0-000-12 hbase]$ &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; i in 1 2 3; &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; ./bin/hbase org.apache.hadoop.hbase.PerformanceEvaluation mapfile 1; done
07/12/24 18:34:50 WARN util.NativeCodeLoader: Unable to load &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;-hadoop library &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; your platform... using builtin-java classes where applicable
07/12/24 18:34:50 INFO hbase.PerformanceEvaluation: Writing 100000 rows to hdfs:&lt;span class=&quot;code-comment&quot;&gt;//XXXX:9123/user/?/performanceevaluation.mapfile
&lt;/span&gt;07/12/24 18:35:13 INFO hbase.PerformanceEvaluation: Writing 100000 records took 23644ms (Note: generation of keys and values is done inline and has been seen to consume significant time: e.g. ~30% of cpu time
07/12/24 18:35:13 INFO hbase.PerformanceEvaluation: Reading 100000 random rows
....
07/12/24 18:37:23 INFO hbase.PerformanceEvaluation: Reading 100000 random records took 129879ms (Note: generation of random key is done in line and takes a significant amount of cpu time: e.g 10-15%
07/12/24 18:37:23 INFO hbase.PerformanceEvaluation: Reading 100000 rows sequentially
07/12/24 18:37:25 INFO hbase.PerformanceEvaluation: Reading 100000 records serially took 1832ms
07/12/24 18:37:26 WARN util.NativeCodeLoader: Unable to load &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;-hadoop library &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; your platform... using builtin-java classes where applicable
07/12/24 18:37:26 INFO hbase.PerformanceEvaluation: Writing 100000 rows to hdfs:&lt;span class=&quot;code-comment&quot;&gt;//XXXXX:9123/user/?/performanceevaluation.mapfile
&lt;/span&gt;07/12/24 18:37:50 INFO hbase.PerformanceEvaluation: Writing 100000 records took 24188ms (Note: generation of keys and values is done inline and has been seen to consume significant time: e.g. ~30% of cpu time
07/12/24 18:37:50 INFO hbase.PerformanceEvaluation: Reading 100000 random rows
...
07/12/24 18:39:58 INFO hbase.PerformanceEvaluation: Reading 100000 random records took 127879ms (Note: generation of random key is done in line and takes a significant amount of cpu time: e.g 10-15%
07/12/24 18:39:58 INFO hbase.PerformanceEvaluation: Reading 100000 rows sequentially
07/12/24 18:40:00 INFO hbase.PerformanceEvaluation: Reading 100000 records serially took 1787ms
07/12/24 18:40:01 WARN util.NativeCodeLoader: Unable to load &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;-hadoop library &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; your platform... using builtin-java classes where applicable
07/12/24 18:40:01 INFO hbase.PerformanceEvaluation: Writing 100000 rows to hdfs:&lt;span class=&quot;code-comment&quot;&gt;//XXXX:9123/user/?/performanceevaluation.mapfile
&lt;/span&gt;07/12/24 18:40:24 INFO hbase.PerformanceEvaluation: Writing 100000 records took 23832ms (Note: generation of keys and values is done inline and has been seen to consume significant time: e.g. ~30% of cpu time
07/12/24 18:40:24 INFO hbase.PerformanceEvaluation: Reading 100000 random rows
..
07/12/24 18:42:31 INFO hbase.PerformanceEvaluation: Reading 100000 random records took 126954ms (Note: generation of random key is done in line and takes a significant amount of cpu time: e.g 10-15%
07/12/24 18:42:31 INFO hbase.PerformanceEvaluation: Reading 100000 rows sequentially
07/12/24 18:42:33 INFO hbase.PerformanceEvaluation: Reading 100000 records serially took 1766ms
07/12/24 17:24:25 WARN util.NativeCodeLoader: Unable to load &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;-hadoop library &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; your platform... using builtin-java classes where applicable
07/12/24 17:24:25 INFO hbase.PerformanceEvaluation: Writing 100000 rows to hdfs:&lt;span class=&quot;code-comment&quot;&gt;//XXXXX:9123/user/?/performanceevaluation.mapfile
&lt;/span&gt;07/12/24 17:24:49 INFO hbase.PerformanceEvaluation: Writing 100000 records took 24181ms (Note: generation of keys and values is done inline and has been seen to consume significant time: e.g. ~30% of cpu time
07/12/24 17:24:49 INFO hbase.PerformanceEvaluation: Reading 100000 random rows
...
07/12/24 17:26:59 INFO hbase.PerformanceEvaluation: Reading 100000 random records took 129564ms (Note: generation of random key is done in line and takes a significant amount of cpu time: e.g 10-15%
07/12/24 17:26:59 INFO hbase.PerformanceEvaluation: Reading 100000 rows sequentially
07/12/24 17:27:00 INFO hbase.PerformanceEvaluation: Reading 100000 records serially took 1793ms 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;TRUNK&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[stack@aa0-000-12 hbase]$ ./bin/hbase org.apache.hadoop.hbase.PerformanceEvaluation mapfile 1
07/12/24 18:02:26 WARN util.NativeCodeLoader: Unable to load &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;-hadoop library &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; your platform... using builtin-java classes where applicable
07/12/24 18:02:26 INFO hbase.PerformanceEvaluation: Writing 100000 rows to hdfs:&lt;span class=&quot;code-comment&quot;&gt;//XXXX3/user/?/performanceevaluation.mapfile
&lt;/span&gt;07/12/24 18:02:51 INFO hbase.PerformanceEvaluation: Writing 100000 records took 25500ms (Note: generation of keys and values is done inline and has been seen to consume significant time: e.g. ~30% of cpu time
07/12/24 18:02:51 INFO hbase.PerformanceEvaluation: Reading 100000 random rows
....
07/12/24 18:11:11 INFO hbase.PerformanceEvaluation: Reading 100000 random records took 500306ms (Note: generation of random key is done in line and takes a significant amount of cpu time: e.g 10-15%
07/12/24 18:11:11 INFO hbase.PerformanceEvaluation: Reading 100000 rows sequentially
07/12/24 18:11:13 INFO hbase.PerformanceEvaluation: Reading 100000 records serially took 1940ms

[stack@aa0-000-12 hbase]$ ./bin/hbase org.apache.hadoop.hbase.PerformanceEvaluation mapfile 1
07/12/24 18:12:46 WARN util.NativeCodeLoader: Unable to load &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;-hadoop library &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; your platform... using builtin-java classes where applicable
07/12/24 18:12:46 INFO hbase.PerformanceEvaluation: Writing 100000 rows to hdfs:&lt;span class=&quot;code-comment&quot;&gt;//XXXX/user/?/performanceevaluation.mapfile
&lt;/span&gt;07/12/24 18:13:12 INFO hbase.PerformanceEvaluation: Writing 100000 records took 25593ms (Note: generation of keys and values is done inline and has been seen to consume significant time: e.g. ~30% of cpu time
07/12/24 18:13:12 INFO hbase.PerformanceEvaluation: Reading 100000 random rows
...
07/12/24 18:22:16 INFO hbase.PerformanceEvaluation: Reading 100000 random records took 543992ms (Note: generation of random key is done in line and takes a significant amount of cpu time: e.g 10-15%
07/12/24 18:22:16 INFO hbase.PerformanceEvaluation: Reading 100000 rows sequentially
07/12/24 18:22:18 INFO hbase.PerformanceEvaluation: Reading 100000 records serially took 1786ms
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Above was done on a small hdfs cluster of 4 machines with each a dfs node.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12385171">HBASE-252</key>
            <summary>Random reads in mapfile are ~40% slower in TRUNK than they are in 0.15.x</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="stack">stack</reporter>
                        <labels>
                    </labels>
                <created>Mon, 24 Dec 2007 18:51:59 +0000</created>
                <updated>Fri, 22 Aug 2008 21:34:57 +0000</updated>
                            <resolved>Thu, 3 Jan 2008 21:51:32 +0000</resolved>
                                                                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12554314" author="rangadi" created="Mon, 24 Dec 2007 22:43:41 +0000"  >&lt;p&gt;How do I set up the environment? I didn&apos;t have bin/hbase, so I tried&lt;br/&gt;
&apos;build/contrib/hbase/bin/hbase org.apache.hadoop.hbase.PerformanceEvaluation mapfile 1&apos; from top level dir and got :&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Unrecognized VM option &apos;+HeapDumpOnOutOfMemoryError&apos;
Could not create the Java virtual machine.&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12554315" author="stack" created="Mon, 24 Dec 2007 22:53:55 +0000"  >&lt;p&gt;Thanks for trying to take a look at this Raghu.&lt;/p&gt;

&lt;p&gt;Problem seems to be the JVM you are using.  It doesn&apos;t seem to like the &apos;HBASE_OPTS=&quot;$HBASE_OPTS -XX:+HeapDumpOnOutOfMemoryError&quot;&apos; we add in hbase.  Try editing it out of your bin/hbase.&lt;/p&gt;

&lt;p&gt;More info on this bug is that it seems to be another symptom of &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-1989&quot; title=&quot;Add support for simulated Data Nodes  - helpful for testing and performance benchmarking of the Name Node without having a large cluster&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-1989&quot;&gt;&lt;del&gt;HADOOP-1989&lt;/del&gt;&lt;/a&gt;.  I just backed it out and the random reads come in close to 0.15.x times again.&lt;/p&gt;

&lt;p&gt;Only think I could see profiling is that we seem to be making too many invocations of DataXceiver.readBlock (thats where we are spending bulk of CPU time); ten or a hundred more times than I&apos;d expect.&lt;/p&gt;
</comment>
                            <comment id="12554317" author="rangadi" created="Mon, 24 Dec 2007 23:24:42 +0000"  >&lt;p&gt;1989 was my first suspect as well. I am going to look at the patch and the code. &lt;/p&gt;</comment>
                            <comment id="12554450" author="stack" created="Wed, 26 Dec 2007 18:36:24 +0000"  >&lt;p&gt;I ran tests with the revision that added 1989.  It slows things down by about 50% so its not the only culprit it seems.&lt;/p&gt;

&lt;p&gt;Looking in the profiler, I see that ~10k invocations of readBlock turn into ~2M invocations of sendChunk.  Chunks seem to be 512 bytes.  Is that right?  Seems small.&lt;/p&gt;</comment>
                            <comment id="12554455" author="stack" created="Wed, 26 Dec 2007 19:23:08 +0000"  >&lt;p&gt;Hmm... seems like checksum sizes are default of 512 in 0.15 branch so that ain&apos;t it.&lt;/p&gt;

&lt;p&gt;I did a clean checkout of trunk and spent more time on timings and my original claim that TRUNK is 3times slower is incorrect: its &lt;b&gt;just&lt;/b&gt; ~40% slower.&lt;/p&gt;

&lt;p&gt;0.15 branch&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[stack@aa0-000-12 hbase]$ &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; i in 1 2 3 ; &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; ./bin/hbase org.apache.hadoop.hbase.PerformanceEvaluation mapfile 1; done
07/12/26 19:08:11 WARN util.NativeCodeLoader: Unable to load &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;-hadoop library &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; your platform... using builtin-java classes where applicable
07/12/26 19:08:11 INFO hbase.PerformanceEvaluation: Writing 100000 rows to hdfs:&lt;span class=&quot;code-comment&quot;&gt;//X.X.X:9123/user/?/performanceevaluation.mapfile
&lt;/span&gt;07/12/26 19:08:36 INFO hbase.PerformanceEvaluation: Writing 100000 records took 24159ms (Note: generation of keys and values is done inline and has been seen to consume significant time: e.g. ~30% of cpu time
07/12/26 19:08:36 INFO hbase.PerformanceEvaluation: Reading 100000 random rows
07/12/26 19:08:52 INFO hbase.PerformanceEvaluation: Read 10000
07/12/26 19:09:05 INFO hbase.PerformanceEvaluation: Read 20000
07/12/26 19:09:17 INFO hbase.PerformanceEvaluation: Read 30000
07/12/26 19:09:30 INFO hbase.PerformanceEvaluation: Read 40000
07/12/26 19:09:42 INFO hbase.PerformanceEvaluation: Read 50000
07/12/26 19:09:55 INFO hbase.PerformanceEvaluation: Read 60000
07/12/26 19:10:08 INFO hbase.PerformanceEvaluation: Read 70000
07/12/26 19:10:20 INFO hbase.PerformanceEvaluation: Read 80000
07/12/26 19:10:33 INFO hbase.PerformanceEvaluation: Read 90000
07/12/26 19:10:45 INFO hbase.PerformanceEvaluation: Reading 100000 random records took 129836ms (Note: generation of random key is done in line and takes a significant amount of cpu time: e.g 10-15%
07/12/26 19:10:45 INFO hbase.PerformanceEvaluation: Reading 100000 rows sequentially
07/12/26 19:10:47 INFO hbase.PerformanceEvaluation: Reading 100000 records serially took 1717ms
07/12/26 19:10:48 WARN util.NativeCodeLoader: Unable to load &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;-hadoop library &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; your platform... using builtin-java classes where applicable
07/12/26 19:10:48 INFO hbase.PerformanceEvaluation: Writing 100000 rows to hdfs:&lt;span class=&quot;code-comment&quot;&gt;//X.X.X:9123/user/?/performanceevaluation.mapfile
&lt;/span&gt;07/12/26 19:11:12 INFO hbase.PerformanceEvaluation: Writing 100000 records took 23859ms (Note: generation of keys and values is done inline and has been seen to consume significant time: e.g. ~30% of cpu time
07/12/26 19:11:12 INFO hbase.PerformanceEvaluation: Reading 100000 random rows
07/12/26 19:11:25 INFO hbase.PerformanceEvaluation: Read 10000
07/12/26 19:11:39 INFO hbase.PerformanceEvaluation: Read 20000
07/12/26 19:11:51 INFO hbase.PerformanceEvaluation: Read 30000
07/12/26 19:12:03 INFO hbase.PerformanceEvaluation: Read 40000
07/12/26 19:12:16 INFO hbase.PerformanceEvaluation: Read 50000
07/12/26 19:12:29 INFO hbase.PerformanceEvaluation: Read 60000
07/12/26 19:12:41 INFO hbase.PerformanceEvaluation: Read 70000
07/12/26 19:12:54 INFO hbase.PerformanceEvaluation: Read 80000
07/12/26 19:13:06 INFO hbase.PerformanceEvaluation: Read 90000
07/12/26 19:13:19 INFO hbase.PerformanceEvaluation: Reading 100000 random records took 126779ms (Note: generation of random key is done in line and takes a significant amount of cpu time: e.g 10-15%
07/12/26 19:13:19 INFO hbase.PerformanceEvaluation: Reading 100000 rows sequentially
07/12/26 19:13:20 INFO hbase.PerformanceEvaluation: Reading 100000 records serially took 1769ms
07/12/26 19:13:21 WARN util.NativeCodeLoader: Unable to load &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;-hadoop library &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; your platform... using builtin-java classes where applicable
07/12/26 19:13:21 INFO hbase.PerformanceEvaluation: Writing 100000 rows to hdfs:&lt;span class=&quot;code-comment&quot;&gt;//X.X.X:9123/user/?/performanceevaluation.mapfile
&lt;/span&gt;07/12/26 19:13:45 INFO hbase.PerformanceEvaluation: Writing 100000 records took 23679ms (Note: generation of keys and values is done inline and has been seen to consume significant time: e.g. ~30% of cpu time
07/12/26 19:13:45 INFO hbase.PerformanceEvaluation: Reading 100000 random rows
07/12/26 19:13:58 INFO hbase.PerformanceEvaluation: Read 10000
07/12/26 19:14:11 INFO hbase.PerformanceEvaluation: Read 20000
07/12/26 19:14:23 INFO hbase.PerformanceEvaluation: Read 30000
07/12/26 19:14:36 INFO hbase.PerformanceEvaluation: Read 40000
07/12/26 19:14:48 INFO hbase.PerformanceEvaluation: Read 50000
07/12/26 19:15:01 INFO hbase.PerformanceEvaluation: Read 60000
07/12/26 19:15:13 INFO hbase.PerformanceEvaluation: Read 70000
07/12/26 19:15:26 INFO hbase.PerformanceEvaluation: Read 80000
07/12/26 19:15:38 INFO hbase.PerformanceEvaluation: Read 90000
07/12/26 19:15:51 INFO hbase.PerformanceEvaluation: Reading 100000 random records took 125860ms (Note: generation of random key is done in line and takes a significant amount of cpu time: e.g 10-15%
07/12/26 19:15:51 INFO hbase.PerformanceEvaluation: Reading 100000 rows sequentially
07/12/26 19:15:52 INFO hbase.PerformanceEvaluation: Reading 100000 records serially took 1836ms
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;TRUNK&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[stack@aa0-000-12 hbase]$ &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; i in 1 2 3 ; &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; ./bin/hbase org.apache.hadoop.hbase.PerformanceEvaluation mapfile 1; done
07/12/26 18:50:17 WARN util.NativeCodeLoader: Unable to load &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;-hadoop library &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; your platform... using builtin-java classes where applicable
07/12/26 18:50:17 INFO hbase.PerformanceEvaluation: Writing 100000 rows to hdfs:&lt;span class=&quot;code-comment&quot;&gt;//X.X.X:9123/user/?/performanceevaluation.mapfile
&lt;/span&gt;07/12/26 18:50:41 INFO hbase.PerformanceEvaluation: Writing 100000 records took 24191ms (Note: generation of keys and values is done inline and has been seen to consume significant time: e.g. ~30% of cpu time
07/12/26 18:50:41 INFO hbase.PerformanceEvaluation: Reading 100000 random rows
07/12/26 18:51:02 INFO hbase.PerformanceEvaluation: Read 10000
07/12/26 18:51:20 INFO hbase.PerformanceEvaluation: Read 20000
07/12/26 18:51:38 INFO hbase.PerformanceEvaluation: Read 30000
07/12/26 18:51:55 INFO hbase.PerformanceEvaluation: Read 40000
07/12/26 18:52:13 INFO hbase.PerformanceEvaluation: Read 50000
07/12/26 18:52:29 INFO hbase.PerformanceEvaluation: Read 60000
07/12/26 18:52:47 INFO hbase.PerformanceEvaluation: Read 70000
07/12/26 18:53:04 INFO hbase.PerformanceEvaluation: Read 80000
07/12/26 18:53:21 INFO hbase.PerformanceEvaluation: Read 90000
07/12/26 18:53:39 INFO hbase.PerformanceEvaluation: Reading 100000 random records took 177692ms (Note: generation of random key is done in line and takes a significant amount of cpu time: e.g 10-15%
07/12/26 18:53:39 INFO hbase.PerformanceEvaluation: Reading 100000 rows sequentially
07/12/26 18:53:41 INFO hbase.PerformanceEvaluation: Reading 100000 records serially took 1749ms
07/12/26 18:53:42 WARN util.NativeCodeLoader: Unable to load &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;-hadoop library &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; your platform... using builtin-java classes where applicable
07/12/26 18:53:42 INFO hbase.PerformanceEvaluation: Writing 100000 rows to hdfs:&lt;span class=&quot;code-comment&quot;&gt;//X.X.X:9123/user/?/performanceevaluation.mapfile
&lt;/span&gt;07/12/26 18:54:06 INFO hbase.PerformanceEvaluation: Writing 100000 records took 23873ms (Note: generation of keys and values is done inline and has been seen to consume significant time: e.g. ~30% of cpu time
07/12/26 18:54:06 INFO hbase.PerformanceEvaluation: Reading 100000 random rows
07/12/26 18:54:25 INFO hbase.PerformanceEvaluation: Read 10000
07/12/26 18:54:44 INFO hbase.PerformanceEvaluation: Read 20000
07/12/26 18:55:01 INFO hbase.PerformanceEvaluation: Read 30000
07/12/26 18:55:17 INFO hbase.PerformanceEvaluation: Read 40000
07/12/26 18:55:33 INFO hbase.PerformanceEvaluation: Read 50000
07/12/26 18:55:51 INFO hbase.PerformanceEvaluation: Read 60000
07/12/26 18:56:08 INFO hbase.PerformanceEvaluation: Read 70000
07/12/26 18:56:25 INFO hbase.PerformanceEvaluation: Read 80000
07/12/26 18:56:41 INFO hbase.PerformanceEvaluation: Read 90000
07/12/26 18:56:57 INFO hbase.PerformanceEvaluation: Reading 100000 random records took 171167ms (Note: generation of random key is done in line and takes a significant amount of cpu time: e.g 10-15%
07/12/26 18:56:57 INFO hbase.PerformanceEvaluation: Reading 100000 rows sequentially
07/12/26 18:56:59 INFO hbase.PerformanceEvaluation: Reading 100000 records serially took 1789ms
07/12/26 18:57:00 WARN util.NativeCodeLoader: Unable to load &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;-hadoop library &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; your platform... using builtin-java classes where applicable
07/12/26 18:57:00 INFO hbase.PerformanceEvaluation: Writing 100000 rows to hdfs:&lt;span class=&quot;code-comment&quot;&gt;//X.X.X:9123/user/?/performanceevaluation.mapfile
&lt;/span&gt;07/12/26 18:57:25 INFO hbase.PerformanceEvaluation: Writing 100000 records took 24076ms (Note: generation of keys and values is done inline and has been seen to consume significant time: e.g. ~30% of cpu time
07/12/26 18:57:25 INFO hbase.PerformanceEvaluation: Reading 100000 random rows
07/12/26 18:57:43 INFO hbase.PerformanceEvaluation: Read 10000
07/12/26 18:58:01 INFO hbase.PerformanceEvaluation: Read 20000
07/12/26 18:58:18 INFO hbase.PerformanceEvaluation: Read 30000
07/12/26 18:58:35 INFO hbase.PerformanceEvaluation: Read 40000
07/12/26 18:58:52 INFO hbase.PerformanceEvaluation: Read 50000
07/12/26 18:59:09 INFO hbase.PerformanceEvaluation: Read 60000
07/12/26 18:59:26 INFO hbase.PerformanceEvaluation: Read 70000
07/12/26 18:59:42 INFO hbase.PerformanceEvaluation: Read 80000
07/12/26 19:00:00 INFO hbase.PerformanceEvaluation: Read 90000
07/12/26 19:00:16 INFO hbase.PerformanceEvaluation: Reading 100000 random records took 171260ms (Note: generation of random key is done in line and takes a significant amount of cpu time: e.g 10-15%
07/12/26 19:00:16 INFO hbase.PerformanceEvaluation: Reading 100000 rows sequentially
07/12/26 19:00:18 INFO hbase.PerformanceEvaluation: Reading 100000 records serially took 1764ms
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12554490" author="stack" created="Wed, 26 Dec 2007 23:22:13 +0000"  >&lt;p&gt;The below patch &amp;#8211; using the BufferedInputStream implementation of skip rather than default InputStream version &amp;#8211; brings it close to 0.15 speeds.  With below applied, TRUNK is just 5% slower.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Index: src/java/org/apache/hadoop/dfs/FSDatasetInterface.java
===================================================================
--- src/java/org/apache/hadoop/dfs/FSDatasetInterface.java      (revision 606938)
+++ src/java/org/apache/hadoop/dfs/FSDatasetInterface.java      (working copy)
@@ -68,6 +68,16 @@
       &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; inStream.read(b, off, len);
     } 

+    @Override
+    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; available() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
+      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.inStream.available();
+    }
+
+    @Override
+    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; skip(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; n) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
+      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.inStream.skip(n);
+    }
+
     &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; getLength() {
       &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; length;
     }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12554506" author="rangadi" created="Thu, 27 Dec 2007 02:10:20 +0000"  >&lt;p&gt;This is interesting. I haven&apos;t tried more to run the hbase command yet. &lt;br/&gt;
This implies two things: &lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;FileInpuStream.skip() probably does seek() internally. good.&lt;/li&gt;
	&lt;li&gt;seek() instead of skip is important even for crc files.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Could you make MetadataInputStream extend FilterInputStream so that it is less prone to such errors?&lt;br/&gt;
we can remove all the implementations of read(), skip() etc from it.&lt;/p&gt;

&lt;p&gt;Could you give approximate size of each random read and what the block size is?&lt;/p&gt;
</comment>
                            <comment id="12554507" author="rangadi" created="Thu, 27 Dec 2007 02:22:42 +0000"  >&lt;p&gt;&amp;gt; make MetadataInputStream extend FilterInputStream so that it is less prone to such errors?&lt;br/&gt;
&amp;gt; we can remove all the implementations of read(), skip() etc from it.&lt;br/&gt;
patch attached.&lt;/p&gt;</comment>
                            <comment id="12554526" author="stack" created="Thu, 27 Dec 2007 05:44:06 +0000"  >&lt;p&gt;I tried the patch.  Has same general effect moving us to within ~5-7% of the 0.15.x timings:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[stack@aa0-000-12 hbase]$ &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; i in 1 2 3 ; &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; ./bin/hbase org.apache.hadoop.hbase.PerformanceEvaluation mapfile 1; done
07/12/27 05:29:17 WARN util.NativeCodeLoader: Unable to load &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;-hadoop library &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; your platform... using builtin-java classes where applicable
07/12/27 05:29:17 INFO hbase.PerformanceEvaluation: Writing 100000 rows to hdfs:&lt;span class=&quot;code-comment&quot;&gt;//X.X.X:9123/user/?/performanceevaluation.mapfile
&lt;/span&gt;07/12/27 05:29:42 INFO hbase.PerformanceEvaluation: Writing 100000 records took 24882ms (Note: generation of keys and values is done inline and has been seen to consume significant time: e.g. ~30% of cpu time
07/12/27 05:29:42 INFO hbase.PerformanceEvaluation: Reading 100000 random rows
...
07/12/27 05:32:01 INFO hbase.PerformanceEvaluation: Reading 100000 random records took 138881ms (Note: generation of random key is done in line and takes a significant amount of cpu time: e.g 10-15%
07/12/27 05:32:01 INFO hbase.PerformanceEvaluation: Reading 100000 rows sequentially
07/12/27 05:32:03 INFO hbase.PerformanceEvaluation: Reading 100000 records serially took 1831ms
07/12/27 05:32:04 WARN util.NativeCodeLoader: Unable to load &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;-hadoop library &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; your platform... using builtin-java classes where applicable
07/12/27 05:32:04 INFO hbase.PerformanceEvaluation: Writing 100000 rows to hdfs:&lt;span class=&quot;code-comment&quot;&gt;//X.X.X:9123/user/?/performanceevaluation.mapfile
&lt;/span&gt;07/12/27 05:32:28 INFO hbase.PerformanceEvaluation: Writing 100000 records took 24043ms (Note: generation of keys and values is done inline and has been seen to consume significant time: e.g. ~30% of cpu time
07/12/27 05:32:28 INFO hbase.PerformanceEvaluation: Reading 100000 random rows
...
07/12/27 05:34:45 INFO hbase.PerformanceEvaluation: Reading 100000 random records took 136419ms (Note: generation of random key is done in line and takes a significant amount of cpu time: e.g 10-15%
07/12/27 05:34:45 INFO hbase.PerformanceEvaluation: Reading 100000 rows sequentially
07/12/27 05:34:47 INFO hbase.PerformanceEvaluation: Reading 100000 records serially took 1810ms
07/12/27 05:34:48 WARN util.NativeCodeLoader: Unable to load &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;-hadoop library &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; your platform... using builtin-java classes where applicable
07/12/27 05:34:48 INFO hbase.PerformanceEvaluation: Writing 100000 rows to hdfs:&lt;span class=&quot;code-comment&quot;&gt;//X,X,X:9123/user/?/performanceevaluation.mapfile
&lt;/span&gt;07/12/27 05:35:12 INFO hbase.PerformanceEvaluation: Writing 100000 records took 23832ms (Note: generation of keys and values is done inline and has been seen to consume significant time: e.g. ~30% of cpu time
07/12/27 05:35:12 INFO hbase.PerformanceEvaluation: Reading 100000 random rows
....
07/12/27 05:37:33 INFO hbase.PerformanceEvaluation: Reading 100000 random records took 140445ms (Note: generation of random key is done in line and takes a significant amount of cpu time: e.g 10-15%
07/12/27 05:37:33 INFO hbase.PerformanceEvaluation: Reading 100000 rows sequentially
07/12/27 05:37:35 INFO hbase.PerformanceEvaluation: Reading 100000 records serially took 1852ms
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12554535" author="stack" created="Thu, 27 Dec 2007 06:40:04 +0000"  >&lt;p&gt;On the character of the data this little mapfile test uses, its a key that is a a null-padded integer and a random string of 1000 bytes.  Its the data format described in the Performance Evaluation section of the bigtable paper.  See code if you want to know more.&lt;/p&gt;

&lt;p&gt;On seek rather than skip even in CRC files, yes, that would help I think.  E.g. in BlockSender, it calls IOUtils.skipFully to position in the CRC file.  In the profiler, it looks like IOUtils.skipFully is dumbing down the DIS into an IS calling default InputStream.skip instead of the BufferedInputStream version which runs a bit faster &amp;#8211; though in the overall scheme of things, we&apos;re talking a pittance... probably &amp;lt; 1%.&lt;/p&gt;

&lt;p&gt;Of interest though is that the likes of the sendChunk method can be called millions of times randomly accessing a file of any decent size.  I tried assigning instance variables to locals to see if it would make a difference but detected nothing noticeable.&lt;/p&gt;</comment>
                            <comment id="12554962" author="stack" created="Sat, 29 Dec 2007 22:29:17 +0000"  >&lt;p&gt;Get a +1 from hudson so can get this committed.&lt;/p&gt;</comment>
                            <comment id="12555044" author="hadoopqa" created="Sun, 30 Dec 2007 22:50:05 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
&lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12372241/HADOOP-2488.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12372241/HADOOP-2488.patch&lt;/a&gt;&lt;br/&gt;
against trunk revision r607330.&lt;/p&gt;

&lt;p&gt;    @author +1.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    javadoc +1.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    javac +1.  The applied patch does not generate any new compiler warnings.&lt;/p&gt;

&lt;p&gt;    findbugs +1.  The patch does not introduce any new Findbugs warnings.&lt;/p&gt;

&lt;p&gt;    core tests +1.  The patch passed core unit tests.&lt;/p&gt;

&lt;p&gt;    contrib tests -1.  The patch failed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1438/testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1438/testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1438/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1438/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle results: &lt;a href=&quot;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1438/artifact/trunk/build/test/checkstyle-errors.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1438/artifact/trunk/build/test/checkstyle-errors.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1438/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1438/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="12555047" author="stack" created="Sun, 30 Dec 2007 23:04:06 +0000"  >&lt;p&gt;The failures were unrelated, in hbase.  These should not get in the way of this patch getting committed.  Thanks.&lt;/p&gt;</comment>
                            <comment id="12555048" author="stack" created="Sun, 30 Dec 2007 23:06:59 +0000"  >&lt;p&gt;Oh, I took a look at adding seek to the reading of CRC files.  Would take a bit of work given that the files have a header of info that that has to be read first before can start seeking around.  Should I make an issue to add seeking?  Wouldn&apos;t save us much but does look like seek to the correct offset in the CRC file is suboptimal when random reading.&lt;/p&gt;</comment>
                            <comment id="12555148" author="rangadi" created="Mon, 31 Dec 2007 22:03:23 +0000"  >&lt;p&gt;Thanks for running the patch.&lt;/p&gt;

&lt;p&gt;&amp;gt; E.g. in BlockSender, it calls IOUtils.skipFully to position in the CRC file. In the profiler, it looks like IOUtils.skipFully is&lt;br/&gt;
&amp;gt; dumbing down the DIS into an IS calling default InputStream.skip instead of the BufferedInputStream&lt;br/&gt;
&amp;gt; version which runs a bit faster - though in the overall scheme of things, we&apos;re talking a pittance... probably &amp;lt; 1%.&lt;/p&gt;

&lt;p&gt;I am not sure what the difference is. IOUtils.skipFully() just invokes in.skip().  &lt;br/&gt;
It does not imply it invokes InputStream.skip(), it depends on actual runtime class of &apos;in&apos;. I am not sure if I &lt;br/&gt;
understood the actual concern.&lt;/p&gt;

&lt;p&gt;&amp;gt; I took a look at adding seek to the reading of CRC files. &lt;br/&gt;
FileInputStream is probably results in seek internally. Otherwise I am not sure what accounts for &lt;br/&gt;
this bug and the fix. We could make it a buffered input stream after reading the header, it might make it a bit faster than 15. &lt;/p&gt;
</comment>
                            <comment id="12555152" author="stack" created="Mon, 31 Dec 2007 23:25:11 +0000"  >&lt;p&gt;&amp;gt;&amp;gt; I took a look at adding seek to the reading of CRC files.&lt;br/&gt;
&amp;gt; FileInputStream is probably results in seek internally...We could make it a buffered input stream after reading the header, it might make it a bit faster than 15.&lt;/p&gt;

&lt;p&gt;It is already? (See line 1287 of DataNode.java).  Maybe you mean something else?&lt;/p&gt;</comment>
                            <comment id="12555637" author="rangadi" created="Thu, 3 Jan 2008 18:49:31 +0000"  >&lt;p&gt;I will commit this today. Moving to true random read basically avoids the extra read of &apos;BUFFER_SIZE&apos; at the beginning. We can fix that later.&lt;/p&gt;</comment>
                            <comment id="12555687" author="rangadi" created="Thu, 3 Jan 2008 21:51:32 +0000"  >&lt;p&gt;I just committed this. Thanks Stack!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12372241" name="HADOOP-2488.patch" size="1141" author="rangadi" created="Thu, 27 Dec 2007 02:22:41 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 24 Dec 2007 22:43:41 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>25036</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 49 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0h5wf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>98218</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>