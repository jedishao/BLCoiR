<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 02 20:03:02 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-291/HBASE-291.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-291] Adding versioning to Record I/O</title>
                <link>https://issues.apache.org/jira/browse/HBASE-291</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;There is a need to add versioning support to Record I/O. Users frequently update DDL files, usually by adding/removing fields, but do not want to change the name of the data structure. They would like older &amp;amp; newer deserializers to read as much data as possible. For example, suppose Record I/O is used to serialize/deserialize log records, each of which contains a message and a timestamp. An initial data definition could be as follows:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;class MyLogRecord {
  ustring msg;
  &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; timestamp;
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Record I/O creates a class, &lt;em&gt;MyLogRecord&lt;/em&gt;, which represents a log record and can serialize/deserialize itself. Now, suppose newer log records additionally contain a severity level. A user would want to update the definition for a log record but use the same class name. The new definition would be:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;class MyLogRecord {
  ustring msg;
  &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; timestamp;
  &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; severity;
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Users would want a new deserializer to read old log records (and perhaps use a default value for the severity field), and an old deserializer to read newer log records (and skip the severity field).&lt;/p&gt;

&lt;p&gt;This requires some concept of versioning in Record I/O, or rather, the additional ability to read/write type information of a record. The following is a proposal to do this. &lt;/p&gt;

&lt;p&gt;Every Record I/O Record will have type information which represents how the record is structured (what fields it has, what types, etc.). This type information, represented by the class &lt;em&gt;RecordTypeInfo&lt;/em&gt;, is itself serializable/deserializable. Every Record supports a method &lt;em&gt;getRecordTypeInfo()&lt;/em&gt;, which returns a &lt;em&gt;RecordTypeInfo&lt;/em&gt; object. Users are expected to serialize this type information (by calling &lt;em&gt;RecordTypeInfo.serialize()&lt;/em&gt;) in an appropriate fashion (in a separate file, for example, or at the beginning of a file). Using the same DDL as above, here&apos;s how we could serialize log records: &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;FileOutputStream fOut = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; FileOutputStream(&lt;span class=&quot;code-quote&quot;&gt;&quot;data.log&quot;&lt;/span&gt;);
CsvRecordOutput csvOut = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; CsvRecordOutput(fOut);
...
&lt;span class=&quot;code-comment&quot;&gt;// get the type information &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; MyLogRecord
&lt;/span&gt;RecordTypeInfo typeInfo = MyLogRecord.getRecordTypeInfo();
&lt;span class=&quot;code-comment&quot;&gt;// ask it to write itself out
&lt;/span&gt;typeInfo.serialize(csvOut);
...
&lt;span class=&quot;code-comment&quot;&gt;// now, serialize a bunch of records
&lt;/span&gt;&lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (...) {
   MyLogRecord log = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; MyLogRecord();
   &lt;span class=&quot;code-comment&quot;&gt;// fill up the MyLogRecord object
&lt;/span&gt;  ...
  &lt;span class=&quot;code-comment&quot;&gt;// serialize
&lt;/span&gt;  log.serialize(csvOut);
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In this example, the type information of a Record is serialized fist, followed by contents of various records, all into the same file. &lt;/p&gt;

&lt;p&gt;Every Record also supports a method that allows a user to set a filter for deserializing. A method &lt;em&gt;setRTIFilter()&lt;/em&gt; takes a &lt;em&gt;RecordTypeInfo&lt;/em&gt; object as a parameter. This filter represents the type information of the data that is being deserialized. When deserializing, the Record uses this filter (if one is set) to figure out what to read. Continuing with our example, here&apos;s how we could deserialize records:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;FileInputStream fIn = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; FileInputStream(&lt;span class=&quot;code-quote&quot;&gt;&quot;data.log&quot;&lt;/span&gt;);
&lt;span class=&quot;code-comment&quot;&gt;// we know the record was written in CSV format
&lt;/span&gt;CsvRecordInput csvIn = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; CsvRecordInput(fIn);
...
&lt;span class=&quot;code-comment&quot;&gt;// we know the type info is written in the beginning. read it. 
&lt;/span&gt;RecordTypeInfo typeInfoFilter = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; RecordTypeInfo();
&lt;span class=&quot;code-comment&quot;&gt;// deserialize it
&lt;/span&gt;typeInfoFilter.deserialize(csvIn);
&lt;span class=&quot;code-comment&quot;&gt;// let MyLogRecord know what to expect
&lt;/span&gt;MyLogRecord.setRTIFilter(typeInfoFilter);
&lt;span class=&quot;code-comment&quot;&gt;// deserialize each record
&lt;/span&gt;&lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (there is data in file) {
  MyLogRecord log = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; MyLogRecord();
  log.read(csvIn);
  ...
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The filter is optional. If not provided, the deserializer expects data to be in the same format as it would serialize. (Note that a filter can also be provided for serializing, forcing the serializer to write information in the format of the filter, but there is no use case for this functionality yet). &lt;/p&gt;

&lt;p&gt;What goes in the type information for a record? The type information for each field in a Record is made up of:&lt;br/&gt;
   1. a unique field ID, which is the field name. &lt;br/&gt;
   2. a type ID, which denotes the type of the field (int, string, map, etc). &lt;/p&gt;

&lt;p&gt;The type information for a composite type contains type information for each of its fields. This approach is somewhat similar to the one taken by &lt;a href=&quot;http://developers.facebook.com/thrift/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Facebook&apos;s Thrift&lt;/a&gt;, as well as by Google&apos;s Sawzall. The main difference is that we use field names as the field ID, whereas Thrift and Sawzall use user-defined field numbers. While field names take more space, they have the big advantage that there is no change to support existing DDLs. &lt;/p&gt;

&lt;p&gt;When deserializing, a Record looks at the filter and compares it with its own set of &lt;/p&gt;
{field name, field type}
&lt;p&gt; tuples. If there is a field in the data that it doesn&apos;t know about it, it skips it (it knows how many bytes to skip, based on the filter). If the deserialized data does not contain some field values, the Record gives them default values. Additionally, we could allow users to optionally specify default values in the DDL. The location of a field in a structure does not matter. This lets us support reordering of fields. Note that there is no change required to the DDL syntax, and very minimal changes to client code (clients just need to read/write type information, in addition to record data). &lt;/p&gt;

&lt;p&gt;This scheme gives us an addition powerful feature: we can build a generic serializer/deserializer, so that users can read all kinds of data without having access to the original DDL or the original stubs. As long as you know where the type information of a record is serialized, you can read all kinds of data. One can also build a simple UI that displays the structure of data serialized in any generic file. This is very useful for handling data across lots of versions. &lt;/p&gt;
</description>
                <environment></environment>
        <key id="12378043">HBASE-291</key>
            <summary>Adding versioning to Record I/O</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="vivekr">Vivek Ratan</reporter>
                        <labels>
                    </labels>
                <created>Wed, 12 Sep 2007 12:04:11 +0000</created>
                <updated>Fri, 22 Aug 2008 21:34:58 +0000</updated>
                            <resolved>Thu, 17 Jan 2008 10:19:37 +0000</resolved>
                                                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="12527406" author="nilayvaish" created="Fri, 14 Sep 2007 08:31:47 +0000"  >&lt;p&gt;I was thinking about the type info required for composite types. As per the Sawzall paper, the field ID is required for identifying the field in the binary representation. I was wondering how it will happen if we use field Names as field IDs. Can you provide your thoughts on this?&lt;/p&gt;</comment>
                            <comment id="12527705" author="vivekr" created="Sat, 15 Sep 2007 06:49:31 +0000"  >&lt;p&gt;Not sure I understand your question fully. As long as a field name or a field number uniquely identifies a field within the enclosing record, we can serialize/deserialize simple and composite types. Suppose we have the following DDL: &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
class small_struct {
  &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; a;
  &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; b;
}

class big_struct {
  &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; a;
  small_struct s;
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Within a class, I cannot have more than one field with the same &lt;/p&gt;
{type, name} tuple. So the {type, name}
&lt;p&gt; tuple is the unique identifier of the field. The two fields named &apos;a&apos; are in different classes, so we&apos;re OK. Sawzall/Thrift leave it to the user to assign unique field numbers to each field, and use that as the unique field identifier. This approach uses fewer bytes, but requires the user&apos;s support. For Jute, the former approach seems better.&lt;/p&gt;

&lt;p&gt;Is this what you were asking? &lt;/p&gt;</comment>
                            <comment id="12527951" author="nilayvaish" created="Mon, 17 Sep 2007 05:59:02 +0000"  >&lt;p&gt;Let me break my question into parts. That should help. &lt;/p&gt;

&lt;p&gt;1. Why do Swazall/Thrift use field numbers when each field can be recognised by the ID? Do they not keep the field IDs? Having both field IDs and field names should require more space than just having the field IDs.&lt;br/&gt;
2. Within a class, does not a name itself identifies a field? AFAIK type is not required. The class given below should be invalid since it has two fields of same name.&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;class a{
  int s;
  char s;
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Thanks&lt;br/&gt;
Nilay&lt;/p&gt;</comment>
                            <comment id="12527961" author="vivekr" created="Mon, 17 Sep 2007 07:02:11 +0000"  >&lt;p&gt;Let me answer #2 first. Remember, with versioning, we&apos;re looking to figure out which fields have changed. You need both a field name and its type to uniquely identify a field. Suppose we have: &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
class a{
  &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; s;
  &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt; c;
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now, suppose I replace the second field: &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
class a{
  &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; s;
  &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; c;
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;A deserializer generated from the new class, when reading code serialized by the old class, needs to understand that the second field in the serialized data needs to be skipped, i.e., &apos;char c&apos; is different from from &apos;long c&apos;. Similarly, if I changed just the name of a field, and not its type, it is a different field (this one is more debatable, but it&apos;s safer to assume that it&apos;s a different field). So the type information needs to contain both the field name and field type, which a deserializer matches with the field name and type of its own fields to see what to read and what to skip. &lt;span class=&quot;error&quot;&gt;&amp;#91;BTW, your example is true in that the class is invalid because both fields have the same name, but I think it&amp;#39;s the wrong example for what we&amp;#39;re discussing&amp;#93;&lt;/span&gt;. &lt;/p&gt;

&lt;p&gt;Now, alternatively, I could have the user assign a unique field number to each field (which Thrift and Sawzall do). I could have something like this: &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
class a{
  1: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; s;
  2: &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt; c;
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;If a user changes a field, they decide whether the field number changes. They SHOULD change the field number if the field type changes (and maybe if only the name changes). Any deserializer will depend on the user-generated field numbers to decide what fields to read and what to skip. So, for example, you could change the class as follows: &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
class a{
  1:&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; s;
  3:&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; c;
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Here, the changed field has been given a new field number. &lt;/p&gt;

&lt;p&gt;Either approach works. The latter (using field numbers) is more space-efficient as we just need to keep track of field numbers (and types, in order to know how many bytes to skip). But it requires manual user support and is more prone to errors. We&apos;re recommending using the former as the space inefficiency is minuscule (since you presumably will store the type information once, for hundreds and thousands of records), and you don&apos;t have to change DDLs and depend on users generating field numbers. &lt;/p&gt;</comment>
                            <comment id="12528245" author="nilayvaish" created="Tue, 18 Sep 2007 04:53:03 +0000"  >&lt;p&gt;That explains it all. Have you started working on this?&lt;/p&gt;

&lt;p&gt;Thanks&lt;br/&gt;
Nilay&lt;/p&gt;</comment>
                            <comment id="12528295" author="hammer" created="Tue, 18 Sep 2007 08:06:13 +0000"  >&lt;p&gt;i&apos;m no expert here, but this approach appears to be sacrificing the long-term benefit of ever using jute for high-frequency rpc in favor of the short-term benefit of not breaking existing ddls (and also encourages developers to come up with short names for fields, never a good thing).  your approach does make for much nicer ddl files, however.  it should be noted that thrift works just fine without the numbering of fields: it generates field indentifiers counting down from -1 for unnumbered fields.&lt;/p&gt;

&lt;p&gt;this seems like a drawback if one ever wanted to replace hadoop&apos;s ipc serialization (about which i know nothing) with jute, though i&apos;m having trouble concocting scenarios of high-frequency, low payload rpc in the hadoop system.&lt;/p&gt;</comment>
                            <comment id="12528311" author="vivekr" created="Tue, 18 Sep 2007 08:57:27 +0000"  >&lt;p&gt;Jeff, you have a valid point, in that, if we use Record I/O versioning for Hadoop RPC (and it certainly is possible), the cost of using field names can become prohibitive. If you think about it, the requirements for RPC are quite different from that for storage. In the former, the serialized type info is comparable in size to the serialized parameters, whereas in the latter, the type information is minuscule compared to the large amounts of serialized data. It&apos;s unlikely that one solution will satisfy both, so here&apos;s a long-term view of our proposed solution: for storage, using field names seems appropriate. If we use Record I/O for RPC, we introduce optional field numbers, ala Thrift/Sawzall. If field numbers are not provided, one can use field names (or have the compiler generate field numbers). we just need to make sure that the current design (and its implementation) does not prevent us from adding field numbers in the future, and I don&apos;t think it does. It&apos;s also worth actually seeing what the cost of using field names in RPCs will actually be. Perhaps there are other bigger bottlenecks that will show up. Regardless, we can relatively easily add support for field numbers (or some such solution) in the future with minimal fuss. &lt;/p&gt;

&lt;p&gt;Regarding your other points: &lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Developers do not need to use short names when using Record I/O for storage. The savings will be negligible.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;The Thrift compiler does generate default negative numbers for fields. There is a problem with that approach, however, because it cannot remember these numbers across different versions of the DDL. So suppose I have a DDL as follows:
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
class a {
  1: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; s;
  &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt; c;
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The Thrift compiler will assign a value of -1 (or a similar number) to &apos;c&apos;. Now suppose I change the DDL to: &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
class a {
  1: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; s;
  &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; l;
  &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt; c;
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;we have a problem, because the compiler does not remember that it assigned -1 to &apos;c&apos; (unless it explicitly changes the DDL, which it doesn&apos;t). It wil go ahead and assign -1 to &apos;l&apos; and -2 to &apos;c&apos;, which will cause a new deserializer to not read the field &apos;c&apos; from the old serialized data. Things will still not crash, but the solution is not optimal. &lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;In summary, I think that once/if we get to RPC, and if we see a real performance issue, we should look at adding field numbers or something similar. And I think we can do it in a way that doesn&apos;t break backwards compatibility, and lets you pick the optimal solution, depending on whether you&apos;re using versioning for storage or RPC. But the details, and the implementation, can probably wait till we get to that point.&lt;/p&gt;</comment>
                            <comment id="12528403" author="breed" created="Tue, 18 Sep 2007 14:54:21 +0000"  >&lt;p&gt;Using DDLs with RPC shouldn&apos;t be inefficient. The schema of RPCs don&apos;t change. So you get the DDL of the RPC when you first connect and then remember it for subsequent invocations. (Kind of like what happens when you use the DDL for storage.)&lt;/p&gt;

&lt;p&gt;If you are only using the RPC once, then you do pay a price for the DDL transfer, but after a couple of calls it becomes much more efficient than passing a compressed encoding by mapping names to numbers with each invocation.&lt;/p&gt;

&lt;p&gt;Even supporting changes to the RPC DDL while running isn&apos;t hard. (For example, the RPC server goes away and comes back with a new DDL.) You simply have a unique version number (the server can just generate a counter) that represents an instance of the DDL or RPC instance. The client sends the one number with each request. If the a client sends an invalid number, the server sends back a new DDL with a new number. (This is just simple caching.)&lt;/p&gt;

&lt;p&gt;Note the above implies a client conforms to server scheme. You can do the reverse if you want a server conforms to client scheme. I prefer the former.&lt;/p&gt;</comment>
                            <comment id="12528541" author="sameerp" created="Tue, 18 Sep 2007 20:20:17 +0000"  >&lt;p&gt;&amp;gt; i&apos;m no expert here, but this approach appears to be sacrificing the long-term benefit of ever using jute for high-frequency rpc in favor of the short-term benefit of not breaking &lt;br/&gt;
&amp;gt; existing ddls&lt;/p&gt;

&lt;p&gt;Not really. The field names are not part of the serialized record. Field names are only ever present in the serialized DDL. In the RPC use case, the client and server would do an initial handshake where the client discovers the servers interface. All subsequent calls would involve record serialization only. It might actually help in high frequency RPCs since type-ids/names don&apos;t occur over and over again.&lt;/p&gt;</comment>
                            <comment id="12528641" author="hammer" created="Wed, 19 Sep 2007 02:40:43 +0000"  >&lt;p&gt;hmm, talked this over with a thrift dev.  in our services at facebook, most follow the connect -&amp;gt; make call -&amp;gt; disconnect model.  maintaining persistent connections, a negotiation step, and caching of ddl all overly complicate matters, which is deadly for high volume and high performance service deployment.  all of these things may make sense in a system for storage and transfer of massive data streams, however.&lt;/p&gt;</comment>
                            <comment id="12529014" author="eric14" created="Thu, 20 Sep 2007 07:48:38 +0000"  >&lt;p&gt;Yupp.  So we should all pause and discuss before integrating recordio into hadoop RPC.&lt;br/&gt;
There are solutions to your concern, but they all add complexity.&lt;br/&gt;
I&apos;m not sure it makes sense to evolve recordio in that direction.&lt;/p&gt;</comment>
                            <comment id="12530069" author="vivekr" created="Tue, 25 Sep 2007 09:03:40 +0000"  >&lt;p&gt;I have attached the first cut of the code changes (1883_patch01). The versioning functionality currently works only for Java-generated classes. I&apos;d appreciate any comments. Some details of what&apos;s been done: &lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;A new folder org/apache/hadoop/record/platform contains all the new classes that the compiler needs for versioning support.&lt;/li&gt;
	&lt;li&gt;Every generated class has a static method &lt;em&gt;getTypeInfo()&lt;/em&gt; which returns an object of type &lt;em&gt;RecordTypeInfo&lt;/em&gt;. This object is itself a Record and can be read/written.&lt;/li&gt;
	&lt;li&gt;Every generated class also has a method, &lt;em&gt;setTypeFilter()&lt;/em&gt; wherein a user passes in a &lt;em&gt;RecordTypeInfo&lt;/em&gt; object and instructs the class to deserialize data based on this filter.&lt;/li&gt;
	&lt;li&gt;Internally, a &lt;em&gt;RecordTypeInfo&lt;/em&gt; object is a collection of &lt;em&gt;TypeInfo&lt;/em&gt; objects, each representing a field in the record. A &lt;em&gt;TypeInfo&lt;/em&gt; object is made of a field name and a &lt;em&gt;TypeID&lt;/em&gt; object, which represents the type of the field. &lt;em&gt;TypeID&lt;/em&gt; represents a basic type, whereas &lt;em&gt;StructTypeID&lt;/em&gt;, &lt;em&gt;VectorTypeID&lt;/em&gt;, and &lt;em&gt;MapTypeID&lt;/em&gt; (which are subclasses) represent the composite types.&lt;/li&gt;
	&lt;li&gt;When deserializing, an object checks whether it has a filter set. If it doesn&apos;t, it deserializes as before. If a filter is set, the filter is compared against the object&apos;s type information to decide what to read, which member variables to assign data to, and what to skip. To prevent comparing field names and types each time, we compare the two &lt;em&gt;RecordTypeInfo&lt;/em&gt; objects once, and create a vector of ints, which indicates which field to assign data to.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I&apos;m happy to provide class diagrams of changes, if things are not clear. &lt;/p&gt;

&lt;p&gt;I have also attached a zip file (example.zip) which contains a DDL and test code to read and write records with version information. &lt;/p&gt;</comment>
                            <comment id="12532292" author="milindb" created="Wed, 3 Oct 2007 23:40:10 +0000"  >&lt;p&gt;Vivek,&lt;/p&gt;

&lt;p&gt;Can you please generate the patch from within the top hadoop dir ? I cannot apply this patch to trunk, because the filesnames all start with C:\eclipse... etc.&lt;/p&gt;
</comment>
                            <comment id="12532331" author="vivekr" created="Thu, 4 Oct 2007 05:54:54 +0000"  >&lt;p&gt;Sorry, I&apos;ve been inexplicably forgetting to remove the full path from the patch files. I have attached a new patch (1883_patch02) which contains support for both Java and C+&lt;ins&gt;. It&apos;s pretty complete . I have also attached a new zip file (example.zip) which contains Java and C&lt;/ins&gt;+ files that read and write records using the new code. They&apos;re pretty good for testing. &lt;/p&gt;</comment>
                            <comment id="12536769" author="milindb" created="Mon, 22 Oct 2007 18:00:53 +0000"  >&lt;p&gt;Overall:&lt;/p&gt;

&lt;p&gt;Place apache license at the top of each newly added file.&lt;br/&gt;
All public methods, and preferably all methods should have javadoc comments.&lt;br/&gt;
Please integrate examples (converting them to unit tests) into the patch.&lt;br/&gt;
Also please run the record I/O benchmark with and without RTI filter, and please report results.&lt;/p&gt;

&lt;p&gt;package: org.apache.hadoop.record.platform:&lt;/p&gt;


&lt;p&gt;TypeID.java:&lt;/p&gt;

&lt;p&gt;TypeID should extend Record, since it needs to be serialized and deserialized. Currently it implements only the write method. The write method of Record serializes to binary format only, and not any generic serializers, whereas TypeID&apos;s write method can serialize to any RecordOut. This applies to all TypeIDs that extend TypeID.&lt;/p&gt;

&lt;p&gt;Please consider making RIOType a private static inner class.&lt;/p&gt;

&lt;p&gt;StructTypeID.java:&lt;/p&gt;

&lt;p&gt;Class javadoc should say typeID for struct type.&lt;br/&gt;
Also, the serialization format comment does not include the struct name.&lt;/p&gt;

&lt;p&gt;VectorTypeID.java:&lt;/p&gt;

&lt;p&gt;MapTypeID.java:&lt;/p&gt;

&lt;p&gt;class javadoc comment says vector.&lt;br/&gt;
Serialization format comment does not mention keyType, valueType.&lt;/p&gt;


&lt;p&gt;TypeInfo.java:&lt;/p&gt;

&lt;p&gt;TypeInfo should extend Record. (See comment on TypeID above.)&lt;/p&gt;

&lt;p&gt;RecordTypeInfo.java:&lt;/p&gt;

&lt;p&gt;Should extend TypeInfo, once TypeInfo extends Record.&lt;br/&gt;
That would move the hairy serialization and deserialization code (the genericRead* methods) to TypeInfo, and TypeID where they belong.&lt;/p&gt;

&lt;p&gt;Utils.java:&lt;/p&gt;

&lt;p&gt;The skip method really belongs to TypeID. So, we can get rid of Utils.java.&lt;/p&gt;


&lt;p&gt;package: org.apache.hadoop.record.compiler:&lt;/p&gt;

&lt;p&gt;JType.java:&lt;/p&gt;

&lt;p&gt;Methods genRtiFieldCondition and genRtiNestedFieldCondition are commented out. Please remove them.&lt;/p&gt;

&lt;p&gt;JCompType.java:&lt;/p&gt;

&lt;p&gt;Consts.java:&lt;/p&gt;

&lt;p&gt;Please consider making these constants into static methods that take a string as parameter, and return another string (prepended by that constant).&lt;/p&gt;

&lt;p&gt;CppGenerator.java:&lt;/p&gt;

&lt;p&gt;JBuffer.java:&lt;br/&gt;
JBoolean.java:&lt;br/&gt;
JByte.java:&lt;br/&gt;
JDouble.java:&lt;br/&gt;
JFloat.java&lt;br/&gt;
JInt.java:&lt;br/&gt;
JLong.java:&lt;br/&gt;
JString.java:&lt;/p&gt;

&lt;p&gt;All types have an additional inner class now that extends from generic CppType, and adds one method getTypeIDObjectString() that returns the TypeID string. These classes can be eliminated by providing this method in the base class CppType. CppType&apos;s constructor should be modified to take as parameter the TypeIDString. Is there any other functionality that these inner type-specific classes are providing ?&lt;/p&gt;

&lt;p&gt;JVector.java:&lt;br/&gt;
JMap.java:&lt;br/&gt;
JType.java:&lt;/p&gt;

&lt;p&gt;Methods genRtiFieldCondition and genRtiNestedFieldCondition are commented out. Please remove them.&lt;/p&gt;

&lt;p&gt;Method getID() should be modified to prepend RIO_PREFIX, rather than prepending RIO_PREFIX everywhere to getId()&apos;s return value.&lt;/p&gt;

&lt;p&gt;genCompareBytes() and genSlurpBytes() code is not modified to use RIO_PREFIXES.&lt;/p&gt;


&lt;p&gt;JRecord.java:&lt;/p&gt;

&lt;p&gt;Needs cleanup. Lots of commented out code.&lt;br/&gt;
Generate another private method called deserializeWithFilter. That will make generated code more readable.&lt;/p&gt;

&lt;p&gt;In C++ generated code, deserializeWithoutFilter need not be virtual.&lt;/p&gt;</comment>
                            <comment id="12537069" author="vivekr" created="Tue, 23 Oct 2007 16:51:22 +0000"  >
&lt;p&gt;Thanks for the feedback, Milind. This was the first patch, a prototype, and is weak on documentation. That will be fixed in the next patch. I will also be adding test cases, and removing code that has been commented out. &lt;/p&gt;

&lt;p&gt;My feedback&apos;s below. I&apos;ve spent a fair bit of time thinking about the class design for the type information functionality, both in terms of simplicity/extensibility, and also for performance, so that we don&apos;t create extra objects or spend too much time dealing with type information. Therefore I&apos;m addressing your concerns individually.&lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt; TypeID should extend Record, since it needs to be serialized and deserialized. &lt;br/&gt;
TypeID is not a Record. Yes, it can write itself to a stream, but that&apos;s the only similarity. A Record implements WritableComparable and Cloneable, neither of which are needed for TypeID. TypeID, and its children, are very different from Record. They represent the ID of a Jute type. &lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt; Please consider making RIOType a private static inner class.&lt;br/&gt;
RIOType is referred to outside of TypeID (in RecordTypeInfo, for example). It cannot be private.&lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt; TypeInfo should extend Record. (See comment on TypeID above.)&lt;br/&gt;
As I mentioned for TypeID, TypeInfo is also not a Record and shouldn&apos;t extend it. &lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt; RecordTypeInfo.java:Should extend TypeInfo, once TypeInfo extends Record.&lt;br/&gt;
&amp;gt;&amp;gt;That would move the hairy serialization and deserialization code (the genericRead* methods) to TypeInfo, and TypeID where they belong.&lt;br/&gt;
Again, RecordTypeInfo is actually a Record, as you can serialize/deserialize and compare it. It , however, is not a TypeInfo. RecordTypeInfo represents the type information for a record. It is the class that a Jute user sees.  TypeInfo and TypeID are internal classes used by RecordTypeInfo to represent type information (though they do show up in the generated code). Think of it this way: Type information for a record, represented by RecordTypeInfo, is a collection of type information for each of its fields. Each field&apos;s type information, represented by a TypeInfo object, is comprised of the field name (a string) and a field type ID (a TypeID object). So TypeInfo and TypeID are helper classes used by RecordTypeInfo. &lt;br/&gt;
The genericRead* methods belong to RecordTypeInfo as they are used during deserialization. Not sure why you think they&apos;re &apos;hairy&apos;. They&apos;re required because there is a hierarchy of TypeID classes and RecordTypeInfo does not know which to create unless it reads the type of a field during deserialization. And having read the type, it can itself create the right TypeID object - this is clean, simple, and minimizes performance impact. In fact, this same code will be used for generic deserialization. Any particular reasons you think the code is hairy or belongs elsewhere? &lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt; The skip method really belongs to TypeID. So, we can get rid of Utils.java.&lt;br/&gt;
Not really. skip() is a general purpose method and has nothing to do with a TypeID. It&apos;s used during deserialization by RecordTypeInfo. I placed it in a separate class because it really is a utility method, and it can be used in other places (generic deserialization, for example). I realize that Utils only has this one method for now, but that&apos;s where it belongs. &lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt; Please consider making these constants into static methods that take a string as parameter, and return another string (prepended by that constant).&lt;br/&gt;
Why? These really are constants. Turning them into method calls will cost us a method invocation each time they&apos;re used, which seems completely unnecessary. What do I gain by using static methods? What I&apos;ve done is a pretty standard way of defining constants in Java. &lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt; All types have an additional inner class now that extends from generic CppType, and adds one method getTypeIDObjectString() that returns the TypeID string. These classes can be eliminated by providing this method in the base class CppType. CppType&apos;s constructor should be modified to take as parameter the TypeIDString. Is there any other functionality that these inner type-specific classes are providing ?&lt;/p&gt;

&lt;p&gt;I&apos;ve defined inner classes for the CPP types for the following reasons: &lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;they mirror more closely the inner classes for the Java types&lt;/li&gt;
	&lt;li&gt;even though they really have only one method for now, this is the right way to do OO. Rather than pass a string to the constructor, each class overrides the getTypeIDObjectString() method, just as with the Java classes. Makes it much easier for change - tomorrow, if the method does other stuff besides just return a string (which it actually did ,before I optimized the code out), then this design makes it so much easier. I don&apos;t like passing subclass-specific stuff to the constructor, just to save on a method. It&apos;s not good design. I realize we have additional classes, but so what? There&apos;s no performance impact, and the code, IMO, is much cleaner, symmetric, and more OO.&lt;/li&gt;
	&lt;li&gt;it&apos;s quite possible that we will add other methods to these classes in the future. The Java classes already have other methods. I didn&apos;t look at redesigning the C++ classes, but I would think that the C++ inner classes would mirror the Java classes quite closely. This way, we don&apos;t have two different algorithms or control flows, one for Java and one for C++.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&amp;gt;&amp;gt; Method getID() should be modified to prepend RIO_PREFIX, rather than prepending RIO_PREFIX everywhere to getId()&apos;s return value.&lt;br/&gt;
I&apos;m ambivalent on this one. getID() is supposed to append a level number to a string. The string is prefixed by RIO_PREFIX  in some cases (where we can clash with user defined variables; see &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-1994&quot; title=&quot;Variable names generated by Record I/O should not clash with user fields&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-1994&quot;&gt;&lt;del&gt;HADOOP-1994&lt;/del&gt;&lt;/a&gt;), but there are other cases where the string passed to getID() is not prefixed by RIO_PREFIX. So we can&apos;t add RIO_PREFIX in getID(). Well, we could, but the generated code would look a little more ugly (RIO_PREFIX, while required, does not make for pretty variable names). Right now, the Jute code looks a little more ugly with RIO_PREFIX being explicitly prefixed in some cases, but I&apos;d prefer that over slightly uglier generated code, which the user is more likely to look at. This is a pretty small matter, so if you have stronger feelings about it than I do, I can make the change. &lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt; genCompareBytes() and genSlurpBytes() code is not modified to use RIO_PREFIXES.&lt;br/&gt;
This is because this code does not use the DDL-defined fields, so we don&apos;t need RIO_PREFIX (again, see &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-1994&quot; title=&quot;Variable names generated by Record I/O should not clash with user fields&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-1994&quot;&gt;&lt;del&gt;HADOOP-1994&lt;/del&gt;&lt;/a&gt;). &lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt; Generate another private method called deserializeWithFilter. That will make generated code more readable.&lt;br/&gt;
deserialize() is really &apos;deserialize with filter&apos;. It checks if a filter is present. If not, it calls deserializeWithoutFilter(). Otherwise it continues. Seems unnecessary to have another method called deserializeWithFilter, and have deserialize() just do a check for the presence of a filter and call either deserializeWithFilter() or deserializeWithoutFilter(). I don&apos;t think this will enhance readability much. &lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt; In C++ generated code, deserializeWithoutFilter need not be virtual&lt;br/&gt;
deserializeWithoutFilter(), which really is the old deserialize(), is virtual because deserialize() is virtual. I think we either want both to be virtual or both to not be virtual. Since deserialize() was virtual in the old code, I also made deserializeWithoutFilter() also virtual. &lt;/p&gt;
</comment>
                            <comment id="12537094" author="owen.omalley" created="Tue, 23 Oct 2007 17:54:03 +0000"  >&lt;p&gt;Please change to use autoconf/automake for the c++ code like the src/c++/utils and pipes do. It makes it much much easier to make the code compile in a cross-platform environment. There is also duplicated code between utils and librecordio that should be shared.&lt;/p&gt;</comment>
                            <comment id="12537216" author="vivekr" created="Wed, 24 Oct 2007 06:23:47 +0000"  >&lt;p&gt;&amp;gt;&amp;gt; Please change to use autoconf/automake for the c++ code like the src/c++/utils and pipes do. It makes it much much easier to make the code compile in a cross-platform environment. There is also duplicated code between utils and librecordio that should be shared.&lt;/p&gt;

&lt;p&gt;These are valid points, but I think it makes more sense to track them separately in Jira. They&apos;re more to do with cleanup of the current C++ code, than with Record I/O versioning. Owen, if it makes sense, can you open up a separate Jira issue for your suggestions? Thanks. &lt;/p&gt;</comment>
                            <comment id="12537424" author="owen.omalley" created="Wed, 24 Oct 2007 21:11:18 +0000"  >&lt;p&gt;Ok, I just assigned &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-397&quot; title=&quot;c/c++ record io library does not use autoconf&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-397&quot;&gt;&lt;del&gt;HADOOP-397&lt;/del&gt;&lt;/a&gt; to you. &lt;b&gt;smile&lt;/b&gt;&lt;/p&gt;</comment>
                            <comment id="12537541" author="cwalters" created="Thu, 25 Oct 2007 08:25:30 +0000"  >&lt;p&gt;Picking back up the thread on RPC, HBase has some use cases that would entail high-frequency, low payload RPC. So the HBase folks would be interested in solutions that allow for this.&lt;/p&gt;</comment>
                            <comment id="12555079" author="vivekr" created="Mon, 31 Dec 2007 11:30:11 +0000"  >&lt;p&gt;The latest patch (1883_patch03) is attached, along with unit test cases for both Java and C++. &lt;/p&gt;</comment>
                            <comment id="12555528" author="hadoopqa" created="Thu, 3 Jan 2008 10:41:12 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
&lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12372354/1883_patch03&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12372354/1883_patch03&lt;/a&gt;&lt;br/&gt;
against trunk revision .&lt;/p&gt;

&lt;p&gt;    @author +1.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    javadoc +1.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    javac +1.  The applied patch does not generate any new compiler warnings.&lt;/p&gt;

&lt;p&gt;    findbugs -1.  The patch appears to introduce 9 new Findbugs warnings.&lt;/p&gt;

&lt;p&gt;    core tests +1.  The patch passed core unit tests.&lt;/p&gt;

&lt;p&gt;    contrib tests -1.  The patch failed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1453/testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1453/testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1453/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1453/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle results: &lt;a href=&quot;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1453/artifact/trunk/build/test/checkstyle-errors.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1453/artifact/trunk/build/test/checkstyle-errors.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1453/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1453/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="12555961" author="vivekr" created="Fri, 4 Jan 2008 16:10:48 +0000"  >&lt;p&gt;Fixed findings from Findbugs. New patch (1883_patch04) submitted. &lt;/p&gt;</comment>
                            <comment id="12555962" author="vivekr" created="Fri, 4 Jan 2008 16:11:34 +0000"  >&lt;p&gt;Resubmitting new patch&lt;/p&gt;</comment>
                            <comment id="12556333" author="hadoopqa" created="Sun, 6 Jan 2008 05:33:36 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
&lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12372512/1883_patch04&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12372512/1883_patch04&lt;/a&gt;&lt;br/&gt;
against trunk revision .&lt;/p&gt;

&lt;p&gt;    @author +1.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    javadoc -1.  The javadoc tool appears to have generated  messages.&lt;/p&gt;

&lt;p&gt;    javac +1.  The applied patch does not generate any new compiler warnings.&lt;/p&gt;

&lt;p&gt;    findbugs -1.  The patch appears to cause Findbugs to fail.&lt;/p&gt;

&lt;p&gt;    core tests -1.  The patch failed core unit tests.&lt;/p&gt;

&lt;p&gt;    contrib tests -1.  The patch failed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1482/testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1482/testReport/&lt;/a&gt;&lt;br/&gt;
Checkstyle results: &lt;a href=&quot;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1482/artifact/trunk/build/test/checkstyle-errors.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1482/artifact/trunk/build/test/checkstyle-errors.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1482/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1482/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="12556485" author="vivekr" created="Mon, 7 Jan 2008 05:29:41 +0000"  >&lt;p&gt;Build broke because of hbase problems (don&apos;t know why). Cancelling patch so I can resubmit it. &lt;/p&gt;</comment>
                            <comment id="12556540" author="hadoopqa" created="Mon, 7 Jan 2008 10:42:42 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
&lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12372512/1883_patch04&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12372512/1883_patch04&lt;/a&gt;&lt;br/&gt;
against trunk revision .&lt;/p&gt;

&lt;p&gt;    @author +1.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    javadoc +1.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    javac +1.  The applied patch does not generate any new compiler warnings.&lt;/p&gt;

&lt;p&gt;    findbugs -1.  The patch appears to introduce 4 new Findbugs warnings.&lt;/p&gt;

&lt;p&gt;    core tests +1.  The patch passed core unit tests.&lt;/p&gt;

&lt;p&gt;    contrib tests +1.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1497/testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1497/testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1497/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1497/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle results: &lt;a href=&quot;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1497/artifact/trunk/build/test/checkstyle-errors.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1497/artifact/trunk/build/test/checkstyle-errors.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1497/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1497/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="12556555" author="vivekr" created="Mon, 7 Jan 2008 12:39:09 +0000"  >&lt;p&gt;Findbugs warnings can be ignored. &lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;The Bad Practice warning, &apos;org.apache.hadoop.record.meta.RecordTypeInfo defines compareTo(Object) and uses Object.equals()&apos;, can be ignored since RecordTypeInfo::comparTo() is unsupported (it throws an exception and shouldn&apos;t be called).&lt;/li&gt;
	&lt;li&gt;The other 3 warnings, &apos;Dodgy warnings&apos;, are for unchecked casts. All three casts are valid as they&apos;re based on the typeVal field of a TypeID object. No sense in doing a dynamic check as the typeVal field guarantees the type of the object.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12559838" author="devaraj" created="Thu, 17 Jan 2008 07:03:17 +0000"  >&lt;p&gt;I just committed this. Thanks, Vivek!&lt;/p&gt;</comment>
                            <comment id="12559873" author="devaraj" created="Thu, 17 Jan 2008 09:34:40 +0000"  >&lt;p&gt;Reverted patch due to a bad commit. Will commit the patch again in a bit.&lt;/p&gt;</comment>
                            <comment id="12559890" author="devaraj" created="Thu, 17 Jan 2008 10:19:37 +0000"  >&lt;p&gt;Fixed the commit issue.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12366516" name="1883_patch01" size="75374" author="vivekr" created="Tue, 25 Sep 2007 09:03:40 +0000"/>
                            <attachment id="12367048" name="1883_patch02" size="108474" author="vivekr" created="Thu, 4 Oct 2007 05:54:54 +0000"/>
                            <attachment id="12372354" name="1883_patch03" size="145843" author="vivekr" created="Mon, 31 Dec 2007 11:30:10 +0000"/>
                            <attachment id="12372512" name="1883_patch04" size="147997" author="vivekr" created="Fri, 4 Jan 2008 16:10:48 +0000"/>
                            <attachment id="12367049" name="example.zip" size="4669" author="vivekr" created="Thu, 4 Oct 2007 05:54:54 +0000"/>
                            <attachment id="12366517" name="example.zip" size="2550" author="vivekr" created="Tue, 25 Sep 2007 09:03:40 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>6.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 14 Sep 2007 08:31:47 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>25075</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 47 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0h6an:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>98282</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>