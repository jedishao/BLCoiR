<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sat Dec 03 19:34:36 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-9864/HBASE-9864.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-9864] Notifications bus for use by cluster members keeping up-to-date on changes</title>
                <link>https://issues.apache.org/jira/browse/HBASE-9864</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;In namespaces and acls, zk callbacks are used so all participating servers are notified when there is a change in acls/namespaces list.&lt;/p&gt;

&lt;p&gt;The new visibility tags feature coming in copies the same model of using zk with listeners for the features&apos; particular notifications.&lt;/p&gt;

&lt;p&gt;Three systems each w/ their own implementation of the notifications all using zk w/ their own feature-specific watchers.&lt;/p&gt;

&lt;p&gt;Should probably unify.&lt;/p&gt;

&lt;p&gt;Do we have to go via zk?  Seems like all want to be notified when an hbase table is updated.  Could we tell servers directly rather than go via zk?&lt;/p&gt;</description>
                <environment></environment>
        <key id="12676713">HBASE-9864</key>
            <summary>Notifications bus for use by cluster members keeping up-to-date on changes</summary>
                <type id="13" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/genericissue.png">Brainstorming</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="stack">stack</reporter>
                        <labels>
                    </labels>
                <created>Wed, 30 Oct 2013 20:03:40 +0000</created>
                <updated>Thu, 23 Oct 2014 17:47:37 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>17</watches>
                                                                <comments>
                            <comment id="13809595" author="nkeywal" created="Wed, 30 Oct 2013 20:42:33 +0000"  >&lt;p&gt;We have the cluster status, sent w/ a multicast message. It scales, and the server does not need to know about the client.&lt;br/&gt;
ZK is interesting as it now has cheap local session (&lt;a href=&quot;https://issues.apache.org/jira/browse/ZOOKEEPER-1147&quot; title=&quot;Add support for local sessions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;ZOOKEEPER-1147&quot;&gt;&lt;del&gt;ZOOKEEPER-1147&lt;/del&gt;&lt;/a&gt;). &lt;/p&gt;

&lt;p&gt;It depends as well on the reliability we need, and if we need to see all states or not.&lt;/p&gt;</comment>
                            <comment id="13809599" author="apurtell" created="Wed, 30 Oct 2013 20:46:45 +0000"  >&lt;p&gt;See &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7254&quot; title=&quot;Refactor AccessController ZK-mediated permissions cache into a generic mechanism&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7254&quot;&gt;&lt;del&gt;HBASE-7254&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13809943" author="anoop.hbase" created="Thu, 31 Oct 2013 05:31:09 +0000"  >&lt;p&gt;One item came up was using Procedure way. But this would involve Master also into these ops. Take case of ACL where the ACL region is associated with an HRS, the ACL admin operations are performed via Endpoints now. So client need to talks with one HRS only. A procedure for ACL admin operation means HM involvement and APIs in HM &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/help_16.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  This was my worry point.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Do we have to go via zk? Seems like all want to be notified when an hbase table is updated. Could we tell servers directly rather than go via zk?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Such a generic framework will be good..&lt;/p&gt;</comment>
                            <comment id="13809985" author="ram_krish" created="Thu, 31 Oct 2013 06:38:48 +0000"  >&lt;p&gt;Yes.  I noted the same point in RB.  I tried using the Procedure when we started the Visibility implementation and found that is involving master also.  So that would not suit these ACLs, Visibility etc.  May be make the procedure framework itself more flexible can be checked (not sure). +1 for the idea.&lt;/p&gt;</comment>
                            <comment id="13810307" author="apurtell" created="Thu, 31 Oct 2013 14:45:18 +0000"  >&lt;p&gt;Granting or revoking table or CF permissions or clearauths/setauths or add_label is just like a snapshot prepare or schema change action, something that needs to be globally applied and Procedure provides a way to do that with tracking of success or failure in that regard. That seems like a good thing to me. What we don&apos;t have with ZK watches today is any guarantee or confirmation that all clients with a watch received notification. In practice it works but ZK makes no guarantee, any given quorum peer can be behind the leader by some delta. The guarantee that ZK provides is that any znode change that a client sees was agreed upon by the majority at the time the proposal was committed. The client can call sync() on a znode to ask the quorum peer to sync with the leader first but to my knowledge there is no syncWatchers().&lt;/p&gt;</comment>
                            <comment id="13942167" author="apurtell" created="Thu, 20 Mar 2014 19:20:30 +0000"  >&lt;p&gt;With the namespace auditor we have yet another ZK based cache+notification bus possibly going in. At some point we have to stop reimplementing variations of this and pay down the accumulating technical debt. It&apos;s not fair to require a contributor to do that work along with what they actually want to accomplish, but at some point we have to deal with this. Is 1.0 a reasonable line in the sand? I have set this as a blocker for that release to stimulate some discussion.&lt;/p&gt;</comment>
                            <comment id="13942168" author="apurtell" created="Thu, 20 Mar 2014 19:20:53 +0000"  >&lt;p&gt;The namespace auditor is &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8410&quot; title=&quot;Basic quota support for namespaces&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8410&quot;&gt;&lt;del&gt;HBASE-8410&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13961461" author="apurtell" created="Sun, 6 Apr 2014 17:05:24 +0000"  >&lt;p&gt;See &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10919&quot; title=&quot;[VisibilityController] ScanLabelGenerator using LDAP&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10919&quot;&gt;HBASE-10919&lt;/a&gt;. It could be useful if the envisioned distributed cache there could be propagated among RegionServers in the background with best effort. Update conflicts could be resolved with a latest update wins policy and cache misses during propagation would be fine.&lt;/p&gt;

&lt;p&gt;Consider a trivial internal distributed non-persistent store where we reserve a small proportion of heap for in-memory storage and propagate updates from RegionServer to RegionServer using an epidemic gossip protocol over UDP. &lt;/p&gt;

&lt;p&gt;We could use this same new component for backing the AccessController&apos;s table/CF ACL cache, and other caches of this nature, if in addition we support pinning of specific items to prevent eviction and provide an alternative update propagation option using a distributed barrier procedure (&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-9426&quot; title=&quot;Make custom distributed barrier procedure pluggable &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-9426&quot;&gt;&lt;del&gt;HBASE-9426&lt;/del&gt;&lt;/a&gt;) to guarantee the global consistency of the update. Change notification could piggyback on cache updates by way of a listener interface.&lt;/p&gt;

&lt;p&gt;Then we would have for distributing internal state a lightweight option for lazy propagation when only that is needed (idempotent updates, eventual consistency) and a heavyweight option for assuring change notification or state updates are delivered to all RegionServers. Neither need be tightly coupled to ZooKeeper. The gossip protocol would have no relationship to ZooKeeper. The Procedure based update should be abstracted from ZK after &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10909&quot; title=&quot;Abstract out ZooKeeper usage in HBase - phase 1&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10909&quot;&gt;&lt;del&gt;HBASE-10909&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13961659" author="mantonov" created="Mon, 7 Apr 2014 06:19:19 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;when you&apos;re talking about &quot;propagated in the background with best effort&quot; and &quot;internal distributed non-persistent store&quot;, and that it doesn&apos;t have to be coupled to ZK, you mean that this store would be kind of option for the consensus library (referred via &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10909&quot; title=&quot;Abstract out ZooKeeper usage in HBase - phase 1&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10909&quot;&gt;&lt;del&gt;HBASE-10909&lt;/del&gt;&lt;/a&gt;), and that it would have 2 modes of replication - one for &quot;guaranteed&quot; propagation of distributed state (like part of distributed state machine&quot; and one for &quot;best effort&quot; propagation&quot;? Do I understand that correct? I.e. when you say &quot;best effort&quot;, what kind of guarantees you imply?&lt;/p&gt;</comment>
                            <comment id="13961699" author="apurtell" created="Mon, 7 Apr 2014 08:21:03 +0000"  >&lt;p&gt;Not a store for the consensus library, a distributed store/cache for internal use by components like the security coprocessors and namespace management (all of which currently do their own thing).&lt;/p&gt;

&lt;p&gt;By best effort I proposed above epidemic propagation. We could tune by interval and fanout. No guarantees besides a likelihood of convergence after an interval that can be derived from those parameters. &lt;/p&gt;

&lt;p&gt;Yes, another mode that guarantees propagation to all RegionServers or returns failure. &lt;/p&gt;

&lt;p&gt;We could add a simple gossip protocol for the first and use the pluggable distributed barrier facility for the second. The consensus package could handle the second also.&lt;/p&gt;</comment>
                            <comment id="13961705" author="mantonov" created="Mon, 7 Apr 2014 08:32:33 +0000"  >&lt;p&gt;So the emphasis in that case would be on performance over the strong consistency, right? So that if some piece of info hasn&apos;t been timely replicated to a particular node, it&apos;s fine - the request will look for them using remote call or..?&lt;/p&gt;</comment>
                            <comment id="13961746" author="apurtell" created="Mon, 7 Apr 2014 09:43:50 +0000"  >&lt;p&gt;In this particular case we would be propagating updates for a distributed cache, where we want to loosly synchronize a cache kept on all RegionServers. If an update does arrive in time before we go to query the external system, then we have saved some work. Otherwise still no problem. So performance, yes, but lightweight more so. &lt;/p&gt;</comment>
                            <comment id="13961751" author="mantonov" created="Mon, 7 Apr 2014 09:48:16 +0000"  >&lt;p&gt;thanks for clarification! now better understand the usecase&lt;/p&gt;</comment>
                            <comment id="13961759" author="anoop.hbase" created="Mon, 7 Apr 2014 09:57:56 +0000"  >&lt;p&gt;ACL data, Visibility labels and NS details, these are the current items which can use this Notification bus. correct?&lt;/p&gt;</comment>
                            <comment id="13961797" author="apurtell" created="Mon, 7 Apr 2014 11:52:50 +0000"  >&lt;blockquote&gt;&lt;p&gt;ACL data, visibility labels, and NS details &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes and these would need/use the consistent propagation option. &lt;/p&gt;

&lt;p&gt;Also a new security related use case for LDAP attribute query cache that would only need lightweight propagation. &lt;/p&gt;</comment>
                            <comment id="13962414" author="stack" created="Mon, 7 Apr 2014 23:59:54 +0000"  >&lt;p&gt;Chatting w/ Matteo, would the following do?&lt;/p&gt;

&lt;p&gt;+ For namespaces, tags, and ACL, each RS needs to host an up-to-date copy of the table in its memory.&lt;br/&gt;
+ When any of these tables are changed, either the editor pokes the Master or the Master &apos;notices&apos; the change because it is proactively scanning the tables.&lt;br/&gt;
+ On change, the master ups an internal, in-memory sequence id.&lt;br/&gt;
+ When the regionserver heartbeats, currently the response is empty.  Change the Master so its response is a Set of table names X seqid.&lt;br/&gt;
+ When the regionserver gets the heartbeat reply, it checks the seqid.  If any seqids fail to match, scan the src table and then update the regionserver&apos;s seqid to match that of the master.&lt;br/&gt;
+ If the Master crashes, it will reset its seqids.  They won&apos;t match the regionservers.  Regionservers will all rescan (redundantly).&lt;/p&gt;

&lt;p&gt;No zk and piggybacking on system we already have in place?&lt;/p&gt;</comment>
                            <comment id="13962420" author="mantonov" created="Tue, 8 Apr 2014 00:06:36 +0000"  >&lt;p&gt;Would it make sense to make backup masters host the copy of all seqids, to avoid global rescan?&lt;/p&gt;</comment>
                            <comment id="13962429" author="mbertozzi" created="Tue, 8 Apr 2014 00:14:35 +0000"  >&lt;p&gt;The idea, was that a master going down has the same consequence of an update to e.g. ACL table.&lt;br/&gt;
keeping the copy of the seqid on the backup master is just an optimization and lot of extra work, and I&apos;m not sure if it is really necessary.&lt;/p&gt;</comment>
                            <comment id="13962576" author="ram_krish" created="Tue, 8 Apr 2014 04:57:19 +0000"  >&lt;blockquote&gt;&lt;p&gt;When any of these tables are changed, either the editor pokes the Master or the Master &apos;notices&apos; the change because it is proactively scanning the tables.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This editor is now on the master side? Currently master does not get involved in these updations on the ACL/visibility tables.&lt;/p&gt;</comment>
                            <comment id="13962587" author="stack" created="Tue, 8 Apr 2014 05:07:59 +0000"  >&lt;blockquote&gt;&lt;p&gt;This editor is now on the master side?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It doesn&apos;t have to be but over in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10295&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-10295&lt;/a&gt; it is suggested that the master edit system tables only.  Would it be hard to do this?&lt;/p&gt;</comment>
                            <comment id="13963078" author="apurtell" created="Tue, 8 Apr 2014 15:26:27 +0000"  >&lt;blockquote&gt;&lt;p&gt;When any of these tables are changed, either the editor pokes the Master or the Master &apos;notices&apos; the change because it is proactively scanning the tables.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This part I&apos;m fuzzy about because currently the coprocessors running on the meta table notice the change immediately and trigger a notification by changing znode data. How would this work in the alternative? The reason I suggest a Procedure based update (or equivalent) is so we can guarantee that the change has committed &quot;immediately&quot; in every local cache, with the additional benefit of knowing if not. (We don&apos;t have this last part today because we use ZK watchers, but we really should.)&lt;/p&gt;</comment>
                            <comment id="13963407" author="stack" created="Tue, 8 Apr 2014 20:35:51 +0000"  >&lt;p&gt;The editor will not need to poke the master or the master will not need to do proactive scans looking for updates if the argument that master and meta are tied prevails over in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10569&quot; title=&quot;Co-locate meta and master&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10569&quot;&gt;&lt;del&gt;HBASE-10569&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So, allowing &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10569&quot; title=&quot;Co-locate meta and master&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10569&quot;&gt;&lt;del&gt;HBASE-10569&lt;/del&gt;&lt;/a&gt;, system table edits will be noticed &apos;immediately&apos;.&lt;/p&gt;

&lt;p&gt;In the proposal, we could pass the edit on the back of the heartbeat or easier, just prompt the heartbeater go do the lookup on the table itself.  In the first case, it may be a full heartbeat period before changes are noticed.  In the second case, it would be the heartbeat period + time to scan the table.  This could be seconds.   Is this &apos;soon-as-possible&apos; too much for say, an ACL update?&lt;/p&gt;

&lt;p&gt;On plus side, this is easy-to-do and undoes our reliance on a 3rd system (zk) for notification.&lt;/p&gt;

&lt;p&gt;Later we could do a new Procedure mechanism if needed that writes over a new x-cluster direct channel between Master and RS pushing out the change, waiting on all to acknowledge and taking evasive action if any fails.  This would be more work but probably closer to &apos;immediate&apos;.&lt;/p&gt;</comment>
                            <comment id="13963437" author="apurtell" created="Tue, 8 Apr 2014 21:00:10 +0000"  >&lt;blockquote&gt;&lt;p&gt;On plus side, this is easy-to-do and undoes our reliance on a 3rd system (zk) for notification.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I thought other issues are undoing our reliance on ZK? Presumably distributed barriers would be ported to it so therefore no reliance on ZK then?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Later we could do a new Procedure mechanism &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think it needs to be now. We have anecdotal evidence that ZK watches &quot;work&quot; but won&apos;t have such evidence for something else. We should not be comfortable with security subsystems that need consistent state everywhere running on something that doesn&apos;t guarantee that. Every current component that has a cache like this needs this guarantee (ACLs, visibility, namespaces) right?&lt;/p&gt;</comment>
                            <comment id="13963440" author="apurtell" created="Tue, 8 Apr 2014 21:01:43 +0000"  >&lt;blockquote&gt;&lt;p&gt;Is this &apos;soon-as-possible&apos; too much for say, an ACL update?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m not concerned with time, it&apos;s the guarantee that the update has been applied at every live location (or not)&lt;/p&gt;</comment>
                            <comment id="13963445" author="mbertozzi" created="Tue, 8 Apr 2014 21:06:26 +0000"  >&lt;blockquote&gt;&lt;p&gt;I&apos;m not concerned with time, it&apos;s the guarantee that the update has been applied at every live location (or not)&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;If a &quot;cache update&quot; cannot be applied, is probably because that RS is in a bad state. and it should be aborted.&lt;br/&gt;
if it is just slow (e.g. GC) no one can probably query it, so in that case is fine if the cache update it will be applied later.&lt;/p&gt;

&lt;p&gt;I don&apos;t think the procedure is a good thing e.g. for ACL&lt;br/&gt;
let say that one node is in GC or has some network problem.&lt;br/&gt;
You try to do &quot;grant user&quot; and it fails because one node is not responding within N seconds.&lt;br/&gt;
by using the &quot;heartbeat&quot; everyone will be updated as soon as they can &lt;/p&gt;</comment>
                            <comment id="13963447" author="apurtell" created="Tue, 8 Apr 2014 21:07:02 +0000"  >&lt;p&gt;Part of where I am coming from is &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10569&quot; title=&quot;Co-locate meta and master&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10569&quot;&gt;&lt;del&gt;HBASE-10569&lt;/del&gt;&lt;/a&gt; won&apos;t be backported to 0.98 or 0.96. My above comments should not be viewed as against solving the concerns regarding cache updates in a different way in trunk versus 0.98 or earlier. &lt;/p&gt;</comment>
                            <comment id="13963449" author="apurtell" created="Tue, 8 Apr 2014 21:08:07 +0000"  >&lt;blockquote&gt;&lt;p&gt;You try to do &quot;grant user&quot; and it fails because one node is not responding within N seconds. by using the &quot;heartbeat&quot; everyone will be updated as soon as they can&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m a lot more concerned about a &quot;revoke user&quot; that doesn&apos;t get applied for hours because someone was napping.&lt;/p&gt;</comment>
                            <comment id="13963450" author="apurtell" created="Tue, 8 Apr 2014 21:11:38 +0000"  >&lt;p&gt;Anyway, like I said above I&apos;m a bit fuzzy on how this would work for 0.98 because of assumptions based on code not available in any release yet. &lt;br/&gt;
Edit: ... or backportable to them. This is why I think of Procedures.&lt;/p&gt;</comment>
                            <comment id="13963767" author="stack" created="Wed, 9 Apr 2014 03:56:40 +0000"  >&lt;blockquote&gt;&lt;p&gt;I&apos;m a lot more concerned about a &quot;revoke user&quot; that doesn&apos;t get applied for hours because someone was napping.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;What you thinking Andrew?  Chatting w/ Matteo, if a RS fails to update its local cache, it should abort as we would not being able to update our WAL.  No napping allowed.&lt;/p&gt;

&lt;p&gt;You need something in the 0.98 timeframe too boss?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I thought other issues are undoing our reliance on ZK? Presumably distributed barriers would be ported to it so therefore no reliance on ZK then?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;There are others to undo our zk heavy-reliance, yes.  The suggestion here is that in genericizing a notification system, if possible, avoid zk if we can (Yeah, current zk &apos;works&apos; but if we could avoid having to go to another system...).&lt;/p&gt;</comment>
                            <comment id="13964275" author="apurtell" created="Wed, 9 Apr 2014 15:23:57 +0000"  >&lt;blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;I&apos;m a lot more concerned about a &quot;revoke user&quot; that doesn&apos;t get applied for hours because someone was napping.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;What you thinking Andrew?  Chatting w/ Matteo, if a RS fails to update its local cache, it should abort as we would not being able to update our WAL.  No napping allowed.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m worried about missed notifications, and more generally about proving at the time the update is done that it was applied everywhere, because security guys like proof.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;You need something in the 0.98 timeframe too boss?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thinking about it yes. We have other security fixes and refinements on deck. Thinking is 0.98 is the security proving ground ahead of 1.0+.&lt;/p&gt;</comment>
                            <comment id="13964280" author="mbertozzi" created="Wed, 9 Apr 2014 15:27:52 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;I&apos;m worried about missed notifications, and more generally about proving at the time the update is done that it was applied everywhere, because security guys like proof.&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;ok. so, do you prefer to fail an operation if a machine is slow?&lt;br/&gt;
e.g. the user type &apos;revoke&apos; and if within the timeout the operation is not applied to every RS (cache update), the user will get a failure?&lt;/p&gt;</comment>
                            <comment id="13964297" author="apurtell" created="Wed, 9 Apr 2014 15:48:22 +0000"  >&lt;blockquote&gt;&lt;p&gt;ok. so, do you prefer to fail an operation if a machine is slow?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, the grant or revoke, or label definition, or setauths, etc. should be retried since it failed to be consistently applied.&lt;/p&gt;

&lt;p&gt;(In addition, as part of cleanup any cache updates applied should be rolled back.)&lt;/p&gt;

&lt;p&gt;If somehow onerous elsewhere we could build one thing shared by the the security coprocessors and namespace code and do something else for other kinds of distributed cache / state updates.&lt;/p&gt;</comment>
                            <comment id="13964311" author="mbertozzi" created="Wed, 9 Apr 2014 16:00:03 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Yes, the grant or revoke, or label definition, or setauths, etc. should be retried since it failed to be consistently applied.&lt;br/&gt;
(In addition, as part of cleanup any cache updates applied should be rolled back.)&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;ok, we were trying to unify all the cache updates under a single mechanism but I guess is fine having a relaxed update and a non-relaxed one for security like features. In this case we can just use the Procedure that we have today for the non-relaxed notification, but this means to change operations as something like this:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;RPC revoke
	&lt;ul&gt;
		&lt;li&gt;new Procedure(revoke)&lt;/li&gt;
		&lt;li&gt;acquire: fetch new updates&lt;/li&gt;
		&lt;li&gt;reached: Add the revoke to table + apply the updates&lt;/li&gt;
		&lt;li&gt;abort: discard the updates&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13964317" author="apurtell" created="Wed, 9 Apr 2014 16:05:02 +0000"  >&lt;blockquote&gt;&lt;p&gt;In this case we can just use the Procedure that we have today for the non-relaxed notification, but this means to change operations as something like this:&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Agreed&lt;/p&gt;</comment>
                            <comment id="13964322" author="apurtell" created="Wed, 9 Apr 2014 16:12:41 +0000"  >&lt;p&gt;Above security related discussion relates to &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10544&quot; title=&quot;Surface completion state of global administrative actions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10544&quot;&gt;HBASE-10544&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14181634" author="stack" created="Thu, 23 Oct 2014 17:46:44 +0000"  >&lt;p&gt;Removed from branch-1 because no assignee and not being worked on.&lt;/p&gt;</comment>
                            <comment id="14181636" author="stack" created="Thu, 23 Oct 2014 17:47:15 +0000"  >&lt;p&gt;bq .... not being worked on.&lt;/p&gt;

&lt;p&gt;... in time for 1.0 release (to my knowledge &amp;#8211; correct me if I am wrong)&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12618471">HBASE-7254</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12695314">HBASE-10544</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12666797">HBASE-9426</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12687786">HBASE-10295</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12706836">HBASE-10919</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12730571">HBASE-11608</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12706580">HBASE-10909</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 30 Oct 2013 20:42:33 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>356145</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 6 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1pebb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>356433</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310230" key="com.atlassian.jira.plugin.system.customfieldtypes:textfield">
                        <customfieldname>Tags</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>architecture service</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>