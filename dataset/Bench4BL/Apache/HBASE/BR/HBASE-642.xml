<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 02 20:24:53 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-642/HBASE-642.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-642] Splitting log in a hostile environment -- bad hdfs -- we drop write-ahead-log edits</title>
                <link>https://issues.apache.org/jira/browse/HBASE-642</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;The master has noticed that the regionserver that was carrying the .META. region among others has died and it goes to split its logs:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;2008-05-18 19:58:01,292 DEBUG org.apache.hadoop.hbase.HLog: Splitting 0 of 2: hdfs:&lt;span class=&quot;code-comment&quot;&gt;//domU-12-31-38-00-D4-21:9000/hbase/log_10.254.30.79_1210899434766_60020/hlog.dat.017
&lt;/span&gt;2008-05-18 19:58:01,408 DEBUG org.apache.hadoop.hbase.HLog: Creating &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; log file writer &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; path hdfs:&lt;span class=&quot;code-comment&quot;&gt;//domU-12-31-38-00-D4-21:9000/hbase/categories/1060231198/oldlogfile.log and region categories,2864153,1211005494348
&lt;/span&gt;2008-05-18 19:58:01,573 DEBUG org.apache.hadoop.hbase.HLog: Creating &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; log file writer &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; path hdfs:&lt;span class=&quot;code-comment&quot;&gt;//domU-12-31-38-00-D4-21:9000/hbase/categories/297165731/oldlogfile.log and region categories,5992242,1211005494349&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Master can&apos;t write hdfs for some reason so can&apos;t do the log split:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;2008-05-18 19:59:15,265 INFO org.apache.hadoop.dfs.DFSClient: Exception in createBlockOutputStream java.net.SocketTimeoutException: Read timed out
2008-05-18 19:59:15,266 INFO org.apache.hadoop.dfs.DFSClient: Abandoning block blk_7852777250062244002
2008-05-18 19:59:15,268 INFO org.apache.hadoop.dfs.DFSClient: Waiting to find target node: 10.252.219.207:50010
2008-05-18 19:59:39,945 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.254.30.79:60020. Already tried 6 time(s).
2008-05-18 20:00:21,274 INFO org.apache.hadoop.dfs.DFSClient: Exception in createBlockOutputStream java.io.IOException: Bad connect ack with firstBadLink 10.254.30.79:50010
2008-05-18 20:00:21,275 INFO org.apache.hadoop.dfs.DFSClient: Abandoning block blk_7007215478628265924
2008-05-18 20:00:21,277 INFO org.apache.hadoop.dfs.DFSClient: Waiting to find target node: 10.252.219.207:50010
2008-05-18 20:00:40,955 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.254.30.79:60020. Already tried 7 time(s).
2008-05-18 20:01:31,178 INFO org.apache.hadoop.dfs.DFSClient: Exception in createBlockOutputStream java.io.IOException: Bad connect ack with firstBadLink 10.254.30.79:50010
2008-05-18 20:01:31,178 INFO org.apache.hadoop.dfs.DFSClient: Abandoning block blk_2374125514769088471
2008-05-18 20:01:31,180 INFO org.apache.hadoop.dfs.DFSClient: Waiting to find target node: 10.252.219.207:50010
2008-05-18 20:01:40,145 INFO org.apache.hadoop.dfs.DFSClient: Exception in createBlockOutputStream java.net.SocketTimeoutException: Read timed out
2008-05-18 20:01:40,145 INFO org.apache.hadoop.dfs.DFSClient: Abandoning block blk_-621042589816139684
2008-05-18 20:01:40,148 INFO org.apache.hadoop.dfs.DFSClient: Waiting to find target node: 10.252.219.207:50010
..
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Weirdly, the above is complaining can&apos;t connect to the datanode running on same host as master.&lt;/p&gt;

&lt;p&gt;Eventually the split fails with:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;2008-05-18 20:24:28,393 WARN org.apache.hadoop.hbase.HMaster: Processing pending operations: ProcessServerShutdown of 10.254.30.79:60020
java.io.IOException: java.io.IOException: Could not complete write to file /hbase/categories/1060231198/oldlogfile.log by DFSClient_520078809
    at org.apache.hadoop.dfs.NameNode.complete(NameNode.java:343)
    at sun.reflect.GeneratedMethodAccessor44.invoke(Unknown Source)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:409)
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:901)

    at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
    at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
    at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
    at org.apache.hadoop.hbase.RemoteExceptionHandler.decodeRemoteException(RemoteExceptionHandler.java:82)
    at org.apache.hadoop.hbase.HMaster.run(HMaster.java:1116)
2008-05-18 20:24:28,394 DEBUG org.apache.hadoop.hbase.HMaster: Main processing loop: ProcessServerShutdown of 10.254.30.79:60020
2008-05-18 20:24:28,394 INFO org.apache.hadoop.hbase.HMaster: process shutdown of server 10.254.30.79:60020: logSplit: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, rootRescanned: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, numberOfMetaRegions: 1, onlineMetaRegions.size(): 1
2008-05-18 20:24:28,395 INFO org.apache.hadoop.hbase.HLog: splitting 1 log(s) in hdfs:&lt;span class=&quot;code-comment&quot;&gt;//domU-12-31-38-00-D4-21:9000/hbase/log_10.254.30.79_1210899434766_60020
&lt;/span&gt;2008-05-18 20:24:28,395 DEBUG org.apache.hadoop.hbase.HLog: Splitting 0 of 1: hdfs:&lt;span class=&quot;code-comment&quot;&gt;//domU-12-31-38-00-D4-21:9000/hbase/log_10.254.30.79_1210899434766_60020/hlog.dat.018
&lt;/span&gt;2008-05-18 20:24:28,399 WARN org.apache.hadoop.hbase.HLog: Old log file hdfs:&lt;span class=&quot;code-comment&quot;&gt;//domU-12-31-38-00-D4-21:9000/hbase/categories/297165731/oldlogfile.log already exists. Copying existing file to &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; file
&lt;/span&gt;2008-05-18 20:25:03,105 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.254.30.79:60020. Already tried 9 time(s).
2008-05-18 20:25:28,401 WARN org.apache.hadoop.hbase.HLog: Exception processing hdfs:&lt;span class=&quot;code-comment&quot;&gt;//domU-12-31-38-00-D4-21:9000/hbase/log_10.254.30.79_1210899434766_60020/hlog.dat.018 -- continuing. Possible DATA LOSS!
&lt;/span&gt;java.net.SocketTimeoutException: timed out waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; rpc response
...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And we just move on to the next log &amp;#8211; we notice the earlier attempt at distributing the edits and try to pick them up (though in this case, the file is likely empty) &amp;#8211; but the split of new log also fails.&lt;/p&gt;

&lt;p&gt;Though log says &apos;Possible DATA LOSS!&apos;, we keep going . The .META. and other regions are reassigned and deployed though they are likely missing edits.&lt;/p&gt;

&lt;p&gt;In this catastrophic case, I&apos;d say master should not move and if it has to, go down rather than reassign regions and try to keep going.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12396766">HBASE-642</key>
            <summary>Splitting log in a hostile environment -- bad hdfs -- we drop write-ahead-log edits</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="stack">stack</assignee>
                                    <reporter username="stack">stack</reporter>
                        <labels>
                    </labels>
                <created>Sat, 24 May 2008 21:37:51 +0000</created>
                <updated>Fri, 22 Aug 2008 21:13:16 +0000</updated>
                            <resolved>Wed, 28 May 2008 18:15:22 +0000</resolved>
                                                    <fixVersion>0.1.3</fixVersion>
                    <fixVersion>0.2.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12600552" author="stack" created="Wed, 28 May 2008 18:15:22 +0000"  >&lt;p&gt;Committed branch and trunk.&lt;/p&gt;

&lt;p&gt;Changed the try/catches around the reconstruction log replay so that we only catch and pass on the EOFExceptions.  If an IOE, just report it and let the region fail on each open attempt until human intervention.  If IOE playing reconstruction log, there is something badly wrong probably in hdfs.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Index: src/java/org/apache/hadoop/hbase/HStore.java
===================================================================
--- src/java/org/apache/hadoop/hbase/HStore.java        (revision 660681)
+++ src/java/org/apache/hadoop/hbase/HStore.java        (working copy)
@@ -825,13 +825,21 @@
     
     &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
       doReconstructionLog(reconstructionLog, maxSeqId, reporter);
+    } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (EOFException e) {
+      &lt;span class=&quot;code-comment&quot;&gt;// Presume we got here because of lack of HADOOP-1700; &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; now keep going
&lt;/span&gt;+      &lt;span class=&quot;code-comment&quot;&gt;// but &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; is probably not what we want &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; term.  If we got here there
&lt;/span&gt;+      &lt;span class=&quot;code-comment&quot;&gt;// has been data-loss
&lt;/span&gt;+      LOG.warn(&lt;span class=&quot;code-quote&quot;&gt;&quot;Exception processing reconstruction log &quot;&lt;/span&gt; + reconstructionLog +
+        &lt;span class=&quot;code-quote&quot;&gt;&quot; opening &quot;&lt;/span&gt; + &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.storeName +
+        &lt;span class=&quot;code-quote&quot;&gt;&quot; -- continuing.  Probably lack-of-HADOOP-1700 causing DATA LOSS!&quot;&lt;/span&gt;, e);
     } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (IOException e) {
-      &lt;span class=&quot;code-comment&quot;&gt;// Presume we got here because of some HDFS issue or because of a lack of
&lt;/span&gt;-      &lt;span class=&quot;code-comment&quot;&gt;// HADOOP-1700; &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; now keep going but &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; is probably not what we want
&lt;/span&gt;-      &lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; term.  If we got here there has been data-loss
&lt;/span&gt;+      &lt;span class=&quot;code-comment&quot;&gt;// Presume we got here because of some HDFS issue. Don&apos;t just keep going.
&lt;/span&gt;+      &lt;span class=&quot;code-comment&quot;&gt;// Fail to open the HStore.  Probably means we&apos;ll fail over and over
&lt;/span&gt;+      &lt;span class=&quot;code-comment&quot;&gt;// again until human intervention but alternative has us skipping logs
&lt;/span&gt;+      &lt;span class=&quot;code-comment&quot;&gt;// and losing edits: HBASE-642.
&lt;/span&gt;       LOG.warn(&lt;span class=&quot;code-quote&quot;&gt;&quot;Exception processing reconstruction log &quot;&lt;/span&gt; + reconstructionLog +
-        &lt;span class=&quot;code-quote&quot;&gt;&quot; opening &quot;&lt;/span&gt; + &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.storeName +
-        &lt;span class=&quot;code-quote&quot;&gt;&quot; -- continuing.  Probably DATA LOSS!&quot;&lt;/span&gt;, e);
+        &lt;span class=&quot;code-quote&quot;&gt;&quot; opening &quot;&lt;/span&gt; + &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.storeName, e);
+      &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; e;
     }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>25308</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 28 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0h8k7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>98649</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>