<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sat Dec 03 15:46:48 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-643/HBASE-643.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-643] Rename tables</title>
                <link>https://issues.apache.org/jira/browse/HBASE-643</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;It would be nice to be able to rename tables, if this is possible.  Some of our internal users are doing things like: upload table mytable -&amp;gt; realize they screwed up -&amp;gt; upload table mytable_2 -&amp;gt; decide mytable_2 looks better -&amp;gt; have to go on using mytable_2 instead of originally desired table name.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12396782">HBASE-643</key>
            <summary>Rename tables</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="bien">Michael Bieniosek</reporter>
                        <labels>
                    </labels>
                <created>Sun, 25 May 2008 18:59:27 +0000</created>
                <updated>Thu, 23 May 2013 01:35:23 +0000</updated>
                            <resolved>Thu, 23 May 2013 01:35:23 +0000</resolved>
                                                                        <due></due>
                            <votes>2</votes>
                                    <watches>12</watches>
                                                                <comments>
                            <comment id="12599810" author="udanax" created="Mon, 26 May 2008 10:24:14 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="12599902" author="bryanduxbury" created="Mon, 26 May 2008 19:39:19 +0000"  >&lt;p&gt;Agree, we should have this. +1&lt;/p&gt;</comment>
                            <comment id="12600600" author="franco" created="Wed, 28 May 2008 21:09:59 +0000"  >&lt;p&gt;in alternative:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;overwrite a table&lt;/li&gt;
	&lt;li&gt;remove a table&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;something which basically support the use case of:&lt;/p&gt;

&lt;p&gt;load, reload, reload, ..., reload, ... I am happy ... keep it&lt;/p&gt;</comment>
                            <comment id="12630728" author="stack" created="Sat, 13 Sep 2008 03:00:33 +0000"  >&lt;p&gt;Script to rename a table; needs some more testing.&lt;/p&gt;</comment>
                            <comment id="12630732" author="stack" created="Sat, 13 Sep 2008 07:06:58 +0000"  >&lt;p&gt;Tested against table of 40 regions.  Table was millions of rows, new and so &apos;clean&apos;.  Script worked without issue.&lt;/p&gt;</comment>
                            <comment id="12633098" author="stack" created="Sun, 21 Sep 2008 21:41:08 +0000"  >&lt;p&gt;Previous version put all tables into one.  This new version does the right thing.&lt;/p&gt;</comment>
                            <comment id="12633099" author="stack" created="Sun, 21 Sep 2008 21:41:45 +0000"  >&lt;p&gt;Deleted old broken version.&lt;/p&gt;</comment>
                            <comment id="12634573" author="stack" created="Thu, 25 Sep 2008 18:27:04 +0000"  >&lt;p&gt;Here&apos;s a script to copy a table in hbase.  I&apos;ve been using it here at pset to make copies of tables to get around deletes made before &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-826&quot; title=&quot;delete table followed by recreation results in honked table&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-826&quot;&gt;&lt;del&gt;HBASE-826&lt;/del&gt;&lt;/a&gt; went in.&lt;/p&gt;

&lt;p&gt;If we were to commit these scripts, need to refactor both since they have a bunch in common; we should start a ruby lib subdir under hbase lib into which we put common script utility.&lt;/p&gt;</comment>
                            <comment id="12638403" author="stack" created="Thu, 9 Oct 2008 21:49:36 +0000"  >&lt;p&gt;I committed the above two scripts though 10 lines of duplication.  I went about adding new lib/ruby dir that both require but its a pain making sure we don&apos;t overlap imports &amp;#8211; get messy warnings if duplicated &amp;#8211; so I need to do more study first.&lt;/p&gt;</comment>
                            <comment id="12674736" author="gzbigegg" created="Wed, 18 Feb 2009 18:43:52 +0000"  >&lt;p&gt;I am running hbase-0.19.0 on EC2, when I tried to use that &quot;rename_table.rb&quot;, I hit the following problem:&lt;/p&gt;

&lt;p&gt;bin/hbase org.jruby.Main /mnt/rename_table.rb 1001_profiles 1001_profiles_backup&lt;/p&gt;

&lt;p&gt;09/02/18 13:19:27 INFO regionserver.HLog: New log writer: /user/root/log_1234981167000/hlog.dat.1234981167004&lt;br/&gt;
09/02/18 13:19:27 INFO util.NativeCodeLoader: Loaded the native-hadoop library&lt;br/&gt;
09/02/18 13:19:27 INFO zlib.ZlibFactory: Successfully loaded &amp;amp; initialized native-zlib library&lt;br/&gt;
09/02/18 13:19:27 INFO compress.CodecPool: Got brand-new decompressor&lt;br/&gt;
09/02/18 13:19:27 INFO compress.CodecPool: Got brand-new decompressor&lt;br/&gt;
09/02/18 13:19:27 INFO compress.CodecPool: Got brand-new decompressor&lt;br/&gt;
09/02/18 13:19:27 INFO compress.CodecPool: Got brand-new decompressor&lt;br/&gt;
09/02/18 13:19:27 INFO regionserver.HRegion: region &lt;del&gt;ROOT&lt;/del&gt;,,0/70236052 available&lt;br/&gt;
09/02/18 13:19:27 INFO regionserver.HRegion: starting  compaction on region &lt;del&gt;ROOT&lt;/del&gt;,,0&lt;br/&gt;
09/02/18 13:19:27 INFO compress.CodecPool: Got brand-new compressor&lt;br/&gt;
09/02/18 13:19:27 INFO regionserver.HRegion: compaction completed on region &lt;del&gt;ROOT&lt;/del&gt;,,0 in 0sec&lt;br/&gt;
09/02/18 13:19:27 INFO rename_table: Scanning .META.,,1&lt;br/&gt;
09/02/18 13:19:27 INFO regionserver.HRegion: region .META.,,1/1028785192 available&lt;br/&gt;
09/02/18 13:19:27 INFO regionserver.HRegion: starting  compaction on region .META.,,1&lt;br/&gt;
09/02/18 13:19:28 INFO regionserver.HRegion: compaction completed on region .META.,,1 in 0sec&lt;br/&gt;
09/02/18 13:19:28 INFO rename_table: Renaming hdfs://domU-12-31-39-03-BD-A7.compute-1.internal:50001/hbase/1001_profiles/1153297718 as hdfs://domU-12-31-39-03-BD-A7.compute-1.internal:50001/hbase/1001_profiles_backup/1047320069&lt;br/&gt;
09/02/18 13:19:28 INFO rename_table: Removing 1001_profiles,,1234593264387 from .META.&lt;br/&gt;
09/02/18 13:19:28 INFO regionserver.HRegion: Closed &lt;del&gt;ROOT&lt;/del&gt;,,0&lt;br/&gt;
09/02/18 13:19:28 INFO regionserver.HRegion: Closed .META.,,1&lt;br/&gt;
09/02/18 13:19:28 INFO regionserver.HLog: Closed hdfs://domU-12-31-39-03-BD-A7.compute-1.internal:50001/user/root/log_1234981167000/hlog.dat.0, entries=0. New log writer: /user/root/log_1234981167000/hlog.dat.1234981168417&lt;br/&gt;
09/02/18 13:19:28 INFO regionserver.HLog: removing old log file /user/root/log_1234981167000/hlog.dat.0 whose highest sequence/edit id is 75001755&lt;br/&gt;
&lt;a href=&quot;file:/usr/local/hbase-0.19.0/lib/jruby-complete-1.1.2.jar!/builtin/java/collections.rb:29:&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;file:/usr/local/hbase-0.19.0/lib/jruby-complete-1.1.2.jar!/builtin/java/collections.rb:29:&lt;/a&gt; no deleteAll with arguments matching [class &lt;span class=&quot;error&quot;&gt;&amp;#91;B, class java.lang.Long&amp;#93;&lt;/span&gt; on object #&amp;lt;Java::OrgApacheHadoopHbaseRegionserver::HRegion:0xa8a314 @java_object=.META.,,1&amp;gt; (NameError)&lt;br/&gt;
	from &lt;a href=&quot;file:/usr/local/hbase-0.19.0/lib/jruby-complete-1.1.2.jar!/builtin/java/collections.rb:29:in&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;file:/usr/local/hbase-0.19.0/lib/jruby-complete-1.1.2.jar!/builtin/java/collections.rb:29:in&lt;/a&gt; `call&apos;&lt;br/&gt;
	from &lt;a href=&quot;file:/usr/local/hbase-0.19.0/lib/jruby-complete-1.1.2.jar!/builtin/java/collections.rb:29:in&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;file:/usr/local/hbase-0.19.0/lib/jruby-complete-1.1.2.jar!/builtin/java/collections.rb:29:in&lt;/a&gt; `each&apos;&lt;br/&gt;
	from /mnt/rename_table.rb:100&lt;/p&gt;

&lt;p&gt;After that, I can&apos;t even do a &quot;list&quot; command in HBase shell &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; When I issued &quot;list&quot; in the shell, I see the following dump:&lt;/p&gt;

&lt;p&gt;hbase(main):001:0&amp;gt; list&lt;br/&gt;
NativeException: org.apache.hadoop.hbase.client.RetriesExhaustedException: Trying to contact region server 10.249.190.85:60020 for region .META.,,1, row &apos;&apos;, but failed after 5 attempts.&lt;br/&gt;
Exceptions:&lt;br/&gt;
java.io.IOException: java.io.IOException: HStoreScanner failed construction&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.&amp;lt;init&amp;gt;(StoreFileScanner.java:70)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HStoreScanner.&amp;lt;init&amp;gt;(HStoreScanner.java:88)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HStore.getScanner(HStore.java:2125)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion$HScanner.&amp;lt;init&amp;gt;(HRegion.java:1989)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1180)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.openScanner(HRegionServer.java:1700)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:632)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:895)&lt;br/&gt;
Caused by: java.io.FileNotFoundException: File does not exist: hdfs://domU-12-31-39-03-BD-A7.compute-1.internal:50001/hbase/.META./1028785192/info/mapfiles/1397620458287085628/data&lt;br/&gt;
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:394)&lt;br/&gt;
	at org.apache.hadoop.fs.FileSystem.getLength(FileSystem.java:679)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.SequenceFile$Reader.&amp;lt;init&amp;gt;(SequenceFile.java:1431)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.SequenceFile$Reader.&amp;lt;init&amp;gt;(SequenceFile.java:1426)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.MapFile$Reader.createDataFileReader(MapFile.java:310)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.HBaseMapFile$HBaseReader.createDataFileReader(HBaseMapFile.java:96)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.MapFile$Reader.open(MapFile.java:292)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.HBaseMapFile$HBaseReader.&amp;lt;init&amp;gt;(HBaseMapFile.java:79)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.BloomFilterMapFile$Reader.&amp;lt;init&amp;gt;(BloomFilterMapFile.java:65)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HStoreFile.getReader(HStoreFile.java:443)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.openReaders(StoreFileScanner.java:96)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.&amp;lt;init&amp;gt;(StoreFileScanner.java:67)&lt;br/&gt;
	... 10 more&lt;/p&gt;

&lt;p&gt;java.io.IOException: java.io.IOException: HStoreScanner failed construction&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.&amp;lt;init&amp;gt;(StoreFileScanner.java:70)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HStoreScanner.&amp;lt;init&amp;gt;(HStoreScanner.java:88)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HStore.getScanner(HStore.java:2125)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion$HScanner.&amp;lt;init&amp;gt;(HRegion.java:1989)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1180)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.openScanner(HRegionServer.java:1700)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:632)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:895)&lt;br/&gt;
Caused by: java.io.FileNotFoundException: File does not exist: hdfs://domU-12-31-39-03-BD-A7.compute-1.internal:50001/hbase/.META./1028785192/info/mapfiles/1397620458287085628/data&lt;br/&gt;
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:394)&lt;br/&gt;
	at org.apache.hadoop.fs.FileSystem.getLength(FileSystem.java:679)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.SequenceFile$Reader.&amp;lt;init&amp;gt;(SequenceFile.java:1431)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.SequenceFile$Reader.&amp;lt;init&amp;gt;(SequenceFile.java:1426)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.MapFile$Reader.createDataFileReader(MapFile.java:310)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.HBaseMapFile$HBaseReader.createDataFileReader(HBaseMapFile.java:96)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.MapFile$Reader.open(MapFile.java:292)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.HBaseMapFile$HBaseReader.&amp;lt;init&amp;gt;(HBaseMapFile.java:79)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.BloomFilterMapFile$Reader.&amp;lt;init&amp;gt;(BloomFilterMapFile.java:65)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HStoreFile.getReader(HStoreFile.java:443)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.openReaders(StoreFileScanner.java:96)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.&amp;lt;init&amp;gt;(StoreFileScanner.java:67)&lt;br/&gt;
	... 10 more&lt;/p&gt;

&lt;p&gt;java.io.IOException: java.io.IOException: HStoreScanner failed construction&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.&amp;lt;init&amp;gt;(StoreFileScanner.java:70)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HStoreScanner.&amp;lt;init&amp;gt;(HStoreScanner.java:88)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HStore.getScanner(HStore.java:2125)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion$HScanner.&amp;lt;init&amp;gt;(HRegion.java:1989)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1180)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.openScanner(HRegionServer.java:1700)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:632)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:895)&lt;br/&gt;
Caused by: java.io.FileNotFoundException: File does not exist: hdfs://domU-12-31-39-03-BD-A7.compute-1.internal:50001/hbase/.META./1028785192/info/mapfiles/1397620458287085628/data&lt;br/&gt;
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:394)&lt;br/&gt;
	at org.apache.hadoop.fs.FileSystem.getLength(FileSystem.java:679)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.SequenceFile$Reader.&amp;lt;init&amp;gt;(SequenceFile.java:1431)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.SequenceFile$Reader.&amp;lt;init&amp;gt;(SequenceFile.java:1426)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.MapFile$Reader.createDataFileReader(MapFile.java:310)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.HBaseMapFile$HBaseReader.createDataFileReader(HBaseMapFile.java:96)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.MapFile$Reader.open(MapFile.java:292)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.HBaseMapFile$HBaseReader.&amp;lt;init&amp;gt;(HBaseMapFile.java:79)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.BloomFilterMapFile$Reader.&amp;lt;init&amp;gt;(BloomFilterMapFile.java:65)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HStoreFile.getReader(HStoreFile.java:443)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.openReaders(StoreFileScanner.java:96)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.&amp;lt;init&amp;gt;(StoreFileScanner.java:67)&lt;br/&gt;
	... 10 more&lt;/p&gt;

&lt;p&gt;java.io.IOException: java.io.IOException: HStoreScanner failed construction&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.&amp;lt;init&amp;gt;(StoreFileScanner.java:70)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HStoreScanner.&amp;lt;init&amp;gt;(HStoreScanner.java:88)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HStore.getScanner(HStore.java:2125)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion$HScanner.&amp;lt;init&amp;gt;(HRegion.java:1989)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1180)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.openScanner(HRegionServer.java:1700)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:632)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:895)&lt;br/&gt;
Caused by: java.io.FileNotFoundException: File does not exist: hdfs://domU-12-31-39-03-BD-A7.compute-1.internal:50001/hbase/.META./1028785192/info/mapfiles/1397620458287085628/data&lt;br/&gt;
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:394)&lt;br/&gt;
	at org.apache.hadoop.fs.FileSystem.getLength(FileSystem.java:679)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.SequenceFile$Reader.&amp;lt;init&amp;gt;(SequenceFile.java:1431)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.SequenceFile$Reader.&amp;lt;init&amp;gt;(SequenceFile.java:1426)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.MapFile$Reader.createDataFileReader(MapFile.java:310)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.HBaseMapFile$HBaseReader.createDataFileReader(HBaseMapFile.java:96)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.MapFile$Reader.open(MapFile.java:292)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.HBaseMapFile$HBaseReader.&amp;lt;init&amp;gt;(HBaseMapFile.java:79)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.BloomFilterMapFile$Reader.&amp;lt;init&amp;gt;(BloomFilterMapFile.java:65)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HStoreFile.getReader(HStoreFile.java:443)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.openReaders(StoreFileScanner.java:96)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.&amp;lt;init&amp;gt;(StoreFileScanner.java:67)&lt;br/&gt;
	... 10 more&lt;/p&gt;

&lt;p&gt;java.io.IOException: java.io.IOException: HStoreScanner failed construction&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.&amp;lt;init&amp;gt;(StoreFileScanner.java:70)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HStoreScanner.&amp;lt;init&amp;gt;(HStoreScanner.java:88)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HStore.getScanner(HStore.java:2125)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion$HScanner.&amp;lt;init&amp;gt;(HRegion.java:1989)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1180)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.openScanner(HRegionServer.java:1700)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:632)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:895)&lt;br/&gt;
Caused by: java.io.FileNotFoundException: File does not exist: hdfs://domU-12-31-39-03-BD-A7.compute-1.internal:50001/hbase/.META./1028785192/info/mapfiles/1397620458287085628/data&lt;br/&gt;
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:394)&lt;br/&gt;
	at org.apache.hadoop.fs.FileSystem.getLength(FileSystem.java:679)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.SequenceFile$Reader.&amp;lt;init&amp;gt;(SequenceFile.java:1431)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.SequenceFile$Reader.&amp;lt;init&amp;gt;(SequenceFile.java:1426)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.MapFile$Reader.createDataFileReader(MapFile.java:310)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.HBaseMapFile$HBaseReader.createDataFileReader(HBaseMapFile.java:96)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.MapFile$Reader.open(MapFile.java:292)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.HBaseMapFile$HBaseReader.&amp;lt;init&amp;gt;(HBaseMapFile.java:79)&lt;br/&gt;
	at org.apache.hadoop.hbase.io.BloomFilterMapFile$Reader.&amp;lt;init&amp;gt;(BloomFilterMapFile.java:65)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HStoreFile.getReader(HStoreFile.java:443)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.openReaders(StoreFileScanner.java:96)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.&amp;lt;init&amp;gt;(StoreFileScanner.java:67)&lt;br/&gt;
	... 10 more&lt;/p&gt;


&lt;p&gt;	from org/apache/hadoop/hbase/client/HConnectionManager.java:841:in `getRegionServerWithRetries&apos;&lt;br/&gt;
	from org/apache/hadoop/hbase/client/MetaScanner.java:56:in `metaScan&apos;&lt;br/&gt;
	from org/apache/hadoop/hbase/client/MetaScanner.java:30:in `metaScan&apos;&lt;br/&gt;
	from org/apache/hadoop/hbase/client/HConnectionManager.java:311:in `listTables&apos;&lt;br/&gt;
	from org/apache/hadoop/hbase/client/HBaseAdmin.java:122:in `listTables&apos;&lt;br/&gt;
	from sun/reflect/NativeMethodAccessorImpl.java:-2:in `invoke0&apos;&lt;br/&gt;
	from sun/reflect/NativeMethodAccessorImpl.java:39:in `invoke&apos;&lt;br/&gt;
	from sun/reflect/DelegatingMethodAccessorImpl.java:25:in `invoke&apos;&lt;br/&gt;
	from java/lang/reflect/Method.java:597:in `invoke&apos;&lt;br/&gt;
	from org/jruby/javasupport/JavaMethod.java:250:in `invokeWithExceptionHandling&apos;&lt;br/&gt;
	from org/jruby/javasupport/JavaMethod.java:219:in `invoke&apos;&lt;br/&gt;
	from org/jruby/javasupport/JavaClass.java:416:in `execute&apos;&lt;br/&gt;
	from org/jruby/internal/runtime/methods/SimpleCallbackMethod.java:67:in `call&apos;&lt;br/&gt;
	from org/jruby/internal/runtime/methods/DynamicMethod.java:70:in `call&apos;&lt;br/&gt;
	from org/jruby/runtime/CallSite.java:123:in `cacheAndCall&apos;&lt;br/&gt;
	from org/jruby/runtime/CallSite.java:298:in `call&apos;&lt;br/&gt;
... 130 levels...&lt;br/&gt;
	from ruby.usr.local.hbase_minus_0_dot_19_dot_0.bin.hirbInvokermethod__32$RUBY$startOpt:-1:in `call&apos;&lt;br/&gt;
	from org/jruby/internal/runtime/methods/DynamicMethod.java:74:in `call&apos;&lt;br/&gt;
	from org/jruby/internal/runtime/methods/CompiledMethod.java:48:in `call&apos;&lt;br/&gt;
	from org/jruby/runtime/CallSite.java:123:in `cacheAndCall&apos;&lt;br/&gt;
	from org/jruby/runtime/CallSite.java:298:in `call&apos;&lt;br/&gt;
	from ruby/usr/local/hbase_minus_0_dot_19_dot_0/bin//usr/local/hbase-0.19.0/bin/../bin/hirb.rb:429:in `_&lt;em&gt;file&lt;/em&gt;_&apos;&lt;br/&gt;
	from ruby/usr/local/hbase_minus_0_dot_19_dot_0/bin//usr/local/hbase-0.19.0/bin/../bin/hirb.rb:-1:in `_&lt;em&gt;file&lt;/em&gt;_&apos;&lt;br/&gt;
	from ruby/usr/local/hbase_minus_0_dot_19_dot_0/bin//usr/local/hbase-0.19.0/bin/../bin/hirb.rb:-1:in `load&apos;&lt;br/&gt;
	from org/jruby/Ruby.java:512:in `runScript&apos;&lt;br/&gt;
	from org/jruby/Ruby.java:432:in `runNormally&apos;&lt;br/&gt;
	from org/jruby/Ruby.java:312:in `runFromMain&apos;&lt;br/&gt;
	from org/jruby/Main.java:144:in `run&apos;&lt;br/&gt;
	from org/jruby/Main.java:89:in `run&apos;&lt;br/&gt;
	from org/jruby/Main.java:80:in `main&apos;&lt;br/&gt;
	from /usr/local/hbase-0.19.0/bin/../bin/hirb.rb:288:in `list&apos;&lt;/p&gt;</comment>
                            <comment id="12720543" author="stack" created="Wed, 17 Jun 2009 08:01:39 +0000"  >&lt;p&gt;You interested in this one Erik?&lt;/p&gt;</comment>
                            <comment id="12720724" author="erikholstad@gmail.com" created="Wed, 17 Jun 2009 15:43:36 +0000"  >&lt;p&gt;Yeah, I will deal with this. I have been working on it for the last couple of days, but have had some problems with versions and stuff, maybe you can give me a had later today or so?&lt;/p&gt;</comment>
                            <comment id="12848257" author="stack" created="Mon, 22 Mar 2010 18:10:49 +0000"  >&lt;p&gt;bin/rename_table.rb has been updated to match new api in 0.20 and trunk.&lt;/p&gt;</comment>
                            <comment id="13245620" author="kturner" created="Tue, 3 Apr 2012 19:14:41 +0000"  >&lt;p&gt;Accumulo supports this feature by using table ids.   Tables ids are generated using zookeeper and are never reused (base 36 numbers are used to keep them short and readable).  A mapping from table id to table name is stored in zookeeper.  To rename a table, lock the table and change the mapping in zookeeper.  &lt;/p&gt;

&lt;p&gt;Accumulo used to not use table ids, it stored the table name in meta and hdfs.  Now it uses the table id in hdfs and meta.  We were discussing renaming tables, and it seemed so complicated.  Then someone thought of this table id solution, it was such an elegant solution and made the problem trivial.&lt;/p&gt;

&lt;p&gt;Although table ids were implemented to support table renaming, they had the nice side effect of making hdfs and meta entries much shorter.&lt;/p&gt;</comment>
                            <comment id="13438938" author="sameerv" created="Tue, 21 Aug 2012 18:47:24 +0000"  >&lt;p&gt;@stack Seems this bug can be closed ?&lt;/p&gt;</comment>
                            <comment id="13438946" author="stack" created="Tue, 21 Aug 2012 19:00:01 +0000"  >&lt;p&gt;@Sameer I don&apos;t think so.  The rename script was recently removed because it had rotted; it had not been updated to match changed API.  We really need something like ids for tables, something like what Keith talks of in the above so a rename is a near-costless operations (as opposed to the rewrite of .META. and HDFS dir name that the rename script used do).&lt;/p&gt;</comment>
                            <comment id="13472387" author="akvadrako" created="Tue, 9 Oct 2012 14:00:14 +0000"  >&lt;p&gt;Hi. Is it safe to use the rename_table.rb script attached to this bug? Which versions does it work with?&lt;/p&gt;</comment>
                            <comment id="13472458" author="stack" created="Tue, 9 Oct 2012 15:21:04 +0000"  >&lt;p&gt;@Devin No.  What is attached here has rotted.  It would need work to update it.  Even then, the script was a band-aid.  What is needed is our keeping an id rather than the table name everywhere so a rename requires our changing the tablename once in a table to id map rather than in a few places in the filesystem as well as in the metadata kept by each table region.&lt;/p&gt;</comment>
                            <comment id="13583128" author="qwertymaniac" created="Thu, 21 Feb 2013 11:45:51 +0000"  >&lt;p&gt;Here&apos;s a link to &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shrijeet&quot; class=&quot;user-hover&quot; rel=&quot;shrijeet&quot;&gt;Shrijeet Paliwal&lt;/a&gt;&apos;s java code snippet that seems to work (may need extra disable/enable and a hbck -fix afterwards though): &lt;a href=&quot;https://gist.github.com/3913529&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://gist.github.com/3913529&lt;/a&gt;. This was posted on the user lists.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12633449">HBASE-7896</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12390940" name="copy_table.rb" size="5433" author="stack" created="Thu, 25 Sep 2008 18:27:03 +0000"/>
                            <attachment id="12390595" name="rename_table.rb" size="5787" author="stack" created="Sun, 21 Sep 2008 21:41:08 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 26 May 2008 10:24:14 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>31797</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 41 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i07hpz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>41638</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>