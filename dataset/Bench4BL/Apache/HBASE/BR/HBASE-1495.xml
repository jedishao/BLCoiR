<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 02 19:30:26 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-1495/HBASE-1495.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-1495] IllegalArgumentException in halfhfilereader#next</title>
                <link>https://issues.apache.org/jira/browse/HBASE-1495</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;From posix4e up on IRC&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
#
2009-06-07 20:22:33,367 ERROR org.apache.hadoop.hbase.regionserver.CompactSplitThread: Compaction failed &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; region t3,*******************,1244420117045
#
java.lang.IllegalArgumentException
#
        at java.nio.Buffer.position(Buffer.java:218)
#
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader$Scanner.next(HFile.java:1072)
#
        at org.apache.hadoop.hbase.io.HalfHFileReader$1.next(HalfHFileReader.java:108)
#
        at org.apache.hadoop.hbase.regionserver.StoreFileScanner.next(StoreFileScanner.java:52)
#
        at org.apache.hadoop.hbase.regionserver.KeyValueHeap.next(KeyValueHeap.java:79)
#
        at org.apache.hadoop.hbase.regionserver.MinorCompactingStoreScanner.next(MinorCompactingSto
#
reScanner.java:101)
#
        at org.apache.hadoop.hbase.regionserver.Store.compact(Store.java:849)
#
        at org.apache.hadoop.hbase.regionserver.Store.compact(Store.java:714)
#
        at org.apache.hadoop.hbase.regionserver.HRegion.compactStores(HRegion.java:766)
#
        at org.apache.hadoop.hbase.regionserver.HRegion.compactStores(HRegion.java:723)
#
        at org.apache.hadoop.hbase.regionserver.CompactSplitThread.run(CompactSplitThread.java:105)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12427373">HBASE-1495</key>
            <summary>IllegalArgumentException in halfhfilereader#next</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="stack">stack</assignee>
                                    <reporter username="stack">stack</reporter>
                        <labels>
                    </labels>
                <created>Mon, 8 Jun 2009 15:39:37 +0000</created>
                <updated>Sun, 13 Sep 2009 22:24:41 +0000</updated>
                            <resolved>Mon, 15 Jun 2009 06:00:13 +0000</resolved>
                                                    <fixVersion>0.20.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12717461" author="stack" created="Mon, 8 Jun 2009 22:14:52 +0000"  >&lt;p&gt;Here are some numbers from posix4e:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2009-06-08 15:46:59,325 WARN org.apache.hadoop.hbase.io.hfile.HFile: block.position(): 65648
2009-06-08 15:46:59,325 WARN org.apache.hadoop.hbase.io.hfile.HFile: currKeyLen: 37
2009-06-08 15:46:59,325 WARN org.apache.hadoop.hbase.io.hfile.HFile: currValueLen: 95
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here is code:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
      &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; next() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
        &lt;span class=&quot;code-comment&quot;&gt;// LOG.deug(&lt;span class=&quot;code-quote&quot;&gt;&quot;rem:&quot;&lt;/span&gt; + block.remaining() + &lt;span class=&quot;code-quote&quot;&gt;&quot; p:&quot;&lt;/span&gt; + block.position() +
&lt;/span&gt;        &lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-quote&quot;&gt;&quot; kl: &quot;&lt;/span&gt; + currKeyLen + &lt;span class=&quot;code-quote&quot;&gt;&quot; kv: &quot;&lt;/span&gt; + currValueLen);
&lt;/span&gt;        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (block == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
          &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; IOException(&lt;span class=&quot;code-quote&quot;&gt;&quot;Next called on non-seeked scanner&quot;&lt;/span&gt;);
        }
        block.position(block.position() + currKeyLen + currValueLen);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here is the Buffer position code:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Buffer position(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; newPosition) {
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; ((newPosition &amp;gt; limit) || (newPosition &amp;lt; 0))
        &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; IllegalArgumentException();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12717462" author="stack" created="Mon, 8 Jun 2009 22:17:24 +0000"  >&lt;p&gt;From posix4e:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
#
2009-06-08 17:45:48,706 WARN org.apache.hadoop.hbase.io.hfile.HFile: block.position():67551
#
2009-06-08 17:45:48,706 WARN org.apache.hadoop.hbase.io.hfile.HFile: block.capacity():67559
#
2009-06-08 17:45:48,706 WARN org.apache.hadoop.hbase.io.hfile.HFile: block.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;():java.nio.HeapByteBuffer[pos=67551 lim=67551 cap=67559]
#
2009-06-08 17:45:48,706 WARN org.apache.hadoop.hbase.io.hfile.HFile: block.array():[B@77932b46
#
2009-06-08 17:45:48,706 WARN org.apache.hadoop.hbase.io.hfile.HFile: block.array().length:67559
#
2009-06-08 17:45:48,706 WARN org.apache.hadoop.hbase.io.hfile.HFile: currKeyLen:37
#
2009-06-08 17:45:48,706 WARN org.apache.hadoop.hbase.io.hfile.HFile: currValueLen:3557
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12717469" author="posix4e" created="Mon, 8 Jun 2009 22:27:14 +0000"  >&lt;p&gt;2009-06-08 18:04:36,722 WARN org.apache.hadoop.hbase.io.hfile.HFile: &lt;br/&gt;
2009-06-08 18:04:36,722 WARN org.apache.hadoop.hbase.io.hfile.HFile: block.position():66795&lt;br/&gt;
2009-06-08 18:04:36,722 WARN org.apache.hadoop.hbase.io.hfile.HFile: block.capacity():66803&lt;br/&gt;
2009-06-08 18:04:36,722 WARN org.apache.hadoop.hbase.io.hfile.HFile: block.String():java.nio.HeapByteBuffer&lt;span class=&quot;error&quot;&gt;&amp;#91;pos=66795 lim=66795 cap=66803&amp;#93;&lt;/span&gt;&lt;br/&gt;
2009-06-08 18:04:36,722 WARN org.apache.hadoop.hbase.io.hfile.HFile: block.array():[B@5c74b704&lt;br/&gt;
2009-06-08 18:04:36,722 WARN org.apache.hadoop.hbase.io.hfile.HFile: block.array().length:66803&lt;br/&gt;
2009-06-08 18:04:36,722 WARN org.apache.hadoop.hbase.io.hfile.HFile: currKeyLen:37&lt;br/&gt;
2009-06-08 18:04:36,722 WARN org.apache.hadoop.hbase.io.hfile.HFile: currValueLen:23965&lt;br/&gt;
2009-06-08 18:04:36,722 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor&lt;br/&gt;
2009-06-08 18:04:36,724 INFO org.apache.hadoop.hdfs.DFSClient: Could not obtain block blk_626364962828652414_6670983 from any node:  java.io.IOException: No live nodes contain current block&lt;br/&gt;
2009-06-08 18:04:39,728 INFO org.apache.hadoop.hdfs.DFSClient: Could not obtain block blk_626364962828652414_6670983 from any node:  java.io.IOException: No live nodes contain current block&lt;br/&gt;
2009-06-08 18:04:42,731 WARN org.apache.hadoop.hdfs.DFSClient: DFS Read: java.io.IOException: Cannot open filename /hbase/t3/1992779812/block/3201548317092254781&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.openInfo(DFSClient.java:1444)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.chooseDataNode(DFSClient.java:1769)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.blockSeekTo(DFSClient.java:1585)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:1712)&lt;br/&gt;
        at java.io.DataInputStream.read(DataInputStream.java:132)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.BoundedRangeFileInputStream.read(BoundedRangeFileInputStream.java:99)&lt;br/&gt;
        at org.apache.hadoop.io.compress.DecompressorStream.getCompressedData(DecompressorStream.java:96)&lt;br/&gt;
        at org.apache.hadoop.io.compress.DecompressorStream.decompress(DecompressorStream.java:86)&lt;br/&gt;
        at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:74)&lt;br/&gt;
        at java.io.BufferedInputStream.read1(BufferedInputStream.java:256)&lt;br/&gt;
        at java.io.BufferedInputStream.read(BufferedInputStream.java:317)&lt;br/&gt;
        at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:100)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.decompress(HFile.java:950)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.readBlock(HFile.java:906)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader$Scanner.next(HFile.java:1093)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.HalfHFileReader$1.next(HalfHFileReader.java:108)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.StoreFileScanner.next(StoreFileScanner.java:52)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.KeyValueHeap.next(KeyValueHeap.java:79)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.MinorCompactingStoreScanner.next(MinorCompactingStoreScanner.java:101)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.Store.compact(Store.java:852)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.Store.compact(Store.java:717)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.compactStores(HRegion.java:766)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.compactStores(HRegion.java:723)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.CompactSplitThread.run(CompactSplitThread.java:105)&lt;/p&gt;</comment>
                            <comment id="12717493" author="posix4e" created="Tue, 9 Jun 2009 00:10:35 +0000"  >&lt;p&gt;computation.&lt;br/&gt;
Regions On FS   20      Number of regions on FileSystem. Rough count.&lt;br/&gt;
:       servers: 7              requests=0, regions=13&lt;/p&gt;


&lt;p&gt;node 5&lt;br/&gt;
2009-06-07 20:14:59,702 INFO org.apache.hadoop.hdfs.DFSClient: Could not obtain block blk_8054294304707090727_6626586 from any node:  java.io.IOException: No live nodes contain current block&lt;br/&gt;
2009-06-07 20:15:23,007 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Scanner -8896201081780238142 lease expired&lt;br/&gt;
2009-06-07 20:15:27,879 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Scanner 1596079652788274335 lease expired&lt;br/&gt;
2009-06-07 20:15:40,059 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Scanner -2733198405792644962 lease expired&lt;br/&gt;
2009-06-07 20:16:10,248 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Scanner -7860104214020620019 lease expired&lt;br/&gt;
2009-06-07 20:16:25,149 INFO org.apache.hadoop.hdfs.DFSClient: Could not obtain block blk_8054294304707090727_6626586 from any node:  java.io.IOException: No live nodes contain current block&lt;br/&gt;
2009-06-07 20:16:40,440 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Scanner 6217323943013460033 lease expired&lt;br/&gt;
2009-06-07 20:17:10,680 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Scanner -6711331116393695890 lease expired&lt;br/&gt;
2009-06-07 20:17:40,835 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Scanner 3871771505311058479 lease expired&lt;br/&gt;
2009-06-07 20:18:10,069 INFO org.apache.hadoop.hdfs.DFSClient: Could not obtain block blk_8054294304707090727_6626586 from any node:  java.io.IOException: No live nodes contain current block&lt;br/&gt;
2009-06-07 20:18:11,037 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Scanner -8973011642755732600 lease expired&lt;br/&gt;
2009-06-07 20:18:41,201 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Scanner 3807906792818606834 lease expired&lt;br/&gt;
2009-06-07 20:19:13,095 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Scanner 579239649970047854 lease expired&lt;br/&gt;
2009-06-07 20:19:14,773 WARN org.apache.hadoop.hdfs.DFSClient: DFS Read: java.io.IOException: Could not obtain block: blk_8054294304707090727_6626586 file=/hbase/.META./1028785192/info/8853829816968996247&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.chooseDataNode(DFSClient.java:1757)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.blockSeekTo(DFSClient.java:1585)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:1712)&lt;br/&gt;
        at java.io.DataInputStream.read(DataInputStream.java:132)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.BoundedRangeFileInputStream.read(BoundedRangeFileInputStream.java:99)&lt;br/&gt;
        at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:100)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.decompress(HFile.java:950)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.readBlock(HFile.java:906)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader$Scanner.loadBlock(HFile.java:1222)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader$Scanner.seekTo(HFile.java:1105)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.StoreFileGetScan.getStoreFile(StoreFileGetScan.java:80)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.StoreFileGetScan.get(StoreFileGetScan.java:65)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.Store.get(Store.java:1480)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1037)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1706)&lt;br/&gt;
        at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)&lt;br/&gt;
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
        at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:643)&lt;br/&gt;
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:913)&lt;br/&gt;
....&lt;br/&gt;
node 1&lt;br/&gt;
2009-06-07 20:22:33,342 WARN org.apache.hadoop.hdfs.DFSClient: DFS Read: java.io.IOException: Canno&lt;br/&gt;
t open filename /hbase/t3/601977017/block/4848245505122296259&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.openInfo(DFSClient.java:1444)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.chooseDataNode(DFSClient.java:1769)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.blockSeekTo(DFSClient.java:1585)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:1712)&lt;br/&gt;
        at java.io.DataInputStream.read(DataInputStream.java:132)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.BoundedRangeFileInputStream.read(BoundedRangeFileInputStream.java:99)&lt;br/&gt;
        at org.apache.hadoop.io.compress.DecompressorStream.getCompressedData(DecompressorStream.java:96)&lt;br/&gt;
        at org.apache.hadoop.io.compress.DecompressorStream.decompress(DecompressorStream.java:86)&lt;br/&gt;
        at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:74)&lt;br/&gt;
        at java.io.BufferedInputStream.read1(BufferedInputStream.java:256)&lt;br/&gt;
        at java.io.BufferedInputStream.read(BufferedInputStream.java:317)&lt;br/&gt;
        at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:100)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.decompress(HFile.java:950)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.readBlock(HFile.java:906)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader$Scanner.next(HFile.java:1082)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.HalfHFileReader$1.next(HalfHFileReader.java:108)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.StoreFileScanner.next(StoreFileScanner.java:52)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.KeyValueHeap.next(KeyValueHeap.java:79)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.MinorCompactingStoreScanner.next(MinorCompactingStoreScanner.java:101)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.Store.compact(Store.java:849)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.Store.compact(Store.java:714)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.compactStores(HRegion.java:766)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.compactStores(HRegion.java:723)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.CompactSplitThread.run(CompactSplitThread.java:105)&lt;/p&gt;

&lt;p&gt;2009-06-07 20:22:33,367 ERROR org.apache.hadoop.hbase.regionserver.CompactSplitThread: Compaction failed for region t3,*******************,1244420117045&lt;br/&gt;
java.lang.IllegalArgumentException&lt;br/&gt;
        at java.nio.Buffer.position(Buffer.java:218)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader$Scanner.next(HFile.java:1072)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.HalfHFileReader$1.next(HalfHFileReader.java:108)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.StoreFileScanner.next(StoreFileScanner.java:52)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.KeyValueHeap.next(KeyValueHeap.java:79)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.MinorCompactingStoreScanner.next(MinorCompactingSto&lt;br/&gt;
reScanner.java:101)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.Store.compact(Store.java:849)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.Store.compact(Store.java:714)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.compactStores(HRegion.java:766)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.compactStores(HRegion.java:723)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.CompactSplitThread.run(CompactSplitThread.java:105)&lt;br/&gt;
2009-06-07 20:22:33,368 INFO org.apache.hadoop.hbase.regionserver.HRegion: Starting compaction on region t3,,1244420449037&lt;br/&gt;
2009-06-07 20:22:33,368 INFO org.apache.hadoop.hbase.regionserver.HRegion: Starting compaction on region t3,,1244420449037&lt;br/&gt;
2009-06-07 20:22:33,373 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor&lt;br/&gt;
2009-06-07 20:25:01,766 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: compactions no longer limited&lt;br/&gt;
2009-06-07 20:27:47,938 INFO org.apache.hadoop.hbase.regionserver.HRegion: compaction completed on region t3,,1244420449037 in 5mins, 14sec&lt;br/&gt;
2009-06-07 20:27:47,938 INFO org.apache.hadoop.hbase.regionserver.HRegion: Starting split of region  t3,,1244420449037&lt;br/&gt;
2009-06-07 20:27:47,942 INFO org.apache.hadoop.hbase.regionserver.HRegion: Closed t3,,1244420449037&lt;br/&gt;
2009-06-07 20:27:48,319 INFO org.apache.hadoop.hbase.regionserver.HRegion: region t3,,1244420867941/2082155757 available; sequence id is 9633520&lt;/p&gt;

&lt;p&gt;2009-06-07 20:27:48,319 INFO org.apache.hadoop.hbase.regionserver.HRegion: Closed t3,,1244420867941&lt;br/&gt;
2009-06-07 20:27:48,465 INFO org.apache.hadoop.hbase.regionserver.HRegion: region t3,******************,1244420867941/1057048264 available; sequence id is 9633521&lt;br/&gt;
2009-06-07 20:27:48,465 INFO org.apache.hadoop.hbase.regionserver.HRegion: Closed t3,U*****************,1244420867941&lt;br/&gt;
2009-06-07 20:27:48,470 INFO org.apache.hadoop.hbase.regionserver.CompactSplitThread: region split, META updated, and report to master all successful. Old region=REGION =&amp;gt; {NAME =&amp;gt; &apos;t3,,1244420449037&apos;, STARTKEY =&amp;gt; &apos;&apos;, ENDKEY =&amp;gt; &apos;*****************&apos;, ENCODED =&amp;gt; 2120511499, OFFLINE =&amp;gt; true, SPLIT =&amp;gt; true, TABLE =&amp;gt; {{NAME =&amp;gt; &apos;t3&apos;, FAMILIES =&amp;gt; [&lt;/p&gt;
{NAME =&amp;gt; &apos;*****************&apos;, COMPRESSION =&amp;gt; &apos;GZ&apos;, VERSIONS =&amp;gt; &apos;3&apos;, TTL =&amp;gt; &apos;2147483647&apos;, BLOCKSIZE =&amp;gt; &apos;65536&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;, BLOCKCACHE =&amp;gt; &apos;true&apos;}
&lt;p&gt;]}}, new regions: t3,,1244420867941, t3,*****************,1244420867941. Split took 0sec&lt;br/&gt;
2009-06-07 20:27:48,470 INFO org.apache.hadoop.hbase.regionserver.HRegion: Starting compaction on region t3,*****************,1244420449037&lt;br/&gt;
2009-06-07 20:27:58,106 INFO org.apache.hadoop.hdfs.DFSClient: Could not obtain block blk_7797131986764001105_6627592 from any node:  java.io.IOException: No live nodes contain current block&lt;br/&gt;
2009-06-07 20:28:01,111 INFO org.apache.hadoop.hdfs.DFSClient: Could not obtain block blk_7797131986764001105_6627592 from any node:  java.io.IOException: No live nodes contain current block&lt;br/&gt;
2009-06-07 20:28:04,113 WARN org.apache.hadoop.hdfs.DFSClient: DFS Read: java.io.IOException: Cannot open filename /hbase/t3/82566562/block/7165913658187924750&lt;br/&gt;
  at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.openInfo(DFSClient.java:1444)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.chooseDataNode(DFSClient.java:1769)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.blockSeekTo(DFSClient.java:1585)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:1712)&lt;br/&gt;
        at java.io.DataInputStream.read(DataInputStream.java:132)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.BoundedRangeFileInputStream.read(BoundedRangeFileInputStream.java:99)&lt;br/&gt;
        at org.apache.hadoop.io.compress.DecompressorStream.getCompressedData(DecompressorStream.java:96)&lt;br/&gt;
        at org.apache.hadoop.io.compress.DecompressorStream.decompress(DecompressorStream.java:86)&lt;br/&gt;
        at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:74)&lt;br/&gt;
        at java.io.BufferedInputStream.read1(BufferedInputStream.java:256)&lt;br/&gt;
        at java.io.BufferedInputStream.read(BufferedInputStream.java:317)&lt;br/&gt;
        at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:100)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.decompress(HFile.java:950)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.readBlock(HFile.java:906)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader$Scanner.next(HFile.java:1082)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.HalfHFileReader$1.next(HalfHFileReader.java:108)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.StoreFileScanner.next(StoreFileScanner.java:52)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.KeyValueHeap.next(KeyValueHeap.java:79)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.MinorCompactingStoreScanner.next(MinorCompactingStoreScanner.java:101)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.Store.compact(Store.java:849)&lt;br/&gt;
   at org.apache.hadoop.hbase.regionserver.Store.compact(Store.java:714)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.compactStores(HRegion.java:766)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.compactStores(HRegion.java:723)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.CompactSplitThread.run(CompactSplitThread.java:105)&lt;/p&gt;

&lt;p&gt;2009-06-07 20:28:04,124 ERROR org.apache.hadoop.hbase.regionserver.CompactSplitThread: Compaction failed for region t3,*****************,1244420449037&lt;br/&gt;
java.lang.IllegalArgumentException&lt;br/&gt;
        at java.nio.Buffer.position(Buffer.java:218)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader$Scanner.next(HFile.java:1072)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.HalfHFileReader$1.next(HalfHFileReader.java:108)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.StoreFileScanner.next(StoreFileScanner.java:52)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.KeyValueHeap.next(KeyValueHeap.java:79)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.MinorCompactingStoreScanner.next(MinorCompactingStoreScanner.java:101)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.Store.compact(Store.java:849)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.Store.compact(Store.java:714)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.compactStores(HRegion.java:766)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.compactStores(HRegion.java:723)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.CompactSplitThread.run(CompactSplitThread.java:105)&lt;br/&gt;
2009-06-07 20:07:36,330 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=****&lt;b&gt;,&lt;/b&gt;****       ip=/**&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;*.110       cmd=mkdirs      src=/hbase/.META./1028785192/historian  dst=null        perm=ts:ticker:rwxr-xr-x&lt;br/&gt;
2009-06-07 20:07:36,335 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=****&lt;b&gt;,&lt;/b&gt;****       ip=/**&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;*.110       cmd=create      src=/hbase/.META./1028785192/historian/3542463731429695625      dst=null        perm=ts:ticker:&lt;br/&gt;
rw-r-&lt;del&gt;r&lt;/del&gt;-&lt;br/&gt;
2009-06-07 20:07:36,340 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /hbase/.META./1028785192/historian/3542463731429695625. blk_-4350004983998257175_6626584&lt;br/&gt;
2009-06-07 20:07:36,348 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: **&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;*.111:50010 is added to blk_7773188474590228904_6626583 size 778360&lt;br/&gt;
2009-06-07 20:07:36,348 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: **&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;*.107:50010 is added to blk_7773188474590228904_6626583 size 778360&lt;br/&gt;
2009-06-07 20:07:36,349 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: **&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;*.112:50010 is added to blk_7773188474590228904_6626583 size 778360&lt;br/&gt;
2009-06-07 20:07:36,354 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=****&lt;b&gt;,&lt;/b&gt;****       ip=/**&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.112       cmd=create      src=/hbase/.logs/&lt;/b&gt;************,60020,1244418229161/hlog.dat.1244419656351 dst=null&lt;br/&gt;
        perm=ts:ticker:rw-r-&lt;del&gt;r&lt;/del&gt;-&lt;br/&gt;
2009-06-07 20:07:36,365 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: **&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;*.111:50010 is added to blk_-4350004983998257175_6626584 size 3190&lt;br/&gt;
2009-06-07 20:07:36,365 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: **&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;*.107:50010 is added to blk_-4350004983998257175_6626584 size 3190&lt;br/&gt;
2009-06-07 20:07:36,365 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: **&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;*.110:50010 is added to blk_-4350004983998257175_6626584 size 3190&lt;br/&gt;
2009-06-07 20:07:36,373 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=****&lt;b&gt;,&lt;/b&gt;****       ip=/**&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;*.110       cmd=open        src=/hbase/.META./1028785192/historian/3542463731429695625      dst=null        perm=null&lt;br/&gt;
2009-06-07 20:07:36,379 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=****&lt;b&gt;,&lt;/b&gt;****       ip=/**&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;*.110       cmd=mkdirs      src=/hbase/.META./1028785192/info       dst=null        perm=ts:ticker:rwxr-xr-x&lt;br/&gt;
2009-06-07 20:07:36,382 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=****&lt;b&gt;,&lt;/b&gt;****       ip=/**&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;*.110       cmd=create      src=/hbase/.META./1028785192/info/8853829816968996247   dst=null        perm=ts:ticker:rw-r-&lt;del&gt;r&lt;/del&gt;&lt;br/&gt;
-&lt;br/&gt;
2009-06-07 20:07:36,384 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /hbase/.META./1028785192/info/8853829816968996247. blk_8054294304707090727_6626586&lt;br/&gt;
2009-06-07 20:07:36,387 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: **&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;*.107:50010 is added to blk_8054294304707090727_6626586 size 7296&lt;br/&gt;
2009-06-07 20:07:36,387 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: **&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;*.111:50010 is added to blk_8054294304707090727_6626586 size 7296&lt;br/&gt;
2009-06-07 20:07:36,388 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: **&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;*.110:50010 is added to blk_8054294304707090727_6626586 size 7296&lt;br/&gt;
2009-06-07 20:07:36,392 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=****&lt;b&gt;,&lt;/b&gt;****       ip=/**&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;*.110       cmd=open        src=/hbase/.META./1028785192/info/8853829816968996247   dst=null        perm=null&lt;br/&gt;
2009-06-07 20:07:36,409 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /hbase/.logs/**************,60020,1244418229161/hlog.dat.1244419656351. blk_-249701538603762950_6626586&lt;br/&gt;
2009-06-07 20:07:37,238 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: **&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;*.110:50010 is added to blk_-249701538603762950_6626586 size 783411&lt;br/&gt;
2009-06-07 20:07:37,239 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: **&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;*.107:50010 is added to blk_-249701538603762950_6626586 size 783411&lt;br/&gt;
2009-06-07 20:07:37,239 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: **&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;*.112:50010 is added to blk_-249701538603762950_6626586 size 783411&lt;br/&gt;
2009-06-07 20:07:37,244 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=****&lt;b&gt;,&lt;/b&gt;****       ip=/**&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.112       cmd=create      src=/hbase/.logs/&lt;/b&gt;***********,60020,1244418229161/hlog.dat.1244419657242 dst=null&lt;br/&gt;
        perm=ts:ticker:rw-r-&lt;del&gt;r&lt;/del&gt;-&lt;br/&gt;
2009-06-07 20:07:37,354 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /hbase/.logs/************,60020,1244418229161/hlog.dat.1244419657242. blk_-4367384643419626092_6626587&lt;br/&gt;
2009-06-07 20:07:37,830 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: **&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;*.29:50010 is added to blk_4530508892235409778_6626487 size 778943&lt;br/&gt;
2009-06-07 20:07:37,830 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: **&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;*.112:50010 is added to blk_4530508892235409778_6626487 size 778943&lt;br/&gt;
2009-06-07 20:07:37,831 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: **&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;*.109:50010 is added to blk_4530508892235409778_6626487 size 778943&lt;br/&gt;
2009-06-07 20:07:37,834 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=****&lt;b&gt;,&lt;/b&gt;****       ip=/**&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.109       cmd=create      src=/hbase/.logs/&lt;/b&gt;***********,60020,1244418229042/hlog.dat.1244419657833 dst=null&lt;br/&gt;
        perm=ts:ticker:rw-r-&lt;del&gt;r&lt;/del&gt;-&lt;br/&gt;
 less /home/fds/ts/logs/&lt;b&gt;datanode&lt;/b&gt;.log.2009-06-07&lt;br/&gt;
node 6&lt;br/&gt;
2009-06-07 20:07:36,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_8054294304707090727_6626586 src: /**&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.110:57200 dest: /&lt;/b&gt;*&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;*.111:50010&lt;br/&gt;
2009-06-07 20:07:36,387 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /**&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.110:57200, dest: /&lt;/b&gt;*&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.111:50010, bytes: 7296, op: HDFS_WRITE, cliID: DFSClient_&lt;del&gt;930264054, srvID: DS-118466857&lt;/del&gt;&lt;/b&gt;*&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;*.111-50&lt;br/&gt;
010-1234138704820, blockid: blk_8054294304707090727_6626586&lt;br/&gt;
2009-06-07 20:07:36,387 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 1 for block blk_8054294304707090727_6626586 terminating&lt;br/&gt;
....&lt;/p&gt;


&lt;p&gt;2009-06-07 20:14:28,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /**&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.111:50010, dest: /&lt;/b&gt;*&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.110:54059, bytes: 7356, op: HDFS_READ, cliID: DFSClient_&lt;del&gt;930264054, srvID: DS-118466857&lt;/del&gt;&lt;/b&gt;*&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;*.111-500&lt;br/&gt;
10-1234138704820, blockid: blk_8054294304707090727_6626586&lt;br/&gt;
repeated thousands of times&lt;br/&gt;
....&lt;br/&gt;
2009-06-07 21:02:02,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleting block blk_8054294304707090727_6626586 file /data/2/hadoop/current/subdir42/blk_8054294304707090727&lt;/p&gt;

&lt;p&gt;node 5&lt;br/&gt;
2009-06-07 20:07:36,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_8054294304707090727_6626586 src: /**&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.110:50289 dest: /&lt;/b&gt;*&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;*.110:50010&lt;br/&gt;
2009-06-07 20:07:36,388 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /**&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.110:50289, dest: /&lt;/b&gt;*&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.110:50010, bytes: 7296, op: HDFS_WRITE, cliID: DFSClient_&lt;del&gt;930264054, srvID: DS-793422389&lt;/del&gt;&lt;/b&gt;*&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;*.110-50&lt;br/&gt;
010-1234138704958, blockid: blk_8054294304707090727_6626586&lt;br/&gt;
2009-06-07 20:07:36,388 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 2 for block blk_8054294304707090727_6626586 terminating&lt;/p&gt;

&lt;p&gt;2009-06-07 20:07:36,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /**&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.110:50010, dest: /&lt;/b&gt;*&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.110:50291, bytes: 132, op: HDFS_READ, cliID: DFSClient_&lt;del&gt;930264054, srvID: DS-793422389&lt;/del&gt;&lt;/b&gt;*&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;*.110-5001&lt;br/&gt;
0-1234138704958, blockid: blk_8054294304707090727_6626586&lt;br/&gt;
node 2&lt;br/&gt;
2009-06-07 20:07:36,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_8054294304707090727_6626586 src: /**&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.111:35284 dest: /&lt;/b&gt;*&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;*.107:50010&lt;br/&gt;
2009-06-07 20:07:36,386 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /**&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.111:35284, dest: /&lt;/b&gt;*&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.107:50010, bytes: 7296, op: HDFS_WRITE, cliID: DFSClient_&lt;del&gt;930264054, srvID: DS-274843024&lt;/del&gt;&lt;/b&gt;*&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;*.107-50&lt;br/&gt;
010-1234138705859, blockid: blk_8054294304707090727_6626586&lt;br/&gt;
2009-06-07 20:07:36,386 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for block blk_8054294304707090727_6626586 terminating&lt;br/&gt;
....&lt;br/&gt;
2009-06-07 20:14:03,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /**&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.107:50010, dest: /&lt;/b&gt;*&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.110:55798, bytes: 7356, op: HDFS_READ, cliID: DFSClient_&lt;del&gt;930264054, srvID: DS-274843024&lt;/del&gt;&lt;/b&gt;*&lt;b&gt;.&lt;/b&gt;&lt;b&gt;.&lt;/b&gt;*.107-500&lt;br/&gt;
10-1234138705859, blockid: blk_8054294304707090727_6626586&lt;br/&gt;
repeated thousands of times&lt;br/&gt;
2009-06-07 21:02:07,245 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleting block blk_8054294304707090727_6626586 file /data/1/hadoop/current/blk_8054294304707090727&lt;/p&gt;</comment>
                            <comment id="12717494" author="posix4e" created="Tue, 9 Jun 2009 00:12:39 +0000"  >&lt;p&gt;try &lt;/p&gt;
{
            block.position(block.position() + currKeyLen + currValueLen);
        }
&lt;p&gt; catch (IllegalArgumentException e)&lt;/p&gt;
{
            LOG.warn(e.getMessage());
            LOG.warn(&quot;block.position():&quot;+block.position());
            LOG.warn(&quot;block.capacity():&quot;+block.capacity());
            LOG.warn(&quot;block.String():&quot;+block.toString());
            LOG.warn(&quot;block.array():&quot;+block.array());
            LOG.warn(&quot;block.array().length:&quot;+block.array().length);
            LOG.warn(&quot;currKeyLen:&quot;+currKeyLen);
            LOG.warn(&quot;currValueLen:&quot;+currValueLen);
        }
&lt;p&gt;        if (block.remaining() &amp;lt;= 0) {&lt;/p&gt;

&lt;p&gt;results in &lt;/p&gt;

&lt;p&gt;2009-06-08 17:45:48,706 WARN org.apache.hadoop.hbase.io.hfile.HFile: block.position():67551&lt;br/&gt;
2009-06-08 17:45:48,706 WARN org.apache.hadoop.hbase.io.hfile.HFile: block.capacity():67559&lt;br/&gt;
2009-06-08 17:45:48,706 WARN org.apache.hadoop.hbase.io.hfile.HFile: block.String():java.nio.HeapByteBuffer&lt;span class=&quot;error&quot;&gt;&amp;#91;pos=67551 lim=67551 cap=67559&amp;#93;&lt;/span&gt;&lt;br/&gt;
2009-06-08 17:45:48,706 WARN org.apache.hadoop.hbase.io.hfile.HFile: block.array():[B@77932b46&lt;br/&gt;
2009-06-08 17:45:48,706 WARN org.apache.hadoop.hbase.io.hfile.HFile: block.array().length:67559&lt;br/&gt;
2009-06-08 17:45:48,706 WARN org.apache.hadoop.hbase.io.hfile.HFile: currKeyLen:37&lt;br/&gt;
2009-06-08 17:45:48,706 WARN org.apache.hadoop.hbase.io.hfile.HFile: currValueLen:3557&lt;br/&gt;
2009-06-08 17:45:48,706 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor&lt;br/&gt;
2009-06-08 17:45:48,709 INFO org.apache.hadoop.hdfs.DFSClient: Could not obtain block blk_-8600012014215763562_6667788 from any node:  java.io.IOException: No live nodes contain current block&lt;br/&gt;
2009-06-08 17:45:51,714 INFO org.apache.hadoop.hdfs.DFSClient: Could not obtain block blk_-8600012014215763562_6667788 from any node:  java.io.IOException: No live nodes contain current block&lt;br/&gt;
2009-06-08 17:45:54,716 WARN org.apache.hadoop.hdfs.DFSClient: DFS Read: java.io.IOException: Cannot open filename /hbase/t3/299987382/block/2277509959628818760&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.openInfo(DFSClient.java:1444)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.chooseDataNode(DFSClient.java:1769)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.blockSeekTo(DFSClient.java:1585)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:1712)&lt;br/&gt;
        at java.io.DataInputStream.read(DataInputStream.java:132)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.BoundedRangeFileInputStream.read(BoundedRangeFileInputStream.java:99)&lt;br/&gt;
        at org.apache.hadoop.io.compress.DecompressorStream.getCompressedData(DecompressorStream.java:96)&lt;br/&gt;
        at org.apache.hadoop.io.compress.DecompressorStream.decompress(DecompressorStream.java:86)&lt;br/&gt;
        at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:74)&lt;br/&gt;
        at java.io.BufferedInputStream.read1(BufferedInputStream.java:256)&lt;br/&gt;
        at java.io.BufferedInputStream.read(BufferedInputStream.java:317)&lt;br/&gt;
        at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:100)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.decompress(HFile.java:950)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.readBlock(HFile.java:906)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader$Scanner.next(HFile.java:1093)&lt;br/&gt;
        at org.apache.hadoop.hbase.io.HalfHFileReader$1.next(HalfHFileReader.java:108)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.StoreFileScanner.next(StoreFileScanner.java:52)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.KeyValueHeap.next(KeyValueHeap.java:79)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.MinorCompactingStoreScanner.next(MinorCompactingStoreScanner.java:101)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.Store.compact(Store.java:852)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.Store.compact(Store.java:717)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.compactStores(HRegion.java:766)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.compactStores(HRegion.java:723)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.CompactSplitThread.run(CompactSplitThread.java:105)&lt;/p&gt;</comment>
                            <comment id="12717747" author="stack" created="Tue, 9 Jun 2009 16:58:56 +0000"  >&lt;p&gt;I see this in my testing now.  Looks like issue around split; parent is being cleaned up &amp;#8211; deleted &amp;#8211; though daughters are still out on cluster being served.&lt;/p&gt;</comment>
                            <comment id="12719082" author="stack" created="Sat, 13 Jun 2009 05:15:23 +0000"  >&lt;p&gt;Attachment fixes two issues: 1. splitting, we were updating .META. using one side of split for both splitA and splitB, and 2., on processing of split removals, we were getting NPE.&lt;/p&gt;

&lt;p&gt;Still to do are the following phenomeon:&lt;/p&gt;

&lt;p&gt;1. On remove of a info:splitA or info:splitB from a parent regions&apos; row, on the next meta scan, splitA and splitB are missing even though only one side has been removed.  Because we think both removed, we&apos;ll remove the parent injuring the daughter split still being served.&lt;/p&gt;

&lt;p&gt;2. I&apos;m seeing store files that have keys in excess of the start and end row of hosting region.&lt;/p&gt;

&lt;p&gt;Still working on 1 and 2.&lt;/p&gt;</comment>
                            <comment id="12719084" author="stack" created="Sat, 13 Jun 2009 05:20:25 +0000"  >&lt;p&gt;Here is example from logs of item 1. that would seem to indicate the issue is in Scanners.  I&apos;ve instrumented meta scanner so that on each next, I print out what was found.  Immediately, I do a get on the row and I print that too.  Usually the two match.  When they don&apos;t is when I have issue:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  794 2009-06-12 22:41:18,377 [RegionManager.metaScanner] INFO org.apache.hadoop.hbase.master.BaseScanner: REMOVE NEXT VALUES keyvalues={TestTable,,1244846310969/info:regioninfo/1244846397895/Put/vlen=277, TestTable,,1244846310969/info:server/1244846319501/Put/vle      n=19, TestTable,,1244846310969/info:serverstartcode/1244846319501/Put/vlen=8, TestTable,,1244846310969/info:splitA/1244846397895/Put/vlen=277, TestTable,,1244846310969/info:splitB/1244846397895/Put/vlen=297}
  795 2009-06-12 22:41:18,379 [RegionManager.metaScanner] INFO org.apache.hadoop.hbase.master.BaseScanner: REMOVE GET keyvalues={TestTable,,1244846310969/historian:assignment/1244846315138/Put/vlen=71, TestTable,,1244846310969/historian:compaction/1244846393353/Pu      t/vlen=36, TestTable,,1244846310969/historian:open/1244846319510/Put/vlen=51, TestTable,,1244846310969/historian:split/1244846312701/Put/vlen=43, TestTable,,1244846310969/info:regioninfo/1244846397895/Put/vlen=277, TestTable,,1244846310969/info:server/124484      6319501/Put/vlen=19, TestTable,,1244846310969/info:serverstartcode/1244846319501/Put/vlen=8, TestTable,,1244846310969/info:splitA/1244846397895/Put/vlen=277, TestTable,,1244846310969/info:splitB/1244846397895/Put/vlen=297}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;When above scan finishes, is when we remove splitA.  On next meta scan, I see this:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  840 2009-06-12 22:41:28,390 [RegionManager.metaScanner] INFO org.apache.hadoop.hbase.master.BaseScanner: REMOVE NEXT VALUES keyvalues={TestTable,,1244846310969/info:regioninfo/1244846397895/Put/vlen=277, TestTable,,1244846310969/info:server/1244846319501/Put/vle      n=19, TestTable,,1244846310969/info:serverstartcode/1244846319501/Put/vlen=8}
  841 2009-06-12 22:41:28,403 [RegionManager.metaScanner] INFO org.apache.hadoop.hbase.master.BaseScanner: REMOVE GET keyvalues={TestTable,,1244846310969/historian:assignment/1244846315138/Put/vlen=71, TestTable,,1244846310969/historian:compaction/1244846393353/Pu      t/vlen=36, TestTable,,1244846310969/historian:open/1244846319510/Put/vlen=51, TestTable,,1244846310969/historian:split/1244846312701/Put/vlen=43, TestTable,,1244846310969/info:regioninfo/1244846397895/Put/vlen=277, TestTable,,1244846310969/info:server/124484      6319501/Put/vlen=19, TestTable,,1244846310969/info:serverstartcode/1244846319501/Put/vlen=8, TestTable,,1244846310969/info:splitB/1244846397895/Put/vlen=297}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Above, the splitB is present in the Get but not in the Scan next.&lt;/p&gt;</comment>
                            <comment id="12719112" author="ryanobjc" created="Sat, 13 Jun 2009 10:43:50 +0000"  >&lt;p&gt;compactions are fucking up - the bottom half gets both, and the top half gets the top part.&lt;/p&gt;

&lt;p&gt;This is a fix to that problem.&lt;/p&gt;</comment>
                            <comment id="12719169" author="apurtell" created="Sat, 13 Jun 2009 18:45:35 +0000"  >&lt;p&gt;Patch &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1495&quot; title=&quot;IllegalArgumentException in halfhfilereader#next&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1495&quot;&gt;&lt;del&gt;HBASE-1495&lt;/del&gt;&lt;/a&gt; does not apply cleanly to trunk. Store.java edits are rejected.&lt;/p&gt;</comment>
                            <comment id="12719170" author="stack" created="Sat, 13 Jun 2009 18:49:35 +0000"  >&lt;p&gt;Excellent Ryan.  Testing now.&lt;/p&gt;

&lt;p&gt;Comments on patch:&lt;/p&gt;

&lt;p&gt;Why remove this:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-          LOG.debug(location);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;IIRC, its useful emitting when region when its added cache... some hope of figuring whats going on client-side?&lt;/p&gt;

&lt;p&gt;The half-file reader fix looks great.&lt;/p&gt;

&lt;p&gt;Don&apos;t commit the System.out.printlns&lt;/p&gt;

&lt;p&gt;You do this:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
-    &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.row = row;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Is that right?&lt;/p&gt;

&lt;p&gt;Patch mixes in compacting fix but thats fine.&lt;/p&gt;

&lt;p&gt;Patch looks good.&lt;/p&gt;

&lt;p&gt;Trying it now.&lt;/p&gt;</comment>
                            <comment id="12719171" author="apurtell" created="Sat, 13 Jun 2009 18:49:57 +0000"  >&lt;p&gt;Fixed up patch for trunk. Testing against &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1500&quot; title=&quot;KeyValue$KeyComparator array overrun&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1500&quot;&gt;&lt;del&gt;HBASE-1500&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12719172" author="stack" created="Sat, 13 Jun 2009 18:54:19 +0000"  >&lt;p&gt;And things below should be inside try/finallys:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+       MinorCompactingStoreScanner scanner = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; MinorCompactingStoreScanner(&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;, scanners); 
                      
+       &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; ( scanner.next(writer) ) { } 
+        
+       scanner.close();   
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12719217" author="stack" created="Sun, 14 Jun 2009 03:01:42 +0000"  >&lt;p&gt;I&apos;m going out.  As of this evening, item 1 in comment &apos;12/Jun/09 10:15 PM&apos; above is still happening in spite of a bunch of Jon work (hbase-1516, etc.).  Will try again tomorrow... but probably not till monday.&lt;/p&gt;</comment>
                            <comment id="12719223" author="ryanobjc" created="Sun, 14 Jun 2009 04:27:14 +0000"  >&lt;p&gt;my IDE says this.row = row is self assigning &apos;row&apos; to itself.  It is a noop essentially.&lt;/p&gt;

&lt;p&gt;I thought I was removing the System.out.printlns, but I&apos;ll check again.&lt;/p&gt;

&lt;p&gt;I found that LOG.debug(location) was kicking out 1 line for every item I am committing, making my client stupidly noisy. Maybe the problem is my client has debug on, but i dont know how to solve having client and server on different log settings if they are using the same classpath on the same machine.&lt;/p&gt;

&lt;p&gt;I&apos;ll try to create some new patches.&lt;/p&gt;</comment>
                            <comment id="12719224" author="ryanobjc" created="Sun, 14 Jun 2009 04:29:25 +0000"  >&lt;p&gt;my patch is bogus. it&apos;s out of date now.&lt;/p&gt;

&lt;p&gt;I&apos;ll be submitting a combined patch to 1513 that fixes Half HFile issues and compaction speed.&lt;/p&gt;</comment>
                            <comment id="12719412" author="ryanobjc" created="Mon, 15 Jun 2009 05:59:35 +0000"  >&lt;p&gt;I&apos;ve figured out this bug, and it has been fixed in the guise of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1520&quot; title=&quot;StoreFileScanner catches and ignore IOExceptions from HFile&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1520&quot;&gt;&lt;del&gt;HBASE-1520&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1522&quot; title=&quot;We delete splits before their time occasionally&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1522&quot;&gt;&lt;del&gt;HBASE-1522&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So to outline the problems:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1522&quot; title=&quot;We delete splits before their time occasionally&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1522&quot;&gt;&lt;del&gt;HBASE-1522&lt;/del&gt;&lt;/a&gt; would cause the problem whereby a split child would have it&apos;s parent removed from under it.  &lt;/p&gt;

&lt;p&gt;Then we&apos;d go to next() in hfile, this it the code:&lt;br/&gt;
      public boolean next() throws IOException {&lt;br/&gt;
        if (block == null) &lt;/p&gt;
{
          throw new IOException(&quot;Next called on non-seeked scanner&quot;);
        }
&lt;p&gt;        block.position(block.position() + currKeyLen + currValueLen);&lt;br/&gt;
        if (block.remaining() &amp;lt;= 0) &lt;/p&gt;
{
          // load next block
        }

&lt;p&gt;So we&apos;d call block.position(...), and get to the end of the block, thus triggering the &apos;load next block&apos; code.&lt;/p&gt;

&lt;p&gt;But at this point, the HDFS code would throw an exception - reading a deleted file fails.&lt;/p&gt;

&lt;p&gt;But due to &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1520&quot; title=&quot;StoreFileScanner catches and ignore IOExceptions from HFile&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1520&quot;&gt;&lt;del&gt;HBASE-1520&lt;/del&gt;&lt;/a&gt;, the scan code would ignore the exception.  &lt;/p&gt;

&lt;p&gt;Then, we&apos;d call next() again.  Only this time the block.position() is at the end, so attempts to push it forward would throw the InvalidArgumentException indicated above.&lt;/p&gt;

&lt;p&gt;The fixes are 2 fold:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;don&apos;t ignore IOExceptions&lt;/li&gt;
	&lt;li&gt;don&apos;t delete a split parent if there are children pointing to it.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Both of these have been fixed in other issues.&lt;/p&gt;

&lt;p&gt;I am very satisfied that the bug has been nailed to the wall.  Both these bugs were committed to trunk.  Please verify if you can and let me know if it&apos;s fixed.&lt;/p&gt;</comment>
                            <comment id="12719413" author="ryanobjc" created="Mon, 15 Jun 2009 06:00:13 +0000"  >&lt;p&gt;feel free to file a new bug if you still experience this.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12410531" name="1495.patch" size="2349" author="stack" created="Sat, 13 Jun 2009 05:15:23 +0000"/>
                            <attachment id="12410546" name="HBASE-1495.patch" size="11887" author="apurtell" created="Sat, 13 Jun 2009 18:49:57 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 8 Jun 2009 22:27:14 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>25788</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 25 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hdlb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>99464</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fixed by &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1520&quot; title=&quot;StoreFileScanner catches and ignore IOExceptions from HFile&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1520&quot;&gt;&lt;strike&gt;HBASE-1520&lt;/strike&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1522&quot; title=&quot;We delete splits before their time occasionally&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1522&quot;&gt;&lt;strike&gt;HBASE-1522&lt;/strike&gt;&lt;/a&gt;</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>