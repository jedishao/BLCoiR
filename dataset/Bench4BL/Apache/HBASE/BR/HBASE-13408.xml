<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sat Dec 03 16:50:02 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-13408/HBASE-13408.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-13408] HBase In-Memory Memstore Compaction</title>
                <link>https://issues.apache.org/jira/browse/HBASE-13408</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;A store unit holds a column family in a region, where the memstore is its in-memory component. The memstore absorbs all updates to the store; from time to time these updates are flushed to a file on disk, where they are compacted. Unlike disk components, the memstore is not compacted until it is written to the filesystem and optionally to block-cache. This may result in underutilization of the memory due to duplicate entries per row, for example, when hot data is continuously updated. &lt;br/&gt;
Generally, the faster the data is accumulated in memory, more flushes are triggered, the data sinks to disk more frequently, slowing down retrieval of data, even if very recent.&lt;/p&gt;

&lt;p&gt;In high-churn workloads, compacting the memstore can help maintain the data in memory, and thereby speed up data retrieval. &lt;br/&gt;
We suggest a new compacted memstore with the following principles:&lt;br/&gt;
1.	The data is kept in memory for as long as possible&lt;br/&gt;
2.	Memstore data is either compacted or in process of being compacted &lt;br/&gt;
3.	Allow a panic mode, which may interrupt an in-progress compaction and force a flush of part of the memstore.&lt;/p&gt;

&lt;p&gt;We suggest applying this optimization only to in-memory column families.&lt;/p&gt;

&lt;p&gt;A design document is attached.&lt;br/&gt;
This feature was previously discussed in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5311&quot; title=&quot;Allow inmemory Memstore compactions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5311&quot;&gt;HBASE-5311&lt;/a&gt;.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12788345">HBASE-13408</key>
            <summary>HBase In-Memory Memstore Compaction</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="eshcar">Eshcar Hillel</reporter>
                        <labels>
                    </labels>
                <created>Sun, 5 Apr 2015 13:37:59 +0000</created>
                <updated>Fri, 21 Oct 2016 18:48:01 +0000</updated>
                            <resolved>Fri, 21 Oct 2016 06:24:14 +0000</resolved>
                                                                        <due></due>
                            <votes>0</votes>
                                    <watches>39</watches>
                                                                <comments>
                            <comment id="14396259" author="apache9" created="Sun, 5 Apr 2015 14:33:24 +0000"  >&lt;p&gt;Looks good.&lt;/p&gt;

&lt;p&gt;And a little hint, log truncating is also an important purpose of doing flush. So if you keep some data in memstore for a long time, then there will be lots of WALs that can not be truncated and increase MTTR. So if the flush request comes from LogRoller, then you should enter the panic mode and flush the memstore(Maybe you have already known but I haven&apos;t seen log truncating things in your design doc so just put it here &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; )&lt;/p&gt;

&lt;p&gt;And I remember that xiaomi said they have a &apos;HLog reform&apos; feature which can solve this problem in their private version of HBase, but seems they have not donated to community yet.&lt;/p&gt;</comment>
                            <comment id="14396342" author="lhofhansl" created="Sun, 5 Apr 2015 17:45:51 +0000"  >&lt;p&gt;Why not continue on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5311&quot; title=&quot;Allow inmemory Memstore compactions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5311&quot;&gt;HBASE-5311&lt;/a&gt;? In any case, good to pick this topic up again!&lt;/p&gt;

&lt;p&gt;Some comments/questions:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Apache9&quot; class=&quot;user-hover&quot; rel=&quot;Apache9&quot;&gt;Duo Zhang&lt;/a&gt; the memstore (by default) will limit the maximum time of any edit in the memstore to 1h. So that should be OK.&lt;/li&gt;
	&lt;li&gt;The in-memstore compaction has to be SLAB aware or we&apos;ll get horrible fragmentation issues (maybe that&apos;s what you meant with MAB on the doc)&lt;/li&gt;
	&lt;li&gt;A skiplist is actually a bad data structure when it comes to cache line locality. The HFile format is much better. So if the data is compacted anyway, might as well write it in HFile format, that would also allow to write that to disk later.&lt;/li&gt;
	&lt;li&gt;If the &quot;compactions&quot; will simply remove expired KVs, it will likely make things worse. (that was also my initial thought on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5311&quot; title=&quot;Allow inmemory Memstore compactions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5311&quot;&gt;HBASE-5311&lt;/a&gt;, but it will not work)&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14436431" author="stack" created="Sun, 5 Apr 2015 23:54:42 +0000"  >&lt;p&gt;In the doc it says the proposal is for in-memory column families only and may not be generally unless there are lots of instances of Cells at exact same coordinates. But as Lars says above, the memstore is a costly data structure for keeping all in-memory state sorted; a compacted version that was hfile sorted could make for better perf than the skiplist (as speculated over in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5311&quot; title=&quot;Allow inmemory Memstore compactions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5311&quot;&gt;HBASE-5311&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Other comments:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The data is kept in memory for as long as possible&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;What Duo says above...We need to flush to free up WALs to contain our WAL-burden of edits to replay on crash.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;pull the last component of the compaction pipeline and shift it to snapshot&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;What is involved running above step?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;CellSetMgr&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;What is one of these? It is a skiplist?&lt;/p&gt;

&lt;p&gt;What do you think of the attempt at lockless snapshotting suggested over in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5311&quot; title=&quot;Allow inmemory Memstore compactions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5311&quot;&gt;HBASE-5311&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Thanks for taking this up&lt;/p&gt;
</comment>
                            <comment id="14480911" author="anoop.hbase" created="Mon, 6 Apr 2015 04:04:45 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10713&quot; title=&quot;A MemStore implementation with in memory flushes to CellBlocks&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10713&quot;&gt;&lt;del&gt;HBASE-10713&lt;/del&gt;&lt;/a&gt;  also related.  There I aim to make in memory flushes to a  cell block.  We can do compaction of these in memory Cell blocks in btw.&lt;/p&gt;</comment>
                            <comment id="14480918" author="stack" created="Mon, 6 Apr 2015 04:19:58 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt; Oh yeah. Sorry. Forgot that one. Yeah, for sure related.&lt;/p&gt;</comment>
                            <comment id="14480923" author="anoop.hbase" created="Mon, 6 Apr 2015 04:28:44 +0000"  >&lt;p&gt;I will revisit that Jira once &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-11425&quot; title=&quot;Cell/DBB end-to-end on the read-path&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-11425&quot;&gt;&lt;del&gt;HBASE-11425&lt;/del&gt;&lt;/a&gt; is split into smaller patches. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="14481015" author="anastas" created="Mon, 6 Apr 2015 07:20:21 +0000"  >&lt;p&gt;Hey! Thanks for taking a look &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;There is the panic mode for any case when flush is a must. We will improve the design document to refer to log truncating as well, so it would be clearer for the reader.&lt;/p&gt;</comment>
                            <comment id="14481016" author="anastas" created="Mon, 6 Apr 2015 07:23:48 +0000"  >&lt;p&gt;Regarding the second comment, yes, we meant SLAB to be encapsulated into CellSetMgr.&lt;/p&gt;</comment>
                            <comment id="14482938" author="eshcar" created="Tue, 7 Apr 2015 10:00:19 +0000"  >&lt;p&gt;Thank you &lt;span class=&quot;error&quot;&gt;&amp;#91;~zhangduo&amp;#93;&lt;/span&gt; for raising the important WAL truncating issue and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lhofhansl&quot; class=&quot;user-hover&quot; rel=&quot;lhofhansl&quot;&gt;Lars Hofhansl&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; for raising the components format issue. These two issues should definitely be addressed in our solution. &lt;br/&gt;
1.	When the memstore compactor completes a compaction it can inquire the resulting component for the oldest record sequence id, and use it to apply WAL truncation. This might not be good enough in all scenarios, in which case the memstore should get into a panic mode and do a real flush. So there are several triggers for entering a panic mode, one relates to the memstore size and the other relates to the WAL size. &lt;br/&gt;
2.	The CellSetMgr and CellSetScanner abstractions we suggested should allow for easy support of any cell storage format. Specifically, the active set can use a skip-list to absorb the updates and the compactor can generate b-trees or any other cache friendly format. We can use a Factory pattern for this purpose.&lt;/p&gt;

&lt;p&gt;There is no technical challenge in making this feature available for all column families; however, we believe in-memory columns have better chance of benefiting from it while in the general case this memstore could put a burden on the region server. If you believe this has the potential to improve performance also in other scenarios there is no reason not to make it a first citizen column type. &lt;/p&gt;

&lt;p&gt;A CellSetMgr, as explained above, is an abstraction of the cell set storage, be it skip list or a b-tree, w/o SLAB, compressed or not, and any other details that should be encapsulated and de-coupled from the users of these objects.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5311&quot; title=&quot;Allow inmemory Memstore compactions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5311&quot;&gt;HBASE-5311&lt;/a&gt; suggested using an RCU-like mechanism to protect the components (layers) of the memstore as they shift around, and also applied a freezing phase. Our solution uses the existing sync mechanism to push the component into the pipeline. Once the component is in the pipeline it is read-only, therefore can be accessed without using locks. The only part we might need to protect is when we swap the subset of pipeline components with the new single compacted component. This should be as easy as changing a pointer and can use an RCU as well. When no protection is applied a concurrent reader can miss this swap then it goes through the &#8220;old&#8221; components, which is more expensive but is still correct.&lt;/p&gt;

&lt;p&gt;Shifting a component from the pipeline to the snapshot should be the same as shifting it from active set to snapshot (as it is done today).&lt;/p&gt;</comment>
                            <comment id="14483589" author="stack" created="Tue, 7 Apr 2015 17:38:54 +0000"  >&lt;p&gt;All sounds good &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=eshcar&quot; class=&quot;user-hover&quot; rel=&quot;eshcar&quot;&gt;Eshcar Hillel&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;If you believe this has the potential to improve performance also in other scenarios there is no reason not to make it a first citizen column type.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We should go with your suggestion and make it an in-memory only facility first. Then if we have numbers to show it a general benefit, only then turn it on everywhere.&lt;/p&gt;</comment>
                            <comment id="14489988" author="narendra" created="Fri, 10 Apr 2015 17:44:59 +0000"  >&lt;p&gt;When running a Trafodion workload with a high churn (e.g. updating the same row key many times over), we also observed that it would lead to a performance degradation (attributed to a few-row same-region scans that are part of the workload) over time .&lt;/p&gt;

&lt;p&gt;A flush of the memstore would lead to an HFile that&#8217;s ~15% of the memstore size.&lt;/p&gt;

&lt;p&gt;Major compaction would, of course, help get the performance back to the original level. A manually driven flush of the workload tables would also improve the performance (~20%) &#8211; and then again a gradual decline as the workload progressed.&lt;/p&gt;

&lt;p&gt;This JIRA should help with the performance degradation that we see in our Trafodion test case (though our tables may not necessarily be in-memory).&lt;/p&gt;</comment>
                            <comment id="14490731" author="lhofhansl" created="Sat, 11 Apr 2015 02:36:13 +0000"  >&lt;p&gt;One - maybe simpler - thing we could do is flushing earlier if we have a lot of Cells with more versions than MAX_VERSION, or a lot of expired or deleted Cells. (see also &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-4241&quot; title=&quot;Optimize flushing of the Store cache for max versions and (new) min versions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-4241&quot;&gt;&lt;del&gt;HBASE-4241&lt;/del&gt;&lt;/a&gt;)&lt;/p&gt;</comment>
                            <comment id="14626301" author="eshcar" created="Tue, 14 Jul 2015 12:51:16 +0000"  >&lt;p&gt;Hi - we are back with an implementation of the basic feature (see link to the review board for the &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-13408&quot; title=&quot;HBase In-Memory Memstore Compaction&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-13408&quot;&gt;&lt;del&gt;HBASE-13408&lt;/del&gt;&lt;/a&gt;-098 code), and some experimental results. We were able to show 30-65% performance gain for read accesses in high-churn workloads (comprising of 50% reads and 50% writes), and mainly to maintain predictable latency SLA (see performance evaluation document for full results). We&#8217;ve also adapted the design document to reflect the code, specifically renaming some classes and describing the changes we made in the region flushing policy. (see design document ver02).&lt;/p&gt;</comment>
                            <comment id="14626309" author="eshcar" created="Tue, 14 Jul 2015 12:58:40 +0000"  >&lt;p&gt;A comment and a request: we&#8217;ve yet to address the WAL truncating issue.&lt;br/&gt;
The problem is twofold:&lt;br/&gt;
(1) if the region comprises only an in-memory column (store) then flush may not occur for a long time resulting in a big log which in turn may significantly increase MTTR. This is bad.&lt;br/&gt;
(2) if the in-memory column (store) is part of a region with default stores then flushes do occur, and the WAL truncates even entries it should not. Specifically it truncate entries of the in-memory store that are still present in the memstore, that is, not eliminated by compaction and not flushed to disk. This is a real threat to HBase durability guarantees.&lt;/p&gt;

&lt;p&gt;The same solution can help avoid both problems. Currently the WAL uses a region counter to mark the entries as well as to decide which entries are truncable. However, the memstore is unaware of these sequence numbers and therefore cannot indicate which WAL entries should not be truncated.&lt;br/&gt;
We would like to come up with a mechanism that allows the memstore and WAL to share the minimal required information in order to ensure the data durability. We&#8217;d appreciate suggestions/insights. &lt;/p&gt;</comment>
                            <comment id="14626370" author="yuzhihong@gmail.com" created="Tue, 14 Jul 2015 14:01:43 +0000"  >&lt;p&gt;In the review request, please add &apos;hbase&apos; to Groups field so that people can receive review comments.&lt;/p&gt;</comment>
                            <comment id="14630194" author="ebortnik" created="Thu, 16 Jul 2015 19:03:33 +0000"  >&lt;p&gt;Community, please chime in ...&lt;/p&gt;</comment>
                            <comment id="14630253" author="stack" created="Thu, 16 Jul 2015 20:12:14 +0000"  >&lt;p&gt;Numbers look great. On 1., we used to have a mechanism for figuring which region had oldest outstanding edits. That no longer works? I need to understand 2. Let me look at the patch. Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=eshcar&quot; class=&quot;user-hover&quot; rel=&quot;eshcar&quot;&gt;Eshcar Hillel&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14631385" author="stack" created="Fri, 17 Jul 2015 14:16:43 +0000"  >&lt;p&gt;I left some comments on rb but should have read the design first.&lt;/p&gt;

&lt;p&gt;I read the design and had these few questions (design is nicely written):&lt;/p&gt;

&lt;p&gt;FYI, Flush-by-column-family is on by default in 1.2 HBase. Will you need to do anything to accommodate this?&lt;/p&gt;

&lt;p&gt;You say &quot;In high&#173;churn workloads, compacting the memstore can help maintain the data in memory, and thereby speed up data retrieval&quot; The pipeline entries are still skiplists sets? What is the compacted representation? Is it still a skiplist? Skip list is slow especially as we get large. Was wondering if you saw any speedup if only because you have many small skip lists rather than one big one?&lt;/p&gt;

&lt;p&gt;&quot;Therefore, we suggest applying this optimization only to in&#173;memory column families.&quot; In testing you find that the overhead slows us down?&lt;/p&gt;

&lt;p&gt;I asked in rb what threading model was? Is there a new thread per Store memstore? &lt;/p&gt;

&lt;p&gt;Is the new force&#173;flush&#173;size a new config? I wasn&apos;t following why we need it? If size of current Set + pipeline is above max size, flush? I wasn&apos;t clear on why the need of 2.5.&lt;/p&gt;

&lt;p&gt;Is memstoresegment our old snapshot? it has other facility beyond old snapshot?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="14632806" author="eshcar" created="Sun, 19 Jul 2015 13:14:17 +0000"  >&lt;p&gt;Snapshot active set and the pipeline components are all memstore segments, it&apos;s an abstraction that allows to treat all these parts equally.&lt;/p&gt;

&lt;p&gt;The memstore compaction should work also with flush-by-column-family. However, even when flushing by column the WAL sequence id is defined per region (right?) so WAL truncation is not trivial.&lt;/p&gt;

&lt;p&gt;forceflushsize is not a new config, instead we take the average of flush size and the blocking flush size: flush-size &amp;lt; forceflushsize &amp;lt; blockingflushsize.&lt;br/&gt;
When considering a flush-by-column-family mode, if the active segment is greater than flush size then flush is invoked and the active segment is pushed to the pipeline. If the active +pipeline segments are greater the forceflushsize then the flush is forced and snapshot is flushed to disk.&lt;/p&gt;

&lt;p&gt;All entries (active, pipeline, snapshot) are stored in a skip-list. The performance gain comes from accessing only memory and not the disk. The skip lists are not too large as multiple versions of the same key are removed within the compacted pipeline, but are not too small either, e.g., active is pushed to pipeline only when it gets to 128MB.&lt;/p&gt;

&lt;p&gt;When there is no duplication, i.e., a large set of active keys and no multiple versions per active key compaction is of no help, data is flushed to disk anyway but the compaction pipeline consumes memory and cpu. We don&apos;t see slow down in our experiments but in a setting where the memory/cpu resources are limited and contended for might show slow down.&lt;/p&gt;</comment>
                            <comment id="14634908" author="anoop.hbase" created="Tue, 21 Jul 2015 10:14:54 +0000"  >&lt;p&gt;So here , in order to use a bigger memstore and keep more data in memory, no need for change in memstore size (flush size).  That flush will try keeping the cells for some more time in memory. So when one model the memstore sizing and deciding on the #regions to keep in a node, how can he safely decide?&lt;br/&gt;
After in memory compaction, we will make one buffer of memory where the cell&apos;s data is serialized as plain bytes?&lt;/p&gt;</comment>
                            <comment id="14634999" author="eshcar" created="Tue, 21 Jul 2015 11:46:30 +0000"  >&lt;p&gt;Is your first concern ``how can an admin safely decide on the number of region per region server if the memory trace of a region may be bigger than flush size?&apos;&apos;&lt;br/&gt;
First, this can happen also with default memstore implementation, and for this reason the blocking flush size is defined, and we make sure not to cross this upper limit even with compacted memstore implementation.&lt;br/&gt;
Second, while less trivial, it is still possible to come up with a reasonable computation if you have an upper limit on the number of regions with compacted memstore at any point in time.&lt;/p&gt;

&lt;p&gt;Regarding you second question, the compaction pipeline is composed of memstore segments (1 or more). Each memstore segment has a cell set, currently this is the same data structure as in the active segment, namely a skip list. If found useful it is possible to change the format in which the cells are stored in the pipeline after compaction.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt; I hope to answer your questions.&lt;/p&gt;</comment>
                            <comment id="14638791" author="eshcar" created="Thu, 23 Jul 2015 13:20:30 +0000"  >&lt;p&gt;I did some learning of the flush-by-column-family feature (&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10201&quot; title=&quot;Port &amp;#39;Make flush decisions per column family&amp;#39; to trunk&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10201&quot;&gt;&lt;del&gt;HBASE-10201&lt;/del&gt;&lt;/a&gt;). I think it will help us in supporting WAL truncation in compacting memstore. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Apache9&quot; class=&quot;user-hover&quot; rel=&quot;Apache9&quot;&gt;Duo Zhang&lt;/a&gt; I would appreciate if you can confirm that this should work.&lt;/p&gt;

&lt;p&gt;In the current implementation, when a region flushes a store, the previous sequence id that was associated with this store in the WAL oldestUnflushedStoreSequenceIds set is removed. The first put operation to occur after the flush installs a new sequence id for the store.&lt;br/&gt;
The WAL uses this bookeeping when it needs to decide which WAL files can be archived (WAL truncation).&lt;/p&gt;

&lt;p&gt;For compacting memstore we would like to keep the sequence id in the oldestUnflushedStoreSequenceIds set of the WAL even after a flush is invoked. Instead, the memstore compaction thread will be responsible for setting an approximation of the correct sequence id for the store in the set.&lt;br/&gt;
To this end, the compacting memstore maintains a mapping of timestamp to region sequence number (the same sequence numbers that are attached to WAL edits). Whenever a flush is invoked on a compacting memstore it adds the current time and current sequence number pair to this mapping. &lt;br/&gt;
As an additional artifact of the memstore compaction the minimal timestamp that is still present in the memstore is computed. This timestamp is then used to identify the maximal sequence id in the timestamp-&amp;gt;seqId mapping for which no entries are left in the memstore. Finally, it uses this approximated sequence number to update the oldestUnflushedStoreSequenceIds set.&lt;/p&gt;

&lt;p&gt;This way the WAL is being truncated with some delay with respect to the real sequence number, but the memory overhead if fairly small (only a small map of ts-&amp;gt;seq is added to the memstore) when compared to a solution that adds a sequence number to each cell in the memstore and then uses it to find the &lt;b&gt;exact&lt;/b&gt; oldest unflushed sequence id.&lt;/p&gt;

&lt;p&gt;What say you?&lt;/p&gt;</comment>
                            <comment id="14646101" author="apache9" created="Wed, 29 Jul 2015 14:20:18 +0000"  >&lt;p&gt;Things we talking here are all &apos;In Memory&apos;, so I do not think we need to modify WAL...&lt;/p&gt;

&lt;p&gt;I think all the logic could be down in a special memstore implementation? For example, you can set the flush-size to 128M, and introduce a compact-size which only consider the active set size to 32M. When you find the active set reaches 32M then you put it into pipeline and try to compact segments in pipeline to reduce memory usage. The upper layer does not care about how many segments you have, it only cares about the total memstore size. If it reaches 128M then a flush request is coming, then you should flush all data to disk. If there are many redundant cells then the total memstore will never reaches 128M, I think this is exactly what we want here? And this way you do not change the semantic of flush, the log truncating should also work as well.&lt;/p&gt;

&lt;p&gt;And I think you can use some more compact data structures instead of skip list since the segments in pipeline are read only? This may bring some benefits even if we do not have many redundant cells.&lt;/p&gt;

&lt;p&gt;What do you think? &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=eshcar&quot; class=&quot;user-hover&quot; rel=&quot;eshcar&quot;&gt;Eshcar Hillel&lt;/a&gt;. Sorry a bit late. Thanks.&lt;/p&gt;</comment>
                            <comment id="14646130" author="anoop.hbase" created="Wed, 29 Jul 2015 14:43:58 +0000"  >&lt;p&gt;I agree to both these points. And this is exactly what &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10713&quot; title=&quot;A MemStore implementation with in memory flushes to CellBlocks&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10713&quot;&gt;&lt;del&gt;HBASE-10713&lt;/del&gt;&lt;/a&gt; is doing. Sorry I left that in btw as I got busy with completing off heap read path project. Will revive with that jira soon. Will appreciate joint work if possible.&lt;/p&gt;</comment>
                            <comment id="14647297" author="eshcar" created="Thu, 30 Jul 2015 07:35:33 +0000"  >&lt;p&gt;Thank you &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Apache9&quot; class=&quot;user-hover&quot; rel=&quot;Apache9&quot;&gt;Duo Zhang&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt; for your comments.&lt;/p&gt;

&lt;p&gt;There is a question of when to push the active set into the pipeline, and which threshold to use. This should be some configurable parameter. But please let&#8217;s put this aside for a minute.&lt;br/&gt;
The problem I meant to handle with the WAL truncation mechanism is orthogonal to this decision. Consider a region with one compacting store. Assume we add the following key-value-ts tuples to the memstore:&lt;br/&gt;
(A,1,1) (A,4,4) (A,7,7)&lt;br/&gt;
(B,2,2) (B,5,5) (B,8,8)&lt;br/&gt;
(C,3,3) (C,6,6) (C,9,9)&lt;br/&gt;
All these items will have edits in the WAL. After compaction what is left in-memory are&lt;br/&gt;
(A,7,7) (B,8,8) (C,9,9)&lt;br/&gt;
however these edits are not removed from the WAL since no flushing occurs.&lt;br/&gt;
This can go on and on without ever flushing data to disk and without removing WAL edits.&lt;br/&gt;
The solution we suggested earlier is to have a small map that would help determine that after the compaction in the example above we can remove all WAL entries that correspond to ts equal or lower than 6. And it happens not within the scope of a flush as compaction is a background process. &lt;br/&gt;
If we don&#8217;t change the WAL truncation in this way WAL can grow without limit.&lt;/p&gt;

&lt;p&gt;Supporting a more compacted format in the compaction pipeline was discussed when we just started this JIRA. The design we suggested enables plugging-in any data structure: it can be the CellBlocks by &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt;, it can be a b-tree, or any alternative that is suggested in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-3993&quot; title=&quot;Alternatives to ConcurrentSkipListMap in MemStore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-3993&quot;&gt;HBASE-3993&lt;/a&gt;. It only needs to support the API defined by the CellSkipListSet wrapper class (in our patch we changed its name to CellSet to indicate the implementation is not restricted to a skip-list).&lt;br/&gt;
Having said that, we would like to keep the initial solution simple. The plug-in infrastructure is in; experimenting with different data structures can be allocated a different task.&lt;/p&gt;

&lt;p&gt;Coming back to the timing of the in-memory flush, since this action mandates the same synchronization as in a flush to disk (to block the updaters while allocating a new active set) it seems appropriate to apply it upon a disk flush. &lt;br/&gt;
Moreover, if we don&#8217;t change the flush semantics a compacting memstore can be forced to flush to disk when it reaches 16M (I can show an example) which would countervail the benefits of this feature.&lt;/p&gt;</comment>
                            <comment id="14647348" author="apache9" created="Thu, 30 Jul 2015 08:38:46 +0000"  >&lt;p&gt;OK, I get your point. After a memstore compaction we may drop some old cells so set a new value of the &lt;tt&gt;oldestUnflushedSeqId&lt;/tt&gt; in WAL is reasonable. And yes, this can avoid WAL triggers a flush for log truncating under your cases.&lt;/p&gt;

&lt;p&gt;But I still think you can find a way to set it without changing the semantics of flush... Flush is a very critical operation in HBase so you should keep away from it as much as possible unless you have to...&lt;/p&gt;

&lt;p&gt;Or a more difficult way, remove the old flush operation and introduce some new operations such as &quot;reduce your memory usage&quot; and &quot;persist old cells&quot; and so on. You can put your compaction logic in the &quot;reduce your memory usage&quot; operation.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="14650518" author="eshcar" created="Sat, 1 Aug 2015 20:19:07 +0000"  >&lt;p&gt;Then how about we&#8217;ll make use of the FlushPolicy abstraction that is written so nicely and is easy to extend &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;.&lt;br/&gt;
We can add to it a method selectStoresToCompact(), so that a flush process manages 2 sets to reduce memory usage (1) stores to flush (2) stores to be compacted. A store is in either of the two sets or in none, but not in both of them. The decision whether reducing the memory usage is done by a flush or a compaction depends on the store type and state.&lt;br/&gt;
In addition, we&#8217;ll add a method to the MemStore interface doInmemoryCompaction(). In compacted memstore the implementation of this method would be to push the active set into the compaction pipeline and invoke a compaction.&lt;/p&gt;

&lt;p&gt;With this solution the semantics of prepare-to-flush remains the same.&lt;/p&gt;</comment>
                            <comment id="14681774" author="eshcar" created="Tue, 11 Aug 2015 13:06:58 +0000"  >&lt;p&gt;We&apos;ve submitted the patch that is based on trunk. This includes all the changes that were presented in 0.98 plus the comments from the code review and necessary changes to adapt the code to master branch. Also added a link to the review board.&lt;br/&gt;
Next we plan to work on WAL truncation upon memory compaction based on the discussion in this Jira.&lt;/p&gt;</comment>
                            <comment id="14682135" author="hadoopqa" created="Tue, 11 Aug 2015 17:27:57 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12749830/HBASE-13408-trunk-v01.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12749830/HBASE-13408-trunk-v01.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit 7d4de20cafd6b765bd5f33df72fc0e630d1731f7.&lt;br/&gt;
  ATTACHMENT ID: 12749830&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 42 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.0 2.4.1 2.5.0 2.5.1 2.5.2 2.6.0 2.7.0)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 protoc&lt;/font&gt;.  The applied patch does not increase the total number of protoc compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;                &lt;font color=&quot;red&quot;&gt;-1 checkstyle&lt;/font&gt;.  The applied patch generated 1870 checkstyle errors (more than the master&apos;s current 1858 errors).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces the following lines longer than 100:&lt;br/&gt;
    + * in a single read-only component. The &#226;&#128;&#156;old&#226;&#128;&#157; components are discarded when no scanner is reading&lt;br/&gt;
+                  actualFlushes + &quot; attempts on region: &quot; + Bytes.toStringBinary(getRegionInfo().getRegionName())&lt;br/&gt;
+  /* Constructor used only when the scan usage is unknown and need to be defined according to the first move */&lt;br/&gt;
+    // so I wonder whether we need to come with our own workaround, or to update ReversedKeyValueHeap&lt;br/&gt;
+//  private boolean walkForwardInSingleRow(final Cell firstOnRow, final GetClosestRowBeforeTracker state) {&lt;br/&gt;
+            KeyValueUtil.createFirstOnRow(cell.getRowArray(), cell.getRowOffset(), cell.getRowLength());&lt;br/&gt;
+        .snapshot();                    // As compaction is starting in the background the repetition&lt;br/&gt;
+    assertTrue(&quot;History size has not increased&quot;, oldHistorySize &amp;lt; hmc.getSnapshot().getCellsCount());&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn post-site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;/p&gt;


&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15043//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15043//testReport/&lt;/a&gt;&lt;br/&gt;
Release Findbugs (version 2.0.3) 	warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15043//artifact/patchprocess/newFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15043//artifact/patchprocess/newFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15043//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15043//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;                Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15043//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15043//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14705603" author="eshcar" created="Thu, 20 Aug 2015 19:32:36 +0000"  >&lt;p&gt;We attach a new patch which covers wal truncation.&lt;br/&gt;
We also attach evaluation results for scans. The trend is very similar to the improvement we see for read operation.&lt;/p&gt;

&lt;p&gt;Following the approach suggested in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10713&quot; title=&quot;A MemStore implementation with in memory flushes to CellBlocks&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10713&quot;&gt;&lt;del&gt;HBASE-10713&lt;/del&gt;&lt;/a&gt;, we now divide flushed stores into two groups: one doing the traditional flush to disk, and the other group does in-memory flush into an inactive (read-only) memstore segment, which is subject to compaction. By default, an in-memory column family has compacted memstore which does in-memory flush, while all other column families have a default memstore which flush to disk. However, in some use cases, e.g. upon region split/merge/close, even in-memory columns flush their content to disk.&lt;/p&gt;

&lt;p&gt;Therefore, flush policy selects &lt;b&gt;two&lt;/b&gt; sets of stores: one to flush to disk, and one to do in-memory flush. The first set invokes snapshot(), and the second set invokes flushInMemory() during the prepare phase.&lt;br/&gt;
The main changes to support wal truncation are threefold:&lt;br/&gt;
(1) upon in-memory compaction the wal is updated with a sequence number which is a lower approximation of the lowest-unflushed-sequence-id&lt;br/&gt;
(2) When the number of log files exceed a certain threshold the store is forced to flush to disk even if it is an in-memory column.&lt;br/&gt;
(3) upon flush to disk lowest-unflushed-sequence-id is cleared (like it used to be). Stores with in-memory segments, update this with a lower approximation of the lowest sequence id still in memory. Other stores update this sequence id with the first insert after the flush (like it used to be)&lt;/p&gt;

&lt;p&gt;While (1) should help in prolonging the time an item can stay in memory, (2) and (3) are there to ensure the wal size is maintainable and cannot explode.&lt;/p&gt;</comment>
                            <comment id="14706110" author="yuzhihong@gmail.com" created="Fri, 21 Aug 2015 02:05:35 +0000"  >&lt;p&gt;Reading InMemoryMemstoreCompactionScansEvaluationResults.pdf, can you explain what 0.98-inmem represents ?&lt;/p&gt;

&lt;p&gt;Have you updated the patch on review board ?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="14706125" author="yuzhihong@gmail.com" created="Fri, 21 Aug 2015 02:22:59 +0000"  >&lt;p&gt;There were two rejected hunks for HStore.java&lt;/p&gt;

&lt;p&gt;FYI&lt;/p&gt;</comment>
                            <comment id="14706496" author="eshcar" created="Fri, 21 Aug 2015 10:05:07 +0000"  >&lt;p&gt;Patch is updated on review board.&lt;br/&gt;
0.98-inmem means setting the cluster with the code of branch 0.98 and running an in-memory column family.&lt;/p&gt;</comment>
                            <comment id="14707192" author="hadoopqa" created="Fri, 21 Aug 2015 18:18:35 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12751563/HBASE-13408-trunk-v02.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12751563/HBASE-13408-trunk-v02.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit bcef28eefaf192b0ad48c8011f98b8e944340da5.&lt;br/&gt;
  ATTACHMENT ID: 12751563&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 65 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15205//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15205//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14707438" author="mbertozzi" created="Fri, 21 Aug 2015 20:53:19 +0000"  >&lt;p&gt;some general comment on the design:&lt;/p&gt;

&lt;p&gt;The doc says something like &quot;we apply memstore compaction only to in-memory families, because we may end up with compacting something that has no updates/deletes&quot;.&lt;br/&gt;
but, in theory it should be easy to know if we have updates and deletes. since we have a skiplist, when we insert we can check if the previous record is the same key is an update/delete. so we end up with 2 counters of how many updates and deletes we have and we can apply a logic like &quot;if (update/delete - insert) &amp;gt; 40% do a memstore compact otherwise flush on disk.&lt;br/&gt;
given the above, we don&apos;t really need to have the compaction running randomly, we can start the compaction on flush if necessary.&lt;/p&gt;

&lt;p&gt;one other thing I was expecting was that the compacted version of the memstore was written as an in-memory hfile, so we can have leverage stuff like compression and encoding. but from the code looks like the compacted version (memstore segment?) is just another skiplist.&lt;/p&gt;

&lt;p&gt;can you expand more on why you ended up with the current implementation? what are the benefit and so on.&lt;/p&gt;</comment>
                            <comment id="14708312" author="ebortnik" created="Sun, 23 Aug 2015 07:14:58 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mbertozzi&quot; class=&quot;user-hover&quot; rel=&quot;mbertozzi&quot;&gt;Matteo Bertozzi&lt;/a&gt; we absolutely agree that there is a room for more optimizations. We strived to demonstrate a minimum viable implementation, and this is already a big patch. The published performance results show benefits for both random access and scan patterns, for a variety of data distributions. Admittedly, we were more after speed than memory optimization. &lt;/p&gt;

&lt;p&gt;Re/ the concrete questions:&lt;br/&gt;
1. HFile implementation for memstore segments. Very plausible (in fact, the internal API&apos;s allow to plug in this implementation quite easily). &lt;br/&gt;
2. Automatic memstore compaction (not only in-memory families). Our thinking was to let the system administrator remain in control of what is happening, so we introduced this limitation. Could be relaxed in the future. &lt;/p&gt;

&lt;p&gt;Thanks for all the feedback. We are open to discussion and adjustments that would eventually lead this feature to HBase mainstream.  &lt;/p&gt;</comment>
                            <comment id="14710978" author="anoop.hbase" created="Tue, 25 Aug 2015 09:24:36 +0000"  >&lt;p&gt;The in memory memstore compaction help us in many ways. I think the one in your use case is where data is constantly updated. So the in memory compaction can remove old cells.  One more thing is it can allow us to use much bigger memstore size and hold more cells in memory. The CSLM having perf impact when the #entries in it increases. So if we have in mem compaction in btw, we can overcome this limitation.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;one other thing I was expecting was that the compacted version of the memstore was written as an in-memory hfile, so we can have leverage stuff like compression and encoding. but from the code looks like the compacted version (memstore segment?) is just another skiplist&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This is the concern I also have which I raised in some older comments.  If we can do this, we can help all kind of use cases where the update of cells not happening. The CSLM each entry having some heap size overhead which we can avoid.&lt;/p&gt;

&lt;p&gt;Also the in mem compaction memstore is a kind of memstore impl. Now after the memstore is pluggable memstore interface impl way, we can have any kind of impl. So I was expecting all the things for decision of in mem compaction, how it happens etc etc to keep as an impl detail of memstore.  So from outside no changes as such required for this. It will be ugly if we have to change outside to support an in mem compacting memstore.&lt;/p&gt;</comment>
                            <comment id="14721512" author="ebortnik" created="Sun, 30 Aug 2015 13:00:48 +0000"  >&lt;p&gt;We did our homework to address &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt;&apos;s and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mbertozzi&quot; class=&quot;user-hover&quot; rel=&quot;mbertozzi&quot;&gt;Matteo Bertozzi&lt;/a&gt;&apos;s concerns. In-memory HFile&apos;s are absolutely possible to implement. The challenge with the current implementation is that the StoreFile implementation is too tightly coupled with HDFS whereas it could be associated with byte stream just as well. Most of the code is FS-independent, however some accurate refactoring and a couple of new abstractions would be required. Our concern is that this code is already a bulk, and further expanding it only increases the risk. Would it make sense do the following: (1) start reviewing and checking-in the existing code, either in one bulk or piecemeal, and (2) in parallel, design, implement and evaluate in-memory HFile&apos;s, either in a separate jira or as subtask in this jira. This could be just one more patch in the series.  &lt;/p&gt;</comment>
                            <comment id="14725937" author="yuzhihong@gmail.com" created="Tue, 1 Sep 2015 19:36:03 +0000"  >&lt;p&gt;Decoupling StoreFile implementation from hdfs can be addressed in another JIRA.&lt;/p&gt;

&lt;p&gt;I suggest giving current patch reviews so that we can move forward.&lt;/p&gt;</comment>
                            <comment id="14727170" author="eshcar" created="Wed, 2 Sep 2015 10:59:33 +0000"  >&lt;p&gt;New patch after rebase and code review changes.&lt;/p&gt;</comment>
                            <comment id="14727363" author="hadoopqa" created="Wed, 2 Sep 2015 13:49:41 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12753740/HBASE-13408-trunk-v03.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12753740/HBASE-13408-trunk-v03.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit f8dd99d7380e5eafae62a9f0c526ba24f98eb2e5.&lt;br/&gt;
  ATTACHMENT ID: 12753740&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 66 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.0 2.4.1 2.5.0 2.5.1 2.5.2 2.6.0 2.7.0 2.7.1)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 protoc&lt;/font&gt;.  The applied patch does not increase the total number of protoc compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 checkstyle&lt;/font&gt;.  The applied patch does not increase the total number of checkstyle errors&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces the following lines longer than 100:&lt;br/&gt;
    + * in a single read-only component. The &#226;&#128;&#156;old&#226;&#128;&#157; components are discarded when no scanner is reading&lt;br/&gt;
+  public FlushResult flush(boolean force,boolean forceDiskFlushInsteadOfInMemoryFlush) throws IOException {&lt;br/&gt;
+   * @see #internalFlushcache(java.util.Collection, java.util.Collection, org.apache.hadoop.hbase.monitoring.MonitoredTask, boolean)&lt;br/&gt;
+   * @see #internalFlushcache(org.apache.hadoop.hbase.wal.WAL, long, java.util.Collection, java.util.Collection, org.apache.hadoop.hbase.monitoring.MonitoredTask, boolean)&lt;br/&gt;
+        .snapshot();                    // As compaction is starting in the background the repetition&lt;br/&gt;
+      // snapshot() after setForceFlushToDisk() will reset timeOfOldestEdit. The method will also assert&lt;br/&gt;
+    assertTrue(&quot;History size has not increased&quot;, oldHistorySize &amp;lt; hmc.getSnapshot().getCellsCount());&lt;br/&gt;
+   * &lt;/p&gt;
{@link HBaseTestingUtility#createWal(Configuration, Path, org.apache.hadoop.hbase.HRegionInfo)}
&lt;p&gt; because that method&lt;br/&gt;
+            } else if (flushDesc.getAction() == WALProtos.FlushDescriptor.FlushAction.COMMIT_FLUSH) {&lt;br/&gt;
+            WALProtos.FlushDescriptor.StoreFlushDescriptor storeFlushDesc = flushDesc.getStoreFlushes(0);&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn post-site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;/p&gt;


&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are 2 zombie test(s): 	at org.apache.hadoop.hbase.filter.TestFuzzyRowFilterEndToEnd.testEndToEnd(TestFuzzyRowFilterEndToEnd.java:143)&lt;br/&gt;
	at org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat2.testMRIncrementalLoadWithLocality(TestHFileOutputFormat2.java:400)&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15391//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15391//testReport/&lt;/a&gt;&lt;br/&gt;
Release Findbugs (version 2.0.3) 	warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15391//artifact/patchprocess/newFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15391//artifact/patchprocess/newFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15391//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15391//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;  Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15391//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15391//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14802971" author="eowhadi" created="Thu, 17 Sep 2015 14:19:36 +0000"  >&lt;p&gt;Question on re-using the in-memory attribute: let&#8217;s imagine the use case of an online cart where people keep adding, deleting, updating quantity before submitting the order. That use case will love this patch. But if we also have some processes doing daily or weekly statistics, or simply users performing &#8220;what did I buy over the last 6 months&#8221;, but very infrequently, this will trigger population of old data in block cache with in-memory stickiness, even if the use case going back in time are not important enough to consume valuable block cache resources with in-memory stickiness?&lt;/p&gt;</comment>
                            <comment id="14802981" author="ebortnik" created="Thu, 17 Sep 2015 14:29:31 +0000"  >&lt;p&gt;JFYI, there is a discussion of a very similar feature in the rocksdb dev group: &lt;a href=&quot;https://www.facebook.com/groups/rocksdb.dev/permalink/812072708891245/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://www.facebook.com/groups/rocksdb.dev/permalink/812072708891245/&lt;/a&gt;. &lt;/p&gt;</comment>
                            <comment id="14906099" author="eshcar" created="Thu, 24 Sep 2015 09:27:32 +0000"  >&lt;p&gt;Attaching a new patch for supporting different formats of store segments.&lt;br/&gt;
Also attaching a low level design document to explain the class hierarchy for supporting existing format and adding other formats in the future.&lt;/p&gt;</comment>
                            <comment id="14906226" author="ebortnik" created="Thu, 24 Sep 2015 11:35:07 +0000"  >&lt;p&gt;The new internal API demonstrates how future segment formats can fit in (e.g., in-memory HFile for compact format, as suggested by &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt;). The last patch also addresses most of the comments raised by the recent code reviews. &lt;/p&gt;

&lt;p&gt;Dear community - please help with evaluating this feature with more benchmarks/use cases, in parallel with code reviews. &lt;/p&gt;

&lt;p&gt;Thanks in advance.   &lt;/p&gt;</comment>
                            <comment id="14906279" author="hadoopqa" created="Thu, 24 Sep 2015 12:21:38 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12762098/HBASE-13408-trunk-v04.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12762098/HBASE-13408-trunk-v04.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit 5b7894f92ba3e9ff700da1e9194ebb4774d8b71e.&lt;br/&gt;
  ATTACHMENT ID: 12762098&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 74 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.0 2.4.1 2.5.0 2.5.1 2.5.2 2.6.0 2.7.0 2.7.1)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 protoc&lt;/font&gt;.  The applied patch does not increase the total number of protoc compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 3 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 checkstyle&lt;/font&gt;.  The applied patch does not increase the total number of checkstyle errors&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 release audit&lt;/font&gt;.  The applied patch generated 1 release audit warnings (more than the master&apos;s current 0 warnings).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces the following lines longer than 100:&lt;br/&gt;
    +   * @see #internalFlushcache(java.util.Collection, java.util.Collection, org.apache.hadoop.hbase.monitoring.MonitoredTask, boolean)&lt;br/&gt;
+   * @see #internalFlushcache(org.apache.hadoop.hbase.wal.WAL, long, java.util.Collection, java.util.Collection, org.apache.hadoop.hbase.monitoring.MonitoredTask, boolean)&lt;br/&gt;
+   * store files, MutableCellSetSegmentScanner always does the seek, therefore always returning true.&lt;br/&gt;
+  public FlushResult flush(boolean forceFlushAllStores, boolean forceFlushInsteadOfCompaction) throws IOException;&lt;br/&gt;
+      // snapshot() after setForceFlushToDisk() will reset timeOfOldestEdit. The method will also assert&lt;br/&gt;
+    assertTrue(&quot;History size has not increased&quot;, oldHistorySize &amp;lt; hmc.getSnapshot().getCellsCount());&lt;br/&gt;
+   * &lt;/p&gt;
{@link HBaseTestingUtility#createWal(Configuration, Path, org.apache.hadoop.hbase.HRegionInfo)}
&lt;p&gt; because that method&lt;br/&gt;
+    GetTillDoneOrException(final int i, final byte[] r, final AtomicBoolean d, final AtomicInteger c) {&lt;br/&gt;
+        assertEquals((i == 5) ? HConstants.OperationStatusCode.BAD_FAMILY : HConstants.OperationStatusCode.SUCCESS,&lt;br/&gt;
+      final AtomicReference&amp;lt;OperationStatus[]&amp;gt; retFromThread = new AtomicReference&amp;lt;OperationStatus[]&amp;gt;();&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn post-site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.regionserver.TestHRegionWithInMemoryFlush&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are 2 zombie test(s): 	at org.apache.hadoop.hbase.regionserver.TestHRegion.testFlushCacheWhileScanning(TestHRegion.java:3734)&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15715//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15715//testReport/&lt;/a&gt;&lt;br/&gt;
Release audit warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15715//artifact/patchprocess/patchReleaseAuditWarnings.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15715//artifact/patchprocess/patchReleaseAuditWarnings.txt&lt;/a&gt;&lt;br/&gt;
Release Findbugs (version 2.0.3) 	warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15715//artifact/patchprocess/newFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15715//artifact/patchprocess/newFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15715//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15715//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;  Javadoc warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15715//artifact/patchprocess/patchJavadocWarnings.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15715//artifact/patchprocess/patchJavadocWarnings.txt&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15715//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15715//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14907245" author="yuzhihong@gmail.com" created="Thu, 24 Sep 2015 23:28:09 +0000"  >&lt;blockquote&gt;&lt;p&gt;getCellSet() which can be very inefficient.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Under which scenario(s) would this method be inefficient ?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The compaction pipeline may generate different type of mutable segments.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I thought the compaction pipeline would generate immutable segments ?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;HStoreFileScanner can be refactored to implement StoreSegmentScanner&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Would the above be done in a future patch or different JIRA ?&lt;/p&gt;</comment>
                            <comment id="14907642" author="hadoopqa" created="Fri, 25 Sep 2015 05:55:05 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12762309/HBASE-13408-trunk-v05.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12762309/HBASE-13408-trunk-v05.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit dff86542d558394cc87ede256bd5432d071ed73f.&lt;br/&gt;
  ATTACHMENT ID: 12762309&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 74 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.0 2.4.1 2.5.0 2.5.1 2.5.2 2.6.0 2.7.0 2.7.1)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 protoc&lt;/font&gt;.  The applied patch does not increase the total number of protoc compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 3 warning messages.&lt;/p&gt;

&lt;p&gt;                &lt;font color=&quot;red&quot;&gt;-1 checkstyle&lt;/font&gt;.  The applied patch generated 1790 checkstyle errors (more than the master&apos;s current 1783 errors).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces the following lines longer than 100:&lt;br/&gt;
    + * in a single read-only component. The &#226;&#128;&#156;old&#226;&#128;&#157; components are discarded when no scanner is reading&lt;br/&gt;
+  public FlushResult flush(boolean forceFlushAllStores, boolean forceFlushInsteadOfCompaction) throws IOException;&lt;br/&gt;
+      // snapshot() after setForceFlushToDisk() will reset timeOfOldestEdit. The method will also assert&lt;br/&gt;
+    assertTrue(&quot;History size has not increased&quot;, oldHistorySize &amp;lt; hmc.getSnapshot().getCellsCount());&lt;br/&gt;
+   * &lt;/p&gt;
{@link HBaseTestingUtility#createWal(Configuration, Path, org.apache.hadoop.hbase.HRegionInfo)}
&lt;p&gt; because that method&lt;br/&gt;
+    GetTillDoneOrException(final int i, final byte[] r, final AtomicBoolean d, final AtomicInteger c) {&lt;br/&gt;
+        assertEquals((i == 5) ? HConstants.OperationStatusCode.BAD_FAMILY : HConstants.OperationStatusCode.SUCCESS,&lt;br/&gt;
+      final AtomicReference&amp;lt;OperationStatus[]&amp;gt; retFromThread = new AtomicReference&amp;lt;OperationStatus[]&amp;gt;();&lt;br/&gt;
+        assertEquals((i == 5) ? HConstants.OperationStatusCode.BAD_FAMILY : HConstants.OperationStatusCode.SUCCESS,&lt;br/&gt;
+        assertEquals(HConstants.OperationStatusCode.SANITY_CHECK_FAILURE, codes&lt;span class=&quot;error&quot;&gt;&amp;#91;i&amp;#93;&lt;/span&gt;.getOperationStatusCode());&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn post-site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;/p&gt;


&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are 1 zombie test(s): 	at org.apache.hadoop.hbase.regionserver.TestHRegionWithInMemoryFlush.testWritesWhileScanning(TestHRegionWithInMemoryFlush.java:3779)&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15734//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15734//testReport/&lt;/a&gt;&lt;br/&gt;
Release Findbugs (version 2.0.3) 	warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15734//artifact/patchprocess/newFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15734//artifact/patchprocess/newFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15734//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15734//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;                Javadoc warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15734//artifact/patchprocess/patchJavadocWarnings.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15734//artifact/patchprocess/patchJavadocWarnings.txt&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15734//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15734//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14908118" author="eshcar" created="Fri, 25 Sep 2015 15:07:17 +0000"  >&lt;p&gt;Rebased - again!!&lt;/p&gt;</comment>
                            <comment id="14908371" author="hadoopqa" created="Fri, 25 Sep 2015 17:32:21 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12762390/HBASE-13408-trunk-v06.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12762390/HBASE-13408-trunk-v06.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit a33adf2f0b050e9cf9330fd5ab7e200a7dd27d6d.&lt;br/&gt;
  ATTACHMENT ID: 12762390&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 74 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.0 2.4.1 2.5.0 2.5.1 2.5.2 2.6.0 2.7.0 2.7.1)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 protoc&lt;/font&gt;.  The applied patch does not increase the total number of protoc compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 3 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 checkstyle&lt;/font&gt;.  The applied patch does not increase the total number of checkstyle errors&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces the following lines longer than 100:&lt;br/&gt;
    + * in a single read-only component. The &#226;&#128;&#156;old&#226;&#128;&#157; components are discarded when no scanner is reading&lt;br/&gt;
+  public FlushResult flush(boolean forceFlushAllStores, boolean forceFlushInsteadOfCompaction) throws IOException;&lt;br/&gt;
+    assertTrue(&quot;History size has not increased&quot;, oldHistorySize &amp;lt; hmc.getSnapshot().getCellsCount());&lt;br/&gt;
+   * &lt;/p&gt;
{@link HBaseTestingUtility#createWal(Configuration, Path, org.apache.hadoop.hbase.HRegionInfo)}
&lt;p&gt; because that method&lt;br/&gt;
+    GetTillDoneOrException(final int i, final byte[] r, final AtomicBoolean d, final AtomicInteger c) {&lt;br/&gt;
+      boolean res = region.checkAndMutate(row1, fam1, qf1, CompareFilter.CompareOp.EQUAL, new BinaryComparator(&lt;br/&gt;
+      res = region.checkAndMutate(row1, fam1, qf1, CompareFilter.CompareOp.EQUAL, new BinaryComparator(emptyVal),&lt;br/&gt;
+      res = region.checkAndMutate(row1, fam1, qf1, CompareFilter.CompareOp.EQUAL, new BinaryComparator(emptyVal),&lt;br/&gt;
+      res = region.checkAndMutate(row1, fam1, qf1, CompareFilter.CompareOp.EQUAL, new BinaryComparator(emptyVal),&lt;br/&gt;
+      res = region.checkAndMutate(row1, fam1, qf1, CompareFilter.CompareOp.EQUAL, new BinaryComparator(val1),&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn post-site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;/p&gt;


&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are 3 zombie test(s): 	at org.apache.hadoop.hbase.filter.TestFuzzyRowFilterEndToEnd.testEndToEnd(TestFuzzyRowFilterEndToEnd.java:143)&lt;br/&gt;
	at org.apache.hadoop.hbase.client.TestFromClientSide.testUpdates(TestFromClientSide.java:3498)&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15740//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15740//testReport/&lt;/a&gt;&lt;br/&gt;
Release Findbugs (version 2.0.3) 	warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15740//artifact/patchprocess/newFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15740//artifact/patchprocess/newFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15740//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15740//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;  Javadoc warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15740//artifact/patchprocess/patchJavadocWarnings.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15740//artifact/patchprocess/patchJavadocWarnings.txt&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/15740//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/15740//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14908550" author="eshcar" created="Fri, 25 Sep 2015 19:25:14 +0000"  >&lt;blockquote&gt;&lt;p&gt;Under which scenario(s) would this method be inefficient ?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;When the memstore needs to build the Cell Set by traversing all cells in the segment.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I thought the compaction pipeline would generate immutable segments ?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;You are right, this is a typo in the document. The compaction pipeline can generate different type of &lt;b&gt;immutable&lt;/b&gt; segments like HFile format.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Would the above be done in a future patch or different JIRA ?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, we believe it should be implemented as a different task.&lt;/p&gt;</comment>
                            <comment id="14934289" author="yuzhihong@gmail.com" created="Mon, 28 Sep 2015 23:02:06 +0000"  >&lt;p&gt;&lt;a href=&quot;https://reviews.apache.org/r/37354/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/37354/&lt;/a&gt; has patch v5.&lt;/p&gt;

&lt;p&gt;Mind uploading patch v6 ?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="14935051" author="anastas" created="Tue, 29 Sep 2015 12:04:15 +0000"  >&lt;p&gt;The recent version was uploaded for review in the new review board. Thanks!&lt;/p&gt;</comment>
                            <comment id="14938285" author="yuzhihong@gmail.com" created="Wed, 30 Sep 2015 19:03:28 +0000"  >&lt;p&gt;I downloaded patch from review board which was still ver 5.&lt;br/&gt;
Can you double check ?&lt;/p&gt;</comment>
                            <comment id="14938293" author="ebortnik" created="Wed, 30 Sep 2015 19:09:12 +0000"  >&lt;p&gt;Please see the review at &lt;a href=&quot;https://reviews.apache.org/r/38847/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/38847/&lt;/a&gt; (&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anastas&quot; class=&quot;user-hover&quot; rel=&quot;anastas&quot;&gt;Anastasia Braginsky&lt;/a&gt; uploaded it). &lt;/p&gt;</comment>
                            <comment id="14938758" author="yuzhihong@gmail.com" created="Wed, 30 Sep 2015 19:58:12 +0000"  >&lt;p&gt;I was looking at &lt;a href=&quot;https://reviews.apache.org/r/37354/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://reviews.apache.org/r/37354/&lt;/a&gt; where previous review comments reside.&lt;/p&gt;

&lt;p&gt;Please upload v6 to the above review board.&lt;/p&gt;</comment>
                            <comment id="14939562" author="anastas" created="Thu, 1 Oct 2015 09:22:30 +0000"  >&lt;p&gt;Eshcar is OOO now, and since she started the review board, we could only post the new patch to a new board. We&apos;ll post early next week. &lt;br/&gt;
There is no big difference between v5 and v6, v6 was to catch up with trunk.&lt;/p&gt;</comment>
                            <comment id="14974308" author="eshcar" created="Mon, 26 Oct 2015 14:43:42 +0000"  >&lt;p&gt;Attaching a new patch after rebase and code review changes.&lt;br/&gt;
One of the changes in the code is aligning the initialization of the memstore with the memstore class name configuration setting. To create a compacted memstore one needs to configure the hbase with&lt;br/&gt;
&amp;lt;code&amp;gt;&lt;br/&gt;
hbase.regionserver.memstore.class=org.apache.hadoop.hbase.regionserver.CompactedMemStore&lt;br/&gt;
&amp;lt;code&amp;gt;&lt;/p&gt;

&lt;p&gt;In addition, we reproduced the results of the benchmarks for the master code (new and original) measured in different settings and workloads. Report is attached.&lt;/p&gt;</comment>
                            <comment id="14974383" author="eshcar" created="Mon, 26 Oct 2015 15:27:05 +0000"  >&lt;p&gt;Following a comment in the Jira the compacted memstore configuration is now disconnected from the in-memory column family configuration setting; instead it can be set at the region server level by setting the memstore class name attribute. We are open to suggestions on how it would be best to set the memstore at each region, and specifically to add an additional column family attribute.&lt;/p&gt;

&lt;p&gt;In parallel, we should discuss the optimal way to push this branch into trunk after we&apos;ve handled all major concerns that were raised so far.&lt;/p&gt;</comment>
                            <comment id="14974684" author="hadoopqa" created="Mon, 26 Oct 2015 18:03:49 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12768731/HBASE-13408-trunk-v07.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12768731/HBASE-13408-trunk-v07.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit 8a2cef3315516501627c7a30bdcf989b12a32303.&lt;br/&gt;
  ATTACHMENT ID: 12768731&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 74 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.0 2.4.1 2.5.0 2.5.1 2.5.2 2.6.0 2.6.1 2.7.0 2.7.1)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 protoc&lt;/font&gt;.  The applied patch does not increase the total number of protoc compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 4 warning messages.&lt;/p&gt;

&lt;p&gt;                &lt;font color=&quot;red&quot;&gt;-1 checkstyle&lt;/font&gt;.  The applied patch generated 1754 checkstyle errors (more than the master&apos;s current 1732 errors).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces the following lines longer than 100:&lt;br/&gt;
    + * in a single read-only component. The &#226;&#128;&#156;old&#226;&#128;&#157; components are discarded when no scanner is reading&lt;br/&gt;
+  public FlushResult flush(boolean forceFlushAllStores, boolean forceFlushInsteadOfCompaction) throws IOException;&lt;br/&gt;
+    assertTrue(&quot;History size has not increased&quot;, oldHistorySize &amp;lt; hmc.getSnapshot().getCellsCount());&lt;br/&gt;
+   * &lt;/p&gt;
{@link HBaseTestingUtility#createWal(Configuration, Path, org.apache.hadoop.hbase.HRegionInfo)}
&lt;p&gt; because that method&lt;br/&gt;
+    GetTillDoneOrException(final int i, final byte[] r, final AtomicBoolean d, final AtomicInteger c) {&lt;br/&gt;
+      boolean res = region.checkAndMutate(row1, fam1, qf1, CompareFilter.CompareOp.EQUAL, new BinaryComparator(&lt;br/&gt;
+      res = region.checkAndMutate(row1, fam1, qf1, CompareFilter.CompareOp.EQUAL, new BinaryComparator(emptyVal),&lt;br/&gt;
+      res = region.checkAndMutate(row1, fam1, qf1, CompareFilter.CompareOp.EQUAL, new BinaryComparator(emptyVal),&lt;br/&gt;
+      res = region.checkAndMutate(row1, fam1, qf1, CompareFilter.CompareOp.EQUAL, new BinaryComparator(emptyVal),&lt;br/&gt;
+      res = region.checkAndMutate(row1, fam1, qf1, CompareFilter.CompareOp.EQUAL, new BinaryComparator(val1),&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn post-site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.regionserver.TestHRegion&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.TestWalAndCompactedMemstoreFlush&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16229//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16229//testReport/&lt;/a&gt;&lt;br/&gt;
Release Findbugs (version 2.0.3) 	warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16229//artifact/patchprocess/newFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16229//artifact/patchprocess/newFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16229//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16229//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;                Javadoc warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16229//artifact/patchprocess/patchJavadocWarnings.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16229//artifact/patchprocess/patchJavadocWarnings.txt&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16229//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16229//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14974990" author="yuzhihong@gmail.com" created="Mon, 26 Oct 2015 20:38:12 +0000"  >&lt;p&gt;Can you check unit test failures ?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="14975124" author="yuzhihong@gmail.com" created="Mon, 26 Oct 2015 21:28:08 +0000"  >&lt;p&gt;&lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16229//testReport/org.apache.hadoop.hbase.regionserver/TestHRegion/testReverseScanner_StackOverflow/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16229//testReport/org.apache.hadoop.hbase.regionserver/TestHRegion/testReverseScanner_StackOverflow/&lt;/a&gt; revealed StackOverflow error due to recursive call of seekToPreviousRow().&lt;/p&gt;</comment>
                            <comment id="14976200" author="eshcar" created="Tue, 27 Oct 2015 10:36:05 +0000"  >&lt;p&gt;We were able to find the cause of the TestHRegion failure.&lt;br/&gt;
There were some changes to the code implementing memstore scans that were applied to the default memstore scanner. In master this code resides in the DefaultMemStore.java file, while in our patch we extracted this code into a different file MutableCellSetSegmentScanner.java. &lt;br/&gt;
This case demonstrates the fact that in such a major refactoring Jira tracking all relevant changes when rebasing is very hard to do, we are at a risk of such changes occurring each time we rebase. &lt;/p&gt;

&lt;p&gt;For a long time now there were no serious discussion regarding the contribution of this Jira and the fundamental ideas at the base of the code.&lt;br/&gt;
What are the main reasons holding this Jira from being pushed into master?&lt;/p&gt;</comment>
                            <comment id="14976620" author="yuzhihong@gmail.com" created="Tue, 27 Oct 2015 16:04:00 +0000"  >&lt;p&gt;I understand the amount of work involved in rebasing half MB patch.&lt;br/&gt;
Thanks for your patience.&lt;/p&gt;

&lt;p&gt;The patch is steered in the right direction.&lt;br/&gt;
I hope after a few more reviews this can land.&lt;/p&gt;</comment>
                            <comment id="14977622" author="hadoopqa" created="Wed, 28 Oct 2015 02:57:59 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12769116/HBASE-13408-trunk-v08.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12769116/HBASE-13408-trunk-v08.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit 0e6dd3257b1bebe3e12c84aace59dd9cf0dcac2b.&lt;br/&gt;
  ATTACHMENT ID: 12769116&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 74 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.0 2.4.1 2.5.0 2.5.1 2.5.2 2.6.0 2.6.1 2.7.0 2.7.1)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 protoc&lt;/font&gt;.  The applied patch does not increase the total number of protoc compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 5 warning messages.&lt;/p&gt;

&lt;p&gt;                &lt;font color=&quot;red&quot;&gt;-1 checkstyle&lt;/font&gt;.  The applied patch generated 1735 checkstyle errors (more than the master&apos;s current 1732 errors).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces the following lines longer than 100:&lt;br/&gt;
    + * in a single read-only component. The &#226;&#128;&#156;old&#226;&#128;&#157; components are discarded when no scanner is reading&lt;br/&gt;
+      boolean isReadOnly, Durability durability, WAL wal, boolean[] compactedMemStore, byte[]... families)&lt;br/&gt;
+   * &lt;/p&gt;
{@link HBaseTestingUtility#createWal(Configuration, Path, org.apache.hadoop.hbase.HRegionInfo)}
&lt;p&gt; because that method&lt;br/&gt;
+  public static final TableName TABLENAME = TableName.valueOf(&quot;TestWalAndCompactedMemstoreFlush&quot;, &quot;t1&quot;);&lt;br/&gt;
+        + &quot;, CompactedMemStore DEEP_OVERHEAD_PER_PIPELINE_ITEM is:&quot; + CompactedMemStore.DEEP_OVERHEAD_PER_PIPELINE_ITEM&lt;br/&gt;
+        + &quot;, the smallest sequence in CF1:&quot; + smallestSeqCF1PhaseII + &quot;, the smallest sequence in CF2:&quot;&lt;br/&gt;
+        + &quot;, the smallest sequence in CF1:&quot; + smallestSeqCF1PhaseIV + &quot;, the smallest sequence in CF2:&quot;&lt;br/&gt;
+        + &quot;. After additional inserts and last flush, the entire region size is:&quot; + region.getMemstoreSize()&lt;br/&gt;
+        + &quot;, the smallest sequence in CF1:&quot; + smallestSeqCF1PhaseIII + &quot;, the smallest sequence in CF2:&quot;&lt;br/&gt;
+        + &quot;, the smallest sequence in CF1:&quot; + smallestSeqCF1PhaseIV + &quot;, the smallest sequence in CF2:&quot;&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn post-site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16252//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16252//testReport/&lt;/a&gt;&lt;br/&gt;
Release Findbugs (version 2.0.3) 	warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16252//artifact/patchprocess/newFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16252//artifact/patchprocess/newFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16252//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16252//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;                Javadoc warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16252//artifact/patchprocess/patchJavadocWarnings.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16252//artifact/patchprocess/patchJavadocWarnings.txt&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16252//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16252//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14977783" author="eshcar" created="Wed, 28 Oct 2015 05:42:36 +0000"  >&lt;p&gt;The attached patch fixes the tests failures and adds support for setting compacted memstore through HColumnDescriptor methods:&lt;br/&gt;
String getMemStoreClassName()&lt;br/&gt;
HColumnDescriptor setMemStoreClass(String className)&lt;/p&gt;</comment>
                            <comment id="14978807" author="yuzhihong@gmail.com" created="Wed, 28 Oct 2015 17:22:51 +0000"  >&lt;p&gt;w.r.t. setting MemStore class per column family, can you add test(s) where table has 2 column families, one with traditional MemStore class, one with compacted MemStore class ?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="14978969" author="eshcar" created="Wed, 28 Oct 2015 18:30:21 +0000"  >&lt;p&gt;TestWalAndCompactedMemstoreFlush has tests which initialize a region with mixed types of memstore.&lt;/p&gt;</comment>
                            <comment id="14979287" author="yuzhihong@gmail.com" created="Wed, 28 Oct 2015 21:36:46 +0000"  >&lt;p&gt;I am making last pass on reviewboard.&lt;/p&gt;

&lt;p&gt;In next patch, please address line length warnings.&lt;/p&gt;</comment>
                            <comment id="14980339" author="anoop.hbase" created="Thu, 29 Oct 2015 12:25:04 +0000"  >&lt;p&gt;The default memstore impl (what we have today) will keep cells in memory and flush when request comes (as per reach of max size or global heap pressure).   When we say a new memstore impl which will do in memory compaction and keep more cell in memory for longer time  I would expect this to be purely a new memstore impl alone with out much affecting the other areas..  But on a pass over the RB, I can see we are touching many other areas adding new APIs around flush etc...  IMHO this should be avoided..  Like it is not good that an outside module tells Memstore to do in memory flush and in memory compaction and do disk flush.. It is an internal detail of that memstore impl.   &lt;br/&gt;
The new memstore impl has to decide till when to keep cells in a CSLM and when to do an in memory compaction and keep cells in serialized format within memory.  &lt;br/&gt;
On general this is the concern.&lt;/p&gt;</comment>
                            <comment id="14980597" author="eshcar" created="Thu, 29 Oct 2015 15:12:29 +0000"  >&lt;p&gt;Our initial design did not include new flush API. Following the comment by &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Apache9&quot; class=&quot;user-hover&quot; rel=&quot;Apache9&quot;&gt;Duo Zhang&lt;/a&gt; from July 30 and the discussion preceding it we introduced new APIs one for disk flush and one for in-memory flush. &lt;br/&gt;
In hind-sight, we believe this comment was in place, and making in-memory flush a first-class-citizen is the right decision. &lt;br/&gt;
Whether or not a new API is required, making an in-memory flush must involve decisions at a higher level, specifically using the region updatesLock while moving data around inside the memstore, as is the case with disk flush - and for good reason.&lt;/p&gt;</comment>
                            <comment id="14980955" author="stack" created="Thu, 29 Oct 2015 18:16:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=eshcar&quot; class=&quot;user-hover&quot; rel=&quot;eshcar&quot;&gt;Eshcar Hillel&lt;/a&gt;  Looking at Duo comments in this issue, he seems to be arguing the same as &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt; above, that in-memory compaction &amp;#8211; when and how &amp;#8211; should be done inside the MemStore implementation only. If I go back to July 30, he allows you have a point but even then is hoping you can keep logic contained.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;....making an in-memory flush must involve decisions at a higher level....&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The justification for the involvement of higher levels making decision on when to flush is that the updatesLock needs to be held. What if the MemStore had reference to the updatesLock? Would it then have all it needs to make decision on when to compact and the means for doing it?&lt;/p&gt;

&lt;p&gt;Do you have other examples of where the decision needs to be made at a higher level outside the bounds of the MemStore Implementation?&lt;/p&gt;

&lt;p&gt;Let me take a look at the RB patch.&lt;/p&gt;

&lt;p&gt;Does the design as is apply to the patch posted or has there been some drift?&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;

</comment>
                            <comment id="14981101" author="eshcar" created="Thu, 29 Oct 2015 19:24:58 +0000"  >&lt;p&gt;The updatesLock affects the performance of the entire region; holding it in exclusive mode should be reduced to the minimum possible time. Therefore, holding it exclusively is a decision to make at the region level. In our design we were very careful not to introduce any additional locks, and also not to introduce new code that acquires existing locks let alone in exclusive mode. We believe this design choice is imperative for keeping the overall performance of the system.  &lt;/p&gt;</comment>
                            <comment id="14987363" author="eshcar" created="Tue, 3 Nov 2015 14:33:40 +0000"  >&lt;p&gt;Hi All,&lt;br/&gt;
We compiled a new design document (attached) capturing all changes (we noticed there are many changes since the original design suggestion).&lt;br/&gt;
In this new design document the behavior of the compacted memstore is confined mainly to the scope of the memstore, however some minimal changes are done at the scope of the region level, in order to give compacted memstore some slack to manage the in-memory flushes and in-memory compaction.&lt;br/&gt;
Next we plan to prepare the patch; main changes with respect to current patch would be to remove most of the code changes at the region level, and allow compacted memstore have access to the region lock to apply in-memory flushes.&lt;/p&gt;</comment>
                            <comment id="14987470" author="ebortnik" created="Tue, 3 Nov 2015 15:33:38 +0000"  >&lt;p&gt;Part of the next patch will be configurable in-memory-compaction per-store property, unrelated to the in-memory property. &lt;/p&gt;

&lt;p&gt;General request - please speak up about any additional major issues now. We&apos;d prefer this re-design round be the final before landing the feature. &lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;</comment>
                            <comment id="14988099" author="stack" created="Tue, 3 Nov 2015 20:54:13 +0000"  >&lt;p&gt;Thanks for the update to the design doc. It is great.&lt;/p&gt;

&lt;p&gt;&quot;This may result in underutilization of the memory due to duplicate entries per row, for example, when hot data is continuously updated.&quot;&lt;/p&gt;

&lt;p&gt;Other reasons for compactions in memory would be to move data from an expensive, fat if-convenient data structure &amp;#8211; the skip list &amp;#8211; to a data structure that is more compact in memory and more efficient to access (can exploit the fact that it is read-only, can trigger the in-memory flush when memstore hits some &apos;small&apos; size &amp;#8211; should improve perf). The latter is especially pertinent in the case where a flush is encoded and/or compressed such that the in-memory representation may be, say 128MB, but then the hfile on disk is much smaller than this.  IIRC we have seen cases where it takes longer to pull an entry from a large skip list than it does from cache. We could also remove &apos;duplicates&apos; by coalescing increments, applying deletes to deleted data if present in memory.&lt;/p&gt;

&lt;p&gt;Downsides to in-memory compaction is that we carry a larger backlog of WALs making MTTR take longer.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Data is kept in memory for as long as possible, by periodically compacting the memstore content.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think the principal should be more that you will afford yourself the luxury of being able to make smarter decisions on when to flush (Keeping data in memory as long as possible could actual be detrimental over the long run).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;A flush call may interrupt an in&#173;progress compaction and flush to the disk part of the data.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The part that will be flushed is the &apos;compacted&apos; part? Just trying to understand better.&lt;/p&gt;

&lt;p&gt;On name of the config., I think it should be IN_MEMORY_COMPACTION rather than COMPACTED. We already have a compaction process. Add the IN_MEMORY prefix to show where it applies.  Also, this feature should be on by default. You might want to say that in the doc as being your intent. Lets prove it makes life better so we can indeed enable it by default.&lt;/p&gt;

&lt;p&gt;Can the in-memory flush use same code as the flush-to-disk flush? Ditto on compaction?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;. An additional flush&#173;total&#173;size is defined as the average of flush&#173;size and blocking&#173;flush&#173;size. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Pardon me, what is the above for?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;In case of FlushLargeStoresPolicy, the decision is based on the size of the active segment.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m not clear on when a flush to disk will happen. I get you need headroom for in-memory flush and compaction to run but can you be more clear on where the threshold for flush to disk is?  Thanks.&lt;/p&gt;

&lt;p&gt;What is a snapshot in this scheme? It is just the last segment in the pipeline? Each pipeline segment because an hfile? Or we have to do a merge sort on flush to make the hfile?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Upon in&#173;memory flush, we take advantage of the existing blocking mechanism &#173;&#173; the active
segment is pushed to the pipeline &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; holding the region updatesLockin exclusive mode.
Then, a compaction is applied at the background to all pipeline segments resulting in a single
immutable segment. This procedure is executed at the scope of the store level, and specifically
in the context of the compacted memstore.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Do we hold the region lock while we compact the in-memory segments on a column family? Every time a compaction runs, it compacts all segments in the pipeline?&lt;/p&gt;

&lt;p&gt;I&apos;m not sure I follow the approximation of oldest sequence id. Why does it have to to be an approximation? Can&apos;t we keep a running oldest sequenceid seen? (Removing it too if compactions remove the cell that is oldest &amp;#8211; I suppose this could complicate acccounting... how you find the next oldest). So, you have a map of timestamp to oldest sequenceid in the segment? And when a segment is flushed to disk, the next oldest becomes oldest edit in memory?&lt;/p&gt;

&lt;p&gt;Do you have a rig where you can try out your implementation apart from running it inside a regionserver?&lt;/p&gt;

&lt;p&gt;Should be CompactingMemStore rather than CompactedMemStore.&lt;/p&gt;

&lt;p&gt;The class diagram looks great.&lt;/p&gt;

&lt;p&gt;So, on design, we talking about adding one more thread &amp;#8211; a compacting thread &amp;#8211; per Store? Do we have to do this?  HBase has too many threads already. Minimally, these threads can be run by an executor so they don&apos;t live for ever while the process is up?  It could be trigger by an in-memory flush.&lt;/p&gt;

&lt;p&gt;On compactionpipeline, add rather than push-in and remove rather than pull-out?&lt;/p&gt;

&lt;p&gt;On MemstoreScanner, we are keeping the fact that the implementation is crossing Segments an internal implementation detail? +1 on making the MemStoreScanner first-class detached from DefaultMemStore.&lt;/p&gt;

&lt;p&gt;MemStoreCompactor&#8203; should not be first class, right? It should be internal to the CompactingMemStore implementation?&lt;/p&gt;

&lt;p&gt;Yeah, its fine if internally the kv sets go into a StoreSegment...but clients don&apos;t have to know this, right?&lt;/p&gt;

&lt;p&gt;How will you implement low priority compacting memstore? (Not important, just interested)&lt;/p&gt;

&lt;p&gt;We should add your seek and sequenceid to KeyValueScanner so you don&apos;t have to have them implement something else (we have too many tiers of classes already)? What have a set sequenceid rather than pass to the scanner on construction?  Same with the seek.&lt;/p&gt;

&lt;p&gt;Do you have a harness so you can run this little engine outside of a regionserver? Might make testing and proofing, debugging easier?&lt;/p&gt;

&lt;p&gt;I suppose you&apos;ll deliver a skiplist version first and then move on to work on in-memory storefile, a more compact in-memory representation?&lt;/p&gt;

&lt;p&gt;Design writeup is great. Thanks.  Let me review your last rb too... might help.&lt;/p&gt;





















</comment>
                            <comment id="14988156" author="stack" created="Tue, 3 Nov 2015 21:25:26 +0000"  >&lt;p&gt;I took a look at a bit of review board. I left some comments there. Seems like the whole notion of snapshot should not be exposed to the client. It is an implementation detail of the original memstore, the defaultmemstore, something that we should try not expose.&lt;/p&gt;</comment>
                            <comment id="14990234" author="eshcar" created="Wed, 4 Nov 2015 19:31:00 +0000"  >&lt;p&gt;Great comments and questions &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;.&lt;br/&gt;
We will work on improving the document and code along the lines you suggested and the code review. Meanwhile here are some answers and clarifications:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The part that will be flushed is the &apos;compacted&apos; part?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes. And specifically, it would be the tail of the compaction pipeline which is comprised of segments list.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;On name of the config., I think it should be IN_MEMORY_COMPACTION rather than COMPACTED&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We&#8217;ll change the name, however we feel it is better to have it off by default, at least until users/applications are fully aware of the implications of this feature.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Can the in-memory flush use same code as the flush-to-disk flush? Ditto on compaction?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Flush - no, compaction - yes.&lt;br/&gt;
In memory flush makes changes to in memory data structures, while disk flush writes to disk.&lt;br/&gt;
When compacted memstore fully supports HFile format, can share the same compaction code.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;what is the above (flush&#173;total&#173;size) for?&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;can you be more clear on where the threshold for flush to disk is?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Currently flush is called when memstore size reaches 128MB, however region can tolerate even larger memstore size before blocking the update operation. So there is lower bound for triggering a flush and an upper bound for triggering a flush while blocking update operations.&lt;br/&gt;
With flush-total-size we attempt to further refine these boundaries, and have a soft lower bound instead of a hard bound.&lt;br/&gt;
In the new solution region can tolerate memstore size larger than 128MB (but smaller than flush-total-size) before calling a flush to disk, knowing that the size is not necessarily monotonically increasing between flushes. We distinguish between the data that is in active segments (which are still bounded by 128MB) and overflow segments being compacted. The size of all data in memstore is bounded by flush-total-size, where flush-size &amp;lt; flush-total-size &amp;lt; flush-blocking size.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;What is a snapshot in this scheme? we have to do a merge sort on flush to make the hfile?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The snapshot is a single immutable segment that is &lt;b&gt;not&lt;/b&gt; subject to compaction. There is no need to do a merge sort on flush to disk.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Do we hold the region lock while we compact the in-memory segments on a column family? Every time a compaction runs, it compacts all segments in the pipeline?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;No - the lock is held only while making the changes to the in-memory data structures: removing the tail segment from the compaction pipeline and crossing it to snapshot.&lt;br/&gt;
Yes - currently a compacion compacts all segments in the pipeline.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I&apos;m not sure I follow the approximation of oldest sequence id.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This was explained in posts between july 23-july 30. Can explain this again if required.  &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Do you have a rig where you can try out your implementation apart from running it inside a regionserver?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;What do you mean by rig? If you mean benchmark environment then no. If you mean testing then these are included in the patch.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;we talking about adding one more thread &#8211; a compacting thread &#8211; per Store?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;In the new design, the threads are run by the region server executor.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;On MemstoreScanner, we are keeping the fact that the implementation is crossing Segments an internal implementation detail?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I suppose you&apos;ll deliver a skiplist version first and then move on to work on in-memory storefile, a more compact in-memory representation?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is a task that should definitely be completed; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-10713&quot; title=&quot;A MemStore implementation with in memory flushes to CellBlocks&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-10713&quot;&gt;&lt;del&gt;HBASE-10713&lt;/del&gt;&lt;/a&gt; is a good starting point.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Seems like the whole notion of snapshot should not be exposed to the client. It is an implementation detail of the original memstore, the defaultmemstore, something that we should try not expose.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Agree, however seems out of the scope of the current Jira which focuses on in-memory compaction.&lt;/p&gt;</comment>
                            <comment id="14998409" author="eshcar" created="Tue, 10 Nov 2015 11:07:19 +0000"  >&lt;p&gt;We attach a new patch which includes the changes required by the recent discussion.&lt;br/&gt;
Specifically, we removed (undo) some of the changes to the HRegion and FlushPolicy classes. We moved the code for triggering in memory flush into the compacting memstore implementation.&lt;br/&gt;
We excluded two changes:&lt;br/&gt;
(1) we did not remove the StoreSegmentScanner tier from the KeyValueScanner hierarchy as this would result in empty implementation (of the two methods we define here) in the other 5 concrete classes implementing the KeyValueScanner interface, which seems unnecessary.&lt;br/&gt;
(2) we did not remove the snapshot - this needs to be discussed in a different Jira; there are pros and cons, and it shouldn&#8217;t be decided without thorough discussion.&lt;/p&gt;</comment>
                            <comment id="14998594" author="hadoopqa" created="Tue, 10 Nov 2015 13:46:00 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12771526/HBASE-13408-trunk-v09.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12771526/HBASE-13408-trunk-v09.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit 112900d0425a8157b89041f0e353ebf5cc259c69.&lt;br/&gt;
  ATTACHMENT ID: 12771526&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 66 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.0 2.4.1 2.5.0 2.5.1 2.5.2 2.6.0 2.6.1 2.7.0 2.7.1)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 protoc&lt;/font&gt;.  The applied patch does not increase the total number of protoc compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 checkstyle&lt;/font&gt;.  The applied patch does not increase the total number of checkstyle errors&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 release audit&lt;/font&gt;.  The applied patch generated 1 release audit warnings (more than the master&apos;s current 0 warnings).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces the following lines longer than 100:&lt;br/&gt;
    +        // setting the inMemoryFlushInProgress flag again for the case this method is invoked directly&lt;br/&gt;
+      this.versionedList = pipeline.getVersionedList(); // get the list of segments from the pipeline&lt;br/&gt;
+      LOG.info(&quot;Starting the MemStore in-memory compaction for store &quot; + store.getColumnFamilyName());&lt;br/&gt;
+    this.cms = new CompactingMemStore(HBaseConfiguration.create(), CellComparator.COMPARATOR, store);&lt;br/&gt;
+        + region.getMemstoreSize() + &quot;, Memstore Total Size: &quot; + region.getMemstoreTotalSize() + &quot;\n\n&quot;;&lt;br/&gt;
+        region.put(new Put(row).addColumn(fam, Bytes.toBytes(&quot;qual&quot;), System.currentTimeMillis() + 2000,&lt;br/&gt;
+    while (((CompactingMemStore) region.getStore(FAMILY3).getMemStore()).isMemStoreFlushingInMemory())&lt;br/&gt;
+    while (((CompactingMemStore) region.getStore(FAMILY1).getMemStore()).isMemStoreFlushingInMemory())&lt;br/&gt;
+    while (((CompactingMemStore) region.getStore(FAMILY3).getMemStore()).isMemStoreFlushingInMemory())&lt;br/&gt;
+    while (((CompactingMemStore) region.getStore(FAMILY1).getMemStore()).isMemStoreFlushingInMemory())&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn post-site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.regionserver.TestWalAndCompactingMemStoreFlush&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16476//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16476//testReport/&lt;/a&gt;&lt;br/&gt;
Release audit warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16476//artifact/patchprocess/patchReleaseAuditWarnings.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16476//artifact/patchprocess/patchReleaseAuditWarnings.txt&lt;/a&gt;&lt;br/&gt;
Release Findbugs (version 2.0.3) 	warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16476//artifact/patchprocess/newFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16476//artifact/patchprocess/newFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16476//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16476//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;  Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16476//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16476//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14999480" author="hadoopqa" created="Tue, 10 Nov 2015 22:36:53 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12771605/HBASE-13408-trunk-v10.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12771605/HBASE-13408-trunk-v10.patch&lt;/a&gt;&lt;br/&gt;
  against master branch at commit 1a6ec1bac65fa04a30a57891fb66dd248f3bed9c.&lt;br/&gt;
  ATTACHMENT ID: 12771605&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 66 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop versions&lt;/font&gt;. The patch compiles with all supported hadoop versions (2.4.0 2.4.1 2.5.0 2.5.1 2.5.2 2.6.0 2.6.1 2.7.0 2.7.1)&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 protoc&lt;/font&gt;.  The applied patch does not increase the total number of protoc compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 checkstyle&lt;/font&gt;.  The applied patch does not increase the total number of checkstyle errors&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any  new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 release audit&lt;/font&gt;.  The applied patch generated 1 release audit warnings (more than the master&apos;s current 0 warnings).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn post-site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in .&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16482//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16482//testReport/&lt;/a&gt;&lt;br/&gt;
Release audit warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16482//artifact/patchprocess/patchReleaseAuditWarnings.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16482//artifact/patchprocess/patchReleaseAuditWarnings.txt&lt;/a&gt;&lt;br/&gt;
Release Findbugs (version 2.0.3) 	warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16482//artifact/patchprocess/newFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16482//artifact/patchprocess/newFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle Errors: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16482//artifact/patchprocess/checkstyle-aggregate.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16482//artifact/patchprocess/checkstyle-aggregate.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;  Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/16482//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/16482//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14999964" author="eshcar" created="Wed, 11 Nov 2015 05:39:28 +0000"  >&lt;p&gt;The patch is now available also on review board.&lt;/p&gt;

&lt;p&gt;I wasn&apos;t able to extract the audit warning. Can someone point out what the problem is? thanks&lt;/p&gt;</comment>
                            <comment id="14999971" author="yuzhihong@gmail.com" created="Wed, 11 Nov 2015 05:47:37 +0000"  >&lt;p&gt;Release audit is fixed now - not related to your patch. &lt;/p&gt;</comment>
                            <comment id="15006791" author="eshcar" created="Mon, 16 Nov 2015 15:32:34 +0000"  >&lt;p&gt;Hi all &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
Nothing else on our table.&lt;br/&gt;
Any feedback?&lt;br/&gt;
Patch is available on RB.&lt;br/&gt;
Considering release audit is unrelated to our patch last QA is &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;+1 overall&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; &lt;/p&gt;

&lt;p&gt;Thanks &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15009577" author="ebortnik" created="Tue, 17 Nov 2015 21:36:32 +0000"  >&lt;p&gt;Community - please review. &lt;/p&gt;</comment>
                            <comment id="15013119" author="ebortnik" created="Thu, 19 Nov 2015 08:12:25 +0000"  >&lt;p&gt;Sorry about the persistence ... &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tedyu&quot; class=&quot;user-hover&quot; rel=&quot;tedyu&quot;&gt;Ted Yu&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt; - please weigh in. You used to be passionate about this feature &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15023885" author="stack" created="Tue, 24 Nov 2015 06:57:58 +0000"  >&lt;blockquote&gt;&lt;p&gt;You used to be passionate about this feature&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The passion has not gone away... This could be an important enabling feature.. especially if we can get to in-memory hfile and smaller memstores....&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Specifically, we removed (undo) some of the changes to the HRegion and FlushPolicy classes. We moved the code for triggering in memory flush into the compacting memstore implementation.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Good.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;we did not remove the snapshot &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;You mean, the comment that snapshot is an implementation detail of the default implementation that should not be exposed outside of DefaultMemStore? If so, that is fine. Yes, a follow-on issue.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;we did not remove the StoreSegmentScanner tier from the KeyValueScanner hierarchy...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Not sure what this refers too... I&apos;ve been away from the patch too long.. let me look at the patch.&lt;/p&gt;</comment>
                            <comment id="15023894" author="stack" created="Tue, 24 Nov 2015 07:12:03 +0000"  >&lt;p&gt;Did the design doc get updated with justifications for this feature?  In particular principals like &apos;The data is kept in memory for as long as possible&apos;  or statements like this: &quot;...may help in some scenarios, however it might also add unnecessary overhead in other scenarios without any performance gains, like when there are no in&#173;memory duplicate records most of the time.&quot; We still think this last statement true? If this feature is only of use when in-memory duplicate records &amp;#8211; a relatively rare instance &amp;#8211; then there is a lot of code being added for this case. Can you go bigger? Can you come up with arguments that have it that this feature is advantageous 90% of the time. Above I talk of better perf because we&apos;ll be able to have the in-memory data in a more compact, perforrmant (read-only) format than having it in ConcurrentSkipList. Flushes could be faster if the format in memory is an hfile (especially if the hfile were offheap as came up in a recent offlist chat w/ &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt;). Can we come up with other reasons with why this is the bees knees? (&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt; you have input here boss?). Thanks. Let me look at the patch.&lt;/p&gt;</comment>
                            <comment id="15024910" author="stack" created="Tue, 24 Nov 2015 17:29:19 +0000"  >&lt;p&gt;Thanks for the design doc update.&lt;/p&gt;

&lt;p&gt;What do you lot think of the new &apos;principals&apos; (am asking the authors).&lt;/p&gt;

&lt;p&gt;We go from &quot;The data is kept in memory for as long as possible&quot; to instead, &quot;...&lt;span class=&quot;error&quot;&gt;&amp;#91;u&amp;#93;&lt;/span&gt;se the in&#173;memory space effectively, by periodically compacting the memstore content.&quot;&lt;/p&gt;

&lt;p&gt;We also talk of &apos;compaction&apos;. What do we mean by compaction? The removal of data that has been overwritten? Or making the data take up smaller space in RAM?  The latter is a fine objective but what are you thinking? At first there will be no compaction. We&apos;ll just introduce the segments and pipeline. Later we&apos;ll want to add in &apos;compaction&apos;. We&apos;ll expend CPU to change skip list to a more compact format. What should it be. We posit hfile or the blocks that will go into hfiles. Does that makes sense as an in memory data structure? If it does, good. If not, what should the in memory compacted format be? Have you done any exploration here?&lt;/p&gt;

&lt;p&gt;Do we have a sense of how much advantage there is to be had &apos;compacting&apos; segments in the pipeline?&lt;/p&gt;

&lt;p&gt;How do we ensure this feature is of benefit 90% of the time and not for some exotic use case where most of the data is being overwritten and the column families are &apos;in memory&apos;. Even then, do we have measure to see the improvement to be had?&lt;/p&gt;

&lt;p&gt;Let me look at the patch (smile). In fact, the above questions come of my trying to look at the patch. Thanks.&lt;/p&gt;
</comment>
                            <comment id="15025089" author="stack" created="Tue, 24 Nov 2015 18:48:19 +0000"  >&lt;p&gt;Reading patch, in_memory_flush seems like better name for this feature... &lt;/p&gt;

&lt;p&gt;Other observations having looked at the patch are that,  there is benefit here if only for the refactor that was done so could introduce pipeline and segment. You might consider getting in the enabling refactor first. It would make your patch smaller and piecemeal its delivery. Would be easier for reviewers to digest and you&apos;d have a win under your belt.&lt;/p&gt;

&lt;p&gt;Any numbers/metrics on this patch running against a dataset?&lt;/p&gt;

&lt;p&gt;Finished reviewing page #1. There are enough comments posted for the moment. Thanks.&lt;/p&gt;</comment>
                            <comment id="15025324" author="eshcar" created="Tue, 24 Nov 2015 20:38:12 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; we&apos;ll get back with answers to your comments/suggestions/review later on, just wanted to say that the evaluation results for the patch is attached (posted October 26), please take a look.&lt;/p&gt;</comment>
                            <comment id="15025366" author="stack" created="Tue, 24 Nov 2015 20:50:47 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=eshcar&quot; class=&quot;user-hover&quot; rel=&quot;eshcar&quot;&gt;Eshcar Hillel&lt;/a&gt; Thanks. I missed that. There is at least one case where there is a clear benefit (I can help w/ the latency spike). Hopefully we can have it so this feature is near always beneficial and if not that, that it is an enabler of other features that will show general benefit (We are on that path I believe).&lt;/p&gt;</comment>
                            <comment id="15025386" author="eshcar" created="Tue, 24 Nov 2015 20:57:57 +0000"  >&lt;p&gt;Latency spikes are from the evaluation we did with the 0.98 branch (posted July 14).&lt;br/&gt;
In the more recent evaluation we did we were able to identify the cause of the spikes and avoid it (anyway thanks for suggesting to help &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; ).&lt;br/&gt;
Without the spikes it is easier to see the benefit of the new feature.&lt;/p&gt;</comment>
                            <comment id="15028849" author="ebortnik" created="Thu, 26 Nov 2015 14:20:38 +0000"  >&lt;p&gt;Thanks for all the feedback. &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;, you actually point out two things. &lt;br/&gt;
1. Need to sharpen the feature focus. &lt;br/&gt;
2. Need to structure the change in a digestible way, in more than just one patch. &lt;/p&gt;

&lt;p&gt;Addressing your questions/suggestions.&lt;br/&gt;
1. The primary goal is speeding up data access, via eliminating redundancies (compacting) before the data is flushed to disk. The optimization is beneficial for workloads with medium-to-high locality of writes, for example workloads with medium-to-high key churn, like persistent messaging. It is not beneficial for all use cases because it requires more memory for memstores, and therefore eats into the cache memory. Following the community advice, we designed it as a CF-level attribute (non-default). The admin should know what he is doing. The secondary goal is reducing the memstore footprint, by storing immutable parts of it in RAM in serialized, and potentially compressed, format (e.g., in-memory HFile). Doing so reduces the memory-speed tradeoff. The current implementation achieves the first goal, and provides platform to implement the second goal easily. &lt;/p&gt;

&lt;p&gt;2. With that in mind, we suggest to start a new clean umbrella jira, and structure it as 3 subtasks (respectively, patches). (1) Infrastructure - refactoring of the MemStore hierarchy, including having StoreSegment as first-class citizen. (2) Implementation of CompactingMemstore, with non-optimized immutable segment implementation; this includes all (few) changes at the HRegion level, and  (3) in-memory HFile optimization (not implemented currently). The objective is landing the first two patches one after the other, while making the reviewers&apos; life easier (credit goes to &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;). The third patch could be implemented later, either by us or by someone else; it should not gate the second one though because that would defeat the purpose of having small, controllable changes. &lt;/p&gt;

&lt;p&gt;Does this make sense? Once we get a green light, we&apos;ll go restructure the current patch. &lt;/p&gt;</comment>
                            <comment id="15031369" author="stack" created="Mon, 30 Nov 2015 06:11:25 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ebortnik&quot; class=&quot;user-hover&quot; rel=&quot;ebortnik&quot;&gt;Edward Bortnikov&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;On 1., do you have a particular use that you are targeting? A particular app/user?&lt;/p&gt;

&lt;p&gt;On...&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The admin should know what he is doing.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think for many hbase deploys, the admin knows what they are doing but finding all the features and configs that are available is work that many admins do not have the time to figure and even when found, unless there is lots of hearsay that enabling the config helps their case, that others have had good success enabling the feature, they are often reluctant to enable the feature themselves (usually because they are overworked supporting hbase and many other subsubsystems more than for any other reason...or, there is lots of stuff in hbase and the hadoop space that has been added but is not well tested...)  Hence my argument for having the feature always on. If they are doing lots of overwrite, they get an improvement. If not, could we have it so it does not cost having it enabled? (Tall order I know). If always on, it will get exercise and we&apos;ll find the bugs. BTW, it is ok if it eats into cache especially if the StoreSegment soon converts to be a data structure that is fast lookup.&lt;/p&gt;

&lt;p&gt;Otherwise, 1. sounds great.&lt;/p&gt;

&lt;p&gt;2. sounds great too. Will be easier on all concerned getting the work contributed. Could we replace Snapshot with StoreSegment?  Yeah, someone of us maybe could have a go at step 3.&lt;/p&gt;

&lt;p&gt;Good by you too &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;Anoop Sam John&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="15031627" author="anoop.hbase" created="Mon, 30 Nov 2015 10:31:22 +0000"  >&lt;p&gt;Ya looks like a good approach..   With respect to memory this will help all when we have in memory HFile flush stuff as those cells will not have other java object overhead.  Till that level was/is our aim..   And then the off heaping stuff..  (As a next step Stack?)&lt;/p&gt;</comment>
                            <comment id="15031696" author="eshcar" created="Mon, 30 Nov 2015 12:02:53 +0000"  >&lt;p&gt;OK then we&apos;ll go for several steps.&lt;br/&gt;
I also assume this is an ok to open a new umbrella Jira for this purpose with a link back to this jira. &lt;/p&gt;</comment>
                            <comment id="15037825" author="eshcar" created="Thu, 3 Dec 2015 14:16:05 +0000"  >&lt;p&gt;Created new Jira &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14918&quot; title=&quot;In-Memory MemStore Flush and Compaction&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14918&quot;&gt;HBASE-14918&lt;/a&gt; with three sub-tasks.&lt;br/&gt;
Submitted patch for first refactoring task.&lt;br/&gt;
This Jira is EOL; if you wish to continue followING this issue please start watching &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14918&quot; title=&quot;In-Memory MemStore Flush and Compaction&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14918&quot;&gt;HBASE-14918&lt;/a&gt; (and/or &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14919&quot; title=&quot;Infrastructure refactoring for In-Memory Flush&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14919&quot;&gt;&lt;del&gt;HBASE-14919&lt;/del&gt;&lt;/a&gt;/&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14920&quot; title=&quot;Compacting Memstore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14920&quot;&gt;&lt;del&gt;HBASE-14920&lt;/del&gt;&lt;/a&gt;/&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14921&quot; title=&quot;Inmemory Compaction Optimizations; Segment Structure&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14921&quot;&gt;&lt;del&gt;HBASE-14921&lt;/del&gt;&lt;/a&gt;).&lt;/p&gt;</comment>
                            <comment id="15037831" author="eshcar" created="Thu, 3 Dec 2015 14:22:38 +0000"  >&lt;p&gt;This is an umbrella Jira continuing the current issue.&lt;/p&gt;</comment>
                            <comment id="15594231" author="anoop.hbase" created="Fri, 21 Oct 2016 06:24:15 +0000"  >&lt;p&gt;Dup of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-14918&quot; title=&quot;In-Memory MemStore Flush and Compaction&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-14918&quot;&gt;HBASE-14918&lt;/a&gt;.  &lt;/p&gt;</comment>
                            <comment id="15595991" author="stack" created="Fri, 21 Oct 2016 18:48:01 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ram_krish&quot; class=&quot;user-hover&quot; rel=&quot;ram_krish&quot;&gt;ramkrishna.s.vasudevan&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoopsamjohn&quot; class=&quot;user-hover&quot; rel=&quot;anoopsamjohn&quot;&gt;Anoop Sam John&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=eshcar&quot; class=&quot;user-hover&quot; rel=&quot;eshcar&quot;&gt;Eshcar Hillel&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ebortnik&quot; class=&quot;user-hover&quot; rel=&quot;ebortnik&quot;&gt;Edward Bortnikov&lt;/a&gt; and myself met last Weds morning, the 19th of October to chat about where we are all at on inmemory compaction. Here are some rough notes:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
1. Reiteration that inmemory compaction needs to be on all the time with no associated perf degradation and with minimal config required to get benefit.
2. Need more testing and with more variety (Zipfian so inmemory compaction gets a chance to shine). We&apos;ll all pitch in here.
3. When to merge (Eshcar &lt;span class=&quot;code-quote&quot;&gt;&quot;It is just a question of when..&quot;&lt;/span&gt;). Back and forth. Concern that current &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt; of merge on every flush is a &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt; that will make inmemory compaction look bad because it &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; sure generates loads of garbage. Suggestion to go to other extreme where we merge only at flush-to-disk letting the pipeline build up in memory.
4. We&apos;ll pick up CellChunkMap at the next meeting but meantime wukk revive a rumored existing umbrella issue. CCM is where we&apos;ll get biggest bang &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the buck so excited to get &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; done. Need to solve the cell-too-big-issue still. Maybe split its dev some between Y! and Intel/St.Ack... TBD.
5. Ram and Anoop fixed some GC issues in &lt;span class=&quot;code-quote&quot;&gt;&quot;HBASE-16608 Introducing the ability to merge ImmutableSegments without copy-compaction or SQM usage&quot;&lt;/span&gt; and will put up a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; version of patch w/ fixes. Generally agreed patch is close to commit.

The Y! crew are on holiday until next Tuesday.

Did the note to the dev list go up on state of inmemory compaction (after Tuesday -- smile).
...

The back-and-forth about when/how to merge will probably &lt;span class=&quot;code-keyword&quot;&gt;continue&lt;/span&gt; into HBase-16417; we have to keep looking &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the sweet spot. 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12540674">HBASE-5311</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12699803">HBASE-10713</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12478262">HBASE-3149</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12685435">HBASE-10201</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12917935">HBASE-14918</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12749830" name="HBASE-13408-trunk-v01.patch" size="264245" author="eshcar" created="Tue, 11 Aug 2015 12:52:42 +0000"/>
                            <attachment id="12751563" name="HBASE-13408-trunk-v02.patch" size="561582" author="eshcar" created="Thu, 20 Aug 2015 19:32:36 +0000"/>
                            <attachment id="12753740" name="HBASE-13408-trunk-v03.patch" size="556704" author="eshcar" created="Wed, 2 Sep 2015 10:59:33 +0000"/>
                            <attachment id="12762098" name="HBASE-13408-trunk-v04.patch" size="600251" author="eshcar" created="Thu, 24 Sep 2015 09:27:32 +0000"/>
                            <attachment id="12762309" name="HBASE-13408-trunk-v05.patch" size="621697" author="eshcar" created="Fri, 25 Sep 2015 02:50:29 +0000"/>
                            <attachment id="12762390" name="HBASE-13408-trunk-v06.patch" size="613588" author="eshcar" created="Fri, 25 Sep 2015 15:07:17 +0000"/>
                            <attachment id="12768731" name="HBASE-13408-trunk-v07.patch" size="612618" author="eshcar" created="Mon, 26 Oct 2015 14:43:42 +0000"/>
                            <attachment id="12769116" name="HBASE-13408-trunk-v08.patch" size="615560" author="eshcar" created="Tue, 27 Oct 2015 21:34:47 +0000"/>
                            <attachment id="12771526" name="HBASE-13408-trunk-v09.patch" size="628964" author="eshcar" created="Tue, 10 Nov 2015 11:07:19 +0000"/>
                            <attachment id="12771605" name="HBASE-13408-trunk-v10.patch" size="629202" author="eshcar" created="Tue, 10 Nov 2015 19:58:29 +0000"/>
                            <attachment id="12745246" name="HBaseIn-MemoryMemstoreCompactionDesignDocument-ver02.pdf" size="236822" author="eshcar" created="Tue, 14 Jul 2015 12:49:22 +0000"/>
                            <attachment id="12770329" name="HBaseIn-MemoryMemstoreCompactionDesignDocument-ver03.pdf" size="296673" author="eshcar" created="Tue, 3 Nov 2015 14:33:40 +0000"/>
                            <attachment id="12774083" name="HBaseIn-MemoryMemstoreCompactionDesignDocument-ver04.pdf" size="303277" author="anastas" created="Tue, 24 Nov 2015 15:40:31 +0000"/>
                            <attachment id="12709471" name="HBaseIn-MemoryMemstoreCompactionDesignDocument.pdf" size="304875" author="eshcar" created="Sun, 5 Apr 2015 13:40:28 +0000"/>
                            <attachment id="12745247" name="InMemoryMemstoreCompactionEvaluationResults.pdf" size="740614" author="eshcar" created="Tue, 14 Jul 2015 12:49:22 +0000"/>
                            <attachment id="12768732" name="InMemoryMemstoreCompactionMasterEvaluationResults.pdf" size="1488648" author="eshcar" created="Mon, 26 Oct 2015 14:43:42 +0000"/>
                            <attachment id="12751562" name="InMemoryMemstoreCompactionScansEvaluationResults.pdf" size="345300" author="eshcar" created="Thu, 20 Aug 2015 19:32:36 +0000"/>
                            <attachment id="12762097" name="StoreSegmentandStoreSegmentScannerClassHierarchies.pdf" size="126984" author="eshcar" created="Thu, 24 Sep 2015 09:27:32 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>18.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sun, 5 Apr 2015 14:33:24 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2nwc7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>