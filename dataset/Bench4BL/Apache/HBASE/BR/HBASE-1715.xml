<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 02 19:48:30 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-1715/HBASE-1715.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-1715] compaction failure in ScanWildcardColumnTracker.checkColumn</title>
                <link>https://issues.apache.org/jira/browse/HBASE-1715</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;I have at least one region that won&apos;t compact.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;hbase&amp;gt; status &apos;detailed&apos;
[...]
content,0b41cdd2ee9b36b0674ad423089800ba,1248257816633
     stores=3, storefiles=113, storefileSizeMB=1213, memstoreSizeMB=0, storefileIndexSizeMB=0
[...]
hbase&amp;gt; major_compact &apos;content&apos;
[...]
hbase&amp;gt; status &apos;detailed&apos;
[...]
content,0b41cdd2ee9b36b0674ad423089800ba,1248257816633
     stores=3, storefiles=113, storefileSizeMB=1213, memstoreSizeMB=0, storefileIndexSizeMB=0
[...]
hbase&amp;gt; major_compact &apos;content,0b41cdd2ee9b36b0674ad423089800ba,1248257816633&apos;
[...]
hbase&amp;gt; status &apos;detailed&apos;
[...]
content,0b41cdd2ee9b36b0674ad423089800ba,1248257816633
     stores=3, storefiles=113, storefileSizeMB=1213, memstoreSizeMB=0, storefileIndexSizeMB=0
[...]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;$ hadoop fs -ls /hbase/content/1226419153/content
Found 37 items
-rw-r--r--   2 hadoop supergroup   86422089 2009-07-24 16:11 /hbase/content/1226419153/content/1045181559873943545
-rw-r--r--   2 hadoop supergroup    7167852 2009-07-26 05:13 /hbase/content/1226419153/content/1225211885117827793
-rw-r--r--   2 hadoop supergroup       2678 2009-07-24 20:24 /hbase/content/1226419153/content/1275251824404920815
-rw-r--r--   2 hadoop supergroup   10288489 2009-07-26 02:16 /hbase/content/1226419153/content/1386224161790061095
-rw-r--r--   2 hadoop supergroup   16111798 2009-07-24 23:43 /hbase/content/1226419153/content/1454452327579297030
-rw-r--r--   2 hadoop supergroup   12650208 2009-07-26 23:31 /hbase/content/1226419153/content/1534514745508157864
-rw-r--r--   2 hadoop supergroup    6994590 2009-07-27 10:45 /hbase/content/1226419153/content/1706519919143970421
-rw-r--r--   2 hadoop supergroup   13449537 2009-07-26 20:53 /hbase/content/1226419153/content/2186668356269910871
-rw-r--r--   2 hadoop supergroup   10397457 2009-07-26 22:15 /hbase/content/1226419153/content/2292706332643873473
-rw-r--r--   2 hadoop supergroup    6481576 2009-07-27 05:59 /hbase/content/1226419153/content/2438489739664745000
-rw-r--r--   2 hadoop supergroup   10810191 2009-07-25 19:48 /hbase/content/1226419153/content/2538008511360230014
-rw-r--r--   2 hadoop supergroup   13877559 2009-07-27 18:26 /hbase/content/1226419153/content/2772019170563217117
-rw-r--r--   2 hadoop supergroup   12796040 2009-07-26 10:14 /hbase/content/1226419153/content/2902101782772083009
-rw-r--r--   2 hadoop supergroup    6541657 2009-07-27 01:06 /hbase/content/1226419153/content/3113808018684114931
-rw-r--r--   2 hadoop supergroup    8655428 2009-07-25 18:17 /hbase/content/1226419153/content/3817932211925236778
-rw-r--r--   2 hadoop supergroup    1445535 2009-07-27 16:10 /hbase/content/1226419153/content/4286233593585189878
-rw-r--r--   2 hadoop supergroup    9139508 2009-07-27 02:11 /hbase/content/1226419153/content/495340788313226264
-rw-r--r--   2 hadoop supergroup    3313459 2009-07-26 05:57 /hbase/content/1226419153/content/5167064731599803595
-rw-r--r--   2 hadoop supergroup    9473393 2009-07-26 14:44 /hbase/content/1226419153/content/5490426319631514899
-rw-r--r--   2 hadoop supergroup    9321224 2009-07-26 19:40 /hbase/content/1226419153/content/5790825797519034907
-rw-r--r--   2 hadoop supergroup   12171283 2009-07-27 12:20 /hbase/content/1226419153/content/6036401533248383324
-rw-r--r--   2 hadoop supergroup  824790136 2009-07-23 22:28 /hbase/content/1226419153/content/6211942192349190964
-rw-r--r--   2 hadoop supergroup    9905606 2009-07-27 07:45 /hbase/content/1226419153/content/6295275445036553977
-rw-r--r--   2 hadoop supergroup   23857510 2009-07-27 17:02 /hbase/content/1226419153/content/6535266251812885635
-rw-r--r--   2 hadoop supergroup    9177439 2009-07-26 11:21 /hbase/content/1226419153/content/6625735185665629662
-rw-r--r--   2 hadoop supergroup    6916543 2009-07-27 20:15 /hbase/content/1226419153/content/6934569497672884872
-rw-r--r--   2 hadoop supergroup    8818427 2009-07-27 13:48 /hbase/content/1226419153/content/7162767181372457089
-rw-r--r--   2 hadoop supergroup   12028925 2009-07-25 08:48 /hbase/content/1226419153/content/7254368961746328584
-rw-r--r--   2 hadoop supergroup   14695089 2009-07-27 09:16 /hbase/content/1226419153/content/728058506789102941
-rw-r--r--   2 hadoop supergroup    9154325 2009-07-27 03:43 /hbase/content/1226419153/content/7462549804082617977
-rw-r--r--   2 hadoop supergroup   22295283 2009-07-27 21:46 /hbase/content/1226419153/content/7498645200757573769
-rw-r--r--   2 hadoop supergroup    5414671 2009-07-27 15:27 /hbase/content/1226419153/content/758918234053985701
-rw-r--r--   2 hadoop supergroup   11260015 2009-07-26 08:16 /hbase/content/1226419153/content/7626050291010778604
-rw-r--r--   2 hadoop supergroup   11309116 2009-07-26 12:57 /hbase/content/1226419153/content/7704085331915902813
-rw-r--r--   2 hadoop supergroup    6326623 2009-07-26 17:58 /hbase/content/1226419153/content/7735737241739599956
-rw-r--r--   2 hadoop supergroup        832 2009-07-24 20:15 /hbase/content/1226419153/content/8170327402351444879
-rw-r--r--   2 hadoop supergroup   13480887 2009-07-26 16:32 /hbase/content/1226419153/content/890729481029340216
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Relevant nonstandard options:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hbase.hregion.max.filesize&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;1073741824&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12431554">HBASE-1715</key>
            <summary>compaction failure in ScanWildcardColumnTracker.checkColumn</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="apurtell">Andrew Purtell</assignee>
                                    <reporter username="apurtell">Andrew Purtell</reporter>
                        <labels>
                    </labels>
                <created>Tue, 28 Jul 2009 00:23:31 +0000</created>
                <updated>Sun, 13 Sep 2009 22:24:53 +0000</updated>
                            <resolved>Wed, 2 Sep 2009 22:25:09 +0000</resolved>
                                                    <fixVersion>0.20.0</fixVersion>
                    <fixVersion>0.90.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="12735858" author="apurtell" created="Tue, 28 Jul 2009 00:37:18 +0000"  >&lt;p&gt;The culprit:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2009-07-28 00:32:40,028 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Worker: MSG_REGION_MAJOR_COMPACT: content,0b41cdd2ee9b36b0674ad423089800ba,1248257816633
2009-07-28 00:32:40,028 DEBUG org.apache.hadoop.hbase.regionserver.CompactSplitThread: Compaction (major) requested for region content,0b41cdd2ee9b36b0674ad423089800ba,1248257816633/1226419153 because: MSG_REGION_MAJOR_COMPACT
2009-07-28 00:32:40,029 INFO org.apache.hadoop.hbase.regionserver.HRegion: Starting major compaction on region content,0b41cdd2ee9b36b0674ad423089800ba,1248257816633
2009-07-28 00:32:40,140 DEBUG org.apache.hadoop.hbase.regionserver.Store: Started compaction of 38 file(s)  into /hbase/content/compaction.dir/1226419153/7891145528453156195
2009-07-28 00:32:40,165 INFO org.apache.hadoop.util.NativeCodeLoader: Loaded the native-hadoop library
2009-07-28 00:32:40,166 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded &amp;amp; initialized native-zlib library
2009-07-28 00:32:40,167 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor
2009-07-28 00:32:41,847 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor
2009-07-28 00:32:49,677 ERROR org.apache.hadoop.hbase.regionserver.CompactSplitThread: Compaction failed for region content,0b41cdd2ee9b36b0674ad423089800ba,1248257816633
java.lang.RuntimeException: ScanWildcardColumnTracker.checkColumn ran into a column actually smaller than the previous column!
	at org.apache.hadoop.hbase.regionserver.ScanWildcardColumnTracker.checkColumn(ScanWildcardColumnTracker.java:89)
	at org.apache.hadoop.hbase.regionserver.ScanQueryMatcher.match(ScanQueryMatcher.java:172)
	at org.apache.hadoop.hbase.regionserver.StoreScanner.next(StoreScanner.java:157)
	at org.apache.hadoop.hbase.regionserver.Store.compact(Store.java:869)
	at org.apache.hadoop.hbase.regionserver.Store.compact(Store.java:730)
	at org.apache.hadoop.hbase.regionserver.HRegion.compactStores(HRegion.java:776)
	at org.apache.hadoop.hbase.regionserver.HRegion.compactStores(HRegion.java:729)
	at org.apache.hadoop.hbase.regionserver.CompactSplitThread.run(CompactSplitThread.java:104)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So how does one fix this condition?&lt;/p&gt;</comment>
                            <comment id="12735864" author="apurtell" created="Tue, 28 Jul 2009 00:45:58 +0000"  >&lt;p&gt;Raising priority as this is both effective data loss and an occurrence &quot;in the wild&quot; of a condition the author of ScanWildcardColumnTracker thought should be impossible. &lt;/p&gt;</comment>
                            <comment id="12735866" author="stack" created="Tue, 28 Jul 2009 00:46:54 +0000"  >&lt;p&gt;Can you fix the exception so it prints out at least the row and file its currently on?&lt;/p&gt;

&lt;p&gt;Then use ./bin/hbase org.apache.hadoop.hbase.io.hfile.HFile to print out that file and see if actually out of order.&lt;/p&gt;</comment>
                            <comment id="12735867" author="stack" created="Tue, 28 Jul 2009 00:47:24 +0000"  >&lt;p&gt;You could copy the region and operate it in another instance of hbase?&lt;/p&gt;</comment>
                            <comment id="12735872" author="apurtell" created="Tue, 28 Jul 2009 01:06:04 +0000"  >&lt;p&gt;@Stack: The values are coming out of the KeyValueHeap so I don&apos;t see immediately how to narrow down any particular file or memstore. I am going to try a patch which catches the exception and continues on with QueryMatcher.MatchCode.INCLUDE. &lt;/p&gt;</comment>
                            <comment id="12735879" author="apurtell" created="Tue, 28 Jul 2009 01:19:09 +0000"  >&lt;p&gt;The attached patch allowed compaction to complete and the region to split. An exception was only thrown once, so there was a single case only of the problem. &lt;/p&gt;</comment>
                            <comment id="12735887" author="apurtell" created="Tue, 28 Jul 2009 01:48:35 +0000"  >&lt;p&gt;With more logging:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2009-07-28 01:45:29,427 WARN org.apache.hadoop.hbase.regionserver.StoreScanner: exception in QueryMatcher, continuing with INCLUDE: java.lang.RuntimeException: ScanWildcardColumnTracker.checkColumn ran into a column actually smaller than the previous column!
	at org.apache.hadoop.hbase.regionserver.ScanWildcardColumnTracker.checkColumn(ScanWildcardColumnTracker.java:89)
	at org.apache.hadoop.hbase.regionserver.ScanQueryMatcher.match(ScanQueryMatcher.java:172)
	at org.apache.hadoop.hbase.regionserver.StoreScanner.next(StoreScanner.java:162)
	at org.apache.hadoop.hbase.regionserver.Store.compact(Store.java:869)
	at org.apache.hadoop.hbase.regionserver.Store.compact(Store.java:730)
	at org.apache.hadoop.hbase.regionserver.HRegion.compactStores(HRegion.java:776)
	at org.apache.hadoop.hbase.regionserver.HRegion.compactStores(HRegion.java:729)
	at org.apache.hadoop.hbase.regionserver.CompactSplitThread.run(CompactSplitThread.java:104)

2009-07-28 01:45:29,427 WARN org.apache.hadoop.hbase.regionserver.StoreScanner:   row=d02a3326b884ab60274576209f6fb42f
2009-07-28 01:45:29,428 WARN org.apache.hadoop.hbase.regionserver.StoreScanner:   kv=d02a3326b884ab60274576209f6fb42f/url:https\x7Cwww.det.nsw.edu.au\x7C80\x7Chsctafex\x7Cservlet\x7CHscCourse\x7CCommand\x3DGetUnitDetail\x26VNAME\x3D\x252B\x26VUNIT_CODE\x3DLMFID5004A\x26VEXEMPTION_BASIS_NO\x3D0\x26VMODE\x3DC/1248465727983/Put/vlen=140
2009-07-28 01:45:29,428 WARN org.apache.hadoop.hbase.regionserver.StoreScanner:   last=d02a3326b884ab60274576209f6fb42f/content:raw/1248526709061/Put/vlen=7169
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12735888" author="apurtell" created="Tue, 28 Jul 2009 01:51:20 +0000"  >&lt;p&gt;Another one:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2009-07-28 01:46:15,046 WARN org.apache.hadoop.hbase.regionserver.StoreScanner: exception in QueryMatcher, continuing with INCLUDE: java.lang.RuntimeException: ScanWildcardColumnTracker.checkColumn ran into a column actually smaller than the previous column!
[...]
2009-07-28 01:46:15,047 WARN org.apache.hadoop.hbase.regionserver.StoreScanner:   row=d02a3326b884ab60274576209f6fb42f
2009-07-28 01:46:15,047 WARN org.apache.hadoop.hbase.regionserver.StoreScanner:   kv=d02a3326b884ab60274576209f6fb42f/url:https\x7Cwww.det.nsw.edu.au\x7C80\x7Chsctafex\x7Cservlet\x7CHscCourse\x7CCommand\x3DGetUnitDetail\x26VNAME\x3D\x252B\x26VUNIT_CODE\x3DLMFID5004A\x26VEXEMPTION_BASIS_NO\x3D0\x26VMODE\x3DC/1248465727983/Put/vlen=140
2009-07-28 01:46:15,047 WARN org.apache.hadoop.hbase.regionserver.StoreScanner:   last=d02a3326b884ab60274576209f6fb42f/info:mimetype/1248526709061/Put/vlen=29
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12735889" author="apurtell" created="Tue, 28 Jul 2009 01:57:10 +0000"  >&lt;p&gt;The schema:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;hbase(main):004:0&amp;gt; htd = admin.getTableDescriptor(Bytes.toBytes(&apos;content&apos;))
=&amp;gt; #&amp;lt;Java::OrgApacheHadoopHbase::HTableDescriptor:0x2d6f4ce0 @java_object=#&amp;lt;Java::JavaObject:0x66201d6d&amp;gt;&amp;gt;
hbase(main):005:0&amp;gt; htd.toString
=&amp;gt; &quot;{NAME =&amp;gt; &apos;content&apos;, FAMILIES =&amp;gt; [{NAME =&amp;gt; &apos;content&apos;, VERSIONS =&amp;gt; &apos;1&apos;, COMPRESSION =&amp;gt; &apos;GZ&apos;, TTL =&amp;gt; &apos;2147483647&apos;,
    BLOCKSIZE =&amp;gt; &apos;65536&apos;, IN_MEMORY =&amp;gt; &apos;false&apos;,BLOCKCACHE =&amp;gt; &apos;true&apos;}, 
{NAME =&amp;gt; &apos;info&apos;, VERSIONS =&amp;gt; &apos;100&apos;, COMPRESSION =&amp;gt; &apos;NONE&apos;, TTL =&amp;gt; &apos;2147483647&apos;, BLOCKSIZE =&amp;gt; &apos;65536&apos;,
    IN_MEMORY =&amp;gt; &apos;false&apos;, BLOCKCACHE =&amp;gt;  &apos;true&apos;}, 
{NAME =&amp;gt; &apos;url&apos;, VERSIONS =&amp;gt; &apos;1&apos;, COMPRESSION =&amp;gt; &apos;GZ&apos;, TTL =&amp;gt; &apos;2147483647&apos;, BLOCKSIZE =&amp;gt; &apos;65536&apos;, 
    IN_MEMORY =&amp;gt; &apos;false&apos;, BLOCKCACHE =&amp;gt; &apos;true&apos;}]}&quot;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12736045" author="stack" created="Tue, 28 Jul 2009 12:15:20 +0000"  >&lt;p&gt;As Ryan suggests, this looks like a Store that has both &apos;content&apos; and &apos;url&apos; in it (assuming StoreScanner is to scan a Store only &amp;#8211; then shouldn&apos;t be seeing two different column families in there?).&lt;/p&gt;</comment>
                            <comment id="12736103" author="apurtell" created="Tue, 28 Jul 2009 15:24:41 +0000"  >&lt;p&gt;So it&apos;s another instance of a KV stored into the wrong store. &lt;/p&gt;</comment>
                            <comment id="12736107" author="apurtell" created="Tue, 28 Jul 2009 15:34:59 +0000"  >&lt;p&gt;To get out from under this, I&apos;m going to combine my patches for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1638&quot; title=&quot;hfile has entry from wrong family&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1638&quot;&gt;&lt;del&gt;HBASE-1638&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1715&quot; title=&quot;compaction failure in ScanWildcardColumnTracker.checkColumn&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1715&quot;&gt;&lt;del&gt;HBASE-1715&lt;/del&gt;&lt;/a&gt; and also add code to commit any errant KVs found in the wrong store file into the correct store. That&apos;s a band aid not a solution but if you want the patch I can attach it here. Let me know.&lt;/p&gt;</comment>
                            <comment id="12736200" author="apurtell" created="Tue, 28 Jul 2009 18:24:09 +0000"  >&lt;p&gt;See combined patch -v3. Does some surgery to commit errant values to the correct store.&lt;/p&gt;


&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2009-07-28 18:16:45,949 INFO org.apache.hadoop.hbase.regionserver.HRegion: Starting major compaction on region content,9c3bfc73c37edabe01867ea9c4d8ef9e,1248750470366
2009-07-28 18:16:45,975 DEBUG org.apache.hadoop.hbase.regionserver.Store: Started compaction of 4 file(s)  into /hbase/content/compaction.dir/448268753, seqid=42603721
2009-07-28 18:17:19,017 WARN org.apache.hadoop.hbase.regionserver.Store: key with wrong family found in store: want=content, got=url: fixing
2009-07-28 18:18:13,646 DEBUG org.apache.hadoop.hbase.regionserver.Store: Completed major compaction of content; new storefile is hdfs://test01:50000/hbase/content/448268753/content/848892875550881398; store size is 521.4m
2009-07-28 18:18:13,646 DEBUG org.apache.hadoop.hbase.regionserver.Store: Started compaction of 4 file(s)  into /hbase/content/compaction.dir/448268753, seqid=42603721
2009-07-28 18:18:13,935 WARN org.apache.hadoop.hbase.regionserver.Store: key with wrong family found in store: want=info, got=url: fixing
2009-07-28 18:18:14,171 DEBUG org.apache.hadoop.hbase.regionserver.Store: Completed major compaction of info; new storefile is hdfs://test01:50000/hbase/content/448268753/info/2762972429935516536; store size is 4.3m
2009-07-28 18:18:14,171 DEBUG org.apache.hadoop.hbase.regionserver.Store: Started compaction of 4 file(s)  into /hbase/content/compaction.dir/448268753, seqid=42603721
2009-07-28 18:18:14,762 DEBUG org.apache.hadoop.hbase.regionserver.Store: Completed major compaction of url; new storefile is hdfs://test01:50000/hbase/content/448268753/url/7504151949043213112; store size is 1.5m
2009-07-28 18:18:14,779 INFO org.apache.hadoop.hbase.regionserver.HRegion: compaction completed on region content,9c3bfc73c37edabe01867ea9c4d8ef9e,1248750470366 in 1mins, 28sec
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;p&gt;After compaction completes, values are in the right place:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2009-07-28 18:20:11,865 INFO org.apache.hadoop.hbase.regionserver.HRegion: Starting major compaction on region content,9c3bfc73c37edabe01867ea9c4d8ef9e,1248750470366
2009-07-28 18:20:11,917 DEBUG org.apache.hadoop.hbase.regionserver.Store: Started compaction of 1 file(s)  into /hbase/content/compaction.dir/448268753, seqid=42603721
2009-07-28 18:21:35,491 DEBUG org.apache.hadoop.hbase.regionserver.Store: Completed major compaction of content; new storefile is hdfs://test01:50000/hbase/content/448268753/content/6780236562798836512; store size is 521.4m
2009-07-28 18:21:35,491 DEBUG org.apache.hadoop.hbase.regionserver.Store: Started compaction of 1 file(s)  into /hbase/content/compaction.dir/448268753, seqid=42603721
2009-07-28 18:21:35,757 DEBUG org.apache.hadoop.hbase.regionserver.Store: Completed major compaction of info; new storefile is hdfs://test01:50000/hbase/content/448268753/info/1792173903054446564; store size is 4.3m
2009-07-28 18:21:35,757 DEBUG org.apache.hadoop.hbase.regionserver.Store: Started compaction of 1 file(s)  into /hbase/content/compaction.dir/448268753, seqid=42603721
2009-07-28 18:21:36,182 DEBUG org.apache.hadoop.hbase.regionserver.Store: Completed major compaction of url; new storefile is hdfs://test01:50000/hbase/content/448268753/url/182518719874068306; store size is 1.5m
2009-07-28 18:21:36,198 INFO org.apache.hadoop.hbase.regionserver.HRegion: compaction completed on region content,9c3bfc73c37edabe01867ea9c4d8ef9e,1248750470366 in 1mins, 24sec
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Patch may break TestStore.&lt;/p&gt;</comment>
                            <comment id="12736203" author="jdcryans" created="Tue, 28 Jul 2009 18:28:54 +0000"  >&lt;p&gt;That means that much data goes at the wrong place currently right? This freaks me out!&lt;/p&gt;</comment>
                            <comment id="12736204" author="streamy" created="Tue, 28 Jul 2009 18:32:15 +0000"  >&lt;p&gt;Apurtell, did you have any log replays on your cluster before you saw the errant KV(s)?  I am running into this situation and it appeared immediately following some log replays.&lt;/p&gt;

&lt;p&gt;I&apos;m also getting a bunch of deleteFamilys in .META. for the row:  METAROW.  We&apos;re digging on what&apos;s causing that now, but also points to log replay issues.&lt;/p&gt;</comment>
                            <comment id="12736218" author="apurtell" created="Tue, 28 Jul 2009 18:47:25 +0000"  >&lt;p&gt;No, no log replays. I&apos;m adding additional logging in HRegion.put to see if I can track down where the errors are introduced.&lt;/p&gt;</comment>
                            <comment id="12736225" author="streamy" created="Tue, 28 Jul 2009 19:01:13 +0000"  >&lt;p&gt;It seems really unlikely to me that it&apos;s in the normal Put codepath.  It&apos;s fairly straightforward, and things are divided up by family from the client-side on... families are never mixed in a List or anything, ever, on the Put codepath... Hard to see where they&apos;d switch.  It seems more likely to me that this is happening during compactions, splits, assignment/reassignment, log replays, etc...  Though no stone should be left unturned.&lt;/p&gt;

&lt;p&gt;We should debug on the way in though, so we can see when it&apos;s actually happening.  I was writing a patch to check HFile.Writer to make sure it never wrote out a different family, but then saw this in the append() code:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.lastKeyBuffer != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.comparator.compare(&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.lastKeyBuffer, &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.lastKeyOffset,
            &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.lastKeyLength, key, offset, length) &amp;gt; 0) {
          &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; IOException(&lt;span class=&quot;code-quote&quot;&gt;&quot;Added a key not lexically larger than&quot;&lt;/span&gt; +
            &lt;span class=&quot;code-quote&quot;&gt;&quot; previous key=&quot;&lt;/span&gt; + Bytes.toString(key, offset, length) +
            &lt;span class=&quot;code-quote&quot;&gt;&quot;, lastkey=&quot;&lt;/span&gt; + Bytes.toString(&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.lastKeyBuffer, &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.lastKeyOffset,
                &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.lastKeyLength));
        }
      }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;That is being called for every KV that is appended to the HFile.Writer.  It seems that this would throw an exception if we ever had the wrong family intermixed with another one, however would not work at the edges if the wrong family was first or last (and appropriately ordered as to not be triggered here).&lt;/p&gt;</comment>
                            <comment id="12736232" author="stack" created="Tue, 28 Jul 2009 19:18:26 +0000"  >&lt;p&gt;I had to fix my fixup script because it wasn&apos;t finding a bad key that was first in an hfile, so at least once the bad key was first in the file.  Not sure its every time though.&lt;/p&gt;</comment>
                            <comment id="12736265" author="apurtell" created="Tue, 28 Jul 2009 20:21:14 +0000"  >&lt;p&gt;I&apos;m running with this local patch:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Index: src/java/org/apache/hadoop/hbase/regionserver/HRegion.java
===================================================================
--- src/java/org/apache/hadoop/hbase/regionserver/HRegion.java  (revision 798568
)
+++ src/java/org/apache/hadoop/hbase/regionserver/HRegion.java  (working copy)
@@ -1250,6 +1250,7 @@
           &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt; [] family = entry.getKey();
           checkFamily(family);
           List&amp;lt;KeyValue&amp;gt; puts = entry.getValue();
+          checkFamilyValues(family, puts);
           &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (updateKeys(puts, now)) {
             put(family, puts, writeToWAL);
           }
@@ -1262,6 +1263,22 @@
     }
   }

+  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; void checkFamilyValues(&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[] family, List&amp;lt;KeyValue&amp;gt; puts)
+      &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
+    &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (KeyValue kv: puts) {
+      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (Bytes.compareTo(
+          kv.getBuffer(),
+          kv.getFamilyOffset(),
+          kv.getFamilyLength(),
+          family,
+          0,
+          family.length) != 0) {
+        &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; IOException(&lt;span class=&quot;code-quote&quot;&gt;&quot;KV in edit set has wrong family: want=&quot;&lt;/span&gt; +
+          Bytes.toStringBinary(family) + &lt;span class=&quot;code-quote&quot;&gt;&quot;, got=&quot;&lt;/span&gt; +
+          Bytes.toStringBinary(kv.getFamily()));
+      }
+    }
+  }

   &lt;span class=&quot;code-comment&quot;&gt;//TODO, Think that gets/puts and deletes should be refactored a bit so that
&lt;/span&gt;   &lt;span class=&quot;code-comment&quot;&gt;//the getting of the lock happens before, so that you would just pass it into&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;and am watching the client logs. I may be wrong, but I don&apos;t think the family of every KV is sanity checked elsewhere. Just about all of the ~250 regions of my table have the error at hand, so I think the occurrence frequency here is high enough that if there is some client problem it should show up.&lt;/p&gt;</comment>
                            <comment id="12736301" author="stack" created="Tue, 28 Jul 2009 21:19:25 +0000"  >&lt;p&gt;Excellent Andrew. &lt;/p&gt;

&lt;p&gt;I keep trying to reproduce here...&lt;/p&gt;</comment>
                            <comment id="12736306" author="ryanobjc" created="Tue, 28 Jul 2009 21:24:03 +0000"  >&lt;p&gt;can you log the Put when it happens?&lt;/p&gt;</comment>
                            <comment id="12736312" author="streamy" created="Tue, 28 Jul 2009 21:28:52 +0000"  >&lt;p&gt;Apurtell, I&apos;m seeing this in production, on a running system.  Everything seems to be working, we don&apos;t do much scanning at all, almost everything is row-scoped.  I&apos;m seeing this during compactions.mostly, and very infrequently (but have seen it) from client requests.&lt;/p&gt;

&lt;p&gt;Your v3 patch cleans itself up.  Should I drop this in tonight when I&apos;m already planning on doing a restart?  How are things behaving now that you have it in?  I guess once you compact stuff, it will clean it up so will be fine, and then eventually the same bug will cause it to happen again...?&lt;/p&gt;</comment>
                            <comment id="12736327" author="stack" created="Tue, 28 Jul 2009 21:52:37 +0000"  >&lt;p&gt;I went back to look at the data rapleaf sent me.  The errant row from historian that was in the info storefile was in the middle of the flie, not at the edges.  Also, this entry was only in the info file, not in both.&lt;/p&gt;</comment>
                            <comment id="12736366" author="apurtell" created="Tue, 28 Jul 2009 23:46:48 +0000"  >&lt;p&gt;I don&apos;t see anything coming in from the client. It might still happen. Will continue to look. Next step. I&apos;m going to add logging to simple compactions to see if this might be happening when merging flushes. &lt;/p&gt;</comment>
                            <comment id="12736372" author="streamy" created="Wed, 29 Jul 2009 00:02:42 +0000"  >&lt;p&gt;Sounds good on simple compactions.  Couldn&apos;t you add a check way down in HFile.Writer so it would check all scenarios?&lt;/p&gt;

&lt;p&gt;I talked about doing it earlier, but then ryan corrected me... the KVs are always &quot;in order&quot; as defined by the comparator, even if different families.  Let me see if I can make a patch.&lt;/p&gt;</comment>
                            <comment id="12736376" author="streamy" created="Wed, 29 Jul 2009 00:12:34 +0000"  >&lt;p&gt;Adds a check of the family for each HFile.Writer.append(KV).  Note, only the KV method is ever used in non-tests.  This also relies on looking at the first KV to get the current family.&lt;/p&gt;</comment>
                            <comment id="12736391" author="apurtell" created="Wed, 29 Jul 2009 00:47:32 +0000"  >&lt;p&gt;Running now with jgray&apos;s patch.&lt;/p&gt;

&lt;p&gt;Most of my regions have gone through major compaction now and are repaired. &lt;/p&gt;</comment>
                            <comment id="12736392" author="streamy" created="Wed, 29 Jul 2009 00:48:06 +0000"  >&lt;p&gt;I need to verify I was running with v3 patch, but I&apos;m pretty sure I was and it did not seem to correct itself, still see the same exception.&lt;/p&gt;</comment>
                            <comment id="12736395" author="apurtell" created="Wed, 29 Jul 2009 00:54:30 +0000"  >&lt;p&gt;The v3 patch uses the HRegion.put() code path to attempt to place the value in the correct store, so can easily trip over the same bug as the cause of the trouble. It&apos;s working for me but is not meant to be a solution. &lt;/p&gt;</comment>
                            <comment id="12736398" author="streamy" created="Wed, 29 Jul 2009 00:56:33 +0000"  >&lt;p&gt;I just mean that I see the exception as normal, I don&apos;t see the attempt to fix.  It&apos;s probably me, let me verify.&lt;/p&gt;

&lt;p&gt;Please let us know if you run in to the exception, you seem to be the best bet right now at tracking this down &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="12736441" author="streamy" created="Wed, 29 Jul 2009 04:50:06 +0000"  >&lt;p&gt;Another version of the writerverify patch.  This one makes a bunch of noise in the logs, including enough to reconstitute data, but just returns / fails silent instead of throwing an exception.&lt;/p&gt;</comment>
                            <comment id="12736448" author="streamy" created="Wed, 29 Jul 2009 05:09:12 +0000"  >&lt;p&gt;New version that will reset the family if the problem occurs on the 1st or 2nd key.  This prevents the nasty case of the first KV being the wrong family and silently ignoring the rest of the appends.  Assumption is that there will only be 1 wrong KV (out of the first three, actually, could be more later on).&lt;/p&gt;</comment>
                            <comment id="12736474" author="apurtell" created="Wed, 29 Jul 2009 06:49:09 +0000"  >&lt;p&gt;I&apos;m running now with latest trunk plus failsilent-v2. Jgray&apos;s earlier patch did not trigger.&lt;/p&gt;</comment>
                            <comment id="12736521" author="apurtell" created="Wed, 29 Jul 2009 08:04:41 +0000"  >&lt;p&gt;A bit more about my test setup. I realize reviewing this issue that I failed to list the other nonstandard options I&apos;m currently using.&lt;/p&gt;

&lt;p&gt;4 node cluster, dual quad core CPUs, 4 GB RAM each&lt;br/&gt;
test01: namenode, master, Heritrix (web UI), JBoss minimal (for JNDI only), datanode, gmond, gmetad&lt;br/&gt;
test02: datanode, regionserver, Heritrix (engine), gmond&lt;br/&gt;
test03: datanode, regionserver, Heritrix (engine), gmond&lt;br/&gt;
test04: datanode, regionserver, Heritrix (engine), gmond&lt;/p&gt;

&lt;p&gt;Heritrix instances running with ~50-100 active threads each, pulling down and writing 10-20 MB/sec in the aggregate.&lt;/p&gt;

&lt;p&gt;Store split point at 1 GB.&lt;/p&gt;

&lt;p&gt;Regionserver heap at 2 GB. CMS GC, Ryan&apos;s option set. &lt;/p&gt;

&lt;p&gt;100 Zookeeper connections allowed per host.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;100 IPC handlers&lt;/b&gt; per region server.&lt;/p&gt;

&lt;p&gt;Don&apos;t gate memstore flusher unless more than 20 flushes are pending compaction.&lt;/p&gt;

&lt;p&gt;This experiment/evaluation is a write heavy high concurrency test. &lt;/p&gt;</comment>
                            <comment id="12736524" author="streamy" created="Wed, 29 Jul 2009 08:19:26 +0000"  >&lt;p&gt;Thanks apurtell.  Now, you are absolutely positive there were no log replays?  0.20 has a new thing now where under certain fail scenarios, a regionserver will close and then immediately reopen... this will still cause log replays to happen.&lt;/p&gt;

&lt;p&gt;I only ask because it&apos;s your single data point that leads me to believe &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1718&quot; title=&quot;Reuse of KeyValue during log replay could cause the wrong data to be used&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1718&quot;&gt;&lt;del&gt;HBASE-1718&lt;/del&gt;&lt;/a&gt; was not the cause of this cross-family bug... Otherwise, it does seem to be a plausible explanation.  Nonetheless, it was a serious bug that is now fixed.&lt;/p&gt;</comment>
                            <comment id="12736650" author="apurtell" created="Wed, 29 Jul 2009 14:42:15 +0000"  >&lt;p&gt;It&apos;s possible. It was a while before I noticed the trouble with compactions. I reset for a new experiment / settings change and cleared old logs at some point last week. I&apos;ve been running for 12 hours with checking in HFile Writer and it has not been triggered. Give it another 12 or 24 hours and I&apos;m fine to resolve this and the other issues linked to &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1716&quot; title=&quot;values stored into the wrong store&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1716&quot;&gt;&lt;del&gt;HBASE-1716&lt;/del&gt;&lt;/a&gt;. &lt;/p&gt;</comment>
                            <comment id="12736889" author="apurtell" created="Wed, 29 Jul 2009 23:00:53 +0000"  >&lt;p&gt;Still nothing after about 24 hours. Just to try and push things I altered my schema to use LZO instead of GZ compression, ran major compaction, and kept the writers going.&lt;/p&gt;</comment>
                            <comment id="12736893" author="apurtell" created="Wed, 29 Jul 2009 23:03:50 +0000"  >&lt;p&gt;Lowering priority. Should not stand in the way of a RC.&lt;/p&gt;</comment>
                            <comment id="12736898" author="apurtell" created="Wed, 29 Jul 2009 23:13:42 +0000"  >&lt;p&gt;Resolved because stack closed &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1638&quot; title=&quot;hfile has entry from wrong family&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1638&quot;&gt;&lt;del&gt;HBASE-1638&lt;/del&gt;&lt;/a&gt; in the belief that &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1718&quot; title=&quot;Reuse of KeyValue during log replay could cause the wrong data to be used&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1718&quot;&gt;&lt;del&gt;HBASE-1718&lt;/del&gt;&lt;/a&gt; was cause of this issue.  Will reopen if seen again.&lt;/p&gt;</comment>
                            <comment id="12750034" author="apurtell" created="Tue, 1 Sep 2009 18:44:22 +0000"  >&lt;p&gt;I don&apos;t think having ScanWildcardColumnTracker.checkColumn throw an exception which kills the store scanner is the right thing to do. Reopening to address this.&lt;/p&gt;</comment>
                            <comment id="12750527" author="stack" created="Wed, 2 Sep 2009 16:45:33 +0000"  >&lt;p&gt;What shall we do about this issue?  We just going to put in place the logging of this condition for the RC?  Or are we going to keep on with trying to figure how this thing arises?  In absence of reproducibility, I&apos;m for the former.&lt;/p&gt;</comment>
                            <comment id="12750604" author="apurtell" created="Wed, 2 Sep 2009 18:40:51 +0000"  >&lt;p&gt;I think the log-and-continue patch should go in for RC3, and this issue can be closed. &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1638&quot; title=&quot;hfile has entry from wrong family&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1638&quot;&gt;&lt;del&gt;HBASE-1638&lt;/del&gt;&lt;/a&gt; can be reopened to hunt down the root cause.&lt;/p&gt;</comment>
                            <comment id="12750643" author="stack" created="Wed, 2 Sep 2009 20:16:43 +0000"  >&lt;p&gt;So, we should commit: &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1715&quot; title=&quot;compaction failure in ScanWildcardColumnTracker.checkColumn&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1715&quot;&gt;&lt;del&gt;HBASE-1715&lt;/del&gt;&lt;/a&gt;-StoreFileScanner-hack.patch?  Its a test done on every append but its a byte level compare of a portion of a KV so should not be too bad.  I reviewed the patch and its fine by me.  Will reopen hbase-1638 when we get more data on this failure?&lt;/p&gt;</comment>
                            <comment id="12750675" author="apurtell" created="Wed, 2 Sep 2009 21:31:11 +0000"  >&lt;p&gt;@Stack: You must have been looking at the wrong patch. StoreFileScanner-hack.patch has no byte level compare of a KV in any diff hunk.&lt;/p&gt;</comment>
                            <comment id="12750688" author="stack" created="Wed, 2 Sep 2009 21:50:37 +0000"  >&lt;p&gt;Yes.  Wrong patch.&lt;/p&gt;

&lt;p&gt;+1 on applying StoreFileScanner-hack.patch logging at ERROR level condition where we see a &amp;lt; last KV.&lt;/p&gt;</comment>
                            <comment id="12750704" author="apurtell" created="Wed, 2 Sep 2009 22:25:09 +0000"  >&lt;p&gt;Committed to branch and trunk.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310010">
                    <name>Incorporates</name>
                                                                <inwardlinks description="is part of">
                                        <issuelink>
            <issuekey id="12431596">HBASE-1716</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12418274" name="HBASE-1715-StoreFileScanner-hack.patch" size="2012" author="apurtell" created="Tue, 1 Sep 2009 18:45:22 +0000"/>
                            <attachment id="12414691" name="HBASE-1715-v2.patch" size="1806" author="apurtell" created="Tue, 28 Jul 2009 01:48:35 +0000"/>
                            <attachment id="12414777" name="HBASE-1715-v3.patch" size="8169" author="apurtell" created="Tue, 28 Jul 2009 18:24:09 +0000"/>
                            <attachment id="12414842" name="HBASE-1715-writer-failsilent-v2.patch" size="1860" author="streamy" created="Wed, 29 Jul 2009 05:09:12 +0000"/>
                            <attachment id="12414839" name="HBASE-1715-writer-failsilent.patch" size="1553" author="streamy" created="Wed, 29 Jul 2009 04:50:05 +0000"/>
                            <attachment id="12414822" name="HBASE-1715-writerverify.patch" size="1407" author="streamy" created="Wed, 29 Jul 2009 00:12:34 +0000"/>
                            <attachment id="12414690" name="HBASE-1715.patch" size="1171" author="apurtell" created="Tue, 28 Jul 2009 01:19:09 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>7.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 28 Jul 2009 00:46:54 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>25934</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 14 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0heuv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>99669</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>