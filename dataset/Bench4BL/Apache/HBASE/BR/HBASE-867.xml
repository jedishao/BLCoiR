<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 02 20:22:39 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-867/HBASE-867.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-867] If millions of columns in a column family, hbase scanner won&apos;t come up</title>
                <link>https://issues.apache.org/jira/browse/HBASE-867</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Our Daniel has uploaded a table that has a column family with millions of columns in it.  He can get items from the table promptly specifying row and column.  Scanning is another matter.  Thread dumping I see we&apos;re stuck in the scanner constructor nexting through cells.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12403648">HBASE-867</key>
            <summary>If millions of columns in a column family, hbase scanner won&apos;t come up</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="streamy">Jonathan Gray</assignee>
                                    <reporter username="stack">stack</reporter>
                        <labels>
                    </labels>
                <created>Thu, 4 Sep 2008 00:06:09 +0000</created>
                <updated>Sun, 13 Sep 2009 22:24:14 +0000</updated>
                            <resolved>Wed, 17 Jun 2009 21:46:35 +0000</resolved>
                                                    <fixVersion>0.20.0</fixVersion>
                                        <due></due>
                            <votes>3</votes>
                                    <watches>4</watches>
                                                                <comments>
                            <comment id="12628210" author="stack" created="Thu, 4 Sep 2008 00:11:06 +0000"  >&lt;p&gt;It looks like we should be breaking out of the main while loop in the next method after we pass out a column match &amp;#8211; because store keys are sorted &amp;#8211; but then we fall on the next while loop which just nexts until we hit the next row.&lt;/p&gt;

&lt;p&gt;Normally this is fine, if only a few columns in a row, but in Daniel&apos;s case its taking forever to move to the next row.&lt;/p&gt;

&lt;p&gt;Also, we won&apos;t split a region if only one row so its looking like his store files are large, 1G.&lt;/p&gt;</comment>
                            <comment id="12628374" author="stack" created="Thu, 4 Sep 2008 16:28:49 +0000"  >&lt;p&gt;To be clear, if thousands of columns plus &amp;#8211; i.e. a canonical usage &amp;#8211; hbase does not work.  Here is some of the problem code form StoreFileScanner#next:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
...
          &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; ((keys[i] != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;)
              &amp;amp;&amp;amp; (Bytes.compareTo(keys[i].getRow(), viableRow.getRow()) == 0)) {

            &lt;span class=&quot;code-comment&quot;&gt;// If we are doing a wild card match or there are multiple matchers
&lt;/span&gt;            &lt;span class=&quot;code-comment&quot;&gt;// per column, we need to scan all the older versions of &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; row
&lt;/span&gt;            &lt;span class=&quot;code-comment&quot;&gt;// to pick up the &lt;span class=&quot;code-keyword&quot;&gt;rest&lt;/span&gt; of the family members
&lt;/span&gt;            &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt;(!isWildcardScanner()
                &amp;amp;&amp;amp; !isMultipleMatchScanner()
                &amp;amp;&amp;amp; (keys[i].getTimestamp() != viableRow.getTimestamp())) {
              &lt;span class=&quot;code-keyword&quot;&gt;break&lt;/span&gt;;
            }

            &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (columnMatch(i)) {              
              &lt;span class=&quot;code-comment&quot;&gt;// We only want the first result &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; any specific family member
&lt;/span&gt;              &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt;(!results.containsKey(keys[i].getColumn())) {
                results.put(keys[i].getColumn(), 
                    &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Cell(vals[i], keys[i].getTimestamp()));
                insertedItem = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
              }
            } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
              &lt;span class=&quot;code-comment&quot;&gt;// Content is sorted.  If column no longer matches, &lt;span class=&quot;code-keyword&quot;&gt;break&lt;/span&gt;.
&lt;/span&gt;              &lt;span class=&quot;code-keyword&quot;&gt;break&lt;/span&gt;;
            }

            &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!getNext(i)) {
              closeSubScanner(i);
            }
          }

          &lt;span class=&quot;code-comment&quot;&gt;// Advance the current scanner beyond the chosen row, to
&lt;/span&gt;          &lt;span class=&quot;code-comment&quot;&gt;// a valid timestamp, so we&apos;re ready next time.
&lt;/span&gt;          &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; ((keys[i] != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) &amp;amp;&amp;amp;
              ((Bytes.compareTo(keys[i].getRow(), viableRow.getRow()) &amp;lt;= 0)
                  || (keys[i].getTimestamp() &amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.timestamp)
                  || (! columnMatch(i)))) {
            getNext(i);
          }
..
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The whiles find next row by getting cells until the row does not match.  If many columns per row, then that can take for ever (as its doing in Daniel&apos;s case).  Need to have a file format that has an index that says where next row is.  An option would say whether to get to next row by nexting or instead asking index.&lt;/p&gt;</comment>
                            <comment id="12628420" author="stack" created="Thu, 4 Sep 2008 18:19:05 +0000"  >&lt;p&gt;Marking this a critical issue.  Only fix that I see is new mapfile type that keeps an index of each row offset.&lt;/p&gt;</comment>
                            <comment id="12628421" author="stack" created="Thu, 4 Sep 2008 18:19:29 +0000"  >&lt;p&gt;Its critical because this is canonical usage-pattern.&lt;/p&gt;</comment>
                            <comment id="12643551" author="stack" created="Wed, 29 Oct 2008 17:49:50 +0000"  >&lt;p&gt;Going to take a look at doing this for 0.19.0 since its embarrassing we don&apos;t do the canonical use case.&lt;/p&gt;</comment>
                            <comment id="12648197" author="stack" created="Mon, 17 Nov 2008 17:39:08 +0000"  >&lt;p&gt;Moving to 0.20.0. Need access to the MapFile index to do this fix.  Currently its private.&lt;/p&gt;</comment>
                            <comment id="12675207" author="stack" created="Fri, 20 Feb 2009 01:24:31 +0000"  >&lt;p&gt;From #IRC, here is another case we need to be smarter about:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
01:13 &amp;lt; BenM&amp;gt;       keys[i] = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; HStoreKey(HConstants.EMPTY_BYTE_ARRAY, &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.store.getHRegionInfo());
01:13 &amp;lt; BenM&amp;gt;       &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (firstRow != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; &amp;amp;&amp;amp; firstRow.length != 0) {
01:13 &amp;lt; BenM&amp;gt;         &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (findFirstRow(i, firstRow)) {
01:13 &amp;lt; BenM&amp;gt;           &lt;span class=&quot;code-keyword&quot;&gt;continue&lt;/span&gt;;
01:13 &amp;lt; BenM&amp;gt;         }
01:13 &amp;lt; BenM&amp;gt;       }
01:13 &amp;lt; BenM&amp;gt;       &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (getNext(i)) {
01:13 &amp;lt; BenM&amp;gt;         &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (columnMatch(i)) {
01:13 &amp;lt; BenM&amp;gt;           &lt;span class=&quot;code-keyword&quot;&gt;break&lt;/span&gt;;
01:13 &amp;lt; BenM&amp;gt;         }
01:13 &amp;lt; BenM&amp;gt;       }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Its setting up scanners after store files have been changed.&lt;/p&gt;

&lt;p&gt;If lots of entries for rows we don&apos;t care about, then these iterations will take a long time.  Need to be smarter about the seek.&lt;/p&gt;</comment>
                            <comment id="12675234" author="bmaurer" created="Fri, 20 Feb 2009 04:15:20 +0000"  >&lt;p&gt;I confirmed that this code is what was causing crashes for me. What happened is that I had a MR job that would launch multiple scanners on a region that made updates to the same column family as they were scanning on (but not the same column). As a result, there were lots of processes that had to grep through all of the irrelevent inserts many times as flushes occurred.&lt;/p&gt;

&lt;p&gt;I think that this case could be fixed in 0.19.0, and furthermore I think the fix might actually clean up the code a lot:&lt;/p&gt;

&lt;p&gt;(10:58:18 PM) BenM: yeah&lt;br/&gt;
(10:58:21 PM) BenM: was just doing that&lt;br/&gt;
(10:58:30 PM) BenM: IMHO, this is a somewhat easier issue to fix&lt;br/&gt;
(10:58:38 PM) BenM: i think it could be done in a way that cleans up the code&lt;br/&gt;
(10:58:50 PM) BenM: right now, the code just scans through each of the map files&lt;br/&gt;
(10:59:02 PM) BenM: without regard to the relative key positions&lt;br/&gt;
(10:59:12 PM) BenM: i think it could use a priority queue so that it only works on the relevent files&lt;br/&gt;
(11:01:22 PM) St^Ack_: BenM: please expand, I don&apos;t follow exactly&lt;br/&gt;
(11:01:50 PM) BenM: lets say we have two map files&lt;br/&gt;
(11:02:09 PM) BenM: one with 1/foo:bar 2/foo:bar 3/foo:bar&lt;br/&gt;
(11:02:17 PM) BenM: (row/family:col)&lt;br/&gt;
(11:02:31 PM) BenM: and the other with 1000/blah:blah 1001/blah:blah&lt;br/&gt;
(11:02:39 PM) BenM: the curent logic is&lt;br/&gt;
(11:02:44 PM) BenM: for each map file:&lt;br/&gt;
(11:02:56 PM) BenM:    find the first potential row in this file&lt;br/&gt;
(11:03:08 PM) BenM: look at min(all potential rows)&lt;br/&gt;
(11:03:34 PM) BenM: the algorith should be:&lt;br/&gt;
(11:03:43 PM) BenM: q = new PriorityQueue()&lt;br/&gt;
(11:04:05 PM) BenM: for each map file: insert the HStoreKey of the first key in the file&lt;br/&gt;
(11:04:17 PM) BenM: while(k = q.pop()) &lt;/p&gt;
{
(11:04:37 PM) BenM:   if (k is intersting) break;
(11:04:37 PM) BenM:   advance k
(11:04:37 PM) BenM:   q.push(k)
(11:04:38 PM) BenM: }
&lt;p&gt;(11:05:00 PM) BenM: that way, we don&apos;t try to find a matching key in the larger rows&lt;/p&gt;</comment>
                            <comment id="12703744" author="streamy" created="Tue, 28 Apr 2009 17:08:58 +0000"  >&lt;p&gt;Would like to get this solved as part of 1249 issues.&lt;/p&gt;</comment>
                            <comment id="12707220" author="streamy" created="Fri, 8 May 2009 03:31:31 +0000"  >&lt;p&gt;The idea Ben describes above is part of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1249&quot; title=&quot;Rearchitecting of server, client, API, key format, etc for 0.20&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1249&quot;&gt;&lt;del&gt;HBASE-1249&lt;/del&gt;&lt;/a&gt;.  This issue will be resolved as part of 1249.&lt;/p&gt;</comment>
                            <comment id="12716922" author="streamy" created="Sat, 6 Jun 2009 21:48:20 +0000"  >&lt;p&gt;Issue is probably resolved, but I&apos;m going to continue testing.  It&apos;s not possible to create JUnit tests because the psuedo-distr. cluster falls over under load this high.&lt;/p&gt;

&lt;p&gt;First simple test (gets though, not scans... scans next):&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Generated 1 Puts in 3068ms
        1 rows, 8 bytes/row key
        1000000 columns/row, 8 bytes/column key
        8 bytes/column value
Inserted Put in 23295ms
Get0 (1000000 KVs) completed in 4031ms
Get1 (1000000 KVs) completed in 2300ms
Get2 (1000000 KVs) completed in 2831ms
Get3 (1000000 KVs) completed in 1707ms
Get4 (1000000 KVs) completed in 2588ms
Get5 (1000000 KVs) completed in 2671ms
Get6 (1000000 KVs) completed in 2442ms
Get7 (1000000 KVs) completed in 2560ms
Get8 (1000000 KVs) completed in 2462ms
Get9 (1000000 KVs) completed in 2822ms
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12717118" author="stack" created="Mon, 8 Jun 2009 02:08:14 +0000"  >&lt;p&gt;Whats above saying JGray? That you added single row with a million columns?  And then you did 10 gets and they took 2.5ms on average to complete?  Which column were you getting?&lt;/p&gt;

&lt;p&gt;Scans would be good to get numbers for.  That was reason for original filing.&lt;/p&gt;

&lt;p&gt;Good stuff.&lt;/p&gt;</comment>
                            <comment id="12720856" author="streamy" created="Wed, 17 Jun 2009 19:59:35 +0000"  >&lt;p&gt;I am doing tests for this issue on a 5+1 node cluster, each node is 2core/2gb and hosting two HDFS and two HBase instances (0.19 cluster still up but it&apos;s idle).&lt;/p&gt;

&lt;p&gt;Using a newer version of the HBench tool I posted in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1501&quot; title=&quot;Benchmark Tool for 0.20 API&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1501&quot;&gt;&lt;del&gt;HBASE-1501&lt;/del&gt;&lt;/a&gt;, I&apos;m able to run a number of different tests with high numbers of columns.&lt;/p&gt;

&lt;p&gt;My test is inserting 10 rows, each with 2M columns.  I do it in 200 rounds, each round I insert 10k columns in each of the 10 rows.&lt;/p&gt;

&lt;p&gt;Qualifiers are incremented binary longs (1 -&amp;gt; 2M), so 8 bytes.  Values are randomized binary data of fixed length.  By varying the size of the value (have tried between 8 and 32 bytes per value), I can get different behavior.  &lt;/p&gt;

&lt;p&gt;With not much memory to give the RS, I run into OOME problems when serializing the Result.  I&apos;m going to rerun tests at higher value sizes and get some clean logs to look at, making sure I have block caching disabled so it doesn&apos;t hog heap.&lt;/p&gt;

&lt;p&gt;However, with 8 byte values I&apos;m able to import without a problem (causes several splits, in the end we have 5 regions for the 10 rows).  In addition to the import test, I&apos;m also scanning these 10 rows in two ways.  A full scan (all in family) as well as a skip scan (i&apos;m asking for two specific columns, qualifier=1 and qualifier=1888888, so beginning and end of each row).&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Inserted 10 rows each with 2000000 total columns in 344566ms (34456.6ms/row)

Skip Scanner open
Row [row0] Scanned, Contains 2 Columns (10155 ms)
Row [row1] Scanned, Contains 2 Columns (9978 ms)
Row [row2] Scanned, Contains 2 Columns (10675 ms)
Row [row3] Scanned, Contains 2 Columns (9608 ms)
Row [row4] Scanned, Contains 2 Columns (11703 ms)
Row [row5] Scanned, Contains 2 Columns (12103 ms)
Row [row6] Scanned, Contains 2 Columns (6828 ms)
Row [row7] Scanned, Contains 2 Columns (6603 ms)
Row [row8] Scanned, Contains 2 Columns (6331 ms)
Row [row9] Scanned, Contains 2 Columns (6553 ms)
Scanned 10 rows in 90551ms (9055.1ms/row)

Full Scanner open
Row [row0] Scanned, Contains 2000000 Columns (14374 ms)
Row [row1] Scanned, Contains 2000000 Columns (14879 ms)
Row [row2] Scanned, Contains 2000000 Columns (14053 ms)
Row [row3] Scanned, Contains 2000000 Columns (14263 ms)
Row [row4] Scanned, Contains 2000000 Columns (8811 ms)
Row [row5] Scanned, Contains 2000000 Columns (10327 ms)
Row [row6] Scanned, Contains 2000000 Columns (9757 ms)
Row [row7] Scanned, Contains 2000000 Columns (9343 ms)
Row [row8] Scanned, Contains 2000000 Columns (9526 ms)
Row [row9] Scanned, Contains 2000000 Columns (10004 ms)
Scanned 10 rows in 115342ms (11534.2ms/row)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Repeated runs improve performance, and ordering of the two types of scans makes a difference.  Block cache is off so we&apos;re seeing the effect of the linux file cache.&lt;/p&gt;</comment>
                            <comment id="12720918" author="streamy" created="Wed, 17 Jun 2009 21:46:35 +0000"  >&lt;p&gt;Given that I can do the above on a smallish cluster without a problem (the only problems come from OOME when serializing these big rows if I grow value size), I am resolving this issue as fixed by &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1304&quot; title=&quot;New client server implementation of how gets and puts are handled. &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1304&quot;&gt;&lt;del&gt;HBASE-1304&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;To be able to scale further as far as columns in a row, we need intra-row scanning.  I have filed &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1537&quot; title=&quot;Intra-row scanning&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1537&quot;&gt;&lt;del&gt;HBASE-1537&lt;/del&gt;&lt;/a&gt; currently targeted at 0.21 for now.&lt;/p&gt;

&lt;p&gt;There are still improvements to be made when not returning all columns in a row with millions of columns.  That optimization is addressed in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1517&quot; title=&quot;Implement inexpensive seek operations in HFile&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1517&quot;&gt;&lt;del&gt;HBASE-1517&lt;/del&gt;&lt;/a&gt; and slated for 0.20.1.&lt;/p&gt;</comment>
                            <comment id="12720927" author="stack" created="Wed, 17 Jun 2009 21:59:45 +0000"  >&lt;p&gt;I&apos;m +1 on resolving this issue because of 1304 work (in spite of what the issue title says) and doing further improvements out in other issues.  Let me add note that this issue was resolved to CHANGES.txt&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12415194">HBASE-1206</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12416456">HBASE-1249</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fri, 20 Feb 2009 04:15:20 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>25447</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 25 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0h9xr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>98872</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>