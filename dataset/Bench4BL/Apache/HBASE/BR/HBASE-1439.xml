<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 02 19:52:08 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-1439/HBASE-1439.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-1439] race between master and regionserver after missed heartbeat</title>
                <link>https://issues.apache.org/jira/browse/HBASE-1439</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Seen on one of our 0.19.1 clusters:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
java.io.FileNotFoundException: File does not exist: hdfs:&lt;span class=&quot;code-comment&quot;&gt;//jdc2-atr-dc-2.atr.trendmicro.com:50000
&lt;/span&gt;/data/hbase/log_10.3.134.207_1242286427894_60020/hlog.dat.1242528291898
 at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:415)
 at org.apache.hadoop.fs.FileSystem.getLength(FileSystem.java:679)
 at org.apache.hadoop.hbase.io.SequenceFile$Reader.&amp;lt;init&amp;gt;(SequenceFile.java:1431)
 at org.apache.hadoop.hbase.io.SequenceFile$Reader.&amp;lt;init&amp;gt;(SequenceFile.java:1426)
 at org.apache.hadoop.hbase.regionserver.HLog.splitLog(HLog.java:753)
 at org.apache.hadoop.hbase.regionserver.HLog.splitLog(HLog.java:716)
 at org.apache.hadoop.hbase.master.ProcessServerShutdown.process(ProcessServerShutdown.java:249)
 at org.apache.hadoop.hbase.master.HMaster.processToDoQueue(HMaster.java:442)
 at org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:377)
2009-05-17 04:05:55,481 INFO org.apache.hadoop.hbase.master.RegionServerOperation: process
shutdown of server 10.3.134.207:60020: logSplit: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, rootRescanned: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, numberOfMetaRegions: 1,
onlineMetaRegions.size(): 1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I do not have the region server log yet, but here is my conjecture:&lt;/p&gt;

&lt;p&gt;Here, the write ahead log for 10.3.134.207 is missing in DFS: java.io.FileNotFoundException: hdfs://jdc2-atr-dc-2.atr.trendmicro.com:50000/data/hbase/log_10.3.134.207_1242286427894_60020/hlog.dat.1242528291898 when the master tries to split it after declaring the region server crashed. There have been recent trouble reports on this cluster that indicate severe memory stress, e.g. kernel panics due to OOM. Based on that I think it is likely that the region server here missed a heartbeat so the master declared it crashed and began to split the log. But, the log was then deleted out from underneath the master&apos;s split thread. I think the region server was actually still running but partially swapped out or the node was otherwise overloaded so it missed its heartbeat. Then, when the region server came back after being swapped in, it realized it missed its heartbeat and shut down, deleting the log as is normally done. &lt;/p&gt;

&lt;p&gt;Even if the above is not the actual cause in this case, I think the scenario is plausible. What do you think?&lt;/p&gt;</description>
                <environment>&lt;p&gt;CentOS 5.2 x86_64, HBase 0.19.1, Hadoop 0.19.1&lt;/p&gt;</environment>
        <key id="12425851">HBASE-1439</key>
            <summary>race between master and regionserver after missed heartbeat</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="apurtell">Andrew Purtell</reporter>
                        <labels>
                    </labels>
                <created>Tue, 19 May 2009 18:44:50 +0000</created>
                <updated>Fri, 20 Nov 2015 13:01:36 +0000</updated>
                            <resolved>Tue, 24 Aug 2010 23:11:15 +0000</resolved>
                                    <version>0.19.1</version>
                                    <fixVersion>0.90.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                <comments>
                            <comment id="12710837" author="stack" created="Tue, 19 May 2009 19:23:48 +0000"  >&lt;p&gt;This seems plausible to me.  I looked through the server start code thinking that it had done a quick recovery &amp;#8211; I saw it show soon after lease expiration in the master log &amp;#8211; thinking that server start up removed logs but thats not it.&lt;/p&gt;</comment>
                            <comment id="12710954" author="apurtell" created="Wed, 20 May 2009 00:32:06 +0000"  >&lt;p&gt;If the conjecture holds after we get evidence in the form of the regionserver log, this would be like &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1314&quot; title=&quot;master sees HRS znode expire and splits log while the HRS is still running and accepting edits&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1314&quot;&gt;&lt;del&gt;HBASE-1314&lt;/del&gt;&lt;/a&gt;, where the master is taking recovery actions while the regionserver is still up. Any thoughts on how to close or narrow the window? ZK can be as much of a problem as solution, and there are few atomic operations in DFS that could help (afaik, only rename is atomic). &lt;/p&gt;</comment>
                            <comment id="12711322" author="stack" created="Wed, 20 May 2009 20:33:18 +0000"  >&lt;p&gt;I took a look at the regionserver log (provided by andrew lee).&lt;/p&gt;

&lt;p&gt;This machine is under heavy write load.  Its expiring client leases.  Some client is confused thinking it hosting .META.&lt;/p&gt;

&lt;p&gt;I see this in log from about five minutes earlier:&lt;/p&gt;

&lt;p&gt;2009-05-17 04:00:09,506 WARN org.apache.hadoop.hbase.util.Sleeper: We slept 128679ms, ten times longer than scheduled: 3000&lt;br/&gt;
2009-05-17 04:00:09,507 WARN org.apache.hadoop.hbase.regionserver.HRegionServer: unable to report to master for 128680 milliseconds - retrying&lt;br/&gt;
2009-05-17 04:00:09,508 WARN org.apache.hadoop.hbase.util.Sleeper: We slept 127641ms, ten times longer than scheduled: 1000&lt;br/&gt;
2009-05-17 04:00:09,526 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: MSG_CALL_SERVER_STARTUP: safeMode=false&lt;/p&gt;

&lt;p&gt;We get the MSG_CALL_SERVER_STARTUP because master thinks we&apos;re showing up new though what seems to have happened, as apurtell speculated, was that we just went too sleep for too long.&lt;/p&gt;

&lt;p&gt;In the src we do this on above message in regionserver:&lt;/p&gt;

&lt;p&gt;              case MSG_CALL_SERVER_STARTUP:&lt;br/&gt;
                // We the MSG_CALL_SERVER_STARTUP on startup but we can also&lt;br/&gt;
                // get it when the master is panicing because for instance&lt;br/&gt;
                // the HDFS has been yanked out from under it.  Be wary of&lt;br/&gt;
                // this message.&lt;br/&gt;
                if (checkFileSystem()) {&lt;br/&gt;
                  closeAllRegions();&lt;br/&gt;
                  try &lt;/p&gt;
{
                    log.closeAndDelete();
                  }
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
                    LOG.error(&quot;error closing and deleting HLog&quot;, e);
                  }
&lt;p&gt;                  try &lt;/p&gt;
{
                    serverInfo.setStartCode(System.currentTimeMillis());
                    log = setupHLog();
                    this.logFlusher.setHLog(log);
                  }
&lt;p&gt; catch (IOException e) &lt;/p&gt;
{
                    this.abortRequested = true;
                    this.stopRequested.set(true);
                    e = RemoteExceptionHandler.checkIOException(e);
                    LOG.fatal(&quot;error restarting server&quot;, e);
                    break;
                  }
&lt;p&gt;                  reportForDuty(sleeper);&lt;br/&gt;
                  restart = true;&lt;br/&gt;
                } else &lt;/p&gt;
{
                  LOG.fatal(&quot;file system available check failed. &quot; +
                  &quot;Shutting down server.&quot;);
                }
&lt;p&gt;                break;&lt;/p&gt;

&lt;p&gt;We shut all regions then call close and delete on the hlog.  This is likely what pulled log out from under regionserver (as per apurtell speculation).&lt;/p&gt;

&lt;p&gt;This is bad.&lt;/p&gt;

&lt;p&gt;Can commit log ownership be mediated by zk?  When the hosting regionserver&apos;s lease expires, can the lease on the commit log expire too so regionserver doesn&apos;t remove logs being worked on by another?&lt;/p&gt;</comment>
                            <comment id="12711380" author="apurtell" created="Wed, 20 May 2009 21:55:44 +0000"  >&lt;p&gt;Discussion on IRC agrees this will be addressed for 0.20 release.&lt;/p&gt;</comment>
                            <comment id="12717850" author="jdcryans" created="Tue, 9 Jun 2009 22:47:45 +0000"  >&lt;p&gt;The region servers should watch their own znodes to make sure that they don&apos;t continue to live even if the master sees them as dead. Masters should also watch their own nodes.&lt;/p&gt;</comment>
                            <comment id="12723242" author="jdcryans" created="Tue, 23 Jun 2009 18:37:08 +0000"  >&lt;p&gt;I did a little experiment to confirm some assumptions I have. I started 1 master, 1 RS and a ZK server on my machine on a fresh HDFS. Right when the RS finished opening the ROOT and META regions, I killed the ZK server to simulate a network partition. The master got:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Got ZooKeeper event, state: Disconnected, type: None, path: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The RS got:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
org.apache.hadoop.hbase.regionserver.HRegionServer: Got ZooKeeper event, state: Disconnected, type: None, path: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then both nodes continued to live and that&apos;s a real problem. If ZK is the boss and you can&apos;t talk to it, you should do an emergency shutdown. They have something like that in Bigtable:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;To ensure that a Bigtable cluster is not vulnera-&lt;br/&gt;
ble to networking issues between the master and Chubby,&lt;br/&gt;
the master kills itself if its Chubby session expires.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I also tried deleting the hbase/rs/number to simulate a RS being unable to contact ZK but still able to talk to HDFS and I got a boat load of:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2009-06-23 14:32:21,502 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 9 on 60000, call regionServerReport(address: 192.168.1.86:60020, 
startcode: 1245781887285, load: (requests=0, regions=2, usedHeap=25, maxHeap=991), [Lorg.apache.hadoop.hbase.HMsg;@4baa2c23, 
[Lorg.apache.hadoop.hbase.HRegionInfo;@1137d4a4) from 192.168.1.86:37090: error: org.apache.hadoop.hbase.Leases$LeaseStillHeldException
org.apache.hadoop.hbase.Leases$LeaseStillHeldException
	at org.apache.hadoop.hbase.master.ServerManager.regionServerReport(ServerManager.java:251)
	at org.apache.hadoop.hbase.master.HMaster.regionServerReport(HMaster.java:662)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:643)
	at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:913)
2009-06-23 14:32:21,511 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 0 on 60000, call regionServerReport(address: 192.168.1.86:60020, 
startcode: 1245781887285, load: (requests=0, regions=2, usedHeap=26, maxHeap=991), [Lorg.apache.hadoop.hbase.HMsg;@6e4eeaaf, 
[Lorg.apache.hadoop.hbase.HRegionInfo;@7f11bfbc) from 192.168.1.86:37090: error: org.apache.hadoop.hbase.Leases$LeaseStillHeldException
org.apache.hadoop.hbase.Leases$LeaseStillHeldException
	at org.apache.hadoop.hbase.master.ServerManager.regionServerReport(ServerManager.java:251)
	at org.apache.hadoop.hbase.master.HMaster.regionServerReport(HMaster.java:662)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:643)
	at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:913)
2009-06-23 14:32:21,515 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 1 on 60000, call regionServerReport(address: 192.168.1.86:60020, 
startcode: 1245781887285, load: (requests=0, regions=2, usedHeap=26, maxHeap=991), [Lorg.apache.hadoop.hbase.HMsg;@664310d0, 
[Lorg.apache.hadoop.hbase.HRegionInfo;@3d04fc23) from 192.168.1.86:37090: error: org.apache.hadoop.hbase.Leases$LeaseStillHeldException
org.apache.hadoop.hbase.Leases$LeaseStillHeldException
	at org.apache.hadoop.hbase.master.ServerManager.regionServerReport(ServerManager.java:251)
	at org.apache.hadoop.hbase.master.HMaster.regionServerReport(HMaster.java:662)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:643)
	at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:913)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The RS was receiving that kind of errors too:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2009-06-23 14:32:21,507 WARN org.apache.hadoop.hbase.regionserver.HRegionServer: Processing message (Retry: 0)
org.apache.hadoop.hbase.Leases$LeaseStillHeldException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.hbase.RemoteExceptionHandler.decodeRemoteException(RemoteExceptionHandler.java:94)
	at org.apache.hadoop.hbase.RemoteExceptionHandler.checkThrowable(RemoteExceptionHandler.java:48)
	at org.apache.hadoop.hbase.RemoteExceptionHandler.checkIOException(RemoteExceptionHandler.java:66)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:561)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:619)
2009-06-23 14:32:21,512 WARN org.apache.hadoop.hbase.regionserver.HRegionServer: Processing message (Retry: 1)
org.apache.hadoop.hbase.Leases$LeaseStillHeldException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.hbase.RemoteExceptionHandler.decodeRemoteException(RemoteExceptionHandler.java:94)
	at org.apache.hadoop.hbase.RemoteExceptionHandler.checkThrowable(RemoteExceptionHandler.java:48)
	at org.apache.hadoop.hbase.RemoteExceptionHandler.checkIOException(RemoteExceptionHandler.java:66)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:561)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:619)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I&apos;m marking this issue as a blocker since it&apos;s really bad.&lt;/p&gt;</comment>
                            <comment id="12728121" author="jdcryans" created="Tue, 7 Jul 2009 14:23:37 +0000"  >&lt;p&gt;Since both the RSs and the Master (with &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1575&quot; title=&quot;HMaster does not handle ZK session expiration&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1575&quot;&gt;&lt;del&gt;HBASE-1575&lt;/del&gt;&lt;/a&gt;) will handle session expiration, the possibility that a region server deletes its hlogs after sleeping for too long is greatly lessened as it will just abort and restart. The other possibility, as I described in the previous post, is that the region server cannot reach any ZK server for any reason and gets detected as dead by the Master which can still reach a ZK server. When I first tested that, it seemed like a very serious issue but now that I gave it some thought I think that it if happened HDFS would probably be wedged too by such a network partition. &lt;/p&gt;

&lt;p&gt;Anyways, the fix would be to have a timer in a generic Watch specialization that catches all disconnections and that after ~tickTime*1.5 would send a fabricated session expiration. IMO this is a nice to have for 0.20.0. Should we punt this?&lt;/p&gt;</comment>
                            <comment id="12728163" author="stack" created="Tue, 7 Jul 2009 16:00:59 +0000"  >&lt;p&gt;Lets move it out of 0.20.0 (until we find evidence to undo your rationale above).  Thanks J-D.&lt;/p&gt;</comment>
                            <comment id="12728437" author="jdcryans" created="Wed, 8 Jul 2009 00:28:14 +0000"  >&lt;p&gt;Punting to 0.20.1&lt;/p&gt;</comment>
                            <comment id="12731061" author="jdcryans" created="Tue, 14 Jul 2009 19:16:52 +0000"  >&lt;p&gt;This log from a recent trunk makes me think we should still do that special watcher (the master split logs around 14:11:58):&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2009-07-13 14:10:44,219 INFO org.apache.hadoop.hbase.regionserver.HRegion: compaction completed on region t3,,1247502416090 in 0sec
2009-07-13 14:10:46,735 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: MSG_REGION_CLOSE: t3,******************,1247507770509: Overloaded
2009-07-13 14:10:46,743 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Worker: MSG_REGION_CLOSE: t3******************,1247507770509: Overloaded
2009-07-13 14:10:46,743 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Closing t3,******************,1247507770509: compactions &amp;amp; flushes disabled 
2009-07-13 14:10:46,743 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Updates disabled &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; region, no outstanding scanners on t3,**************,1247507770509
2009-07-13 14:10:46,744 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: No more row locks outstanding on region t3,U**************9,1247507770509
2009-07-13 14:10:46,744 DEBUG org.apache.hadoop.hbase.regionserver.Store: closed block
2009-07-13 14:10:46,744 INFO org.apache.hadoop.hbase.regionserver.HRegion: Closed t3,,******************,1247507770509
2009-07-13 14:11:54,283 DEBUG org.apache.hadoop.hbase.io.hfile.LruBlockCache: Cache Stats: Sizes: Total=336.81897MB (353180272), Free=59.856064MB (62763632), Max=396.67502MB (415943904), Counts: Blocks=5251, Access=259404, Hit=5232, Miss=2
54172, Evictions=13, Evicted=8223, Ratios: Hit Ratio=2.016931027173996%, Miss Ratio=97.98306822776794%, Evicted/Run=632.5384521484375
2009-07-13 14:11:54,375 WARN org.apache.zookeeper.ClientCnxn: Exception closing session 0x12274aa40060001 to sun.nio.ch.SelectionKeyImpl@2b20bf2c
java.io.IOException: TIMED OUT
        at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:858)
2009-07-13 14:11:54,375 WARN org.apache.zookeeper.ClientCnxn: Exception closing session 0x22274aa40700002 to sun.nio.ch.SelectionKeyImpl@12746ad0
java.io.IOException: TIMED OUT
        at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:858)
2009-07-13 14:11:58,996 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Got ZooKeeper event, state: Disconnected, type: None, path: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
2009-07-13 14:11:59,002 WARN org.apache.hadoop.hbase.regionserver.HRegionServer: Processing message (Retry: 0)
org.apache.hadoop.hbase.Leases$LeaseStillHeldException
        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
...
2009-07-13 14:11:59,097 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: Exceeded max retries: 10
org.apache.hadoop.hbase.Leases$LeaseStillHeldException
        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
        at org.apache.hadoop.hbase.RemoteExceptionHandler.decodeRemoteException(RemoteExceptionHandler.java:94)
        at org.apache.hadoop.hbase.RemoteExceptionHandler.checkThrowable(RemoteExceptionHandler.java:48)
        at org.apache.hadoop.hbase.RemoteExceptionHandler.checkIOException(RemoteExceptionHandler.java:66)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:561)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:619)
2009-07-13 14:11:59,262 INFO org.apache.zookeeper.ClientCnxn: Attempting connection to server **************/**************:2181
2009-07-13 14:11:59,262 INFO org.apache.zookeeper.ClientCnxn: Priming connection to java.nio.channels.SocketChannel[connected local=/**************53663 remote=**************/**************:2181]
2009-07-13 14:11:59,262 INFO org.apache.zookeeper.ClientCnxn: Server connection successful
2009-07-13 14:11:59,635 INFO org.apache.zookeeper.ClientCnxn: Attempting connection to server **************/**************:2181
2009-07-13 14:11:59,635 INFO org.apache.zookeeper.ClientCnxn: Priming connection to java.nio.channels.SocketChannel[connected local=/**************:44760 remote=**************/**************:2181]
2009-07-13 14:11:59,635 INFO org.apache.zookeeper.ClientCnxn: Server connection successful
2009-07-13 14:12:00,103 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Got ZooKeeper event, state: Expired, type: None, path: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
2009-07-13 14:12:00,104 WARN org.apache.zookeeper.ClientCnxn: Exception closing session 0x12274aa40060001 to sun.nio.ch.SelectionKeyImpl@5e297e83
java.io.IOException: Session Expired
        at org.apache.zookeeper.ClientCnxn$SendThread.readConnectResult(ClientCnxn.java:548)
        at org.apache.zookeeper.ClientCnxn$SendThread.doIO(ClientCnxn.java:661)
        at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:897)
2009-07-13 14:12:00,104 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: ZooKeeper session expired
2009-07-13 14:12:00,104 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Restarting Region Server
2009-07-13 14:12:00,105 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: Exceeded max retries: 10
org.apache.hadoop.hbase.Leases$LeaseStillHeldException
        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
        at org.apache.hadoop.hbase.RemoteExceptionHandler.decodeRemoteException(RemoteExceptionHandler.java:94)
        at org.apache.hadoop.hbase.RemoteExceptionHandler.checkThrowable(RemoteExceptionHandler.java:48)
        at org.apache.hadoop.hbase.RemoteExceptionHandler.checkIOException(RemoteExceptionHandler.java:66)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:561)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:619)
2009-07-13 14:12:00,106 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Dump of metrics: request=0.0, regions=4, stores=4, storefiles=7, storefileIndexSize=4, memstoreSize=96, usedHeap=1153, maxHeap=1983, blockCacheSize=353180272,
 blockCacheFree=62763632, blockCacheCount=5251, blockCacheHitRatio=2
2009-07-13 14:12:00,110 WARN org.apache.hadoop.hbase.regionserver.HLog: IPC Server handler 9 on 60020 took 1033ms appending an edit to hlog; editcount=60781
2009-07-13 14:12:04,256 WARN org.apache.hadoop.hbase.regionserver.HLog: IPC Server handler 9 on 60020 took 4128ms appending an edit to hlog; editcount=62375
2009-07-13 14:12:04,257 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Stop was requested, clearing the toDo despite of the exception
2009-07-13 14:12:04,257 WARN org.apache.zookeeper.ClientCnxn: Exception closing session 0x22274aa40700002 to sun.nio.ch.SelectionKeyImpl@54f015d5
java.io.IOException: TIMED OUT
        at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:858)
2009-07-13 14:12:04,257 DEBUG org.apache.hadoop.hbase.RegionHistorian: Offlined
 2009-07-13 14:12:04,257 INFO org.apache.hadoop.ipc.HBaseServer: Stopping server on 60020
2009-07-13 14:12:04,257 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 0 on 60020: exiting
2009-07-13 14:12:04,257 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 1 on 60020: exiting
2009-07-13 14:12:04,258 INFO org.apache.hadoop.ipc.HBaseServer: Stopping IPC Server listener on 60020
2009-07-13 14:12:04,282 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Stopping infoServer
2009-07-13 14:12:04,286 INFO org.apache.hadoop.hbase.regionserver.MemStoreFlusher: regionserver/**************:60020.cacheFlusher exiting
2009-07-13 14:12:04,286 INFO org.apache.hadoop.hbase.regionserver.LogRoller: LogRoller exiting.
2009-07-13 14:12:04,286 INFO org.apache.hadoop.hbase.Leases: regionserver/**************:60020.leaseChecker closing leases
2009-07-13 14:12:04,286 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: worker thread exiting
2009-07-13 14:12:04,286 INFO org.apache.hadoop.hbase.Leases: regionserver/**************:60020.leaseChecker closed leases
2009-07-13 14:12:04,318 INFO org.apache.hadoop.hbase.regionserver.LogFlusher: regionserver/**************:60020.logFlusher exiting
2009-07-13 14:12:04,484 INFO org.apache.hadoop.ipc.HBaseServer: Stopping IPC Server Responder
2009-07-13 14:12:04,494 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 2 on 60020: exiting
2009-07-13 14:12:04,512 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 4 on 60020: exiting
2009-07-13 14:12:04,512 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 6 on 60020: exiting
2009-07-13 14:12:04,512 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 5 on 60020: exiting
2009-07-13 14:12:04,512 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 8 on 60020: exiting
2009-07-13 14:12:04,512 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 3 on 60020: exiting
2009-07-13 14:12:04,513 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 7 on 60020: exiting
2009-07-13 14:12:05,076 DEBUG org.apache.hadoop.hbase.regionserver.HLog: closing hlog writer in hdfs:&lt;span class=&quot;code-comment&quot;&gt;//**************:50000/hbase/.logs/**************,60020,1247497897306
&lt;/span&gt;2009-07-13 14:12:05,076 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: java.io.IOException: Cannot append; log is closed
2009-07-13 14:12:05,076 INFO org.apache.hadoop.hbase.regionserver.CompactSplitThread: regionserver/**************:60020.compactor exiting
2009-07-13 14:12:05,076 INFO org.apache.hadoop.hbase.regionserver.HRegionServer$MajorCompactionChecker: regionserver/**************:60020.majorCompactionChecker exiting
2009-07-13 14:12:05,138 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: Unable to close log in abort
java.io.IOException: java.io.IOException: Could not complete write to file /hbase/.logs/**************60020,1247497897306/hlog.dat.1247508029747 by DFSClient_51605845
        at org.apache.hadoop.hdfs.server.namenode.NameNode.complete(NameNode.java:449)
        at sun.reflect.GeneratedMethodAccessor17.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)

        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
        at org.apache.hadoop.hbase.RemoteExceptionHandler.decodeRemoteException(RemoteExceptionHandler.java:94)
        at org.apache.hadoop.hbase.RemoteExceptionHandler.checkThrowable(RemoteExceptionHandler.java:48)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:626)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:619)
2009-07-13 14:12:05,138 INFO org.apache.hadoop.fs.FileSystem: Could not cancel cleanup thread, though no FileSystems are open
2009-07-13 14:12:05,138 ERROR org.apache.hadoop.hbase.util.FSUtils: file system close failed: 
java.lang.NullPointerException
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.closeThreads(DFSClient.java:3127)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.closeInternal(DFSClient.java:3170)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.close(DFSClient.java:3115)
        at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.close(DFSClient.java:1002)
        at org.apache.hadoop.hdfs.DFSClient.close(DFSClient.java:208)
        at org.apache.hadoop.hdfs.DistributedFileSystem.close(DistributedFileSystem.java:269)
        at org.apache.hadoop.hbase.util.FSUtils.checkFileSystemAvailable(FSUtils.java:119)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.checkFileSystem(HRegionServer.java:861)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.cleanup(HRegionServer.java:809)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.cleanup(HRegionServer.java:792)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.put(HRegionServer.java:1793)
        at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:643)
      at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:913)
2009-07-13 14:12:05,138 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: closing region t3,**************
2009-07-13 14:12:05,138 FATAL org.apache.hadoop.hbase.regionserver.HRegionServer: Shutting down HRegionServer: file system not available
java.io.IOException: File system is not available
        at org.apache.hadoop.hbase.util.FSUtils.checkFileSystemAvailable(FSUtils.java:123)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.checkFileSystem(HRegionServer.java:861)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.cleanup(HRegionServer.java:809)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.cleanup(HRegionServer.java:792)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.put(HRegionServer.java:1793)
        at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:643)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:913)
Caused by: java.io.IOException: Call to **************1/**************:50000 failed on local exception: java.nio.channels.ClosedChannelException
        at org.apache.hadoop.ipc.Client.wrapException(Client.java:774)
        at org.apache.hadoop.ipc.Client.call(Client.java:742)
        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
        at $Proxy1.getFileInfo(Unknown Source)
        at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
        at $Proxy1.getFileInfo(Unknown Source)
        at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:587)
        at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:453)
        at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:643)
        at org.apache.hadoop.hbase.util.FSUtils.checkFileSystemAvailable(FSUtils.java:112)
        ... 9 more
Caused by: java.nio.channels.ClosedChannelException
        at sun.nio.ch.SocketChannelImpl.ensureReadOpen(SocketChannelImpl.java:113)
        at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:156)
        at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:55)
        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
        at java.io.FilterInputStream.read(FilterInputStream.java:116)
        at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:276)
        at java.io.BufferedInputStream.fill(BufferedInputStream.java:218)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:237)
        at java.io.DataInputStream.readInt(DataInputStream.java:370)
        at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
2009-07-13 14:12:05,138 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Closing t3,**************: compactions &amp;amp; flushes disabled 
2009-07-13 14:12:05,143 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Updates disabled &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; region, no outstanding scanners on t3,**************
2009-07-13 14:12:05,143 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Dump of metrics: request=0.0, regions=4, stores=4, storefiles=7, storefileIndexSize=4, memstoreSize=96, usedHeap=1156, maxHeap=1983, blockCacheSize=353180272,
 blockCacheFree=62763632, blockCacheCount=5251, blockCacheHitRatio=2
2009-07-13 14:12:05,143 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: No more row locks outstanding on region t3,**************
2009-07-13 14:12:05,144 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 9 on 60020, call put([B@1df68388, [Lorg.apache.hadoop.hbase.client.Put;@23356516) from **************:48126: error: java.io.IOException: Cannot append; log is
 closed
java.io.IOException: Cannot append; log is closed
        at org.apache.hadoop.hbase.regionserver.HLog.append(HLog.java:584)
        at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:1446)
        at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:1246)
        at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:1209)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.put(HRegionServer.java:1785)
        at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:643)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:913)
2009-07-13 14:12:05,151 DEBUG org.apache.hadoop.hbase.regionserver.Store: closed block
2009-07-13 14:12:05,152 INFO org.apache.hadoop.hbase.regionserver.HRegion: Closed t3,**************
2009-07-13 14:12:05,152 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: closing region t3,**************
2009-07-13 14:12:05,152 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Closing t3,**************: compactions &amp;amp; flushes disabled 
2009-07-13 14:12:05,152 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Updates disabled &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; region, no outstanding scanners on t3**************
2009-07-13 14:12:05,152 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: No more row locks outstanding on region t3,**************
2009-07-13 14:12:05,152 DEBUG org.apache.hadoop.hbase.regionserver.Store: closed block
2009-07-13 14:12:05,152 INFO org.apache.hadoop.hbase.regionserver.HRegion: Closed t3,**************
2009-07-13 14:12:05,152 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: closing region t3,,1247502416090
2009-07-13 14:12:05,152 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Closing t3,,1247502416090: compactions &amp;amp; flushes disabled 
2009-07-13 14:12:05,152 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Updates disabled &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; region, no outstanding scanners on t3,,1247502416090
2009-07-13 14:12:05,152 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: No more row locks outstanding on region t3,,1247502416090
2009-07-13 14:12:05,152 DEBUG org.apache.hadoop.hbase.regionserver.Store: closed block
2009-07-13 14:12:05,152 INFO org.apache.hadoop.hbase.regionserver.HRegion: Closed t3,,1247502416090
2009-07-13 14:12:05,152 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: closing region t3,**************
2009-07-13 14:12:05,152 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Closing t3,**************: compactions &amp;amp; flushes disabled 
2009-07-13 14:12:05,152 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Updates disabled &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; region, no outstanding scanners on t3,**************
2009-07-13 14:12:05,152 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: No more row locks outstanding on region t3,**************
-07-13 14:12:05,153 WARN org.apache.hadoop.ipc.HBaseServer: IPC Server Responder, call put([B@1df68388, [Lorg.apache.hadoop.hbase.client.Put;@23356516) from **************:48126: output error
2009-07-13 14:12:05,156 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 9 on 60020 caught: java.nio.channels.ClosedChannelException
        at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:126)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:324)
        at org.apache.hadoop.hbase.ipc.HBaseServer.channelWrite(HBaseServer.java:1122)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Responder.processResponse(HBaseServer.java:613)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Responder.doRespond(HBaseServer.java:677)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:941)

2009-07-13 14:12:05,156 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 9 on 60020: exiting
2009-07-13 14:12:05,156 DEBUG org.apache.hadoop.hbase.regionserver.Store: closed block
2009-07-13 14:12:05,156 INFO org.apache.hadoop.hbase.regionserver.HRegion: Closed t3,**************
2009-07-13 14:12:05,156 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: aborting server at: **************:60020
2009-07-13 14:12:05,157 INFO org.apache.zookeeper.ZooKeeper: Closing session: 0x12274aa40060001
2009-07-13 14:12:05,157 INFO org.apache.zookeeper.ClientCnxn: Closing ClientCnxn &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; session: 0x12274aa40060001
2009-07-13 14:12:05,157 INFO org.apache.zookeeper.ClientCnxn: Disconnecting ClientCnxn &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; session: 0x12274aa40060001
2009-07-13 14:12:05,157 INFO org.apache.zookeeper.ZooKeeper: Session: 0x12274aa40060001 closed
2009-07-13 14:12:05,157 DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper: Closed connection with ZooKeeper
2009-07-13 14:12:05,157 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: regionserver/**************:60020 exiting
2009-07-13 14:12:05,172 INFO org.apache.hadoop.hbase.ipc.HBaseRpcMetrics: Initializing RPC Metrics with hostName=HRegionServer, port=60020
2009-07-13 14:12:05,181 INFO org.apache.hadoop.hbase.regionserver.MemStoreFlusher: globalMemStoreLimit=793.4m, globalMemStoreLimitLowMark=495.8m, maxHeap=1.9g
2009-07-13 14:12:05,181 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Starting shutdown thread.
2009-07-13 14:12:05,195 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Shutdown thread complete
2009-07-13 14:12:05,195 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Runs every 10000000ms
2009-07-13 14:12:05,219 INFO org.apache.zookeeper.ClientCnxn: Attempting connection to server **************/**************:2181
2009-07-13 14:12:05,219 INFO org.apache.zookeeper.ClientCnxn: Priming connection to java.nio.channels.SocketChannel[connected local=/**************:33151 remote=**************/**************:2181]
2009-07-13 14:12:05,219 INFO org.apache.zookeeper.ClientCnxn: Server connection successful
2009-07-13 14:12:05,380 INFO org.apache.zookeeper.ZooKeeper: Initiating client connection, host=*****************:2181 sessionTimeout=30000 watcher=org.apache.hadoop.hbase.regionserver.HRegionServer@47315d34
2009-07-13 14:12:10,636 INFO org.apache.zookeeper.ClientCnxn: EventThread shut down
2009-07-13 14:12:10,636 INFO org.apache.zookeeper.ClientCnxn: Attempting connection to server **************/**************:2181
2009-07-13 14:12:10,636 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: Failed init
java.lang.NullPointerException
        at org.apache.hadoop.hbase.regionserver.HRegionServer.init(HRegionServer.java:710)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:425)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:619)
2009-07-13 14:12:10,636 FATAL org.apache.hadoop.hbase.regionserver.HRegionServer: Unhandled exception. Aborting...
java.io.IOException: Region server startup failed
        at org.apache.hadoop.hbase.regionserver.HRegionServer.convertThrowableToIOE(HRegionServer.java:829)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.init(HRegionServer.java:748)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:425)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:619)
Caused by: java.lang.NullPointerException
        at org.apache.hadoop.hbase.regionserver.HRegionServer.init(HRegionServer.java:710)
      ... 2 more
2009-07-13 14:12:10,636 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Dump of metrics: request=0.0, regions=4, stores=4, storefiles=7, storefileIndexSize=4, memstoreSize=96, usedHeap=1173, maxHeap=1983, blockCacheSize=353180272,
 blockCacheFree=62763632, blockCacheCount=5251, blockCacheHitRatio=2
2009-07-13 14:12:10,636 DEBUG org.apache.hadoop.hbase.RegionHistorian: Offlined
2009-07-13 14:12:11,084 INFO org.apache.zookeeper.ClientCnxn: Priming connection to java.nio.channels.SocketChannel[connected local=/**************:52015 remote=**************/**************:2181]
2009-07-13 14:12:11,084 INFO org.apache.zookeeper.ClientCnxn: Server connection successful
2009-07-13 14:12:11,086 INFO org.apache.hadoop.ipc.HBaseServer: Stopping server on 60020
2009-07-13 14:12:11,086 WARN org.apache.zookeeper.ClientCnxn: Exception closing session 0x22274aa40700002 to sun.nio.ch.SelectionKeyImpl@411cac1d
java.io.IOException: TIMED OUT
        at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:858)
2009-07-13 14:12:11,090 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Stopping infoServer
2009-07-13 14:12:11,135 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: aborting server at: **************:60020
2009-07-13 14:12:11,135 INFO org.apache.zookeeper.ZooKeeper: Closing session: 0x0
2009-07-13 14:12:11,135 INFO org.apache.zookeeper.ClientCnxn: Closing ClientCnxn &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; session: 0x0
2009-07-13 14:12:11,365 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Got ZooKeeper event, state: SyncConnected, type: None, path: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
2009-07-13 14:12:11,365 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: Ignoring ZooKeeper event &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; shutting down
2009-07-13 14:12:11,417 INFO org.apache.zookeeper.ClientCnxn: Attempting connection to server **************/**************:2181
2009-07-13 14:12:11,421 INFO org.apache.zookeeper.ClientCnxn: Priming connection to java.nio.channels.SocketChannel[connected local=/**************52016 remote=**************/**************:2181]
2009-07-13 14:12:11,421 INFO org.apache.zookeeper.ClientCnxn: Server connection successful
2009-07-13 14:12:11,422 WARN org.apache.zookeeper.ClientCnxn: Exception closing session 0x22274aa40700002 to sun.nio.ch.SelectionKeyImpl@44a45d2c
java.io.IOException: Session Expired
        at org.apache.zookeeper.ClientCnxn$SendThread.readConnectResult(ClientCnxn.java:548)
        at org.apache.zookeeper.ClientCnxn$SendThread.doIO(ClientCnxn.java:661)
        at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:897)
2009-07-13 14:12:11,422 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Got ZooKeeper event, state: Expired, type: None, path: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
2009-07-13 14:12:11,422 INFO org.apache.zookeeper.ZooKeeper: Closing session: 0x22274aa40700002
2009-07-13 14:12:11,422 INFO org.apache.zookeeper.ClientCnxn: Closing ClientCnxn &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; session: 0x22274aa40700002
2009-07-13 14:12:11,422 INFO org.apache.zookeeper.ClientCnxn: Disconnecting ClientCnxn &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; session: 0x22274aa40700002
2009-07-13 14:12:11,422 INFO org.apache.zookeeper.ZooKeeper: Session: 0x22274aa40700002 closed
2009-07-13 14:12:11,422 DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper: Closed connection with ZooKeeper
2009-07-13 14:12:11,422 INFO org.apache.zookeeper.ClientCnxn: EventThread shut down
2009-07-13 14:12:11,997 INFO org.apache.zookeeper.ClientCnxn: Exception &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; closing send thread &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; session 0x12274aa40060005 : Read error rc = -1 java.nio.DirectByteBuffer[pos=0 lim=4 cap=4]
2009-07-13 14:12:12,101 INFO org.apache.zookeeper.ClientCnxn: Disconnecting ClientCnxn &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; session: 0x12274aa40060005
2009-07-13 14:12:12,101 INFO org.apache.zookeeper.ZooKeeper: Session: 0x12274aa40060005 closed
2009-07-13 14:12:12,101 INFO org.apache.zookeeper.ClientCnxn: EventThread shut down
2009-07-13 14:12:12,101 DEBUG org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper: Closed connection with ZooKeeper
2009-07-13 14:12:12,149 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: regionserver/**************:60020 exiting
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12744674" author="stack" created="Tue, 18 Aug 2009 19:59:33 +0000"  >&lt;p&gt;Moving to 0.21.  Too meaty for a point release and 0.21 master rewrite is all about fixing this kinda thing.  Please move it back if any of you lads think different.&lt;/p&gt;</comment>
                            <comment id="12864613" author="jdcryans" created="Thu, 6 May 2010 01:32:01 +0000"  >&lt;p&gt;I vote we resolve this issue as a dupe of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2231&quot; title=&quot;Compaction events should be written to HLog&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2231&quot;&gt;&lt;del&gt;HBASE-2231&lt;/del&gt;&lt;/a&gt;, what happens here is that the region is processing stuff even after a GC when it shouldn&apos;t and what we need is more like IO fencing.&lt;/p&gt;</comment>
                            <comment id="12902139" author="jdcryans" created="Tue, 24 Aug 2010 23:11:15 +0000"  >&lt;p&gt;Resolving as duplicate of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-2231&quot; title=&quot;Compaction events should be written to HLog&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-2231&quot;&gt;&lt;del&gt;HBASE-2231&lt;/del&gt;&lt;/a&gt; and many others per my last comment. &lt;/p&gt;</comment>
                            <comment id="15017847" author="lars_francke" created="Fri, 20 Nov 2015 13:01:36 +0000"  >&lt;p&gt;This issue was closed as part of a bulk closing operation on 2015-11-20. All issues that have been resolved and where all fixVersions have been released have been closed (following discussions on the mailing list).&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310010">
                    <name>Incorporates</name>
                                                                <inwardlinks description="is part of">
                                        <issuelink>
            <issuekey id="12434794">HBASE-1816</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12422196">HBASE-1314</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 19 May 2009 19:23:48 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>25755</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 2 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hd9r:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>99412</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>