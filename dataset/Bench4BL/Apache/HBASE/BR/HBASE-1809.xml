<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 02 20:22:03 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-1809/HBASE-1809.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-1809] NPE thrown in BoundedRangeFileInputStream</title>
                <link>https://issues.apache.org/jira/browse/HBASE-1809</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;NPE is thrown in BoundedRangeFileInputStream.read when attempting to synchronize on &apos;in&apos; (line 97).&lt;/p&gt;

&lt;p&gt;This probably means the BRFIS was created with a null FSDIS.&lt;/p&gt;</description>
                <environment>&lt;p&gt;All&lt;/p&gt;</environment>
        <key id="12434554">HBASE-1809</key>
            <summary>NPE thrown in BoundedRangeFileInputStream</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="stack">stack</assignee>
                                    <reporter username="herberts">Mathias Herberts</reporter>
                        <labels>
                    </labels>
                <created>Tue, 1 Sep 2009 20:55:51 +0000</created>
                <updated>Fri, 20 Nov 2015 13:01:20 +0000</updated>
                            <resolved>Wed, 23 Sep 2009 00:13:52 +0000</resolved>
                                                    <fixVersion>0.20.1</fixVersion>
                                    <component>io</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="12750095" author="herberts" created="Tue, 1 Sep 2009 20:58:42 +0000"  >&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2009-09-01 18:05:15,644 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: 
java.lang.NullPointerException
        at org.apache.hadoop.hbase.io.hfile.BoundedRangeFileInputStream.read(BoundedRangeFileInputStream.java:97)
        at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:100)
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.decompress(HFile.java:979)
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.readBlock(HFile.java:936)
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader$Scanner.loadBlock(HFile.java:1258)
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader$Scanner.seekTo(HFile.java:1141)
        at org.apache.hadoop.hbase.regionserver.StoreFileGetScan.getStoreFile(StoreFileGetScan.java:80)
        at org.apache.hadoop.hbase.regionserver.StoreFileGetScan.get(StoreFileGetScan.java:65)
        at org.apache.hadoop.hbase.regionserver.Store.get(Store.java:1442)
        at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1043)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1755)
        at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:650)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:915)
2009-09-01 18:05:15,665 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 8 on 60020, call getClosestRowBefore([B@68f2f88, [B@22798d15, [B@5a1d6f61) from 10.154.99.180:37118: error: java.io.IOException: java.lang.NullPointerException
java.io.IOException: java.lang.NullPointerException
        at org.apache.hadoop.hbase.regionserver.HRegionServer.convertThrowableToIOE(HRegionServer.java:847)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.convertThrowableToIOE(HRegionServer.java:837)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1758)
        at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:650)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:915)
Caused by: java.lang.NullPointerException
        at org.apache.hadoop.hbase.io.hfile.BoundedRangeFileInputStream.read(BoundedRangeFileInputStream.java:97)
        at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:100)
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.decompress(HFile.java:979)
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.readBlock(HFile.java:936)
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader$Scanner.loadBlock(HFile.java:1258)
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader$Scanner.seekTo(HFile.java:1141)
        at org.apache.hadoop.hbase.regionserver.StoreFileGetScan.getStoreFile(StoreFileGetScan.java:80)
        at org.apache.hadoop.hbase.regionserver.StoreFileGetScan.get(StoreFileGetScan.java:65)
        at org.apache.hadoop.hbase.regionserver.Store.get(Store.java:1442)
        at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1043)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1755)
        ... 5 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12750096" author="herberts" created="Tue, 1 Sep 2009 21:00:37 +0000"  >&lt;p&gt;This error probably caused a row not to be inserted during a bulk upload (with WriteBuffer size set to 0, AutoFlush set to false and setWriteToWAL set to false in the Put instance).&lt;/p&gt;</comment>
                            <comment id="12750102" author="herberts" created="Tue, 1 Sep 2009 21:18:12 +0000"  >&lt;p&gt;While digging in the code for this issue I came across a problem in HFile$Reader.decompress.&lt;/p&gt;

&lt;p&gt;In case an exception is thrown, the decompressor is not returned to the pool.&lt;/p&gt;

&lt;p&gt;The attached patch fixes this by enclosing the content in a try ... finally&lt;/p&gt;</comment>
                            <comment id="12750174" author="stack" created="Tue, 1 Sep 2009 23:12:18 +0000"  >&lt;p&gt;My guess is the file was closed by one thread while another was trying to read.  This is a bit of a race condition.  Simple fix would be to add a volatile &apos;closed&apos; flag.. returning immediately from read and available when set (or just check for a null &apos;in&apos;).  Better would be to figure how this race condition arose (Something peculiar to getClosestRowBefore).&lt;/p&gt;</comment>
                            <comment id="12750180" author="stack" created="Tue, 1 Sep 2009 23:27:18 +0000"  >&lt;p&gt;I applied the above try/catch addition from Mathias to branch and trunk.&lt;/p&gt;</comment>
                            <comment id="12751341" author="herberts" created="Fri, 4 Sep 2009 07:16:18 +0000"  >&lt;p&gt;I hit this NPE again, this time in a call to &apos;get&apos;, as the log message contains a row key, I will try to hunt the region to see if there was any particular activity around that time.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2009-09-04 02:31:52,192 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: 
java.lang.NullPointerException
        at org.apache.hadoop.hbase.io.hfile.BoundedRangeFileInputStream.read(BoundedRangeFileInputStream.java:97)
        at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:100)
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.decompress(HFile.java:982)
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.readBlock(HFile.java:936)
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader$Scanner.loadBlock(HFile.java:1265)
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader$Scanner.seekTo(HFile.java:1148)
        at org.apache.hadoop.hbase.regionserver.StoreFileGetScan.getStoreFile(StoreFileGetScan.java:80)
        at org.apache.hadoop.hbase.regionserver.StoreFileGetScan.get(StoreFileGetScan.java:65)
        at org.apache.hadoop.hbase.regionserver.Store.get(Store.java:1442)
        at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:2301)
        at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:2290)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.get(HRegionServer.java:1768)
        at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:650)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:915)
2009-09-04 02:31:52,195 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 4 on 60020, call get([B@3e507609, row=domirama,0TE332647699C&#65533;&#65533;^?&#65533;&#65533;&#65533;,1252024306264, maxVersions=1, timeRange=[0,9223372036854775807), families={(family=info, columns=ALL}) from 10.154.99.180:57418: error: java.i
o.IOException: java.lang.NullPointerException
java.io.IOException: java.lang.NullPointerException
        at org.apache.hadoop.hbase.regionserver.HRegionServer.convertThrowableToIOE(HRegionServer.java:847)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.convertThrowableToIOE(HRegionServer.java:837)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.get(HRegionServer.java:1770)
        at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:650)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:915)
Caused by: java.lang.NullPointerException
        at org.apache.hadoop.hbase.io.hfile.BoundedRangeFileInputStream.read(BoundedRangeFileInputStream.java:97)
        at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:100)
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.decompress(HFile.java:982)
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.readBlock(HFile.java:936)
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader$Scanner.loadBlock(HFile.java:1265)
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader$Scanner.seekTo(HFile.java:1148)
        at org.apache.hadoop.hbase.regionserver.StoreFileGetScan.getStoreFile(StoreFileGetScan.java:80)
        at org.apache.hadoop.hbase.regionserver.StoreFileGetScan.get(StoreFileGetScan.java:65)
        at org.apache.hadoop.hbase.regionserver.Store.get(Store.java:1442)
        at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:2301)
        at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:2290)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.get(HRegionServer.java:1768)
        ... 5 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12751616" author="stack" created="Fri, 4 Sep 2009 21:15:47 +0000"  >&lt;p&gt;This patch would address the immediate NPE (What I do in the constructor might not be the smartest) but something else is going on if we have one thread reading off a closed stream.  Chatting w/ Mathias, he sees this NPE with get and getclosest.  Both take out read locks on the store so another thread shouldn&apos;t be doing close this store file.  Mathias is trying to figure more input.&lt;/p&gt;</comment>
                            <comment id="12758494" author="stack" created="Tue, 22 Sep 2009 23:33:42 +0000"  >&lt;p&gt;Mathias later ran with the above patch applied.  The above patch makes the stream final in BoundedRangeFileInputStream which would seem to indicate that it was passed a null stream... that the stream had already been closed by Reader.  Need to back up into Reader and try to figure why a read came in after it had been closed.&lt;/p&gt;</comment>
                            <comment id="12758504" author="ryanobjc" created="Wed, 23 Sep 2009 00:07:35 +0000"  >&lt;p&gt;+1, surprised how long it took to find this one.&lt;/p&gt;</comment>
                            <comment id="12758505" author="stack" created="Wed, 23 Sep 2009 00:09:35 +0000"  >&lt;p&gt;OK. The issue is that everything takes out a read lock in store EXCEPT get.  The first stack trace was misleading in that it was in getclosest.  When I looked at getclosest, it was taking out the read lock so I couldn&apos;t figure it but up in HRegion#getclosest, at its tail, it makes a call to get with the row returned by getclosest.  The second stack trace is bare about what the issue is in that its just a pure get. &lt;/p&gt;

&lt;p&gt;The attached patch adds getting of a read lock to get.  It lets go of the messing I made in the first version of the patch where I added a flag to BoundedRangeFilterInputStream.  It was not fixing the root cause.&lt;/p&gt;</comment>
                            <comment id="12758506" author="stack" created="Wed, 23 Sep 2009 00:13:52 +0000"  >&lt;p&gt;Committed branch and trunk&lt;/p&gt;</comment>
                            <comment id="12759715" author="stack" created="Fri, 25 Sep 2009 19:26:55 +0000"  >&lt;p&gt;I just ran into this on an 0.20.0RC2 hbase:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2009-09-24 23:14:45,578 DEBUG org.apache.hadoop.hbase.regionserver.Store: Completed compaction of info; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; storefile is hdfs:&lt;span class=&quot;code-comment&quot;&gt;//XX.XX.XX.XX:10000/hbase/coral_hbase/.META./1028785192/info/1652111193973935565; store size is 752.9k
&lt;/span&gt;2009-09-24 23:14:45,581 INFO org.apache.hadoop.hbase.regionserver.HRegion: compaction completed on region .META.,,1 in 0sec
2009-09-24 23:14:45,607 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: 
java.lang.NullPointerException
        at org.apache.hadoop.hbase.io.hfile.BoundedRangeFileInputStream.read(BoundedRangeFileInputStream.java:97)
        at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:100)
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.decompress(HFile.java:979)
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.readBlock(HFile.java:936)
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader$Scanner.loadBlock(HFile.java:1258)
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader$Scanner.seekTo(HFile.java:1141)
        at org.apache.hadoop.hbase.regionserver.StoreFileGetScan.getStoreFile(StoreFileGetScan.java:80)
        at org.apache.hadoop.hbase.regionserver.StoreFileGetScan.get(StoreFileGetScan.java:65)
        at org.apache.hadoop.hbase.regionserver.Store.get(Store.java:1442)
        at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1043)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1755)
        at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:650)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:915)
2009-09-24 23:14:45,607 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: 
java.io.IOException: Stream closed
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:1705)
        at java.io.DataInputStream.read(Unknown Source)
        at org.apache.hadoop.hbase.io.hfile.BoundedRangeFileInputStream.read(BoundedRangeFileInputStream.java:99)
        at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:100)
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.decompress(HFile.java:979)
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.readBlock(HFile.java:936)
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader$Scanner.loadBlock(HFile.java:1258)
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader$Scanner.seekTo(HFile.java:1141)
        at org.apache.hadoop.hbase.regionserver.StoreFileGetScan.getStoreFile(StoreFileGetScan.java:80)
        at org.apache.hadoop.hbase.regionserver.StoreFileGetScan.get(StoreFileGetScan.java:65)
        at org.apache.hadoop.hbase.regionserver.Store.get(Store.java:1442)
        at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1043)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1755)
        at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:650)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:915)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So a compaction completion and then just after &amp;#8211; about 30ms &amp;#8211; a read comes in and gets NPE I guess because its going against a closed storefile.&lt;/p&gt;</comment>
                            <comment id="15017777" author="lars_francke" created="Fri, 20 Nov 2015 13:01:20 +0000"  >&lt;p&gt;This issue was closed as part of a bulk closing operation on 2015-11-20. All issues that have been resolved and where all fixVersions have been released have been closed (following discussions on the mailing list).&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12420326" name="1809-v2.patch" size="2438" author="stack" created="Wed, 23 Sep 2009 00:05:37 +0000"/>
                            <attachment id="12418670" name="1809.patch" size="1876" author="stack" created="Fri, 4 Sep 2009 21:15:47 +0000"/>
                            <attachment id="12418300" name="HFile-returnDecompressor.patch" size="2046" author="herberts" created="Tue, 1 Sep 2009 21:18:12 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 1 Sep 2009 23:12:18 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>25995</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 2 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hfdr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>99754</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>