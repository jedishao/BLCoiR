<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 02 19:56:31 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-1061/HBASE-1061.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-1061] Region Server  throw NotServingRegionException when batchUpdate during compaction/spliting and then shutdown</title>
                <link>https://issues.apache.org/jira/browse/HBASE-1061</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;2008-12-13 21:30:58,184 INFO org.apache.hadoop.hbase.regionserver.LogRoller: Rolling hlog. Number of entries: 30015&lt;br/&gt;
2008-12-13 21:30:58,595 INFO org.apache.hadoop.hbase.regionserver.HRegion: starting compaction on region GDR,138884579261228161625885,1229166027688&lt;br/&gt;
2008-12-13 21:31:00,162 INFO org.apache.hadoop.hbase.regionserver.HLog: New log writer created at /hbase/log_10.24.1.12_1229150189049_60020/hlog.dat.1229175060158&lt;br/&gt;
2008-12-13 21:31:00,162 INFO org.apache.hadoop.hbase.regionserver.HLog: removing old log file /hbase/log_10.24.1.12_1229150189049_60020/hlog.dat.1229173244235 whose highest sequence/edit id is 145008256&lt;br/&gt;
2008-12-13 21:31:00,165 INFO org.apache.hadoop.hbase.regionserver.HLog: removing old log file /hbase/log_10.24.1.12_1229150189049_60020/hlog.dat.1229173248573 whose highest sequence/edit id is 145038271&lt;br/&gt;
2008-12-13 21:31:05,571 INFO org.apache.hadoop.hbase.regionserver.HRegion: compaction completed on region GDR,138884579261228161625885,1229166027688 in 6sec&lt;br/&gt;
2008-12-13 21:31:05,571 INFO org.apache.hadoop.hbase.regionserver.HRegion: Starting split of region GDR,138884579261228161625885,1229166027688&lt;br/&gt;
2008-12-13 21:31:05,735 INFO org.apache.hadoop.hbase.regionserver.HRegion: closed GDR,138884579261228161625885,1229166027688&lt;br/&gt;
2008-12-13 21:31:05,863 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 60020, call batchUpdate([B@4df611bd, row =&amp;gt; 138884603141228853661885, &lt;/p&gt;
{column =&amp;gt; gdr:start_time, value =&amp;gt; &apos;...&apos;, column =&amp;gt; gdr:imsi, value =&amp;gt; &apos;...&apos;, column =&amp;gt; gdr:msisdn, value =&amp;gt; &apos;...&apos;, column =&amp;gt; gdr:sourceip, value =&amp;gt; &apos;...&apos;, column =&amp;gt; gdr:destip, value =&amp;gt; &apos;...&apos;, column =&amp;gt; gdr:gdrtype, value =&amp;gt; &apos;...&apos;, column =&amp;gt; gdr:req_num, value =&amp;gt; &apos;...&apos;, column =&amp;gt; gdr:apn, value =&amp;gt; &apos;...&apos;, column =&amp;gt; gdr:gdrtime, value =&amp;gt; &apos;...&apos;, column =&amp;gt; gdr:result, value =&amp;gt; &apos;...&apos;, column =&amp;gt; gdr:gtpver, value =&amp;gt; &apos;...&apos;, column =&amp;gt; gdr:remoteno, value =&amp;gt; &apos;...&apos;, column =&amp;gt; gdr:frontno, value =&amp;gt; &apos;...&apos;, column =&amp;gt; gdr:offset, value =&amp;gt; &apos;...&apos;, column =&amp;gt; gdr:url, value =&amp;gt; &apos;...&apos;}
&lt;p&gt;, -1) from 10.24.1.10:39000: error: org.apache.hadoop.hbase.NotServingRegionException: Region GDR,138884579261228161625885,1229166027688 closed&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: Region GDR,138884579261228161625885,1229166027688 closed&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1836)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1901)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1432)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1415)&lt;br/&gt;
        at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)&lt;br/&gt;
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
        at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;br/&gt;
2008-12-13 21:31:07,594 INFO org.apache.hadoop.hbase.regionserver.HRegion: region GDR,138884579261228161625885,1229175065574/642186371 available&lt;br/&gt;
2008-12-13 21:31:07,594 INFO org.apache.hadoop.hbase.regionserver.HRegion: closed GDR,138884579261228161625885,1229175065574&lt;br/&gt;
2008-12-13 21:31:07,885 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 60020, call batchUpdate([B@7792b8d, row =&amp;gt; 138884603141228853661885, &lt;/p&gt;
{column =&amp;gt; gdr:start_time, value =&amp;gt; &apos;...&apos;, column =&amp;gt; gdr:imsi, value =&amp;gt; &apos;...&apos;, column =&amp;gt; gdr:msisdn, value =&amp;gt; &apos;...&apos;, column =&amp;gt; gdr:sourceip, value =&amp;gt; &apos;...&apos;, column =&amp;gt; gdr:destip, value =&amp;gt; &apos;...&apos;, column =&amp;gt; gdr:gdrtype, value =&amp;gt; &apos;...&apos;, column =&amp;gt; gdr:req_num, value =&amp;gt; &apos;...&apos;, column =&amp;gt; gdr:apn, value =&amp;gt; &apos;...&apos;, column =&amp;gt; gdr:gdrtime, value =&amp;gt; &apos;...&apos;, column =&amp;gt; gdr:result, value =&amp;gt; &apos;...&apos;, column =&amp;gt; gdr:gtpver, value =&amp;gt; &apos;...&apos;, column =&amp;gt; gdr:remoteno, value =&amp;gt; &apos;...&apos;, column =&amp;gt; gdr:frontno, value =&amp;gt; &apos;...&apos;, column =&amp;gt; gdr:offset, value =&amp;gt; &apos;...&apos;, column =&amp;gt; gdr:url, value =&amp;gt; &apos;...&apos;}
&lt;p&gt;, -1) from 10.24.1.10:39000: error: org.apache.hadoop.hbase.NotServingRegionException: Region GDR,138884579261228161625885,1229166027688 closed&lt;br/&gt;
org.apache.hadoop.hbase.NotServingRegionException: Region GDR,138884579261228161625885,1229166027688 closed&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1836)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1901)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1432)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1406)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1415)&lt;br/&gt;
        at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)&lt;br/&gt;
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
        at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:554)&lt;br/&gt;
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;br/&gt;
2008-12-13 21:31:08,346 INFO org.apache.hadoop.hbase.regionserver.HRegion: region GDR,138884596811227665528885,1229175065574/1240335718 available&lt;/p&gt;


&lt;p&gt;The many region throw such exception. and then the region server shutdown&lt;/p&gt;

&lt;p&gt;2008-12-13 22:01:46,700 WARN org.apache.hadoop.dfs.DFSClient: DataStreamer Exception: java.io.IOException: Unable to create new block.&lt;br/&gt;
        at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.nextBlockOutputStream(DFSClient.java:2349)&lt;br/&gt;
        at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.access$1800(DFSClient.java:1735)&lt;br/&gt;
        at org.apache.hadoop.dfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:1912)&lt;/p&gt;

&lt;p&gt;2008-12-13 22:01:46,701 WARN org.apache.hadoop.dfs.DFSClient: Error Recovery for block blk_-1991134958879829135_36755 bad datanode&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;&lt;br/&gt;
2008-12-13 22:01:46,701 FATAL org.apache.hadoop.hbase.regionserver.Flusher: Replay of hlog required. Forcing server shutdown&lt;/p&gt;

&lt;p&gt;and at last:&lt;br/&gt;
008-12-13 22:04:53,414 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.24.1.18:60020. Already tried 6 time(s).&lt;br/&gt;
2008-12-13 22:04:54,417 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.24.1.18:60020. Already tried 7 time(s).&lt;br/&gt;
2008-12-13 22:04:55,420 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.24.1.18:60020. Already tried 8 time(s).&lt;br/&gt;
2008-12-13 22:04:56,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.24.1.18:60020. Already tried 9 time(s).&lt;br/&gt;
2008-12-13 22:07:04,556 ERROR org.apache.hadoop.hbase.regionserver.CompactSplitThread: Compaction failed for region GDR,138883452271227827193885,1229167157710&lt;br/&gt;
java.lang.NullPointerException&lt;br/&gt;
        at org.apache.hadoop.hbase.client.ServerCallable.getRegionName(ServerCallable.java:71)&lt;br/&gt;
        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getRegionServerWithRetries(HConnectionManager.java:863)&lt;br/&gt;
        at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:964)&lt;br/&gt;
        at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:950)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.CompactSplitThread.split(CompactSplitThread.java:167)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.CompactSplitThread.run(CompactSplitThread.java:85)&lt;br/&gt;
2008-12-13 22:07:04,558 INFO org.apache.hadoop.hbase.regionserver.CompactSplitThread: regionserver/0:0:0:0:0:0:0:0:60020.compactor exiting&lt;br/&gt;
2008-12-13 22:07:04,558 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: regionserver/0:0:0:0:0:0:0:0:60020 exiting&lt;br/&gt;
2008-12-13 22:07:04,627 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Starting shutdown thread.&lt;br/&gt;
2008-12-13 22:07:04,627 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Shutdown thread complete&lt;/p&gt;
</description>
                <environment>&lt;p&gt;1 master, 4 region server&lt;br/&gt;
Hadoop 0.18.1&lt;br/&gt;
When about 30GB  30,000,000 rows loaded&lt;/p&gt;</environment>
        <key id="12410629">HBASE-1061</key>
            <summary>Region Server  throw NotServingRegionException when batchUpdate during compaction/spliting and then shutdown</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="schubertzhang">Schubert Zhang</assignee>
                                    <reporter username="schubertzhang">Schubert Zhang</reporter>
                        <labels>
                    </labels>
                <created>Sat, 13 Dec 2008 14:53:02 +0000</created>
                <updated>Sun, 13 Sep 2009 22:24:17 +0000</updated>
                            <resolved>Sun, 30 Aug 2009 20:19:40 +0000</resolved>
                                    <version>0.18.1</version>
                                    <fixVersion>0.20.0</fixVersion>
                                    <component>regionserver</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="12656330" author="stack" created="Sat, 13 Dec 2008 21:18:53 +0000"  >&lt;p&gt;Please enable DEBUG and repost (See FAQ for how).   What are the stats on your hdfs?  Tell us about your uploader?  Looks like your cluster may be suffering overloading as seemed apparent from the other JIRA you opened.&lt;/p&gt;</comment>
                            <comment id="12656371" author="schubertzhang" created="Sun, 14 Dec 2008 08:49:37 +0000"  >&lt;p&gt;I enbaled the DEBUG log, and the log file is attached.&lt;br/&gt;
The state of HDFS is OK, &lt;br/&gt;
Node 	 Last Contact 	 Admin State 	 Size (GB) 	 Used (%) 	 Used (%) 	 Remaining (GB) 	 Blocks&lt;br/&gt;
nd1-rack0-cloud	1	In Service	822.8	1.13	&lt;/p&gt;

&lt;p&gt;	755.27	806&lt;br/&gt;
nd2-rack0-cloud	2	In Service	822.8	1.1	&lt;/p&gt;

&lt;p&gt;	755.4	3204&lt;br/&gt;
nd3-rack0-cloud	1	In Service	822.8	1.17	&lt;/p&gt;

&lt;p&gt;	755.14	1918&lt;br/&gt;
nd4-rack0-cloud	2	In Service	822.8	1.18	&lt;/p&gt;

&lt;p&gt;	755.13	2325&lt;/p&gt;

&lt;p&gt;The loader code like following code:&lt;br/&gt;
		HTable table = new HTable(ConfInstance.instance(), tableName);&lt;/p&gt;

&lt;p&gt;		for(int i = 0; ;++i) {&lt;br/&gt;
			Date start = new Date(date.getTime() - random.nextInt(30*24*60*60) * 1000L);&lt;/p&gt;

&lt;p&gt;			Integer end = random.nextInt(900000) + 100000;&lt;br/&gt;
			String imsi = TestAdd.imsiBegin + end.toString();&lt;/p&gt;

&lt;p&gt;			BatchUpdate update = new BatchUpdate(imsi + start.getTime());&lt;br/&gt;
			update.put(&quot;gdr:start_time&quot;, TypeDefine.toBytes(start.getTime()));&lt;br/&gt;
			update.put(&quot;gdr:msisdn&quot;, TypeDefine.toBytes(imsi));&lt;br/&gt;
			update.put(&quot;gdr:sourceip&quot;, TypeDefine.toBytes(random.nextInt()));&lt;br/&gt;
			update.put(&quot;gdr:destip&quot;, TypeDefine.toBytes(random.nextInt()));&lt;/p&gt;

&lt;p&gt;			update.put(&quot;gdr:gdrtype&quot;, TypeDefine.toBytes(random.nextInt(10) + 1));&lt;br/&gt;
			update.put(&quot;gdr:req_num&quot;, TypeDefine.toBytes(random.nextInt(10) + 1));		&lt;br/&gt;
			update.put(&quot;gdr:apn&quot;, TypeDefine.toBytes(TestAdd.apns&lt;span class=&quot;error&quot;&gt;&amp;#91;random.nextInt(2)&amp;#93;&lt;/span&gt;));	&lt;br/&gt;
			update.put(&quot;gdr:gdrtime&quot;, TypeDefine.toBytes(random.nextInt(10000) + 1));		&lt;br/&gt;
			update.put(&quot;gdr:result&quot;, TypeDefine.toBytes(random.nextInt(2)));	&lt;br/&gt;
			update.put(&quot;gdr:gtpver&quot;, TypeDefine.toBytes(random.nextInt(100) + 1));	&lt;br/&gt;
			update.put(&quot;gdr:remoteno&quot;, TypeDefine.toBytes(random.nextInt(1000) + 1));&lt;br/&gt;
			update.put(&quot;gdr:frontno&quot;, TypeDefine.toBytes(random.nextInt(1000) + 1));	&lt;br/&gt;
			update.put(&quot;gdr:url&quot;, TypeDefine.toBytes(TestAdd.urls&lt;span class=&quot;error&quot;&gt;&amp;#91;random.nextInt(TestAdd.urls.length)&amp;#93;&lt;/span&gt;));&lt;/p&gt;

&lt;p&gt;			try &lt;/p&gt;
{
				table.commit(update);
			}
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
				e.printStackTrace();
				Thread.sleep(60000);
			}
</comment>
                            <comment id="12656385" author="apurtell" created="Sun, 14 Dec 2008 12:42:44 +0000"  >&lt;p&gt;I&apos;ve seen a failure case recently where delayed splits cause so much data to build that when finally the compact/split happens, DFS is overwhelmed, and file errors result. See &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1050?focusedCommentId=12656384#action_12656384&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-1050?focusedCommentId=12656384#action_12656384&lt;/a&gt; . Maybe this is another instance of that?&lt;/p&gt;</comment>
                            <comment id="12749319" author="schubertzhang" created="Sun, 30 Aug 2009 20:19:40 +0000"  >&lt;p&gt;Duplicated to &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1050&quot; title=&quot;Allow regions to split around scanners&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1050&quot;&gt;&lt;del&gt;HBASE-1050&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310010">
                    <name>Incorporates</name>
                                            <outwardlinks description="incorporates">
                                        <issuelink>
            <issuekey id="12411412">HBASE-1094</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12396021" name="hbase-stephen-regionserver-nd4-rack0-cloud.log" size="2961494" author="schubertzhang" created="Sun, 14 Dec 2008 08:49:37 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sat, 13 Dec 2008 21:18:53 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>25549</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 14 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hb3b:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>99059</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>