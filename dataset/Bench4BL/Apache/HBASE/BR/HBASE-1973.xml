<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sat Dec 03 16:37:33 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-1973/HBASE-1973.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-1973] Second RS goes down because &quot;Bad connect ack with firstBadLink as...&quot;</title>
                <link>https://issues.apache.org/jira/browse/HBASE-1973</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Placeholder for issue where a second RS goes down when I kill another RS and its DN.  I asked over on hdfs-user why we&apos;re stuck on 140.  Why can&apos;t it move on to another DN creating a block.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2009-11-12 05:09:38,624 [regionserver/208.76.44.141:60020.logRoller] INFO org.apache.hadoop.hbase.regionserver.wal.HLog: Roll /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002405346, entries=52747, calcsize=63757973, filesize=58588977. New hlog /hbase/.logs/aa0-000-14.u.powerset.com,60020,12
58002404935/hlog.dat.1258002578617
2009-11-12 05:09:38,628 [regionserver/208.76.44.141:60020.logRoller] DEBUG org.apache.hadoop.hbase.regionserver.wal.HLog: Found 0 hlogs to remove  out of total 1; oldest outstanding seqnum is 1 from region .META.,,1
2009-11-12 05:09:38,628 [IPC Server handler 16 on 60020] INFO org.apache.hadoop.hbase.regionserver.wal.HLog: edit=0, write=TestTable/TestTable,,1258002466308/612228
2009-11-12 05:09:38,630 [regionserver/208.76.44.141:60020.logSyncer] INFO org.apache.hadoop.hbase.regionserver.wal.HLog: sync
2009-11-12 05:09:38,646 [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-61] INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream java.io.IOException: Bad connect ack with firstBadLink as 208.76.44.140:51010
2009-11-12 05:09:38,646 [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-61] INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_1786802275426334496_1076
2009-11-12 05:09:44,662 [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-61] INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream java.io.IOException: Bad connect ack with firstBadLink as 208.76.44.140:51010
2009-11-12 05:09:44,662 [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-61] INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_5838454320666652488_1076
2009-11-12 05:09:46,226 [pool-1-thread-1] DEBUG org.apache.hadoop.hbase.io.hfile.LruBlockCache: Cache Stats: Sizes: Total=5.5656967MB (5836056), Free=672.77185MB (705452392), Max=678.3375MB (711288448), Counts: Blocks=0, Access=0, Hit=0, Miss=0, Evictions=0, Evicted=0, Ratios: Hit Ratio=NaN%, Miss Ratio=NaN%, Evicted
/Run=NaN
2009-11-12 05:09:50,683 [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-61] INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream java.io.IOException: Bad connect ack with firstBadLink as 208.76.44.140:51010
2009-11-12 05:09:50,684 [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-61] INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_8615264034947520229_1076
2009-11-12 05:09:56,691 [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-61] INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream java.io.IOException: Bad connect ack with firstBadLink as 208.76.44.140:51010
2009-11-12 05:09:56,692 [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-61] INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_-5632723632070749366_1077
2009-11-12 05:10:02,696 [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-61] WARN org.apache.hadoop.hdfs.DFSClient: DataStreamer Exception: java.io.IOException: Unable to create &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; block.
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSClient.java:3100)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2681)

2009-11-12 05:10:02,697 [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-61] WARN org.apache.hadoop.hdfs.DFSClient: Could not get block locations. Source file &lt;span class=&quot;code-quote&quot;&gt;&quot;/hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617&quot;&lt;/span&gt; - Aborting...
2009-11-12 05:10:02,699 [regionserver/208.76.44.141:60020.logSyncer] FATAL org.apache.hadoop.hbase.regionserver.wal.HLog: Could not append. Requesting close of hlog
java.io.IOException: Bad connect ack with firstBadLink as 208.76.44.140:51010
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.createBlockOutputStream(DFSClient.java:3160)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSClient.java:3080)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2681)
2009-11-12 05:10:02,701 [regionserver/208.76.44.141:60020.logSyncer] ERROR org.apache.hadoop.hbase.regionserver.wal.HLog: Error &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; syncing, requesting close of hlog 
java.io.IOException: Bad connect ack with firstBadLink as 208.76.44.140:51010
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.createBlockOutputStream(DFSClient.java:3160)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSClient.java:3080)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2681)
2009-11-12 05:10:02,703 [IPC Server handler 20 on 60020] FATAL org.apache.hadoop.hbase.regionserver.wal.HLog: Could not append. Requesting close of hlog
java.io.IOException: IOException flush:java.io.IOException: Bad connect ack with firstBadLink as 208.76.44.140:51010
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.hflush(DFSClient.java:3527)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.sync(DFSClient.java:3473)
        at org.apache.hadoop.fs.FSDataOutputStream.sync(FSDataOutputStream.java:97)
        at org.apache.hadoop.hbase.regionserver.wal.HLog.hflush(HLog.java:829)
        at org.apache.hadoop.hbase.regionserver.wal.HLog$LogSyncer.run(HLog.java:751)
2009-11-12 05:10:02,703 [regionserver/208.76.44.141:60020.logSyncer] INFO org.apache.hadoop.hbase.regionserver.wal.HLog: regionserver/208.76.44.141:60020.logSyncer exiting
2009-11-12 05:10:02,706 [IPC Server handler 10 on 60020] FATAL org.apache.hadoop.hbase.regionserver.wal.HLog: Could not append. Requesting close of hlog
java.io.IOException: IOException flush:java.io.IOException: Bad connect ack with firstBadLink as 208.76.44.140:51010
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.hflush(DFSClient.java:3527)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.sync(DFSClient.java:3473)
        at org.apache.hadoop.fs.FSDataOutputStream.sync(FSDataOutputStream.java:97)
        at org.apache.hadoop.hbase.regionserver.wal.HLog.hflush(HLog.java:829)
        at org.apache.hadoop.hbase.regionserver.wal.HLog$LogSyncer.run(HLog.java:751)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12440474">HBASE-1973</key>
            <summary>Second RS goes down because &quot;Bad connect ack with firstBadLink as...&quot;</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="stack">stack</reporter>
                        <labels>
                    </labels>
                <created>Thu, 12 Nov 2009 05:16:01 +0000</created>
                <updated>Tue, 24 Nov 2009 21:05:19 +0000</updated>
                            <resolved>Tue, 24 Nov 2009 21:05:19 +0000</resolved>
                                                                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12776855" author="stack" created="Thu, 12 Nov 2009 05:38:06 +0000"  >&lt;p&gt;Weird thing is that it seems like the create eventually succeeds.. after we&apos;ve given up on it if I look at the NN:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[stack@aa0-000-12 logs]$ grep &apos;/hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617&apos; hadoop-stack-namenode-aa0-000-12.u.powerset.com.log 
2009-11-12 05:09:38,618 DEBUG org.apache.hadoop.hdfs.StateChange: *DIR* NameNode.create: file /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; DFSClient_276778250 at 208.76.44.141
2009-11-12 05:09:38,618 DEBUG org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.startFile: src=/hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617, holder=DFSClient_276778250, clientMachine=208.76.44.141, createParent=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, replication=3, overwrite=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, append=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
2009-11-12 05:09:38,619 DEBUG org.apache.hadoop.hdfs.StateChange: DIR* FSDirectory.addFile: /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617 is added to the file system
2009-11-12 05:09:38,619 DEBUG org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.startFile: add /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617 to namespace &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; DFSClient_276778250
2009-11-12 05:09:38,620 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=stack,powerset,engineering  ip=/208.76.44.141       cmd=create      src=/hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617   dst=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;        perm=stack:supergroup:rw-r--r--
2009-11-12 05:09:38,630 DEBUG org.apache.hadoop.hdfs.StateChange: *BLOCK* NameNode.addBlock: file /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; DFSClient_276778250
2009-11-12 05:09:38,630 DEBUG org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getAdditionalBlock: file /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; DFSClient_276778250
2009-11-12 05:09:38,631 DEBUG org.apache.hadoop.hdfs.StateChange: DIR* FSDirectory.addFile: /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617 with blk_1786802275426334496_1076 block is added to the in-memory file system
2009-11-12 05:09:38,631 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617. blk_1786802275426334496_1076{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[208.76.44.141:51010|RBW], ReplicaUnderConstruction[208.76.44.139:51010|RBW], ReplicaUnderConstruction[208.76.44.140:51010|RBW]]}
2009-11-12 05:09:38,646 DEBUG org.apache.hadoop.hdfs.StateChange: *BLOCK* NameNode.abandonBlock: blk_1786802275426334496_1076 of file /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617
2009-11-12 05:09:38,646 DEBUG org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.abandonBlock: blk_1786802275426334496_1076of file /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617
2009-11-12 05:09:38,646 DEBUG org.apache.hadoop.hdfs.StateChange: DIR* FSDirectory.addFile: /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617 with blk_1786802275426334496_1076 block is added to the file system
2009-11-12 05:09:44,655 DEBUG org.apache.hadoop.hdfs.StateChange: *BLOCK* NameNode.addBlock: file /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; DFSClient_276778250
2009-11-12 05:09:44,655 DEBUG org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getAdditionalBlock: file /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; DFSClient_276778250
2009-11-12 05:09:44,656 DEBUG org.apache.hadoop.hdfs.StateChange: DIR* FSDirectory.addFile: /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617 with blk_5838454320666652488_1076 block is added to the in-memory file system
2009-11-12 05:09:44,656 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617. blk_5838454320666652488_1076{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[208.76.44.141:51010|RBW], ReplicaUnderConstruction[208.76.44.140:51010|RBW], ReplicaUnderConstruction[208.76.44.139:51010|RBW]]}
2009-11-12 05:09:44,662 DEBUG org.apache.hadoop.hdfs.StateChange: *BLOCK* NameNode.abandonBlock: blk_5838454320666652488_1076 of file /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617
2009-11-12 05:09:44,662 DEBUG org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.abandonBlock: blk_5838454320666652488_1076of file /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617
2009-11-12 05:09:44,662 DEBUG org.apache.hadoop.hdfs.StateChange: DIR* FSDirectory.addFile: /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617 with blk_5838454320666652488_1076 block is added to the file system
2009-11-12 05:09:50,675 DEBUG org.apache.hadoop.hdfs.StateChange: *BLOCK* NameNode.addBlock: file /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; DFSClient_276778250
2009-11-12 05:09:50,675 DEBUG org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getAdditionalBlock: file /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; DFSClient_276778250
2009-11-12 05:09:50,676 DEBUG org.apache.hadoop.hdfs.StateChange: DIR* FSDirectory.addFile: /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617 with blk_8615264034947520229_1076 block is added to the in-memory file system
2009-11-12 05:09:50,676 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617. blk_8615264034947520229_1076{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[208.76.44.141:51010|RBW], ReplicaUnderConstruction[208.76.44.139:51010|RBW], ReplicaUnderConstruction[208.76.44.140:51010|RBW]]}
2009-11-12 05:09:50,683 DEBUG org.apache.hadoop.hdfs.StateChange: *BLOCK* NameNode.abandonBlock: blk_8615264034947520229_1076 of file /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617
2009-11-12 05:09:50,683 DEBUG org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.abandonBlock: blk_8615264034947520229_1076of file /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617
2009-11-12 05:09:50,683 DEBUG org.apache.hadoop.hdfs.StateChange: DIR* FSDirectory.addFile: /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617 with blk_8615264034947520229_1076 block is added to the file system
2009-11-12 05:09:56,685 DEBUG org.apache.hadoop.hdfs.StateChange: *BLOCK* NameNode.addBlock: file /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; DFSClient_276778250
2009-11-12 05:09:56,685 DEBUG org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getAdditionalBlock: file /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; DFSClient_276778250
2009-11-12 05:09:56,686 DEBUG org.apache.hadoop.hdfs.StateChange: DIR* FSDirectory.addFile: /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617 with blk_-5632723632070749366_1077 block is added to the in-memory file system
2009-11-12 05:09:56,686 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.allocateBlock: /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617. blk_-5632723632070749366_1077{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[208.76.44.141:51010|RBW], ReplicaUnderConstruction[208.76.44.140:51010|RBW], ReplicaUnderConstruction[208.76.44.139:51010|RBW]]}
2009-11-12 05:09:56,691 DEBUG org.apache.hadoop.hdfs.StateChange: *BLOCK* NameNode.abandonBlock: blk_-5632723632070749366_1077 of file /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617
2009-11-12 05:09:56,691 DEBUG org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.abandonBlock: blk_-5632723632070749366_1077of file /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617
2009-11-12 05:09:56,691 DEBUG org.apache.hadoop.hdfs.StateChange: DIR* FSDirectory.addFile: /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617 with blk_-5632723632070749366_1077 block is added to the file system

Its failing above opening the file.

Below is open by the master doing its split....

2009-11-12 05:10:10,924 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=stack,powerset,engineering  ip=/208.76.44.139       cmd=open        src=/hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617   dst=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;        perm=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
2009-11-12 05:10:10,925 DEBUG org.apache.hadoop.hdfs.StateChange: *DIR* Namenode.delete: src=/hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617, recursive=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
2009-11-12 05:10:10,926 DEBUG org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.delete: /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617
2009-11-12 05:10:10,926 DEBUG org.apache.hadoop.hdfs.StateChange: DIR* FSDirectory.delete: /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617
2009-11-12 05:10:10,926 DEBUG org.apache.hadoop.hdfs.StateChange: DIR* FSDirectory.unprotectedDelete: /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617 is removed
2009-11-12 05:10:10,926 DEBUG org.apache.hadoop.hdfs.server.namenode.LeaseManager: LeaseManager.findLease: prefix=/hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617
2009-11-12 05:10:10,926 DEBUG org.apache.hadoop.hdfs.server.namenode.LeaseManager: LeaseManager.removeLeaseWithPrefixPath: entry=/hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617=[Lease.  Holder: DFSClient_276778250, pendingcreates: 1]
2009-11-12 05:10:10,926 DEBUG org.apache.hadoop.hdfs.StateChange: DIR* Namesystem.delete: /hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617 is removed
2009-11-12 05:10:10,927 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit: ugi=stack,powerset,engineering  ip=/208.76.44.139       cmd=delete      src=/hbase/.logs/aa0-000-14.u.powerset.com,60020,1258002404935/hlog.dat.1258002578617   dst=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;        perm=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The above open on master actually throws an EOFE.  File length is seen as zero.  We don&apos;t do the available on the backing stream to get the length hdfs sees.&lt;/p&gt;</comment>
                            <comment id="12782165" author="stack" created="Tue, 24 Nov 2009 21:05:19 +0000"  >&lt;p&gt;Apply &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-630&quot; title=&quot;In DFSOutputStream.nextBlockOutputStream(), the client can exclude specific datanodes when locating the next block.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-630&quot;&gt;&lt;del&gt;HDFS-630&lt;/del&gt;&lt;/a&gt; to fix this issue.  Resolving.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>26088</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 2 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hg1r:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>99862</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>