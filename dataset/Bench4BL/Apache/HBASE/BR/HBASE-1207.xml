<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 02 20:29:59 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-1207/HBASE-1207.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-1207] Fix locking in memcache flush</title>
                <link>https://issues.apache.org/jira/browse/HBASE-1207</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;memcache flushing holds a write lock while it reopens StoreFileScanners. I had a case where this process timed out and caused an exception to be thrown, which made the region server believe it had been unable to flush it&apos;s cache and shut itself down.&lt;/p&gt;

&lt;p&gt;Stack trace is:&lt;/p&gt;

&lt;p&gt;#&lt;br/&gt;
&quot;regionserver/0:0:0:0:0:0:0:0:60020.cacheFlusher&quot; daemon prio=10 tid=0x00000000562df400 nid=0x15d1 runnable &lt;span class=&quot;error&quot;&gt;&amp;#91;0x000000004108b000..0x000000004108bd90&amp;#93;&lt;/span&gt;&lt;br/&gt;
#&lt;br/&gt;
   java.lang.Thread.State: RUNNABLE&lt;br/&gt;
#&lt;br/&gt;
        at java.util.zip.CRC32.updateBytes(Native Method)&lt;br/&gt;
#&lt;br/&gt;
        at java.util.zip.CRC32.update(CRC32.java:45)&lt;br/&gt;
#&lt;br/&gt;
        at org.apache.hadoop.util.DataChecksum.update(DataChecksum.java:223)&lt;br/&gt;
#&lt;br/&gt;
        at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:241)&lt;br/&gt;
#&lt;br/&gt;
        at org.apache.hadoop.fs.FSInputChecker.fill(FSInputChecker.java:177)&lt;br/&gt;
#&lt;br/&gt;
        at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:194)&lt;br/&gt;
#&lt;br/&gt;
        at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:159)&lt;br/&gt;
#&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;locked &amp;lt;0x00002aaaec1bd2d8&amp;gt; (a org.apache.hadoop.hdfs.DFSClient$BlockReader)&lt;br/&gt;
#&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$BlockReader.read(DFSClient.java:1061)&lt;br/&gt;
#&lt;/li&gt;
	&lt;li&gt;locked &amp;lt;0x00002aaaec1bd2d8&amp;gt; (a org.apache.hadoop.hdfs.DFSClient$BlockReader)&lt;br/&gt;
#&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.readBuffer(DFSClient.java:1616)&lt;br/&gt;
#&lt;/li&gt;
	&lt;li&gt;locked &amp;lt;0x00002aaad1239000&amp;gt; (a org.apache.hadoop.hdfs.DFSClient$DFSInputStream)&lt;br/&gt;
#&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:1666)&lt;br/&gt;
#&lt;/li&gt;
	&lt;li&gt;locked &amp;lt;0x00002aaad1239000&amp;gt; (a org.apache.hadoop.hdfs.DFSClient$DFSInputStream)&lt;br/&gt;
#&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:1593)&lt;br/&gt;
#&lt;/li&gt;
	&lt;li&gt;locked &amp;lt;0x00002aaad1239000&amp;gt; (a org.apache.hadoop.hdfs.DFSClient$DFSInputStream)&lt;br/&gt;
#&lt;br/&gt;
        at java.io.DataInputStream.readInt(DataInputStream.java:371)&lt;br/&gt;
#&lt;br/&gt;
        at org.apache.hadoop.hbase.io.SequenceFile$Reader.next(SequenceFile.java:1943)&lt;br/&gt;
#&lt;/li&gt;
	&lt;li&gt;locked &amp;lt;0x00002aaad1238c38&amp;gt; (a org.apache.hadoop.hbase.io.SequenceFile$Reader)&lt;br/&gt;
#&lt;br/&gt;
        at org.apache.hadoop.hbase.io.SequenceFile$Reader.next(SequenceFile.java:1844)&lt;br/&gt;
#&lt;/li&gt;
	&lt;li&gt;locked &amp;lt;0x00002aaad1238c38&amp;gt; (a org.apache.hadoop.hbase.io.SequenceFile$Reader)&lt;br/&gt;
#&lt;br/&gt;
        at org.apache.hadoop.hbase.io.SequenceFile$Reader.next(SequenceFile.java:1890)&lt;br/&gt;
#&lt;/li&gt;
	&lt;li&gt;locked &amp;lt;0x00002aaad1238c38&amp;gt; (a org.apache.hadoop.hbase.io.SequenceFile$Reader)&lt;br/&gt;
#&lt;br/&gt;
        at org.apache.hadoop.hbase.io.MapFile$Reader.next(MapFile.java:525)&lt;br/&gt;
#&lt;/li&gt;
	&lt;li&gt;locked &amp;lt;0x00002aaad1238b80&amp;gt; (a org.apache.hadoop.hbase.io.HalfMapFileReader)&lt;br/&gt;
#&lt;br/&gt;
        at org.apache.hadoop.hbase.io.HalfMapFileReader.next(HalfMapFileReader.java:192)&lt;br/&gt;
#&lt;/li&gt;
	&lt;li&gt;locked &amp;lt;0x00002aaad1238b80&amp;gt; (a org.apache.hadoop.hbase.io.HalfMapFileReader)&lt;br/&gt;
#&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.StoreFileScanner.getNext(StoreFileScanner.java:312)&lt;br/&gt;
#&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.StoreFileScanner.openReaders(StoreFileScanner.java:110)&lt;br/&gt;
#&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.StoreFileScanner.updateReaders(StoreFileScanner.java:378)&lt;br/&gt;
#&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HStore.notifyChangedReadersObservers(HStore.java:737)&lt;br/&gt;
#&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HStore.updateReaders(HStore.java:725)&lt;br/&gt;
#&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HStore.internalFlushCache(HStore.java:694)&lt;br/&gt;
#&lt;/li&gt;
	&lt;li&gt;locked &amp;lt;0x00002aaab7b41d30&amp;gt; (a java.lang.Integer)&lt;br/&gt;
#&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:630)&lt;br/&gt;
#&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:881)&lt;br/&gt;
#&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:789)&lt;br/&gt;
#&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.MemcacheFlusher.flushRegion(MemcacheFlusher.java:227)&lt;br/&gt;
#&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.MemcacheFlusher.run(MemcacheFlusher.java:137)&lt;/li&gt;
&lt;/ul&gt;
</description>
                <environment></environment>
        <key id="12415196">HBASE-1207</key>
            <summary>Fix locking in memcache flush</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="streamy">Jonathan Gray</assignee>
                                    <reporter username="bmaurer">Ben Maurer</reporter>
                        <labels>
                    </labels>
                <created>Fri, 20 Feb 2009 04:43:39 +0000</created>
                <updated>Sun, 13 Sep 2009 22:24:25 +0000</updated>
                            <resolved>Tue, 16 Jun 2009 15:58:23 +0000</resolved>
                                    <version>0.19.0</version>
                                    <fixVersion>0.20.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12719308" author="streamy" created="Sun, 14 Jun 2009 17:31:20 +0000"  >&lt;p&gt;Having a hard time following the flow of memcache flushing.&lt;/p&gt;

&lt;p&gt;Checks to see whether a memcache flush is necessary is done with a call to MemcacheFlusher.reclaimMemcacheMemory()&lt;/p&gt;

&lt;p&gt;If we are above the acceptable watermark, then we call MemcacheFlusher.flushSomeRegions().  This is supposed to flush out (from largest to smallest) memcaches in the HRegion until we are below the low watermark.&lt;/p&gt;

&lt;p&gt;Each region to be flushed has MemcacheFlusher.flushRegion(HRegion) called on it.  At the end of flushing regions, those which had a memcache flush also have a minor compaction triggered (by adding to the queue in the CompactSplitThread).&lt;/p&gt;

&lt;p&gt;Once in flushRegion() i&apos;m a bit lost.  Seems to be called from multiple different places and a bit hard to follow.&lt;/p&gt;

&lt;p&gt;When the actual flush happens via HRegion.flushcache() , we ensure another flush is not running and writes are enabled (using WriteState for synchronization and volatile booleans).  We then grab a splitsAndCloses readLock in that method and call internalFlushcache().&lt;/p&gt;

&lt;p&gt;Inside this method we grab a writeLock on the updatesLock in the region.  This throws the gate down and does not allow any further mutations on the region.  But this write lock is only used to do the snapshotting, flushing is actually done outside of this lock.&lt;/p&gt;

&lt;p&gt;Where is the reopening of StoreFileScanners being referred to in this issue?  Is it what is addressed in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1503&quot; title=&quot;hbase-1304 dropped updating list of store files on flush&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1503&quot;&gt;&lt;del&gt;HBASE-1503&lt;/del&gt;&lt;/a&gt;?  If so, then this is no longer an issue... If not, need some pointers from here.&lt;/p&gt;</comment>
                            <comment id="12719378" author="streamy" created="Mon, 15 Jun 2009 03:18:52 +0000"  >&lt;p&gt;Later on in the compaction process, this method is called:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;  private int updateStorefiles(final long logCacheFlushId,
    final StoreFile sf, final NavigableSet&amp;lt;KeyValue&amp;gt; cache)
  throws IOException {
    int count = 0;
    this.lock.writeLock().lock();
    try {
      this.storefiles.put(Long.valueOf(logCacheFlushId), sf);
      count = this.storefiles.size();
      // Tell listeners of the change in readers.
      notifyChangedReadersObservers();
      this.memcache.clearSnapshot(cache);
      return count;
    } finally {
      this.lock.writeLock().unlock();
    }
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Do we need this lock given the implementation of changed readers observers now?  I think that we do... this might also means we can drop synchronization in StoreScanner.&lt;/p&gt;</comment>
                            <comment id="12719403" author="streamy" created="Mon, 15 Jun 2009 05:41:24 +0000"  >&lt;p&gt;We also grab a lock when we swap the memcache and snapshot.  There are no concurrency issues with open StoreScanners then, so we can drop synchronization added by my patch in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1503&quot; title=&quot;hbase-1304 dropped updating list of store files on flush&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1503&quot;&gt;&lt;del&gt;HBASE-1503&lt;/del&gt;&lt;/a&gt;.  &lt;b&gt;However&lt;/b&gt; I think there is a problem here.&lt;/p&gt;

&lt;p&gt;We are not notifying readers when we swap the memcache and the snapshot.  So there is a period of time, after snapshot before flush, where we drop the write lock (allowing readers in).  We now have a case where the memcache is empty (snapshot&apos;d) but it has not made it to the storefile yet.  In the case of gets, we look at both the memcache and the snapshot, so this is not an issue.  Scanners, this is not the case.  We will still be &quot;peeked&quot; potentially at a value in the memcache that has been now moved to the snapshot.  Other situations we might iterate down and reach to top of the memcache but it won&apos;t actually exist.&lt;/p&gt;</comment>
                            <comment id="12719429" author="ryanobjc" created="Mon, 15 Jun 2009 06:59:27 +0000"  >&lt;p&gt;following your logic, it suggests that a scanner could get an empty memcache, and files 1-N, but we might scan some, then once notifyChangedReadersObservers() is called, we get file N+1.  If the data that was flushed is &apos;before&apos; the key that is the &apos;top&apos; key, we have missed some data that was written, but not flushed.&lt;/p&gt;

&lt;p&gt;The hole is smalish, but not tiny.  Flushes take about 700ms.&lt;/p&gt;

&lt;p&gt;I think maybe we should:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;add the snapshot to the scan&lt;/li&gt;
	&lt;li&gt;notify changed observers when snapshot is created (and catching the snapshot if it wasnt there)&lt;/li&gt;
	&lt;li&gt;notify changed observers when snapshot is finished flushing to disk (already doing)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;This should close the hole.&lt;/p&gt;

&lt;p&gt;But we should think of a way to verify this bug, and then be able to validate it later on.&lt;/p&gt;</comment>
                            <comment id="12719657" author="stack" created="Mon, 15 Jun 2009 17:25:22 +0000"  >&lt;p&gt;Queue should be updated when snapshot has been made.&lt;/p&gt;

&lt;p&gt;On locking, I&apos;m not sure I follow.  You are now thinking we should remove synchronizations added by 1503 instead of reentrant lock?  And going by your review above, at least to you, seems like locks are a mess around flushing.... Should be cleaning this up?&lt;/p&gt;</comment>
                            <comment id="12719864" author="stack" created="Tue, 16 Jun 2009 00:09:37 +0000"  >&lt;p&gt;Lets chat Jon.  Not sure I follow your dropping synchronization reasoning in StoreScanner.  The referenced lock above is on Store, not on StoreScanner.&lt;/p&gt;

&lt;p&gt;1528 makes it so Scanners continue to see in-memory edits after a snapshot &amp;#8211; we added a MemcacheScanner for snapshot to the KeyValueHeap in StoreScanner (1528 does not notify readers &amp;#8211; it just keeps up scanners on memcache and snapshot... if one is cleared, the scanner on the other finds in-memory scan values for scan#next).&lt;/p&gt;
</comment>
                            <comment id="12719871" author="stack" created="Tue, 16 Jun 2009 00:29:50 +0000"  >&lt;p&gt;Originally, Ben is complaining that updateReaders is taking a long time, so long, a flush timedout and regionserver crashed.&lt;/p&gt;

&lt;p&gt;1. We don&apos;t call updateReaders in StoreFileScanners anymore.  We only do it in one place now, in StoreScanner&lt;br/&gt;
2. Updating readers in SFS was a matter of opening new MapFile.Readers, one for each storefile.  Now, there is no opening inline of a Reader, an expensive operation.  Scanners just use the existing, already-opened HFile.Reader&lt;br/&gt;
3. The seek in new stuff is a lookup into an hfile index that is memory resident.  The seek in old stuff was an actual stream seek.&lt;/p&gt;

&lt;p&gt;New stuff should have difficultly timing out though I suppose it could happen.&lt;/p&gt;

&lt;p&gt;I&apos;d suggest we close this issue because so much has changed since its been reported.  Lets open a new issue if we see timeout in TRUNK.&lt;/p&gt;


</comment>
                            <comment id="12719890" author="stack" created="Tue, 16 Jun 2009 01:20:49 +0000"  >&lt;p&gt;#3 above is not exactly true.  Can actually read in a block.  Let me see what it would take to do another Ben suggested optimization; i.e. reuse scanners we already have open.&lt;/p&gt;</comment>
                            <comment id="12720194" author="streamy" created="Tue, 16 Jun 2009 15:40:33 +0000"  >&lt;p&gt;I have started up a patch to do what you&apos;re describing; reusing the open scanners, basically diff&apos;ing what has changed rather than rebuilding.&lt;/p&gt;

&lt;p&gt;It&apos;s certainly possible but requires a bunch of changes, from the ChangedReadersObserver interface to actually adding some stuff to KeyValueScanner.  The actual modification of the heap should probably actually happen in the KeyValueHeap.  The set of parameters that gets passed through changed readers to KVHeap is (List&amp;lt;StoreFile&amp;gt; deleted, StoreFile added) where added always exists but deleted list is sometimes null.&lt;/p&gt;

&lt;p&gt;I&apos;m happy to finish the patch, but wanted to know if you still think it&apos;s a good idea given the complexity.  It will be far easier to just rebuild the heap and won&apos;t require changing much.  Another approach might be to actually do a &quot;diff&quot;, looking at current storefiles against what&apos;s in the heap.  This will prevent us from needing to change the changed observer interface but we&apos;ll basically be recalculating what we already know when we make the call to it.  If no one comments I will try to get a patch up later today.&lt;/p&gt;</comment>
                            <comment id="12720202" author="streamy" created="Tue, 16 Jun 2009 15:58:23 +0000"  >&lt;p&gt;Fixed as part of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1503&quot; title=&quot;hbase-1304 dropped updating list of store files on flush&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1503&quot;&gt;&lt;del&gt;HBASE-1503&lt;/del&gt;&lt;/a&gt;.  If we see any more weird behavior will open new JIRA.&lt;/p&gt;

&lt;p&gt;Opened &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1530&quot; title=&quot;Optimize changed readers notification to only update what has changed rather than rebuild entire KV heap&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1530&quot;&gt;&lt;del&gt;HBASE-1530&lt;/del&gt;&lt;/a&gt; to deal with optimization discussed in this issue.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310010">
                    <name>Incorporates</name>
                                                                <inwardlinks description="is part of">
                                        <issuelink>
            <issuekey id="12427421">HBASE-1503</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Sun, 14 Jun 2009 17:31:20 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>25625</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 25 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hbyn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>99200</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>