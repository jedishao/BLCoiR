<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sat Dec 03 15:57:21 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-8258/HBASE-8258.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-8258] Make mapreduce tests pass on hadoop2</title>
                <link>https://issues.apache.org/jira/browse/HBASE-8258</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7904&quot; title=&quot;Make mapreduce jobs pass based on 2.0.4-alpha&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7904&quot;&gt;&lt;del&gt;HBASE-7904&lt;/del&gt;&lt;/a&gt; was a first attempt at making this work but it got lost in the weeds.&lt;/p&gt;

&lt;p&gt;This is a new attempt at making hbase mapreduce jobs run on hadoop2 (w/o breaking mapreduce on hadoop1)&lt;/p&gt;</description>
                <environment></environment>
        <key id="12640563">HBASE-8258</key>
            <summary>Make mapreduce tests pass on hadoop2</summary>
                <type id="7" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/subtask_alternate.png">Sub-task</type>
                            <parent id="12609485">HBASE-6891</parent>
                                    <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="jmhsieh">Jonathan Hsieh</assignee>
                                    <reporter username="stack">stack</reporter>
                        <labels>
                    </labels>
                <created>Wed, 3 Apr 2013 18:59:11 +0000</created>
                <updated>Sat, 13 Apr 2013 13:42:16 +0000</updated>
                            <resolved>Tue, 9 Apr 2013 21:56:42 +0000</resolved>
                                                                    <component>mapreduce</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                <comments>
                            <comment id="13621526" author="devaraj" created="Wed, 3 Apr 2013 23:43:23 +0000"  >&lt;p&gt;Am looking at this. Currently, trying to identify which tests fail.&lt;/p&gt;</comment>
                            <comment id="13621542" author="jmhsieh" created="Wed, 3 Apr 2013 23:57:53 +0000"  >&lt;p&gt;Links to previous attempts.  I&apos;m taking a look as well DD.&lt;/p&gt;</comment>
                            <comment id="13621559" author="jmhsieh" created="Thu, 4 Apr 2013 00:11:36 +0000"  >&lt;p&gt;builds.apache.org&apos;s attempts &lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; have been fairly flakey in general recently for tests that are generally fail due to interference from other processes / unit test suites. &lt;/p&gt;

&lt;p&gt;From a recent runs on &quot;beefy&quot; physical hardware, I see these test cases failing regularly:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
org.apache.hadoop.hbase.mapreduce.TestImportExport.testSimpleCase
org.apache.hadoop.hbase.mapreduce.TestImportExport.testMetaExport
org.apache.hadoop.hbase.mapreduce.TestImportExport.testExportScannerBatching
org.apache.hadoop.hbase.mapreduce.TestImportExport.testWithFilter
org.apache.hadoop.hbase.mapreduce.TestImportExport.testWithDeletes
org.apache.hadoop.hbase.mapreduce.TestRowCounter.testRowCounterNoColumn
org.apache.hadoop.hbase.mapreduce.TestRowCounter.testRowCounterHiddenColumn
org.apache.hadoop.hbase.mapreduce.TestRowCounter.testRowCounterExclusiveColumn
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;TestImportExport seems flakey (50:50) while TestRowCounter seems to failed consistently for while.&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13621613" author="devaraj" created="Thu, 4 Apr 2013 01:01:00 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jmhsieh&quot; class=&quot;user-hover&quot; rel=&quot;jmhsieh&quot;&gt;Jonathan Hsieh&lt;/a&gt; for the list of the tests.&lt;/p&gt;

&lt;p&gt;Maybe I am missing something, but when I run the command:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;mvn -PlocalTests -Dhadoop.profile=2.0 -Dtest=TestImportExport test
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;the test fails but the error is very fundamental. There is a &lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;java.lang.NoSuchMethodError: org.apache.hadoop.hdfs.MiniDFSCluster.&amp;amp;lt;init&amp;amp;gt;(ILorg/apache/hadoop/conf/Configuration;IZZZLorg/apache/hadoop/hdfs/server/common/HdfsConstants$StartupOption;[Ljava/lang/String;[Ljava/lang/String;[J)V 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13621618" author="jmhsieh" created="Thu, 4 Apr 2013 01:14:57 +0000"  >&lt;p&gt;Hm.. you are right &amp;#8211; on my setup on April 1 (before the revert of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7904&quot; title=&quot;Make mapreduce jobs pass based on 2.0.4-alpha&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7904&quot;&gt;&lt;del&gt;HBASE-7904&lt;/del&gt;&lt;/a&gt;) trunk runs I have 21 tests in org.apache.hadoop.hbase.mapreduce.  The TestImportExport cases are actually flaking between failure and non being reported (hanging?) sowing only 16 tests in org.apache.hadoop.hbase.mapreduce.&lt;/p&gt;

&lt;p&gt;Here&apos;s my theory from a previous attempt.  I  believe several months ago I narrowed the problem to hbase and the yarn/mr2 instances writing to different hdfs&apos;s.  I might have this flipped but it was something like hbase would write and read from a the minihdfs cluster&apos;s hfds.  So a table would be written to the minihdfs.  The mr2 export job would read from hbase, but write data to a its different &quot;local&quot; file system.  The import job would check for files in its minihdfs cluster and not find them and then fail. &lt;/p&gt;

&lt;p&gt;I&apos;m in the process of confirming if this is still the case.&lt;/p&gt;</comment>
                            <comment id="13621625" author="yuzhihong@gmail.com" created="Thu, 4 Apr 2013 01:25:03 +0000"  >&lt;p&gt;This patch would show the failed tests on top of hadoop 2.0&lt;/p&gt;</comment>
                            <comment id="13621633" author="hadoopqa" created="Thu, 4 Apr 2013 01:33:32 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12576898/8258-plain.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12576898/8258-plain.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5122//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5122//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13621647" author="hadoopqa" created="Thu, 4 Apr 2013 01:52:48 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12576904/8258-plain.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12576904/8258-plain.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javac&lt;/font&gt;.  The patch appears to cause mvn compile goal to fail.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 findbugs&lt;/font&gt;.  The patch appears to cause Findbugs (version 1.3.9) to fail.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 site&lt;/font&gt;.  The patch appears to cause mvn site goal to fail.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;/p&gt;


&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5124//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5124//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5124//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5124//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13621696" author="hadoopqa" created="Thu, 4 Apr 2013 03:07:58 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12576907/8258-plain.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12576907/8258-plain.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 42 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javac&lt;/font&gt;.  The applied patch generated 16 javac compiler warnings (more than the trunk&apos;s current 12 warnings).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 site&lt;/font&gt;.  The patch appears to cause mvn site goal to fail.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.mapreduce.TestMultiTableInputFormat&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestRowCounter&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestImportTsv&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestImportExport&lt;br/&gt;
                  org.apache.hadoop.hbase.mapred.TestTableMapReduce&lt;br/&gt;
                  org.apache.hadoop.hbase.security.token.TestTokenAuthentication&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestTableMapReduce&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestWALPlayer&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestMultithreadedTableMapper&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan&lt;br/&gt;
                  org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are 2 zombie test(s): 	at org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFilesSplitRecovery.testSplitWhileBulkLoadPhase(TestLoadIncrementalHFilesSplitRecovery.java:298)&lt;br/&gt;
	at org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFiles.testSimpleLoad(TestLoadIncrementalHFiles.java:86)&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5126//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5126//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5126//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5126//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5126//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5126//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5126//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5126//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5126//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5126//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5126//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5126//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5126//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5126//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5126//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5126//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5126//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5126//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5126//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5126//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13622371" author="jmhsieh" created="Thu, 4 Apr 2013 14:29:55 +0000"  >&lt;p&gt;The old theory I mentioned above is not relevant.  Here&apos;s the new idea I&apos;m working on.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Certain mapreduce on hadoop2 minicluster jobs are failing, because&lt;/li&gt;
	&lt;li&gt;we are getting an UndeclaredThrowableException when waiting for the MR job to complete, because&lt;/li&gt;
	&lt;li&gt;we get a ConnectException from the mr client trying to talk to 0.0.0.0:8032 (the resource manager port), because&lt;/li&gt;
	&lt;li&gt;... there is a gap here between the local runs and the jenkins runs ...&lt;/li&gt;
	&lt;li&gt;the Yarn MRAppMaster for the job is getting killed the Yarn nodemanager&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;, (separate processes) because&lt;/li&gt;
	&lt;li&gt;virtual memory is being over provisioned in the MRAppMaster&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2013-04-04 04:46:18,895 WARN  [AsyncDispatcher event handler] resourcemanager.RMAuditLogger(255): USER=jenkins	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1365075961471_0001 failed 1 times due to AM Container &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; appattempt_1365075961471_0001_000001 exited with  exitCode: 143 due to: Container [pid=31600,containerID=container_1365075961471_0001_01_000001] is running beyond virtual memory limits. Current usage: 259.7mb of 2.0gb physical memory used; 5.6gb of 4.2gb virtual memory used. Killing container.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13622388" author="jmhsieh" created="Thu, 4 Apr 2013 14:52:52 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=devaraj&quot; class=&quot;user-hover&quot; rel=&quot;devaraj&quot;&gt;Devaraj Das&lt;/a&gt; I&apos;m not getting the same error you are getting.  Are you working ontop of the current hadoop2 in the pom 2.0.2-alpha or a different version? (I have build problems with ted&apos;s 8258-plain.txt patch applied).&lt;/p&gt;</comment>
                            <comment id="13622406" author="stack" created="Thu, 4 Apr 2013 15:18:43 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jmhsieh&quot; class=&quot;user-hover&quot; rel=&quot;jmhsieh&quot;&gt;Jonathan Hsieh&lt;/a&gt; You saw the discussion over in hbase-7904 about YARN doing process kill because of vmem excess?  Ted added this addendum over in hbase-7904: &lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12576220/7904-addendum.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12576220/7904-addendum.txt&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13622415" author="jmhsieh" created="Thu, 4 Apr 2013 15:28:21 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt; yeah, saw that &amp;#8211; I think instead of depending on the new flag in 2.0.4, we should be able to just bump those numbers to bypass the failures.  Currently trying this.&lt;/p&gt;</comment>
                            <comment id="13622873" author="yuzhihong@gmail.com" created="Thu, 4 Apr 2013 22:10:56 +0000"  >&lt;p&gt;If &lt;a href=&quot;https://issues.apache.org/jira/browse/MAPREDUCE-5094&quot; title=&quot;Disable mem monitoring by default in MiniMRYarnCluster&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAPREDUCE-5094&quot;&gt;&lt;del&gt;MAPREDUCE-5094&lt;/del&gt;&lt;/a&gt; goes into 2.0.4, there should be no need to set vmem config parameter.&lt;/p&gt;</comment>
                            <comment id="13622951" author="devaraj" created="Thu, 4 Apr 2013 23:12:45 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yuzhihong%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;yuzhihong@gmail.com&quot;&gt;Ted Yu&lt;/a&gt;, since &lt;a href=&quot;https://issues.apache.org/jira/browse/MAPREDUCE-5094&quot; title=&quot;Disable mem monitoring by default in MiniMRYarnCluster&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAPREDUCE-5094&quot;&gt;&lt;del&gt;MAPREDUCE-5094&lt;/del&gt;&lt;/a&gt; is not checked in yet, do you want to put the configs for bumping up the vmem (&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12576220/7904-addendum.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12576220/7904-addendum.txt&lt;/a&gt;) so that we get a more realistic hadoopqa run.&lt;/p&gt;</comment>
                            <comment id="13622954" author="jmhsieh" created="Thu, 4 Apr 2013 23:14:13 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tedyu%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;tedyu@apache.org&quot;&gt;Ted Yu&lt;/a&gt; I&apos;d like to get this fixed without having to upgrade hadoop versions to a snapshot version.  I&apos;d also like an explanation of &lt;b&gt;why&lt;/b&gt; the changes fix problems &amp;#8211; vague statements &quot;necessary configuration values&quot; without explanation does not help.  Ideally this is in the code as comments or at the least in the jira.&lt;/p&gt;
</comment>
                            <comment id="13623091" author="yuzhihong@gmail.com" created="Thu, 4 Apr 2013 23:58:45 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jmhsieh&quot; class=&quot;user-hover&quot; rel=&quot;jmhsieh&quot;&gt;Jonathan Hsieh&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;I&apos;d like to get this fixed without having to upgrade hadoop versions to a snapshot version.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Did you mean that we should wait for 2.0.4-alpha to come out ? I think for 0.95, we should use 2.0.4-alpha which is to be released soon.&lt;/p&gt;

&lt;p&gt;If we use 2.0.3-alpha, we would get (due to capacity-scheduler.xml missing in artifact):&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7904?focusedCommentId=13584497&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13584497&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-7904?focusedCommentId=13584497&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13584497&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In case you haven&apos;t read comments from Siddharth, you can find them starting with this one :&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7904?focusedCommentId=13611080&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13611080&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-7904?focusedCommentId=13611080&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13611080&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;That was how the HBaseConfiguration.merge() call in HBaseTestingUtility.java came about.&lt;/p&gt;

&lt;p&gt;Changes in TestImportExport.java were to align with remaining tests in that file. The comment below would provide some more context:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7904?focusedCommentId=13617700&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13617700&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-7904?focusedCommentId=13617700&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13617700&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;vague statements &quot;necessary configuration values&quot; without explanation&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I think you were referring to the following:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-comment&quot;&gt;// copy or add the necessary configuration values from the map reduce config to the hbase config&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Such comments have been in TestImportExport. This command can show us the history:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
$ svn blame hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportExport.java | grep &apos;necessary configurati&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;For SecureBulkLoadEndpoint.java, here is the background:&lt;br/&gt;
Secure bulk loading needs to establish staging directory on hdfs. So it calls:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
      fs = FileSystem.get(conf);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The conf above is an instance of CompoundConfiguration. NameNodeProxies would set up RPC engine by modifying conf.&lt;br/&gt;
This results in:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2013-03-25 22:36:19,493 ERROR [IPC Server handler 2 on 40900] access.SecureBulkLoadEndpoint$1(240): Failed to complete bulk load
java.lang.UnsupportedOperationException: Immutable Configuration
  at org.apache.hadoop.hbase.CompoundConfiguration.setClass(CompoundConfiguration.java:474)
  at org.apache.hadoop.ipc.RPC.setProtocolEngine(RPC.java:193)
  at org.apache.hadoop.hdfs.NameNodeProxies.createNNProxyWithClientProtocol(NameNodeProxies.java:249)
  at org.apache.hadoop.hdfs.NameNodeProxies.createNonHAProxy(NameNodeProxies.java:168)
  at org.apache.hadoop.hdfs.NameNodeProxies.createProxy(NameNodeProxies.java:129)
  at org.apache.hadoop.hdfs.DFSClient.&amp;lt;init&amp;gt;(DFSClient.java:421)
  at org.apache.hadoop.hdfs.DFSClient.&amp;lt;init&amp;gt;(DFSClient.java:388)
  at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:125)
  at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2277)
  at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:86)
  at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2311)
  at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2293)
  at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:317)
  at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:163)
  at org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint$1.run(SecureBulkLoadEndpoint.java:224)
  at org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint$1.run(SecureBulkLoadEndpoint.java:218)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In 8258-v1-hadoop-2.0.txt, I tried to limit the scope of changes while satisfying requirement from hadoop 2.0&lt;br/&gt;
That is, clone a mutable Configuration (an HBaseConfiguration to be more exact) from the CompoundConfiguration and pass it to FileSystem.get().&lt;/p&gt;

&lt;p&gt;I am open to discussion about proposed changes. I can upload the patch onto review board so that opinion on each change can be expressed better.&lt;/p&gt;

&lt;p&gt;I am open to other proposals as well.&lt;/p&gt;</comment>
                            <comment id="13623096" author="hadoopqa" created="Fri, 5 Apr 2013 00:08:26 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12577098/8258-v1-hadoop-2.0.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12577098/8258-v1-hadoop-2.0.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 6 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 42 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javac&lt;/font&gt;.  The applied patch generated 16 javac compiler warnings (more than the trunk&apos;s current 12 warnings).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 site&lt;/font&gt;.  The patch appears to cause mvn site goal to fail.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.security.token.TestTokenAuthentication&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestTableLockManager&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are 2 zombie test(s): 	at org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFilesSplitRecovery.testSplitWhileBulkLoadPhase(TestLoadIncrementalHFilesSplitRecovery.java:298)&lt;br/&gt;
	at org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFiles.testSimpleLoad(TestLoadIncrementalHFiles.java:86)&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5144//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5144//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5144//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5144//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5144//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5144//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5144//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5144//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5144//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5144//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5144//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5144//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5144//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5144//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5144//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5144//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5144//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5144//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5144//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5144//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13623114" author="jmhsieh" created="Fri, 5 Apr 2013 00:24:06 +0000"  >&lt;blockquote&gt;&lt;p&gt;Did you mean that we should wait for 2.0.4-alpha to come out ? I think for 0.95, we should use 2.0.4-alpha which is to be released soon.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t want to build off of things that aren&apos;t released yet, especially a SNAPSHOT jar &amp;#8211; it will change underneath us and cause us pain by introducing another variable that culd introduces problems under us.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;That was how the HBaseConfiguration.merge() call in HBaseTestingUtility.java came about&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It says what we did but I&apos;m not able to get a simple explanation of why from it.  &lt;/p&gt;

&lt;p&gt;At least for the limited test cases, the copyConfigurationValues changes seem to fix the problem (without the merge call).  Extraneous calls mean we didn&apos;t understand how or why it fixed the problem.  The comment on copyConfigurationValues() is a little more helpful (it gives me a clue why, but doesn&apos;t get down to which particular variables are important.  &lt;/p&gt;

&lt;p&gt;Without understanding this we don&apos;t know if and why all the other mr tests on need these tweaks.  Should it get folded in to all them?  Why or why not?  How can we make it so that future tests don&apos;t run into these problems?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Such comments have been in TestImportExport.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It is more important to convey why things are they way they are in the comments or summarize blocks of code do a single idea that we can verify in review or in code reading.  We shouldn&apos;t propagate vague comments from the past &amp;#8211; we should make them clearer for the next person.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;For SecureBulkLoadEndpoint.java, here is the background:&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;From my testing at the moment (on hadoop 2.0.2-alpha) this is out of scope.  If and when it becomes an issue with hadoop 2.0.4-beta, we&apos;ll address it then.&lt;/p&gt;


</comment>
                            <comment id="13623357" author="yuzhihong@gmail.com" created="Fri, 5 Apr 2013 04:39:18 +0000"  >&lt;blockquote&gt;&lt;p&gt;it will change underneath us and cause us pain&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;As I said above, 0.95 needs a stable hadoop 2 release (2.0.4-alpha).&lt;br/&gt;
For trunk, building against SNAPSHOT artifacts would allow us to find the problem much sooner. If I understand Roman&apos;s point of view correctly, he wants to discover regression in upstream project in a similar way.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;but doesn&apos;t get down to which particular variables are important.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;One such config param is YarnConfiguration.IS_MINI_YARN_CLUSTER which must be set true in order for MiniMRCluster to work.&lt;br/&gt;
See &lt;a href=&quot;https://issues.apache.org/jira/browse/YARN-129&quot; title=&quot;Simplify classpath construction for mini YARN tests&quot; class=&quot;issue-link&quot; data-issue-key=&quot;YARN-129&quot;&gt;&lt;del&gt;YARN-129&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Should it get folded in to all them?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Can you explain folding a little bit ?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;we should make them clearer for the next person.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Agreed. Will add comment once solution is finalized.&lt;/p&gt;</comment>
                            <comment id="13623662" author="devaraj" created="Fri, 5 Apr 2013 14:24:17 +0000"  >&lt;p&gt;I think we have to move to the next release of hadoop (2.0.4+). That fixes some issues needed by HBase tests to work. On the usage of &lt;em&gt;merge&lt;/em&gt; versus &lt;em&gt;copyConfiguration&lt;/em&gt;, I think we should use copyConfiguration and if not at least identify what configs we really need to copy from the possibly updated configuration. If I am not mistaken, I think that is the main point of confusion in this jira. Right, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jmhsieh&quot; class=&quot;user-hover&quot; rel=&quot;jmhsieh&quot;&gt;Jonathan Hsieh&lt;/a&gt;?&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yuzhihong%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;yuzhihong@gmail.com&quot;&gt;Ted Yu&lt;/a&gt;, do you mind trying the usage of copyConfiguration instead of merge?&lt;/p&gt;</comment>
                            <comment id="13623673" author="yuzhihong@gmail.com" created="Fri, 5 Apr 2013 14:38:30 +0000"  >&lt;p&gt;Patch v2 moves copyConfigurationValues() to HBaseTestingUtility where it is called in place of the merge() call.&lt;/p&gt;</comment>
                            <comment id="13623732" author="hadoopqa" created="Fri, 5 Apr 2013 15:47:07 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12577217/8258-v2-hadoop-2.0.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12577217/8258-v2-hadoop-2.0.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 6 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 42 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javac&lt;/font&gt;.  The applied patch generated 16 javac compiler warnings (more than the trunk&apos;s current 12 warnings).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 site&lt;/font&gt;.  The patch appears to cause mvn site goal to fail.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.security.token.TestTokenAuthentication&lt;br/&gt;
                  org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are 2 zombie test(s): 	at org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFiles.testSimpleLoad(TestLoadIncrementalHFiles.java:86)&lt;br/&gt;
	at org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFilesSplitRecovery.testSplitWhileBulkLoadPhase(TestLoadIncrementalHFilesSplitRecovery.java:298)&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5152//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5152//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5152//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5152//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5152//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5152//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5152//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5152//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5152//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5152//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5152//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5152//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5152//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5152//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5152//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5152//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5152//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5152//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5152//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5152//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13623739" author="jmhsieh" created="Fri, 5 Apr 2013 15:52:38 +0000"  >&lt;blockquote&gt;&lt;p&gt;As I said above, 0.95 needs a stable hadoop 2 release (2.0.4-alpha).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;2.0.4 is not released yet &lt;a href=&quot;http://hadoop.apache.org/releases.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hadoop.apache.org/releases.html&lt;/a&gt;.  When it is, we&apos;ll deal with it.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;SNAPSHOT artifacts would allow us to find the problem much sooner. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;-1 to building hbase on SNAPSHOT default. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;One such config param is YarnConfiguration.IS_MINI_YARN_CLUSTER which must be set true in order for MiniMRCluster to work.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;From my experiments I&apos;m not sure if that is relevant to the current problems.&lt;/p&gt;

&lt;p&gt;I&apos;ve narrowed it down to only needing to set these two yarn configs (because something overrides their defaults).  All the rest of the yarn config values are not needed.  &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
yarn.resourcemanager.scheduler.address : localhost:49649
yarn.resourcemanager.address : localhost:48993
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;yarn.rm.schedule.addrss is default port 8030 and yarn.resourcemanager.address is default port 8032.  The need for the different value here explains why we get the ConnectException from the mr client trying to talk to 0.0.0.0:8032.&lt;/p&gt;

&lt;p&gt;The follow-on questions this leads me to are:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Why is do we need to override these in our minimrcluster tests?&lt;/li&gt;
	&lt;li&gt;Why isn&apos;t this need documented and where should it be?&lt;/li&gt;
	&lt;li&gt;Why isn&apos;t this a problem on other HBase-MR jobs?&lt;/li&gt;
	&lt;li&gt;What can we do to properly propagate this so that future MR tests won&apos;t have this problem?&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I feel that these need to be answered and hopefully addressed before we commit a fix.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Can you explain folding a little bit ?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m using folding and merging as synonyms &amp;#8211; what the copyConfigurationValues does.&lt;/p&gt;
</comment>
                            <comment id="13623826" author="devaraj" created="Fri, 5 Apr 2013 17:37:02 +0000"  >&lt;blockquote&gt;&lt;p&gt;2.0.4 is not released yet &lt;a href=&quot;http://hadoop.apache.org/releases.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hadoop.apache.org/releases.html&lt;/a&gt;. When it is, we&apos;ll deal with it.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;2.0.4 has some fixes that impact HBase tests (&lt;a href=&quot;https://issues.apache.org/jira/browse/MAPREDUCE-5083&quot; title=&quot;MiniMRCluster should use a random component when creating an actual cluster&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAPREDUCE-5083&quot;&gt;&lt;del&gt;MAPREDUCE-5083&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/YARN-470&quot; title=&quot;Support a way to disable resource monitoring on the NodeManager&quot; class=&quot;issue-link&quot; data-issue-key=&quot;YARN-470&quot;&gt;&lt;del&gt;YARN-470&lt;/del&gt;&lt;/a&gt; at the least). I think we should wait for the release to happen before we do anything more on this issue. The release is slated to go out soon (a few days as per &lt;a href=&quot;http://bit.ly/10A7gCc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bit.ly/10A7gCc&lt;/a&gt;), and I agree that we shouldn&apos;t have HBase depend on a SNAPSHOT version of Hadoop.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Why is do we need to override these in our minimrcluster tests?&lt;br/&gt;
Why isn&apos;t this need documented and where should it be?&lt;br/&gt;
Why isn&apos;t this a problem on other HBase-MR jobs?&lt;br/&gt;
What can we do to properly propagate this so that future MR tests won&apos;t have this problem?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This (the need to copy configuration values) was discovered and introduced way back in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6601&quot; title=&quot;TestImportExport on Hadoop 2 must copy YARN configuration vars&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6601&quot;&gt;&lt;del&gt;HBASE-6601&lt;/del&gt;&lt;/a&gt;. Ted&apos;s patch that had the reference to &quot;merge&quot; made it so that all MR tests could get all the (updated) configuration key/vals. In reality, copyConfigurationValues alone is sufficient. Ted&apos;s current patch has it that way (all MR tests get the updated configs via copyConfigurationValues). I think the javadoc comment on copyConfigurationValues is already a nice document. Maybe, we could enhance that a bit..&lt;/p&gt;
</comment>
                            <comment id="13623845" author="ndimiduk" created="Fri, 5 Apr 2013 17:47:46 +0000"  >&lt;p&gt;bq 2.0.4 has some fixes that impact HBase tests (&lt;a href=&quot;https://issues.apache.org/jira/browse/MAPREDUCE-5083&quot; title=&quot;MiniMRCluster should use a random component when creating an actual cluster&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAPREDUCE-5083&quot;&gt;&lt;del&gt;MAPREDUCE-5083&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/YARN-470&quot; title=&quot;Support a way to disable resource monitoring on the NodeManager&quot; class=&quot;issue-link&quot; data-issue-key=&quot;YARN-470&quot;&gt;&lt;del&gt;YARN-470&lt;/del&gt;&lt;/a&gt; at the least). I think we should wait for the release to happen before we do anything more on this issue.&lt;/p&gt;

&lt;p&gt;+1&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The release is slated to go out soon (a few days as per &lt;a href=&quot;http://bit.ly/10A7gCc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bit.ly/10A7gCc&lt;/a&gt;), and I agree that we shouldn&apos;t have HBase depend on a SNAPSHOT version of Hadoop.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;and +1&lt;/p&gt;</comment>
                            <comment id="13623907" author="jmhsieh" created="Fri, 5 Apr 2013 18:29:51 +0000"  >&lt;blockquote&gt;&lt;p&gt;2.0.4 has some fixes that impact HBase tests (&lt;a href=&quot;https://issues.apache.org/jira/browse/MAPREDUCE-5083&quot; title=&quot;MiniMRCluster should use a random component when creating an actual cluster&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAPREDUCE-5083&quot;&gt;&lt;del&gt;MAPREDUCE-5083&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/YARN-470&quot; title=&quot;Support a way to disable resource monitoring on the NodeManager&quot; class=&quot;issue-link&quot; data-issue-key=&quot;YARN-470&quot;&gt;&lt;del&gt;YARN-470&lt;/del&gt;&lt;/a&gt; at the least). I think we should wait for the release to happen before we do anything more on this issue.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;When it comes out we deal with it.  &lt;/p&gt;

&lt;p&gt;The isolation of the particular relevant yarn configs demonstrate that the vmem stuff is red herring and unrelated as of hadoop 2.0.2.  &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;This (the need to copy configuration values) was discovered and introduced way back in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6601&quot; title=&quot;TestImportExport on Hadoop 2 must copy YARN configuration vars&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6601&quot;&gt;&lt;del&gt;HBASE-6601&lt;/del&gt;&lt;/a&gt;. Ted&apos;s patch that had the reference to &quot;merge&quot; made it so that all MR tests could get all the (updated) configuration key/vals. In reality, copyConfigurationValues alone is sufficient. Ted&apos;s current patch has it that way (all MR tests get the updated configs via copyConfigurationValues). I think the javadoc comment on copyConfigurationValues is already a nice document. Maybe, we could enhance that a bit..&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;copyConfigurationValues seems overly broad and doesn&apos;t expose the root cause.  &lt;/p&gt;

&lt;p&gt;You also skipped the last two questions &amp;#8211; without getting to the root, this still doesn&apos;t explain why it works for other hbase-mr tests and not here, and how to make it so that any other mr tests doesn&apos;t have to have a special copyConfiguraitonValues equivalent call.&lt;/p&gt;</comment>
                            <comment id="13623937" author="stack" created="Fri, 5 Apr 2013 18:49:17 +0000"  >&lt;blockquote&gt;&lt;p&gt;I think we should wait for the release to happen before we do anything more on this issue.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;My fear is that there are fixes we need in upstream so lets figure them out sooner rather than later (figuring them out after 2.0.4-alpha means hbase 0.96 can&apos;t release till 2.0.5-alpha/beta whenever that is).&lt;/p&gt;

&lt;p&gt;On copyConfigurationValues, we could do that but it blankets over questions Jon is asking of why the breakage and only in one of our MR tests.&lt;/p&gt;
</comment>
                            <comment id="13624073" author="jmhsieh" created="Fri, 5 Apr 2013 21:16:01 +0000"  >&lt;blockquote&gt;&lt;p&gt;Why is do we need to override these in our minimrcluster tests?&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Why isn&apos;t this a problem on other HBase-MR jobs?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The other MR tests use the HBaseTestingUtility&apos;s getConfiguration conf.  When the mini-mr cluster is started it adds values to it.  The current TestImportExport gets the values from HBaseTestingUtility.getMiniCluster.getConf which does not have yarn/mr values added.  That&apos;s why we had to the extra copy junk.&lt;/p&gt;

&lt;p&gt;If we use the pattern used in the other MR jobs, we don&apos;t have this problem.  There is one catch &amp;#8211; we need to make a &quot;copy&quot; of the conf for the job conf by using new Configuration(htu.getConfiguration).  Without that I was having data from previous exports from one test interfere with subsequent runs in suite.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Why isn&apos;t this need documented and where should it be?&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;What can we do to properly propagate this so that future MR tests won&apos;t have this problem?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I will improve javadoc in HBaseTestingUtility to explain the proper way of getting configurations for hbase unit test mr jobs.&lt;/p&gt;</comment>
                            <comment id="13624081" author="jmhsieh" created="Fri, 5 Apr 2013 21:27:49 +0000"  >&lt;p&gt;I&apos;ve attached a patch that gets rid of all the goofiness and makes the TestImportExport test consistent with the other MR tests.  It also refactors the test to make it cleaner.&lt;/p&gt;</comment>
                            <comment id="13624084" author="ndimiduk" created="Fri, 5 Apr 2013 21:29:25 +0000"  >&lt;blockquote&gt;&lt;p&gt;My fear is that there are fixes we need in upstream so lets figure them out sooner rather than later&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Good point.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;copyConfigurationValues seems overly broad and doesn&apos;t expose the root cause.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Cluster management in this test is pretty difficult to follow. I think the underlying cause is that the job configuration is built against the wrong cluster config. Let&apos;s see if I understand this correctly.&lt;/p&gt;

&lt;p&gt;Back in &lt;tt&gt;beforeClass&lt;/tt&gt; we have:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
@BeforeClass
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; void beforeClass() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; Exception {
  cluster = UTIL.startMiniCluster();
  UTIL.startMiniMapReduceCluster();
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I guess these are two different clusters, one running HBase, managed via &lt;tt&gt;cluster&lt;/tt&gt;, and the other running MR, managed by &lt;tt&gt;UTIL&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;testSimpleCase&lt;/tt&gt; starts by populating a table on &lt;tt&gt;cluster&lt;/tt&gt; (HBase cluster), it then creates the Export job using the configuration of &lt;tt&gt;cluster&lt;/tt&gt; (HBase cluster), even though that&apos;s the cluster lacking MR. Thus, it&apos;s necessary to copy the MR details from &lt;tt&gt;UTIL&lt;/tt&gt; (MR cluster) into the Export job&apos;s config.&lt;/p&gt;

&lt;p&gt;Since the test is, at it&apos;s essence, running a MR job, wouldn&apos;t the test be made more stable (and realistic to user jobs) if instead the HBase connection details were copied into a MR job config build from &lt;tt&gt;UTIL&lt;/tt&gt; (MR cluster)? Further, that copy can be done in one place, way back in &lt;tt&gt;beforeClass&lt;/tt&gt;. That way, the code repeated for each test is limited.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-comment&quot;&gt;// in beforeClass:
&lt;/span&gt;&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.baseConf = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Configuration(UTIL.getConfiguration());
... &lt;span class=&quot;code-comment&quot;&gt;// copy hbase configs into baseConf
&lt;/span&gt;
&lt;span class=&quot;code-comment&quot;&gt;// in each test
&lt;/span&gt;GenericOptionsParser opts = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; GenericOptionsParser(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Configuration(baseConf), args);
Configuration exportConf = opts.getConfiguration();
args = opts.getRemainingArgs();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This can be further simplified if the jobs under test implement the &lt;tt&gt;Tool&lt;/tt&gt; interface (like I did for ImportTsv in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8011&quot; title=&quot;Refactor ImportTsv&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8011&quot;&gt;&lt;del&gt;HBASE-8011&lt;/del&gt;&lt;/a&gt;) and deprecating the &lt;tt&gt;createSubmittableJob&lt;/tt&gt; nonsense. Then it becomes something closer to:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
ToolRunner.run(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Configuration(baseConf), &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Export(), args);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13624087" author="devaraj" created="Fri, 5 Apr 2013 21:38:57 +0000"  >&lt;blockquote&gt;
&lt;p&gt;When it comes out we deal with it.&lt;br/&gt;
The isolation of the particular relevant yarn configs demonstrate that the vmem stuff is red herring and unrelated as of hadoop 2.0.2.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Are you saying that we fix the problems in HBase assuming hadoop-2.0.2-alpha as the underlying hadoop version? So far, the assumption I have been working with is that we wanted to get HBase working with 2.0.4-alpha (and this whole thread started with trying to make HBase work with hadoo-2.0.3-alpha, ref &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7904&quot; title=&quot;Make mapreduce jobs pass based on 2.0.4-alpha&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7904&quot;&gt;&lt;del&gt;HBASE-7904&lt;/del&gt;&lt;/a&gt;).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;copyConfigurationValues seems overly broad and doesn&apos;t expose the root cause.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Hmm.. One can dump all the yarn configurations (yarn.* config keys) before and after the copyConfigurationValues call, and figure out what changed. That might be a worthwhile experiment. So let&apos;s say that we identify two or three configs. We should then change copyConfigurationValues to be more restrictive in copying?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;You also skipped the last two questions &#8211; without getting to the root, this still doesn&apos;t explain why it works for other hbase-mr tests and not here, and how to make it so that any other mr tests doesn&apos;t have to have a special copyConfiguraitonValues equivalent call&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sorry about missing these earlier...&lt;/p&gt;

&lt;p&gt;On the first one, as per the last hadoopQA run without the fixes with hadoop-2.0.4-SNAPSHOT (&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8258?focusedCommentId=13621696&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13621696&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-8258?focusedCommentId=13621696&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13621696&lt;/a&gt;), almost all of the mapreduce tests failed. I haven&apos;t looked at all the tests that passed but one quick check on one of the passing test in the mapreduce package like TestTableSplit.java doesn&apos;t submit jobs, and maybe that&apos;s why they passed.&lt;/p&gt;

&lt;p&gt;On the other question, if the approach of calling copyConfigurationValues in the common part of the test code makes the tests work (as per the last 1 or 2 hadoopqa runs), I think we should make a note of this in some doc. We can get to this detail once we all agree on the proposed patch.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;My fear is that there are fixes we need in upstream so lets figure them out sooner rather than later (figuring them out after 2.0.4-alpha means hbase 0.96 can&apos;t release till 2.0.5-alpha/beta whenever that is).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Stack, are you suggesting that we should depend on 2.0.4-alpha sooner rather than later, maybe even check with 2.0.4-SNAPSHOT on a periodic basis until 2.0.4-alpha is released?&lt;/p&gt;</comment>
                            <comment id="13624088" author="jmhsieh" created="Fri, 5 Apr 2013 21:39:09 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ndimiduk&quot; class=&quot;user-hover&quot; rel=&quot;ndimiduk&quot;&gt;Nick Dimiduk&lt;/a&gt; That is very close the explanation that I have.  The minimrcluster for yarn adds values to the configuration so if we refer to the same one and copy it later, we get the updated yarn settings.  This is what all the other MR tests do.&lt;/p&gt;

&lt;p&gt;I need to look into why we need to do the copy of the config to prevent interference (likely some if the value is set don&apos;t update it logic). &lt;/p&gt;

&lt;p&gt;I agree that using the tool interface makes sense as well &amp;#8211; feels like a nice follow up issue.  &lt;/p&gt;

&lt;p&gt;I&apos;ve been running with the version I posted on trunk against hadoop 2.0 &amp;#8211; will report on that and against hadoop 1.0 when results return.&lt;/p&gt;</comment>
                            <comment id="13624103" author="hadoopqa" created="Fri, 5 Apr 2013 21:51:40 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12577283/8258-v4-hadoop-2.0.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12577283/8258-v4-hadoop-2.0.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 9 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javadoc&lt;/font&gt;.  The javadoc tool appears to have generated 42 warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 javac&lt;/font&gt;.  The applied patch generated 16 javac compiler warnings (more than the trunk&apos;s current 12 warnings).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 lineLengths&lt;/font&gt;.  The patch does not introduce lines longer than 100&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 site&lt;/font&gt;.  The patch appears to cause mvn site goal to fail.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.TestZooKeeper&lt;br/&gt;
                  org.apache.hadoop.hbase.security.token.TestTokenAuthentication&lt;br/&gt;
                  org.apache.hadoop.hbase.security.access.TestAccessController&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core zombie tests&lt;/font&gt;.  There are 2 zombie test(s): 	at org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFiles.testSimpleLoad(TestLoadIncrementalHFiles.java:86)&lt;br/&gt;
	at org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFilesSplitRecovery.testSplitWhileBulkLoadPhase(TestLoadIncrementalHFilesSplitRecovery.java:299)&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5155//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5155//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5155//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5155//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5155//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5155//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5155//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5155//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5155//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5155//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5155//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5155//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5155//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5155//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5155//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5155//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5155//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5155//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5155//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5155//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13624104" author="stack" created="Fri, 5 Apr 2013 21:53:45 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=devaraj&quot; class=&quot;user-hover&quot; rel=&quot;devaraj&quot;&gt;Devaraj Das&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Stack, are you suggesting that we should depend on 2.0.4-alpha sooner rather than later, maybe even check with 2.0.4-SNAPSHOT on a periodic basis until 2.0.4-alpha is released?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I suggest sooner so if any issues in hdfs/mr/yarn, we can help out our parent project by surfacing them quicker (For example, I don&apos;t mind shipping a 0.95.x &quot;Development&quot; Series release against a hadoop SNAPSHOT; I don&apos;t see it as a problem given the quick decay half-life of 0.95.x release).&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="13624105" author="jmhsieh" created="Fri, 5 Apr 2013 21:53:45 +0000"  >
&lt;blockquote&gt;&lt;p&gt;Are you saying that we fix the problems in HBase assuming hadoop-2.0.2-alpha as the underlying hadoop version?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes.  Its been what this build has been broken against for a long time so let&apos;s get that fixed first. Haven&apos;t tried 2.0.3 yet, but after this gets fixed we can go there.  &lt;b&gt;One problem at a time and ideally per jira.&lt;/b&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;So let&apos;s say that we identify two or three configs. We should then change copyConfigurationValues to be more restrictive in copying?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Experiment was already done, see &lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; &amp;#8211; yarn.resourcemanager.scheduler.address,&lt;br/&gt;
yarn.resourcemanager.address were the main ones.&lt;/p&gt;

&lt;p&gt;That lead to the follow up questions, which lead me to see that the whole copying stuff is moot.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;On the first one, as per the last hadoopQA run without the fixes with hadoop-2.0.4-SNAPSHOT (&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8258?focusedCommentId=13621696&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13621696&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-8258?focusedCommentId=13621696&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13621696&lt;/a&gt;), almost all of the mapreduce tests failed.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m going to ignore tests run against a hadoop SNAPSHOT.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Stack, are you suggesting that we should depend on 2.0.4-alpha sooner rather than later, maybe even check with 2.0.4-SNAPSHOT on a periodic basis until 2.0.4-alpha is released?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think he means that not fixing this until 2.0.4 comes out is not a good idea, but I&apos;ll let him answer.&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8258?focusedCommentId=13623739&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13623739&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-8258?focusedCommentId=13623739&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13623739&lt;/a&gt;  &lt;/p&gt;
</comment>
                            <comment id="13624163" author="hadoopqa" created="Fri, 5 Apr 2013 23:08:23 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12577297/hbase-8258-simple.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12577297/hbase-8258-simple.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 6 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.mapreduce.TestImportExport&lt;br/&gt;
                  org.apache.hadoop.hbase.master.TestTableLockManager&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5157//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5157//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5157//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5157//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5157//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13624173" author="jmhsieh" created="Fri, 5 Apr 2013 23:32:19 +0000"  >&lt;p&gt;Hm.. On my second try, it looks like hadoop1 has got some failures (essentially same as hadoopqa bot), but the hadoop2 build (on an internal jenkins) is good. &lt;/p&gt;

&lt;p&gt;On my first run against hadoop2 I had problems with vmem overuse:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2013-04-05 14:57:45,983 WARN  [AsyncDispatcher event handler] resourcemanager.RMAuditLogger(255): USER=jenkins	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1365199040071_0001 failed 1 times due to AM Container &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; appattempt_1365199040071_0001_000001 exited with  exitCode: 143 due to: Container [pid=24860,containerID=container_1365199040071_0001_01_000001] is running beyond virtual memory limits. Current usage: 269.3mb of 2.0gb physical memory used; 6.3gb of 4.2gb virtual memory used. Killing container.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I&apos;ve uncommented the pmem/vmem lines in the patch to make hadoop2 happy.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-comment&quot;&gt;// Tests were failing because &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; process used 6GB of virtual memory and was getting killed.
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;// we up the VM usable so that processes don&apos;t get killed.
&lt;/span&gt;    conf.setInt(&lt;span class=&quot;code-quote&quot;&gt;&quot;yarn.nodemanager.resource.memory-mb&quot;&lt;/span&gt;, 8 * 1024);
    conf.setFloat(&lt;span class=&quot;code-quote&quot;&gt;&quot;yarn.nodemanager.vmem-pmem-ratio&quot;&lt;/span&gt;, 8.0f);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Digging into the hadoop 1 issues now.&lt;/p&gt;

</comment>
                            <comment id="13624178" author="yuzhihong@gmail.com" created="Fri, 5 Apr 2013 23:36:36 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jmhsieh&quot; class=&quot;user-hover&quot; rel=&quot;jmhsieh&quot;&gt;Jonathan Hsieh&lt;/a&gt;:&lt;br/&gt;
What do you think of Stack&apos;s comment:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;For example, I don&apos;t mind shipping a 0.95.x &quot;Development&quot; Series release against a hadoop SNAPSHOT; I don&apos;t see it as a problem given the quick decay half-life of 0.95.x release&lt;/p&gt;&lt;/blockquote&gt;</comment>
                            <comment id="13624191" author="devaraj" created="Fri, 5 Apr 2013 23:46:03 +0000"  >&lt;blockquote&gt;&lt;p&gt;I suggest sooner so if any issues in hdfs/mr/yarn, we can help out our parent project by surfacing them quicker (For example, I don&apos;t mind shipping a 0.95.x &quot;Development&quot; Series release against a hadoop SNAPSHOT; I don&apos;t see it as a problem given the quick decay half-life of 0.95.x release).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Hmm.. fair point, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stack&quot; class=&quot;user-hover&quot; rel=&quot;stack&quot;&gt;stack&lt;/a&gt;, given 0.95.x is not meant for production. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jmhsieh&quot; class=&quot;user-hover&quot; rel=&quot;jmhsieh&quot;&gt;Jonathan Hsieh&lt;/a&gt;, what do you think about this suggestion. The vmem issues you encountered won&apos;t happen with hadoop-2.0.4 since the YARN fixes are committed to not do vmem checks by default.&lt;br/&gt;
Your patch AFAICT is not sufficient to ride HBase over the hadoop-2.0.3 / 2.0.4 releases. We need some variant of Ted&apos;s patch for having HBase pass the unit tests successfully over the 2.0.4 release.. (otherwise we will have this saga all over again in a few weeks).&lt;/p&gt;</comment>
                            <comment id="13624205" author="jmhsieh" created="Fri, 5 Apr 2013 23:56:53 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tedyu%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;tedyu@apache.org&quot;&gt;Ted Yu&lt;/a&gt; I disagree with stack&apos;s comment.  I think moving 2.0.3 (a released version) would be reasonable, but would prefer handling that after we get this tackled.  I&apos;m against 2.0.4-SNAPSHOT (or any *-SNAPSHOT hadoop).  &lt;/p&gt;

&lt;p&gt;We need be on known good points and ideally move to other known good points.  If it ends up that 2.0.3 breaks us somewhere, I feel that we should stand pat where we are &quot;stable&quot; until there is a version that works for us or if we are forced to upgrade.  If 2.0.4 (released) is the safe point and it is released, I&apos;m all for moving to it.  &lt;/p&gt;

&lt;p&gt;We have enough problems with flaky tests, and I&apos;d rather not have to consider hadoop code changes shifting under us as another source of bugs.  I&apos;m concerned if upgrading breaks us &amp;#8211; this means hadoop broke compatibility.&lt;/p&gt;</comment>
                            <comment id="13624209" author="apurtell" created="Fri, 5 Apr 2013 23:59:15 +0000"  >&lt;blockquote&gt;&lt;p&gt;We have enough problems with flaky tests, and I&apos;d rather not have to consider hadoop code changes shifting under us as another source of bugs.  I&apos;m concerned if upgrading breaks us &amp;#8211; this means hadoop broke compatibility.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;On the other hand, I see no problem setting up builds on Apache Jenkins or the EC2 Jenkins which redefines hadoop.version for the build. THen you can specify 2.0.4-SNAPSHOT or whatever you like. Call the builds &quot;HBase-2.x-SNAPSHOT&quot; or similar. &lt;/p&gt;</comment>
                            <comment id="13625519" author="jmhsieh" created="Mon, 8 Apr 2013 16:38:05 +0000"  >&lt;p&gt;As a follow on to &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt;, you can always pick the profile and then add a -Dhadoop-two.version=&amp;lt;version&amp;gt; with your favorite hadoop2 version &amp;#8211; e.g.:&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;mvn dependency:list -Dhadoop.profile=2.0 -Dhadoop-two.version=2.0.3-alpha&lt;/tt&gt;&lt;/p&gt;
</comment>
                            <comment id="13625521" author="jmhsieh" created="Mon, 8 Apr 2013 16:41:43 +0000"  >&lt;p&gt;Looks like the failures in the hadoop1 verson is the theory from a previous part of the conversation &amp;#8211; writing to different hdfs&apos;s from &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6330&quot; title=&quot;TestImportExport has been failing against hadoop 0.23/2.0 profile&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6330&quot;&gt;&lt;del&gt;HBASE-6330&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;.&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6330?focusedCommentId=13420691&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13420691&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-6330?focusedCommentId=13420691&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13420691&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13625660" author="jmhsieh" created="Mon, 8 Apr 2013 18:51:28 +0000"  >&lt;p&gt;Fully qualifying the export path to hdfs makes the job work in hadoop1. &lt;/p&gt;

&lt;p&gt;In hadoop 1: &lt;br/&gt;
export was exporting to a &quot;random&quot; dir in hdfs, while import was expecting data from the hadoop file system.  &lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;export to: hdfs://localhost:46368/user/jon/test-data/72b45ff2-9203-4791-aa28-2b95e44f5d95/hadoop/mapred-working-dir/outputdir/part-m-00000&lt;br/&gt;
h&lt;/li&gt;
	&lt;li&gt;import from: hdfs://localhost:46368/user/jon/outputdir/&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;In hadoop 2: &lt;br/&gt;
export was exporting to the hdfs while import was expecting data form hdfs.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;export to: hdfs://localhost:60549/user/jon/outputdir/part-m-00000&lt;/li&gt;
	&lt;li&gt;import from: hdfs://localhost:60549/user/jon/outputdir/&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;So at least for the export tests, I&apos;m going to use fully qualified hdfs paths for the export output &lt;/p&gt;</comment>
                            <comment id="13625787" author="jmhsieh" created="Mon, 8 Apr 2013 20:44:26 +0000"  >&lt;p&gt;simple.v2 expands fully qualified pathnames for export and import args.&lt;/p&gt;</comment>
                            <comment id="13626096" author="jmhsieh" created="Tue, 9 Apr 2013 01:45:13 +0000"  >&lt;p&gt;Full suite passes for me with patch applied against hadoop2 and hadoop1.  Will commit tomorrow afternoon unless I hear otherwise.&lt;/p&gt;</comment>
                            <comment id="13626111" author="yuzhihong@gmail.com" created="Tue, 9 Apr 2013 02:02:06 +0000"  >&lt;p&gt;From &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5193/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5193/console&lt;/a&gt; :&lt;/p&gt;

&lt;p&gt;/home/jenkins/tools/maven/latest/bin/mvn clean test -DskipTests -DHBasePatchProcess &amp;gt; /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/patchprocess/trunkJavacWarnings.txt 2&amp;gt;&amp;amp;1&lt;br/&gt;
Trunk compilation is broken?&lt;/p&gt;

&lt;p&gt;Once the patch is checked in, do we keep this JIRA open for the upcoming 2.0.4-alpha or open new JIRA ?&lt;/p&gt;</comment>
                            <comment id="13626119" author="jmhsieh" created="Tue, 9 Apr 2013 02:13:44 +0000"  >&lt;p&gt;simple.v3 uses git --no-prefix when generating patch.&lt;/p&gt;</comment>
                            <comment id="13626120" author="jmhsieh" created="Tue, 9 Apr 2013 02:14:56 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tedyu%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;tedyu@apache.org&quot;&gt;Ted Yu&lt;/a&gt; we close this and then when 2.0.4 comes out we file a new jira to deal with the problems it introduces there.&lt;/p&gt;
</comment>
                            <comment id="13626122" author="jmhsieh" created="Tue, 9 Apr 2013 02:16:32 +0000"  >&lt;p&gt;I&apos;m suprised that our script doesn&apos;t report if a patch files to apply.  &lt;/p&gt;</comment>
                            <comment id="13626211" author="yuzhihong@gmail.com" created="Tue, 9 Apr 2013 04:33:49 +0000"  >&lt;p&gt;I got the following test failures running on top of 2.0.2-alpha:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Running org.apache.hadoop.hbase.regionserver.TestRSKilledWhenMasterInitializing
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 128.739 sec &amp;lt;&amp;lt;&amp;lt; FAILURE!
--
Running org.apache.hadoop.hbase.regionserver.TestJoinedScanners
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 238.319 sec &amp;lt;&amp;lt;&amp;lt; FAILURE!
--
Running org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat
Tests run: 10, Failures: 2, Errors: 0, Skipped: 0, Time elapsed: 273.141 sec &amp;lt;&amp;lt;&amp;lt; FAILURE!
--
Running org.apache.hadoop.hbase.util.TestMiniClusterLoadParallel
Tests run: 4, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 526.378 sec &amp;lt;&amp;lt;&amp;lt; FAILURE!
Running org.apache.hadoop.hbase.util.TestMiniClusterLoadSequential
Tests run: 4, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 534.981 sec &amp;lt;&amp;lt;&amp;lt; FAILURE!
--
Running org.apache.hadoop.hbase.TestDrainingServer
Tests run: 2, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 72.381 sec &amp;lt;&amp;lt;&amp;lt; FAILURE!
--
Running org.apache.hadoop.hbase.master.TestDistributedLogSplitting
Tests run: 4, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 345.015 sec &amp;lt;&amp;lt;&amp;lt; FAILURE!
Running org.apache.hadoop.hbase.master.TestTableLockManager
Tests run: 5, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 655.895 sec &amp;lt;&amp;lt;&amp;lt; FAILURE!
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;TestHFileOutputFormat is in the scope of this JIRA.&lt;/p&gt;</comment>
                            <comment id="13626214" author="yuzhihong@gmail.com" created="Tue, 9 Apr 2013 04:36:32 +0000"  >&lt;p&gt;After test suite completed, I saw two hanging JVMs:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-quote&quot;&gt;&quot;pool-1-thread-1&quot;&lt;/span&gt; prio=10 tid=0x00007f2d006b2000 nid=0x3a2c waiting on condition [0x00007f2cb1c92000]
   java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt;  &amp;lt;0x00000000edb7c3d8&amp;gt; (a java.util.concurrent.FutureTask$Sync)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:156)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:811)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:969)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1281)
	at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:218)
	at java.util.concurrent.FutureTask.get(FutureTask.java:83)
	at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.bulkLoadPhase(LoadIncrementalHFiles.java:324)
	at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.doBulkLoad(LoadIncrementalHFiles.java:264)
	at org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFiles.runTest(TestLoadIncrementalHFiles.java:158)
	at org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFiles.testSimpleLoad(TestLoadIncrementalHFiles.java:86)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-quote&quot;&gt;&quot;pool-1-thread-1&quot;&lt;/span&gt; prio=10 tid=0x00007f15a069c000 nid=0x5584 waiting on condition [0x00007f15662e6000]
   java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt;  &amp;lt;0x00000000daf6f150&amp;gt; (a java.util.concurrent.FutureTask$Sync)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:156)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:811)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:969)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1281)
	at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:218)
	at java.util.concurrent.FutureTask.get(FutureTask.java:83)
	at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.groupOrSplitPhase(LoadIncrementalHFiles.java:374)
	at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.doBulkLoad(LoadIncrementalHFiles.java:261)
	at org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFilesSplitRecovery.populateTable(TestLoadIncrementalHFilesSplitRecovery.java:148)
	at org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFilesSplitRecovery.testSplitWhileBulkLoadPhase(TestLoadIncrementalHFilesSplitRecovery.java:298)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13626290" author="stack" created="Tue, 9 Apr 2013 06:25:47 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ted_yu&quot; class=&quot;user-hover&quot; rel=&quot;ted_yu&quot;&gt;Ted Yu&lt;/a&gt; Did you even look to see why the tests fail?  What you have pasted, a list of test failures that seem unrelated, is close to zero help.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jmhsieh&quot; class=&quot;user-hover&quot; rel=&quot;jmhsieh&quot;&gt;Jonathan Hsieh&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;I disagree with stack&apos;s comment...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Fair enough.  If can get this to work w/ current hadoop2, good.  If fails against 2.0.4-SNAPSHOT, we should figure why but we would be in a better position if it first was working (and we knew why it had not been working previously).&lt;/p&gt;</comment>
                            <comment id="13626610" author="jmhsieh" created="Tue, 9 Apr 2013 13:40:14 +0000"  >&lt;p&gt;simple.v4 reduces the memory allowed to a smaller value.&lt;/p&gt;</comment>
                            <comment id="13626635" author="jmhsieh" created="Tue, 9 Apr 2013 14:13:18 +0000"  >&lt;p&gt;I only changed two lines that could modify all other tests &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    &lt;span class=&quot;code-comment&quot;&gt;// Tests were failing because &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; process used 6GB of virtual memory and was getting killed.
&lt;/span&gt;+    &lt;span class=&quot;code-comment&quot;&gt;// we up the VM usable so that processes don&apos;t get killed.
&lt;/span&gt;+    conf.setInt(&lt;span class=&quot;code-quote&quot;&gt;&quot;yarn.nodemanager.resource.memory-mb&quot;&lt;/span&gt;, 8 * 1024);
+    conf.setFloat(&lt;span class=&quot;code-quote&quot;&gt;&quot;yarn.nodemanager.vmem-pmem-ratio&quot;&lt;/span&gt;, 8.0f);
+
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;doing the math this could mean allocating 64gb of vmem which may be excessive.  I removed the *.memory-mb line (I believe the default is 1.5gb &amp;#8211; maxing out vmem at 12gb).&lt;/p&gt;</comment>
                            <comment id="13626648" author="jmhsieh" created="Tue, 9 Apr 2013 14:24:41 +0000"  >&lt;p&gt;precommit breakage not due to this code. N fixed (and initially broke) the precommit builds last night with these commits: &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://svn.apache.org/viewvc?view=revision&amp;amp;revision=1465726&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewvc?view=revision&amp;amp;revision=1465726&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;http://svn.apache.org/viewvc?view=revision&amp;amp;revision=1465934&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewvc?view=revision&amp;amp;revision=1465934&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;http://svn.apache.org/viewvc?view=revision&amp;amp;revision=1465964&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://svn.apache.org/viewvc?view=revision&amp;amp;revision=1465964&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13626672" author="hadoopqa" created="Tue, 9 Apr 2013 14:46:56 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12577796/hbase-8258.simple.v4.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12577796/hbase-8258.simple.v4.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 6 new or modified tests.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 hadoop2.0&lt;/font&gt;.  The patch compiles against the hadoop 2.0 profile.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 lineLengths&lt;/font&gt;.  The patch introduces lines longer than 100&lt;/p&gt;

&lt;p&gt;  &lt;font color=&quot;green&quot;&gt;+1 site&lt;/font&gt;.  The mvn site goal succeeds with this patch.&lt;/p&gt;

&lt;p&gt;     &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests:&lt;br/&gt;
                       org.apache.hadoop.hbase.security.access.TestAccessController&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5220//testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5220//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5220//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5220//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5220//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5220//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5220//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5220//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5220//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5220//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5220//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5220//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5220//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5220//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5220//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5220//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5220//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5220//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HBASE-Build/5220//console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/PreCommit-HBASE-Build/5220//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13626770" author="apurtell" created="Tue, 9 Apr 2013 16:21:38 +0000"  >&lt;blockquote&gt;&lt;p&gt;doing the math this could mean allocating 64gb of vmem which may be excessive&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It is. This wouldn&apos;t work on EC2 jenkins as each instance has 15 GB total RAM and 0 GB swap. A max of 12 GB is still excessive IMHO.&lt;/p&gt;</comment>
                            <comment id="13626800" author="jmhsieh" created="Tue, 9 Apr 2013 16:45:41 +0000"  >&lt;p&gt;Without the memory-mb and vmem-pmem lines, yarn jobs were failing out with ~250 mb physical memory and 6.2gb vmem.  I haven&apos;t been using the same memory constraints on my test runs, but since these are the only lines that could affect those tests.  &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;Andrew Purtell&lt;/a&gt; do you have an alternate suggestion? (2x vmem seems reasonable)&lt;/p&gt;

&lt;p&gt;That amount of vmem implies that either our client uses way too many threads (allocating vmem for each threads&apos; stack) or there is something funny in yarn.&lt;/p&gt;

</comment>
                            <comment id="13626823" author="apurtell" created="Tue, 9 Apr 2013 17:04:42 +0000"  >&lt;blockquote&gt;&lt;p&gt;do you have an alternate suggestion? (2x vmem seems reasonable)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Not here, let&apos;s get the mr tests passing.&lt;/p&gt;</comment>
                            <comment id="13626840" author="stack" created="Tue, 9 Apr 2013 17:22:32 +0000"  >&lt;p&gt;Would it be of help breaking up some of the big MR unit tests?  Or just  moving them over to hbase-it (I don&apos;t want to paper-over a possible incompatibility or some mess in minimrcluster... )&lt;/p&gt;</comment>
                            <comment id="13626849" author="jmhsieh" created="Tue, 9 Apr 2013 17:28:09 +0000"  >&lt;blockquote&gt;&lt;p&gt;Would it be of help breaking up some of the big MR unit tests? &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t think that will really matter.  My builds are coming up clean or with failures on unrelated unit tests.  &lt;/p&gt;

&lt;p&gt;I plan on committing this afternoon and will monitor the trunk on hadoop2 build.  If the TestImportExports come back clean, I&apos;ll port to 0.95 and possibly 0.94.&lt;/p&gt;</comment>
                            <comment id="13626852" author="yuzhihong@gmail.com" created="Tue, 9 Apr 2013 17:30:39 +0000"  >&lt;p&gt;Did TestHFileOutputFormat pass based on your patch, Jon ?&lt;/p&gt;</comment>
                            <comment id="13626896" author="jmhsieh" created="Tue, 9 Apr 2013 18:08:48 +0000"  >&lt;p&gt;Looks like my internal runs haven&apos;t been running the large tests, so the specific test and several of the others you pointed out were not run.  I&apos;m running them now.  Note that from recent trunk-on-hadoop2 &lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; runs, it looks like that the TestHFileOutputFormat test has been broken for a while, and the others are at the least flakey.&lt;/p&gt;

&lt;p&gt;I&apos;ll move the &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6330&quot; title=&quot;TestImportExport has been failing against hadoop 0.23/2.0 profile&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6330&quot;&gt;&lt;del&gt;HBASE-6330&lt;/del&gt;&lt;/a&gt; in here as a sub-issue and commit the path to deal with TestImportExport this afternoon.  I&apos;ll also follow up on the other broken tests.&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/488/testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/488/testReport/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13626904" author="devaraj" created="Tue, 9 Apr 2013 18:13:01 +0000"  >&lt;p&gt;Good to know your progress, Jon on hadoop-2.0.2. &lt;br/&gt;
On the vmem stuff, can&apos;t you disable the checks via some yarn configuration? (I know that these checks have been disabled by default in the newer not-yet-released hadoop versions but I am not sure whether such config semantics already exist) &lt;/p&gt;</comment>
                            <comment id="13626908" author="jmhsieh" created="Tue, 9 Apr 2013 18:15:58 +0000"  >&lt;p&gt;Deveraj, the addition of the disable checks is new hadoop-2.0.4 (&lt;a href=&quot;https://issues.apache.org/jira/browse/YARN-470&quot; title=&quot;Support a way to disable resource monitoring on the NodeManager&quot; class=&quot;issue-link&quot; data-issue-key=&quot;YARN-470&quot;&gt;&lt;del&gt;YARN-470&lt;/del&gt;&lt;/a&gt;) i believe.  Bumping the vmem number higher is a workaround that attempts to achieve the same result (avoiding the vmem checker from killing the job).&lt;/p&gt;</comment>
                            <comment id="13626910" author="jmhsieh" created="Tue, 9 Apr 2013 18:20:30 +0000"  >&lt;p&gt;Seeing &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6330&quot; title=&quot;TestImportExport has been failing against hadoop 0.23/2.0 profile&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6330&quot;&gt;&lt;del&gt;HBASE-6330&lt;/del&gt;&lt;/a&gt; and its parent, &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6891&quot; title=&quot;Hadoop 2 unit test failures&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6891&quot;&gt;&lt;del&gt;HBASE-6891&lt;/del&gt;&lt;/a&gt;, I&apos;m more inclined to close this as a dupe, commit he simple.v4 patch as &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6330&quot; title=&quot;TestImportExport has been failing against hadoop 0.23/2.0 profile&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6330&quot;&gt;&lt;del&gt;HBASE-6330&lt;/del&gt;&lt;/a&gt;, and then use &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6891&quot; title=&quot;Hadoop 2 unit test failures&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6891&quot;&gt;&lt;del&gt;HBASE-6891&lt;/del&gt;&lt;/a&gt; as the parent issue.   Some of the issues over there are resolved as &quot;later&quot; and we can reopen those issues with proper details as they get worked.&lt;/p&gt;</comment>
                            <comment id="13626917" author="yuzhihong@gmail.com" created="Tue, 9 Apr 2013 18:27:31 +0000"  >&lt;p&gt;I think we should keep this JIRA open - it was opened for making mapreduce jobs pass based on 2.0.4-alpha.&lt;br/&gt;
If we resolve this one, another (the 3rd) would be opened when 2.0.4-alpha comes out.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;commit he simple.v4 patch as &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6330&quot; title=&quot;TestImportExport has been failing against hadoop 0.23/2.0 profile&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6330&quot;&gt;&lt;del&gt;HBASE-6330&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13626945" author="jmhsieh" created="Tue, 9 Apr 2013 18:48:13 +0000"  >&lt;p&gt;This issue&apos;s current title is &apos;Make mapreduce tests pass on hadoop2&apos;.  The overall effort should first go into properly fixing the unit tests against hadoop2 in our current build.  From my runs I thought it was just one test but it looks like I missed a bunch.  So this should be treated as an umbrella issue which makes it a dupe of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6891&quot; title=&quot;Hadoop 2 unit test failures&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6891&quot;&gt;&lt;del&gt;HBASE-6891&lt;/del&gt;&lt;/a&gt; (where efforts had started a while back). &lt;/p&gt;

&lt;p&gt;It doesn&apos;t make sense to have an issue open for something that cannot be worked on.  Since 2.0.4 isn&apos;t released whatever fixes we&apos;d commit along this line would have the same problem as building on SNAPSHOTs &amp;#8211; it may break because of changes between the hbase commit and when 2.0.4 is released.  Once hadoop 2.0.4 is released, we can test against it then and if there are new issues with it, open jiras and fix it then.&lt;/p&gt;</comment>
                            <comment id="13627168" author="jmhsieh" created="Tue, 9 Apr 2013 21:56:42 +0000"  >&lt;p&gt;The &quot;simple&quot; versions were committed as &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6330&quot; title=&quot;TestImportExport has been failing against hadoop 0.23/2.0 profile&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6330&quot;&gt;&lt;del&gt;HBASE-6330&lt;/del&gt;&lt;/a&gt;, hadoop2 issues now umbrella&apos;ed by &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6891&quot; title=&quot;Hadoop 2 unit test failures&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6891&quot;&gt;&lt;del&gt;HBASE-6891&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13627220" author="yuzhihong@gmail.com" created="Tue, 9 Apr 2013 22:49:40 +0000"  >&lt;p&gt;Your action is quick, Jon &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Secure bulk load would not work, based on current hdfs branch 2.0&lt;br/&gt;
When 2.0.4-alpha gets released, I plan to log a JIRA to fix that.&lt;/p&gt;</comment>
                            <comment id="13627250" author="jmhsieh" created="Tue, 9 Apr 2013 23:24:40 +0000"  >&lt;blockquote&gt;&lt;p&gt;Secure bulk load would not work, based on current hdfs branch 2.0&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;When 2.0.4-alpha gets released, I plan to log a JIRA to fix that.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think you mean that the current trunk on the hdfs&apos;s repo&apos;s branch-2 will fail and that after 2.0.4 comes out you&apos;ll file a jira to fix it.  Sounds good to me!&lt;/p&gt;</comment>
                            <comment id="13627253" author="yuzhihong@gmail.com" created="Tue, 9 Apr 2013 23:27:26 +0000"  >&lt;p&gt;That was what I meant.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12609485">HBASE-6891</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12597528">HBASE-6330</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12633550">HBASE-7904</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12576907" name="8258-plain.txt" size="4813" author="yuzhihong@gmail.com" created="Thu, 4 Apr 2013 02:06:28 +0000"/>
                            <attachment id="12577098" name="8258-v1-hadoop-2.0.txt" size="11722" author="yuzhihong@gmail.com" created="Thu, 4 Apr 2013 22:59:24 +0000"/>
                            <attachment id="12577217" name="8258-v2-hadoop-2.0.txt" size="16157" author="yuzhihong@gmail.com" created="Fri, 5 Apr 2013 14:38:30 +0000"/>
                            <attachment id="12577283" name="8258-v4-hadoop-2.0.txt" size="18123" author="yuzhihong@gmail.com" created="Fri, 5 Apr 2013 20:33:21 +0000"/>
                            <attachment id="12577297" name="hbase-8258-simple.patch" size="14239" author="jmhsieh" created="Fri, 5 Apr 2013 21:27:49 +0000"/>
                            <attachment id="12577614" name="hbase-8258.simple.v2.patch" size="16705" author="jmhsieh" created="Mon, 8 Apr 2013 20:44:26 +0000"/>
                            <attachment id="12577676" name="hbase-8258.simple.v3.patch" size="16705" author="jmhsieh" created="Tue, 9 Apr 2013 02:13:44 +0000"/>
                            <attachment id="12577796" name="hbase-8258.simple.v4.patch" size="16638" author="jmhsieh" created="Tue, 9 Apr 2013 13:40:14 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>8.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 3 Apr 2013 23:43:23 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>321023</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 34 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1je0n:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>321364</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>