<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sat Dec 03 15:55:03 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-6798/HBASE-6798.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-6798] HDFS always read checksum form meta file</title>
                <link>https://issues.apache.org/jira/browse/HBASE-6798</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;I use hbase0.941 and hadoop-0.20.2-cdh3u5 version.&lt;/p&gt;

&lt;p&gt;The HBase support checksums in HBase block cache in &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; jira.&lt;br/&gt;
The  HBase  support checksums for decrease the iops of  HDFS, so that HDFS&lt;br/&gt;
dont&apos;t need to read the checksum from meta file of block file.&lt;br/&gt;
But in hadoop-0.20.2-cdh3u5 version, BlockSender still read the metadata file even if the&lt;br/&gt;
 hbase.regionserver.checksum.verify property is ture.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12607846">HBASE-6798</key>
            <summary>HDFS always read checksum form meta file</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="liulei.cn">LiuLei</reporter>
                        <labels>
                    </labels>
                <created>Mon, 17 Sep 2012 02:40:19 +0000</created>
                <updated>Sat, 22 Sep 2012 03:21:57 +0000</updated>
                            <resolved>Wed, 19 Sep 2012 20:17:10 +0000</resolved>
                                    <version>0.94.0</version>
                    <version>0.94.1</version>
                                                    <component>Performance</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>10</watches>
                                                                <comments>
                            <comment id="13456748" author="lhofhansl" created="Mon, 17 Sep 2012 04:08:18 +0000"  >&lt;p&gt;If this is a cloudera specific problem you file this through the cloudera channels.&lt;br/&gt;
Unless this occurs with HBase and an &quot;official&quot; version of Hadoop (such as 1.0.3) we cannot do much about this.&lt;/p&gt;</comment>
                            <comment id="13456786" author="liulei.cn" created="Mon, 17 Sep 2012 06:15:35 +0000"  >&lt;p&gt;yes, Hadoop1.0.3 also has the problem.&lt;/p&gt;</comment>
                            <comment id="13456790" author="lhofhansl" created="Mon, 17 Sep 2012 06:27:41 +0000"  >&lt;p&gt;Thanks LiuLei.&lt;/p&gt;</comment>
                            <comment id="13457292" author="stack" created="Mon, 17 Sep 2012 20:35:24 +0000"  >&lt;p&gt;Marking a blocker on 0.96 (Can backport if find what issues is to 0.94)&lt;/p&gt;</comment>
                            <comment id="13457327" author="tlipcon" created="Mon, 17 Sep 2012 21:07:53 +0000"  >&lt;p&gt;Fixing this for remote reads (ie not short circuit ones) is going to be somewhat tricky for Hadoop 1.0, because we need to keep protocol compatibility. Doing it for Hadoop 2 shouldn&apos;t be bad, because we have protobufs, but will still take a bit of careful HDFS surgery. I vaguely remember an existing HDFS JIRA about this, but now not sure where it went. Anyone remember the number or should we re-file?&lt;/p&gt;</comment>
                            <comment id="13457347" author="yuzhihong@gmail.com" created="Mon, 17 Sep 2012 21:23:20 +0000"  >&lt;p&gt;I found the following hdfs JIRAs:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-1034&quot; title=&quot;Enhance datanode to read data and checksum file in parallel&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-1034&quot;&gt;HDFS-1034&lt;/a&gt;: Enhance datanode to read data and checksum file in parallel&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-2699&quot; title=&quot;Store data and checksums together in block file&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-2699&quot;&gt;HDFS-2699&lt;/a&gt;: Store data and checksums together in block file&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-2699&quot; title=&quot;Store data and checksums together in block file&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-2699&quot;&gt;HDFS-2699&lt;/a&gt; garnered some attention early this year but there seems to be no active development.&lt;/p&gt;</comment>
                            <comment id="13457588" author="stack" created="Tue, 18 Sep 2012 04:10:02 +0000"  >&lt;p&gt;I did not realize hbase checksumming was a local-reads only facility.  If so, LiuLei, if you enable local reads &amp;#8211; &lt;a href=&quot;http://hbase.apache.org/book.html#perf.hdfs.configs&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hbase.apache.org/book.html#perf.hdfs.configs&lt;/a&gt; &amp;#8211; do you still see us double checksum checking when you read?  &lt;/p&gt;</comment>
                            <comment id="13457593" author="anoopsamjohn" created="Tue, 18 Sep 2012 04:38:13 +0000"  >&lt;blockquote&gt;&lt;p&gt;I did not realize hbase checksumming was a local-reads only facility.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Stack - In HBase handled checksum we write the checksum info also into the HFile blocks and do comparison once block data is fetched into RS. Does it related with only local reads? Pls correct me if my understanding is wrong..&lt;br/&gt;
Here when we fetch data from HDFS I guess we were using diff APIs or so to tell HDFS not to do the checksum check&lt;/p&gt;</comment>
                            <comment id="13457601" author="ram_krish" created="Tue, 18 Sep 2012 04:56:29 +0000"  >&lt;p&gt;Are we explicitly mentioning somewhere in the code that HBase check summing works with local read only?  &lt;/p&gt;</comment>
                            <comment id="13457679" author="liulei.cn" created="Tue, 18 Sep 2012 08:01:49 +0000"  >&lt;p&gt;The HBase check summing works with local read only,  The HBase check summing don&apos;t work with remote read.&lt;/p&gt;</comment>
                            <comment id="13457682" author="liulei.cn" created="Tue, 18 Sep 2012 08:06:55 +0000"  >&lt;p&gt;When we use the HDFS local read,  we should set dfs.client.read.shortcircuit.skip.checksum property to true. When the property is true,  DFSClient don&apos;t read the meta file, so HBase check summing work.&lt;/p&gt;</comment>
                            <comment id="13457716" author="anoopsamjohn" created="Tue, 18 Sep 2012 09:31:44 +0000"  >&lt;p&gt;So there is no effect on doing FileSystem#setVerifyChecksum(false)&lt;br/&gt;
We have this piece of code in HFileSystem&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-comment&quot;&gt;// If hbase checksum verification is switched on, then create a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt;
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;// filesystem object that has cksum verification turned off.
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;// We will avoid verifying checksums in the fs client, instead &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; it
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;// inside of hbase.
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;// If &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; is the local file system hadoop has a bug where seeks
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; not go to the correct location &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; setVerifyChecksum(&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;) is called.
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;// This manifests itself in that incorrect data is read and HFileBlocks won&apos;t be able to read
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;// their header magic numbers. See HBASE-5885
&lt;/span&gt;    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (useHBaseChecksum &amp;amp;&amp;amp; !(fs &lt;span class=&quot;code-keyword&quot;&gt;instanceof&lt;/span&gt; LocalFileSystem)) {
      &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.noChecksumFs = newInstanceFileSystem(conf);
      &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.noChecksumFs.setVerifyChecksum(&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;);
    } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
      &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.noChecksumFs = fs;
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

</comment>
                            <comment id="13457735" author="liulei.cn" created="Tue, 18 Sep 2012 10:47:33 +0000"  >&lt;p&gt;Anoop Sam John - When we set  dfs.client.read.shortcircuit property to true, HDFS use  local read,   local read also use the DistributedFileSystem class,  is not LocalFileSystem.&lt;/p&gt;</comment>
                            <comment id="13457737" author="liulei.cn" created="Tue, 18 Sep 2012 10:58:19 +0000"  >&lt;p&gt;We can add one new method in DFSClient, and add also one new method in DataXceiver, to implement don&apos;t read the meta file, that can  keep protocol compatibility in hadoop1.0&lt;/p&gt;</comment>
                            <comment id="13457739" author="anoopsamjohn" created="Tue, 18 Sep 2012 11:05:38 +0000"  >&lt;p&gt;@LiuLei &lt;br/&gt;
Yes I am aware of this..&lt;br/&gt;
What I am asking is that hbase handled checksum check can not be done in non local shortcircuit based reads? I doubt when the feature is developed whether this was the intent.. Atleast no such reference in code or book&lt;br/&gt;
Pls correct me if I have missed some thing.&lt;/p&gt;</comment>
                            <comment id="13457740" author="aoxiang" created="Tue, 18 Sep 2012 11:07:16 +0000"  >&lt;p&gt;DataNode reads checksums even if client does not need them&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-3429&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HDFS-3429&lt;/a&gt;&lt;/p&gt;
</comment>
                            <comment id="13457743" author="anoopsamjohn" created="Tue, 18 Sep 2012 11:10:24 +0000"  >&lt;p&gt;Need to check more in HDFS area..&lt;br/&gt;
Atleast we can document this then?&lt;br/&gt;
In book I am not able to see any thing related to hbase handled checksum checks.&lt;/p&gt;</comment>
                            <comment id="13457749" author="anoopsamjohn" created="Tue, 18 Sep 2012 11:23:45 +0000"  >&lt;p&gt;Clear about the issue. Thanks all...&lt;br/&gt;
Sorry for the noise&lt;/p&gt;</comment>
                            <comment id="13459041" author="stack" created="Wed, 19 Sep 2012 20:12:36 +0000"  >&lt;p&gt;Here is doc. I&apos;ve added to the refguide explaining the current state of things.&lt;/p&gt;</comment>
                            <comment id="13459044" author="stack" created="Wed, 19 Sep 2012 20:17:10 +0000"  >&lt;p&gt;Resolving.  This duplicate of hdfs-3429 or rather that is the root cause.&lt;/p&gt;</comment>
                            <comment id="13459124" author="hudson" created="Wed, 19 Sep 2012 21:36:23 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK #3354 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK/3354/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK/3354/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6798&quot; title=&quot;HDFS always read checksum form meta file&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6798&quot;&gt;&lt;del&gt;HBASE-6798&lt;/del&gt;&lt;/a&gt; HDFS always read checksum form meta file; DOCUMENTATION (Revision 1387734)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/src/docbkx/performance.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13459222" author="hudson" created="Wed, 19 Sep 2012 23:40:46 +0000"  >&lt;p&gt;Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #182 (See &lt;a href=&quot;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/182/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/182/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-6798&quot; title=&quot;HDFS always read checksum form meta file&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-6798&quot;&gt;&lt;del&gt;HBASE-6798&lt;/del&gt;&lt;/a&gt; HDFS always read checksum form meta file; DOCUMENTATION (Revision 1387734)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
stack : &lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hbase/trunk/src/docbkx/performance.xml&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13460151" author="liulei.cn" created="Fri, 21 Sep 2012 03:02:49 +0000"  >&lt;p&gt;Hi all, if HDFS don&apos;t  read checksum form meta file, that can dcrease iops for HFile, but HLog file of Hbase don&apos;t contain the checksum, so when HBase read the HLog, that must use checksum of HDFS, so we should add new setSkipChecksum(boolean) method in FileSystem, let HBase to deceid whether or not read the checksum from meta file.&lt;/p&gt;</comment>
                            <comment id="13460185" author="stack" created="Fri, 21 Sep 2012 04:04:00 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=liulei.cn&quot; class=&quot;user-hover&quot; rel=&quot;liulei.cn&quot;&gt;LiuLei&lt;/a&gt; ....so we should add new setSkipChecksum(boolean) method in FileSystem.... you mean per file?  You mean to HFileSystem?  Pardon my not understanding.  Thanks.&lt;/p&gt;</comment>
                            <comment id="13460513" author="liulei.cn" created="Fri, 21 Sep 2012 14:17:52 +0000"  >&lt;p&gt;Hi stack, yes, I think we should add a new setSkipChecksum(boolean) method in org.apache.hadoop.hdfs.FileSystem class. When read HLog files to use setSkipChecksum(false),  when read HFile file to use setSkipChecksum(true).&lt;/p&gt;</comment>
                            <comment id="13460772" author="stack" created="Fri, 21 Sep 2012 19:44:39 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=liulei.cn&quot; class=&quot;user-hover&quot; rel=&quot;liulei.cn&quot;&gt;LiuLei&lt;/a&gt; Please open a new issue.  We could do something like an add setSkipChecksum per file to hdfs or we could write checksums into WAL if this skip checksum facility is enabled (or have the WAL system use an fs w/ checksuming on).  I was looking through the &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-5074&quot; title=&quot;support checksums in HBase block cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-5074&quot;&gt;&lt;del&gt;HBASE-5074&lt;/del&gt;&lt;/a&gt; to figure how we fall back on the HDFS checksum but had to give up for the moment.  Lets carry the discussion on in a new issue rather than on the tail of this closed one.  Thanks for finding this.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12608728">HBASE-6868</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12555960">HDFS-3429</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12545789" name="6798.txt" size="832" author="stack" created="Wed, 19 Sep 2012 20:12:36 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Mon, 17 Sep 2012 04:08:18 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>242416</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 11 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i02usf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>14589</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>