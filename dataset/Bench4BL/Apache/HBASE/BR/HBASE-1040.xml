<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 02 20:35:38 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-1040/HBASE-1040.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-1040] OOME does not cause graceful shutdown under some failure scenarios</title>
                <link>https://issues.apache.org/jira/browse/HBASE-1040</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;I am seeing these exceptions on our cluster in output from tablemap/tablereduce jobs:&lt;/p&gt;

&lt;p&gt;&amp;gt; java.io.IOException: java.lang.OutOfMemoryError: Java heap space&lt;br/&gt;
&amp;gt; at java.io.DataInputStream.readFull(DataInputSteram.java:175)&lt;br/&gt;
&amp;gt; at org.apache.hadoop.io.DataOutputBuffer$Buffer.write(DataOutputBuffer.java:64)&lt;br/&gt;
&amp;gt; at org.apache.hadoop.io.DataOutputBuffer.write(DataOutputBuffer.java:102)&lt;br/&gt;
&amp;gt; at org.apahce.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1933)&lt;br/&gt;
&amp;gt; at org.apahce.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1833)&lt;br/&gt;
&amp;gt; at org.apahce.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1879)&lt;br/&gt;
&amp;gt; at org.apache.hadoop.io.MapFile$Reader.next(MapFile.java:516)&lt;br/&gt;
&amp;gt; at org.apache.hadoop.hbase.regionserver.StoreFileScanner.getNext(StoreFileScanner.java:312)&lt;/p&gt;

&lt;p&gt;When such OOMEs as above happen, the cluster does not recover without manual intervention. The regionservers sometimes go down after this, or sometimes do not and stay up in sick condition for a while. Regions go offline and remain unavailable.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12409606">HBASE-1040</key>
            <summary>OOME does not cause graceful shutdown under some failure scenarios</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="apurtell">Andrew Purtell</reporter>
                        <labels>
                    </labels>
                <created>Tue, 2 Dec 2008 02:01:06 +0000</created>
                <updated>Sun, 13 Sep 2009 22:26:34 +0000</updated>
                            <resolved>Thu, 4 Dec 2008 04:47:09 +0000</resolved>
                                    <version>0.18.1</version>
                                    <fixVersion>0.19.0</fixVersion>
                                    <component>regionserver</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12652667" author="apurtell" created="Wed, 3 Dec 2008 03:33:27 +0000"  >&lt;p&gt;See &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1038?focusedCommentId=12652658#action_12652658&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HBASE-1038?focusedCommentId=12652658#action_12652658&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12652890" author="apurtell" created="Wed, 3 Dec 2008 18:46:53 +0000"  >&lt;p&gt;OOME last night did not take down the region server and it did not relinquish its regions:&lt;/p&gt;

&lt;p&gt;2008-12-03 10:03:51,625 INFO org.apache.hadoop.ipc.Server: IPC Server handler 21 on 60020, call next(325852455557500270, 30) from 10.30.94.53:51099: error: java.io.IOException: java.lang.OutOfMemoryError: Java heap space&lt;br/&gt;
java.io.IOException: java.lang.OutOfMemoryError: Java heap space&lt;br/&gt;
	at org.apache.hadoop.hbase.io.ImmutableBytesWritable.readFields(ImmutableBytesWritable.java:110)&lt;br/&gt;
	at org.apache.hadoop.io.SequenceFile$Reader.getCurrentValue(SequenceFile.java:1754)&lt;br/&gt;
	at org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1882)&lt;br/&gt;
	at org.apache.hadoop.io.MapFile$Reader.next(MapFile.java:516)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.getNext(StoreFileScanner.java:312)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.next(StoreFileScanner.java:183)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HStoreScanner.next(HStoreScanner.java:226)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion$HScanner.next(HRegion.java:1920)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.next(HRegionServer.java:1356)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:634)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;br/&gt;
2008-12-03 10:03:53,173 INFO org.apache.hadoop.ipc.Server: IPC Server handler 16 on 60020, call next(3850133095248684283, 30) from 10.30.94.53:51111: error: java.io.IOException: java.lang.OutOfMemoryError: Java heap space&lt;br/&gt;
java.io.IOException: java.lang.OutOfMemoryError: Java heap space&lt;br/&gt;
	at org.apache.hadoop.hbase.io.ImmutableBytesWritable.readFields(ImmutableBytesWritable.java:110)&lt;br/&gt;
	at org.apache.hadoop.io.SequenceFile$Reader.getCurrentValue(SequenceFile.java:1754)&lt;br/&gt;
	at org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1882)&lt;br/&gt;
	at org.apache.hadoop.io.MapFile$Reader.next(MapFile.java:516)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.getNext(StoreFileScanner.java:312)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.next(StoreFileScanner.java:183)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HStoreScanner.next(HStoreScanner.java:226)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion$HScanner.next(HRegion.java:1920)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.next(HRegionServer.java:1356)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:634)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;br/&gt;
2008-12-03 10:03:55,024 INFO org.apache.hadoop.ipc.Server: IPC Server handler 13 on 60020, call next(-8816589261293751564, 30) from 10.30.94.35:59972: error: java.io.IOException: java.lang.OutOfMemoryError: GC overhead limit exceeded&lt;br/&gt;
java.io.IOException: java.lang.OutOfMemoryError: GC overhead limit exceeded&lt;br/&gt;
	at sun.nio.ch.Util.releaseTemporaryDirectBuffer(Util.java:67)&lt;br/&gt;
	at sun.nio.ch.IOUtil.read(IOUtil.java:212)&lt;br/&gt;
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:236)&lt;br/&gt;
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:55)&lt;br/&gt;
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:140)&lt;br/&gt;
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:150)&lt;br/&gt;
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:123)&lt;br/&gt;
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:218)&lt;br/&gt;
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:258)&lt;br/&gt;
	at java.io.BufferedInputStream.read(BufferedInputStream.java:317)&lt;br/&gt;
	at java.io.DataInputStream.read(DataInputStream.java:132)&lt;br/&gt;
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:100)&lt;br/&gt;
	at org.apache.hadoop.dfs.DFSClient$BlockReader.readChunk(DFSClient.java:1006)&lt;br/&gt;
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:238)&lt;br/&gt;
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:190)&lt;br/&gt;
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:159)&lt;br/&gt;
	at org.apache.hadoop.dfs.DFSClient$BlockReader.read(DFSClient.java:859)&lt;br/&gt;
	at org.apache.hadoop.dfs.DFSClient$DFSInputStream.readBuffer(DFSClient.java:1394)&lt;br/&gt;
	at org.apache.hadoop.dfs.DFSClient$DFSInputStream.read(DFSClient.java:1430)&lt;br/&gt;
	at java.io.DataInputStream.readFully(DataInputStream.java:178)&lt;br/&gt;
	at org.apache.hadoop.io.DataOutputBuffer$Buffer.write(DataOutputBuffer.java:64)&lt;br/&gt;
	at org.apache.hadoop.io.DataOutputBuffer.write(DataOutputBuffer.java:102)&lt;br/&gt;
	at org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1933)&lt;br/&gt;
	at org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1833)&lt;br/&gt;
	at org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1879)&lt;br/&gt;
	at org.apache.hadoop.io.MapFile$Reader.next(MapFile.java:516)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.getNext(StoreFileScanner.java:312)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.next(StoreFileScanner.java:183)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HStoreScanner.next(HStoreScanner.java:226)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion$HScanner.next(HRegion.java:1920)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.next(HRegionServer.java:1356)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)&lt;br/&gt;
2008-12-03 10:03:57,082 INFO org.apache.hadoop.fs.FSInputChecker: Found checksum error: org.apache.hadoop.fs.ChecksumException: Checksum error: /blk_1503942726006789756:of:/data/hbase/content/38150535/content/mapfiles/1992009933541116621/data at 3610624&lt;br/&gt;
	at org.apache.hadoop.fs.FSInputChecker.verifySum(FSInputChecker.java:277)&lt;br/&gt;
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:242)&lt;br/&gt;
	at org.apache.hadoop.fs.FSInputChecker.fill(FSInputChecker.java:177)&lt;br/&gt;
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:194)&lt;br/&gt;
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:159)&lt;br/&gt;
	at org.apache.hadoop.dfs.DFSClient$BlockReader.read(DFSClient.java:859)&lt;br/&gt;
	at org.apache.hadoop.dfs.DFSClient$DFSInputStream.readBuffer(DFSClient.java:1394)&lt;br/&gt;
	at org.apache.hadoop.dfs.DFSClient$DFSInputStream.read(DFSClient.java:1430)&lt;br/&gt;
	at org.apache.hadoop.dfs.DFSClient$DFSInputStream.read(DFSClient.java:1379)&lt;br/&gt;
	at java.io.DataInputStream.readInt(DataInputStream.java:370)&lt;br/&gt;
	at org.apache.hadoop.io.SequenceFile$Reader.readRecordLength(SequenceFile.java:1898)&lt;br/&gt;
	at org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1928)&lt;br/&gt;
	at org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1833)&lt;br/&gt;
	at org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1879)&lt;br/&gt;
	at org.apache.hadoop.io.MapFile$Reader.next(MapFile.java:516)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.getNext(StoreFileScanner.java:312)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.next(StoreFileScanner.java:183)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HStoreScanner.next(HStoreScanner.java:226)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion$HScanner.next(HRegion.java:1920)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.next(HRegionServer.java:1356)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:634)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;/p&gt;

&lt;p&gt;2008-12-03 10:03:57,083 WARN org.apache.hadoop.dfs.DFSClient: Found Checksum error for blk_1503942726006789756_2211303 from 10.30.94.32:50010 at 3610624&lt;br/&gt;
2008-12-03 10:03:59,711 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 60020, call next(-8816589261293751564, 30) from 10.30.94.35:59972: error: java.io.IOException: java.lang.OutOfMemoryError: Java heap space&lt;br/&gt;
java.io.IOException: java.lang.OutOfMemoryError: Java heap space&lt;br/&gt;
2008-12-03 10:04:02,486 INFO org.apache.hadoop.ipc.Server: IPC Server handler 19 on 60020, call next(-8816589261293751564, 30) from 10.30.94.35:59972: error: java.io.IOException: java.lang.OutOfMemoryError: Java heap space&lt;br/&gt;
java.io.IOException: java.lang.OutOfMemoryError: Java heap space&lt;br/&gt;
2008-12-03 10:04:06,829 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 60020, call next(-8816589261293751564, 30) from 10.30.94.35:59972: error: java.io.IOException: java.lang.OutOfMemoryError: Java heap space&lt;br/&gt;
java.io.IOException: java.lang.OutOfMemoryError: Java heap space&lt;br/&gt;
2008-12-03 10:04:12,044 INFO org.apache.hadoop.ipc.Server: IPC Server handler 18 on 60020, call next(-8816589261293751564, 30) from 10.30.94.35:59972: error: java.io.IOException: java.lang.OutOfMemoryError: Java heap space&lt;br/&gt;
java.io.IOException: java.lang.OutOfMemoryError: Java heap space&lt;br/&gt;
2008-12-03 10:04:13,607 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Scanner 2803606790257188079 lease expired&lt;br/&gt;
2008-12-03 10:04:16,873 INFO org.apache.hadoop.ipc.Server: IPC Server handler 29 on 60020, call next(-8816589261293751564, 30) from 10.30.94.35:59972: error: java.io.IOException: java.lang.OutOfMemoryError: Java heap space&lt;br/&gt;
java.io.IOException: java.lang.OutOfMemoryError: Java heap space&lt;br/&gt;
2008-12-03 10:04:25,970 INFO org.apache.hadoop.ipc.Server: IPC Server handler 14 on 60020, call next(-8816589261293751564, 30) from 10.30.94.35:59972: error: java.io.IOException: java.lang.OutOfMemoryError: Java heap space&lt;br/&gt;
java.io.IOException: java.lang.OutOfMemoryError: Java heap space&lt;br/&gt;
2008-12-03 10:04:34,702 INFO org.apache.hadoop.ipc.Server: IPC Server handler 21 on 60020, call next(-8816589261293751564, 30) from 10.30.94.35:59972: error: java.io.IOException: java.lang.OutOfMemoryError: Java heap space&lt;br/&gt;
java.io.IOException: java.lang.OutOfMemoryError: Java heap space&lt;br/&gt;
2008-12-03 10:04:53,653 INFO org.apache.hadoop.ipc.Server: IPC Server handler 25 on 60020, call next(-8816589261293751564, 30) from 10.30.94.35:60076: error: java.io.IOException: java.lang.OutOfMemoryError: Java heap space&lt;br/&gt;
java.io.IOException: java.lang.OutOfMemoryError: Java heap space&lt;br/&gt;
2008-12-03 10:05:05,487 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 60020, call next(3371752675632192545, 30) from 10.30.94.34:37462: error: java.io.IOException: java.lang.OutOfMemoryError: GC overhead limit exceeded&lt;br/&gt;
java.io.IOException: java.lang.OutOfMemoryError: GC overhead limit exceeded&lt;br/&gt;
2008-12-03 10:05:25,685 INFO org.apache.hadoop.ipc.Server: IPC Server handler 14 on 60020, call next(-8816589261293751564, 30) from 10.30.94.35:60092: error: java.io.IOException: read 218 bytes, should read 1666930&lt;br/&gt;
	at org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1842)&lt;br/&gt;
	at org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1879)&lt;br/&gt;
	at org.apache.hadoop.io.MapFile$Reader.next(MapFile.java:516)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.getNext(StoreFileScanner.java:312)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.next(StoreFileScanner.java:183)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HStoreScanner.next(HStoreScanner.java:226)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegion$HScanner.next(HRegion.java:1920)&lt;br/&gt;
	at org.apache.hadoop.hbase.regionserver.HRegionServer.next(HRegionServer.java:1356)&lt;br/&gt;
	at sun.reflect.GeneratedMethodAccessor43.invoke(Unknown Source)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:634)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)&lt;br/&gt;
2008-12-03 10:05:48,313 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Scanner -6882942580400942785 lease expired&lt;br/&gt;
2008-12-03 10:06:08,014 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Scanner 325852455557500270 lease expired&lt;br/&gt;
2008-12-03 10:09:37,822 INFO org.apache.hadoop.hbase.regionserver.HLog: Closed hdfs://sjdc-atr-dc-1.atr.trendmicro.com:50000/data/hbase/log_10.30.94.32_1228300601380_60020/hlog.dat.1228313220043, entries=100001. New log writer: /data/hbase/log_10.30.94.32_1228300601380_60020/hlog.dat.1228316977821&lt;br/&gt;
2008-12-03 10:20:11,460 INFO org.apache.hadoop.hbase.regionserver.MemcacheFlusher: Forced flushing of content,d6551908ed66a9122f8ec39594c8d36e,1228218699826 because global memcache limit of 536870912 exceeded; currenly 536909348 and flushing till 268435456&lt;br/&gt;
2008-12-03 10:20:16,973 WARN org.apache.hadoop.dfs.DFSClient: DataStreamer Exception: java.lang.OutOfMemoryError: GC overhead limit exceeded&lt;/p&gt;

&lt;p&gt;2008-12-03 10:20:16,974 WARN org.apache.hadoop.dfs.DFSClient: Error Recovery for block blk_-4000942059672147735_2225305 bad datanode&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt; 10.30.94.32:50010&lt;br/&gt;
2008-12-03 10:20:16,974 WARN org.apache.hadoop.dfs.DFSClient: Error Recovery for block blk_-4000942059672147735_2225305 in pipeline 10.30.94.32:50010, 10.30.94.50:50010, 10.30.94.54:50010: bad datanode 10.30.94.32:50010&lt;br/&gt;
2008-12-03 10:20:39,106 INFO org.apache.hadoop.ipc.Server: IPC Server handler 12 on 60020, call batchUpdates([B@31a00084, [Lorg.apache.hadoop.hbase.io.BatchUpdate;@7f81f38f) from 10.30.94.4:52172: error: java.io.IOException: java.lang.OutOfMemoryError: GC overhead limit exceeded&lt;br/&gt;
java.io.IOException: java.lang.OutOfMemoryError: GC overhead limit exceeded&lt;br/&gt;
2008-12-03 10:20:48,269 WARN org.apache.hadoop.ipc.Server: Out of Memory in server select&lt;br/&gt;
java.lang.OutOfMemoryError: GC overhead limit exceeded&lt;br/&gt;
2008-12-03 10:22:39,111 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Scanner -3591169216918124621 lease expired&lt;br/&gt;
2008-12-03 10:27:06,876 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Scanner 7353895356043684043 lease expired&lt;/p&gt;</comment>
                            <comment id="12652896" author="apurtell" created="Wed, 3 Dec 2008 18:51:24 +0000"  >&lt;p&gt;Edited description because I am no longer asking for OOME fixes to be backported to 0.18. (I have upgraded to TRUNK.)&lt;/p&gt;</comment>
                            <comment id="12652928" author="stack" created="Wed, 3 Dec 2008 19:45:45 +0000"  >&lt;p&gt;Last 1042 commit should make it shutdown.&lt;/p&gt;</comment>
                            <comment id="12653160" author="apurtell" created="Thu, 4 Dec 2008 04:47:09 +0000"  >&lt;p&gt;Fixed by &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1042&quot; title=&quot;OOME but we don&amp;#39;t abort&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1042&quot;&gt;&lt;del&gt;HBASE-1042&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12409991">HBASE-1045</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 3 Dec 2008 19:45:45 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>25536</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 1 week, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hayn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>99038</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>