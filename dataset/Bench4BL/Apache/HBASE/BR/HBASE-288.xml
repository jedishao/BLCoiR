<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 02 19:24:35 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-288/HBASE-288.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-288] Add in-memory caching of data</title>
                <link>https://issues.apache.org/jira/browse/HBASE-288</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Bigtable provides two in-memory caches: one for row/column data and one for disk block caches.&lt;/p&gt;

&lt;p&gt;The size of each cache should be configurable, data should be loaded lazily, and the cache managed by an LRU mechanism.&lt;/p&gt;

&lt;p&gt;One complication of the block cache is that all data is read through a SequenceFile.Reader which ultimately reads data off of disk via a RPC proxy for ClientProtocol. This would imply that the block caching would have to be pushed down to either the DFSClient or SequenceFile.Reader&lt;/p&gt;</description>
                <environment></environment>
        <key id="12369866">HBASE-288</key>
            <summary>Add in-memory caching of data</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="5" iconUrl="https://issues.apache.org/jira/images/icons/priorities/trivial.png">Trivial</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="tomwhite">Tom White</assignee>
                                    <reporter username="jimk">Jim Kellerman</reporter>
                        <labels>
                    </labels>
                <created>Mon, 21 May 2007 18:27:21 +0000</created>
                <updated>Thu, 2 May 2013 02:29:08 +0000</updated>
                            <resolved>Thu, 7 Feb 2008 17:50:37 +0000</resolved>
                                                    <fixVersion>0.2.0</fixVersion>
                                    <component>regionserver</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="12559089" author="tomwhite" created="Tue, 15 Jan 2008 15:45:05 +0000"  >&lt;p&gt;Here is an initial implementation - feedback would be much appreciated.&lt;/p&gt;

&lt;p&gt;BlockFSInputStream reads a FSInputStream in a block-oriented manner, and caches blocks. There&apos;s also a BlockMapFile.Reader that uses a BlockFSInputStream to read the MapFile data. HStore uses a BlockMapFile.Reader to read the first HStoreFile - at startup and after compaction. New HStoreFiles produced after memcache flushes are read using a regular reader in order to keep memory use fixed. Currently block caching is configured by the hbase properties hbase.hstore.blockCache.maxSize (defaults to 0 - no cache) and hbase.hstore.blockCache.blockSize (defaults to 64k). (It would be desirable to make caches configurable on a per-column family basis - the current way is just a stop gap.)&lt;/p&gt;

&lt;p&gt;I&apos;ve also had to push details of the block caching implementation up to MapFile.Reader, which is undesirable. The problem is that the streams are opened in the constructor of SequenceFile.Reader, which is called by the constructor of MapFile.Reader, so there is no opportunity to set the final fields blockSize and maxBlockCacheSize on a subclass of MapFile.Reader before the stream is opened. I think the proper solution is to have an explicit open method on SequenceFile.Reader, but I&apos;m not sure about the impact of this since it would be an incompatible change. Perhaps do in conjunction with &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-61&quot; title=&quot;[hbase] Create an HBase-specific MapFile implementation&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-61&quot;&gt;&lt;del&gt;HADOOP-2604&lt;/del&gt;&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="12559208" author="stack" created="Tue, 15 Jan 2008 20:04:33 +0000"  >&lt;p&gt;Patch looks great Tom.&lt;/p&gt;

&lt;p&gt;You pass &apos;length&apos; in the below but its not used:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+    &lt;span class=&quot;code-keyword&quot;&gt;protected&lt;/span&gt; FSDataInputStream openFile(FileSystem fs, Path file,
+        &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; bufferSize, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; length) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
+      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; fs.open(file, bufferSize);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I presume you have plans for it later?&lt;/p&gt;

&lt;p&gt;You have confidence in the LruMap class?  You don&apos;t have unit tests (though these things are hard to test).  I ask because though small, sometimes these kinds of classes can prove a little tricky....&lt;/p&gt;

&lt;p&gt;Do you have any numbers for how it improves throughput when cached blocks are &apos;hot&apos;?   And you talked of a slight &apos;cost&apos;.  Do you have rough numbers for that too? (Playing on datanode adjusting the size of the CRC blocks, a similar type of blocking to what you have here, there was no discernable difference adjusting sizes).&lt;/p&gt;

&lt;p&gt;What do we need to add to make it so its easy to enable/disable this feature on a per-column basis?  Currently edits to column config. requires taking column offline.  Changing this configuration looks safe-to-do while the column stays on line.  Would you agree?&lt;/p&gt;</comment>
                            <comment id="12559267" author="stack" created="Tue, 15 Jan 2008 22:51:20 +0000"  >&lt;p&gt;Tom: Ignore comment above on LruMap.  I just reread it.&lt;/p&gt;</comment>
                            <comment id="12559498" author="tomwhite" created="Wed, 16 Jan 2008 13:58:15 +0000"  >&lt;blockquote&gt;&lt;p&gt;You pass &apos;length&apos; in the below but its not used:&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It is used in the subclass of SequenceFile.Reader by BlockFSInputStream.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Do you have any numbers for how it improves throughput when cached blocks are &apos;hot&apos;?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I haven&apos;t got any numbers yet (working on them), but random reads will suffer in general since a whole 64KB block is retrieved to just read a single key/value. The Bigtable paper talks about reducing the block size to 8KB (see section 7).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;What do we need to add to make it so its easy to enable/disable this feature on a per-column basis? Currently edits to column config. requires taking column offline. Changing this configuration looks safe-to-do while the column stays on line. Would you agree?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Agreed. I think that dynamically editing a column descriptor should go in a separate jira issue. For now, I was planning on just adding the new parameters to HColumnDescriptor. Does the version number need bumping in this case?&lt;/p&gt;</comment>
                            <comment id="12559499" author="tomwhite" created="Wed, 16 Jan 2008 13:58:43 +0000"  >&lt;p&gt;A second patch with minimal changes to MapFile.Reader - there is a now a protected open() method for subclasses that wish to defer opening the streams until further initialization has been carried out.&lt;/p&gt;</comment>
                            <comment id="12560091" author="tomwhite" created="Thu, 17 Jan 2008 21:45:53 +0000"  >&lt;p&gt;I&apos;m trying to add a new parameter to HColumnDescriptor and would appreciate a little guidance. Do I need to worry about the version number? Is the order of the serialized fields important? It would be nice to group together the caching related ones if possible, so the block cache parameter would naturally sit next to the inMemory one. Ditto for the Thrift representation - how does it handle versioning? Thanks.&lt;/p&gt;</comment>
                            <comment id="12560099" author="jimk" created="Thu, 17 Jan 2008 21:58:09 +0000"  >&lt;p&gt;Tom,&lt;/p&gt;

&lt;p&gt;Yes, we need to start versioning everything that goes out to disk. And if we make an incompatible change, we either need to correct for it on the fly or augment the migration tool (hbase.util.Migrate.java)&lt;/p&gt;</comment>
                            <comment id="12560466" author="tomwhite" created="Fri, 18 Jan 2008 17:14:46 +0000"  >&lt;p&gt;This version (v3) changes the cache to a memory sensitive cache, implemented using SoftReferences (&lt;a href=&quot;http://commons.apache.org/collections/api-release/org/apache/commons/collections/map/ReferenceMap.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://commons.apache.org/collections/api-release/org/apache/commons/collections/map/ReferenceMap.html&lt;/a&gt;). See &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-70&quot; title=&quot;Improve region server memory management&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-70&quot;&gt;&lt;del&gt;HADOOP-2624&lt;/del&gt;&lt;/a&gt; for background.&lt;/p&gt;

&lt;p&gt;Also, block caching can be enabled on a column-family basis. The size of the block is a system wide setting - this could be adjustable on a per-column basis in the future, if it were deemed necessary.&lt;/p&gt;

&lt;p&gt;I&apos;m still looking at a performance comparison.&lt;/p&gt;</comment>
                            <comment id="12560467" author="tomwhite" created="Fri, 18 Jan 2008 17:16:59 +0000"  >&lt;p&gt;New dependency to go in src/contrib/hbase/lib/.&lt;/p&gt;</comment>
                            <comment id="12560607" author="stack" created="Fri, 18 Jan 2008 23:40:42 +0000"  >&lt;p&gt;(... continuing IRC discussion).&lt;/p&gt;

&lt;p&gt;I didn&apos;t realize HColumnDescriptor was versioned.  It doesn&apos;t seem to have been added by either Jim or I.  Someone smarter no doubt.  So, my comment that this change is incompatible doesn&apos;t hold since I see you have code to make it so HCD migrates itself.  Nice.&lt;/p&gt;

&lt;p&gt;In the below from HStoreFile, blockCacheEnabled method argument is not being passed to the MapFile constructors.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt; MapFile.Reader getReader(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; FileSystem fs,
+      &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Filter bloomFilter, &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; blockCacheEnabled)
+  &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
+    
+    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (isReference()) {
+      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; HStoreFile.HalfMapFileReader(fs,
+          getMapFilePath(reference).toString(), conf, 
+          reference.getFileRegion(), reference.getMidkey(), bloomFilter);
+    }
+    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; BloomFilterMapFile.Reader(fs, getMapFilePath().toString(),
+        conf, bloomFilter);
+  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Out of interest, did you regenerate the thrift or hand-edit it?  Changes look right &amp;#8211; just wondering.&lt;/p&gt;

&lt;p&gt;Default ReferenceMap constructor makes for hard keys and soft values.  If value has been let go by the GC, does the corresponding key just stay in the Map?&lt;/p&gt;

&lt;p&gt;Otherwise, patch looks great Tom.&lt;/p&gt;</comment>
                            <comment id="12560991" author="tomwhite" created="Mon, 21 Jan 2008 11:48:39 +0000"  >&lt;blockquote&gt;&lt;p&gt;In the below from HStoreFile, blockCacheEnabled method argument is not being passed to the MapFile constructors.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thanks - this had the effect of never enabling the cache! I&apos;ve fixed this.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Out of interest, did you regenerate the thrift or hand-edit it? Changes look right - just wondering.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I regenerated using the latest thrift trunk.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Default ReferenceMap constructor makes for hard keys and soft values. If value has been let go by the GC, does the corresponding key just stay in the Map?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;No, both the key and the value are removed from the map - I checked the source.&lt;/p&gt;

&lt;p&gt;This patch also includes changes to HBase Shell so you can alter a table to enable block caching.&lt;/p&gt;</comment>
                            <comment id="12561028" author="tomwhite" created="Mon, 21 Jan 2008 15:08:22 +0000"  >&lt;p&gt;Fixing the v4 patch which was corrupt.&lt;/p&gt;</comment>
                            <comment id="12561191" author="stack" created="Tue, 22 Jan 2008 01:26:26 +0000"  >&lt;p&gt;Patch looks good Tom.  I changed my mind since IRC this morning.  Now I think hbase should align with the parent and not add new features since feature freeze untill after we make the 0.16 branch (Kick me on IRC if you think different).&lt;/p&gt;</comment>
                            <comment id="12561327" author="tomwhite" created="Tue, 22 Jan 2008 12:37:12 +0000"  >&lt;p&gt;I ran some benchmarks of PerformanceEvaluation with and without block caching enabled. The setup was similar to that described in &lt;a href=&quot;http://wiki.apache.org/hadoop/Hbase/PerformanceEvaluation&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/hadoop/Hbase/PerformanceEvaluation&lt;/a&gt;, with three machines on EC2: one running the namenode and HBase master, one running a datanode and a region server, and one running a datanode and the PerformanceEvaluation program.&lt;/p&gt;

&lt;p&gt;Number of operations per second:&lt;/p&gt;

&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Experiment&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Block cache disabled&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Block cache enabled&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;sequential reads&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;119&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;182&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;random reads&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;110&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;123&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;I&apos;ve seen quite a lot of variation in the results of PerformanceEvaluation, so I&apos;m reluctant to read too much into these figures. But I think we can say that the block cache doesn&apos;t seem to slow down the system. &lt;/p&gt;</comment>
                            <comment id="12564787" author="tomwhite" created="Fri, 1 Feb 2008 14:45:58 +0000"  >&lt;p&gt;Regenerated patch that applies cleanly.&lt;/p&gt;</comment>
                            <comment id="12564817" author="hadoopqa" created="Fri, 1 Feb 2008 16:23:32 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
&lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12374558/hadoop-blockcache-v5.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12374558/hadoop-blockcache-v5.patch&lt;/a&gt;&lt;br/&gt;
against trunk revision 616796.&lt;/p&gt;

&lt;p&gt;    @author +1.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    javadoc +1.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    javac +1.  The applied patch does not generate any new javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    release audit +1.  The applied patch does not generate any new release audit warnings.&lt;/p&gt;

&lt;p&gt;    findbugs -1.  The patch appears to introduce 4 new Findbugs warnings.&lt;/p&gt;

&lt;p&gt;    core tests +1.  The patch passed core unit tests.&lt;/p&gt;

&lt;p&gt;    contrib tests +1.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1721/testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1721/testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1721/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1721/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle results: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1721/artifact/trunk/build/test/checkstyle-errors.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1721/artifact/trunk/build/test/checkstyle-errors.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1721/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1721/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="12565065" author="hudson" created="Sat, 2 Feb 2008 12:38:13 +0000"  >&lt;p&gt;Integrated in Hadoop-trunk #387 (See &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/387/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/387/&lt;/a&gt;)&lt;/p&gt;</comment>
                            <comment id="12565393" author="tomwhite" created="Mon, 4 Feb 2008 15:26:45 +0000"  >&lt;p&gt;Fix for findbugs warnings. (Note that this has not been integrated yet - the previous comment by Hudson was generated since the collections jar has been checked in.)&lt;/p&gt;</comment>
                            <comment id="12565422" author="hadoopqa" created="Mon, 4 Feb 2008 17:00:12 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
&lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12374684/hadoop-blockcache-v6.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12374684/hadoop-blockcache-v6.patch&lt;/a&gt;&lt;br/&gt;
against trunk revision 616796.&lt;/p&gt;

&lt;p&gt;    @author +1.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    javadoc +1.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    javac +1.  The applied patch does not generate any new javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    release audit +1.  The applied patch does not generate any new release audit warnings.&lt;/p&gt;

&lt;p&gt;    findbugs +1.  The patch does not introduce any new Findbugs warnings.&lt;/p&gt;

&lt;p&gt;    core tests +1.  The patch passed core unit tests.&lt;/p&gt;

&lt;p&gt;    contrib tests -1.  The patch failed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1736/testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1736/testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1736/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1736/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle results: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1736/artifact/trunk/build/test/checkstyle-errors.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1736/artifact/trunk/build/test/checkstyle-errors.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1736/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1736/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="12565429" author="stack" created="Mon, 4 Feb 2008 17:42:52 +0000"  >&lt;p&gt;Test passes on my machine.  +1 on applying the patch after quick review of v6.&lt;/p&gt;</comment>
                            <comment id="12565437" author="tomwhite" created="Mon, 4 Feb 2008 17:58:50 +0000"  >&lt;p&gt;I&apos;ve just committed this.&lt;/p&gt;</comment>
                            <comment id="12565529" author="stack" created="Mon, 4 Feb 2008 21:08:50 +0000"  >&lt;p&gt;Tom, I backed out the hbase component of this patch temporarily.  Notion is that we get hbase fixed up over in its new svn home, then we branch.  We want the branch to go against hadoop-0.16.0.  Once branch is done, we&apos;ll put this patch back into hbase TRUNK (With this patch in place, hbase requires post 0.16.0 hadoop).&lt;/p&gt;</comment>
                            <comment id="12565610" author="jimk" created="Tue, 5 Feb 2008 00:02:52 +0000"  >&lt;p&gt;Reopening issue. Patch was not fully backed out of HBase.&lt;/p&gt;</comment>
                            <comment id="12565784" author="tomwhite" created="Tue, 5 Feb 2008 16:03:03 +0000"  >&lt;p&gt;A new patch (v7) with just the HBase parts in it.  I successfully ran the HBase unit tests with this patch by using a Hadoop Core 0.16 jar that had been patched with the MapFile and SequenceFile changes in core trunk.&lt;/p&gt;

&lt;p&gt;This can be applied to trunk after the branch is created. &lt;/p&gt;

&lt;p&gt;Jim/Stack/Bryan: Sorry about the extra work I caused you by committing too early!&lt;/p&gt;</comment>
                            <comment id="12566712" author="stack" created="Thu, 7 Feb 2008 17:50:37 +0000"  >&lt;p&gt;Committed.  Thanks for the patch Tom.&lt;/p&gt;</comment>
                            <comment id="12609180" author="joonbok" created="Mon, 30 Jun 2008 08:27:50 +0000"  >&lt;p&gt;I&apos;m trying to apply this patch to Hbase 1.3.  v7 patch has only the HBase parts and seems not to be works with previous patch&apos;s hdfs part (sequenceFile and mapFile part).  v7 patch use not MapFile.Reader( ..., blocksize, maxBlockCacheSize) but MapFile.Reader( ..., blockCacheEnabled) . Could you upload v7 patch file including hdfs parts?&lt;/p&gt;</comment>
                            <comment id="12609433" author="stack" created="Tue, 1 Jul 2008 03:51:56 +0000"  >&lt;p&gt;Joonbok: I thought this patch had already been applied (to hbase since 0.1 and the hadoop portion to hadoop since 0.16.x?)  Is that why its not applying (Could be hard to figure it because a lot has changed in hbase since 02/07/08).&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12386176">HBASE-344</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12386561">HBASE-362</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310010">
                    <name>Incorporates</name>
                                            <outwardlinks description="incorporates">
                                        <issuelink>
            <issuekey id="12386393">HBASE-80</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12407320">HBASE-965</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                            <outwardlinks description="depends upon">
                                        <issuelink>
            <issuekey id="12369722">HBASE-285</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is depended upon by">
                                        <issuelink>
            <issuekey id="12369867">HADOOP-1399</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12373537" name="commons-collections-3.2.jar" size="571259" author="tomwhite" created="Fri, 18 Jan 2008 17:16:59 +0000"/>
                            <attachment id="12373274" name="hadoop-blockcache-v2.patch" size="22360" author="tomwhite" created="Wed, 16 Jan 2008 13:58:43 +0000"/>
                            <attachment id="12373536" name="hadoop-blockcache-v3.patch" size="38918" author="tomwhite" created="Fri, 18 Jan 2008 17:14:46 +0000"/>
                            <attachment id="12373682" name="hadoop-blockcache-v4.1.patch" size="83623" author="tomwhite" created="Mon, 21 Jan 2008 15:08:22 +0000"/>
                            <attachment id="12373672" name="hadoop-blockcache-v4.patch" size="79471" author="tomwhite" created="Mon, 21 Jan 2008 11:48:39 +0000"/>
                            <attachment id="12374558" name="hadoop-blockcache-v5.patch" size="83619" author="tomwhite" created="Fri, 1 Feb 2008 14:45:58 +0000"/>
                            <attachment id="12374684" name="hadoop-blockcache-v6.patch" size="83632" author="tomwhite" created="Mon, 4 Feb 2008 15:26:45 +0000"/>
                            <attachment id="12374782" name="hadoop-blockcache-v7.patch" size="73311" author="tomwhite" created="Tue, 5 Feb 2008 16:03:03 +0000"/>
                            <attachment id="12373173" name="hadoop-blockcache.patch" size="21173" author="tomwhite" created="Tue, 15 Jan 2008 15:45:05 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 15 Jan 2008 15:45:05 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>25072</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 23 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0h69j:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>98277</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>