<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 02 19:59:47 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-751/HBASE-751.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-751] dfs exception and regionserver stuck during heavy write load</title>
                <link>https://issues.apache.org/jira/browse/HBASE-751</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;It&apos;s a 3 node setup, each runs datanode and regionserver. One runs as hbase master and hadoop namenode.&lt;/p&gt;

&lt;p&gt;After some heavy write load via java client, the client is stuck. Stack trace on the regionserver shows:&lt;/p&gt;

&lt;p&gt;&quot;IPC Server handler 46 on 60020&quot; daemon prio=10 tid=0x4dd3f000 nid=0x4eb3 waiting for monitor entry &lt;span class=&quot;error&quot;&gt;&amp;#91;0x4cc82000..0x4cc83130&amp;#93;&lt;/span&gt;&lt;br/&gt;
   java.lang.Thread.State: BLOCKED (on object monitor)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.rowAtOrBeforeFromMapFile(HStore.java:1424)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;waiting to lock &amp;lt;0x59d27ba0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.getRowKeyAtOrBefore(HStore.java:1399)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1210)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1099)&lt;br/&gt;
    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)&lt;br/&gt;
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
    at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
    at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:438)&lt;br/&gt;
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&quot;IPC Server handler 43 on 60020&quot; daemon prio=10 tid=0x4dd3bc00 nid=0x4eb0 waiting for monitor entry &lt;span class=&quot;error&quot;&gt;&amp;#91;0x4cd75000..0x4cd75fb0&amp;#93;&lt;/span&gt;&lt;br/&gt;
   java.lang.Thread.State: BLOCKED (on object monitor)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.rowAtOrBeforeFromMapFile(HStore.java:1424)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;waiting to lock &amp;lt;0x59d27ba0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.getRowKeyAtOrBefore(HStore.java:1399)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1210)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1099)&lt;br/&gt;
    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)&lt;br/&gt;
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
    at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
    at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:438)&lt;br/&gt;
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&quot;IPC Server handler 40 on 60020&quot; daemon prio=10 tid=0x4dd38400 nid=0x4ead runnable &lt;span class=&quot;error&quot;&gt;&amp;#91;0x4ce68000..0x4ce68e30&amp;#93;&lt;/span&gt;&lt;br/&gt;
   java.lang.Thread.State: RUNNABLE&lt;br/&gt;
    at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)&lt;br/&gt;
    at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:215)&lt;br/&gt;
    at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:65)&lt;br/&gt;
    at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:69)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;locked &amp;lt;0x6a557580&amp;gt; (a sun.nio.ch.Util$1)&lt;/li&gt;
	&lt;li&gt;locked &amp;lt;0x6a557570&amp;gt; (a java.util.Collections$UnmodifiableSet)&lt;/li&gt;
	&lt;li&gt;locked &amp;lt;0x5cdcec18&amp;gt; (a sun.nio.ch.EPollSelectorImpl)&lt;br/&gt;
    at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:80)&lt;br/&gt;
    at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:237)&lt;br/&gt;
    at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:155)&lt;br/&gt;
    at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:149)&lt;br/&gt;
    at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:122)&lt;br/&gt;
    at java.io.BufferedInputStream.fill(BufferedInputStream.java:218)&lt;br/&gt;
    at java.io.BufferedInputStream.read(BufferedInputStream.java:237)&lt;/li&gt;
	&lt;li&gt;locked &amp;lt;0x552ffb60&amp;gt; (a java.io.BufferedInputStream)&lt;br/&gt;
    at java.io.DataInputStream.readInt(DataInputStream.java:370)&lt;br/&gt;
    at org.apache.hadoop.dfs.DFSClient$BlockReader.readChunk(DFSClient.java:928)&lt;/li&gt;
	&lt;li&gt;locked &amp;lt;0x55300f78&amp;gt; (a org.apache.hadoop.dfs.DFSClient$BlockReader)&lt;br/&gt;
    at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:236)&lt;br/&gt;
    at org.apache.hadoop.fs.FSInputChecker.fill(FSInputChecker.java:178)&lt;br/&gt;
    at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:195)&lt;br/&gt;
    at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:159)&lt;/li&gt;
	&lt;li&gt;locked &amp;lt;0x55300f78&amp;gt; (a org.apache.hadoop.dfs.DFSClient$BlockReader)&lt;br/&gt;
    at org.apache.hadoop.dfs.DFSClient$BlockReader.read(DFSClient.java:823)&lt;/li&gt;
	&lt;li&gt;locked &amp;lt;0x55300f78&amp;gt; (a org.apache.hadoop.dfs.DFSClient$BlockReader)&lt;br/&gt;
    at org.apache.hadoop.dfs.DFSClient$DFSInputStream.readBuffer(DFSClient.java:1352)&lt;/li&gt;
	&lt;li&gt;locked &amp;lt;0x59a70e40&amp;gt; (a org.apache.hadoop.dfs.DFSClient$DFSInputStream)&lt;br/&gt;
    at org.apache.hadoop.dfs.DFSClient$DFSInputStream.read(DFSClient.java:1388)&lt;/li&gt;
	&lt;li&gt;locked &amp;lt;0x59a70e40&amp;gt; (a org.apache.hadoop.dfs.DFSClient$DFSInputStream)&lt;br/&gt;
    at org.apache.hadoop.dfs.DFSClient$DFSInputStream.read(DFSClient.java:1337)&lt;/li&gt;
	&lt;li&gt;locked &amp;lt;0x59a70e40&amp;gt; (a org.apache.hadoop.dfs.DFSClient$DFSInputStream)&lt;br/&gt;
    at java.io.DataInputStream.readInt(DataInputStream.java:370)&lt;br/&gt;
    at org.apache.hadoop.io.SequenceFile$Reader.readRecordLength(SequenceFile.java:1847)&lt;/li&gt;
	&lt;li&gt;locked &amp;lt;0x651f77b0&amp;gt; (a org.apache.hadoop.io.SequenceFile$Reader)&lt;br/&gt;
    at org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1877)&lt;/li&gt;
	&lt;li&gt;locked &amp;lt;0x651f77b0&amp;gt; (a org.apache.hadoop.io.SequenceFile$Reader)&lt;br/&gt;
    at org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1782)&lt;/li&gt;
	&lt;li&gt;locked &amp;lt;0x651f77b0&amp;gt; (a org.apache.hadoop.io.SequenceFile$Reader)&lt;br/&gt;
    at org.apache.hadoop.io.MapFile$Reader.seekInternal(MapFile.java:476)&lt;/li&gt;
	&lt;li&gt;locked &amp;lt;0x59d27ba0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)&lt;br/&gt;
    at org.apache.hadoop.io.MapFile$Reader.getClosest(MapFile.java:558)&lt;/li&gt;
	&lt;li&gt;locked &amp;lt;0x59d27ba0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.rowKeyFromMapFileEmptyKeys(HStore.java:1463)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.rowAtOrBeforeFromMapFile(HStore.java:1434)&lt;/li&gt;
	&lt;li&gt;locked &amp;lt;0x59d27ba0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.getRowKeyAtOrBefore(HStore.java:1399)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1210)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1099)&lt;br/&gt;
    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)&lt;br/&gt;
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
    at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
    at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:438)&lt;br/&gt;
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&quot;IPC Server handler 38 on 60020&quot; daemon prio=10 tid=0x4dd36000 nid=0x4eab waiting for monitor entry &lt;span class=&quot;error&quot;&gt;&amp;#91;0x4cf0a000..0x4cf0b130&amp;#93;&lt;/span&gt;&lt;br/&gt;
   java.lang.Thread.State: BLOCKED (on object monitor)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.rowAtOrBeforeFromMapFile(HStore.java:1424)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;waiting to lock &amp;lt;0x59d27ba0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.getRowKeyAtOrBefore(HStore.java:1399)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1210)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1099)&lt;br/&gt;
    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)&lt;br/&gt;
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
    at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
    at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:438)&lt;br/&gt;
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&quot;IPC Server handler 37 on 60020&quot; daemon prio=10 tid=0x4dd35000 nid=0x4eaa waiting for monitor entry &lt;span class=&quot;error&quot;&gt;&amp;#91;0x4cf5b000..0x4cf5c0b0&amp;#93;&lt;/span&gt;&lt;br/&gt;
   java.lang.Thread.State: BLOCKED (on object monitor)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.rowAtOrBeforeFromMapFile(HStore.java:1424)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;waiting to lock &amp;lt;0x59d27ba0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.getRowKeyAtOrBefore(HStore.java:1399)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1210)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1099)&lt;br/&gt;
    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)&lt;br/&gt;
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
    at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
    at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:438)&lt;br/&gt;
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&quot;IPC Server handler 35 on 60020&quot; daemon prio=10 tid=0x4dd32c00 nid=0x4ea8 waiting for monitor entry &lt;span class=&quot;error&quot;&gt;&amp;#91;0x4cffd000..0x4cffdfb0&amp;#93;&lt;/span&gt;&lt;br/&gt;
   java.lang.Thread.State: BLOCKED (on object monitor)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.rowAtOrBeforeFromMapFile(HStore.java:1424)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;waiting to lock &amp;lt;0x59d27ba0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.getRowKeyAtOrBefore(HStore.java:1399)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1210)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1099)&lt;br/&gt;
    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)&lt;br/&gt;
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
    at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
    at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:438)&lt;br/&gt;
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&quot;IPC Server handler 30 on 60020&quot; daemon prio=10 tid=0x4dd2d400 nid=0x4ea3 waiting for monitor entry &lt;span class=&quot;error&quot;&gt;&amp;#91;0x4d192000..0x4d193130&amp;#93;&lt;/span&gt;&lt;br/&gt;
   java.lang.Thread.State: BLOCKED (on object monitor)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.rowAtOrBeforeFromMapFile(HStore.java:1424)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;waiting to lock &amp;lt;0x59d27ba0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.getRowKeyAtOrBefore(HStore.java:1399)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1210)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1099)&lt;br/&gt;
    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)&lt;br/&gt;
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
    at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
    at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:438)&lt;br/&gt;
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&quot;IPC Server handler 29 on 60020&quot; daemon prio=10 tid=0x4dd2c000 nid=0x4ea2 waiting for monitor entry &lt;span class=&quot;error&quot;&gt;&amp;#91;0x4d1e3000..0x4d1e40b0&amp;#93;&lt;/span&gt;&lt;br/&gt;
   java.lang.Thread.State: BLOCKED (on object monitor)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.rowAtOrBeforeFromMapFile(HStore.java:1424)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;waiting to lock &amp;lt;0x59d27ba0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.getRowKeyAtOrBefore(HStore.java:1399)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1210)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1099)&lt;br/&gt;
    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)&lt;br/&gt;
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
    at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
    at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:438)&lt;br/&gt;
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&quot;IPC Server handler 26 on 60020&quot; daemon prio=10 tid=0x4dd29800 nid=0x4e9f waiting for monitor entry &lt;span class=&quot;error&quot;&gt;&amp;#91;0x4d2d6000..0x4d2d6f30&amp;#93;&lt;/span&gt;&lt;br/&gt;
   java.lang.Thread.State: BLOCKED (on object monitor)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.rowAtOrBeforeFromMapFile(HStore.java:1424)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;waiting to lock &amp;lt;0x59d27ba0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.getRowKeyAtOrBefore(HStore.java:1399)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1210)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1099)&lt;br/&gt;
    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)&lt;br/&gt;
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
    at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
    at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:438)&lt;br/&gt;
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&quot;IPC Server handler 17 on 60020&quot; daemon prio=10 tid=0x4dd1f800 nid=0x4e96 waiting for monitor entry &lt;span class=&quot;error&quot;&gt;&amp;#91;0x4d5af000..0x4d5afeb0&amp;#93;&lt;/span&gt;&lt;br/&gt;
   java.lang.Thread.State: BLOCKED (on object monitor)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.rowAtOrBeforeFromMapFile(HStore.java:1424)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;waiting to lock &amp;lt;0x59d27ba0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.getRowKeyAtOrBefore(HStore.java:1399)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1210)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1099)&lt;br/&gt;
    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)&lt;br/&gt;
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
    at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
    at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:438)&lt;br/&gt;
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&quot;IPC Server handler 14 on 60020&quot; daemon prio=10 tid=0x4dd1c400 nid=0x4e93 waiting for monitor entry &lt;span class=&quot;error&quot;&gt;&amp;#91;0x4d6a2000..0x4d6a3130&amp;#93;&lt;/span&gt;&lt;br/&gt;
   java.lang.Thread.State: BLOCKED (on object monitor)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.rowAtOrBeforeFromMapFile(HStore.java:1424)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;waiting to lock &amp;lt;0x59d27ba0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.getRowKeyAtOrBefore(HStore.java:1399)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1210)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1099)&lt;br/&gt;
    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)&lt;br/&gt;
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
    at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
    at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:438)&lt;br/&gt;
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&quot;IPC Server handler 10 on 60020&quot; daemon prio=10 tid=0x4dd17c00 nid=0x4e8f waiting for monitor entry &lt;span class=&quot;error&quot;&gt;&amp;#91;0x4d7e6000..0x4d7e6f30&amp;#93;&lt;/span&gt;&lt;br/&gt;
   java.lang.Thread.State: BLOCKED (on object monitor)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.rowAtOrBeforeFromMapFile(HStore.java:1424)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;waiting to lock &amp;lt;0x59d27ba0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.getRowKeyAtOrBefore(HStore.java:1399)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1210)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1099)&lt;br/&gt;
    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)&lt;br/&gt;
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
    at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
    at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:438)&lt;br/&gt;
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&quot;IPC Server handler 7 on 60020&quot; daemon prio=10 tid=0x4dd14800 nid=0x4e8c waiting for monitor entry &lt;span class=&quot;error&quot;&gt;&amp;#91;0x4d8d9000..0x4d8da1b0&amp;#93;&lt;/span&gt;&lt;br/&gt;
   java.lang.Thread.State: BLOCKED (on object monitor)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.rowAtOrBeforeFromMapFile(HStore.java:1424)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;waiting to lock &amp;lt;0x59d27ba0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.getRowKeyAtOrBefore(HStore.java:1399)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1210)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1099)&lt;br/&gt;
    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)&lt;br/&gt;
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
    at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
    at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:438)&lt;br/&gt;
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&quot;IPC Server handler 0 on 60020&quot; daemon prio=10 tid=0x4e2c0c00 nid=0x4e85 waiting for monitor entry &lt;span class=&quot;error&quot;&gt;&amp;#91;0x4db10000..0x4db10e30&amp;#93;&lt;/span&gt;&lt;br/&gt;
   java.lang.Thread.State: BLOCKED (on object monitor)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.rowAtOrBeforeFromMapFile(HStore.java:1424)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;waiting to lock &amp;lt;0x59d27ba0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.getRowKeyAtOrBefore(HStore.java:1399)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1210)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1099)&lt;br/&gt;
    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)&lt;br/&gt;
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)&lt;br/&gt;
    at java.lang.reflect.Method.invoke(Method.java:597)&lt;br/&gt;
    at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:438)&lt;br/&gt;
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;in regionserver log, I see the following right before the client stuck (there are few other similar logs, but the client keeps going at those time points):&lt;/p&gt;

&lt;p&gt;2008-07-17 22:31:49,404 INFO org.apache.hadoop.hbase.regionserver.HRegion: region aaa,bbb,1216304670433/1145836031 available&lt;br/&gt;
2008-07-17 22:31:49,404 INFO org.apache.hadoop.hbase.regionserver.HRegion: starting compaction on region aaa,bbb,1216304670433&lt;br/&gt;
2008-07-17 22:32:07,653 WARN org.apache.hadoop.hbase.regionserver.HStore: Exception closing reader for 1145836031/ccc&lt;br/&gt;
java.io.IOException: Stream closed&lt;br/&gt;
    at org.apache.hadoop.dfs.DFSClient$DFSInputStream.close(DFSClient.java:1319)&lt;br/&gt;
    at java.io.FilterInputStream.close(FilterInputStream.java:155)&lt;br/&gt;
    at org.apache.hadoop.io.SequenceFile$Reader.close(SequenceFile.java:1581)&lt;br/&gt;
    at org.apache.hadoop.io.MapFile$Reader.close(MapFile.java:577)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.closeCompactionReaders(HStore.java:917)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.compactHStoreFiles(HStore.java:910)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.compact(HStore.java:787)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HRegion.compactStores(HRegion.java:887)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HRegion.compactStores(HRegion.java:847)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.CompactSplitThread.run(CompactSplitThread.java:84)&lt;br/&gt;
(and two of the same exception, since I have 3 HStoreFIle to compact)&lt;br/&gt;
2008-07-17 22:32:07,912 INFO org.apache.hadoop.hbase.regionserver.HRegion: compaction completed on region aaa,bbb,1216304670433 in 18sec&lt;br/&gt;
[after this point, I only see regionserver rotates HLog, no other activities)&lt;/p&gt;

&lt;p&gt;At 22:32, no suspicious log in datanode, but 8mins later, I see this&lt;/p&gt;

&lt;p&gt;2008-07-17 22:40:07,928 WARN org.apache.hadoop.dfs.DataNode: 192.168.1.5650010:Got exception while serving blk_-38731635936101350 to /192.168.1.56&lt;br/&gt;
java.net.SocketTimeoutException: 480000 millis timeout while waiting for channel to be ready for write. ch : java.nio.channels.SocketChannel&lt;span class=&quot;error&quot;&gt;&amp;#91;connected local=/192.168.1.56:50010 remote=/192.168.1.56:40691&amp;#93;&lt;/span&gt;&lt;br/&gt;
    at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:170)&lt;br/&gt;
    at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:144)&lt;br/&gt;
    at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:105)&lt;br/&gt;
    at java.io.BufferedOutputStream.write(BufferedOutputStream.java:105)&lt;br/&gt;
    at java.io.DataOutputStream.write(DataOutputStream.java:90)&lt;br/&gt;
    at org.apache.hadoop.dfs.DataNode$BlockSender.sendChunks(DataNode.java:1784)&lt;br/&gt;
    at org.apache.hadoop.dfs.DataNode$BlockSender.sendBlock(DataNode.java:1840)&lt;br/&gt;
    at org.apache.hadoop.dfs.DataNode$DataXceiver.readBlock(DataNode.java:1055)&lt;br/&gt;
    at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:984)&lt;br/&gt;
    at java.lang.Thread.run(Thread.java:619)&lt;/p&gt;

&lt;p&gt;for this particular block in question, I found around the region available time:&lt;/p&gt;

&lt;p&gt;2008-07-17 22:31:49,642 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-38731635936101350 src: /192.168.1.56:37878 dest: /192.168.1.56:50010&lt;br/&gt;
2008-07-17 22:31:56,856 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-38731635936101350 of size 67108864 from /192.168.1.56&lt;br/&gt;
2008-07-17 22:31:56,857 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 1 for block blk_-38731635936101350 terminating&lt;/p&gt;

&lt;p&gt;And after the hbase client stuck, I found one datanode keeps sending the &lt;b&gt;same&lt;/b&gt; block to the regionserver, which is blocked as shown above.&lt;/p&gt;

&lt;p&gt;=====&lt;/p&gt;

&lt;p&gt;For the record, I did not see this &quot;Stream closed&quot; error on another small 4-node cluster with trunk r675659 (same hadoop version with the 3-node cluster above).&lt;/p&gt;

&lt;p&gt;For hbase trunk r677011, I got &lt;/p&gt;

&lt;p&gt;java.lang.NullPointerException&lt;br/&gt;
        at org.apache.hadoop.hbase.client.ServerCallable.getServerName(ServerCallable.java:63)&lt;br/&gt;
        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getRegionServerWithRetries(HConnectionManager.java:886&lt;br/&gt;
        at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:1161)&lt;/p&gt;

&lt;p&gt;then, the region server stucks&lt;/p&gt;

&lt;p&gt;08/07/18 05:29:29 INFO ipc.RPC: Problem connecting to server: /192.168.1.56:60020&lt;/p&gt;

&lt;p&gt;stack dump shows similar as the above one, and I&apos;m also seeing the dfs exception.&lt;/p&gt;</description>
                <environment>&lt;p&gt;jdk 1.6, hadoop 0.17.2-dev (hadoop-0.17, r677779), hbase trunk r677517&lt;/p&gt;</environment>
        <key id="12400518">HBASE-751</key>
            <summary>dfs exception and regionserver stuck during heavy write load</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="stack">stack</assignee>
                                    <reporter username="rafan">Rong-En Fan</reporter>
                        <labels>
                    </labels>
                <created>Fri, 18 Jul 2008 02:07:17 +0000</created>
                <updated>Fri, 22 Aug 2008 21:13:20 +0000</updated>
                            <resolved>Fri, 1 Aug 2008 06:40:44 +0000</resolved>
                                    <version>0.2.0</version>
                                    <fixVersion>0.2.0</fixVersion>
                                    <component>regionserver</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                <comments>
                            <comment id="12614646" author="rafan" created="Fri, 18 Jul 2008 04:42:43 +0000"  >&lt;p&gt;For the record, I see similar backtrace in Hudson HBase-Patch #224 build:&lt;/p&gt;

&lt;p&gt;regionserver.HStore(919): Exception closing reader for 1028785192/info&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; java.io.IOException: Stream closed&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.dfs.DFSClient$DFSInputStream.close(DFSClient.java:1319)&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at java.io.FilterInputStream.close(FilterInputStream.java:155)&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.io.SequenceFile$Reader.close(SequenceFile.java:1581)&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.io.MapFile$Reader.close(MapFile.java:577)&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hbase.regionserver.HStore.closeCompactionReaders(HStore.java:917)&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hbase.regionserver.HStore.compactHStoreFiles(HStore.java:910)&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hbase.regionserver.HStore.compact(HStore.java:787)&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hbase.regionserver.HRegion.compactStores(HRegion.java:887)&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hbase.regionserver.HRegion.compactStores(HRegion.java:847)&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hbase.regionserver.CompactSplitThread.run(CompactSplitThread.java:84)&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 2008-07-17 16:52:38,638 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;RegionServer:0.compactor&amp;#93;&lt;/span&gt; &lt;/p&gt;</comment>
                            <comment id="12615910" author="rafan" created="Wed, 23 Jul 2008 08:33:55 +0000"  >&lt;p&gt;The IOE in regionserver log is fixed by stack.&lt;/p&gt;

&lt;p&gt;And I still see regionserver hang against latest trunk.&lt;br/&gt;
After ~1hr of the hang, the client shows&lt;/p&gt;

&lt;p&gt;java.lang.NullPointerException&lt;br/&gt;
        at org.apache.hadoop.hbase.client.ServerCallable.getServerName(ServerCallable.java:63)&lt;br/&gt;
        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getRegionServerWithRetries(HConnectionManager.java:885)&lt;br/&gt;
        at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:1167)&lt;/p&gt;

&lt;p&gt;Some non-default settings:&lt;/p&gt;

&lt;p&gt;  &amp;lt;property&amp;gt;&lt;br/&gt;
    &amp;lt;name&amp;gt;hbase.master.lease.period&amp;lt;/name&amp;gt;&lt;br/&gt;
    &amp;lt;value&amp;gt;600000&amp;lt;/value&amp;gt;&lt;br/&gt;
  &amp;lt;/property&amp;gt;&lt;/p&gt;

&lt;p&gt;  &amp;lt;property&amp;gt;&lt;br/&gt;
    &amp;lt;name&amp;gt;hbase.client.retries.number&amp;lt;/name&amp;gt;&lt;br/&gt;
    &amp;lt;value&amp;gt;10&amp;lt;/value&amp;gt;&lt;br/&gt;
  &amp;lt;/property&amp;gt;&lt;/p&gt;




</comment>
                            <comment id="12616026" author="jdcryans" created="Wed, 23 Jul 2008 13:59:28 +0000"  >&lt;p&gt;Can you confirm that you don&apos;t have the same kind of problem as seen in Renaud Delbru&apos;s setup? His main issue was that the nodes were swapping like there is no tomorrow.&lt;/p&gt;</comment>
                            <comment id="12616143" author="rafan" created="Wed, 23 Jul 2008 16:18:09 +0000"  >&lt;p&gt;No. it&apos;s not swapping.&lt;/p&gt;</comment>
                            <comment id="12616225" author="stack" created="Wed, 23 Jul 2008 19:10:44 +0000"  >&lt;p&gt;This is ugly, particularly when its in 0.17.2 hadoop.   I&apos;ve seen variations on this, e.g. &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-634&quot; title=&quot;hbase hungup on hdfs: appending to HLog.  Won&amp;#39;t shut down.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-634&quot;&gt;&lt;del&gt;HBASE-634&lt;/del&gt;&lt;/a&gt;, but not this exact hang not having run big stuff on 0.17.x hadoop yet.&lt;/p&gt;

&lt;p&gt;We&apos;re stuck doing a readInt down in DFSClient.  Looks like an HDFS issue.  Do you want to try asking over in hadoop-user Rong-en to see if you get any pointers? (I started to put together an email myself but its a bit awkward me telling your story; I think you would do it better yourself).  Pertinent I think are the block serving timeout exception that you note above.   Do you think you could reproduce with HDFS logging all on DEBUG?  That&apos;d give us more clues as to whats going on.  Thanks Rong-en&lt;/p&gt;</comment>
                            <comment id="12616226" author="stack" created="Wed, 23 Jul 2008 19:12:08 +0000"  >&lt;p&gt;Out of interest, whats your OS info?  And which particular 1.6 JDK?&lt;/p&gt;</comment>
                            <comment id="12616324" author="rafan" created="Thu, 24 Jul 2008 01:30:32 +0000"  >&lt;p&gt;Ya, I started to think this a HDFS issue. I will write a mail&lt;br/&gt;
to core-user later.&lt;/p&gt;

&lt;p&gt;JDK is 1.6u4, OS is RHEL 4 update 4.&lt;/p&gt;</comment>
                            <comment id="12616543" author="stack" created="Thu, 24 Jul 2008 17:21:23 +0000"  >&lt;p&gt;Made this critical.&lt;/p&gt;

&lt;p&gt;And, looking again, the thread doing the readInt is not stuck, rather, its RUNNABLE.  But I&apos;d guess we probably are not returning up out of this read.  Rong-en, you might try doing a couple of thread dumps in a row to see if this is so.&lt;/p&gt;</comment>
                            <comment id="12616751" author="rafan" created="Fri, 25 Jul 2008 03:30:31 +0000"  >&lt;p&gt;with trunk 679236, I do couple thread dumps in a row, and it suggests that&lt;/p&gt;

&lt;p&gt;    at org.apache.hadoop.hbase.regionserver.HStore.rowKeyFromMapFileEmptyKeys(HStore.java:1510)&lt;/p&gt;

&lt;p&gt;is in a infinite loop as seen in successive dumps:&lt;/p&gt;

&lt;p&gt;    at org.apache.hadoop.io.MapFile$Reader.seekInternal(MapFile.java:463)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;locked &amp;lt;0x5cd28ec8&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)&lt;br/&gt;
    at org.apache.hadoop.io.MapFile$Reader.getClosest(MapFile.java:558)&lt;/li&gt;
	&lt;li&gt;locked &amp;lt;0x5cd28ec8&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.rowKeyFromMapFileEmptyKeys(HStore.java:1510)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.rowAtOrBeforeFromMapFile(HStore.java:1481)&lt;/li&gt;
	&lt;li&gt;locked &amp;lt;0x5cd28ec8&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HStore.getRowKeyAtOrBefore(HStore.java:1446)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1227)&lt;br/&gt;
    at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1099)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The only difference is sometimes it is in&lt;/p&gt;

&lt;p&gt;    at org.apache.hadoop.io.MapFile$Reader.seekInternal(MapFile.java:476)&lt;/p&gt;

&lt;p&gt;The block that dfs keeps sending is&lt;/p&gt;

&lt;p&gt;blk_8253555549802756519&lt;/p&gt;

&lt;p&gt;which is &lt;/p&gt;

&lt;p&gt;/hbase/.META./1028785192/historian/mapfiles/6501633157510870075/data&lt;/p&gt;

&lt;p&gt;A close look at rowKeyFromMapFileEmptyKeys() and the historian file give me some &lt;br/&gt;
hints. The while loop may never exit if we can not find a candidate key (foundCandidate=false)&lt;br/&gt;
&lt;b&gt;and&lt;/b&gt; a deleted or expired row exists (deletedOrExpiredRow != null). In this case,&lt;br/&gt;
we will put the searchKey as the deletedOrExpiredRow. Then do the search again.&lt;br/&gt;
Since the searchKey is the one that is delete or expired and this searchKey&lt;br/&gt;
&lt;b&gt;does&lt;/b&gt; exist in the map file.So next time, &lt;/p&gt;

&lt;p&gt;readkey = (HStoreKey)map.getClosest(searchKey, readval, true);&lt;/p&gt;

&lt;p&gt;gives the same readKey as before which is the row that is deleted or expired.&lt;/p&gt;

&lt;p&gt;This scenario happens if the first searchKey  is an deleted/expired row and &lt;br/&gt;
exist in the mapfile or this does no exist, but the one immediate before this&lt;br/&gt;
key in mapfile is delete/expired.&lt;/p&gt;

&lt;p&gt;I examine the historian file, the first entry&apos;s value is HBASE::DELETEVAL. So if &lt;br/&gt;
we are looking at the row whose HStoreKey is this entry&apos;s key. we end up&lt;br/&gt;
in an infinite loop. Since &lt;/p&gt;

&lt;p&gt;#1 searchKey is the first entry&lt;br/&gt;
#2 we get the readKey which is deleted&lt;br/&gt;
#3 the next key exceeds the row we want&lt;br/&gt;
#4 we set searchKey the the readKey (that are the same!)&lt;br/&gt;
#5 loops begins...&lt;/p&gt;

&lt;p&gt;my 0.02 cents.&lt;/p&gt;</comment>
                            <comment id="12617216" author="stack" created="Sat, 26 Jul 2008 21:15:03 +0000"  >&lt;p&gt;This is an awkward one to fix.&lt;/p&gt;

&lt;p&gt;Chatting with Todd Lipcon, he made two suggestions:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[14:01]	&amp;lt;Toad&amp;gt;	here&apos;s an ugly idea until we can get a patch in hadoop:
[14:02]	&amp;lt;Toad&amp;gt;	class NeverEqualWritableComparable &lt;span class=&quot;code-keyword&quot;&gt;implements&lt;/span&gt; WritableComparable {
[14:02]	&amp;lt;Toad&amp;gt;	&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; NeverEqualWritableComparable(WritableComparable wrapped) {
[14:02]	&amp;lt;Toad&amp;gt;	_wrapped = wrapped;
[14:02]	&amp;lt;Toad&amp;gt;	}
[14:02]	&amp;lt;Toad&amp;gt;	&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; compare(WritableComparable other) {
[14:02]	&amp;lt;Toad&amp;gt;	&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; res = _wrapped.compare(other);
[14:03]	&amp;lt;Toad&amp;gt;	&lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; (res == 0) ? 1 : res;
[14:03]	&amp;lt;Toad&amp;gt;	}
[14:03]	&amp;lt;Toad&amp;gt;	}
[14:03]	&amp;lt;st^ack&amp;gt;	Where would I insert it?
[14:03]	&amp;lt;Toad&amp;gt;	then use getClosest(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; NeverEqualWritableComparable(searchkey), value, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;)
[14:04]	&amp;lt;Toad&amp;gt;	that way you ensure that you won&apos;t get the same one again
[14:04]	* st^ack	looking
[14:04]	&amp;lt;Toad&amp;gt;	err, it&apos;s compareTo(...) I guess, not .compare. and you need to implement write and readFields to wrap the wrapped one
[14:05]	&amp;lt;Toad&amp;gt;	hmm, should it &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; 1 or -1 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; equality...
[14:05]	&amp;lt;Toad&amp;gt;	I think -1 actually
[14:06]	&amp;lt;Toad&amp;gt;	you want the &lt;span class=&quot;code-quote&quot;&gt;&quot;just before&quot;&lt;/span&gt; search key to report that it&apos;s smaller than itself
[14:06]	&amp;lt;st^ack&amp;gt;	We&apos;ve gone too far when we hit the not-wanted hsk
[14:06]	&amp;lt;Toad&amp;gt;	and I guess you should override .equals also to always &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
[14:06]	&amp;lt;Toad&amp;gt;	just to maintain that compareTo/equals consistency contract
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;... or just copy MapFile local and add getBefore to get the row just before the delete record.&lt;/p&gt;</comment>
                            <comment id="12617217" author="stack" created="Sat, 26 Jul 2008 21:15:32 +0000"  >&lt;p&gt;Made blocker for 0.2.0. release.&lt;/p&gt;</comment>
                            <comment id="12617261" author="rafan" created="Sun, 27 Jul 2008 09:15:04 +0000"  >&lt;p&gt;The bug is more serious than I thought.&lt;/p&gt;

&lt;p&gt;It also exists in Memcache. In internalGetRowKeyAtOrBefore(), we search all keys &lt;b&gt;after&lt;/b&gt; the searchKey and if the searchKey is deleted, then we only look into tailMap while we should also check headMap for this case.&lt;/p&gt;</comment>
                            <comment id="12617262" author="rafan" created="Sun, 27 Jul 2008 09:15:56 +0000"  >&lt;p&gt;Attach a unit test that test both memcache and mapfile. The data inserted is simple:&lt;/p&gt;

&lt;p&gt;10&lt;br/&gt;
20 &amp;lt;== deleted&lt;br/&gt;
30 &amp;lt;== deleted&lt;/p&gt;

&lt;p&gt;then we look for 30.&lt;/p&gt;

&lt;p&gt;For Memcache, we get NPE. For HStore, we have the infinite loop.&lt;/p&gt;

&lt;p&gt;The loop in HStore happens like the following. The first searchKey (30 without column name, latest timestamp) gives (20, 30). But since 20 and 30 are all deleted and no candidates found. We set searchKey to 30 (with columnname, latest timestamp. Next search gives us (20, 30). Now the loops begin. If you add some debug messages in HStore, you can see something like this:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
enter rowKeyFromMapFileEmptyKeys to search row 030 now 1217149629818
&lt;span class=&quot;code-comment&quot;&gt;// 1st searchKey
&lt;/span&gt;searchKey 030&lt;span class=&quot;code-comment&quot;&gt;//9223372036854775807
&lt;/span&gt;foundCandidate &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; searchKey 030&lt;span class=&quot;code-comment&quot;&gt;//9223372036854775807
&lt;/span&gt;readKey 020/colfamily1:/1217149629664 readVal 48 42 41 53 45 3a 3a 44 45 4c 45 54 45 56 41 4c
close match, but deleted
readKey 030/colfamily1:/1217149629665 readVal 48 42 41 53 45 3a 3a 44 45 4c 45 54 45 56 41 4c
exact match, but deleted
no candidates, but a deleted/expired row exists
&lt;span class=&quot;code-comment&quot;&gt;// 2nd searchKey
&lt;/span&gt;set searchKey to 030/colfamily1:/9223372036854775807
foundCandidate &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; searchKey 030/colfamily1:/9223372036854775807
readKey 020/colfamily1:/1217149629664 readVal 48 42 41 53 45 3a 3a 44 45 4c 45 54 45 56 41 4c
close match, but deleted
readKey 030/colfamily1:/1217149629665 readVal 48 42 41 53 45 3a 3a 44 45 4c 45 54 45 56 41 4c
exact match, but deleted
no candidates, but a deleted/expired row exists
&lt;span class=&quot;code-comment&quot;&gt;// 3rd searchKey (same as 2nd!!)
&lt;/span&gt;set searchKey to 030/colfamily1:/9223372036854775807
foundCandidate &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; searchKey 030/colfamily1:/9223372036854775807
readKey 020/colfamily1:/1217149629664 readVal 48 42 41 53 45 3a 3a 44 45 4c 45 54 45 56 41 4c
close match, but deleted
readKey 030/colfamily1:/1217149629665 readVal 48 42 41 53 45 3a 3a 44 45 4c 45 54 45 56 41 4c
exact match, but deleted
no candidates, but a deleted/expired row exists
set searchKey to 030/colfamily1:/9223372036854775807
foundCandidate &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; searchKey 030/colfamily1:/9223372036854775807
readKey 020/colfamily1:/1217149629664 readVal 48 42 41 53 45 3a 3a 44 45 4c 45 54 45 56 41 4c
close match, but deleted
readKey 030/colfamily1:/1217149629665 readVal 48 42 41 53 45 3a 3a 44 45 4c 45 54 45 56 41 4c
exact match, but deleted
&lt;span class=&quot;code-comment&quot;&gt;// I &lt;span class=&quot;code-keyword&quot;&gt;break&lt;/span&gt; out here so that unit test can really output debug messages
&lt;/span&gt;same searchKey!
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12617306" author="stack" created="Sun, 27 Jul 2008 16:27:17 +0000"  >&lt;p&gt;Thanks Rong-en.  I&apos;m working on a fix based on Todd Lipcon&apos;s first suggestion; seems least disruptive (though may be issue if multiple deletes in a row &amp;#8211; checking).&lt;/p&gt;</comment>
                            <comment id="12617350" author="stack" created="Mon, 28 Jul 2008 00:28:18 +0000"  >&lt;p&gt;Patch passes all unit tests but still not right.  If I make optional flushes happen every 3 minutes, then on cluster run big loading, things go awry soon after optional flush runs.  Need to spend more time on this.&lt;/p&gt;</comment>
                            <comment id="12617731" author="stack" created="Tue, 29 Jul 2008 07:57:33 +0000"  >&lt;p&gt;Still not right.  Throwing WRE.&lt;/p&gt;</comment>
                            <comment id="12617913" author="stack" created="Tue, 29 Jul 2008 19:20:19 +0000"  >&lt;p&gt;v2 seems to work in my testing.  Here is v3.  Some cleanup.  Running more tests.  Comment on patch to follow....&lt;/p&gt;</comment>
                            <comment id="12618063" author="stack" created="Wed, 30 Jul 2008 05:03:05 +0000"  >&lt;p&gt;Address corner case.  Ensure the first candidate key is not before the first key in a mapfile if first key in mapfile is of same row as candidate.&lt;/p&gt;</comment>
                            <comment id="12618073" author="stack" created="Wed, 30 Jul 2008 06:17:22 +0000"  >&lt;p&gt;Fix error found by Rong-en review.&lt;/p&gt;</comment>
                            <comment id="12618075" author="stack" created="Wed, 30 Jul 2008 06:25:05 +0000"  >&lt;p&gt;Update v5 so applies to trunk.&lt;/p&gt;</comment>
                            <comment id="12618423" author="rafan" created="Wed, 30 Jul 2008 16:26:32 +0000"  >&lt;p&gt;For the record, with v6 applied, I got table not found exception within&lt;br/&gt;
6 mins which suggests the error is in memcache.&lt;/p&gt;</comment>
                            <comment id="12618609" author="stack" created="Thu, 31 Jul 2008 06:17:47 +0000"  >&lt;p&gt;Adds fix for the WrongRegionException I&apos;d been seeing.  Rong-en, don&apos;t know if it fixes the TableNotFound that you were seeing.&lt;/p&gt;</comment>
                            <comment id="12618784" author="stack" created="Thu, 31 Jul 2008 18:02:27 +0000"  >&lt;p&gt;Comment on IRC from Rong-en:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[08:10]	&amp;lt;rafan&amp;gt;	st^ack: my job looks fine with v7 after 6 hours of running
[08:12]	&amp;lt;rafan&amp;gt;	st^ack: but it won&apos;t be finished until 1.5 days later so.. let&apos;s what happens
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12618816" author="stack" created="Thu, 31 Jul 2008 19:12:03 +0000"  >&lt;p&gt;Latest version of patch.  v8/v9 adds fix for case where we found candidate row-before out in the mapfiles but its been deleted up in the memcache; we weren&apos;t moving past the delete.&lt;/p&gt;

&lt;p&gt;There is still one more issue outstanding; getting NULL HRegionInfo up on test cluster about 70% into loading job with 8 clients.&lt;/p&gt;

&lt;p&gt;Rong-en, can we change your loading job into an MR upload once this bug is fixed so it completes faster?&lt;/p&gt;</comment>
                            <comment id="12618866" author="jimk" created="Thu, 31 Jul 2008 21:36:31 +0000"  >&lt;p&gt;Reviewed patch V9. Makes my head hurt as the code becomes even more complicated. However the patch  looks as if it covers the corner cases. A lot of the corner cases are exposed by this patch which is good. Certainly better than before. My only fear is that we still might have missed some, but in view of the complexity of this, I can&apos;t imagine what is being overlooked. Some good additions to test suite. &lt;/p&gt;

&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="12618940" author="stack" created="Fri, 1 Aug 2008 06:30:09 +0000"  >&lt;p&gt;Fix silly mistake in memcache where tailmap would be empty because of test comparing rows; was using the search_key.getRow instead of passed in row.  This is error I introduced.&lt;/p&gt;</comment>
                            <comment id="12618941" author="stack" created="Fri, 1 Aug 2008 06:40:44 +0000"  >&lt;p&gt;Committed.&lt;/p&gt;</comment>
                            <comment id="12619197" author="rafan" created="Sat, 2 Aug 2008 05:58:45 +0000"  >&lt;p&gt;Thanks for the fix! With r681612 (v17 fix in place), I can&lt;br/&gt;
finish my load. But it&apos;s slower due to &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-790&quot; title=&quot;During import, single region blocks requests for &amp;gt;10 minutes, thread dumps, throws out pending requests, and continues&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-790&quot;&gt;&lt;del&gt;HBASE-790&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12386971" name="751-test.diff" size="4334" author="rafan" created="Sun, 27 Jul 2008 09:15:56 +0000"/>
                            <attachment id="12387327" name="751-v17.patch" size="46836" author="stack" created="Fri, 1 Aug 2008 06:30:09 +0000"/>
                            <attachment id="12387086" name="751-v2.patch" size="54674" author="stack" created="Tue, 29 Jul 2008 07:57:33 +0000"/>
                            <attachment id="12387124" name="751-v3.patch" size="36007" author="stack" created="Tue, 29 Jul 2008 19:20:19 +0000"/>
                            <attachment id="12387162" name="751-v4.txt" size="37449" author="stack" created="Wed, 30 Jul 2008 05:03:05 +0000"/>
                            <attachment id="12387165" name="751-v5.txt" size="39413" author="stack" created="Wed, 30 Jul 2008 06:17:22 +0000"/>
                            <attachment id="12387166" name="751-v6.txt" size="55662" author="stack" created="Wed, 30 Jul 2008 06:25:05 +0000"/>
                            <attachment id="12387258" name="751-v7.patch" size="59575" author="stack" created="Thu, 31 Jul 2008 06:17:47 +0000"/>
                            <attachment id="12387306" name="751-v9.patch" size="42858" author="stack" created="Thu, 31 Jul 2008 19:12:03 +0000"/>
                            <attachment id="12387000" name="751.patch" size="41812" author="stack" created="Mon, 28 Jul 2008 00:28:18 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>10.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 23 Jul 2008 13:59:28 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>25376</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 18 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0h987:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>98757</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>