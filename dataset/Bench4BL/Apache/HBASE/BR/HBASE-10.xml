<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 02 20:18:55 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-10/HBASE-10.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-10] HRegionServer hangs upon exit due to DFSClient Exception</title>
                <link>https://issues.apache.org/jira/browse/HBASE-10</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Several HRegionServers hang around indefinitely well after the HMaster has exited.  This was triggered executing $HBASE_HOME/bin/stop-hbase.sh.  The HMaster exists fine, but here is what happens on one of the HRegionServers:&lt;/p&gt;

&lt;p&gt;2008-01-02 18:54:01,907 INFO org.apache.hadoop.hbase.HRegionServer: Got regionserver stop message&lt;br/&gt;
2008-01-02 18:54:01,907 INFO org.apache.hadoop.hbase.Leases: regionserver/0.0.0.0:60020 closing leases&lt;br/&gt;
2008-01-02 18:54:01,907 INFO org.apache.hadoop.hbase.Leases$LeaseMonitor: regionserver/0.0.0.0:60020.leaseChecker exiting&lt;br/&gt;
2008-01-02 18:54:01,908 INFO org.apache.hadoop.hbase.Leases: regionserver/0.0.0.0:60020 closed leases&lt;br/&gt;
2008-01-02 18:54:01,908 INFO org.apache.hadoop.ipc.Server: Stopping server on 60020&lt;br/&gt;
2008-01-02 18:54:01,908 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 60020: exiting&lt;br/&gt;
2008-01-02 18:54:01,908 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 60020: exiting&lt;br/&gt;
2008-01-02 18:54:01,908 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 60020: exiting&lt;br/&gt;
2008-01-02 18:54:01,908 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 60020: exiting&lt;br/&gt;
2008-01-02 18:54:01,908 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 60020: exiting&lt;br/&gt;
2008-01-02 18:54:01,908 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 60020: exiting&lt;br/&gt;
2008-01-02 18:54:01,908 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 60020: exiting&lt;br/&gt;
2008-01-02 18:54:01,908 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 60020: exiting&lt;br/&gt;
2008-01-02 18:54:01,908 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 60020: exiting&lt;br/&gt;
2008-01-02 18:54:01,909 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 60020&lt;br/&gt;
2008-01-02 18:54:01,908 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 60020: exiting&lt;br/&gt;
2008-01-02 18:54:01,909 INFO org.apache.hadoop.hbase.HRegionServer: Stopping infoServer&lt;br/&gt;
2008-01-02 18:54:01,909 DEBUG org.mortbay.util.Container: Stopping org.mortbay.jetty.Server@62c09554&lt;br/&gt;
2008-01-02 18:54:01,909 DEBUG org.mortbay.util.ThreadedServer: closing ServerSocket&lt;span class=&quot;error&quot;&gt;&amp;#91;addr=0.0.0.0/0.0.0.0,port=0,localport=60030&amp;#93;&lt;/span&gt;&lt;br/&gt;
2008-01-02 18:54:01,909 DEBUG org.mortbay.util.ThreadedServer: IGNORED&lt;br/&gt;
java.net.SocketException: Socket closed&lt;br/&gt;
        at java.net.PlainSocketImpl.socketAccept(Native Method)&lt;br/&gt;
        at java.net.PlainSocketImpl.accept(PlainSocketImpl.java:384)&lt;br/&gt;
        at java.net.ServerSocket.implAccept(ServerSocket.java:453)&lt;br/&gt;
        at java.net.ServerSocket.accept(ServerSocket.java:421)&lt;br/&gt;
        at org.mortbay.util.ThreadedServer.acceptSocket(ThreadedServer.java:432)&lt;br/&gt;
        at org.mortbay.util.ThreadedServer$Acceptor.run(ThreadedServer.java:631)&lt;br/&gt;
2008-01-02 18:54:01,910 INFO org.mortbay.util.ThreadedServer: Stopping Acceptor ServerSocket&lt;span class=&quot;error&quot;&gt;&amp;#91;addr=0.0.0.0/0.0.0.0,port=0,localport=60030&amp;#93;&lt;/span&gt;&lt;br/&gt;
2008-01-02 18:54:01,910 DEBUG org.mortbay.util.ThreadedServer: Self connect to close listener /127.0.0.1:60030&lt;br/&gt;
2008-01-02 18:54:01,911 DEBUG org.mortbay.util.ThreadedServer: problem stopping acceptor /127.0.0.1:&lt;br/&gt;
2008-01-02 18:54:01,911 DEBUG org.mortbay.util.ThreadedServer: problem stopping acceptor /127.0.0.1:&lt;br/&gt;
java.net.ConnectException: Connection refused&lt;br/&gt;
        at java.net.PlainSocketImpl.socketConnect(Native Method)&lt;br/&gt;
        at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:333)&lt;br/&gt;
        at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:195)&lt;br/&gt;
        at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:182)&lt;br/&gt;
        at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)&lt;br/&gt;
        at java.net.Socket.connect(Socket.java:519)&lt;br/&gt;
        at java.net.Socket.connect(Socket.java:469)&lt;br/&gt;
        at java.net.Socket.&amp;lt;init&amp;gt;(Socket.java:366)&lt;br/&gt;
        at java.net.Socket.&amp;lt;init&amp;gt;(Socket.java:209)&lt;br/&gt;
        at org.mortbay.util.ThreadedServer$Acceptor.forceStop(ThreadedServer.java:682)&lt;br/&gt;
        at org.mortbay.util.ThreadedServer.stop(ThreadedServer.java:557)&lt;br/&gt;
        at org.mortbay.http.SocketListener.stop(SocketListener.java:211)&lt;br/&gt;
        at org.mortbay.http.HttpServer.doStop(HttpServer.java:781)&lt;br/&gt;
        at org.mortbay.util.Container.stop(Container.java:154)&lt;br/&gt;
        at org.apache.hadoop.hbase.util.InfoServer.stop(InfoServer.java:237)&lt;br/&gt;
        at org.apache.hadoop.hbase.HRegionServer.run(HRegionServer.java:835)&lt;br/&gt;
        at java.lang.Thread.run(Thread.java:619)&lt;br/&gt;
2008-01-02 18:54:01,911 INFO org.mortbay.http.SocketListener: Stopped SocketListener on 0.0.0.0:60030&lt;br/&gt;
2008-01-02 18:54:01,912 DEBUG org.mortbay.util.Container: Stopping HttpContext&lt;span class=&quot;error&quot;&gt;&amp;#91;/static,/static&amp;#93;&lt;/span&gt;&lt;br/&gt;
2008-01-02 18:54:01,912 DEBUG org.mortbay.http.handler.AbstractHttpHandler: Stopped org.mortbay.http.handler.ResourceHandler in HttpContext&lt;span class=&quot;error&quot;&gt;&amp;#91;/static,/static&amp;#93;&lt;/span&gt;&lt;br/&gt;
2008-01-02 18:54:02,039 INFO org.mortbay.util.Container: Stopped HttpContext&lt;span class=&quot;error&quot;&gt;&amp;#91;/static,/static&amp;#93;&lt;/span&gt;&lt;br/&gt;
2008-01-02 18:54:02,039 DEBUG org.mortbay.util.Container: Stopping HttpContext&lt;span class=&quot;error&quot;&gt;&amp;#91;/logs,/logs&amp;#93;&lt;/span&gt;&lt;br/&gt;
2008-01-02 18:54:02,039 DEBUG org.mortbay.http.handler.AbstractHttpHandler: Stopped org.mortbay.http.handler.ResourceHandler in HttpContext&lt;span class=&quot;error&quot;&gt;&amp;#91;/logs,/logs&amp;#93;&lt;/span&gt;&lt;br/&gt;
2008-01-02 18:54:02,154 INFO org.mortbay.util.Container: Stopped HttpContext&lt;span class=&quot;error&quot;&gt;&amp;#91;/logs,/logs&amp;#93;&lt;/span&gt;&lt;br/&gt;
2008-01-02 18:54:02,154 DEBUG org.mortbay.util.Container: Stopping WebApplicationContext&lt;span class=&quot;error&quot;&gt;&amp;#91;/,/&amp;#93;&lt;/span&gt;&lt;br/&gt;
2008-01-02 18:54:02,154 DEBUG org.mortbay.util.Container: Stopping org.mortbay.jetty.servlet.WebApplicationHandler@7ec5495e&lt;br/&gt;
2008-01-02 18:54:02,155 INFO org.mortbay.util.Container: Stopped org.mortbay.jetty.servlet.WebApplicationHandler@7ec5495e&lt;br/&gt;
2008-01-02 18:54:02,277 DEBUG org.mortbay.jetty.servlet.AbstractSessionManager: Session scavenger exited&lt;br/&gt;
2008-01-02 18:54:02,278 DEBUG org.mortbay.util.Container: remove component: org.mortbay.jetty.servlet.WebApplicationHandler@7ec5495e&lt;br/&gt;
2008-01-02 18:54:02,278 INFO org.mortbay.util.Container: Stopped WebApplicationContext&lt;span class=&quot;error&quot;&gt;&amp;#91;/,/&amp;#93;&lt;/span&gt;&lt;br/&gt;
2008-01-02 18:54:02,278 INFO org.mortbay.util.Container: Stopped org.mortbay.jetty.Server@62c09554&lt;br/&gt;
2008-01-02 18:54:02,278 DEBUG org.apache.hadoop.hbase.HRegionServer: closing region spider_pages,10_131455761,1198140179439&lt;br/&gt;
2008-01-02 18:54:02,278 INFO org.apache.hadoop.hbase.HRegionServer: regionserver/0.0.0.0:60020.cacheFlusher exiting&lt;br/&gt;
2008-01-02 18:54:02,278 INFO org.apache.hadoop.hbase.HRegionServer: regionserver/0.0.0.0:60020.compactor exiting&lt;br/&gt;
2008-01-02 18:54:02,278 INFO org.apache.hadoop.hbase.HRegionServer: regionserver/0.0.0.0:60020.splitter exiting&lt;br/&gt;
2008-01-02 18:54:02,279 DEBUG org.apache.hadoop.hbase.HStore: closed spider_pages,10_131455761,1198140179439/search (1501227429/search)&lt;br/&gt;
2008-01-02 18:54:02,279 DEBUG org.apache.hadoop.hbase.HStore: closed spider_pages,10_131455761,1198140179439/profile (1501227429/profile)&lt;br/&gt;
2008-01-02 18:54:02,279 DEBUG org.apache.hadoop.hbase.HStore: closed spider_pages,10_131455761,1198140179439/meta (1501227429/meta)&lt;br/&gt;
2008-01-02 18:54:02,279 INFO org.apache.hadoop.hbase.HRegion: closed spider_pages,10_131455761,1198140179439&lt;br/&gt;
2008-01-02 18:54:02,279 DEBUG org.apache.hadoop.hbase.HRegionServer: closing region spider_pages,10_486594261,1198319654267&lt;br/&gt;
2008-01-02 18:54:02,280 DEBUG org.apache.hadoop.hbase.HStore: closed spider_pages,10_486594261,1198319654267/search (364081590/search)&lt;br/&gt;
2008-01-02 18:54:02,280 DEBUG org.apache.hadoop.hbase.HStore: closed spider_pages,10_486594261,1198319654267/profile (364081590/profile)&lt;br/&gt;
2008-01-02 18:54:02,280 DEBUG org.apache.hadoop.hbase.HStore: closed spider_pages,10_486594261,1198319654267/meta (364081590/meta)&lt;br/&gt;
2008-01-02 18:54:02,280 INFO org.apache.hadoop.hbase.HRegion: closed spider_pages,10_486594261,1198319654267&lt;br/&gt;
...&lt;br/&gt;
... this closing of regions goes on for a while&lt;br/&gt;
...&lt;br/&gt;
... the following continues until a kill -9&lt;br/&gt;
...&lt;br/&gt;
2008-01-02 20:39:20,552 INFO org.apache.hadoop.fs.DFSClient: Could not obtain block blk_5124700261538503923 from any node:  java.io.IOException: No live nodes contain current block&lt;br/&gt;
2008-01-02 20:40:23,556 INFO org.apache.hadoop.fs.DFSClient: Could not obtain block blk_5124700261538503923 from any node:  java.io.IOException: No live nodes contain current block&lt;br/&gt;
2008-01-02 20:41:26,560 INFO org.apache.hadoop.fs.DFSClient: Could not obtain block blk_5124700261538503923 from any node:  java.io.IOException: No live nodes contain current block&lt;br/&gt;
2008-01-02 20:42:29,566 INFO org.apache.hadoop.fs.DFSClient: Could not obtain block blk_5124700261538503923 from any node:  java.io.IOException: No live nodes contain current block&lt;br/&gt;
2008-01-02 20:43:32,571 INFO org.apache.hadoop.fs.DFSClient: Could not obtain block blk_5124700261538503923 from any node:  java.io.IOException: No live nodes contain current block&lt;br/&gt;
...&lt;/p&gt;</description>
                <environment>&lt;p&gt;CentOS 5&lt;/p&gt;</environment>
        <key id="12385606">HBASE-10</key>
            <summary>HRegionServer hangs upon exit due to DFSClient Exception</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jimk">Jim Kellerman</assignee>
                                    <reporter username="chriskline">Chris Kline</reporter>
                        <labels>
                    </labels>
                <created>Fri, 4 Jan 2008 19:24:15 +0000</created>
                <updated>Fri, 22 Aug 2008 21:13:01 +0000</updated>
                            <resolved>Fri, 18 Apr 2008 05:31:42 +0000</resolved>
                                                    <fixVersion>0.2.0</fixVersion>
                                    <component>regionserver</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12559217" author="jimk" created="Tue, 15 Jan 2008 20:35:48 +0000"  >&lt;p&gt;Is this still an issue? Has it occurred since reported?&lt;/p&gt;</comment>
                            <comment id="12559221" author="stack" created="Tue, 15 Jan 2008 20:43:10 +0000"  >&lt;p&gt;What would have fixed it?  Looks like we get stuck trying to close out hdfs connections.  We&apos;ve seen where when a prob. in hdfs, things like close don&apos;t return.  Should we put the clean up of hdfs resources into a timer so we&apos;ll return eventually?&lt;/p&gt;</comment>
                            <comment id="12581325" author="bryanduxbury" created="Sun, 23 Mar 2008 03:18:17 +0000"  >&lt;p&gt;Is this just a matter of catching and ignoring (or at least logging) DFS errors when we&apos;re shutting down? I realize it might have to be on a case-by-case basis, but it seems to make sense. The last thing we want is a braindead region server hanging around messing things up.&lt;/p&gt;</comment>
                            <comment id="12589286" author="jimk" created="Tue, 15 Apr 2008 23:37:10 +0000"  >&lt;p&gt;&amp;gt; stack - 15/Jan/08 12:43 PM&lt;br/&gt;
&amp;gt; What would have fixed it?&lt;/p&gt;

&lt;p&gt;Possibly a new release of hadoop. I don&apos;t recall which version of hadoop was out there when this was reported, but I recall that 0.16.1 had a regression in DFSClient&lt;/p&gt;

&lt;p&gt;&amp;gt; We&apos;ve seen where when a prob. in hdfs, things like close don&apos;t return. Should we put the clean up&lt;br/&gt;
&amp;gt; of hdfs resources into a timer so we&apos;ll return eventually?&lt;/p&gt;

&lt;p&gt;Yes, probably. For 0.1.x, or just 0.2?&lt;/p&gt;
</comment>
                            <comment id="12589634" author="stack" created="Wed, 16 Apr 2008 16:35:03 +0000"  >&lt;p&gt;I&apos;m fine with hadoop has moved on from when this issue was reported.&lt;/p&gt;

&lt;p&gt;I think a timer on HDFS calls on our way out should be a 0.2 issue, not 0.1.&lt;/p&gt;</comment>
                            <comment id="12589725" author="jimk" created="Wed, 16 Apr 2008 20:34:47 +0000"  >&lt;p&gt;It would be &lt;b&gt;nice&lt;/b&gt; if when bugs are entered, the environment field was filled in with at least the hadoop version number.&lt;/p&gt;

&lt;p&gt;For this issue, the hadoop version was 0.16.1 or earlier. This can be determined from the message:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2008-01-02 20:39:20,552 INFO org.apache.hadoop.fs.DFSClient: Could not obtain block blk_5124700261538503923 from any node: java.io.IOException: No live nodes contain current block
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Note how DFSClient misidentifies itself as &apos;org.apache.hadoop.fs.DFSClient&apos;. DFSClient has always lived in org.apache.hadoop.dfs at least for any release since Q4 2007. The reason it misidentifies itself is due to the way it gets its logger in 0.16.1 and earlier:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Log LOG = LogFactory.getLog(&lt;span class=&quot;code-quote&quot;&gt;&quot;org.apache.hadoop.fs.DFSClient&quot;&lt;/span&gt;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In 0.16.2, this was changed to:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Log LOG = LogFactory.getLog(DFSClient.class);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The message itself originates from DFSClient$DFSInputStream.chooseDataNode. This method will try 3 times to get the block. It is called from both DFSClient$DFSInputStream.blockSeekTo and DFSClient$DFSInputStream.fetchBlockByteRange. &lt;/p&gt;

&lt;p&gt;blockSeekTo does not do any retries, however it is called by DFSClient$DFSInputStream.read which will make a total of 3 attempts at calling blockSeekTo, so a single call to read will generate 9 messages if the block cannot be found.&lt;/p&gt;

&lt;p&gt;fetchBlockByteRange will retry calling chooseDataNode for each known block location. If the replication factor is 3, then it would normally call chooseDataNode 3 times. But suppose the namenode was trying to replicate the block. This could result in the number of possible block locations being greater than three. So at a minimum, chooseDataNode will generate 9 messages when called from fetchBlockByteRange, and will add another 3 messages for each additional entry in the block location list.&lt;/p&gt;

&lt;p&gt;If multiple threads were doing reads, the number of messages generated could be seemingly endless.&lt;/p&gt;</comment>
                            <comment id="12589758" author="jimk" created="Wed, 16 Apr 2008 22:44:35 +0000"  >&lt;p&gt;Proposal:&lt;/p&gt;

&lt;p&gt;The only time any of the flusher, compactor or log roller threads needs to be interrupted is if it is dormant waiting for something to do. Interrupting one of these threads at any other time will probably produce undesirable results like the DFSClient issue. If the thread is not dormant, it will finish what it is doing, go to the top of the loop and exit because the stop flag is set.&lt;/p&gt;

&lt;p&gt;So instead of using synchronized, use a ReentrantLock. The interruptor will use tryLock and if it fails, it knows the thread is working and does not need to be interrupted because it is doing something and when it finishes it checks the stop flag and exits.&lt;/p&gt;

&lt;p&gt;If the tryLock succeeds, it interrupts the thread to wake it from its sleep.&lt;/p&gt;

&lt;p&gt;Nothing else needs to be done because the join at the end of HRegionServer.run will take care of coordinating the region server exit.&lt;/p&gt;</comment>
                            <comment id="12589788" author="jimk" created="Thu, 17 Apr 2008 00:38:34 +0000"  >&lt;p&gt;This issue may be related to &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-500&quot; title=&quot;Regionserver stuck on exit&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-500&quot;&gt;&lt;del&gt;HBASE-500&lt;/del&gt;&lt;/a&gt;, although where it happens all the region server threads have already exited. There is no error from the compactor, but if it was interrupted while in the DFSClient, it could possibly have exited even though the DFSClient was hosed.&lt;/p&gt;</comment>
                            <comment id="12590152" author="jimk" created="Thu, 17 Apr 2008 19:05:22 +0000"  >&lt;p&gt;Doesn&apos;t interrupt worker threads if not necessary.&lt;/p&gt;</comment>
                            <comment id="12590153" author="jimk" created="Thu, 17 Apr 2008 19:06:07 +0000"  >&lt;p&gt;Passes local tests - Please review.&lt;/p&gt;</comment>
                            <comment id="12590240" author="bryanduxbury" created="Thu, 17 Apr 2008 23:32:18 +0000"  >&lt;p&gt;We could use a comment in Flusher explaining why we need the removeFromQueue option in flushRegion. Otherwise, tests pass, +1.&lt;/p&gt;</comment>
                            <comment id="12590294" author="jimk" created="Fri, 18 Apr 2008 05:31:42 +0000"  >&lt;p&gt;Addressed comments. Committed.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12387515">HBASE-46</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12380431" name="patch.txt" size="14923" author="jimk" created="Thu, 17 Apr 2008 19:05:22 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 15 Jan 2008 20:35:48 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>24848</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 34 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0h3ef:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>97813</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>