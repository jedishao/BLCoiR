<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 02 19:55:05 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-103/HBASE-103.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-103] [hbase] TestDFSAbort failed in nightly #242</title>
                <link>https://issues.apache.org/jira/browse/HBASE-103</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;TestDFSAbort and TestBloomFilters failed in last nights nightly build (#242).  This issue is about trying to figure whats up w/ TDFSA.&lt;/p&gt;

&lt;p&gt;Studying console logs, HRegionServer stopped logging any activity and HMaster for its part did not expire the HRegionServer lease.  On top of it all, continued tests of the state of HDFS &amp;#8211; the test is meant to sure Hbase shutdown when HDFS is pulled from under it &amp;#8211; seems to have continued reporting itself healthy though it&apos;d be closed.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12378697">HBASE-103</key>
            <summary>[hbase] TestDFSAbort failed in nightly #242</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="stack">stack</reporter>
                        <labels>
                    </labels>
                <created>Wed, 19 Sep 2007 21:17:27 +0000</created>
                <updated>Mon, 4 Feb 2008 18:40:40 +0000</updated>
                            <resolved>Thu, 20 Sep 2007 07:39:15 +0000</resolved>
                                                                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                <comments>
                            <comment id="12528912" author="stack" created="Wed, 19 Sep 2007 21:35:32 +0000"  >&lt;p&gt;Add more info to logging on state of HDFS.&lt;/p&gt;</comment>
                            <comment id="12528913" author="stack" created="Wed, 19 Sep 2007 21:36:14 +0000"  >&lt;p&gt;Patch adds more logging to help w/ diagnosis next time TestDFSAbort fails.&lt;/p&gt;

&lt;p&gt;Builds locally.  Trying against hudson.&lt;/p&gt;</comment>
                            <comment id="12528915" author="stack" created="Wed, 19 Sep 2007 21:40:56 +0000"  >&lt;p&gt;Patch #785 build failed in same manner as the nightly #242&lt;/p&gt;</comment>
                            <comment id="12528928" author="jimk" created="Wed, 19 Sep 2007 22:11:01 +0000"  >&lt;p&gt;TestDFSAbort failed in the same manner in build 794. &lt;/p&gt;</comment>
                            <comment id="12528952" author="stack" created="Wed, 19 Sep 2007 23:38:48 +0000"  >&lt;p&gt;There is a thread dump in &lt;a href=&quot;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/794/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/794/console&lt;/a&gt;   Staring at the snapshot, we are dead-locked waiting on an rpc Client flush to complete or timeout.  A snapshot &amp;gt; 5 seconds later, the ipc.client.timeout in this test would have been sweet so we could tell if we were hung in this state.&lt;/p&gt;</comment>
                            <comment id="12528953" author="hadoopqa" created="Wed, 19 Sep 2007 23:41:30 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
&lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12366233/testdfsabort.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12366233/testdfsabort.patch&lt;/a&gt;&lt;br/&gt;
against trunk revision r577456.&lt;/p&gt;

&lt;p&gt;    @author +1.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    javadoc +1.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    javac +1.  The applied patch does not generate any new compiler warnings.&lt;/p&gt;

&lt;p&gt;    findbugs +1.  The patch does not introduce any new Findbugs warnings.&lt;/p&gt;

&lt;p&gt;    core tests -1.  The patch failed core unit tests.&lt;/p&gt;

&lt;p&gt;    contrib tests -1.  The patch failed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/795/testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/795/testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/795/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/795/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle results: &lt;a href=&quot;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/795/artifact/trunk/build/test/checkstyle-errors.html&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/795/artifact/trunk/build/test/checkstyle-errors.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/795/console&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/795/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="12528957" author="stack" created="Thu, 20 Sep 2007 00:21:39 +0000"  >&lt;p&gt;Patch failed for unrelated reasons: two dfs test failures and a failure in hbase TestRegionServerAbort&lt;/p&gt;</comment>
                            <comment id="12529012" author="jimk" created="Thu, 20 Sep 2007 07:39:15 +0000"  >&lt;p&gt;Fix was incorporated in patch for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-186&quot; title=&quot;[hbase] tests fail sporadically because set up and tear down is inconsistent&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-186&quot;&gt;&lt;del&gt;HADOOP-1923&lt;/del&gt;&lt;/a&gt;. Tests passed. Committed.&lt;/p&gt;</comment>
                            <comment id="12529079" author="hudson" created="Thu, 20 Sep 2007 11:52:25 +0000"  >&lt;p&gt;Integrated in Hadoop-Nightly #243 (See &lt;a href=&quot;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Nightly/243/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Nightly/243/&lt;/a&gt;)&lt;/p&gt;</comment>
                            <comment id="12529188" author="stack" created="Thu, 20 Sep 2007 18:26:16 +0000"  >&lt;p&gt;Here&apos;s notes on examination of a couple of stack traces produced last night by Jim in patch build #798 before application of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-186&quot; title=&quot;[hbase] tests fail sporadically because set up and tear down is inconsistent&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-186&quot;&gt;&lt;del&gt;HADOOP-1923&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In short, we are hung in a flush/write down in the rpc Client call inside of a synchronize on the output stream.  Its never going to return. There is no server side to this blocked write in the stack trace.  The dfs has been shut down.   When the server side went away, we should have gotten a connection aborted exception.  SInce there is no timeout on an established socket write, this flush/write is just going to sit there; its never going to complete and because its inside a synchronize block, all regionserver threads are blocked from continuing/exiting.&lt;/p&gt;

&lt;p&gt;Here is the blocked thread:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    [junit] &lt;span class=&quot;code-quote&quot;&gt;&quot;regionserver/0.0.0.0:62532.splitOrCompactChecker&quot;&lt;/span&gt; daemon prio=10 tid=0x089bc6b8 nid=0x67 runnable [0xe28b3000..0xe28b3db8]
    [junit] 	at java.net.SocketOutputStream.socketWrite0(Native Method)
    [junit] 	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:92)
    [junit] 	at java.net.SocketOutputStream.write(SocketOutputStream.java:136)
    [junit] 	at org.apache.hadoop.ipc.Client$Connection$2.write(Client.java:190)
    [junit] 	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
    [junit] 	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
    [junit] 	- locked &amp;lt;0xe7f640a8&amp;gt; (a java.io.BufferedOutputStream)
    [junit] 	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
    [junit] 	at org.apache.hadoop.ipc.Client$Connection.sendParam(Client.java:325)
    [junit] 	- locked &amp;lt;0xe7f63f78&amp;gt; (a java.io.DataOutputStream)
    [junit] 	at org.apache.hadoop.ipc.Client.call(Client.java:462)
    [junit] 	- locked &amp;lt;0xf66a4488&amp;gt; (a org.apache.hadoop.ipc.Client$Call)
    [junit] 	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:165)
    [junit] 	at org.apache.hadoop.dfs.$Proxy0.getFileInfo(Unknown Source)
    [junit] 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    [junit] 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
    [junit] 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    [junit] 	at java.lang.reflect.Method.invoke(Method.java:585)
    [junit] 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
    [junit] 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
    [junit] 	at org.apache.hadoop.dfs.$Proxy0.getFileInfo(Unknown Source)
    [junit] 	at org.apache.hadoop.dfs.DFSClient.getFileInfo(DFSClient.java:432)
    [junit] 	at org.apache.hadoop.dfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:337)
    [junit] 	at org.apache.hadoop.hbase.HStoreFile.length(HStoreFile.java:971)
    [junit] 	at org.apache.hadoop.hbase.HStore.size(HStore.java:1322)
    [junit] 	at org.apache.hadoop.hbase.HRegion.largestHStore(HRegion.java:624)
    [junit] 	at org.apache.hadoop.hbase.HRegion.needsSplit(HRegion.java:584)
    [junit] 	at org.apache.hadoop.hbase.HRegionServer$SplitOrCompactChecker.checkForSplitsOrCompactions(HRegionServer.java:204)
    [junit] 	at org.apache.hadoop.hbase.HRegionServer$SplitOrCompactChecker.chore(HRegionServer.java:189)
    [junit] 	- locked &amp;lt;0xe7f74028&amp;gt; (a java.lang.&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;)
    [junit] 	at org.apache.hadoop.hbase.Chore.run(Chore.java:59)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The main changes in the applied patch for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-186&quot; title=&quot;[hbase] tests fail sporadically because set up and tear down is inconsistent&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-186&quot;&gt;&lt;del&gt;HADOOP-1923&lt;/del&gt;&lt;/a&gt; are a change the health of the hdfs is checked &amp;#8211; an exists check on the hbase root dir rather than a request for datanode info &amp;#8211; and removal of a synchronize around the call to the check on filesystem health.  I&apos;m unable to explain why these changes would make the hang go away.&lt;/p&gt;

&lt;p&gt;The filesystem health check is just a look up on namenode in-memory datastructures whether its a get of state on datanodes or a check a directory exists.&lt;/p&gt;

&lt;p&gt;The removal of the synchronization on the filesystem check should just make it so instead of threads parking on the entrance to FsUtils.isFileSystemAvailable, their park spot moves down the stack to org.apache.hadoop.ipc.Client.call waiting for sendParams lock of the output stream to free up (Other threads in the stack trace are already parked in this spot).&lt;/p&gt;</comment>
                            <comment id="12529191" author="stack" created="Thu, 20 Sep 2007 18:32:32 +0000"  >&lt;p&gt;Here is relevant except from the patch build #798 console log.&lt;/p&gt;</comment>
                            <comment id="12532549" author="stack" created="Thu, 4 Oct 2007 23:51:55 +0000"  >&lt;p&gt;I posted below to list. &lt;/p&gt;

&lt;p&gt;On Hudson, we&apos;ve been seeing tests sporadically hang on an ipc Client flush of params.  I&apos;m writing the list for suggestions or opinions on what folks think might be happening or ideas on what to try next.  See below for the latest example for a thread dump from a recent patch build.&lt;/p&gt;

&lt;p&gt;The usual scenario is that we are trying to simulate failed servers in a mini-cluster.  All servers &amp;#8211; hbase + dfs servers &amp;#8211; are up and running inside the same JVM.  The remote ipc Server will of-a-sudden have its stop method run to simulate a server crash.  The Client, unawares, tries to go about its usual business.&lt;/p&gt;

&lt;p&gt;   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; &quot;HMaster.metaScanner&quot; daemon prio=10 tid=0x091ecde0 nid=0x4a runnable &lt;span class=&quot;error&quot;&gt;&amp;#91;0xe2af9000..0xe2af9b38&amp;#93;&lt;/span&gt;&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at java.net.SocketOutputStream.socketWrite0(Native Method)&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:92)&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at java.net.SocketOutputStream.write(SocketOutputStream.java:136)&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.ipc.Client$Connection$2.write(Client.java:190)&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     - locked &amp;lt;0xf7bb40e0&amp;gt; (a java.io.BufferedOutputStream)&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at java.io.DataOutputStream.flush(DataOutputStream.java:106)&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.ipc.Client$Connection.sendParam(Client.java:325)&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     - locked &amp;lt;0xf7bb3f68&amp;gt; (a java.io.DataOutputStream)&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.ipc.Client.call(Client.java:462)&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     - locked &amp;lt;0xf7bb3fa8&amp;gt; (a org.apache.hadoop.ipc.Client$Call)&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:165)&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at $Proxy8.openScanner(Unknown Source)&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hbase.HMaster$BaseScanner.scanRegion(HMaster.java:207)&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hbase.HMaster$MetaScanner.scanOneMetaRegion(HMaster.java:643)&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     - locked &amp;lt;0xf7b6b460&amp;gt; (a java.lang.Integer)&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hbase.HMaster$MetaScanner.maintenanceScan(HMaster.java:694)&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hbase.HMaster$BaseScanner.chore(HMaster.java:188)&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt;     at org.apache.hadoop.hbase.Chore.run(Chore.java:59)&lt;/p&gt;


&lt;p&gt;Other threads in the thread dump will be parked at the  DataOutputStream synchronize block.&lt;/p&gt;

&lt;p&gt;Please correct me if I am wrong, but it is my understanding that writes do not timeout nor is this type of I/O interruptable.  The connection is probably already established else it would have timed out trying to connect to the non-existent server and besides, the ipc Client pattern seems to be keeps up the connection multiplexing &apos;commands&apos; to the remote server...&lt;/p&gt;

&lt;p&gt;I&apos;m wondering why don&apos;t we get an exception on client side when the remote side of the socket goes away?&lt;/p&gt;

&lt;p&gt;Am unable to reproduce locally.&lt;/p&gt;

&lt;p&gt;Thanks for any input,&lt;br/&gt;
St.Ack &lt;/p&gt;


&lt;p&gt;Also, patch yesterday added thread dumping every 30 seconds during wait on terminate condition.  A patch build from last night had the same hang: &lt;a href=&quot;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/887/testReport/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/887/testReport/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;TestDFSAbort has just been removed.&lt;/p&gt;</comment>
                            <comment id="12532725" author="cutting" created="Fri, 5 Oct 2007 17:14:23 +0000"  >&lt;p&gt;I have seen such hangs before.  The socket has a timeout set, yet an operation on it never times out.  The only reliable way of handling such situations that I have found is to use the deprecated Thread.stop().  Perhaps it is a JVM bug, fixed in 1.6, or perhaps it is a Solaris bug...&lt;/p&gt;</comment>
                            <comment id="12532737" author="cutting" created="Fri, 5 Oct 2007 17:53:56 +0000"  >&lt;p&gt;It seems that setSoTimeout only affects reads, not writes.  So you&apos;re right, there is no way in Java to set a write timeout!&lt;/p&gt;

&lt;p&gt;One theory is that the server, while stopped, may not in fact be closing all its connections.  I couldn&apos;t see where that was done just now when I looked.  Handlers are interrupted, but they don&apos;t close their connection on interrupt.  The listener thread calls cleanupConnections(true), but only on OutOfMemoryException, not in a &apos;finally&apos; clause.  And, even then cleanupConnections(true) doesn&apos;t look like it closes connections that have been recently active.&lt;/p&gt;

&lt;p&gt;So please check the server&apos;s logs to see if for each &quot;Server connection from&quot; line there is a corresponding &quot;disconnecting client&quot; line.  If there&apos;s not, then this could be the problem.&lt;/p&gt;

&lt;p&gt;Some potentially relevant discussions:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4283017&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4283017&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;http://forum.java.sun.com/thread.jspa?threadID=5203832&amp;amp;tstart=75&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://forum.java.sun.com/thread.jspa?threadID=5203832&amp;amp;tstart=75&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;http://www-1.ibm.com/support/docview.wss?rs=180&amp;amp;uid=swg1PK37506&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://www-1.ibm.com/support/docview.wss?rs=180&amp;amp;uid=swg1PK37506&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;http://archives.java.sun.com/cgi-bin/wa?A2=ind0212&amp;amp;L=rmi-users&amp;amp;P=731&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://archives.java.sun.com/cgi-bin/wa?A2=ind0212&amp;amp;L=rmi-users&amp;amp;P=731&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Other possible things to try:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;call Socket#setKeepAlive() on IPC sockets&lt;/li&gt;
	&lt;li&gt;try calling Thread#interrrupt(), it may help...&lt;/li&gt;
	&lt;li&gt;adjust some of the TCP parameters on lucene.zones.apache.org&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12534439" author="stack" created="Fri, 12 Oct 2007 23:18:42 +0000"  >&lt;p&gt;Thanks for pointers, particularly the comment on how Server doesn&apos;t have a general cleanup of outstanding connections.  Unfortunately, hbase tests do not have ipc debug logging enabled so I can&apos;t do matching of &apos;server connection from&apos; and &apos;disconnecting client&apos; messages.  Let me enable logging from here on out, or maybe better, temporarily bring down a version of Server into hbase adding logging of outstanding connections to see what more I can learn about the Server endgame.&lt;/p&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12366233" name="testdfsabort.patch" size="15072" author="stack" created="Wed, 19 Sep 2007 21:35:32 +0000"/>
                            <attachment id="12366306" name="testdfsabort_patchbuild798.txt" size="270425" author="stack" created="Thu, 20 Sep 2007 18:32:32 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 19 Sep 2007 22:11:01 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>24887</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 8 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0h4c7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>97965</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>