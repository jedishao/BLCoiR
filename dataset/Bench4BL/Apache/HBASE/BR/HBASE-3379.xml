<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sat Dec 03 17:03:37 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-3379/HBASE-3379.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-3379] Log splitting slowed by repeated attempts at connecting to downed datanode</title>
                <link>https://issues.apache.org/jira/browse/HBASE-3379</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Testing if I kill RS and DN on a node, log splitting takes longer as we doggedly try connecting to the downed DN to get WAL blocks.  Here&apos;s the cycle I see:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2010-12-21 17:34:48,239 WARN org.apache.hadoop.hdfs.DFSClient: Error Recovery &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; block blk_900551257176291912_1203821 failed  because recovery from primary datanode 10.20.20.182:10010 failed 5 times.    Pipeline was 10.20.20.184:10010, 10.20.20.186:10010, 10.20.20.182:10010. Will retry...
2010-12-21 17:34:50,240 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.20.20.182:10020. Already tried 0 time(s).
2010-12-21 17:34:51,241 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.20.20.182:10020. Already tried 1 time(s).
2010-12-21 17:34:52,241 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.20.20.182:10020. Already tried 2 time(s).
2010-12-21 17:34:53,242 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.20.20.182:10020. Already tried 3 time(s).
2010-12-21 17:34:54,243 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.20.20.182:10020. Already tried 4 time(s).
2010-12-21 17:34:55,243 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.20.20.182:10020. Already tried 5 time(s).
2010-12-21 17:34:56,244 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.20.20.182:10020. Already tried 6 time(s).
2010-12-21 17:34:57,245 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.20.20.182:10020. Already tried 7 time(s).
2010-12-21 17:34:58,245 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.20.20.182:10020. Already tried 8 time(s).
2010-12-21 17:34:59,246 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.20.20.182:10020. Already tried 9 time(s).
2010-12-21 17:34:59,246 WARN org.apache.hadoop.hdfs.DFSClient: Failed recovery attempt #5 from primary datanode 10.20.20.182:10010
java.net.ConnectException: Call to /10.20.20.182:10020 failed on connection exception: java.net.ConnectException: Connection refused
    at org.apache.hadoop.ipc.Client.wrapException(Client.java:767)
    at org.apache.hadoop.ipc.Client.call(Client.java:743)
    at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
    at $Proxy8.getProtocolVersion(Unknown Source)
    at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
    at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:346)
    at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:383)
...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&quot;because recovery from primary datanode&quot; is done 5 times (hardcoded).  Within these retries we&apos;ll do&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.maxRetries = conf.getInt(&lt;span class=&quot;code-quote&quot;&gt;&quot;ipc.client.connect.max.retries&quot;&lt;/span&gt;, 10);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The hardcoding of 5 attempts we should get fixed and we should doc the ipc.client.connect.max.retries as important config.  We should recommend bringing it down from default.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12493774">HBASE-3379</key>
            <summary>Log splitting slowed by repeated attempts at connecting to downed datanode</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="stack">stack</assignee>
                                    <reporter username="stack">stack</reporter>
                        <labels>
                    </labels>
                <created>Tue, 21 Dec 2010 17:48:18 +0000</created>
                <updated>Fri, 20 Nov 2015 12:43:26 +0000</updated>
                            <resolved>Mon, 21 Mar 2011 21:01:23 +0000</resolved>
                                                    <fixVersion>0.92.0</fixVersion>
                                    <component>wal</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                <comments>
                            <comment id="12978160" author="hairong" created="Thu, 6 Jan 2011 06:22:55 +0000"  >&lt;p&gt;Stack, &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-3285&quot; title=&quot;Hlog recovery takes too much time&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-3285&quot;&gt;&lt;del&gt;HBASE-3285&lt;/del&gt;&lt;/a&gt; should be able to fix the problem by avoiding this code path. This is the solution that our fb internal trunk uses.&lt;/p&gt;</comment>
                            <comment id="12978434" author="stack" created="Thu, 6 Jan 2011 18:21:13 +0000"  >&lt;p&gt;@Hairong Is there a new API in branch-0.20-append that we should be calling?  Thanks.&lt;/p&gt;</comment>
                            <comment id="12978478" author="hairong" created="Thu, 6 Jan 2011 19:54:22 +0000"  >&lt;p&gt;HBase should call recoverLease instead of append. &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-1520&quot; title=&quot;HDFS 20 append: Lightweight NameNode operation to trigger lease recovery&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-1520&quot;&gt;&lt;del&gt;HDFS-1520&lt;/del&gt;&lt;/a&gt; introduced this new API and I recently work on a stronger semantics of recoverLease at &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-1554&quot; title=&quot;Append 0.20: New semantics for recoverLease&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-1554&quot;&gt;&lt;del&gt;HDFS-1554&lt;/del&gt;&lt;/a&gt;. This will make HLog to be closed more deterministic and faster.&lt;/p&gt;

&lt;p&gt;I will upload a patch in HBASE=3285 to make HBase to use the new API. Can I assume that HBase is bundled only with append 0.20?&lt;/p&gt;</comment>
                            <comment id="12978482" author="stack" created="Thu, 6 Jan 2011 19:59:13 +0000"  >&lt;blockquote&gt;&lt;p&gt;I will upload a patch in HBASE=3285 to make HBase to use the new API. Can I assume that HBase is bundled only with append 0.20?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;No.  We have to work w/ CDH too.  If you want, I can muck with it if you write outline of what to do.  We already have some reflection going on that tests for presence of methods.  I can do a bit more to find recoverLease.  Thanks  H.&lt;/p&gt;</comment>
                            <comment id="12978496" author="tlipcon" created="Thu, 6 Jan 2011 20:40:01 +0000"  >&lt;p&gt;We can probably pull that new HDFS patch into CDH3 also. I&quot;ll put it on our list to evaluate.&lt;/p&gt;</comment>
                            <comment id="12979014" author="hairong" created="Fri, 7 Jan 2011 23:01:16 +0000"  >&lt;p&gt;I uploaded a patch to &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-3285&quot; title=&quot;Hlog recovery takes too much time&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-3285&quot;&gt;&lt;del&gt;HBASE-3285&lt;/del&gt;&lt;/a&gt;. Will test it once &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-1554&quot; title=&quot;Append 0.20: New semantics for recoverLease&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-1554&quot;&gt;&lt;del&gt;HDFS-1554&lt;/del&gt;&lt;/a&gt; is committed.&lt;/p&gt;</comment>
                            <comment id="12998701" author="stack" created="Thu, 24 Feb 2011 05:54:32 +0000"  >&lt;p&gt;Making critical and bringing into 0.92.  Assigning myself.&lt;/p&gt;</comment>
                            <comment id="12998937" author="stack" created="Thu, 24 Feb 2011 17:05:02 +0000"  >&lt;p&gt;From a log last night:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
21:06 &amp;lt; jdcryans&amp;gt; jstack looks like
21:06 &amp;lt; jdcryans&amp;gt; Iat org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:2628)
21:06 &amp;lt; jdcryans&amp;gt; Iat org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.&amp;lt;init&amp;gt;(DFSClient.java:2829)
21:06 &amp;lt; jdcryans&amp;gt; Iat org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:528)
21:06 &amp;lt; jdcryans&amp;gt; Iat org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:186)
21:06 &amp;lt; jdcryans&amp;gt; Iat org.apache.hadoop.fs.FileSystem.append(FileSystem.java:572)
21:07 &amp;lt; jdcryans&amp;gt; Iat org.apache.hadoop.hbase.util.FSUtils.recoverFileLease(FSUtils.java:619)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We need to make it so recoverFileLease is calling the new recoverLease rather than append.&lt;/p&gt;</comment>
                            <comment id="13009377" author="stack" created="Mon, 21 Mar 2011 21:01:23 +0000"  >&lt;p&gt;Fixed by &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-3285&quot; title=&quot;Hlog recovery takes too much time&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-3285&quot;&gt;&lt;del&gt;HBASE-3285&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15017520" author="lars_francke" created="Fri, 20 Nov 2015 12:43:26 +0000"  >&lt;p&gt;This issue was closed as part of a bulk closing operation on 2015-11-20. All issues that have been resolved and where all fixVersions have been released have been closed (following discussions on the mailing list).&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12491584">HBASE-3285</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Thu, 6 Jan 2011 06:22:55 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>26819</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 2 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0hm13:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>100831</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>