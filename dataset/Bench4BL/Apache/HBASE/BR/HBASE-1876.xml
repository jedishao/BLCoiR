<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 02 18:35:55 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-1876/HBASE-1876.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-1876] DroppedSnapshotException when flushing memstore after a datanode dies</title>
                <link>https://issues.apache.org/jira/browse/HBASE-1876</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;A dead datanode in the cluster can lead to multiple HRegionServer failures and corrupted data. The HRegionServer failures can be reproduced  consistently on a 7 machines cluster with approx 2000 regions.&lt;/p&gt;

&lt;p&gt;Steps to reproduce&lt;/p&gt;

&lt;p&gt;The easiest and safest way is to reproduce it for the .META. table, however it will work with any table. &lt;/p&gt;

&lt;p&gt;Locate a datanode that stores the .META. files and kill -9 it. &lt;br/&gt;
In order to get multiple writes to the .META. table bring up or shut down a region server this will eventually cause a flush on the memstore&lt;/p&gt;

&lt;p&gt;2009-09-25 09:26:17,775 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Flush requested on .META.,demo__assets,asset_283132172,1252898166036,1253265069920&lt;br/&gt;
2009-09-25 09:26:17,775 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Started memstore flush for region .META.,demo__assets,asset_283132172,1252898166036,1253265069920. Current region memstore si&lt;br/&gt;
ze 16.3k&lt;br/&gt;
2009-09-25 09:26:17,791 INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream java.io.IOException: Bad connect ack with firstBadLink 10.72.79.108:50010&lt;br/&gt;
2009-09-25 09:26:17,791 INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_-8767099282771605606_176852&lt;/p&gt;



&lt;p&gt;The DFSClient will retry for 3 times, but there&apos;s a high chance it will try on the same failed datanode (it takes around 10 minutes for dead datanode to be removed from cluster)&lt;/p&gt;




&lt;p&gt;2009-09-25 09:26:41,810 WARN org.apache.hadoop.hdfs.DFSClient: DataStreamer Exception: java.io.IOException: Unable to create new block.&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.nextBlockOutputStream(DFSClient.java:2814)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2000(DFSClient.java:2078)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2264)&lt;/p&gt;

&lt;p&gt;2009-09-25 09:26:41,810 WARN org.apache.hadoop.hdfs.DFSClient: Error Recovery for block blk_5317304716016587434_176852 bad datanode&lt;span class=&quot;error&quot;&gt;&amp;#91;2&amp;#93;&lt;/span&gt; nodes == null&lt;br/&gt;
2009-09-25 09:26:41,810 WARN org.apache.hadoop.hdfs.DFSClient: Could not get block locations. Source file &quot;/hbase/.META./225980069/info/5573114819456511457&quot; - Aborting...&lt;br/&gt;
2009-09-25 09:26:41,810 FATAL org.apache.hadoop.hbase.regionserver.MemStoreFlusher: Replay of hlog required. Forcing server shutdown&lt;br/&gt;
org.apache.hadoop.hbase.DroppedSnapshotException: region: .META.,demo__assets,asset_283132172,1252898166036,1253265069920&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:942)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:835)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:241)&lt;br/&gt;
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.run(MemStoreFlusher.java:149)&lt;br/&gt;
Caused by: java.io.IOException: Bad connect ack with firstBadLink 10.72.79.108:50010&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.createBlockOutputStream(DFSClient.java:2872)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.nextBlockOutputStream(DFSClient.java:2795)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2000(DFSClient.java:2078)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2264)&lt;/p&gt;



&lt;p&gt;After the HRegionServer shuts down itself the regions will be reassigned however you might hit this &lt;/p&gt;



&lt;p&gt;2009-09-26 08:04:23,646 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Worker: MSG_REGION_OPEN: .META.,demo__assets,asset_283132172,1252898166036,1253265069920&lt;br/&gt;
2009-09-26 08:04:23,684 WARN org.apache.hadoop.hbase.regionserver.Store: Skipping hdfs://b0:9000/hbase/.META./225980069/historian/1432202951743803786 because its empty. &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-646&quot; title=&quot;EOFException opening HStoreFile info file (spin on HBASE-645 and 550)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-646&quot;&gt;&lt;del&gt;HBASE-646&lt;/del&gt;&lt;/a&gt; DATA LOSS?&lt;br/&gt;
...&lt;br/&gt;
2009-09-26 08:04:23,776 INFO org.apache.hadoop.hbase.regionserver.HRegion: region .META.,demo__assets,asset_283132172,1252898166036,1253265069920/225980069 available; sequence id is 1331458484&lt;/p&gt;

&lt;p&gt;We ended up with corrupted data in .META. &quot;info:server&quot; after master got confirmation that it was updated from the HRegionServer that got DroppedSnapshotException&lt;/p&gt;

&lt;p&gt;Since after a cluster restart server:info will be correct, .META. is safer to test with. Also to detect data corruption you can just scan .META. get the start key for each region and attempt to retrieve it from the corresponding table. If .META. is corrupted you get a NotServingRegionException. &lt;/p&gt;

&lt;p&gt;This issue is related to &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-630&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HDFS-630&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;I attached a patch for &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-630&quot; title=&quot;In DFSOutputStream.nextBlockOutputStream(), the client can exclude specific datanodes when locating the next block.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-630&quot;&gt;&lt;del&gt;HDFS-630&lt;/del&gt;&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12420919/HDFS-630.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12420919/HDFS-630.patch&lt;/a&gt; that fixes this problem. &lt;/p&gt;</description>
                <environment></environment>
        <key id="12436937">HBASE-1876</key>
            <summary>DroppedSnapshotException when flushing memstore after a datanode dies</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="clehene">Cosmin Lehene</assignee>
                                    <reporter username="clehene">Cosmin Lehene</reporter>
                        <labels>
                    </labels>
                <created>Wed, 30 Sep 2009 16:48:43 +0000</created>
                <updated>Fri, 20 Nov 2015 13:02:00 +0000</updated>
                            <resolved>Sat, 17 Jul 2010 15:38:05 +0000</resolved>
                                    <version>0.20.0</version>
                                    <fixVersion>0.90.0</fixVersion>
                                    <component>regionserver</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>2</watches>
                                    <timeoriginalestimate seconds="86400">24h</timeoriginalestimate>
                            <timeestimate seconds="86400">24h</timeestimate>
                                        <comments>
                            <comment id="12761046" author="stack" created="Wed, 30 Sep 2009 23:33:36 +0000"  >&lt;p&gt;We should make this a recommended patch for hadoop installs running hbase.  Let me add it to &apos;Getting Started&apos; list.&lt;/p&gt;</comment>
                            <comment id="12762421" author="apurtell" created="Mon, 5 Oct 2009 22:22:19 +0000"  >&lt;p&gt;Should we roll the &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-630&quot; title=&quot;In DFSOutputStream.nextBlockOutputStream(), the client can exclude specific datanodes when locating the next block.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-630&quot;&gt;&lt;del&gt;HDFS-630&lt;/del&gt;&lt;/a&gt; patch into the patched Hadoop jar included in the HBase distrib, alongside the patch for &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-127&quot; title=&quot;DFSClient block read failures cause open DFSInputStream to become unusable&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-127&quot;&gt;&lt;del&gt;HDFS-127&lt;/del&gt;&lt;/a&gt;? &lt;/p&gt;</comment>
                            <comment id="12762423" author="stack" created="Mon, 5 Oct 2009 22:27:35 +0000"  >&lt;p&gt;Its not client-side only like the hdfs-127 patch.  It needs the namenode patched.  I&apos;m adding a note to our getting started recommending adding this patch to your hadoop install.  I think that enough for hbase 0.20.1.&lt;/p&gt;</comment>
                            <comment id="12762432" author="stack" created="Mon, 5 Oct 2009 22:38:50 +0000"  >&lt;p&gt;I added to our &apos;Getting Started&apos; a recommendation that users apply hdfs-630 to their hadoop cluster on branch and trunk.&lt;/p&gt;

&lt;p&gt;I think need for hdfs-630 is going to become more apparent as we test new sync/append, especially on small clusters.&lt;/p&gt;

&lt;p&gt;Moving out of 0.20.1 now....&lt;/p&gt;</comment>
                            <comment id="12766106" author="clehene" created="Thu, 15 Oct 2009 16:00:43 +0000"  >&lt;p&gt;I adapted the previous patch for &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-630&quot; title=&quot;In DFSOutputStream.nextBlockOutputStream(), the client can exclude specific datanodes when locating the next block.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-630&quot;&gt;&lt;del&gt;HDFS-630&lt;/del&gt;&lt;/a&gt; to 0.21.x branch &lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12422242/0001-Fix-HDFS-630-for-0.21.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12422242/0001-Fix-HDFS-630-for-0.21.patch&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12778026" author="stack" created="Sun, 15 Nov 2009 00:29:16 +0000"  >&lt;p&gt;I did more testing of hdfs-630.   For sure it helps with the above situation.  To underline how necessary we think this patch is, especially when cluster is small, I&apos;ve add the patch to the hadoop-hdfs.jar bundled with hbase.&lt;/p&gt;</comment>
                            <comment id="12778083" author="clehene" created="Sun, 15 Nov 2009 09:59:40 +0000"  >&lt;p&gt;stack: the patched DFSClient is not compatible with unpatched NameNode, so if we&apos;re going to include the patch in the hadoop-hdfs.jar we need to explain that it must be used with a patched NameNode as well. &lt;/p&gt;</comment>
                            <comment id="12778121" author="stack" created="Sun, 15 Nov 2009 16:34:20 +0000"  >&lt;p&gt;@Cosmin: Thats bad.  Thanks.  Let me undo.&lt;/p&gt;</comment>
                            <comment id="12789818" author="stack" created="Sat, 12 Dec 2009 23:20:58 +0000"  >&lt;p&gt;I undid bundling an hadoop-hdfs patched with hdfs-630 being part of hbase deploy.&lt;/p&gt;</comment>
                            <comment id="12790071" author="clehene" created="Mon, 14 Dec 2009 09:50:24 +0000"  >&lt;p&gt;Linking to &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-630&quot; title=&quot;In DFSOutputStream.nextBlockOutputStream(), the client can exclude specific datanodes when locating the next block.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-630&quot;&gt;&lt;del&gt;HDFS-630&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12875214" author="stack" created="Thu, 3 Jun 2010 17:45:24 +0000"  >&lt;p&gt;hdfs-630 is in 0.21 hadoop and hadoop trunk.  I just suggested that it get added to 0.20-append branch.  If it goes in, we can resolve this issue against hbase 0.21.&lt;/p&gt;</comment>
                            <comment id="12875695" author="apurtell" created="Fri, 4 Jun 2010 18:26:57 +0000"  >&lt;p&gt;Stack:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;hdfs-630 is in 0.21 hadoop and hadoop trunk.  I just suggested that it get added to 0.20-append branch.  If it goes in, we can resolve this issue against hbase 0.21.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;We have been using a Hadoop patched with 630 internally so HBase is stable on small-ish DFS clusters. &lt;/p&gt;




</comment>
                            <comment id="12875697" author="stack" created="Fri, 4 Jun 2010 18:39:08 +0000"  >&lt;p&gt;Dhruba committed a hdfs-630 but then I saw that Cosmin commented suggesting that Dhruba use a patch Todd made for 0.20 branch.  I wonder why?  Let me ask him.&lt;/p&gt;
</comment>
                            <comment id="12875699" author="stack" created="Fri, 4 Jun 2010 18:40:27 +0000"  >&lt;p&gt;oh, nm... it hasn&apos;t been committed yet.  I misread the issue.&lt;/p&gt;</comment>
                            <comment id="12889417" author="stack" created="Fri, 16 Jul 2010 23:44:34 +0000"  >&lt;p&gt;@Cosmin Can we close this?  branch-0.20-append, what we have checked into hbase and what we expect to run on now has hdfs-630.&lt;/p&gt;</comment>
                            <comment id="12889471" author="clehene" created="Sat, 17 Jul 2010 07:51:57 +0000"  >&lt;p&gt;We&apos;re currently running CDH3b2 and it looks good. I think it&apos;s safe to close it now with &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-630&quot; title=&quot;In DFSOutputStream.nextBlockOutputStream(), the client can exclude specific datanodes when locating the next block.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-630&quot;&gt;&lt;del&gt;HDFS-630&lt;/del&gt;&lt;/a&gt; committed to 0.20-append.&lt;/p&gt;</comment>
                            <comment id="12889513" author="stack" created="Sat, 17 Jul 2010 15:38:05 +0000"  >&lt;p&gt;Closing w/ Cosmin&apos;s blessing.&lt;/p&gt;</comment>
                            <comment id="15017950" author="lars_francke" created="Fri, 20 Nov 2015 13:02:00 +0000"  >&lt;p&gt;This issue was closed as part of a bulk closing operation on 2015-11-20. All issues that have been resolved and where all fixVersions have been released have been closed (following discussions on the mailing list).&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12436024">HDFS-630</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 30 Sep 2009 23:33:36 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 2 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i00xb3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3328</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>