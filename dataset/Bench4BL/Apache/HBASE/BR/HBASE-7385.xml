<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Sat Dec 03 16:36:23 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-7385/HBASE-7385.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-7385] Do not abort regionserver if StoreFlusher.flushCache() fails</title>
                <link>https://issues.apache.org/jira/browse/HBASE-7385</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;A rare NN failover may cause RS abort, in the following sequence of events: &lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;RS tries to flush the memstore&lt;/li&gt;
	&lt;li&gt;Create a file, start block, and acquire a lease&lt;/li&gt;
	&lt;li&gt;Block is complete, lease removed, but before we send the RPC response back to the client, NN is killed.&lt;/li&gt;
	&lt;li&gt;New NN comes up, client retries the block complete again, the new NN throws lease expired since the block was already complete.&lt;/li&gt;
	&lt;li&gt;RS receives the exception, and aborts.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;This is actually a NN+DFSClient issue that, the dfs client from RS does not receive the rpc response about the block close, and upon retry on the new NN, it gets the exception, since the file was already closed. However, although this is DFS client specific, we can also make RS more resilient by not aborting the RS upon exception from the flushCache(). We can change StoreFlusher so that: &lt;/p&gt;

&lt;p&gt;StoreFlusher.prepare() will become idempotent (so will Memstore.snapshot())&lt;br/&gt;
StoreFlusher.flushCache() will throw with IOException upon DFS exception, but we catch IOException, and just abort the flush request (not RS).&lt;br/&gt;
StoreFlusher.commit() still cause RS abort on exception. This is also debatable. If dfs is alive, and we can undo the flush changes, than we should not abort. &lt;/p&gt;

&lt;p&gt;logs: &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
org.apache.hadoop.hbase.DroppedSnapshotException: region: loadtest_ha,e6666658,1355820729877.298bcbd550b80507a379fe67eefbe5ea.
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1485)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1364)
	at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:896)
	at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:845)
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:119)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:169)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:662)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException: No lease on /apps/hbase/data/loadtest_ha/298bcbd550b80507a379fe67eefbe5ea/.tmp/5cf8951ee12449ce8e4e6dd0bf1645c2 File is not open &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; writing. [Lease.  Holder: DFSClient_hb_rs_XXX,60020,1355813552066_203591774_25, pendingcreates: 1]
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:1724)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:1707)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:1762)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:1750)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.complete(NameNode.java:779)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:578)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1393)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1389)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1136)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1387)

	at org.apache.hadoop.ipc.Client.call(Client.java:1107)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at $Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:85)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:62)
	at $Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.closeInternal(DFSClient.java:4087)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.close(DFSClient.java:3988)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:61)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:86)
	at org.apache.hadoop.hbase.io.hfile.AbstractHFileWriter.finishClose(AbstractHFileWriter.java:255)
	at org.apache.hadoop.hbase.io.hfile.HFileWriterV2.close(HFileWriterV2.java:432)
	at org.apache.hadoop.hbase.regionserver.StoreFile$Writer.close(StoreFile.java:1214)
	at org.apache.hadoop.hbase.regionserver.Store.internalFlushCache(Store.java:762)
	at org.apache.hadoop.hbase.regionserver.Store.flushCache(Store.java:674)
	at org.apache.hadoop.hbase.regionserver.Store.access$400(Store.java:109)
	at org.apache.hadoop.hbase.regionserver.Store$StoreFlusherImpl.flushCache(Store.java:2286)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1460)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12624556">HBASE-7385</key>
            <summary>Do not abort regionserver if StoreFlusher.flushCache() fails</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="enis">Enis Soztutar</assignee>
                                    <reporter username="enis">Enis Soztutar</reporter>
                        <labels>
                    </labels>
                <created>Wed, 19 Dec 2012 00:35:04 +0000</created>
                <updated>Wed, 30 Jan 2013 22:57:17 +0000</updated>
                            <resolved>Wed, 30 Jan 2013 22:57:17 +0000</resolved>
                                                                    <component>io</component>
                    <component>regionserver</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                <comments>
                            <comment id="13535633" author="ram_krish" created="Wed, 19 Dec 2012 04:35:44 +0000"  >&lt;p&gt;Nice one. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13535643" author="lhofhansl" created="Wed, 19 Dec 2012 05:06:21 +0000"  >&lt;p&gt;How will Memstore.snapshot() become idempotent?&lt;/p&gt;</comment>
                            <comment id="13536304" author="enis" created="Wed, 19 Dec 2012 18:59:23 +0000"  >&lt;blockquote&gt;&lt;p&gt;How will Memstore.snapshot() become idempotent?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;snapshot already checks for whether there is a previous snapshot lying around, we can just remove the warning log. If flush is aborted, the memstore snapshot will live on, and new snapshot cannot be taken unless this one has been flushed. We might have to adjust the memstore size() calculations. &lt;/p&gt;</comment>
                            <comment id="13567034" author="enis" created="Wed, 30 Jan 2013 22:57:17 +0000"  >&lt;p&gt;Duplicate of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-7507&quot; title=&quot;Make memstore flush be able to retry after exception&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-7507&quot;&gt;&lt;del&gt;HBASE-7507&lt;/del&gt;&lt;/a&gt;. &lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12626327">HBASE-7507</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 19 Dec 2012 04:35:44 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>300377</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 44 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i167jz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>244356</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>