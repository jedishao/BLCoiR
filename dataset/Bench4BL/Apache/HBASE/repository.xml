<?xml version = "1.0" encoding = "UTF-8" ?>
<bugrepository name="HBASE">
	<bug id="421" opendate="2008-02-07 08:24:53" fixdate="2008-02-08 06:45:33" resolution="Fixed">
		<buginformation>
			<summary>TestRegionServerExit broken</summary>
			<description>TestRegionServerExit has a couple of problems:
1. Region server tries to start http server on a port already in use:
[junit] 2008-02-07 07:01:06,529 FATAL [RegionServer:2] hbase.HRegionServer(867): Failed init
[junit] java.io.IOException: Problem starting http server
[junit] 	at org.apache.hadoop.hbase.util.InfoServer.start(InfoServer.java:227)
[junit] 	at org.apache.hadoop.hbase.HRegionServer.startServiceThreads(HRegionServer.java:928)
[junit] 	at org.apache.hadoop.hbase.HRegionServer.init(HRegionServer.java:863)
[junit] 	at org.apache.hadoop.hbase.HRegionServer.run(HRegionServer.java:633)
[junit] 	at java.lang.Thread.run(Thread.java:595)
[junit] Caused by: org.mortbay.util.MultiException[java.net.BindException: Address already in use]
[junit] 	at org.mortbay.http.HttpServer.doStart(HttpServer.java:731)
[junit] 	at org.mortbay.util.Container.start(Container.java:72)
[junit] 	at org.apache.hadoop.hbase.util.InfoServer.start(InfoServer.java:205)
[junit] 	... 4 more
[junit] 2008-02-07 07:01:06,530 FATAL [RegionServer:2] hbase.HRegionServer(772): Unhandled exception. Aborting...
The region server that died apparently was serving the root region.
The test case apparently has a long timeout for finding the root region because you see a lot of 
 [junit] 2008-02-07 07:04:14,813 DEBUG [Thread-540] hbase.HConnectionManager$TableServers(708): Wake. Retry finding root region.
[junit] 2008-02-07 07:04:14,814 DEBUG [Thread-540] hbase.HConnectionManager$TableServers(704): Sleeping. Waiting for root region.
[junit] 2008-02-07 07:04:24,823 DEBUG [Thread-540] hbase.HConnectionManager$TableServers(708): Wake. Retry finding root region.
[junit] 2008-02-07 07:04:24,827 DEBUG [Thread-540] hbase.HConnectionManager$TableServers(704): Sleeping. Waiting for root region.
[junit] 2008-02-07 07:04:34,833 DEBUG [Thread-540] hbase.HConnectionManager$TableServers(708): Wake. Retry finding root region.
[junit] 2008-02-07 07:04:34,836 DEBUG [Thread-540] hbase.HConnectionManager$TableServers(704): Sleeping. Waiting for root region.
[junit] 2008-02-07 07:04:44,842 DEBUG [Thread-540] hbase.HConnectionManager$TableServers(708): Wake. Retry finding root region.
until finally the client gives up:
 [junit] 2008-02-07 07:04:44,843 FATAL [Thread-540] hbase.TestRegionServerExit$1(161): could not re-open meta table because
[junit] org.apache.hadoop.hbase.NoServerForRegionException: Timed out trying to locate root region
[junit] 	at org.apache.hadoop.hbase.HConnectionManager$TableServers.locateRootRegion(HConnectionManager.java:718)
[junit] 	at org.apache.hadoop.hbase.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:329)
[junit] 	at org.apache.hadoop.hbase.HConnectionManager$TableServers.relocateRegion(HConnectionManager.java:311)
[junit] 	at org.apache.hadoop.hbase.HConnectionManager$TableServers.locateRegionInMeta(HConnectionManager.java:476)
[junit] 	at org.apache.hadoop.hbase.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:339)
[junit] 	at org.apache.hadoop.hbase.HConnectionManager$TableServers.relocateRegion(HConnectionManager.java:311)
[junit] 	at org.apache.hadoop.hbase.HTable.getRegionLocation(HTable.java:114)
[junit] 	at org.apache.hadoop.hbase.HTable$ClientScanner.nextScanner(HTable.java:889)
[junit] 	at org.apache.hadoop.hbase.HTable$ClientScanner.&amp;lt;init&amp;gt;(HTable.java:817)
[junit] 	at org.apache.hadoop.hbase.HTable.obtainScanner(HTable.java:522)
[junit] 	at org.apache.hadoop.hbase.HTable.obtainScanner(HTable.java:411)
[junit] 	at org.apache.hadoop.hbase.TestRegionServerExit$1.run(TestRegionServerExit.java:156)
[junit] 	at java.lang.Thread.run(Thread.java:595)
[junit] Exception in thread "Thread-540" junit.framework.AssertionFailedError
[junit] 	at junit.framework.Assert.fail(Assert.java:47)
[junit] 	at junit.framework.Assert.fail(Assert.java:53)
[junit] 	at org.apache.hadoop.hbase.TestRegionServerExit$1.run(TestRegionServerExit.java:162)
[junit] 	at java.lang.Thread.run(Thread.java:595)
Which is not the way the test is supposed to run at all.
It appears that when we start multiple region servers in a MiniHBaseCluster, they all try to start their http server on the same port. In the past I believe that the http server start failure was not fatal, so the test ran.
We should either have some kind of setting for MiniHBaseCluster that tells the master and region servers not to start their http servers, or some way of telling multiple servers not to start on the same port, or making http startup failure non-fatal.
Tests like these are good as they (eventually) point out a regression to us.</description>
			<version>0.1.0</version>
			<fixedVersion>0.1.0, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.TestRegionServerExit.java</file>
		</fixedFiles>
	</bug>
	<bug id="426" opendate="2008-02-07 23:32:03" fixdate="2008-02-09 01:55:12" resolution="Fixed">
		<buginformation>
			<summary>hbase can&amp;apos;t find remote filesystem</summary>
			<description>If filesystem is remote, e.g. its an Hadoop DFS running "over there", there is no means of pointing hbase at it currently (unless you count copying hadoop-site.xml into hbase/conf).  Should be possible to just set a fully qualified hbase.rootdir and that should be sufficient for hbase figuring the fs (needs to be backported to 0.1 too).</description>
			<version>0.1.0</version>
			<fixedVersion>0.1.0, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="M">org.apache.hadoop.hbase.HLog.java</file>
			<file type="M">org.apache.hadoop.hbase.TestLogRolling.java</file>
			<file type="M">org.apache.hadoop.hbase.TestMergeMeta.java</file>
			<file type="M">org.apache.hadoop.hbase.TestCompaction.java</file>
			<file type="M">org.apache.hadoop.hbase.HConstants.java</file>
			<file type="M">org.apache.hadoop.hbase.TestHStoreFile.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.TestTableMapReduce.java</file>
			<file type="M">org.apache.hadoop.hbase.AbstractMergeTestBase.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.TestTableIndex.java</file>
			<file type="M">org.apache.hadoop.hbase.TestScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.TestDeleteFamily.java</file>
			<file type="M">org.apache.hadoop.hbase.HMerge.java</file>
			<file type="M">org.apache.hadoop.hbase.HConnectionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.util.Migrate.java</file>
			<file type="M">org.apache.hadoop.hbase.TestDeleteAll.java</file>
			<file type="M">org.apache.hadoop.hbase.TestHLog.java</file>
			<file type="M">org.apache.hadoop.hbase.TestTimestamp.java</file>
			<file type="M">org.apache.hadoop.hbase.TestHRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.MiniHBaseCluster.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseTestCase.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestMigrate.java</file>
			<file type="M">org.apache.hadoop.hbase.TestGet.java</file>
			<file type="M">org.apache.hadoop.hbase.TestSplit.java</file>
			<file type="M">org.apache.hadoop.hbase.TestGet2.java</file>
		</fixedFiles>
	</bug>
	<bug id="437" opendate="2008-02-11 05:46:21" fixdate="2008-02-11 17:26:02" resolution="Fixed">
		<buginformation>
			<summary>Clear Command should use system.out</summary>
			<description>Current clear command doesn&amp;amp;apos;t work, It should use system.out</description>
			<version>0.1.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.hql.ClearCommand.java</file>
		</fixedFiles>
	</bug>
	<bug id="444" opendate="2008-02-13 01:14:39" fixdate="2008-02-13 20:32:25" resolution="Fixed">
		<buginformation>
			<summary>hbase is very slow at determining table is not present</summary>
			<description>If I misspell a table name, it takes a very long time for hbase to determine that the table doesn&amp;amp;apos;t exist, because there are many levels of retries.  This often causes timeouts, which then obscure the true cause of the problem.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.HConnectionManager.java</file>
		</fixedFiles>
	</bug>
	<bug id="446" opendate="2008-02-14 02:13:18" fixdate="2008-02-14 19:02:09" resolution="Fixed">
		<buginformation>
			<summary>Fully qualified hbase.rootdir doesn&amp;apos;t work</summary>
			<description>Jim was setting up cluster w/ new hbase.  Setting fully qualified hbase.rootdir was failing.  Complaint was that the filesystems didn&amp;amp;apos;t match  i.e. the hdfs of the fully qualified hbase.rootdir didn&amp;amp;apos;t jibe w/ the default hadoop file:///.
Fix needs to be backported.
The problem was that because the hadoop config files were not found (because they are in a different directory and not on the classpath) then fs.get(conf) returns file:///</description>
			<version>0.1.0</version>
			<fixedVersion>0.1.0, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
		</fixedFiles>
	</bug>
	<bug id="460" opendate="2008-02-23 02:57:13" fixdate="2008-02-23 03:19:20" resolution="Fixed">
		<buginformation>
			<summary>TestMigrate broken when HBase moved to subproject</summary>
			<description>When HBase became a formal subproject of Hadoop, its files changed relative locations in SVN tree. As a result, TestMigrate broke because it reads data out of the source tree.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.TestMigrate.java</file>
		</fixedFiles>
	</bug>
	<bug id="462" opendate="2008-02-23 04:07:19" fixdate="2008-02-23 06:12:40" resolution="Fixed">
		<buginformation>
			<summary>Update migration tool</summary>
			<description>HBASE-2 is really an incompatible change as it changes the format of region server log file names.
Update Migration tool so that it ensures there are no unrecovered region server log files.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="M">org.apache.hadoop.hbase.util.Migrate.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.IdentityTableReduce.java</file>
			<file type="M">org.apache.hadoop.hbase.TestBloomFilters.java</file>
			<file type="M">org.apache.hadoop.hbase.AbstractMergeTestBase.java</file>
			<file type="M">org.apache.hadoop.hbase.util.FSUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.HConstants.java</file>
			<file type="M">org.apache.hadoop.hbase.StaticTestEnvironment.java</file>
			<file type="M">org.apache.hadoop.hbase.TestScannerAPI.java</file>
		</fixedFiles>
	</bug>
	<bug id="464" opendate="2008-02-24 00:00:27" fixdate="2008-02-24 00:36:22" resolution="Fixed">
		<buginformation>
			<summary>HBASE-419 introduced javadoc errors</summary>
			<description>Did noone run javadoc on this patch?
 [javadoc] C:\workspace\HBase-test\src\java\org\apache\hadoop\hbase\mapred\GroupingTableMap.java:91: warning - Tag @see: can&amp;amp;apos;t find map(org.apache.hadoop.hbase.HStoreKey, org.apache.hadoop.io.MapWritable, org.apache.hadoop.mapred.OutputCollector, org.apache.hadoop.mapred.Reporter) in org.apache.hadoop.hbase.mapred.TableMap
[javadoc] C:\workspace\HBase-test\src\java\org\apache\hadoop\hbase\mapred\IdentityTableMap.java:47: warning - Tag @see: can&amp;amp;apos;t find map(org.apache.hadoop.hbase.HStoreKey, org.apache.hadoop.io.MapWritable, org.apache.hadoop.mapred.OutputCollector, org.apache.hadoop.mapred.Reporter) in org.apache.hadoop.hbase.mapred.TableMap
[javadoc] C:\workspace\HBase-test\src\java\org\apache\hadoop\hbase\mapred\TableInputFormat.java:58: warning - Tag @see: reference not found: org.apache.hadoop.hbase.HAbstractScanner for column name wildcards
[javadoc] C:\workspace\HBase-test\src\java\org\apache\hadoop\hbase\regionserver\HAbstractScanner.java:205: warning - Tag @see: can&amp;amp;apos;t find next(org.apache.hadoop.hbase.HStoreKey, java.util.SortedMap) in org.apache.hadoop.hbase.HScannerInterface
[javadoc] C:\workspace\HBase-test\src\java\org\apache\hadoop\hbase\regionserver\HRegion.java:713: warning - @return tag has no arguments.
[javadoc] C:\workspace\HBase-test\src\java\org\apache\hadoop\hbase\regionserver\HRegionServer.java:993: warning - Tag @link: reference not found: Flusher</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HAbstractScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.GroupingTableMap.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.IdentityTableMap.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.TableInputFormat.java</file>
		</fixedFiles>
	</bug>
	<bug id="428" opendate="2008-02-08 14:36:14" fixdate="2008-02-26 05:10:32" resolution="Fixed">
		<buginformation>
			<summary>Under continuous upload of rows, WrongRegionExceptions are thrown that reach the client even after retries</summary>
			<description>I have installed 0.16.0 rc 1 which I believe contains a fix for similar issue HBASE-138,  but I still see the same problem.

I am using a single node.
The client application runs in a single thread, loading data into a single table.
I get good throughput of about 200 rows/sec to start with, with occasional significant drops due to NotServingRegionException&amp;amp;apos;s that are recoverable on client retry (internal to hbase).
After 54 minutes, and about 500,000 rows I start to see WrongRegionException&amp;amp;apos;s in the client application, i.e. real failures. (Note that this compares to 0.15.3 which would being to throw NotServingRegionExceptions after a few tens of thousands of rows).

My data consists of a single table with 5 column families. The data written is as follows:&amp;gt;&amp;gt;
key: a URL
family 1: a small string, often emty, 2 longs, 1 int
family 2: a byte averaging averaging between 1k and 10k, a small string
family 3: several columns with different names per row, values of small strings
family 4: most rows have zero columns, some rows have 1 or more columns with a UL value
The URLs are typically "long-ish" URL as seen when crawling a site, not short home page URLs  
I am assuming the data is stored in files of the form &amp;lt;hbaseroot&amp;gt;//&amp;lt;tablename&amp;gt;/&amp;lt;9digitnum&amp;gt;/data/mapfiles/&amp;lt;19digitnum&amp;gt;/data. I have attached a csv file showing the distribution of size of these files. Average size is 19Mb, but the sizes are not evenly distributed at all
Here are two sample exceptions thrown, copied from the region server log:
2008-02-08 02:08:22,495 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 60020, call batchUpdate(pagefetch,http://galsn1.mobilook.mobiwap.com/bm/listproducts;jsessionid=D2ED1EB898163CDB27135DC2CF6958B3.197B?rsi=78011 wap2 20080102052924,1202401088077, 9223372036854775807, org.apache.hadoop.hbase.io.BatchUpdate@feb215) from 66.135.42.137:38484: error: org.apache.hadoop.hbase.WrongRegionException: Requested row out of range for HRegion pagefetch,http://galsn1.mobilook.mobiwap.com/bm/listproducts;jsessionid=D2ED1EB898163CDB27135DC2CF6958B3.197B?rsi=78011 wap2 20080102052924,1202401088077, startKey=&amp;amp;apos;http://galsn1.mobilook.mobiwap.com/bm/listproducts;jsessionid=D2ED1EB898163CDB27135DC2CF6958B3.197B?rsi=78011 wap2 20080102052924&amp;amp;apos;, getEndKey()=&amp;amp;apos;http://galsn1.mobilook.mobiwap.com/bm/listproducts;jsessionid=D2ED1EB898163CDB27135DC2CF6958B3.197B?rsi=78011 wap2 20080102052924&amp;amp;apos;, row=&amp;amp;apos;http://go2purdue.com/Redeemer_University.cfm?pt=2&amp;amp;sp=2&amp;amp;vid=1199243289_3X02X1468757255&amp;amp;rpt=2&amp;amp;kt=4&amp;amp;kp=1 wap2 20080102081237&amp;amp;apos;
org.apache.hadoop.hbase.WrongRegionException: Requested row out of range for HRegion pagefetch,http://galsn1.mobilook.mobiwap.com/bm/listproducts;jsessionid=D2ED1EB898163CDB27135DC2CF6958B3.197B?rsi=78011 wap2 20080102052924,1202401088077, startKey=&amp;amp;apos;http://galsn1.mobilook.mobiwap.com/bm/listproducts;jsessionid=D2ED1EB898163CDB27135DC2CF6958B3.197B?rsi=78011 wap2 20080102052924&amp;amp;apos;, getEndKey()=&amp;amp;apos;http://galsn1.mobilook.mobiwap.com/bm/listproducts;jsessionid=D2ED1EB898163CDB27135DC2CF6958B3.197B?rsi=78011 wap2 20080102052924&amp;amp;apos;, row=&amp;amp;apos;http://go2purdue.com/Redeemer_University.cfm?pt=2&amp;amp;sp=2&amp;amp;vid=1199243289_3X02X1468757255&amp;amp;rpt=2&amp;amp;kt=4&amp;amp;kp=1 wap2 20080102081237&amp;amp;apos;
        at org.apache.hadoop.hbase.HRegion.checkRow(HRegion.java:1486)
        at org.apache.hadoop.hbase.HRegion.obtainRowLock(HRegion.java:1531)
        at org.apache.hadoop.hbase.HRegion.batchUpdate(HRegion.java:1226)
        at org.apache.hadoop.hbase.HRegionServer.batchUpdate(HRegionServer.java:1433)
        at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:585)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:413)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:910)
2008-02-08 02:08:22,696 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 60020, call batchUpdate(pagefetch,http://galsn1.mobilook.mobiwap.com/bm/listproducts;jsessionid=D2ED1EB898163CDB27135DC2CF6958B3.197B?rsi=78011 wap2 20080102052924,1202401088077, 9223372036854775807, org.apache.hadoop.hbase.io.BatchUpdate@15d9be1) from 66.135.42.137:38484: error: org.apache.hadoop.hbase.WrongRegionException: Requested row out of range for HRegion pagefetch,http://galsn1.mobilook.mobiwap.com/bm/listproducts;jsessionid=D2ED1EB898163CDB27135DC2CF6958B3.197B?rsi=78011 wap2 20080102052924,1202401088077, startKey=&amp;amp;apos;http://galsn1.mobilook.mobiwap.com/bm/listproducts;jsessionid=D2ED1EB898163CDB27135DC2CF6958B3.197B?rsi=78011 wap2 20080102052924&amp;amp;apos;, getEndKey()=&amp;amp;apos;http://galsn1.mobilook.mobiwap.com/bm/listproducts;jsessionid=D2ED1EB898163CDB27135DC2CF6958B3.197B?rsi=78011 wap2 20080102052924&amp;amp;apos;, row=&amp;amp;apos;http://go2umass.com/Travel.cfm?pt=2&amp;amp;sp=2&amp;amp;vid=1199230721_3X04X1485302803&amp;amp;rpt=2&amp;amp;kt=5&amp;amp;kp=8 wap2 20080102081239&amp;amp;apos;
org.apache.hadoop.hbase.WrongRegionException: Requested row out of range for HRegion pagefetch,http://galsn1.mobilook.mobiwap.com/bm/listproducts;jsessionid=D2ED1EB898163CDB27135DC2CF6958B3.197B?rsi=78011 wap2 20080102052924,1202401088077, startKey=&amp;amp;apos;http://galsn1.mobilook.mobiwap.com/bm/listproducts;jsessionid=D2ED1EB898163CDB27135DC2CF6958B3.197B?rsi=78011 wap2 20080102052924&amp;amp;apos;, getEndKey()=&amp;amp;apos;http://galsn1.mobilook.mobiwap.com/bm/listproducts;jsessionid=D2ED1EB898163CDB27135DC2CF6958B3.197B?rsi=78011 wap2 20080102052924&amp;amp;apos;, row=&amp;amp;apos;http://go2umass.com/Travel.cfm?pt=2&amp;amp;sp=2&amp;amp;vid=1199230721_3X04X1485302803&amp;amp;rpt=2&amp;amp;kt=5&amp;amp;kp=8 wap2 20080102081239&amp;amp;apos;
        at org.apache.hadoop.hbase.HRegion.checkRow(HRegion.java:1486)
        at org.apache.hadoop.hbase.HRegion.obtainRowLock(HRegion.java:1531)
        at org.apache.hadoop.hbase.HRegion.batchUpdate(HRegion.java:1226)
        at org.apache.hadoop.hbase.HRegionServer.batchUpdate(HRegionServer.java:1433)
        at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:585)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:413)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:910)</description>
			<version>0.1.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.HStoreFile.java</file>
		</fixedFiles>
	</bug>
	<bug id="473" opendate="2008-02-27 00:52:12" fixdate="2008-02-28 22:08:08" resolution="Fixed">
		<buginformation>
			<summary>When a table is deleted, master sends multiple close messages to the region server</summary>
			<description>While TestHBaseCluster succeeds, it demonstrates that the master tells the region server to close the region multiple times.

    [junit] 2008-02-26 15:42:26,718 DEBUG [IPC Server handler 1 on 60000] master.ChangeTableState(131): adding region test,,1204069326375 to kill list
    [junit] 2008-02-26 15:42:26,718 DEBUG [IPC Server handler 1 on 60000] master.ChangeTableState(138): inserted local kill list into kill list for server 10.69.80.2:2154
    [junit] 2008-02-26 15:42:26,796 INFO  [IPC Server handler 1 on 60000] master.HMaster(644): deleted table: test
    [junit] 2008-02-26 15:42:27,515 INFO  [RegionServer:0.worker] regionserver.HRegionServer$Worker(726): MSG_REGION_CLOSE : test,,1204069326375
    [junit] 2008-02-26 15:42:27,515 DEBUG [RegionServer:0.worker] regionserver.HRegion(410): compactions and cache flushes disabled for region test,,1204069326375
    [junit] 2008-02-26 15:42:27,515 DEBUG [RegionServer:0.worker] regionserver.HRegion(428): new updates and scanners for region test,,1204069326375 disabled
    [junit] 2008-02-26 15:42:27,515 DEBUG [RegionServer:0.worker] regionserver.HRegion(446): no more active scanners for region test,,1204069326375
    [junit] 2008-02-26 15:42:27,515 DEBUG [RegionServer:0.worker] regionserver.HRegion(452): no more row locks outstanding on region test,,1204069326375
    [junit] 2008-02-26 15:42:27,515 DEBUG [RegionServer:0.worker] regionserver.HRegion(889): Started memcache flush for region test,,1204069326375. Size 86.4k
    [junit] 2008-02-26 15:42:27,546 INFO  [RegionManager.rootScanner] master.BaseScanner(147): RegionManager.rootScanner scanning meta region {regionname: -ROOT-,,0, startKey: &amp;lt;&amp;gt;, server: 10.69.80.2:2154}
    [junit] 2008-02-26 15:42:27,562 DEBUG [RegionManager.rootScanner] master.BaseScanner(179): RegionManager.rootScanner regioninfo: {regionname: .META.,,1, startKey: &amp;lt;&amp;gt;, endKey: &amp;lt;&amp;gt;, encodedName: 1028785192, tableDesc: {name: .META., families: {info:={name: info, max versions: 1, compression: NONE, in memory: false, block cache enabled: false, max length: 2147483647, bloom filter: none}}}}, server: 10.69.80.2:2154, startCode: 1204069326359
    [junit] 2008-02-26 15:42:27,562 INFO  [RegionManager.rootScanner] master.BaseScanner(225): RegionManager.rootScanner scan of meta region {regionname: -ROOT-,,0, startKey: &amp;lt;&amp;gt;, server: 10.69.80.2:2154} complete
    [junit] 2008-02-26 15:42:27,812 DEBUG [RegionServer:0.worker] regionserver.HStore(1154): Added 1417693581/anchor/2354913287379000616 with 1000 entries, sequence id 2007, and size 60.0k for 1417693581/anchor
    [junit] 2008-02-26 15:42:28,125 DEBUG [RegionServer:0.worker] regionserver.HStore(1154): Added 1417693581/contents/295490293048850969 with 1000 entries, sequence id 2007, and size 55.1k for 1417693581/contents
    [junit] 2008-02-26 15:42:28,125 DEBUG [RegionServer:0.worker] regionserver.HRegion(995): Finished memcache flush for region test,,1204069326375 in 610ms, sequenceid=2007
    [junit] 2008-02-26 15:42:28,125 DEBUG [RegionServer:0.worker] regionserver.HStore(1063): closed 1417693581/anchor
    [junit] 2008-02-26 15:42:28,125 DEBUG [RegionServer:0.worker] regionserver.HStore(1063): closed 1417693581/contents
    [junit] 2008-02-26 15:42:28,125 INFO  [RegionServer:0.worker] regionserver.HRegion(478): closed test,,1204069326375
    [junit] 2008-02-26 15:42:28,515 DEBUG [IPC Server handler 0 on 60000] master.ServerManager(287): Received MSG_REPORT_CLOSE : test,,1204069326375 from 10.69.80.2:2154
    [junit] 2008-02-26 15:42:28,515 INFO  [IPC Server handler 0 on 60000] master.ServerManager(303): 10.69.80.2:2154 no longer serving test,,1204069326375
    [junit] 2008-02-26 15:42:28,515 DEBUG [HMaster] master.HMaster(410): Main processing loop: ProcessRegionClose of test,,1204069326375
    [junit] 2008-02-26 15:42:28,515 INFO  [HMaster] master.ProcessRegionClose(61): region closed: test,,1204069326375
    [junit] 2008-02-26 15:42:28,515 INFO  [RegionServer:0.worker] regionserver.HRegionServer$Worker(726): MSG_REGION_CLOSE : test,,1204069326375
    [junit] 2008-02-26 15:42:28,515 DEBUG [HMaster] master.RegionServerOperation(75): numberOfMetaRegions: 1, onlineMetaRegions.size(): 1
    [junit] 2008-02-26 15:42:28,515 DEBUG [HMaster] regionserver.HRegion(1913): DELETING region hdfs://localhost:2123/user/jim/test/1417693581
    [junit] 2008-02-26 15:42:29,500 INFO  [RegionManager.metaScanner] master.BaseScanner(147): RegionManager.metaScanner scanning meta region {regionname: .META.,,1, startKey: &amp;lt;&amp;gt;, server: 10.69.80.2:2154}
    [junit] 2008-02-26 15:42:29,500 INFO  [RegionManager.metaScanner] master.BaseScanner(225): RegionManager.metaScanner scan of meta region {regionname: .META.,,1, startKey: &amp;lt;&amp;gt;, server: 10.69.80.2:2154} complete
    [junit] 2008-02-26 15:42:29,500 INFO  [RegionManager.metaScanner] master.MetaScanner(136): all meta regions scanned
    [junit] 2008-02-26 15:42:29,515 INFO  [RegionServer:0.worker] regionserver.HRegionServer$Worker(726): MSG_REGION_CLOSE : test,,1204069326375
    [junit] 2008-02-26 15:42:30,515 INFO  [RegionServer:0.worker] regionserver.HRegionServer$Worker(726): MSG_REGION_CLOSE : test,,1204069326375
    [junit] 2008-02-26 15:42:31,531 INFO  [RegionServer:0.worker] regionserver.HRegionServer$Worker(726): MSG_REGION_CLOSE : test,,1204069326375
    [junit] 2008-02-26 15:42:32,531 INFO  [RegionServer:0.worker] regionserver.HRegionServer$Worker(726): MSG_REGION_CLOSE : test,,1204069326375
    [junit] 2008-02-26 15:42:33,531 INFO  [RegionServer:0.worker] regionserver.HRegionServer$Worker(726): MSG_REGION_CLOSE : test,,1204069326375
    [junit] 2008-02-26 15:42:34,531 INFO  [RegionServer:0.worker] regionserver.HRegionServer$Worker(726): MSG_REGION_CLOSE : test,,1204069326375
    [junit] 2008-02-26 15:42:35,531 INFO  [RegionServer:0.worker] regionserver.HRegionServer$Worker(726): MSG_REGION_CLOSE : test,,1204069326375
    [junit] 2008-02-26 15:42:36,531 INFO  [RegionServer:0.worker] regionserver.HRegionServer$Worker(726): MSG_REGION_CLOSE : test,,1204069326375
    [junit] 2008-02-26 15:42:37,531 INFO  [RegionServer:0.worker] regionserver.HRegionServer$Worker(726): MSG_REGION_CLOSE : test,,1204069326375
    [junit] 2008-02-26 15:42:37,546 INFO  [RegionManager.rootScanner] master.BaseScanner(147): RegionManager.rootScanner scanning meta region {regionname: -ROOT-,,0, startKey: &amp;lt;&amp;gt;, server: 10.69.80.2:2154}
    [junit] 2008-02-26 15:42:37,562 DEBUG [RegionManager.rootScanner] master.BaseScanner(179): RegionManager.rootScanner regioninfo: {regionname: .META.,,1, startKey: &amp;lt;&amp;gt;, endKey: &amp;lt;&amp;gt;, encodedName: 1028785192, tableDesc: {name: .META., families: {info:={name: info, max versions: 1, compression: NONE, in memory: false, block cache enabled: false, max length: 2147483647, bloom filter: none}}}}, server: 10.69.80.2:2154, startCode: 1204069326359
    [junit] 2008-02-26 15:42:37,562 INFO  [RegionManager.rootScanner] master.BaseScanner(225): RegionManager.rootScanner scan of meta region {regionname: -ROOT-,,0, startKey: &amp;lt;&amp;gt;, server: 10.69.80.2:2154} complete
    [junit] 2008-02-26 15:42:38,531 INFO  [RegionServer:0.worker] regionserver.HRegionServer$Worker(726): MSG_REGION_CLOSE : test,,1204069326375
    [junit] 2008-02-26 15:42:39,500 INFO  [RegionManager.metaScanner] master.BaseScanner(147): RegionManager.metaScanner scanning meta region {regionname: .META.,,1, startKey: &amp;lt;&amp;gt;, server: 10.69.80.2:2154}
    [junit] 2008-02-26 15:42:39,500 INFO  [RegionManager.metaScanner] master.BaseScanner(225): RegionManager.metaScanner scan of meta region {regionname: .META.,,1, startKey: &amp;lt;&amp;gt;, server: 10.69.80.2:2154} complete
    [junit] 2008-02-26 15:42:39,500 INFO  [RegionManager.metaScanner] master.MetaScanner(136): all meta regions scanned
    [junit] 2008-02-26 15:42:39,531 INFO  [RegionServer:0.worker] regionserver.HRegionServer$Worker(726): MSG_REGION_CLOSE : test,,1204069326375
    [junit] 2008-02-26 15:42:40,531 INFO  [RegionServer:0.worker] regionserver.HRegionServer$Worker(726): MSG_REGION_CLOSE : test,,1204069326375
    [junit] 2008-02-26 15:42:41,531 INFO  [RegionServer:0.worker] regionserver.HRegionServer$Worker(726): MSG_REGION_CLOSE : test,,1204069326375
    [junit] 2008-02-26 15:42:41,812 INFO  [main] client.HBaseAdmin(248): table test deleted

</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.BaseScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.master.RegionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ChangeTableState.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ServerManager.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ProcessServerShutdown.java</file>
		</fixedFiles>
	</bug>
	<bug id="480" opendate="2008-02-29 22:38:24" fixdate="2008-03-01 22:06:56" resolution="Fixed">
		<buginformation>
			<summary>Tool to manually merge two regions</summary>
			<description>hbase-471 needs a tool to merge two regions that have same start key.  This tool may be of use elsewhere making repairs.</description>
			<version>0.1.0</version>
			<fixedVersion>0.1.0, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.HMerge.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">285</link>
		</links>
	</bug>
	<bug id="490" opendate="2008-03-04 01:25:07" fixdate="2008-03-04 19:35:11" resolution="Fixed">
		<buginformation>
			<summary>Doubly-assigned .META.; master uses one and clients another</summary>
			<description>Internal cluster has two .META.,,1 regions up (Its possible for a region to be added twice to the unassigned map if meta scans run close together).  Worse is that the master is working with one .META. but when clients come in, they&amp;amp;apos;re being give the other.  Makes for odd results.
Made it a blocker.  Still trying to track down how master doesn&amp;amp;apos;t see subsequent update of .META. info in ROOT.....</description>
			<version>0.1.0</version>
			<fixedVersion>0.1.0, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.BaseScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.master.MetaScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.master.RootScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.util.Sleeper.java</file>
			<file type="M">org.apache.hadoop.hbase.master.RegionManager.java</file>
		</fixedFiles>
	</bug>
	<bug id="492" opendate="2008-03-04 20:19:37" fixdate="2008-03-06 05:11:30" resolution="Fixed">
		<buginformation>
			<summary>hbase TRUNK does not build against hadoop TRUNK</summary>
			<description>When I build Hadoop&amp;amp;apos;s library from TRUNK and then build Hbase from TRUNK,
when I replace Hbase hadoop&amp;amp;apos;s libraries with the one built from TRUNK, I get the following error.
#/opt/ant/bin/ant clean tar
Buildfile: build.xml
clean:
[delete] Deleting directory /opt/hbase-src/build
init:
[mkdir] Created dir: /opt/hbase-src/build
[mkdir] Created dir: /opt/hbase-src/build/classes
[mkdir] Created dir: /opt/hbase-src/build/test
[mkdir] Created dir: /opt/hbase-src/build/examples
[mkdir] Created dir: /opt/hbase-src/build/webapps
[copy] Copying 8 files to /opt/hbase-src/build/webapps
[mkdir] Created dir: /opt/hbase-src/build/lib
[copy] Copying 22 files to /opt/hbase-src/build/lib
[mkdir] Created dir: /opt/hbase-src/build/conf
[copy] Copying 5 files to /opt/hbase-src/build/conf
[mkdir] Created dir: /opt/hbase-src/build/bin
[copy] Copying 7 files to /opt/hbase-src/build/bin
javacc:
compile:
[javac] Compiling 182 source files to /opt/hbase-src/build/classes
[javac] Note: Some input files use or override a deprecated API.
[javac] Note: Recompile with -Xlint:deprecation for details.
[javac] Note: Some input files use unchecked or unsafe operations.
[javac] Note: Recompile with -Xlint:unchecked for details.
jar:
[jar] Building jar: /opt/hbase-src/build/hbase-0.2.0-dev.jar
javadoc:
[mkdir] Created dir: /opt/hbase-src/build/docs/api
[javadoc] Generating Javadoc
[javadoc] Javadoc execution
[javadoc] Loading source files for package org.apache.hadoop.hbase...
[javadoc] Loading source files for package org.apache.hadoop.hbase.client...
[javadoc] Loading source files for package org.apache.hadoop.hbase.filter...
[javadoc] Loading source files for package org.apache.hadoop.hbase.generated.master...
[javadoc] Loading source files for package org.apache.hadoop.hbase.generated.regionserver...
[javadoc] Loading source files for package org.apache.hadoop.hbase.hql...
[javadoc] Loading source files for package org.apache.hadoop.hbase.hql.formatter...
[javadoc] Loading source files for package org.apache.hadoop.hbase.hql.generated...
[javadoc] Loading source files for package org.apache.hadoop.hbase.io...
[javadoc] Loading source files for package org.apache.hadoop.hbase.ipc...
[javadoc] Loading source files for package org.apache.hadoop.hbase.mapred...
[javadoc] Loading source files for package org.apache.hadoop.hbase.master...
[javadoc] Loading source files for package org.apache.hadoop.hbase.regionserver...
[javadoc] Loading source files for package org.apache.hadoop.hbase.rest...
[javadoc] Loading source files for package org.apache.hadoop.hbase.thrift...
[javadoc] Loading source files for package org.apache.hadoop.hbase.thrift.generated...
[javadoc] Loading source files for package org.apache.hadoop.hbase.util...
[javadoc] Loading source files for package org.onelab.filter...
[javadoc] Constructing Javadoc information...
[javadoc] Standard Doclet version 1.6.0_03
[javadoc] Building tree for all the packages and classes...
[javadoc] Building index for all the packages and classes...
[javadoc] Building index for all classes...
compile-test:
[javac] Compiling 58 source files to /opt/hbase-src/build/test
[javac] /opt/hbase-src/src/test/org/apache/hadoop/hbase/PerformanceEvaluation.java:148: org.apache.hadoop.hbase.PerformanceEvaluation.EvaluationMapTask is not abstract and does not override abstract method map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapred.OutputCollector,org.apache.hadoop.mapred.Reporter) in org.apache.hadoop.mapred.Mapper
[javac]   public static class EvaluationMapTask extends MapReduceBase
[javac]                 ^
[javac] Note: Some input files use or override a deprecated API.
[javac] Note: Recompile with -Xlint:deprecation for details.
[javac] 1 error
BUILD FAILED
/opt/hbase-src/build.xml:308: Compile failed; see the compiler error output for details.
</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.MultiRegionTable.java</file>
			<file type="M">org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
		</fixedFiles>
	</bug>
	<bug id="496" opendate="2008-03-06 19:25:37" fixdate="2008-03-06 21:54:02" resolution="Fixed">
		<buginformation>
			<summary>impossible state for createLease writes 400k lines in about 15seconds</summary>
			<description>Saw this in 0.16.0:

2008-03-06 01:12:03,861 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 60000, call regionServerStartup(address: XX.XX.XX.221:60020, startcode: 1204765922029, load: (requests: 0 regions: 0)) from XX.XX.XX.221:41140: error: java.io.IOException: java.lang.AssertionError: Impossible state for createLease(): Lease 277528057/277528057 is still held.
java.io.IOException: java.lang.AssertionError: Impossible state for createLease(): Lease 277528057/277528057 is still held.
        at org.apache.hadoop.hbase.Leases.createLease(Leases.java:145)
        at org.apache.hadoop.hbase.HMaster.regionServerStartup(HMaster.java:1307)
        at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)                                                                                                                                                                                                                                                              at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:413)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:910)


... over and over for hours.
</description>
			<version>0.16.0</version>
			<fixedVersion>0.1.0, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
		</fixedFiles>
	</bug>
	<bug id="495" opendate="2008-03-06 18:46:16" fixdate="2008-03-07 20:00:22" resolution="Fixed">
		<buginformation>
			<summary>No server address listed in .META.</summary>
			<description>Michael Bieniosek manufactured the following in a 0.16.0 install:

08/03/06 17:52:02 DEBUG hbase.HTable: Advancing internal scanner to startKey g80Fi5WZHlzLqGzErrAd7V==
08/03/06 17:52:02 DEBUG hbase.HConnectionManager$TableServers: reloading table servers because: No server address listed in .META. for region enwiki_080103,g80Fi5WZHlzLqGzErrAd7V==,1204768636421
08/03/06 17:52:12 DEBUG hbase.HConnectionManager$TableServers: reloading table servers because: No server address listed in .META. for region enwiki_080103,g80Fi5WZHlzLqGzErrAd7V==,1204768636421
08/03/06 17:52:22 DEBUG hbase.HConnectionManager$TableServers: reloading table servers because: No server address listed in .META. for region enwiki_080103,g80Fi5WZHlzLqGzErrAd7V==,1204768636421
org.apache.hadoop.hbase.NoServerForRegionException: No server address listed in .META. for region enwiki_080103,g80Fi5WZHlzLqGzErrAd7V==,1204768636421
        at org.apache.hadoop.hbase.HConnectionManager$TableServers.locateRegionInMeta(HConnectionManager.java:449)
        at org.apache.hadoop.hbase.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:346)
        at org.apache.hadoop.hbase.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:309)
        at org.apache.hadoop.hbase.HTable.getRegionLocation(HTable.java:103)
        at org.apache.hadoop.hbase.HTable$ClientScanner.nextScanner(HTable.java:854)
        at org.apache.hadoop.hbase.HTable$ClientScanner.next(HTable.java:915)
        at org.apache.hadoop.hbase.hql.SelectCommand.scanPrint(SelectCommand.java:233)
        at org.apache.hadoop.hbase.hql.SelectCommand.execute(SelectCommand.java:100)
        at org.apache.hadoop.hbase.hql.HQLClient.executeQuery(HQLClient.java:50)
        at org.apache.hadoop.hbase.Shell.main(Shell.java:114)


When I look in the .META., I see that the above region range has multiple mentions... : one offlined, two that have startcodes and servers associated and about 5 others that are just HRIs.  Table is broke.  At least need the merge of overlapping regions tool to fix.  Digging more....</description>
			<version>0.16.0</version>
			<fixedVersion>0.1.0, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.ServerManager.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ProcessServerShutdown.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">12</link>
		</links>
	</bug>
	<bug id="251" opendate="2008-01-15 20:51:40" fixdate="2008-03-12 16:39:43" resolution="Fixed">
		<buginformation>
			<summary>[hbase] Stuck replaying the edits of crashed machine</summary>
			<description>Rapleaf master got stuck trying to replay the logs of the server holding the .META. region.   Here are pertinent log excerpts:

2008-01-12 02:17:42,621 DEBUG org.apache.hadoop.hbase.HLog: Creating new log file writer for path /data/hbase1/hregion_1679905157/oldlogfile.log; map content {spider_pages,25_530417241,1200073704087=org.apache.hadoop.io.SequenceFile$RecordCompressWriter@24336556, spider_pages,6_74488371,1200029312876=org.apache.had
oop.io.SequenceFile$RecordCompressWriter@2a4203ab, spider_pages,2_561473281,1200054637086=org.apache.hadoop.io.SequenceFile$RecordCompressWriter@b972625, .META.,,1=org.apache.hadoop.io.SequenceFile$RecordCompressWriter@67a044a7, spider_pages,5_544278041,1199025825074=org.apache.hadoop.io.SequenceFile$RecordCompress
Writer@42be0008, spider_pages,49_567090611,1200028378117=org.apache.hadoop.io.SequenceFile$RecordCompressWriter@7bf4cbaa, spider_pages,5_566039401,1200058871594=org.apache.hadoop.io.SequenceFile$RecordCompressWriter@16479e88, spider_pages,59_360738971,1200073647952=org.apache.hadoop.io.SequenceFile$RecordCompressWr
iter@70494d14, spider_pages,59_302628011,1200073647951=org.apache.hadoop.io.SequenceFile$RecordCompressWriter@654670a8}
2008-01-12 02:17:44,124 DEBUG org.apache.hadoop.hbase.HLog: Applied 20000 edits
2008-01-12 02:17:49,076 DEBUG org.apache.hadoop.hbase.HLog: Applied 30000 edits
2008-01-12 02:17:49,078 DEBUG org.apache.hadoop.hbase.HLog: Applied 30003 total edits
2008-01-12 02:17:49,078 DEBUG org.apache.hadoop.hbase.HLog: Splitting 1 of 2: hdfs://tf1:7276/data/hbase1/log_XX.XX.XX.32_1200011947645_60020/hlog.dat.003
2008-01-12 02:17:52,574 DEBUG org.apache.hadoop.hbase.HLog: Applied 10000 edits
2008-01-12 02:17:59,822 WARN org.apache.hadoop.hbase.HMaster: Processing pending operations: ProcessServerShutdown of XX.XX.XX.32:60020
java.io.EOFException
        at java.io.DataInputStream.readFully(DataInputStream.java:180)
        at org.apache.hadoop.io.DataOutputBuffer$Buffer.write(DataOutputBuffer.java:56)
        at org.apache.hadoop.io.DataOutputBuffer.write(DataOutputBuffer.java:90)
        at org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1763)
        at org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1663)
        at org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1709)
        at org.apache.hadoop.hbase.HLog.splitLog(HLog.java:168)
        at org.apache.hadoop.hbase.HMaster$ProcessServerShutdown.process(HMaster.java:2144)
        at org.apache.hadoop.hbase.HMaster.run(HMaster.java:1056)
2008-01-12 02:17:59,822 DEBUG org.apache.hadoop.hbase.HMaster: Main processing loop: ProcessServerShutdown of XX.XX.XX.32:60020


It keeps doing the above over and over again.
I suppose we could skip bad logs... or just shut down master w/ a reason why.
Odd is that we seem to be well into the file  we&amp;amp;apos;ve run over 10000 edits... before we trip over the EOF.
I&amp;amp;apos;ve asked for an fsck to see what that says.</description>
			<version>0.1.0</version>
			<fixedVersion>0.1.0, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HLog.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
		</fixedFiles>
		<links>
			<link type="Incorporates" description="is part of">433</link>
		</links>
	</bug>
	<bug id="433" opendate="2008-02-09 23:03:11" fixdate="2008-03-12 17:07:20" resolution="Fixed">
		<buginformation>
			<summary>region server should deleted restore log after successfull restore</summary>
			<description>Currently we do not remove the restore log "oldlogfile.log" after we reopen a region after a crashed region server.
Suggestion would be to remove after we successfully flush of all the edits to a mapfile
so something like:
replay log 
memcache flush
deleted log
</description>
			<version>0.1.0</version>
			<fixedVersion>0.1.0, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HLog.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
		</fixedFiles>
		<links>
			<link type="Incorporates" description="incorporates">251</link>
			<link type="Incorporates" description="incorporates">236</link>
		</links>
	</bug>
	<bug id="27" opendate="2008-01-24 05:23:27" fixdate="2008-03-13 01:27:32" resolution="Fixed">
		<buginformation>
			<summary>[hbase] hregioninfo cell empty in meta table</summary>
			<description>When we notice one of these, instead of reporting on it over and over  see below  lets just axe the whole row.   Its never going to get better on its own.  We should also figure how these horked rows get manufactured.  Below is about split cells but also instances where servercode and servername are all thats left in a row.

2008-01-24 02:01:02,761 WARN org.apache.hadoop.hbase.HMaster:
info:regioninfo is empty; has keys: [info:splitA, info:splitB]
2008-01-24 02:01:02,761 WARN org.apache.hadoop.hbase.HMaster:
info:regioninfo is empty; has keys: [info:splitA]
2008-01-24 02:01:02,762 WARN org.apache.hadoop.hbase.HMaster:
info:regioninfo is empty; has keys: [info:splitA]
2008-01-24 02:01:02,762 WARN org.apache.hadoop.hbase.HMaster:
info:regioninfo is empty; has keys: [info:splitA]
2008-01-24 02:01:02,762 WARN org.apache.hadoop.hbase.HMaster:
info:regioninfo is empty; has keys: [info:splitA]
2008-01-24 02:01:02,763 WARN org.apache.hadoop.hbase.HMaster:
info:regioninfo is empty; has keys: [info:splitB]
2008-01-24 02:01:02,763 WARN org.apache.hadoop.hbase.HMaster:
info:regioninfo is empty; has keys: [info:splitA, info:splitB]
2008-01-24 02:01:02,763 WARN org.apache.hadoop.hbase.HMaster:
info:regioninfo is empty; has keys: [info:splitA, info:splitB]
2008-01-24 02:01:02,764 WARN org.apache.hadoop.hbase.HMaster:
info:regioninfo is empty; has keys: [info:splitA]
2008-01-24 02:01:02,764 WARN org.apache.hadoop.hbase.HMaster:
info:regioninfo is empty; has keys: [info:splitA, info:splitB]
2008-01-24 02:01:02,764 WARN org.apache.hadoop.hbase.HMaster:
info:regioninfo is empty; has keys: [info:splitB]
2008-01-24 02:01:02,765 WARN org.apache.hadoop.hbase.HMaster:
info:regioninfo is empty; has keys: [info:splitA]
2008-01-24 02:01:02,765 WARN org.apache.hadoop.hbase.HMaster:
info:regioninfo is empty; has keys: [info:splitA]
2008-01-24 02:01:02,765 WARN org.apache.hadoop.hbase.HMaster:
info:regioninfo is empty; has keys: [info:splitA]
2008-01-24 02:01:02,766 WARN org.apache.hadoop.hbase.HMaster:
info:regioninfo is empty; has keys: [info:splitA, info:splitB]
2008-01-24 02:01:02,766 WARN org.apache.hadoop.hbase.HMaster:
info:regioninfo is empty; has keys: [info:splitA, info:splitB]
2008-01-24 02:01:02,766 WARN org.apache.hadoop.hbase.HMaster:
info:regioninfo is empty; has keys: [info:splitB]
2008-01-24 02:01:02,767 WARN org.apache.hadoop.hbase.HMaster:
info:regioninfo is empty; has keys: [info:splitA, info:splitB]
2008-01-24 02:01:02,767 WARN org.apache.hadoop.hbase.HMaster:
info:regioninfo is empty; has keys: [info:splitB]
2008-01-24 02:01:02,767 WARN org.apache.hadoop.hbase.HMaster:
info:regioninfo is empty; has keys: [info:splitA, info:splitB]
2008-01-24 02:01:02,768 WARN org.apache.hadoop.hbase.HMaster:
info:regioninfo is empty; has keys: [info:splitB]
2008-01-24 02:01:02,768 WARN org.apache.hadoop.hbase.HMaster:
info:regioninfo is empty; has keys: [info:splitB]
2008-01-24 02:01:02,768 WARN org.apache.hadoop.hbase.HMaster:
info:regioninfo is empty; has keys: [info:splitA, info:splitB]
2008-01-24 02:01:02,769 WARN org.apache.hadoop.hbase.HMaster:
info:regioninfo is empty; has keys: [info:splitA, info:splitB]
2008-01-24 02:01:02,769 WARN org.apache.hadoop.hbase.HMaster:
info:regioninfo is empty; has keys: [info:splitA]
2008-01-24 02:01:02,769 WARN org.apache.hadoop.hbase.HMaster:
info:regioninfo is empty; has keys: [info:splitA, info:splitB]
2008-01-24 02:01:02,770 WARN org.apache.hadoop.hbase.HMaster:
info:regioninfo is empty; has keys: [info:splitA, info:splitB]
2008-01-24 02:01:02,770 WARN org.apache.hadoop.hbase.HMaster:
info:regioninfo is empty; has keys: [info:splitA]
2008-01-24 02:01:02,771 WARN org.apache.hadoop.hbase.HMaster:
info:regioninfo is empty; has keys: [info:splitA, info:splitB]
2008-01-24 02:01:02,771 WARN org.apache.hadoop.hbase.HMaster:
info:regioninfo is empty; has keys: [info:splitB]
2008-01-24 02:01:02,771 WARN org.apache.hadoop.hbase.HMaster:
info:regioninfo is empty; has keys: [info:splitA, info:splitB]
2008-01-24 02:01:02,772 WARN org.apache.hadoop.hbase.HMaster:
info:regioninfo is empty; has keys: [info:splitA]



</description>
			<version>0.1.0</version>
			<fixedVersion>0.1.0, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.ServerManager.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TableOperation.java</file>
			<file type="M">org.apache.hadoop.hbase.master.BaseScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ProcessServerShutdown.java</file>
			<file type="M">org.apache.hadoop.hbase.master.RowMap.java</file>
		</fixedFiles>
	</bug>
	<bug id="501" opendate="2008-03-08 02:32:17" fixdate="2008-03-13 19:37:24" resolution="Fixed">
		<buginformation>
			<summary>Empty region server address in info:server entry and a startcode of -1 in .META.</summary>
			<description>Manufactured a region empty server address and a startcode of -1 when a regionserver was slow to open a region and the alternative regionserver that had been asked open the region fails and reports CLOSE to the master.
Here&amp;amp;apos;s long version of story:
Region is enwiki_080103,CzQ7UPCw-AoIn2JzSEN_pV==.  Was originally on XX.XX.XX.184:60020 but this node ran out of memory (though it had 2G).

2008-03-08 00:29:39,472 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 60020, call batchUpdate(enwiki_071018,6q_ORe3mPzBTOnenVGS6zk==,1204860472398, 9223372036854775807, org.apache.hadoop.hbase.io.BatchUpdate@126d2380) from XX.XX.XX.233:54292: error: java.io.IOException: java.lang.OutOfMemoryError: Java heap space
java.io.IOException: java.lang.OutOfMemoryError: Java heap space
        at java.lang.Object.clone(Native Method)
        at java.lang.reflect.Method.getParameterTypes(Unknown Source)
        at java.lang.Class.searchMethods(Unknown Source)
        at java.lang.Class.getMethod0(Unknown Source)
        at java.lang.Class.getMethod(Unknown Source)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:408)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:910)
2008-03-08 00:29:39,472 WARN org.apache.hadoop.ipc.Server: Out of Memory in server select
java.lang.OutOfMemoryError: Java heap space
        at java.util.HashMap.newKeyIterator(Unknown Source)
        at java.util.HashMap$KeySet.iterator(Unknown Source)
        at java.util.HashSet.iterator(Unknown Source)
        at sun.nio.ch.SelectorImpl.processDeregisterQueue(Unknown Source)
        at sun.nio.ch.PollSelectorImpl.doSelect(Unknown Source)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(Unknown Source)
        at sun.nio.ch.SelectorImpl.select(Unknown Source)
        at sun.nio.ch.SelectorImpl.select(Unknown Source)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:323)
2008-03-08 00:31:15,300 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 60020, call batchUpdate(enwiki_080103_meta,,1204867086244, 9223372036854775807, org.apache.hadoop.hbase.io.BatchUpdate@2d13981b) from XX.XX.XX.233:54810: error: java.io.IOException: java.lang.OutOfMemoryError: Java heap space
java.io.IOException: java.lang.OutOfMemoryError: Java heap space
        at java.lang.String.&amp;lt;init&amp;gt;(Unknown Source)
        at java.lang.StringBuilder.toString(Unknown Source)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:415)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:910)


Was given to XX.XX.XX.227 at 00:36:20 but this server is crazy replaying a bunch of edits (Need to stop emitting edits in HStore  496 removed outputting skipped edits).  It can&amp;amp;apos;t put the region up immediately.  Takes a long time. 
Then given to XX.XX.XX.183 at 00:37:26. It fails to open with:

2008-03-08 00:37:29,827 INFO org.apache.hadoop.hbase.HRegion: compaction completed on region enwiki_071018,AYtsfKtThdIJkVLUSKipA-==,1204860383810. Took 5sec
2008-03-08 00:37:29,943 ERROR org.apache.hadoop.hbase.HRegionServer: error opening region enwiki_080103,CzQ7UPCw-AoIn2JzSEN_pV==,1204865434985
org.apache.hadoop.ipc.RemoteException: java.io.IOException: Could not complete write to file /hbase/aa0-005-2.u.powerset.com/enwiki_080103/1578810967/page/mapfiles/5679937491167886060/data by DFSClient_-540201177
        at org.apache.hadoop.dfs.NameNode.complete(NameNode.java:341)
        at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
...


Sends a CLOSE to the master.
Then 227 says its successfully opened region.
Master says region server XX.XX.XX.227:60020 should not have opened region enwiki_080103,CzQ7UPCw-AoIn2JzSEN_pV==,1204865434985
Now the server field in META is empty.

 59 2008-03-08 00:38:09,167 DEBUG org.apache.hadoop.hbase.HMaster: HMaster.metaScanner regioninfo: {regionname: enwiki_080103,CzQ7UPCw-AoIn2JzSEN_pV==,1204865434985, startKey: &amp;lt;CzQ7UPCw-AoIn2JzSEN_pV==&amp;gt;, endKey: &amp;lt;DUwzKe-niVjzlXs1SvrvVk==&amp;gt;, encodedName: 1578810967, offline: true, tableDesc: {name: enwiki_080103,         families: {anchor:={name: anchor, max versions: 3, compression: NONE, in memory: false, max length: 2147483647, bloom filter: none}, misc:={name: misc, max versions: 3, compression: NONE, in memory: false, max length: 2147483647, bloom filter: none}, page:={name: page, max versions: 3, compression: NONE, i        n memory: false, max length: 2147483647, bloom filter: none}, redirect:={name: redirect, max versions: 3, compression: NONE, in memory: false, max length: 2147483647, bloom filter: none}}}}, server: , startCode: -1

</description>
			<version>0.1.0</version>
			<fixedVersion>0.1.0, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.Sleeper.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HLog.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ProcessRegionClose.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ProcessServerShutdown.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ServerManager.java</file>
		</fixedFiles>
	</bug>
	<bug id="510" opendate="2008-03-13 16:41:06" fixdate="2008-03-14 03:43:24" resolution="Fixed">
		<buginformation>
			<summary>HConnectionManger.listTables returns empty list if exception (though there may be many tables present)</summary>
			<description>Its a problem because commonly a check for existence will get list of current tables.
Yesterday saw problem when .META. went off line.  A piece of client code was asking for list of tables when .META. was offline, it was getting back an empty list because listTables do while was seeing &amp;amp;apos;org.apache.hadoop.hbase.NotServingRegionException: .META.,,1&amp;amp;apos;
Problem is the do while in HCM.listTables goes as long as startRow does not equal LAST_ROW but startRow is initialized with EMPTY_START_ROW which is equal to LAST_ROW.
</description>
			<version>0.1.0</version>
			<fixedVersion>0.1.0, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionManager.java</file>
		</fixedFiles>
	</bug>
	<bug id="516" opendate="2008-03-14 04:09:19" fixdate="2008-03-14 06:07:04" resolution="Fixed">
		<buginformation>
			<summary>HStoreFile.finalKey does not update the final key if it is not the top region of a split region</summary>
			<description>HStoreKey.finalKey does not update the key value if the HStoreFile is not a part of the top of a split region.</description>
			<version>0.1.0</version>
			<fixedVersion>0.1.0, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStoreFile.java</file>
		</fixedFiles>
	</bug>
	<bug id="525" opendate="2008-03-17 22:31:02" fixdate="2008-03-18 00:13:59" resolution="Fixed">
		<buginformation>
			<summary>HTable.getRow(Text) does not work</summary>
			<description>Updated from SVN to find that Hbase.getRow(Text) always return empty map.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
		</fixedFiles>
	</bug>
	<bug id="524" opendate="2008-03-17 20:14:28" fixdate="2008-03-18 19:34:14" resolution="Fixed">
		<buginformation>
			<summary>Problems with getFull</summary>
			<description>There are some issues with the implementation of getFull in HStore. 

If the loop encounters a deleted cell, it stops iterating. This correctly handles deletes, but then accidentally masks away any cells of different qualifiers that would come afterward
Since the mapfiles are search oldest to newest, and the results map is only updated when there isn&amp;amp;apos;t already a value in the results map for for the cell we&amp;amp;apos;re currently looking at, older values actually take precedence over newer ones. This may be fixed by simply reversing the order of mapfiles traversed to newest to oldest.

</description>
			<version>0.1.0</version>
			<fixedVersion>0.1.0, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestGet2.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Memcache.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHMemcache.java</file>
		</fixedFiles>
	</bug>
	<bug id="529" opendate="2008-03-18 19:47:21" fixdate="2008-03-18 21:43:37" resolution="Fixed">
		<buginformation>
			<summary>RegionServer needs to recover if datanode goes down</summary>
			<description>If I take down a datanode, the regionserver will repeatedly return this error:
java.io.IOException: Stream closed.
        at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.isClosed(DFSClient.java:1875)
        at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.writeChunk(DFSClient.java:2096)
        at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunk(FSOutputSummer.java:141)
        at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:124)
        at org.apache.hadoop.fs.FSOutputSummer.write1(FSOutputSummer.java:112)
        at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:86)
        at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:41)
        at java.io.DataOutputStream.write(Unknown Source)
        at org.apache.hadoop.io.SequenceFile$Writer.append(SequenceFile.java:977)
        at org.apache.hadoop.hbase.HLog.append(HLog.java:377)
        at org.apache.hadoop.hbase.HRegion.update(HRegion.java:1455)
        at org.apache.hadoop.hbase.HRegion.batchUpdate(HRegion.java:1259)
        at org.apache.hadoop.hbase.HRegionServer.batchUpdate(HRegionServer.java:1433)
        at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:413)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:910)
It appears that hbase/dfsclient does not attempt to reopen the stream.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HLog.java</file>
		</fixedFiles>
		<links>
			<link type="Cloners" description="is a clone of">497</link>
		</links>
	</bug>
	<bug id="528" opendate="2008-03-18 19:37:11" fixdate="2008-03-18 21:47:27" resolution="Fixed">
		<buginformation>
			<summary>table &amp;apos;does not exist&amp;apos; when it does</summary>
			<description>This one I&amp;amp;apos;ve seen a few times.  In hql, I do show tables and it shows my table.  I then try to do a select against the table and hql reports table does not exist.  Digging, whats happening is that the getClosest facility is failing to find the first table region in the .META. table.  I hacked up a region reading tool  attached (for 0.1 branch)  and tried it against but a copy and the actual instance of the region and it could do the getClosest fine.  I&amp;amp;apos;m pretty sure I restarted the HRS and when it came up again, the master had given it again the .META. and again was failing to find the first region in the table (Looked around in server logs and it seemed &amp;amp;apos;healthy&amp;amp;apos;).</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.HRegionInterface.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHMemcache.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestGet2.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Memcache.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
		</fixedFiles>
		<links>
			<link type="Cloners" description="is a clone of">514</link>
		</links>
	</bug>
	<bug id="537" opendate="2008-03-21 04:42:19" fixdate="2008-03-21 21:43:25" resolution="Fixed">
		<buginformation>
			<summary>We no longer wait on hdfs to exit safe mode</summary>
			<description>We used wait on hdfs to exit safe mode before going on to startup hbase but this feature is broken since we moved out of hadoop contrib.  Now when you try start with hdfs in safe mode you get:

08/03/21 04:39:56 FATAL hbase.HMaster: Not starting HMaster because:
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.dfs.SafeModeException: Cannot create directory /hbase010. Name node is in safe mode.
Safe mode will be turned off automatically.
        at org.apache.hadoop.dfs.FSNamesystem.mkdirsInternal(FSNamesystem.java:1571)
        at org.apache.hadoop.dfs.FSNamesystem.mkdirs(FSNamesystem.java:1559)
        at org.apache.hadoop.dfs.NameNode.mkdirs(NameNode.java:422)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)


If you are lucky, it appears on STDOUT/ERR but may just be stuffed into logs and all looks like its running properly.
Noticed first by Lars George.</description>
			<version>0.1.0</version>
			<fixedVersion>0.1.0, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
		</fixedFiles>
	</bug>
	<bug id="527" opendate="2008-03-18 00:10:32" fixdate="2008-03-22 22:36:18" resolution="Fixed">
		<buginformation>
			<summary>RegexpRowFilter does not work when there are columns from multiple families</summary>
			<description>If there are multiple column families, then creating a scanner with a RegexpRowFilter to match column values will mistakenly filter other columns.</description>
			<version>0.1.0</version>
			<fixedVersion>0.1.0, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.filter.InclusiveStopRowFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.StopRowFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.RowFilterSet.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStoreScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.PageRowFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.WhileMatchRowFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.RegExpRowFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.RowFilterInterface.java</file>
		</fixedFiles>
		<links>
			<link type="Incorporates" description="incorporates">476</link>
			<link type="Reference" description="relates to">476</link>
		</links>
	</bug>
	<bug id="476" opendate="2008-02-29 18:26:48" fixdate="2008-03-22 22:37:37" resolution="Fixed">
		<buginformation>
			<summary>RegexpRowFilter behaves incorectly when there are multiple store files</summary>
			<description>I noticed that after running some table Map/Reduces, then using a
RegExpRowFilter to scan through the table,  the scanner misses
rows when its columns are in different stores.
This (rather convoluted) unit test provokes the behavior.

Set memcache flush size small to trigger multiple stores
put in 10 row with 2 columns. Each row has the same value for col1 (which the RowFilter wants to match)
Scan with and without the filter to be sure that we get all the rows with each
Run an identity table M/R 10 times to fill up the memcache and trigger flush.
Scan again. This time the filter does not pickup anything.

Attaching the log from this run as well.</description>
			<version>0.1.0</version>
			<fixedVersion>0.1.0, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.filter.InclusiveStopRowFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.StopRowFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.RowFilterSet.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStoreScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.PageRowFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.WhileMatchRowFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.RegExpRowFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.RowFilterInterface.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
		</fixedFiles>
		<links>
			<link type="Incorporates" description="is part of">527</link>
			<link type="Reference" description="is related to">527</link>
		</links>
	</bug>
	<bug id="534" opendate="2008-03-20 16:56:21" fixdate="2008-03-24 22:32:43" resolution="Fixed">
		<buginformation>
			<summary>Double-assignment at SPLIT-time (WAS: Stores retaining references to long-deleted mapfiles)</summary>
			<description>Saw the following on the Lars clusters (He&amp;amp;apos;s up on 0.16.1 and very recent 0.1 branch) trying to run a scan over all his content:

java.io.IOException: java.io.IOException: HStoreScanner failed construction
        at org.apache.hadoop.hbase.HStore$StoreFileScanner.&amp;lt;init&amp;gt;(HStore.java:2241)
        at org.apache.hadoop.hbase.HStore$HStoreScanner.&amp;lt;init&amp;gt;(HStore.java:2362)
        at org.apache.hadoop.hbase.HStore.getScanner(HStore.java:2152)
        at org.apache.hadoop.hbase.HRegion$HScanner.&amp;lt;init&amp;gt;(HRegion.java:1640)
        at org.apache.hadoop.hbase.HRegion.getScanner(HRegion.java:1214)
        at org.apache.hadoop.hbase.HRegionServer.openScanner(HRegionServer.java:1448)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:585)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:413)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:910)
Caused by: java.io.FileNotFoundException: File hdfs://lv1-xen-pdc-2.worldlingo.com:9000/hbase/pdc-docs/1733592281/contents/mapfiles/3435064940161142159/data does not exist.
        at org.apache.hadoop.dfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:341)
        at org.apache.hadoop.fs.FileSystem.getLength(FileSystem.java:538)
        at org.apache.hadoop.io.SequenceFile$Reader.&amp;lt;init&amp;gt;(SequenceFile.java:1387)
        at org.apache.hadoop.io.SequenceFile$Reader.&amp;lt;init&amp;gt;(SequenceFile.java:1382)
        at org.apache.hadoop.io.MapFile$Reader.&amp;lt;init&amp;gt;(MapFile.java:254)
        at org.apache.hadoop.io.MapFile$Reader.&amp;lt;init&amp;gt;(MapFile.java:242)
        at org.apache.hadoop.hbase.HStoreFile$HbaseMapFile$HbaseReader.&amp;lt;init&amp;gt;(HStoreFile.java:600)
        at org.apache.hadoop.hbase.HStoreFile$BloomFilterMapFile$Reader.&amp;lt;init&amp;gt;(HStoreFile.java:655)
        at org.apache.hadoop.hbase.HStoreFile$HalfMapFileReader.&amp;lt;init&amp;gt;(HStoreFile.java:758)
        at org.apache.hadoop.hbase.HStoreFile.getReader(HStoreFile.java:424)
        at org.apache.hadoop.hbase.HStore$StoreFileScanner.&amp;lt;init&amp;gt;(HStore.java:2216)
        ... 11 more

        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:494)
        at org.apache.hadoop.hbase.RemoteExceptionHandler.decodeRemoteException(RemoteExceptionHandler.java:82)
        at org.apache.hadoop.hbase.HTable$ClientScanner.nextScanner(HTable.java:874)
        at org.apache.hadoop.hbase.HTable$ClientScanner.next(HTable.java:915)
        at org.apache.hadoop.hbase.hql.SelectCommand.scanPrint(SelectCommand.java:233)
        at org.apache.hadoop.hbase.hql.SelectCommand.execute(SelectCommand.java:100)
        at org.apache.hadoop.hbase.hql.HQLClient.executeQuery(HQLClient.java:50)
        at org.apache.hadoop.hbase.Shell.main(Shell.java:114)


The scanner breaks when it hits the above exception.  The odd thing is that the referenced mapfile is out of a region that was deleted 4 days ago after purportedly all references had been let go:

2008-03-16 15:13:36,744 DEBUG org.apache.hadoop.hbase.HRegion: DELETING region hdfs://lv1-xen-pdc-2.worldlingo.com:9000/hbase/pdc-docs/1733592281

</description>
			<version>0.1.0</version>
			<fixedVersion>0.1.0, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.RegionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ServerManager.java</file>
		</fixedFiles>
	</bug>
	<bug id="550" opendate="2008-03-29 17:38:41" fixdate="2008-03-31 19:25:01" resolution="Fixed">
		<buginformation>
			<summary>EOF trying to read reconstruction log stops region deployment</summary>
			<description>Regions are just being reallocated over and over again because log file is hosed:

2008-03-29 10:37:53,762 ERROR org.apache.hadoop.hbase.HRegionServer: error opening region pdc-docs,EP92114798NWA1,1205741702057
java.io.EOFException
        at java.io.DataInputStream.readFully(DataInputStream.java:178)
        at java.io.DataInputStream.readFully(DataInputStream.java:152)
        at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1421)
        at org.apache.hadoop.io.SequenceFile$Reader.&amp;lt;init&amp;gt;(SequenceFile.java:1398)
        at org.apache.hadoop.io.SequenceFile$Reader.&amp;lt;init&amp;gt;(SequenceFile.java:1387)
        at org.apache.hadoop.io.SequenceFile$Reader.&amp;lt;init&amp;gt;(SequenceFile.java:1382)
        at org.apache.hadoop.hbase.HStore.doReconstructionLog(HStore.java:839)
        at org.apache.hadoop.hbase.HStore.&amp;lt;init&amp;gt;(HStore.java:773)
        at org.apache.hadoop.hbase.HRegion.&amp;lt;init&amp;gt;(HRegion.java:389)
        at org.apache.hadoop.hbase.HRegionServer.openRegion(HRegionServer.java:1159)        at org.apache.hadoop.hbase.HRegionServer$Worker.run(HRegionServer.java:1105)
        at java.lang.Thread.run(Thread.java:595)

</description>
			<version>0.1.0</version>
			<fixedVersion>0.1.1, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
		</fixedFiles>
	</bug>
	<bug id="551" opendate="2008-03-29 22:00:53" fixdate="2008-03-31 20:53:05" resolution="Fixed">
		<buginformation>
			<summary>Master stuck splitting server logs in shutdown loop; on each iteration, edits are aggregated up into the millions</summary>
			<description>Lars cluster is sick with master trying to split logs.   The logs its replaying have millions of edits in them.  
Here is sample from log.   First we get the shutdown and then in the shutdown process, we start to split up the shutdown servers log:

2008-03-28 16:29:45,305 INFO org.apache.hadoop.hbase.HMaster: process shutdown of server 192.168.105.37:60020: logSplit: false, rootRes
canned: false, numberOfMetaRegions: 1, onlineMetaRegions.size(): 1
2008-03-28 16:29:45,310 INFO org.apache.hadoop.hbase.HLog: splitting 3 log(s) in hdfs://lv1-xen-pdc-2.worldlingo.com:9000/hbase/log_192
.168.105.37_1206741382563_60020
2008-03-28 16:29:45,311 DEBUG org.apache.hadoop.hbase.HLog: Splitting 0 of 3: hdfs://lv1-xen-pdc-2.worldlingo.com:9000/hbase/log_192.16
8.105.37_1206741382563_60020/hlog.dat.002
2008-03-28 16:29:45,380 DEBUG org.apache.hadoop.hbase.HLog: Creating new log file writer for path hdfs://lv1-xen-pdc-2.worldlingo.com:9
000/hbase/pdc-docs/488338803/oldlogfile.log and region pdc-docs,EP01108687NWA2,1205739919655
2008-03-28 16:29:45,390 DEBUG org.apache.hadoop.hbase.HLog: Creating new log file writer for path hdfs://lv1-xen-pdc-2.worldlingo.com:9
000/hbase/pdc-docs/447465883/oldlogfile.log and region pdc-docs,EP01900680NWA1,1205754584444
2008-03-28 16:29:45,403 DEBUG org.apache.hadoop.hbase.HLog: Creating new log file writer for path hdfs://lv1-xen-pdc-2.worldlingo.com:9
000/hbase/pdc-docs/2035706226/oldlogfile.log and region pdc-docs,EP01119588NWA2,1205754281917
2008-03-28 16:29:45,428 DEBUG org.apache.hadoop.hbase.HLog: Creating new log file writer for path hdfs://lv1-xen-pdc-2.worldlingo.com:9
000/hbase/pdc-docs/437772136/oldlogfile.log and region pdc-docs,EP00200190NWA2,120576451593
...


We open a file in each region to take edits.  We then start replaying the 3 WAL files from the regionserver.
On the second one, we get exception... 

2008-03-28 16:40:36,537 WARN org.apache.hadoop.hbase.HLog: Old log file hdfs://lv1-xen-pdc-2.worldlingo.com:9000/hbase/pdc-docs/1045858
46/oldlogfile.log already exists. Copying existing file to new file
2008-03-28 16:40:36,545 DEBUG org.apache.hadoop.hbase.HLog: Creating new log file writer for path hdfs://lv1-xen-pdc-2.worldlingo.com:9
000/hbase/pdc-docs/104585846/oldlogfile.log and region pdc-docs,EP96104830NWA1,1205768785572
2008-03-28 16:40:36,979 DEBUG org.apache.hadoop.hbase.HLog: Copied 220000 edits
2008-03-28 16:40:38,853 DEBUG org.apache.hadoop.hbase.HLog: Applied 222812 total edits
2008-03-28 16:40:38,853 DEBUG org.apache.hadoop.hbase.HLog: Splitting 1 of 3: hdfs://lv1-xen-pdc-2.worldlingo.com:9000/hbase/log_192.16
8.105.37_1206741382563_60020/hlog.dat.003
2008-03-28 16:40:56,883 WARN org.apache.hadoop.hbase.HLog: Old log file hdfs://lv1-xen-pdc-2.worldlingo.com:9000/hbase/pdc-docs/2118067
194/oldlogfile.log already exists. Copying existing file to new file
2008-03-28 16:40:56,891 DEBUG org.apache.hadoop.hbase.HLog: Creating new log file writer for path hdfs://lv1-xen-pdc-2.worldlingo.com:9
000/hbase/pdc-docs/2118067194/oldlogfile.log and region pdc-docs,EP97302517NWA2,1205726201776
2008-03-28 16:41:12,910 DEBUG org.apache.hadoop.hbase.HLog: Applied 36638 total edits
2008-03-28 16:41:12,910 DEBUG org.apache.hadoop.hbase.HLog: Splitting 2 of 3: hdfs://lv1-xen-pdc-2.worldlingo.com:9000/hbase/log_192.16
8.105.37_1206741382563_60020/hlog.dat.004
2008-03-28 16:41:18,684 WARN org.apache.hadoop.hbase.HMaster: Processing pending operations: ProcessServerShutdown of 192.168.105.37:60
020
java.io.EOFException
        at java.io.DataInputStream.readFully(DataInputStream.java:178)
        at org.apache.hadoop.io.DataOutputBuffer$Buffer.write(DataOutputBuffer.java:56)
        at org.apache.hadoop.io.DataOutputBuffer.write(DataOutputBuffer.java:90)
        at org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1829)
        at org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1729)
        at org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1775)
        at org.apache.hadoop.hbase.HLog.splitLog(HLog.java:540)
        at org.apache.hadoop.hbase.HMaster$ProcessServerShutdown.process(HMaster.java:2167)
        at org.apache.hadoop.hbase.HMaster.run(HMaster.java:1085)



A finally clause makes sure we close up all the new files we&amp;amp;apos;ve made in all regions.  These new files have accumulated some edits from the splitting of the first file.
Because we got an exception, the shutdown processing runs again.
Because regions have files in place with edits, we won&amp;amp;apos;t overwrite them second time through.  We instead copy the old into a new file to which we start appending until the exception happens again.
After a couple of hours, we&amp;amp;apos;re up into the millions of edits.</description>
			<version>0.1.0</version>
			<fixedVersion>0.1.1, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HLog.java</file>
		</fixedFiles>
	</bug>
	<bug id="505" opendate="2008-03-11 21:52:58" fixdate="2008-04-01 00:07:32" resolution="Fixed">
		<buginformation>
			<summary>Region assignments should never time out so long as the region server reports that it is processing the open request</summary>
			<description>Currently, when the master assigns a region to a region server, it extends the reassignment timeout when the region server reports that it is processing the open. This only happens once, and so if the region takes a long time to come on line due to a large set of transactions in the redo log or because the initial compaction takes a long time, the master will assign the region to another server when the reassignment timeout occurs.
Assigning a region to multiple region servers can easily corrupt the region. For example:
region server 1 is processing the redo log creating a new mapfile. It takes more than one interval to do so so the master assigns the region to region server 2. region server 2 starts processing the redo log creating essentially the same mapFile as region server 1, but with a different name. 
region server 2 can fail to open the region if region server 1 deletes the old log file or if it tries to open the new mapFile that region server 1 is creating.
region server 1 can fail to open the region if it tries to open the mapFile that region server 2 is creating.
Often region server 1 eventually succeeds and reports to the master that it has finished opening the region, but the master tells it to close that region because it has assigned it to another server. Region server 2 often fails to open the region, because the old log file has been deleted, or it fails to process the new map file created by region server 1.
Proposed solution:
During the open process the region server should send a MSG_PROCESS_OPEN with each heartbeat until the region is opened (when it sends MSG_REGION_OPEN). The master will extend the reassignment timeout with each MSG_PROCESS_OPEN it receives and will not assign the region to another server so long as it continues to receive heart beat messages from the region server processing the open.</description>
			<version>0.1.0</version>
			<fixedVersion>0.1.1, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.RegionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
		</fixedFiles>
	</bug>
	<bug id="552" opendate="2008-03-29 22:13:03" fixdate="2008-04-01 17:55:48" resolution="Fixed">
		<buginformation>
			<summary>Bloom filter bugs</summary>
			<description>There are some bugs in Bloom filters in the code that deals with initialization and (de)serialization.</description>
			<version>0.1.0</version>
			<fixedVersion>0.1.1, 0.2.1, 0.18.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.onelab.filter.DynamicBloomFilter.java</file>
			<file type="M">org.onelab.filter.Key.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">3063</link>
		</links>
	</bug>
	<bug id="452" opendate="2008-02-15 21:24:56" fixdate="2008-04-04 19:42:58" resolution="Fixed">
		<buginformation>
			<summary>"region offline" should throw IOException, not IllegalStateException</summary>
			<description>It would be nice if I could wrap my HTable.get calls in try {} catch (IOException e).  But that doesn&amp;amp;apos;t work, since I also need to catch IllegalStateException.  I think that any time there is something wrong with hbase, hbase calls should throw an IOException (or subclass thereof).  Things like IllegalStateException should be reserved for programmer error.</description>
			<version>0.1.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionManager.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">471</link>
		</links>
	</bug>
	<bug id="563" opendate="2008-04-04 21:50:16" fixdate="2008-04-04 21:56:30" resolution="Fixed">
		<buginformation>
			<summary>TestRowFilterAfterWrite erroneously sets master address to 0.0.0.0:60100 rather than relying on conf</summary>
			<description>TestRowFilterAfterWrite sets HConstants.MASTER_ADDRESS to 0.0.0.0:60100 rather than relying on the setting being in the configuration. Until the latest revision of hadoop-trunk this mysteriously worked. Removing this setting makes it work again.</description>
			<version>0.1.0</version>
			<fixedVersion>0.1.1, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.filter.TestRowFilterAfterWrite.java</file>
		</fixedFiles>
	</bug>
	<bug id="507" opendate="2008-03-13 06:26:06" fixdate="2008-04-05 02:13:55" resolution="Fixed">
		<buginformation>
			<summary>In master, there are a load of places where no sleep between retries</summary>
			<description>Here is an example:

 270308 2008-03-12 14:10:02,054 DEBUG org.apache.hadoop.hbase.HMaster: numberOfMetaRegions: 1, onlineMetaRegions.size(): 1                                                                                                                                             
270309 2008-03-12 14:10:02,054 DEBUG org.apache.hadoop.hbase.HMaster: process server shutdown scanning .META.,,1 on XX.XX.XX.184:60020 HMaster                                                                                                                        
270310 2008-03-12 14:10:02,056 DEBUG org.apache.hadoop.hbase.HMaster: process server shutdown scanning .META.,,1 on XX.XX.XX.184:60020 HMaster                                                                                                                        
270311 2008-03-12 14:10:02,057 DEBUG org.apache.hadoop.hbase.HMaster: process server shutdown scanning .META.,,1 on XX.XX.XX.184:60020 HMaster                                                                                                                        
270312 2008-03-12 14:10:02,059 DEBUG org.apache.hadoop.hbase.HMaster: process server shutdown scanning .META.,,1 on XX.XX.XX.184:60020 HMaster
270313 2008-03-12 14:10:02,060 DEBUG org.apache.hadoop.hbase.HMaster: process server shutdown scanning .META.,,1 on XX.XX.XX.184:60020 HMaster
270314 2008-03-12 14:10:02,062 WARN org.apache.hadoop.hbase.HMaster: Processing pending operations: ProcessServerShutdown of XX.XX.XX.180:60020                                                                                                                       
270315 org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException .META.,,1                                                                                                                                                 
270316         at org.apache.hadoop.hbase.HRegionServer.getRegion(HRegionServer.java:1606) 
...


Whats actually going on here is 5 retries without a wait in between (logging should include index numbering retry.  Seems to be a bunch of duplicated code around retrying that we might be able to fix with a Callable.  Jim Firby today suggested we do expotential backoffs in our retries. </description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.ProcessRegionStatusChange.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TableOperation.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ProcessRegionClose.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ProcessServerShutdown.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ProcessRegionOpen.java</file>
		</fixedFiles>
	</bug>
	<bug id="564" opendate="2008-04-05 03:31:23" fixdate="2008-04-07 21:09:04" resolution="Fixed">
		<buginformation>
			<summary>Adding a flush file of zero entries</summary>
			<description>Saw this in log in TRUNK:

    [junit] 2008-04-04 20:22:40,943 DEBUG [RegionServer:0.cacheFlusher] regionserver.HStore(676): Added 1403560700/text/8075392345773720818 with 0 entries, sequence id 537, data size 0.0, file size 110.0 for 1403560700/text


I thought that we&amp;amp;apos;d fixed flushing zero-entry files</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
		</fixedFiles>
	</bug>
	<bug id="573" opendate="2008-04-11 04:32:34" fixdate="2008-04-14 20:37:48" resolution="Fixed">
		<buginformation>
			<summary>HBase does not read hadoop-*.xml for dfs configuration after moving out hadoop/contrib</summary>
			<description>When HBase was in hadoop/contrib, the hbase script set both HADOOP_CONF_DIR
and HBASE_CONF_DIR to CLASSPATH, so that dfs&amp;amp;apos;s configuration can be loaded
correctly. However, when moved out hadoop/contrib, it only sets HBASE_CONF_DIR.
I can think of several possible solutions:
1) set HADOOP_CONF_DIR in hbase-env.sh, then add HADOOP_CONF_DIR to CLASSPATH as before
2) Instruct user to create links for hadoop-*.xml if they want to customize some dfs settings.
3) If only a small set of dfs confs are related to dfs&amp;amp;apos;s client, maybe they can be set via  hbase-site.xml, then hbase sets these for us when create a FileSystem obj.
Please see the thread "# of dfs replications when using hbase" on hbase-user@.
</description>
			<version>0.1.0</version>
			<fixedVersion>0.1.2, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapred.GroupingTableMap.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.IdentityTableMap.java</file>
		</fixedFiles>
	</bug>
	<bug id="12" opendate="2007-12-06 02:14:50" fixdate="2008-04-15 03:36:00" resolution="Fixed">
		<buginformation>
			<summary>when hbase regionserver restarts, it says "impossible state for createLease()"</summary>
			<description>I restarted a regionserver, and got this error in its logs:
org.apache.hadoop.ipc.RemoteException: java.io.IOException: java.lang.AssertionError: Impossible state for createLease(): Lease -435227488/-435227488 is still held.
        at org.apache.hadoop.hbase.Leases.createLease(Leases.java:145)
        at org.apache.hadoop.hbase.HMaster.regionServerStartup(HMaster.java:1278
)
        at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:379)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:596)
        at org.apache.hadoop.ipc.Client.call(Client.java:482)
        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:184)
        at $Proxy0.regionServerStartup(Unknown Source)
        at org.apache.hadoop.hbase.HRegionServer.reportForDuty(HRegionServer.jav
a:1025)
        at org.apache.hadoop.hbase.HRegionServer.run(HRegionServer.java:659)
        at java.lang.Thread.run(Unknown Source)</description>
			<version>0.2.0</version>
			<fixedVersion>0.1.2, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.Leases.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ServerManager.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">495</link>
		</links>
	</bug>
	<bug id="575" opendate="2008-04-11 17:52:15" fixdate="2008-04-15 21:43:30" resolution="Fixed">
		<buginformation>
			<summary>hbase master dies with stack overflow error if rootdir isn&amp;apos;t qualified</summary>
			<description>With a relative rootdir (/hbase/), the hbase master throws this on startup:
08/04/11 17:53:00 ERROR hbase.HMaster: Can not start master
java.lang.reflect.InvocationTargetException
        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)
        at java.lang.reflect.Constructor.newInstance(Unknown Source)
        at org.apache.hadoop.hbase.HMaster.doMain(HMaster.java:3329)
        at org.apache.hadoop.hbase.HMaster.main(HMaster.java:3363)
Caused by: java.lang.StackOverflowError
        at java.net.URI$Parser.checkChars(Unknown Source)</description>
			<version>0.1.1</version>
			<fixedVersion>0.1.2, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.FSUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
		</fixedFiles>
	</bug>
	<bug id="532" opendate="2008-03-19 05:33:16" fixdate="2008-04-17 03:20:52" resolution="Fixed">
		<buginformation>
			<summary>Odd interaction between HRegion.get, HRegion.deleteAll and compactions</summary>
			<description>If you apply the patch for HBASE-483 to the 0.1 branch and comment out lines 309 and 315 of MetaUtils.java (which force compactions of the root and meta regions respectively), TestMergeTool fails. Why forcing compactions makes the test succeed is a mystery to me.</description>
			<version>0.1.1</version>
			<fixedVersion>0.1.2, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.MultiRegionTable.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStoreScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HAbstractScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Flusher.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
			<file type="D">org.apache.hadoop.hbase.regionserver.CacheFlushListener.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Memcache.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHMemcache.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.InternalScanner.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">29</link>
			<link type="Reference" description="is related to">483</link>
		</links>
	</bug>
	<bug id="590" opendate="2008-04-17 21:36:47" fixdate="2008-04-17 22:14:35" resolution="Fixed">
		<buginformation>
			<summary>HBase migration tool does not get correct FileSystem or root directory if configuration is not correct.</summary>
			<description>The HBase migration tool does not validate hbase.rootdir as a valid URI that contains a scheme (e.g., file:// or hdfs://) and fails to find the root directory and the file system if hbase.rootdir is not a URI.</description>
			<version>0.1.1</version>
			<fixedVersion>0.1.2, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.Migrate.java</file>
		</fixedFiles>
	</bug>
	<bug id="595" opendate="2008-04-18 23:24:59" fixdate="2008-04-21 16:43:43" resolution="Fixed">
		<buginformation>
			<summary>RowFilterInterface.rowProcessed() is called *before* fhe final filtering decision is made</summary>
			<description>rowProcessed is called in HStoreScanner, however, the final filtering decision is not made until the full row has been assembled in HRegion</description>
			<version>0.1.1</version>
			<fixedVersion>0.1.2, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStoreScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
		</fixedFiles>
	</bug>
	<bug id="565" opendate="2008-04-05 21:06:36" fixdate="2008-04-23 22:40:20" resolution="Duplicate">
		<buginformation>
			<summary>Move Table Schema out of HRegionInfo</summary>
			<description>Every HRI carries a HTableDescriptor instance.  When a Region context needs a table descriptor, doesn&amp;amp;apos;t have far to go.  Move the HTD out of HRI and when wanted, go elsewhere to go get it.
In Bigtable paper, Schema is stored over in Chubby.  Could run a Zookeeper instance easy-enough and store it there.  Would run on master.  ZooKeeper snapshots its in-memory database to local director on disk  not DFS.  If a ZooKeeper cluster, then that should protect against loss.  Master could tell regionservers the address of the zookeeper instance to use (as it does other vitals currently).  Later we could add the indirection so zookeeper is where regionservers register themselves on startup and master could watch here for the coming and going of servers.
Or, we could store the schema in DFS.  Good thing would be replication of critical data and an hbasck tool could read the file to learn table schema (Would be awkward having to read zookeeper format out on local filesystem).  Downside would be that any change in schema would require offlining unless we develop a message that the master could send regionservers to notify them of of minor schema changes  e.g. flip to being memory-based or to being compressed or that two column families are now of a single locality group (Zookeeper has the watcher mechanism where regionservers could &amp;amp;apos;notice&amp;amp;apos; schema changes).</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegionInfo.java</file>
			<file type="M">org.apache.hadoop.hbase.HRegionInfo.java</file>
			<file type="M">org.apache.hadoop.hbase.util.FSUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestFSTableDescriptors.java</file>
			<file type="M">org.apache.hadoop.hbase.MultiRegionTable.java</file>
			<file type="M">org.apache.hadoop.hbase.avro.AvroServer.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestMergeTable.java</file>
			<file type="M">org.apache.hadoop.hbase.avro.TestAvroServer.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestMergeTool.java</file>
			<file type="M">org.apache.hadoop.hbase.master.handler.TableAddFamilyHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="M">org.apache.hadoop.hbase.TestRegionRebalancing.java</file>
			<file type="M">org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
			<file type="M">org.apache.hadoop.hbase.master.MasterServices.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.java</file>
			<file type="M">org.apache.hadoop.hbase.util.HMerge.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestSplitTransaction.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
			<file type="M">org.apache.hadoop.hbase.master.CatalogJanitor.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.master.handler.ModifyTableHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.handler.OpenMetaHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.handler.OpenRootHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.handler.TestOpenRegionHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestStore.java</file>
			<file type="M">org.apache.hadoop.hbase.master.AssignmentManager.java</file>
			<file type="M">org.apache.hadoop.hbase.util.MetaUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.master.handler.DeleteTableHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestWALReplay.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseTestCase.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestCompactSelection.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.TestCoprocessorInterface.java</file>
			<file type="M">org.apache.hadoop.hbase.master.handler.TableModifyFamilyHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.master.handler.TableDeleteFamilyHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.util.Merge.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.TestWALObserver.java</file>
			<file type="M">org.apache.hadoop.hbase.master.SplitLogManager.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestWALObserver.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
			<file type="M">org.apache.hadoop.hbase.util.HBaseFsck.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
			<file type="M">org.apache.hadoop.hbase.catalog.MetaEditor.java</file>
			<file type="M">org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestWideScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.TestColumnPrefixFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestScannerTimeout.java</file>
			<file type="M">org.apache.hadoop.hbase.util.Writables.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HConnection.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
			<file type="M">org.apache.hadoop.hbase.master.handler.OpenedRegionHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.master.handler.ClosedRegionHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestRSStatusServlet.java</file>
			<file type="M">org.apache.hadoop.hbase.HConstants.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestMasterStatusServlet.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestTimestamp.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestHLog.java</file>
			<file type="M">org.apache.hadoop.hbase.client.MetaScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.Replication.java</file>
			<file type="M">org.apache.hadoop.hbase.client.UnmodifyableHRegionInfo.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.LogRoller.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManager.java</file>
			<file type="M">org.apache.hadoop.hbase.io.HbaseObjectWritable.java</file>
			<file type="M">org.apache.hadoop.hbase.TimestampTestBase.java</file>
			<file type="M">org.apache.hadoop.hbase.TestCompare.java</file>
			<file type="M">org.apache.hadoop.hbase.TestScanMultipleVersions.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.TestRegionObserverStacking.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.TestDependentColumnFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.WALObserver.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestMultipleTimestamps.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestResettingCounters.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
			<file type="M">org.apache.hadoop.hbase.TestSerialization.java</file>
			<file type="M">org.apache.hadoop.hbase.util.RegionSplitter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.TestFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.catalog.MetaReader.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestColumnSeeking.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.TestRegionObserverInterface.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestGetClosestAtOrBefore.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestLoadBalancer.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.model.TestTableRegionModel.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.HMasterInterface.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">451</link>
		</links>
	</bug>
	<bug id="608" opendate="2008-04-30 16:42:46" fixdate="2008-05-01 04:19:54" resolution="Fixed">
		<buginformation>
			<summary>HRegionServer::getThisIP() checks hadoop config var for dns interface name</summary>
			<description>The getThisIP() method of the HRegionServer class checks for the hadoop config var "dfs.datanode.dns.interface" rather than an hbase-specific configuration property.  I propose a new config var called "hbase.regionserver.dns.interface" to check instead.  Will attach patch shortly.</description>
			<version>0.1.1</version>
			<fixedVersion>0.1.2, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
		</fixedFiles>
	</bug>
	<bug id="618" opendate="2008-05-07 04:26:50" fixdate="2008-05-07 17:01:10" resolution="Fixed">
		<buginformation>
			<summary>We always compact if 2 files, regardless of the compaction threshold setting</summary>
			<description>We will always compact if there are two files in a store.  Here is an illustration from a loading run against 0.1.2 candidate:

2008-05-06 18:25:42,255 INFO org.apache.hadoop.hbase.HRegion: starting compaction on region category_rule_pricebin_statistics,,1210116131965
2008-05-06 18:25:42,259 DEBUG org.apache.hadoop.hbase.HStore: started compaction of 2 files [329657396/confidence_interval/1251369679869294899, 329657396/confidence_interval/5238351815319958452] into /hbase/category_rule_pricebin_statistics/compaction.dir/329657396/confidence_interval/mapfiles/6688946093979715350
2008-05-06 18:25:46,223 DEBUG org.apache.hadoop.hbase.HStore: moving /hbase/category_rule_pricebin_statistics/compaction.dir/329657396/confidence_interval/mapfiles/6688946093979715350 to /hbase/category_rule_pricebin_statistics/329657396/confidence_interval/mapfiles/6019580165435904305
2008-05-06 18:25:46,329 DEBUG org.apache.hadoop.hbase.HStore: started compaction of 2 files [329657396/rule_id/4877828519309794708, 329657396/rule_id/3736239181369788409] into /hbase/category_rule_pricebin_statistics/compaction.dir/329657396/rule_id/mapfiles/6451418039787481756
2008-05-06 18:25:50,273 DEBUG org.apache.hadoop.hbase.HStore: moving /hbase/category_rule_pricebin_statistics/compaction.dir/329657396/rule_id/mapfiles/6451418039787481756 to /hbase/category_rule_pricebin_statistics/329657396/rule_id/mapfiles/1365174520347083269
2008-05-06 18:25:50,338 DEBUG org.apache.hadoop.hbase.HStore: started compaction of 2 files [329657396/hidden_variable/7348598912095388790, 329657396/hidden_variable/1402264537929464657] into /hbase/category_rule_pricebin_statistics/compaction.dir/329657396/hidden_variable/mapfiles/7895992615693344978
2008-05-06 18:25:54,103 DEBUG org.apache.hadoop.hbase.HStore: moving /hbase/category_rule_pricebin_statistics/compaction.dir/329657396/hidden_variable/mapfiles/7895992615693344978 to /hbase/category_rule_pricebin_statistics/329657396/hidden_variable/mapfiles/4450886729060218942
2008-05-06 18:25:54,155 DEBUG org.apache.hadoop.hbase.HStore: started compaction of 2 files [329657396/category_id/6976628214412388959, 329657396/category_id/8426537623290869905] into /hbase/category_rule_pricebin_statistics/compaction.dir/329657396/category_id/mapfiles/4017716533879305176
2008-05-06 18:25:57,698 DEBUG org.apache.hadoop.hbase.HStore: moving /hbase/category_rule_pricebin_statistics/compaction.dir/329657396/category_id/mapfiles/4017716533879305176 to /hbase/category_rule_pricebin_statistics/329657396/category_id/mapfiles/657561173732096591
2008-05-06 18:25:57,747 DEBUG org.apache.hadoop.hbase.HStore: started compaction of 2 files [329657396/price_bin_id/165701488423589566, 329657396/price_bin_id/5537046322320665760] into /hbase/category_rule_pricebin_statistics/compaction.dir/329657396/price_bin_id/mapfiles/3214618236668106036
2008-05-06 18:26:01,135 DEBUG org.apache.hadoop.hbase.HStore: moving /hbase/category_rule_pricebin_statistics/compaction.dir/329657396/price_bin_id/mapfiles/3214618236668106036 to /hbase/category_rule_pricebin_statistics/329657396/price_bin_id/mapfiles/8727588456978537416
2008-05-06 18:26:01,181 INFO org.apache.hadoop.hbase.HRegion: compaction completed on region category_rule_pricebin_statistics,,1210116131965 in 18sec


In the above, the region has 6 families, each of which is being loaded fairly evenly.   Every time through we&amp;amp;apos;ll compact a store if two files, which just so happens to be most of the time in this case.</description>
			<version>0.1.2</version>
			<fixedVersion>0.1.2, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
		</fixedFiles>
	</bug>
	<bug id="619" opendate="2008-05-07 17:23:50" fixdate="2008-05-07 17:25:54" resolution="Fixed">
		<buginformation>
			<summary>Fix &amp;apos;logs&amp;apos; link in UI</summary>
			<description>Clicking on the &amp;amp;apos;local logs&amp;amp;apos; link in UI gives 404</description>
			<version>0.1.2</version>
			<fixedVersion>0.1.2, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.InfoServer.java</file>
		</fixedFiles>
	</bug>
	<bug id="478" opendate="2008-02-29 22:10:06" fixdate="2008-05-07 17:57:05" resolution="Fixed">
		<buginformation>
			<summary>offlining of table does not run reliably</summary>
			<description>I have a table of 4 regions made w/ PE.  I cannot reliably offline it.  I&amp;amp;apos;m using &amp;amp;apos;disable TestTable&amp;amp;apos; and have traced it to ensure its not a problem in hql.    What I see is that one region will get the offlined mark or maybe two.. but never all.
Jim in IRC suggested that if we did the .TABLE. catalog table, offlining the entry there might be more reliable than trying to offline all regions in a table.</description>
			<version>0.1.1</version>
			<fixedVersion>0.1.2, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.RegionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.master.RetryableMetaOperation.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Memcache.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ServerManager.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ChangeTableState.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TableOperation.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TableDelete.java</file>
			<file type="M">org.apache.hadoop.hbase.TestHBaseCluster.java</file>
			<file type="M">org.apache.hadoop.hbase.master.BaseScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ProcessRegionClose.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ModifyColumn.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ProcessServerShutdown.java</file>
		</fixedFiles>
		<links>
			<link type="Incorporates" description="incorporates">599</link>
			<link type="Reference" description="is related to">627</link>
		</links>
	</bug>
	<bug id="620" opendate="2008-05-07 23:20:15" fixdate="2008-05-07 23:49:19" resolution="Fixed">
		<buginformation>
			<summary>testmergetool failing in branch and trunk since hbase-618 went in</summary>
			<description>The hbase-618 fix revealed that testmergetool depends on compactions running.</description>
			<version>0.1.2</version>
			<fixedVersion>0.1.2, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
		</fixedFiles>
	</bug>
	<bug id="622" opendate="2008-05-12 20:50:04" fixdate="2008-05-12 21:24:08" resolution="Fixed">
		<buginformation>
			<summary>Remove StaticTestEnvironment and put a log4j.properties in src/test</summary>
			<description>StaticTestEnvironment messes around with log4j properties, overriding what is in log4j.properties
put a log4j.properties in src/test to tweak test case logging.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.MultiRegionTable.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHStoreFile.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseClusterTestCase.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHLog.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestLogRolling.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseTestCase.java</file>
			<file type="M">org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestMigrate.java</file>
			<file type="D">org.apache.hadoop.hbase.StaticTestEnvironment.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestMergeTool.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestDeleteAll.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestDeleteFamily.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestGet.java</file>
		</fixedFiles>
	</bug>
	<bug id="624" opendate="2008-05-13 15:28:09" fixdate="2008-05-13 18:25:59" resolution="Fixed">
		<buginformation>
			<summary>Master will shut down if number of active region servers is zero even if shutdown was not requested</summary>
			<description>The master will initiate shutdown if the number of active region servers goes to zero, even if shutdown has not been requested.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ServerManager.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
		</fixedFiles>
	</bug>
	<bug id="629" opendate="2008-05-16 17:27:32" fixdate="2008-05-16 21:46:05" resolution="Fixed">
		<buginformation>
			<summary>Split reports incorrect elapsed time</summary>
			<description>Split reports incorrect elapsed time. That is because the start time for the split is never set. (It used to be set in closing()).
Additionally, since CompactSplitThread doesn&amp;amp;apos;t do anything in closing or closed anymore, why keep them around?
We can just pass null for the RegionUnavailableListener and can then remove closing and closed from CompactSplitThread.
In fact, it turns out that RegionUnavailableListener is not used anywhere anymore so it should just be removed altogether.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
			<file type="D">org.apache.hadoop.hbase.regionserver.RegionUnavailableListener.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestSplit.java</file>
		</fixedFiles>
	</bug>
	<bug id="589" opendate="2008-04-17 21:30:55" fixdate="2008-05-22 20:34:57" resolution="Fixed">
		<buginformation>
			<summary>Remove references to deprecated methods in Hadoop once hadoop-0.17.0 is released</summary>
			<description>A number of methods in Hadoop have been deprecated for release 0.17.0. Once 0.17.0 is released, use preferred alternate.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHStoreFile.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseClusterTestCase.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.BuildTableIndex.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.RegExpRowFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.TableInputFormat.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHLog.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.ColumnValueFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.TableMap.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.TableOutputFormat.java</file>
			<file type="D">org.apache.hadoop.hbase.DisabledTestScanner2.java</file>
			<file type="M">org.apache.hadoop.hbase.master.DeleteColumn.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.TestTableIndex.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStoreFile.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.IndexOutputFormat.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HLog.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseTestCase.java</file>
			<file type="M">org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestMigrate.java</file>
			<file type="M">org.apache.hadoop.hbase.MapFilePerformanceEvaluation.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TableDelete.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">502</link>
			<link type="Incorporates" description="incorporates">566</link>
			<link type="dependent" description="depends upon">579</link>
		</links>
	</bug>
	<bug id="659" opendate="2008-05-30 20:35:11" fixdate="2008-06-01 05:21:37" resolution="Fixed">
		<buginformation>
			<summary>HLog#cacheFlushLock not cleared; hangs a region</summary>
			<description>I have a region that is stuck in a close that was ordained by a split.  Here is what I have from the log pertaining to the stuck region:

4    6416 2008-05-29 22:29:03,433 INFO org.apache.hadoop.hbase.HRegion: checking compaction completed on region enwiki,IK9sWdHJe6ffGZgFPsqIvk==,1212092907061 in 12sec
5    6417 2008-05-29 22:29:03,439 INFO org.apache.hadoop.hbase.HRegion: Splitting enwiki,IK9sWdHJe6ffGZgFPsqIvk==,1212092907061 because largest aggregate size is 288.3m and desired size is 256.0m                                                                    
6    6418 2008-05-29 22:29:03,443 DEBUG org.apache.hadoop.hbase.HRegion: compactions and cache flushes disabled for region enwiki,IK9sWdHJe6ffGZgFPsqIvk==,1212092907061
7    6419 2008-05-29 22:29:03,443 DEBUG org.apache.hadoop.hbase.HRegion: new updates and scanners for region enwiki,IK9sWdHJe6ffGZgFPsqIvk==,1212092907061 disabled                                                                                                    
8    6420 2008-05-29 22:29:03,443 DEBUG org.apache.hadoop.hbase.HRegion: no more active scanners for region enwiki,IK9sWdHJe6ffGZgFPsqIvk==,1212092907061
9    6421 2008-05-29 22:29:03,443 DEBUG org.apache.hadoop.hbase.HRegion: no more row locks outstanding on region enwiki,IK9sWdHJe6ffGZgFPsqIvk==,1212092907061                                                                                                        
10   6422 2008-05-29 22:29:03,443 DEBUG org.apache.hadoop.hbase.HRegionServer: enwiki,IK9sWdHJe6ffGZgFPsqIvk==,1212092907061 closing (Adding to retiringRegions)
11   6423 2008-05-29 22:29:03,443 DEBUG org.apache.hadoop.hbase.HRegion: Started memcache flush for region enwiki,IK9sWdHJe6ffGZgFPsqIvk==,1212092907061. Current region memcache size 2.1m                                                                           
12    6424 2008-05-29 22:29:03,561 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 60020, call batchUpdate(enwiki,IK9sWdHJe6ffGZgFPsqIvk==,1212092907061, 1171081390000, org.apache.hadoop.hbase.io.BatchUpdate@2eeb0275) from 208.76.44.139:49358: err        or: org.        apache.hadoop.hbase.NotServingRegionException: enwiki,IK9sWdHJe6ffGZgFPsqIvk==,1212092907061                                                                                                                                                        
13   6425 org.apache.hadoop.hbase.NotServingRegionException: enwiki,IK9sWdHJe6ffGZgFPsqIvk==,1212092907061
14   6434 2008-05-29 22:29:03,982 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 60020, call batchUpdate(enwiki,IK9sWdHJe6ffGZgFPsqIvk==,1212092907061, 1202595259000, org.apache.hadoop.hbase.io.BatchUpdate@46ee6763) from 208.76.44.139:49358: err        or: org.        apache.hadoop.hbase.NotServingRegionException: enwiki,IK9sWdHJe6ffGZgFPsqIvk==,1212092907061
15   6435 org.apache.hadoop.hbase.NotServingRegionException: enwiki,IK9sWdHJe6ffGZgFPsqIvk==,1212092907061


Then in thread dump, I have two threads blocked on the HLog#cacheFlushLock but looking in code, there is no obvious code path that would get a situation where a lock is held and then not released.

"regionserver/0:0:0:0:0:0:0:0:60020.compactor" daemon prio=1 tid=0x00002aab381e5fd0 nid=0x6195 waiting on condition [0x0000000041c6c000..0x0000000041c6ce00]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(Unknown Source)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(Unknown Source)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(Unknown Source)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(Unknown Source)
        at java.util.concurrent.locks.ReentrantLock$NonfairSync.lock(Unknown Source)
        at java.util.concurrent.locks.ReentrantLock.lock(Unknown Source)
        at org.apache.hadoop.hbase.HLog.startCacheFlush(HLog.java:459)
        at org.apache.hadoop.hbase.HRegion.internalFlushcache(HRegion.java:1089)
        at org.apache.hadoop.hbase.HRegion.close(HRegion.java:594)
        - locked &amp;lt;0x00002aaab70bf3a0&amp;gt; (a java.lang.Integer)
        at org.apache.hadoop.hbase.HRegion.splitRegion(HRegion.java:759)
        - locked &amp;lt;0x00002aaab70bf3a0&amp;gt; (a java.lang.Integer)
        at org.apache.hadoop.hbase.HRegionServer$CompactSplitThread.split(HRegionServer.java:248)
        at org.apache.hadoop.hbase.HRegionServer$CompactSplitThread.run(HRegionServer.java:204)

...


"regionserver/0:0:0:0:0:0:0:0:60020.logRoller" daemon prio=1 tid=0x00002aab38181d70 nid=0x6193 waiting on condition [0x0000000041a6a000..0x0000000041a6ab00]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(Unknown Source)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(Unknown Source)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(Unknown Source)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(Unknown Source)
        at java.util.concurrent.locks.ReentrantLock$NonfairSync.lock(Unknown Source)
        at java.util.concurrent.locks.ReentrantLock.lock(Unknown Source)
        at org.apache.hadoop.hbase.HLog.rollWriter(HLog.java:219)
        at org.apache.hadoop.hbase.HRegionServer$LogRoller.run(HRegionServer.java:615)
        - locked &amp;lt;0x00002aaab69ccf00&amp;gt; (a java.lang.Integer)
...

</description>
			<version>0.1.2</version>
			<fixedVersion>0.1.3, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.TableOperation.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TableDelete.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ChangeTableState.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ColumnOperation.java</file>
			<file type="M">org.apache.hadoop.hbase.util.MetaUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
		</fixedFiles>
	</bug>
	<bug id="663" opendate="2008-06-03 18:32:48" fixdate="2008-06-03 19:28:07" resolution="Fixed">
		<buginformation>
			<summary>Incorrect sequence number for cache flush</summary>
			<description>An HRegion asks each HStore to flush its cache with a sequence number X. The assumption is that all the updates before X will be flushed. So during the startup reconstruction, the updates before X are skipped.
The use of updatesLock should guarantee that all the updates before X will be flushed when HStore flushes with X - snapshots are taken after the write lock on updatesLock is acquired, while all the updates are written to the log and to the cache with the read lock on updatesLock is acquired. However, because the sequence number X is obtained without the write lock on updatesLock, some updates with sequence number &amp;lt;= X may not have been written to the cache which will be flushed.</description>
			<version>0.1.2</version>
			<fixedVersion>0.1.3, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
		</fixedFiles>
	</bug>
	<bug id="666" opendate="2008-06-04 19:00:09" fixdate="2008-06-04 19:28:19" resolution="Fixed">
		<buginformation>
			<summary>UnmodifyableHRegionInfo gives the wrong encoded name</summary>
			<description>UnmodifyableHRegionInfo never has the same encoded name for a HRegionInfo. To see it, look at a table regions and hit refresh in UI.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.UnmodifyableHRegionInfo.java</file>
			<file type="M">org.apache.hadoop.hbase.HRegionInfo.java</file>
			<file type="M">org.apache.hadoop.hbase.client.UnmodifyableHTableDescriptor.java</file>
		</fixedFiles>
	</bug>
	<bug id="680" opendate="2008-06-12 06:13:40" fixdate="2008-06-12 17:00:18" resolution="Fixed">
		<buginformation>
			<summary>config parameter hbase.io.index.interval  should be hbase.index.interval, accroding to HBaseMapFile.HbaseWriter</summary>
			<description>in conf/hbase-default.xml and FAQ, there has a  performance tuning parameter "hbase.io.index.interval", but can&amp;amp;apos;t find any usage in sources. instead, HStoreFile.java #585 using "hbase.index.interval" to set mapfile index interval (setIndexInterval). so i think  HStoreFile.java mistyped the parameter name.
this mistake will make users thinkgs "hbase.io.index.interval" useless. </description>
			<version>0.1.2</version>
			<fixedVersion>0.1.3, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStoreFile.java</file>
		</fixedFiles>
	</bug>
	<bug id="502" opendate="2008-03-11 18:41:57" fixdate="2008-06-15 21:32:30" resolution="Duplicate">
		<buginformation>
			<summary>When deleting a directory, use FileUtil.fullyDelete instead of FileSystem.delete</summary>
			<description>FileUtil.fullyDelete properly deletes a directory by deleting its contents first. While FileSystem.delete works on HDFS, it does not work on local file systems that do not permit a directory to be deleted if it is not empty.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHStoreFile.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseClusterTestCase.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.BuildTableIndex.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.RegExpRowFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.TableInputFormat.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHLog.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.ColumnValueFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.TableMap.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.TableOutputFormat.java</file>
			<file type="D">org.apache.hadoop.hbase.DisabledTestScanner2.java</file>
			<file type="M">org.apache.hadoop.hbase.master.DeleteColumn.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.TestTableIndex.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStoreFile.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.IndexOutputFormat.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HLog.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseTestCase.java</file>
			<file type="M">org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestMigrate.java</file>
			<file type="M">org.apache.hadoop.hbase.MapFilePerformanceEvaluation.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TableDelete.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">589</link>
		</links>
	</bug>
	<bug id="681" opendate="2008-06-12 21:06:55" fixdate="2008-06-16 19:00:01" resolution="Fixed">
		<buginformation>
			<summary>NPE in Memcache</summary>
			<description>java.io.IOException: java.io.IOException: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.Memcache.internalGetKeys(Memcache.java:585)
	at org.apache.hadoop.hbase.regionserver.Memcache.getKeys(Memcache.java:551)
	at org.apache.hadoop.hbase.regionserver.HStore.getKeys(HStore.java:1437)
	at org.apache.hadoop.hbase.regionserver.HRegion.getKeys(HRegion.java:1243)
	at org.apache.hadoop.hbase.regionserver.HRegion.deleteMultiple(HRegion.java:1498)
	at org.apache.hadoop.hbase.regionserver.HRegion.deleteAll(HRegion.java:1424)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.deleteAll(HRegionServer.java:1266)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:424)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:867)
</description>
			<version>0.1.2</version>
			<fixedVersion>0.1.3, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.MultiRegionTable.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseTestCase.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HAbstractScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.AbstractMergeTestBase.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestMergeTool.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Memcache.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.TestRegionRebalancing.java</file>
		</fixedFiles>
		<links>
			<link type="Incorporates" description="is part of">613</link>
		</links>
	</bug>
	<bug id="686" opendate="2008-06-14 08:12:48" fixdate="2008-06-17 20:52:04" resolution="Fixed">
		<buginformation>
			<summary>MemcacheScanner didn&amp;apos;t return the first row(if it exists), cause HScannerInterface&amp;apos;s output incorrect</summary>
			<description>HTable.obtainScanner methods should return the start row if it exists, although HTable&amp;amp;apos;s javadoc didn&amp;amp;apos;t clearly desc. but i found the result of htable scanners sometimes contain the start row, sometimes not.
after more testing and code review, i found it should be a bug in HStore.Memcache.MemcacheScanner. in the constructor it set this.currentRow = firstRow, but when doing next(), there&amp;amp;apos;s a this.currentRow = getNextRow(this.currentRow) before fetch result.</description>
			<version>0.1.2</version>
			<fixedVersion>0.1.3, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHMemcache.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Memcache.java</file>
		</fixedFiles>
	</bug>
	<bug id="694" opendate="2008-06-17 06:30:05" fixdate="2008-06-18 16:28:47" resolution="Fixed">
		<buginformation>
			<summary>HStore.rowAtOrBeforeFromMapFile() fails to locate the row if # of mapfiles &gt;= 2</summary>
			<description>After HBASE-528 committed, a misplaced return statement and } cause 
rowAtOrBeforeFromMapFile() never look into 2nd (and latter) MapFile
if candidateKeys.firstKey() &amp;lt;= map.finalKey().</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestGet2.java</file>
		</fixedFiles>
	</bug>
	<bug id="699" opendate="2008-06-19 05:49:29" fixdate="2008-06-19 07:14:53" resolution="Fixed">
		<buginformation>
			<summary>Fix TestMigrate up on Hudson</summary>
			<description>Its hanging on hudson again.  Caught a threaddump.  Its that old waiting on a vanished unix process... no hbase threads hanging out.
I tried adding relocateRegion just before taking out scan in verify.  That was good for fixing the first region in the table.  We hung when we tried to get second region.  It was trying to go to old address.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestMigrate.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseClusterTestCase.java</file>
			<file type="M">org.apache.hadoop.hbase.HMerge.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
		</fixedFiles>
	</bug>
	<bug id="615" opendate="2008-05-06 01:33:13" fixdate="2008-06-19 16:30:41" resolution="Fixed">
		<buginformation>
			<summary>Region balancer oscillates during cluster startup</summary>
			<description>When starting a cluster with four region servers and a large table (49 regions) (+root +meta) = 51 total regions, the region balancer oscillates for a very long time and does not seem to reach a steady state.
Additionally, for whatever reason, it seems reluctant to assign regions to the first of four region servers, which may be the root cause. In my test, the first server had 10 regions assigned, the second and fourth had 13 regions assigned, and the master would continually assign and deassign 2 regions to the third server, which oscillated between 13 and 15 regions.  If it assigned the two fluctuating regions to the first server, it would achieve the best balance possible: 12, 13, 13, 13.
After 20 minutes, it had not stopped oscillating. An application trying to work against this cluster would run very slowly as it would be continually re-finding the two regions in flux.
When the table was being created, regions were nicely balanced. On restart, however, it just would not settle down.
Perhaps the balancer should set a target number of regions for each server which when the server achieved +/- 1 regions, the rebalancer would not try to change unless the number of regions changed.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.HServerLoad.java</file>
		</fixedFiles>
		<links>
			<link type="Blocker" description="blocks">627</link>
			<link type="Incorporates" description="is part of">63</link>
		</links>
	</bug>
	<bug id="613" opendate="2008-05-02 23:47:42" fixdate="2008-06-26 04:54:27" resolution="Fixed">
		<buginformation>
			<summary>Timestamp-anchored scanning fails to find all records</summary>
			<description>If I add 3 versions of a cell and then scan across the first set of added cells using a timestamp that should only get values from the first upload, a bunch are missing (I added 100k on each of the three uploads).  I thought it the fact that we set the number of cells found back to 1 in HStore when we move off current row/column but that doesn&amp;amp;apos;t seem to be it.  I also tried upping the MAX_VERSIONs on my table and that seemed to have no effect.  Need to look closer.
Build a unit test because replicating on cluster takes too much time.</description>
			<version>0.1.0</version>
			<fixedVersion>0.1.3, 0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestMergeTool.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
			<file type="M">org.apache.hadoop.hbase.MultiRegionTable.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseTestCase.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HAbstractScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.AbstractMergeTestBase.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Memcache.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.TestRegionRebalancing.java</file>
		</fixedFiles>
		<links>
			<link type="Incorporates" description="incorporates">681</link>
		</links>
	</bug>
	<bug id="716" opendate="2008-06-27 23:04:04" fixdate="2008-06-28 02:33:27" resolution="Fixed">
		<buginformation>
			<summary>TestGet2.testGetClosestBefore fails with hadoop-0.17.1</summary>
			<description>TestGet2.testGetClosestBefore fails with hadoop-0.17.1
After the rows are flushed to a MapFile, we get no result when we try to find the closest row before 038. We find 035, but that is deleted. So we advance, the next record is 040 which is after 038 and we give up. This results in a null result being passed back to the test which then dies with an NPE because it expects that getClosestRowBefore should find row 030.
It appears that there is no logic to back up from a candidate row if the candidate came before the desired key but is deleted. We should find the row before.
I&amp;amp;apos;m guessing that this is failing because hadoop-0.17.1 incorporates HADOOP-3472 (MapFile.Reader getClosest() function returns incorrect results when before is true)</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
		</fixedFiles>
		<links>
			<link type="Blocker" description="blocks">715</link>
		</links>
	</bug>
	<bug id="627" opendate="2008-05-15 09:58:56" fixdate="2008-06-28 02:45:43" resolution="Fixed">
		<buginformation>
			<summary>Disable table doesn&amp;apos;t work reliably</summary>
			<description>When creating a couple of tables like this:
1) create an empty table
2) disable table, add new column family, enable table
3) put 100 small documents into newly created column
around once in 10 tries the disable doesn&amp;amp;apos;t happen.
I have no clue as to why the table isn&amp;amp;apos;t disabled in the first place, but if this occurs, two things in HBaseAdmin.disableTable() strike me as odd:

after numRetries tries to wait for disabling we exit the loop; there is no exception or error message:
...
2008-05-14 16:19:47,903 INFO org.apache.hadoop.hbase.client.HBaseAdmin: Disabled table table31
2008-05-14 16:19:47,910 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 60000, call addColumn(table31, 
{name: document, max versions: 3, compression: NONE, in memory: false, block cache enabled: false, max length: 2147483647, time to live: FOREVER, bloom filter: none}
) from XXX.XX.40.36:47116: error: org.apache.hadoop.hbase.TableNotDisabledException: table31
...


the scanner iterates over HRegionInfos of several tables. If any one of those is disabled, we also leave the loop as if the requested table had been disabled.

I&amp;amp;apos;ve had this disabling problem occur quite reliably over the last days - today I couldn&amp;amp;apos;t reproduce it, though HBase version hasn&amp;amp;apos;t changed. ???</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TableOperation.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HConnection.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
		</fixedFiles>
		<links>
			<link type="Blocker" description="is blocked by">615</link>
			<link type="Reference" description="relates to">478</link>
			<link type="Reference" description="relates to">713</link>
		</links>
	</bug>
	<bug id="717" opendate="2008-06-30 06:32:52" fixdate="2008-07-01 05:13:03" resolution="Fixed">
		<buginformation>
			<summary>alter table broke with new shell returns InvalidColumnNameException</summary>
			<description>create table disable table alter table output below:

hbase(main):041:0&amp;gt; create &amp;amp;apos;t1&amp;amp;apos;, {NAME =&amp;gt; &amp;amp;apos;f1&amp;amp;apos;, VERSIONS =&amp;gt; 5}
08/06/30 01:26:43 DEBUG client.HConnectionManager$TableServers: reloading table servers because: No server address listed in .META. for region t1,,1214807203247
08/06/30 01:26:43 DEBUG client.HConnectionManager$TableServers: Removed .META.,,1 from cache because of t1,,99999999999999
08/06/30 01:26:43 DEBUG client.HConnectionManager$TableServers: Found ROOT REGION =&amp;gt; {NAME =&amp;gt; &amp;amp;apos;-ROOT-,,0&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;&amp;amp;apos;, ENCODED =&amp;gt; 70236052, TABLE =&amp;gt; {NAME =&amp;gt; &amp;amp;apos;-ROOT-&amp;amp;apos;, FAMILIES =&amp;gt; [{NAME =&amp;gt; &amp;amp;apos;info&amp;amp;apos;, VERSIONS =&amp;gt; 1, COMPRESSION =&amp;gt; &amp;amp;apos;NONE&amp;amp;apos;, IN_MEMORY =&amp;gt; false, BLOCKCACHE =&amp;gt; false, LENGTH =&amp;gt; 2147483647, TTL =&amp;gt; FOREVER, BLOOMFILTER =&amp;gt; NONE}]}
0 row(s) in 10.4300 seconds

hbase(main):042:0&amp;gt; disable &amp;amp;apos;t1&amp;amp;apos;
08/06/30 01:27:08 DEBUG client.HBaseAdmin: Sleep. Waiting for first region to be disabled from t1
08/06/30 01:27:18 DEBUG client.HBaseAdmin: Wake. Waiting for first region to be disabled from [B@1bc93a7
08/06/30 01:27:18 INFO client.HBaseAdmin: Disabled t1
0 row(s) in 10.0810 seconds

hbase(main):043:0&amp;gt; alter &amp;amp;apos;t1&amp;amp;apos;, {NAME =&amp;gt; &amp;amp;apos;f1&amp;amp;apos;, VERSIONS =&amp;gt; 1}
NativeException: org.apache.hadoop.hbase.InvalidColumnNameException: org.apache.hadoop.hbase.InvalidColumnNameException: Column family &amp;amp;apos;f1&amp;amp;apos; doesn&amp;amp;apos;t exist, so cannot be modified.
        at org.apache.hadoop.hbase.master.ModifyColumn.postProcessMeta(ModifyColumn.java:51)
        at org.apache.hadoop.hbase.master.TableOperation$ProcessTableOperation.call(TableOperation.java:130)
        at org.apache.hadoop.hbase.master.TableOperation$ProcessTableOperation.call(TableOperation.java:67)
        at org.apache.hadoop.hbase.master.RetryableMetaOperation.doWithRetries(RetryableMetaOperation.java:62)
        at org.apache.hadoop.hbase.master.TableOperation.process(TableOperation.java:141)
        at org.apache.hadoop.hbase.master.HMaster.modifyColumn(HMaster.java:655)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:424)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)

        from sun/reflect/NativeConstructorAccessorImpl.java:-2:in `newInstance0&amp;amp;apos;
        from sun/reflect/NativeConstructorAccessorImpl.java:39:in `newInstance&amp;amp;apos;
        from sun/reflect/DelegatingConstructorAccessorImpl.java:27:in `newInstance&amp;amp;apos;
        from java/lang/reflect/Constructor.java:513:in `newInstance&amp;amp;apos;
        from org/apache/hadoop/hbase/RemoteExceptionHandler.java:82:in `decodeRemoteException&amp;amp;apos;
        from org/apache/hadoop/hbase/client/HBaseAdmin.java:658:in `modifyColumn&amp;amp;apos;
        from org/apache/hadoop/hbase/client/HBaseAdmin.java:636:in `modifyColumn&amp;amp;apos;
        from sun/reflect/NativeMethodAccessorImpl.java:-2:in `invoke0&amp;amp;apos;
        from sun/reflect/NativeMethodAccessorImpl.java:39:in `invoke&amp;amp;apos;
        from sun/reflect/DelegatingMethodAccessorImpl.java:25:in `invoke&amp;amp;apos;
        from java/lang/reflect/Method.java:597:in `invoke&amp;amp;apos;
        from org/jruby/javasupport/JavaMethod.java:250:in `invokeWithExceptionHandling&amp;amp;apos;
        from org/jruby/javasupport/JavaMethod.java:219:in `invoke&amp;amp;apos;
        from org/jruby/javasupport/JavaClass.java:416:in `execute&amp;amp;apos;
        from org/jruby/internal/runtime/methods/SimpleCallbackMethod.java:67:in `call&amp;amp;apos;
        from org/jruby/internal/runtime/methods/DynamicMethod.java:94:in `call&amp;amp;apos;
... 118 levels...
        from ruby.hbase_minus_671438.bin.hirbInvokermethod__23$RUBY$startOpt:-1:in `call&amp;amp;apos;
        from org/jruby/internal/runtime/methods/DynamicMethod.java:74:in `call&amp;amp;apos;
        from org/jruby/internal/runtime/methods/CompiledMethod.java:48:in `call&amp;amp;apos;
        from org/jruby/runtime/CallSite.java:123:in `cacheAndCall&amp;amp;apos;
        from org/jruby/runtime/CallSite.java:298:in `call&amp;amp;apos;
        from ruby/hbase_minus_671438/bin//hbase/bin/hirb.rb:348:in `__file__&amp;amp;apos;
        from ruby/hbase_minus_671438/bin//hbase/bin/hirb.rb:-1:in `__file__&amp;amp;apos;
        from ruby/hbase_minus_671438/bin//hbase/bin/hirb.rb:-1:in `load&amp;amp;apos;
        from org/jruby/Ruby.java:512:in `runScript&amp;amp;apos;
        from org/jruby/Ruby.java:432:in `runNormally&amp;amp;apos;
        from org/jruby/Ruby.java:312:in `runFromMain&amp;amp;apos;
        from org/jruby/Main.java:144:in `run&amp;amp;apos;
        from org/jruby/Main.java:89:in `run&amp;amp;apos;
        from org/jruby/Main.java:80:in `main&amp;amp;apos;
        from /hbase/bin/hirb.rb:229:in `alter&amp;amp;apos;
        from (hbase):44:in `binding&amp;amp;apos;hbase(main):044:0&amp;gt;

</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.ModifyColumn.java</file>
		</fixedFiles>
	</bug>
	<bug id="703" opendate="2008-06-25 06:40:45" fixdate="2008-07-03 19:27:25" resolution="Fixed">
		<buginformation>
			<summary>Invalid regions listed by regionserver.jsp</summary>
			<description>The region list displayed by regionserver.jsp contains regions that have ceased existence due to splits.
Example:
Region Name	Encoded Name	Start Key	End Key
...
maxentriestest,acacdk,1214292085212	732557990 	acacdk	
maxentriestest,acacdk,1214297936860	1583424516 	acacdk	acqtzk
maxentriestest,acacdk,1214293855954	1509492302 	acacdk	adhlxw
maxentriestest,acqtzk,1214297936862	1120286366 	acqtzk	adhlxw
maxentriestest,adhlxw,1214293855955	400707061 	adhlxw	
maxentriestest,adhlxw,1214299372674	2060549477 	adhlxw	aelrxo
maxentriestest,adhlxw,1214297324386	336026175 	adhlxw	afpxzs
maxentriestest,aelrxo,1214299372674	1352588233 	aelrxo	afpxzs
maxentriestest,afpxzs,1214297324387	1235754353 	afpxzs	</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
		</fixedFiles>
	</bug>
	<bug id="674" opendate="2008-06-09 20:54:33" fixdate="2008-07-04 19:16:56" resolution="Fixed">
		<buginformation>
			<summary>memcache size unreliable</summary>
			<description>Multiple updates against same row/column/ts will be seen as increments to cache size on insert but when we then play the memcache at flush time, we&amp;amp;apos;ll only see the most recent entry and decrement the memcache size by whatever its size; memcache will be off.</description>
			<version>0.1.2</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Memcache.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
		</fixedFiles>
	</bug>
	<bug id="726" opendate="2008-07-07 18:50:24" fixdate="2008-07-07 21:19:45" resolution="Fixed">
		<buginformation>
			<summary>Unit tests won&amp;apos;t run because of a typo</summary>
			<description>I had to modify line#101 in HBaseTestCase.java in order to run the unit tests: 
(conf.get("fs.default.name", "file:///").compareTo("file::///") == 0);
I removed the second ":" in compareTo() so it becomes "file:///"</description>
			<version>0.1.4</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.HBaseTestCase.java</file>
		</fixedFiles>
	</bug>
	<bug id="740" opendate="2008-07-11 13:21:16" fixdate="2008-07-11 16:44:15" resolution="Fixed">
		<buginformation>
			<summary>ThriftServer getting table names incorrectly</summary>
			<description>Slight bug.
TableDescriptor name is stored internally as byte[] now, but the thrift server wasn&amp;amp;apos;t updated to reflect that.
It is returning the table name incorrectly in getTableNames. This is also the case, for getTableRegions</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
		</fixedFiles>
		<links>
			<link type="Incorporates" description="is part of">697</link>
		</links>
	</bug>
	<bug id="744" opendate="2008-07-14 01:42:55" fixdate="2008-07-14 20:47:24" resolution="Fixed">
		<buginformation>
			<summary>BloomFilter serialization/deserialization broken</summary>
			<description>BloomFilter serialization/deserialization is broken.Deserializing a serialized BloomFilter appears to work, but running the same tests against the pre-serialized filter returns false negatives against the deserialized filter.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStoreFile.java</file>
			<file type="M">org.onelab.filter.BloomFilter.java</file>
			<file type="M">org.onelab.test.TestFilter.java</file>
			<file type="M">org.onelab.filter.Filter.java</file>
		</fixedFiles>
	</bug>
	<bug id="739" opendate="2008-07-10 21:26:53" fixdate="2008-07-14 21:40:34" resolution="Fixed">
		<buginformation>
			<summary>HBaseAdmin.createTable() using old HTableDescription doesn&amp;apos;t work</summary>
			<description>The following test case (see below) illustrate what used to work in branch 0.1 and that doesn&amp;amp;apos;t anymore. testTruncateInTrunk() shows how I got it to work again. I get this error now when trying the old code but using trunk:
java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at com.openplaces.test.fixture.FixtureLoader.truncateHbaseTable(FixtureLoader.java:105)
	at com.openplaces.test.fixture.FixtureLoader.loadHbaseFixtures(FixtureLoader.java:63)
	at com.openplaces.test.fixture.TestCaseWithFixtures.hbaseFixtures(TestCaseWithFixtures.java:34)
	at com.openplaces.test.isolated.TestSearchSRFIEF.setUp(TestSearchSRFIEF.java:37)
	at junit.framework.TestCase.runBare(TestCase.java:125)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:460)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:673)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:386)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:196)
Caused by: java.net.SocketTimeoutException: timed out waiting for rpc response
	at org.apache.hadoop.ipc.Client.call(Client.java:559)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Invoker.invoke(HbaseRPC.java:211)
	at $Proxy5.createTable(Unknown Source)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:184)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:144)
	at com.openplaces.util.hbaserecord.connectionadapters.HbaseAdapter.truncateTable(HbaseAdapter.java:502)
	at com.openplaces.util.hbaserecord.Base$Singleton.truncate(Base.java:609)
	... 21 more
import java.io.IOException;
import java.util.Collection;
import org.apache.hadoop.hbase.HBaseConfiguration;
import org.apache.hadoop.hbase.HColumnDescriptor;
import org.apache.hadoop.hbase.HTableDescriptor;
import org.apache.hadoop.hbase.client.HBaseAdmin;
import org.apache.hadoop.hbase.client.HTable;
import junit.framework.TestCase;
@SuppressWarnings("deprecation")
public class TestTruncate extends TestCase {
	public void testTruncateInBranch_0_1() throws IOException
{
		HTable table = new HTable("mytable");
		HBaseAdmin admin = new HBaseAdmin(new HBaseConfiguration());
		HTableDescriptor tableDesc = table.getMetadata();
		admin.deleteTable(table.getTableName());
		admin.createTable(tableDesc);
	}

	public void testTruncateInTrunk() throws IOException{
		HTable table = new HTable("mytable");
		HBaseAdmin admin = new HBaseAdmin(new HBaseConfiguration());
		Collection&amp;lt;HColumnDescriptor&amp;gt; families = table.getMetadata().getFamilies();
		HTableDescriptor tableDesc = new HTableDescriptor(table.getTableName());
		for(HColumnDescriptor family : families)
{
			tableDesc.addFamily(family);
		}

		admin.deleteTable(table.getTableName());
		admin.createTable(tableDesc);
	}
}</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.UnmodifyableHTableDescriptor.java</file>
		</fixedFiles>
	</bug>
	<bug id="742" opendate="2008-07-11 17:15:47" fixdate="2008-07-14 21:40:39" resolution="Fixed">
		<buginformation>
			<summary>Column length limit is not enforced</summary>
			<description>HColumnDescriptor provides for a limit on column value length but it is not enforced in 0.1.3 or 0.2.0 other than in the REST and Thrift APIs. (I thought it was enforced in some earlier revision but cannot find it).
Enforcement on the client side would be less complicated than doing it on the server side.</description>
			<version>0.1.3</version>
			<fixedVersion>0.2.0, 0.1.4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.TestBatchUpdate.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
		</fixedFiles>
	</bug>
	<bug id="737" opendate="2008-07-10 17:40:11" fixdate="2008-07-16 00:07:14" resolution="Fixed">
		<buginformation>
			<summary>Scanner: every cell in a row has the same timestamp</summary>
			<description>A row can have multiple cells, and each cell can have a different timestamp.  The get command in the shell demonstrates that cells are being stored with different timestamps:

hbase(main):008:0&amp;gt; get &amp;amp;apos;table1&amp;amp;apos;, &amp;amp;apos;row2&amp;amp;apos;  
COLUMN                       CELL 
 fam1:letters                timestamp=1215707612949, value=def 
 fam1:numbers                timestamp=1215707629064, value=123 
 fam2:letters                timestamp=1215711498969, value=abc 
3 row(s) in 0.0100 seconds


However, using the scanners to retrieve these cells shows that they all have the same timestamp:

hbase(main):009:0&amp;gt; scan &amp;amp;apos;table1&amp;amp;apos;  
ROW                          COLUMN+CELL
 row2                        column=fam1:letters, timestamp=1215711498969, value=def 
 row2                        column=fam1:numbers, timestamp=1215711498969, value=123 
 row2                        column=fam2:letters, timestamp=1215711498969, value=abc 
3 row(s) in 0.0600 seconds


The scanners are losing timestamp information somewhere along the line.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStoreScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HAbstractScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.TestRowFilterAfterWrite.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.PageRowFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Flusher.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.RegExpRowFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestSplit.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.RowFilterSet.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.ColumnValueFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.TestRowFilterSet.java</file>
			<file type="M">org.apache.hadoop.hbase.TimestampTestBase.java</file>
			<file type="M">org.apache.hadoop.hbase.client.UnmodifyableHTableDescriptor.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.util.MetaUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestGet2.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHMemcache.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.StopRowFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.TestRegExpRowFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.HMerge.java</file>
			<file type="D">org.apache.hadoop.hbase.TestBloomFilters.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.WhileMatchRowFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.RowFilterInterface.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseTestCase.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.InternalScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.TestRowFilterOnMultipleFamilies.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Memcache.java</file>
			<file type="M">org.apache.hadoop.hbase.client.UnmodifyableHRegionInfo.java</file>
			<file type="M">org.apache.hadoop.hbase.TestScannerAPI.java</file>
		</fixedFiles>
	</bug>
	<bug id="756" opendate="2008-07-21 15:24:08" fixdate="2008-07-21 15:49:01" resolution="Fixed">
		<buginformation>
			<summary>In HBase shell, the put command doesn&amp;apos;t process the timestamp</summary>
			<description>
      if timestamp
        bu = BatchUpdate.new(row)
      else
        bu = BatchUpdate.new(row)


Something is wrong here.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
		</fixedFiles>
	</bug>
	<bug id="758" opendate="2008-07-21 21:30:10" fixdate="2008-07-21 21:35:08" resolution="Fixed">
		<buginformation>
			<summary>Throwing IOE read-only when should be throwing NSRE</summary>
			<description>Am seeing exceptions like the following during &amp;amp;apos;normal&amp;amp;apos; operation though the region has not been explicitly set to be read-only (new feature added with commit of HBASE-62).

2008-07-21 20:50:25,071 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 60020, call batchUpdate([B@63443c, row =&amp;gt; 0000791906, {column =&amp;gt; info:data, value =&amp;gt; &amp;amp;apos;...&amp;amp;apos;}) from XX.XX.XX.139:59778: error: java.io.IOException: region is read only
java.io.IOException: region is read only
        at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1322)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1151)
        at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:438)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)

</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
		</fixedFiles>
	</bug>
	<bug id="743" opendate="2008-07-11 18:05:34" fixdate="2008-07-21 21:47:31" resolution="Fixed">
		<buginformation>
			<summary>bin/hbase migrate upgrade fails when redo logs exists</summary>
			<description>I migrated several hbase-0.1.3 instances to hbase trunk and even if I stop hbase-0.1.3 cleanup it leaves redo logs on hdfs. The problems is that when migrating the data with hbase-trunk it fails because it finds these redo-logs and quit with a error message saying that we should reinstall the old hbase and shut it down cleanly and that in theory it erases the redo logs. The work around has been to delete the redo logs manually... which is bad.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.BaseScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ServerManager.java</file>
			<file type="M">org.apache.hadoop.hbase.util.Migrate.java</file>
		</fixedFiles>
	</bug>
	<bug id="763" opendate="2008-07-23 01:33:43" fixdate="2008-07-23 15:06:03" resolution="Fixed">
		<buginformation>
			<summary>ClassCastException from RowResult.get(String)</summary>
			<description>[hadoop@sjdc-atr-dns column-test]$ hbase net.iridiant.simpletest.Main --master=10.30.94.1:60000
Exception in thread "main" java.lang.ClassCastException: java.lang.String cannot be cast to [B
        at org.apache.hadoop.hbase.util.Bytes$1.compare(Bytes.java:32)
        at java.util.TreeMap.getEntryUsingComparator(TreeMap.java:351)
        at java.util.TreeMap.getEntry(TreeMap.java:322)
        at java.util.TreeMap.get(TreeMap.java:255)
        at org.apache.hadoop.hbase.io.HbaseMapWritable.get(HbaseMapWritable.java:112)
        at org.apache.hadoop.hbase.io.RowResult.get(RowResult.java:79)
        at net.iridiant.simpletest.Main.main(Unknown Source)
Please see attached testcase.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.RowResult.java</file>
		</fixedFiles>
	</bug>
	<bug id="764" opendate="2008-07-23 06:13:59" fixdate="2008-07-23 17:52:29" resolution="Fixed">
		<buginformation>
			<summary>The name of column request has padding zero using REST interface</summary>
			<description>Today when i play with the REST interface and found the column POST/PUT/GET has a problem.
When i use the hbase shell to check the data, i found the row name has the padding zero.
The cause is that TableHandler use Text class to encode the string to the UTF-8. But CharSetEncoder
will pre-allocate more spaces then the length of String for performance. So we get the padding zero
when inserting the value to the table.  The fix is to get the String instead of the byte[] for the BatchUpdate.
Below is the patch.  Also, the patch includes fixing the wrong use of (bytes[]).toString() using Bytes.toString(byte[])
Index: src/java/org/apache/hadoop/hbase/rest/TableHandler.java
===================================================================
 src/java/org/apache/hadoop/hbase/rest/TableHandler.java    (revision 678664)
+++ src/java/org/apache/hadoop/hbase/rest/TableHandler.java    (working copy)
@@ -174,7 +174,7 @@
         // copy over those cells with requested column names
         for(byte [] current_column: columns_retrieved) {

if(requested_columns_set.contains(current_column.toString()))
Unknown macro: {+          if(requested_columns_set.contains(Bytes.toString(current_column))){
             m.put(current_column, prefiltered_result.get(current_column));           
           }         } 
@@ -295,7 +295,7 @@

     try{
       // start an update

Text key = new Text(row);
+      String key = new Text(row).toString();
       batchUpdate = timestamp == null ?
         new BatchUpdate(key) : new BatchUpdate(key, Long.parseLong(timestamp));

@@ -308,7 +308,7 @@
         // extract the name and value children
         Node name_node = column.getElementsByTagName("name").item(0);

Text name = new Text(name_node.getFirstChild().getNodeValue());
+        String name = new Text(name_node.getFirstChild().getNodeValue()).toString();

         Node value_node = column.getElementsByTagName("value").item(0);
@@ -356,7 +356,7 @@
           XMLOutputter outputter = getXMLOutputter(response.getWriter());
           outputter.startTag("regions");
           for (int i = 0; i &amp;lt; startKeys.length; i++) 
{
-            doElement(outputter, "region", startKeys[i].toString());
+            doElement(outputter, "region", Bytes.toString(startKeys[i]));
           }
           outputter.endTag();
           outputter.endDocument();
@@ -368,7 +368,7 @@
           PrintWriter out = response.getWriter();
           for (int i = 0; i &amp;lt; startKeys.length; i++) 
{
             // TODO: Add in the server location.  Is it needed?
-            out.print(startKeys[i].toString());
+            out.print(Bytes.toString(startKeys[i]));
           }
           out.close();
         break;
@@ -454,7 +454,7 @@
     // pull the row key out of the path
     String row = URLDecoder.decode(pathSegments[2], HConstants.UTF8_ENCODING);

Text key = new Text(row);
+    String key = new Text(row).toString();

     String[] columns = request.getParameterValues(COLUMN);
@@ -472,7 +472,7 @@
       } else{
         // delete each column in turn     
         for(int i = 0; i &amp;lt; columns.length; i++)
{
-          table.deleteAll(key, new Text(columns[i]));
+          table.deleteAll(key, new Text(columns[i]).toString());
         }
       }
       response.setStatus(202);</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.rest.TableHandler.java</file>
		</fixedFiles>
	</bug>
	<bug id="750" opendate="2008-07-17 18:21:43" fixdate="2008-07-23 19:33:10" resolution="Fixed">
		<buginformation>
			<summary>NPE caused by StoreFileScanner.updateReaders</summary>
			<description>Running a test to determine performance during inserts of many 100,000s of cells into a single column family in a single row, the region server involved went down after taking a NPE:
2008-07-17 18:12:18,051 FATAL org.apache.hadoop.hbase.regionserver.Flusher: Replay of hlog required. Forcing server restart
org.apache.hadoop.hbase.DroppedSnapshotException
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1040)
        at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:942)
        at org.apache.hadoop.hbase.regionserver.Flusher.flushRegion(Flusher.java:174)
        at org.apache.hadoop.hbase.regionserver.Flusher.run(Flusher.java:93)
Caused by: java.lang.NullPointerException
        at java.lang.String.&amp;lt;init&amp;gt;(String.java:516)
        at org.apache.hadoop.hbase.util.Bytes.toString(Bytes.java:71)
        at org.apache.hadoop.hbase.regionserver.StoreFileScanner.updateReaders(StoreFileScanner.java:374)
        at org.apache.hadoop.hbase.regionserver.HStore.notifyChangedReadersObservers(HStore.java:797)
        at org.apache.hadoop.hbase.regionserver.HStore.updateReaders(HStore.java:784)
        at org.apache.hadoop.hbase.regionserver.HStore.internalFlushCache(HStore.java:755)
        at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:682)
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1030)
        ... 3 more
Any ideas about this one?</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
		</fixedFiles>
	</bug>
	<bug id="791" opendate="2008-08-01 01:05:27" fixdate="2008-08-01 02:39:59" resolution="Fixed">
		<buginformation>
			<summary>RowCount doesn&amp;apos;t work</summary>
			<description>From Yair Even-Zohar

looked at the code in the 0.2.0 and the args[0] is used twice
   c.set("hbase.master", args[0]);
And
   // First arg is the output directory.
   c.setOutputPath(new Path(args[0]));
Was anybody able to use this class?
In fact it does not work and there is also a NPE that gets thrown.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapred.RowCounter.java</file>
		</fixedFiles>
	</bug>
	<bug id="751" opendate="2008-07-18 02:07:17" fixdate="2008-08-01 06:40:44" resolution="Fixed">
		<buginformation>
			<summary>dfs exception and regionserver stuck during heavy write load</summary>
			<description>It&amp;amp;apos;s a 3 node setup, each runs datanode and regionserver. One runs as hbase master and hadoop namenode.
After some heavy write load via java client, the client is stuck. Stack trace on the regionserver shows:
"IPC Server handler 46 on 60020" daemon prio=10 tid=0x4dd3f000 nid=0x4eb3 waiting for monitor entry [0x4cc82000..0x4cc83130]
   java.lang.Thread.State: BLOCKED (on object monitor)
    at org.apache.hadoop.hbase.regionserver.HStore.rowAtOrBeforeFromMapFile(HStore.java:1424)

waiting to lock &amp;lt;0x59d27ba0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)
    at org.apache.hadoop.hbase.regionserver.HStore.getRowKeyAtOrBefore(HStore.java:1399)
    at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1210)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1099)
    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:438)
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)

"IPC Server handler 43 on 60020" daemon prio=10 tid=0x4dd3bc00 nid=0x4eb0 waiting for monitor entry [0x4cd75000..0x4cd75fb0]
   java.lang.Thread.State: BLOCKED (on object monitor)
    at org.apache.hadoop.hbase.regionserver.HStore.rowAtOrBeforeFromMapFile(HStore.java:1424)

waiting to lock &amp;lt;0x59d27ba0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)
    at org.apache.hadoop.hbase.regionserver.HStore.getRowKeyAtOrBefore(HStore.java:1399)
    at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1210)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1099)
    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:438)
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)

"IPC Server handler 40 on 60020" daemon prio=10 tid=0x4dd38400 nid=0x4ead runnable [0x4ce68000..0x4ce68e30]
   java.lang.Thread.State: RUNNABLE
    at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:215)
    at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:65)
    at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:69)

locked &amp;lt;0x6a557580&amp;gt; (a sun.nio.ch.Util$1)
locked &amp;lt;0x6a557570&amp;gt; (a java.util.Collections$UnmodifiableSet)
locked &amp;lt;0x5cdcec18&amp;gt; (a sun.nio.ch.EPollSelectorImpl)
    at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:80)
    at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:237)
    at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:155)
    at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:149)
    at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:122)
    at java.io.BufferedInputStream.fill(BufferedInputStream.java:218)
    at java.io.BufferedInputStream.read(BufferedInputStream.java:237)
locked &amp;lt;0x552ffb60&amp;gt; (a java.io.BufferedInputStream)
    at java.io.DataInputStream.readInt(DataInputStream.java:370)
    at org.apache.hadoop.dfs.DFSClient$BlockReader.readChunk(DFSClient.java:928)
locked &amp;lt;0x55300f78&amp;gt; (a org.apache.hadoop.dfs.DFSClient$BlockReader)
    at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:236)
    at org.apache.hadoop.fs.FSInputChecker.fill(FSInputChecker.java:178)
    at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:195)
    at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:159)
locked &amp;lt;0x55300f78&amp;gt; (a org.apache.hadoop.dfs.DFSClient$BlockReader)
    at org.apache.hadoop.dfs.DFSClient$BlockReader.read(DFSClient.java:823)
locked &amp;lt;0x55300f78&amp;gt; (a org.apache.hadoop.dfs.DFSClient$BlockReader)
    at org.apache.hadoop.dfs.DFSClient$DFSInputStream.readBuffer(DFSClient.java:1352)
locked &amp;lt;0x59a70e40&amp;gt; (a org.apache.hadoop.dfs.DFSClient$DFSInputStream)
    at org.apache.hadoop.dfs.DFSClient$DFSInputStream.read(DFSClient.java:1388)
locked &amp;lt;0x59a70e40&amp;gt; (a org.apache.hadoop.dfs.DFSClient$DFSInputStream)
    at org.apache.hadoop.dfs.DFSClient$DFSInputStream.read(DFSClient.java:1337)
locked &amp;lt;0x59a70e40&amp;gt; (a org.apache.hadoop.dfs.DFSClient$DFSInputStream)
    at java.io.DataInputStream.readInt(DataInputStream.java:370)
    at org.apache.hadoop.io.SequenceFile$Reader.readRecordLength(SequenceFile.java:1847)
locked &amp;lt;0x651f77b0&amp;gt; (a org.apache.hadoop.io.SequenceFile$Reader)
    at org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1877)
locked &amp;lt;0x651f77b0&amp;gt; (a org.apache.hadoop.io.SequenceFile$Reader)
    at org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:1782)
locked &amp;lt;0x651f77b0&amp;gt; (a org.apache.hadoop.io.SequenceFile$Reader)
    at org.apache.hadoop.io.MapFile$Reader.seekInternal(MapFile.java:476)
locked &amp;lt;0x59d27ba0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)
    at org.apache.hadoop.io.MapFile$Reader.getClosest(MapFile.java:558)
locked &amp;lt;0x59d27ba0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)
    at org.apache.hadoop.hbase.regionserver.HStore.rowKeyFromMapFileEmptyKeys(HStore.java:1463)
    at org.apache.hadoop.hbase.regionserver.HStore.rowAtOrBeforeFromMapFile(HStore.java:1434)
locked &amp;lt;0x59d27ba0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)
    at org.apache.hadoop.hbase.regionserver.HStore.getRowKeyAtOrBefore(HStore.java:1399)
    at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1210)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1099)
    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:438)
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)

"IPC Server handler 38 on 60020" daemon prio=10 tid=0x4dd36000 nid=0x4eab waiting for monitor entry [0x4cf0a000..0x4cf0b130]
   java.lang.Thread.State: BLOCKED (on object monitor)
    at org.apache.hadoop.hbase.regionserver.HStore.rowAtOrBeforeFromMapFile(HStore.java:1424)

waiting to lock &amp;lt;0x59d27ba0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)
    at org.apache.hadoop.hbase.regionserver.HStore.getRowKeyAtOrBefore(HStore.java:1399)
    at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1210)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1099)
    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:438)
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)

"IPC Server handler 37 on 60020" daemon prio=10 tid=0x4dd35000 nid=0x4eaa waiting for monitor entry [0x4cf5b000..0x4cf5c0b0]
   java.lang.Thread.State: BLOCKED (on object monitor)
    at org.apache.hadoop.hbase.regionserver.HStore.rowAtOrBeforeFromMapFile(HStore.java:1424)

waiting to lock &amp;lt;0x59d27ba0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)
    at org.apache.hadoop.hbase.regionserver.HStore.getRowKeyAtOrBefore(HStore.java:1399)
    at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1210)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1099)
    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:438)
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)

"IPC Server handler 35 on 60020" daemon prio=10 tid=0x4dd32c00 nid=0x4ea8 waiting for monitor entry [0x4cffd000..0x4cffdfb0]
   java.lang.Thread.State: BLOCKED (on object monitor)
    at org.apache.hadoop.hbase.regionserver.HStore.rowAtOrBeforeFromMapFile(HStore.java:1424)

waiting to lock &amp;lt;0x59d27ba0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)
    at org.apache.hadoop.hbase.regionserver.HStore.getRowKeyAtOrBefore(HStore.java:1399)
    at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1210)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1099)
    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:438)
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)

"IPC Server handler 30 on 60020" daemon prio=10 tid=0x4dd2d400 nid=0x4ea3 waiting for monitor entry [0x4d192000..0x4d193130]
   java.lang.Thread.State: BLOCKED (on object monitor)
    at org.apache.hadoop.hbase.regionserver.HStore.rowAtOrBeforeFromMapFile(HStore.java:1424)

waiting to lock &amp;lt;0x59d27ba0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)
    at org.apache.hadoop.hbase.regionserver.HStore.getRowKeyAtOrBefore(HStore.java:1399)
    at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1210)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1099)
    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:438)
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)

"IPC Server handler 29 on 60020" daemon prio=10 tid=0x4dd2c000 nid=0x4ea2 waiting for monitor entry [0x4d1e3000..0x4d1e40b0]
   java.lang.Thread.State: BLOCKED (on object monitor)
    at org.apache.hadoop.hbase.regionserver.HStore.rowAtOrBeforeFromMapFile(HStore.java:1424)

waiting to lock &amp;lt;0x59d27ba0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)
    at org.apache.hadoop.hbase.regionserver.HStore.getRowKeyAtOrBefore(HStore.java:1399)
    at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1210)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1099)
    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:438)
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)

"IPC Server handler 26 on 60020" daemon prio=10 tid=0x4dd29800 nid=0x4e9f waiting for monitor entry [0x4d2d6000..0x4d2d6f30]
   java.lang.Thread.State: BLOCKED (on object monitor)
    at org.apache.hadoop.hbase.regionserver.HStore.rowAtOrBeforeFromMapFile(HStore.java:1424)

waiting to lock &amp;lt;0x59d27ba0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)
    at org.apache.hadoop.hbase.regionserver.HStore.getRowKeyAtOrBefore(HStore.java:1399)
    at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1210)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1099)
    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:438)
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)

"IPC Server handler 17 on 60020" daemon prio=10 tid=0x4dd1f800 nid=0x4e96 waiting for monitor entry [0x4d5af000..0x4d5afeb0]
   java.lang.Thread.State: BLOCKED (on object monitor)
    at org.apache.hadoop.hbase.regionserver.HStore.rowAtOrBeforeFromMapFile(HStore.java:1424)

waiting to lock &amp;lt;0x59d27ba0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)
    at org.apache.hadoop.hbase.regionserver.HStore.getRowKeyAtOrBefore(HStore.java:1399)
    at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1210)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1099)
    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:438)
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)

"IPC Server handler 14 on 60020" daemon prio=10 tid=0x4dd1c400 nid=0x4e93 waiting for monitor entry [0x4d6a2000..0x4d6a3130]
   java.lang.Thread.State: BLOCKED (on object monitor)
    at org.apache.hadoop.hbase.regionserver.HStore.rowAtOrBeforeFromMapFile(HStore.java:1424)

waiting to lock &amp;lt;0x59d27ba0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)
    at org.apache.hadoop.hbase.regionserver.HStore.getRowKeyAtOrBefore(HStore.java:1399)
    at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1210)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1099)
    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:438)
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)

"IPC Server handler 10 on 60020" daemon prio=10 tid=0x4dd17c00 nid=0x4e8f waiting for monitor entry [0x4d7e6000..0x4d7e6f30]
   java.lang.Thread.State: BLOCKED (on object monitor)
    at org.apache.hadoop.hbase.regionserver.HStore.rowAtOrBeforeFromMapFile(HStore.java:1424)

waiting to lock &amp;lt;0x59d27ba0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)
    at org.apache.hadoop.hbase.regionserver.HStore.getRowKeyAtOrBefore(HStore.java:1399)
    at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1210)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1099)
    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:438)
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)

"IPC Server handler 7 on 60020" daemon prio=10 tid=0x4dd14800 nid=0x4e8c waiting for monitor entry [0x4d8d9000..0x4d8da1b0]
   java.lang.Thread.State: BLOCKED (on object monitor)
    at org.apache.hadoop.hbase.regionserver.HStore.rowAtOrBeforeFromMapFile(HStore.java:1424)

waiting to lock &amp;lt;0x59d27ba0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)
    at org.apache.hadoop.hbase.regionserver.HStore.getRowKeyAtOrBefore(HStore.java:1399)
    at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1210)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1099)
    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:438)
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)

"IPC Server handler 0 on 60020" daemon prio=10 tid=0x4e2c0c00 nid=0x4e85 waiting for monitor entry [0x4db10000..0x4db10e30]
   java.lang.Thread.State: BLOCKED (on object monitor)
    at org.apache.hadoop.hbase.regionserver.HStore.rowAtOrBeforeFromMapFile(HStore.java:1424)

waiting to lock &amp;lt;0x59d27ba0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Reader)
    at org.apache.hadoop.hbase.regionserver.HStore.getRowKeyAtOrBefore(HStore.java:1399)
    at org.apache.hadoop.hbase.regionserver.HRegion.getClosestRowBefore(HRegion.java:1210)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.getClosestRowBefore(HRegionServer.java:1099)
    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:438)
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)

in regionserver log, I see the following right before the client stuck (there are few other similar logs, but the client keeps going at those time points):
2008-07-17 22:31:49,404 INFO org.apache.hadoop.hbase.regionserver.HRegion: region aaa,bbb,1216304670433/1145836031 available
2008-07-17 22:31:49,404 INFO org.apache.hadoop.hbase.regionserver.HRegion: starting compaction on region aaa,bbb,1216304670433
2008-07-17 22:32:07,653 WARN org.apache.hadoop.hbase.regionserver.HStore: Exception closing reader for 1145836031/ccc
java.io.IOException: Stream closed
    at org.apache.hadoop.dfs.DFSClient$DFSInputStream.close(DFSClient.java:1319)
    at java.io.FilterInputStream.close(FilterInputStream.java:155)
    at org.apache.hadoop.io.SequenceFile$Reader.close(SequenceFile.java:1581)
    at org.apache.hadoop.io.MapFile$Reader.close(MapFile.java:577)
    at org.apache.hadoop.hbase.regionserver.HStore.closeCompactionReaders(HStore.java:917)
    at org.apache.hadoop.hbase.regionserver.HStore.compactHStoreFiles(HStore.java:910)
    at org.apache.hadoop.hbase.regionserver.HStore.compact(HStore.java:787)
    at org.apache.hadoop.hbase.regionserver.HRegion.compactStores(HRegion.java:887)
    at org.apache.hadoop.hbase.regionserver.HRegion.compactStores(HRegion.java:847)
    at org.apache.hadoop.hbase.regionserver.CompactSplitThread.run(CompactSplitThread.java:84)
(and two of the same exception, since I have 3 HStoreFIle to compact)
2008-07-17 22:32:07,912 INFO org.apache.hadoop.hbase.regionserver.HRegion: compaction completed on region aaa,bbb,1216304670433 in 18sec
[after this point, I only see regionserver rotates HLog, no other activities)
At 22:32, no suspicious log in datanode, but 8mins later, I see this
2008-07-17 22:40:07,928 WARN org.apache.hadoop.dfs.DataNode: 192.168.1.5650010:Got exception while serving blk_-38731635936101350 to /192.168.1.56
java.net.SocketTimeoutException: 480000 millis timeout while waiting for channel to be ready for write. ch : java.nio.channels.SocketChannel[connected local=/192.168.1.56:50010 remote=/192.168.1.56:40691]
    at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:170)
    at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:144)
    at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:105)
    at java.io.BufferedOutputStream.write(BufferedOutputStream.java:105)
    at java.io.DataOutputStream.write(DataOutputStream.java:90)
    at org.apache.hadoop.dfs.DataNode$BlockSender.sendChunks(DataNode.java:1784)
    at org.apache.hadoop.dfs.DataNode$BlockSender.sendBlock(DataNode.java:1840)
    at org.apache.hadoop.dfs.DataNode$DataXceiver.readBlock(DataNode.java:1055)
    at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:984)
    at java.lang.Thread.run(Thread.java:619)
for this particular block in question, I found around the region available time:
2008-07-17 22:31:49,642 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-38731635936101350 src: /192.168.1.56:37878 dest: /192.168.1.56:50010
2008-07-17 22:31:56,856 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-38731635936101350 of size 67108864 from /192.168.1.56
2008-07-17 22:31:56,857 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 1 for block blk_-38731635936101350 terminating
And after the hbase client stuck, I found one datanode keeps sending the same block to the regionserver, which is blocked as shown above.
=====
For the record, I did not see this "Stream closed" error on another small 4-node cluster with trunk r675659 (same hadoop version with the 3-node cluster above).
For hbase trunk r677011, I got 
java.lang.NullPointerException
        at org.apache.hadoop.hbase.client.ServerCallable.getServerName(ServerCallable.java:63)
        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getRegionServerWithRetries(HConnectionManager.java:886
        at org.apache.hadoop.hbase.client.HTable.commit(HTable.java:1161)
then, the region server stucks
08/07/18 05:29:29 INFO ipc.RPC: Problem connecting to server: /192.168.1.56:60020
stack dump shows similar as the above one, and I&amp;amp;apos;m also seeing the dfs exception.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.TestCompare.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestGet2.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Memcache.java</file>
			<file type="M">org.apache.hadoop.hbase.io.BatchUpdate.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
		</fixedFiles>
	</bug>
	<bug id="793" opendate="2008-08-04 06:52:52" fixdate="2008-08-04 17:27:55" resolution="Fixed">
		<buginformation>
			<summary>HTable.getStartKeys() ignores table names when matching columns</summary>
			<description>Dru Jensen wrote on hbase-user@
&amp;gt; I found what is causing the same rows being sent to multiple map tasks.
&amp;gt; If you have the same column family name in other tables, the Test will
&amp;gt; send the same rows to multiple map reducers.
Stack wrote in response:
&amp;gt; Indeed, a bug in getStartKeys will make us process all tables that have
&amp;gt; a column family name in common.
[...]
&amp;gt; The above Visitor is visiting the meta table.  Its checking column
&amp;gt; family name.  Any region that is not offlined or split gets added to the
&amp;gt; list of regions.  Its not checking that the region belongs to the wanted
&amp;gt; table.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
		</fixedFiles>
	</bug>
	<bug id="790" opendate="2008-08-01 00:38:11" fixdate="2008-08-05 19:06:05" resolution="Fixed">
		<buginformation>
			<summary>During import, single region blocks requests for &gt;10 minutes, thread dumps, throws out pending requests, and continues</summary>
			<description>During a batch import, I have two processes importing into a single region.
The behavior I saw was a regionserver with 2 regions of the table in question on it.  The first region split, and the new regions were reassigned to another regionserver.
Following that, inserting into the region that was left over began to block client requests.  I am attaching the regionserver log; below is the specific problem area:
2008-07-31 15:38:24,190 DEBUG org.apache.hadoop.hbase.client.HConnectionManager$TableServers: Cache hit in table locations for row &amp;lt;&amp;gt; and tableName .META.: location server 72.34.249.217:60020, location region name .META.,,1
2008-07-31 15:38:24,194 INFO org.apache.hadoop.hbase.regionserver.CompactSplitThread: region split, META updated, and report to master all successful. Old region=REGION =&amp;gt; {NAME =&amp;gt; &amp;amp;apos;items,01beddd6-813b-4f2b-ac48-a0cef395cb7e,12175434512
2008-07-31 15:38:34,052 INFO org.apache.hadoop.hbase.regionserver.HRegion: Blocking updates for &amp;amp;apos;IPC Server handler 7 on 60020&amp;amp;apos; on region items,8001eb31-98bb-4087-bd8d-e4b42805addb,1217543451296: Memcache size 64.0m is &amp;gt;= than blocking
2008-07-31 15:39:00,270 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 60020, call batchUpdate([B@17b4239f, row =&amp;gt; 02c241b4-9d32-452d-8dab-247f4af693eb, {column =&amp;gt; content:title, value =&amp;gt; &amp;amp;apos;...&amp;amp;apos;, column =&amp;gt; content:content, va
org.apache.hadoop.hbase.NotServingRegionException: items,01beddd6-813b-4f2b-ac48-a0cef395cb7e,1217543451296
        at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:1436)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1147)
        at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:616)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:473)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)
2008-07-31 15:39:09,547 INFO org.apache.hadoop.hbase.regionserver.HRegion: Blocking updates for &amp;amp;apos;IPC Server handler 8 on 60020&amp;amp;apos; on region items,8001eb31-98bb-4087-bd8d-e4b42805addb,1217543451296: Memcache size 64.0m is &amp;gt;= than blocking
2008-07-31 15:39:44,079 INFO org.apache.hadoop.hbase.regionserver.HRegion: Blocking updates for &amp;amp;apos;IPC Server handler 9 on 60020&amp;amp;apos; on region items,8001eb31-98bb-4087-bd8d-e4b42805addb,1217543451296: Memcache size 64.0m is &amp;gt;= than blocking
2008-07-31 15:40:19,574 INFO org.apache.hadoop.hbase.regionserver.HRegion: Blocking updates for &amp;amp;apos;IPC Server handler 1 on 60020&amp;amp;apos; on region items,8001eb31-98bb-4087-bd8d-e4b42805addb,1217543451296: Memcache size 64.0m is &amp;gt;= than blocking
2008-07-31 15:49:09,130 INFO org.apache.hadoop.hbase.regionserver.LogRoller: Rolling hlog. Number of entries: 1
2008-07-31 15:49:09,144 DEBUG org.apache.hadoop.hbase.regionserver.HLog: Closing current log writer /hbase/log_72.34.249.212_1217535541159_60020/hlog.dat.1217543884691
2008-07-31 15:49:09,146 INFO org.apache.hadoop.hbase.regionserver.HLog: New log writer created at /hbase/log_72.34.249.212_1217535541159_60020/hlog.dat.1217544549145
2008-07-31 16:03:09,060 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Started memcache flush for region items,8001eb31-98bb-4087-bd8d-e4b42805addb,1217543451296. Current region memcache size 64.0m
2008-07-31 16:03:09,467 INFO org.apache.hadoop.hbase.regionserver.HRegion: Unblocking updates for region items,8001eb31-98bb-4087-bd8d-e4b42805addb,1217543451296 &amp;amp;apos;IPC Server handler 5 on 60020&amp;amp;apos;
2008-07-31 16:03:09,478 INFO org.apache.hadoop.ipc.Server: Process Thread Dump: Discarding call batchUpdate([B@4e727e0e, row =&amp;gt; c08408b4-b68c-433c-ba3f-d46d3ba73288, {column =&amp;gt; content:title, value =&amp;gt; &amp;amp;apos;...&amp;amp;apos;, column =&amp;gt; content:content, v
As you can see there was a 14 minute delay between updates being blocked, and the unblocking occurring.
All the pending batchUpdates were thrown out (too old) and then importing proceeded normally.
The same behavior repeated itself later on a different regionserver, and again after a while it unfroze, kicked out pending updates, and continued.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Flusher.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestGet2.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Memcache.java</file>
			<file type="M">org.apache.hadoop.hbase.HStoreKey.java</file>
		</fixedFiles>
	</bug>
	<bug id="805" opendate="2008-08-08 17:49:02" fixdate="2008-08-11 18:03:51" resolution="Fixed">
		<buginformation>
			<summary>Remove unnecessary getRow overloads in HRS</summary>
			<description>HRS currently contains:
  public RowResult getRow(final byte [] regionName, final byte [] row, final long ts)
  public RowResult getRow(final byte [] regionName, final byte [] row, final byte [][] columns)
  public RowResult getRow(final byte [] regionName, final byte [] row, final byte [][] columns, final long ts)
The first two call the last one which calls HR.getFull.
Changes will be made to HTable to map all getRow calls to a single getRow HRS method.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.1, 0.18.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.HRegionInterface.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
		</fixedFiles>
	</bug>
	<bug id="811" opendate="2008-08-10 02:22:59" fixdate="2008-08-11 20:49:42" resolution="Fixed">
		<buginformation>
			<summary>HTD is not fully copyable</summary>
			<description>Part of my HBASE-62 patch was not applied. </description>
			<version>0.2.0</version>
			<fixedVersion>0.2.1, 0.18.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.HColumnDescriptor.java</file>
			<file type="M">org.apache.hadoop.hbase.client.UnmodifyableHTableDescriptor.java</file>
			<file type="M">org.apache.hadoop.hbase.HTableDescriptor.java</file>
		</fixedFiles>
		<links>
			<link type="Blocker" description="blocks">729</link>
		</links>
	</bug>
	<bug id="729" opendate="2008-07-08 09:36:22" fixdate="2008-08-11 21:58:39" resolution="Fixed">
		<buginformation>
			<summary>client region/metadata cache should have a public method for invalidating entries</summary>
			<description>While writing a testcase for HBASE-62, I observed that table metadata is cached as part of the region information cached  client side. This cached region information (and therefore table metadata) is not directly invalidated by disable/enable table, so to get up to date metadata the client may have to use a scanner over .META. directly using the meta visitor. Ideally other client code  for example the support for HBASE-62  should be able to invalidate entries as necessary, so then the next HTable.getTableDescriptor() would go to meta to return up to date information instead of incorrectly reusing outdated information from the cache.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.1, 0.18.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestHTable.java</file>
		</fixedFiles>
		<links>
			<link type="Blocker" description="blocks">800</link>
			<link type="Blocker" description="is blocked by">811</link>
			<link type="Reference" description="is related to">62</link>
		</links>
	</bug>
	<bug id="819" opendate="2008-08-11 23:57:39" fixdate="2008-08-12 01:01:37" resolution="Fixed">
		<buginformation>
			<summary>Remove DOS-style ^M carriage returns from all code where found</summary>
			<description>There are a few files that contain DOS-style carriage returns.  This is leading to issues when applying patches.
The presence of these may also be causing a snowball effect as some IDEs/editors may see one and attempt to apply that LF/CR format to all lines or files.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.1, 0.18.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.HRegionInterface.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestBatchUpdate.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.HConstants.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
		</fixedFiles>
	</bug>
	<bug id="812" opendate="2008-08-10 15:09:18" fixdate="2008-08-12 04:21:40" resolution="Fixed">
		<buginformation>
			<summary>Compaction needs little better skip algo</summary>
			<description>Looking at this section of one of my compaction&amp;amp;apos;s we have 3 files to compact the new algo is working great in my test but I see this below often we are skipping 2 out of the 3 files and compacting 1 file. 1 file is kind of a wast might as well just copy the file my suggestion is if there is only 1 file left after the new algo skips then just go on to the next column and skip the last file also. This will help improve compaction times a little more. 

2008-08-10 10:00:45,310 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Compaction size of 1339600874/size: 4.6m, skipped 2, 4851776
2008-08-10 10:00:45,438 DEBUG org.apache.hadoop.hbase.regionserver.HStore: started compaction of 1 files into /hbase/webdata/compaction.dir/1339600874/size/mapfiles/8653208152776334891
2008-08-10 10:00:46,838 DEBUG org.apache.hadoop.hbase.regionserver.HStore: moving /hbase/webdata/compaction.dir/1339600874/size/mapfiles/8653208152776334891 to /hbase/webdata/1339600874/size/mapfiles/7539342470259528578
2008-08-10 10:00:47,166 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Completed compaction of 1339600874/size store size is 4.6m

</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.1, 0.18.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
		</fixedFiles>
	</bug>
	<bug id="818" opendate="2008-08-11 23:53:09" fixdate="2008-08-12 16:22:05" resolution="Fixed">
		<buginformation>
			<summary>Deadlock running &amp;apos;flushSomeRegions&amp;apos;</summary>
			<description>Playing with MR uploading no a regionserver with 60+ regions, I ran into a deadlock:

Found one Java-level deadlock:
=============================
"IPC Server handler 19 on 60020":
  waiting to lock monitor 0x084be38c (object 0xb6f69a70, a org.apache.hadoop.hbase.regionserver.Flusher),
  which is held by "IPC Server handler 16 on 60020"
"IPC Server handler 16 on 60020":
  waiting to lock monitor 0x080f8dec (object 0xb73610c0, a org.apache.hadoop.hbase.regionserver.HRegion$WriteState),
  which is held by "IPC Server handler 2 on 60020"
"IPC Server handler 2 on 60020":
  waiting to lock monitor 0x086e8fe8 (object 0xb6f69cf0, a java.util.HashSet),
  which is held by "IPC Server handler 16 on 60020"

Java stack information for the threads listed above:
===================================================
"IPC Server handler 19 on 60020":
        at org.apache.hadoop.hbase.regionserver.Flusher.flushSomeRegions(Flusher.java:261)
        - waiting to lock &amp;lt;0xb6f69a70&amp;gt; (a org.apache.hadoop.hbase.regionserver.Flusher)
        at org.apache.hadoop.hbase.regionserver.Flusher.reclaimMemcacheMemory(Flusher.java:252)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1136)
        at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:623)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:473)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)
"IPC Server handler 16 on 60020":
        at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:948)
        - waiting to lock &amp;lt;0xb73610c0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HRegion$WriteState)
        at org.apache.hadoop.hbase.regionserver.Flusher.flushRegion(Flusher.java:173)
        - locked &amp;lt;0xb6f69cf0&amp;gt; (a java.util.HashSet)
        at org.apache.hadoop.hbase.regionserver.Flusher.flushSomeRegions(Flusher.java:267)
        - locked &amp;lt;0xb6f69a70&amp;gt; (a org.apache.hadoop.hbase.regionserver.Flusher)
        at org.apache.hadoop.hbase.regionserver.Flusher.reclaimMemcacheMemory(Flusher.java:252)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1136)
        at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:623)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:473)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)
"IPC Server handler 2 on 60020":
        at org.apache.hadoop.hbase.regionserver.Flusher.addRegion(Flusher.java:237)
        - waiting to lock &amp;lt;0xb6f69cf0&amp;gt; (a java.util.HashSet)
        at org.apache.hadoop.hbase.regionserver.Flusher.request(Flusher.java:114)
        at org.apache.hadoop.hbase.regionserver.HRegion.requestFlush(HRegion.java:1627)
        - locked &amp;lt;0xb73610c0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HRegion$WriteState)
        at org.apache.hadoop.hbase.regionserver.HRegion.update(HRegion.java:1614)
        at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1398)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1137)
        at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:623)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:473)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)

Found 1 deadlock.


Regionserver is hosed.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.1, 0.18.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
		</fixedFiles>
	</bug>
	<bug id="824" opendate="2008-08-12 21:49:40" fixdate="2008-08-12 22:12:10" resolution="Fixed">
		<buginformation>
			<summary>Bug in Hlog we print array of byes for region name</summary>
			<description>I see lines in the debug logs like this

2008-08-12 16:13:20,638 DEBUG org.apache.hadoop.hbase.regionserver.HLog: Found 1 logs to remove using oldest outstanding seqnum of 265156192 from region [B@18a3257

</description>
			<version>0.2.1</version>
			<fixedVersion>0.2.1, 0.18.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HLog.java</file>
		</fixedFiles>
	</bug>
	<bug id="825" opendate="2008-08-12 23:36:03" fixdate="2008-08-13 00:21:34" resolution="Fixed">
		<buginformation>
			<summary>master logs showing byte[] in place of string on logging</summary>
			<description>
2008-08-12 17:39:48,586 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region [B@6a63d3 because it is already closing.

</description>
			<version>0.2.1</version>
			<fixedVersion>0.2.1, 0.18.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.RegionManager.java</file>
		</fixedFiles>
	</bug>
	<bug id="831" opendate="2008-08-14 17:22:06" fixdate="2008-08-14 19:14:54" resolution="Fixed">
		<buginformation>
			<summary>committing BatchUpdate with no row should complain</summary>
			<description>Running this code:
BatchUpdate update = new BatchUpdate();
update.put(key, value);
table.commit(update);
Down in getRegionServer, this triggers an NPE because the row is null (which I saw because I was running in a debugger); this NPE gets retried somewhere in the bowels of IPC.  Instead, we should either remove the zero-arg BatchUpdate constructor, or have table.commit throw a runtimeexception if the row is null.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.1, 0.18.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
		</fixedFiles>
	</bug>
	<bug id="830" opendate="2008-08-14 15:28:47" fixdate="2008-08-15 18:31:17" resolution="Fixed">
		<buginformation>
			<summary>Debugging HCM.locateRegionInMeta is painful</summary>
			<description>I&amp;amp;apos;ve been debugging a case where a bunch of reduces were hanging for no apparent reason and then get killed because they did not do anything for 600 seconds. I figured that it&amp;amp;apos;s because we are stuck in a very long waiting time due to retry backoffs. 

public static int RETRY_BACKOFF[] = { 1, 1, 1, 1, 2, 4, 8, 16, 32, 64 };


That means we wait 10 sec, 10 sec, 10, 10, ... then 640 sec. That&amp;amp;apos;s a long time, do we really need that much time to finally be warned that there&amp;amp;apos;s a bug in HBase? 
Also, the places where we get this:

LOG.debug("reloading table servers because: " + t.getMessage());


should be more verbose. I my logs these are caused by a table not found but the only thing I see is "reloading table servers because: tableName".</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.1, 0.18.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.HConstants.java</file>
		</fixedFiles>
	</bug>
	<bug id="833" opendate="2008-08-15 18:36:51" fixdate="2008-08-15 19:03:51" resolution="Fixed">
		<buginformation>
			<summary>Doing an insert with an unknown family throws a NPE in HRS</summary>
			<description>When I added the validation of value&amp;amp;apos;s length, I did not check if the family existed. Throws an ugly:

08/08/15 14:15:55 DEBUG client.HConnectionManager$TableServers: reloading table servers because: java.io.IOException: java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.HRegionServer.validateValuesLength(HRegionServer.java:1161)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1136)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:473)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:896)


with some retries.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.1, 0.18.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
		</fixedFiles>
	</bug>
	<bug id="697" opendate="2008-06-18 23:58:13" fixdate="2008-08-16 22:14:39" resolution="Fixed">
		<buginformation>
			<summary>thrift idl needs update/edit to match new 0.2 API (and to fix bugs)</summary>
			<description>Talking w/ Bryan, moving this out of the way of the 0.2.0 release.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.1, 0.18.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">src.examples.thrift.DemoClient.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.generated.IOError.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.generated.Constants.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.generated.RegionDescriptor.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.generated.IllegalArgument.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.generated.Hbase.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.generated.BatchMutation.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.generated.Mutation.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.generated.ScanEntry.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.generated.AlreadyExists.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.ThriftUtilities.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.generated.NotFound.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.generated.ColumnDescriptor.java</file>
		</fixedFiles>
		<links>
			<link type="Blocker" description="blocks">585</link>
			<link type="Incorporates" description="incorporates">740</link>
			<link type="Reference" description="relates to">822</link>
			<link type="Reference" description="relates to">657</link>
			<link type="Reference" description="relates to">800</link>
		</links>
	</bug>
	<bug id="810" opendate="2008-08-09 01:14:46" fixdate="2008-08-21 21:40:31" resolution="Fixed">
		<buginformation>
			<summary>Prevent temporary deadlocks when, during a scan with write operations, the region splits</summary>
			<description>HBASE-804 was not about the good problem, this one is. Anyone that iterates through the results of a scanner and that rewrites data back into the row at each iteration will hit a UnknownScannerException if a split occurs. See the stack in the referred jira. Timeline :
Split occurs, acquires a write lock and waits for scanners to finish
The scanner in the custom code iterates and writes data until the write is blocked by the lock
deadlock
The scanner timeouts thus the region splits but the USE will be thrown when next() is called
Inside a Map, the task will simply be retried when the first one fails. Elsewhere, it becomes more complicated.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.1, 0.18.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestSplit.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
		</fixedFiles>
	</bug>
	<bug id="843" opendate="2008-08-25 18:44:31" fixdate="2008-08-25 19:19:21" resolution="Fixed">
		<buginformation>
			<summary>Deleting and recreating a table in a single process does not work</summary>
			<description>When you delete and then recreate/enable the same table in the same process, when you get the HTable reference to the new table you are actually given the old table.
The connection information is never deleted/invalidated.
To fix, we add a call to HConnectionManager.deleteConnectionInfo(conf) at the end of HBaseAdmin.deleteTable().  This information will then be re-loaded with the latest table references once the client asks for it.</description>
			<version>0.2.1</version>
			<fixedVersion>0.2.1, 0.18.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
		</fixedFiles>
	</bug>
	<bug id="768" opendate="2008-07-23 18:47:57" fixdate="2008-08-28 22:10:27" resolution="Fixed">
		<buginformation>
			<summary>[Migration] This message &amp;apos;java.io.IOException: Install 0.1.x of hbase and run its migration first&amp;apos; is useless</summary>
			<description>You&amp;amp;apos;ll see above message after you&amp;amp;apos;ve committed to a new version of hadoop.  You won&amp;amp;apos;t be able to go back.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.1, 0.18.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.Migrate.java</file>
		</fixedFiles>
	</bug>
	<bug id="855" opendate="2008-08-29 07:45:35" fixdate="2008-08-31 04:21:08" resolution="Fixed">
		<buginformation>
			<summary>compaction can return less versions then we should in some cases</summary>
			<description>say we have a column with max version = 3 and we have 3 records  
we insert a new record with a old timestamp.
What happeds in the compaction is the the new record with the old timestamp get read first and could push out some of our 
versions if the new record(s) with the old timestamp has a expired ttl.
This happens because we track the total times we see a row/column but do not reduce this count if the cell is expired
and sense we pass the cell in order of the newest HStoreFile first with the newest records passed might not be the newest timestamps.
Got to wait for HBASE-834 to be committed then I can add a patch for this bug. will be a simple fix.</description>
			<version>0.2.1</version>
			<fixedVersion>0.2.1, 0.18.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
		</fixedFiles>
	</bug>
	<bug id="860" opendate="2008-09-01 10:35:33" fixdate="2008-09-01 21:47:35" resolution="Fixed">
		<buginformation>
			<summary>IndexTableReduce doesnt write the column name as the lucene index field properly.</summary>
			<description>Instead of using the table column name as the field in the lucene index, the byte array jvm object id is written to the lucene index.  i.e.  [B@234DE3 instead of "myColFamily:myCol"
In the class IndexTableReduce, essentially one line of code needs to be changed as far as i can see to fix this issue.  I will be submitting a patch here within the hour.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.1, 0.18.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapred.IndexTableReduce.java</file>
		</fixedFiles>
	</bug>
	<bug id="865" opendate="2008-09-03 21:24:04" fixdate="2008-09-04 22:59:33" resolution="Fixed">
		<buginformation>
			<summary>Fix javadoc warnings</summary>
			<description>There are javadoc warnings in both the 0.2 branch and in trunk. They must be fixed before 0.2.2 or 0.18.0 are released.</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.2, 0.18.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.TransactionalRegionInterface.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HLog.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.HStoreKey.java</file>
			<file type="M">org.apache.hadoop.hbase.util.Bytes.java</file>
			<file type="M">org.apache.hadoop.hbase.client.transactional.TransactionalTable.java</file>
			<file type="M">org.apache.hadoop.hbase.client.transactional.TransactionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
		</fixedFiles>
	</bug>
	<bug id="872" opendate="2008-09-05 15:50:29" fixdate="2008-09-05 23:57:53" resolution="Fixed">
		<buginformation>
			<summary>Getting exceptions in shell when creating/disabling tables</summary>
			<description>On the list from Dru Jensen:
I am testing the release candidate with hadoop 0.17.2.1 release.  I am curious if others are seeing this or if I have something mis-configured.
I reformatted the dfs and recreated everything from scratch.
hbase(main):009:0&amp;gt; version
Version: 0.2.1, r691710, Wed Sep  3 11:50:24 PDT 2008
I occasionally get the following error performing a create table.  However when I do a list, the table was successfully created.
hbase(main):007:0&amp;gt; create &amp;amp;apos;test&amp;amp;apos;, &amp;amp;apos;avg&amp;amp;apos;, &amp;amp;apos;std&amp;amp;apos;, &amp;amp;apos;max&amp;amp;apos;
NativeException: org.apache.hadoop.hbase.client.NoServerForRegionException: No server address listed in .META. for region test,,1220628716239
       from org/apache/hadoop/hbase/client/HConnectionManager.java:536:in `locateRegionInMeta&amp;amp;apos;
       from org/apache/hadoop/hbase/client/HConnectionManager.java:459:in `locateRegion&amp;amp;apos;
       from org/apache/hadoop/hbase/client/HConnectionManager.java:419:in `locateRegion&amp;amp;apos;
       from org/apache/hadoop/hbase/client/HBaseAdmin.java:157:in `createTable&amp;amp;apos;
       from sun/reflect/NativeMethodAccessorImpl.java:-2:in `invoke0&amp;amp;apos;
       from sun/reflect/NativeMethodAccessorImpl.java:39:in `invoke&amp;amp;apos;
       from sun/reflect/DelegatingMethodAccessorImpl.java:25:in `invoke&amp;amp;apos;
       from java/lang/reflect/Method.java:585:in `invoke&amp;amp;apos;
       from org/jruby/javasupport/JavaMethod.java:250:in `invokeWithExceptionHandling&amp;amp;apos;
       from org/jruby/javasupport/JavaMethod.java:219:in `invoke&amp;amp;apos;
       from org/jruby/javasupport/JavaClass.java:416:in `execute&amp;amp;apos;
       from org/jruby/internal/runtime/methods/SimpleCallbackMethod.java:67:in `call&amp;amp;apos;
       from org/jruby/internal/runtime/methods/DynamicMethod.java:78:in `call&amp;amp;apos;
       from org/jruby/runtime/CallSite.java:329:in `call&amp;amp;apos;
       from org/jruby/evaluator/ASTInterpreter.java:649:in `callNode&amp;amp;apos;
       from org/jruby/evaluator/ASTInterpreter.java:324:in `evalInternal&amp;amp;apos;
... 121 levels...
       from ruby.opt.hbase_minus_0_dot_2_dot_1.bin.hirbInvokermethod__23$RUBY$startOpt:-1:in `call&amp;amp;apos;
       from org/jruby/internal/runtime/methods/DynamicMethod.java:74:in `call&amp;amp;apos;
       from org/jruby/internal/runtime/methods/CompiledMethod.java:48:in `call&amp;amp;apos;
       from org/jruby/runtime/CallSite.java:123:in `cacheAndCall&amp;amp;apos;
       from org/jruby/runtime/CallSite.java:298:in `call&amp;amp;apos;
       from ruby/opt/hbase_minus_0_dot_2_dot_1/bin//opt/hbase/bin/../bin/hirb.rb:351:in `_file_&amp;amp;apos;
       from ruby/opt/hbase_minus_0_dot_2_dot_1/bin//opt/hbase/bin/../bin/hirb.rb:-1:in `_file_&amp;amp;apos;
       from ruby/opt/hbase_minus_0_dot_2_dot_1/bin//opt/hbase/bin/../bin/hirb.rb:-1:in `load&amp;amp;apos;
       from org/jruby/Ruby.java:512:in `runScript&amp;amp;apos;
       from org/jruby/Ruby.java:432:in `runNormally&amp;amp;apos;
       from org/jruby/Ruby.java:312:in `runFromMain&amp;amp;apos;
       from org/jruby/Main.java:144:in `run&amp;amp;apos;
       from org/jruby/Main.java:89:in `run&amp;amp;apos;
       from org/jruby/Main.java:80:in `main&amp;amp;apos;
       from /opt/hbase/bin/../bin/hirb.rb:228:in `create&amp;amp;apos;
       from (hbase):8:in `binding&amp;amp;apos;hbase(main):008:0&amp;gt;
And occasionally, I get this exception when trying to disable a table. However it was successfully disabled.
hbase(main):002:0&amp;gt; disable &amp;amp;apos;test&amp;amp;apos;
NativeException: java.io.IOException: unable to disable table test
       from org/apache/hadoop/hbase/client/HBaseAdmin.java:418:in `disableTable&amp;amp;apos;
       from org/apache/hadoop/hbase/client/HBaseAdmin.java:379:in `disableTable&amp;amp;apos;
       from sun/reflect/NativeMethodAccessorImpl.java:-2:in `invoke0&amp;amp;apos;
       from sun/reflect/NativeMethodAccessorImpl.java:39:in `invoke&amp;amp;apos;
       from sun/reflect/DelegatingMethodAccessorImpl.java:25:in `invoke&amp;amp;apos;
       from java/lang/reflect/Method.java:585:in `invoke&amp;amp;apos;
       from org/jruby/javasupport/JavaMethod.java:250:in `invokeWithExceptionHandling&amp;amp;apos;
       from org/jruby/javasupport/JavaMethod.java:219:in `invoke&amp;amp;apos;
       from org/jruby/javasupport/JavaClass.java:416:in `execute&amp;amp;apos;
       from org/jruby/internal/runtime/methods/SimpleCallbackMethod.java:67:in `call&amp;amp;apos;
       from org/jruby/internal/runtime/methods/DynamicMethod.java:78:in `call&amp;amp;apos;
       from org/jruby/runtime/CallSite.java:155:in `cacheAndCall&amp;amp;apos;
       from org/jruby/runtime/CallSite.java:332:in `call&amp;amp;apos;
       from org/jruby/evaluator/ASTInterpreter.java:649:in `callNode&amp;amp;apos;
       from org/jruby/evaluator/ASTInterpreter.java:324:in `evalInternal&amp;amp;apos;
       from org/jruby/evaluator/ASTInterpreter.java:620:in `blockNode&amp;amp;apos;
... 121 levels...
       from ruby.opt.hbase_minus_0_dot_2_dot_1.bin.hirbInvokermethod__23$RUBY$startOpt:-1:in `call&amp;amp;apos;
       from org/jruby/internal/runtime/methods/DynamicMethod.java:74:in `call&amp;amp;apos;
       from org/jruby/internal/runtime/methods/CompiledMethod.java:48:in `call&amp;amp;apos;
       from org/jruby/runtime/CallSite.java:123:in `cacheAndCall&amp;amp;apos;
       from org/jruby/runtime/CallSite.java:298:in `call&amp;amp;apos;
       from ruby/opt/hbase_minus_0_dot_2_dot_1/bin//opt/hbase/bin/../bin/hirb.rb:351:in `_file_&amp;amp;apos;
       from ruby/opt/hbase_minus_0_dot_2_dot_1/bin//opt/hbase/bin/../bin/hirb.rb:-1:in `_file_&amp;amp;apos;
       from ruby/opt/hbase_minus_0_dot_2_dot_1/bin//opt/hbase/bin/../bin/hirb.rb:-1:in `load&amp;amp;apos;
       from org/jruby/Ruby.java:512:in `runScript&amp;amp;apos;
       from org/jruby/Ruby.java:432:in `runNormally&amp;amp;apos;
       from org/jruby/Ruby.java:312:in `runFromMain&amp;amp;apos;
       from org/jruby/Main.java:144:in `run&amp;amp;apos;
       from org/jruby/Main.java:89:in `run&amp;amp;apos;
       from org/jruby/Main.java:80:in `main&amp;amp;apos;
       from /opt/hbase/bin/../bin/hirb.rb:254:in `disable&amp;amp;apos;
</description>
			<version>0.2.1</version>
			<fixedVersion>0.2.1, 0.18.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.migration.v5.HColumnDescriptor.java</file>
			<file type="M">org.apache.hadoop.hbase.client.RegionOfflineException.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
			<file type="M">org.apache.hadoop.hbase.TableNotFoundException.java</file>
			<file type="M">org.apache.hadoop.hbase.client.NoServerForRegionException.java</file>
		</fixedFiles>
	</bug>
	<bug id="871" opendate="2008-09-04 21:40:49" fixdate="2008-09-07 22:17:18" resolution="Fixed">
		<buginformation>
			<summary>Major compaction periodicity should be specifyable at the column family level, not cluster wide</summary>
			<description>jon gray has a table of ten rows and a couple of columns that is constantly being updated.  Has max versions of 2.  This table is growing fast because all versions written are kept until a major compaction.  The way this table is being used is different than that of others.  Would be good if he could have major compactions run more often than the default once a day.</description>
			<version>0.2.1</version>
			<fixedVersion>0.2.1, 0.18.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStoreFile.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.HStoreKey.java</file>
			<file type="M">org.apache.hadoop.hbase.client.MetaScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHStoreFile.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.master.MetaRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Memcache.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStoreScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.HConstants.java</file>
			<file type="M">org.apache.hadoop.hbase.HRegionInfo.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">800</link>
		</links>
	</bug>
	<bug id="868" opendate="2008-09-04 17:08:45" fixdate="2008-09-08 17:17:22" resolution="Fixed">
		<buginformation>
			<summary>Incrementing binary rows cause strange behavior once table splits</summary>
			<description>We&amp;amp;apos;re now using incrementing binary row keys and to this point had only been doing small tests with them, never having actually had a table split.
I&amp;amp;apos;m still working through the logs but it seems that there&amp;amp;apos;s a problem somewhere with startKey and endKeys.
Binary in general is not well supported (inconsistent in display in the logs, very odd rendering in the web ui, hard to interpret in the shell, etc..)  Once we figure out these serious bugs we will spend some time trying to clean that up.  But right now this makes things even harder to debug.
The actual symptoms are that my import eventually started to throw (in the client and on the region server):
org.apache.hadoop.hbase.regionserver.WrongRegionException: org.apache.hadoop.hbase.regionserver.WrongRegionException: Requested row out of range for HRegion sources,,1220546297947, startKey=&amp;amp;apos;&amp;amp;apos;, getEndKey()=&amp;amp;apos;
&amp;amp;apos;, row=&amp;amp;apos;c&amp;amp;apos;
        at org.apache.hadoop.hbase.regionserver.HRegion.checkRow(HRegion.java:1775)
        at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1831)
        at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1387)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1145)
        at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:616)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:473)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
There are 3 regionservers, but this error only happens on one of them (while the other two always continue normally, allowing updates to this same table).
The regionserver that this happens on is special for two reasons, one it is hosting the META table.  And secondly it also hosts the first region in the table, startkey = &amp;amp;apos;&amp;amp;apos;.  I&amp;amp;apos;m unsure which is the cause, I have a clue leading to both.
After about 15 minutes, the regionserver sees:
2008-09-04 09:52:57,948 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Started memcache flush for region .META.,,1. Current region memcache size 24.5k
2008-09-04 09:52:58,003 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Added /hbase/.META./1028785192/historian/mapfiles/8699673838203663799 with 106 entries, sequence id 25341510, data size 8.9k, file size 10.6k
2008-09-04 09:52:58,050 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Added /hbase/.META./1028785192/info/mapfiles/1791564557665476834 with 96 entries, sequence id 25341510, data size 14.2k, file size 15.8k
2008-09-04 09:52:58,050 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Finished memcache flush for region .META.,,1 in 102ms, sequence id=25341510, compaction requested=true
2008-09-04 09:52:58,050 DEBUG org.apache.hadoop.hbase.regionserver.CompactSplitThread: Compaction requested for region: .META.,,1
2008-09-04 09:52:58,051 INFO org.apache.hadoop.hbase.regionserver.HRegion: starting compaction on region .META.,,1
2008-09-04 09:52:58,055 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Compaction size of 1028785192/historian: 41.9k; Skipped 1 files , size: 21957
2008-09-04 09:52:58,088 DEBUG org.apache.hadoop.hbase.regionserver.HStore: started compaction of 2 files into /hbase/.META./compaction.dir/1028785192/historian/mapfiles/6948796056606699674
2008-09-04 09:52:58,128 DEBUG org.apache.hadoop.hbase.regionserver.HStore: moving /hbase/.META./compaction.dir/1028785192/historian/mapfiles/6948796056606699674 to /hbase/.META./1028785192/historian/mapfiles/75733875840914142
2008-09-04 09:52:58,175 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Completed compaction of 1028785192/historian store size is 41.1k; time since last major compaction: 5426 seconds
2008-09-04 09:52:58,179 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Compaction size of 1028785192/info: 61.9k; Skipped 0 files , size: 0
2008-09-04 09:52:58,192 DEBUG org.apache.hadoop.hbase.regionserver.HStore: started compaction of 3 files into /hbase/.META./compaction.dir/1028785192/info/mapfiles/7781013568996125923
2008-09-04 09:52:58,260 DEBUG org.apache.hadoop.hbase.regionserver.HStore: moving /hbase/.META./compaction.dir/1028785192/info/mapfiles/7781013568996125923 to /hbase/.META./1028785192/info/mapfiles/2187291308709057119
2008-09-04 09:52:58,290 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Completed compaction of 1028785192/info store size is 61.0k; time since last major compaction: 32534 seconds
2008-09-04 09:52:58,296 INFO org.apache.hadoop.hbase.regionserver.HRegion: compaction completed on region .META.,,1 in 0sec
2008-09-04 09:53:09,620 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Scanner -2085474968086468199 lease expired
2008-09-04 09:54:35,449 INFO org.apache.hadoop.hbase.regionserver.LogRoller: Rolling hlog. Number of entries: 30009
Following this, insertion continues normally.  This leads me to believe there&amp;amp;apos;s an issue with the META table memcache, but oddly the other regions of this table on other regionservers continue on fine.
As for the hosting the first region of the table on this region server, it seems to be consistent that I get the row out of range errors when looking for a region with startkey = &amp;amp;apos;&amp;amp;apos;, although there are 5 other regions on this RS.
Will attach full logs from master and three RS.  Also a couple screenshots showing weird behavior in listing the regions in the table.</description>
			<version>0.2.1</version>
			<fixedVersion>0.2.1, 0.18.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStoreFile.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.HStoreKey.java</file>
			<file type="M">org.apache.hadoop.hbase.client.MetaScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHStoreFile.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.master.MetaRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Memcache.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStoreScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.HConstants.java</file>
			<file type="M">org.apache.hadoop.hbase.HRegionInfo.java</file>
		</fixedFiles>
		<links>
			<link type="Incorporates" description="is part of">877</link>
		</links>
	</bug>
	<bug id="881" opendate="2008-09-10 18:47:31" fixdate="2008-09-10 19:25:18" resolution="Fixed">
		<buginformation>
			<summary>If a server&amp;apos;s lease times out or the server dies, All regions will get reassigned even split or offline ones.</summary>
			<description>If a server&amp;amp;apos;s lease times out or a server dies (essentially the same thing), when the master tries to find the regions it was serving, it does not check to see if the region has been offlined or split.
In ProcessServerShutdown.scanMetaRegion, the code:

        } else {
          // Get region reassigned
          regions.add(info);
        }


should be:

        } else {
          if (!info.isOffline() &amp;amp;&amp;amp; !info.isSplit()) {
            // Get region reassigned
            regions.add(info);
          }
        }

</description>
			<version>0.2.0</version>
			<fixedVersion>0.2.1, 0.18.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.ProcessServerShutdown.java</file>
		</fixedFiles>
	</bug>
	<bug id="877" opendate="2008-09-08 02:35:46" fixdate="2008-09-10 19:39:51" resolution="Fixed">
		<buginformation>
			<summary>HCM is unable to find table with multiple regions which contains binary</summary>
			<description>HCM can not find the table with exception:
org.apache.hadoop.hbase.TableNotFoundException: items
        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegionInMeta(HConnectionManager.java:508)
        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:460)
        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:420)
        at org.apache.hadoop.hbase.client.HTable.&amp;lt;init&amp;gt;(HTable.java:130)
        at HBaseRef.&amp;lt;init&amp;gt;(HBaseRef.java:29)
        at Import.&amp;lt;init&amp;gt;(Import.java:20)
        at Import.main(Import.java:26)
I have a fix already for this.  But the problem re-appeared after some time.  I have no recreated it yet, but will post results in the morning.</description>
			<version>0.2.1</version>
			<fixedVersion>0.2.1, 0.18.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.BeforeThisStoreKey.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.HTableDescriptor.java</file>
			<file type="M">org.apache.hadoop.hbase.HStoreKey.java</file>
			<file type="M">org.apache.hadoop.hbase.HMerge.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStoreFile.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Memcache.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHStoreFile.java</file>
		</fixedFiles>
		<links>
			<link type="Incorporates" description="incorporates">868</link>
		</links>
	</bug>
	<bug id="891" opendate="2008-09-19 17:14:00" fixdate="2008-09-22 21:48:24" resolution="Fixed">
		<buginformation>
			<summary>HRS.validateValuesLength throws IOE, gets caught in the retries</summary>
			<description>When HRS.validateValuesLength throws a IOE, it gets caught in the retries because it does not use a DoNotRetryIOException.</description>
			<version>0.2.1</version>
			<fixedVersion>0.2.2, 0.18.1, 0.19.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
		</fixedFiles>
	</bug>
	<bug id="892" opendate="2008-09-20 18:20:52" fixdate="2008-09-22 22:01:21" resolution="Fixed">
		<buginformation>
			<summary>Cell iteration is broken</summary>
			<description>Cell implements Iterable&amp;lt;Cell&amp;gt; but its iteration is broken since it will always go one past the edge and throw an ArrayIndexOutOfBoundsException</description>
			<version>0.19.0</version>
			<fixedVersion>0.19.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.Cell.java</file>
		</fixedFiles>
	</bug>
	<bug id="912" opendate="2008-10-03 16:31:41" fixdate="2008-10-03 19:27:54" resolution="Fixed">
		<buginformation>
			<summary>PE is broken when other tables exist</summary>
			<description>The iteration in checkTable is broken.

      for (int i = 0; i &amp;lt; extantTables.length; i++) {
        if (extantTables[0].equals(tableDescriptor)) {
          LOG.warn("Table " + tableDescriptor + " already exists");
          tableExists = true;
          break;
        }
      }

</description>
			<version>0.18.0</version>
			<fixedVersion>0.18.1, 0.19.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
		</fixedFiles>
	</bug>
	<bug id="851" opendate="2008-08-28 18:21:27" fixdate="2008-10-14 00:37:39" resolution="Duplicate">
		<buginformation>
			<summary>Region is left unassigned after a split/rebalancing, throws NSRE</summary>
			<description>Master log:

2008-08-28 12:12:27,174 INFO org.apache.hadoop.hbase.master.ServerManager: Received MSG_REPORT_PROCESS_OPEN: web_pages,http://www.senior-community.net/michigan/charlevoix.htm,1219939934794 from 192.168.1.95:60020
&amp;lt;jdcryans&amp;gt; 2008-08-28 12:12:27,174 INFO org.apache.hadoop.hbase.master.ServerManager: Received MSG_REPORT_OPEN: web_pages,http://www.salonskincare.co.uk/product_info.php/products_id/168,1219939934794 from 192.168.1.95:60020
&amp;lt;jdcryans&amp;gt; 2008-08-28 12:12:27,174 INFO org.apache.hadoop.hbase.master.ServerManager: Received MSG_REPORT_OPEN: web_pages,http://www.senior-community.net/michigan/charlevoix.htm,1219939934794 from 192.168.1.95:60020
&amp;lt;jdcryans&amp;gt; 2008-08-28 12:12:27,174 DEBUG org.apache.hadoop.hbase.master.RegionManager: Server 192.168.1.95:60020 is overloaded. Server load: 8 avg: 7.0
&amp;lt;jdcryans&amp;gt; 2008-08-28 12:12:27,174 DEBUG org.apache.hadoop.hbase.master.RegionManager: Choosing to reassign 1 regions. mostLoadedRegions has 8 regions in it.
&amp;lt;jdcryans&amp;gt; 2008-08-28 12:12:27,174 DEBUG org.apache.hadoop.hbase.master.RegionManager: Going to close region web_pages,http://www.senior-community.net/michigan/charlevoix.htm,1219939934794
&amp;lt;jdcryans&amp;gt; 2008-08-28 12:12:27,174 DEBUG org.apache.hadoop.hbase.master.HMaster: Main processing loop: PendingOpenOperation from 192.168.1.95:60020
&amp;lt;jdcryans&amp;gt; 2008-08-28 12:12:27,175 INFO org.apache.hadoop.hbase.master.ProcessRegionOpen$1: web_pages,http://www.salonskincare.co.uk/product_info.php/products_id/168,1219939934794 open on 192.168.1.95:60020
&amp;lt;jdcryans&amp;gt; 2008-08-28 12:12:27,175 DEBUG org.apache.hadoop.hbase.master.RegionServerOperation: numberOfMetaRegions: 1, onlineMetaRegions.size(): 1
&amp;lt;jdcryans&amp;gt; 2008-08-28 12:12:27,175 INFO org.apache.hadoop.hbase.master.ProcessRegionOpen$1: updating row web_pages,http://www.salonskincare.co.uk/product_info.php/products_id/168,1219939934794 in region .META.,,1 with startcode 1219931259154 and server 192.168.1.95:60020
&amp;lt;jdcryans&amp;gt; 2008-08-28 12:12:30,352 INFO org.apache.hadoop.hbase.master.ServerManager: Received MSG_REPORT_CLOSE: web_pages,http://www.senior-community.net/michigan/charlevoix.htm,1219939934794 from 192.168.1.95:60020
&amp;lt;jdcryans&amp;gt; 2008-08-28 12:1
&amp;lt;jdcryans&amp;gt; 2008-08-28 12:12:32,557 DEBUG org.apache.hadoop.hbase.master.ServerManager: Total Load: 103, Num Servers: 15, Avg Load: 7.0
&amp;lt;jdcryans&amp;gt; 2008-08-28 12:12:34,093 DEBUG org.apache.hadoop.hbase.master.HMaster: Main processing loop: PendingOpenOperation from 192.168.1.95:60020
&amp;lt;jdcryans&amp;gt; 2008-08-28 12:12:34,093 INFO org.apache.hadoop.hbase.master.ProcessRegionOpen$1: web_pages,http://www.senior-community.net/michigan/charlevoix.htm,1219939934794 open on 192.168.1.95:60020
&amp;lt;jdcryans&amp;gt; 2008-08-28 12:12:34,093 DEBUG org.apache.hadoop.hbase.master.RegionServerOperation: numberOfMetaRegions: 1, onlineMetaRegions.size(): 1
&amp;lt;jdcryans&amp;gt; 2008-08-28 12:12:34,093 INFO org.apache.hadoop.hbase.master.ProcessRegionOpen$1: updating row web_pages,http://www.senior-community.net/michigan/charlevoix.htm,1219939934794 in region .META.,,1 with startcode 1219931259154 and server 192.168.1.95:60020


HRS 192.168.1.95

jdcryans&amp;gt; 2008-08-28 12:12:24,953 DEBUG org.apache.hadoop.hbase.regionserver.CompactSplitThread: Compaction requested for region: web_pages,http://www.senior-community.net/michigan/charlevoix.htm,1219939934794
&amp;lt;jdcryans&amp;gt; 2008-08-28 12:12:27,307 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: MSG_REGION_CLOSE: web_pages,http://www.senior-community.net/michigan/charlevoix.htm,1219939934794: [B@f0a360
&amp;lt;jdcryans&amp;gt; 2008-08-28 12:12:27,307 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: MSG_REGION_CLOSE: web_pages,http://www.senior-community.net/michigan/charlevoix.htm,1219939934794: [B@f0a360
&amp;lt;jdcryans&amp;gt; 2008-08-28 12:12:27,308 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Compactions and cache flushes disabled for region web_pages,http://www.senior-community.net/michigan/charlevoix.htm,1219939934794
&amp;lt;jdcryans&amp;gt; 2008-08-28 12:12:27,308 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Scanners disabled for region web_pages,http://www.senior-community.net/michigan/charlevoix.htm,1219939934794
&amp;lt;jdcryans&amp;gt; 2008-08-28 12:12:27,308 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: No more active scanners for region web_pages,http://www.senior-community.net/michigan/charlevoix.htm,1219939934794
&amp;lt;jdcryans&amp;gt; 2008-08-28 12:12:27,308 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Updates disabled for region web_pages,http://www.senior-community.net/michigan/charlevoix.htm,1219939934794
&amp;lt;jdcryans&amp;gt; 2008-08-28 12:12:27,308 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: No more row locks outstanding on region web_pages,http://www.senior-community.net/michigan/charlevoix.htm,1219939934794
&amp;lt;jdcryans&amp;gt; 2008-08-28 12:12:27,308 DEBUG org.apache.hadoop.hbase.regionserver.HStore: closed 1860667227/attribute
&amp;lt;jdcryans&amp;gt; 2008-08-28 12:12:27,308 INFO org.apache.hadoop.hbase.regionserver.HRegion: closed web_pages,http://www.senior-community.net/michigan/charlevoix.htm,1219939934794
&amp;lt;jdcryans&amp;gt; 2008-08-28 12:12:34,246 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 60020, call batchUpdate([B@552a4a, row =&amp;gt; http://www.simplewebengines.com/, {column =&amp;gt; attribute:traveliness, value =&amp;gt; &amp;amp;apos;...&amp;amp;apos;, column =&amp;gt; attribute:processed_at, value =&amp;gt; &amp;amp;apos;...&amp;amp;apos;, column =&amp;gt; attribute:content, value =&amp;gt; &amp;amp;apos;...&amp;amp;apos;, column =&amp;gt; attribute:refs, value =&amp;gt; &amp;amp;apos;...&amp;amp;apos;, column =&amp;gt; attribute:crawled_at, value =&amp;gt; &amp;amp;apos;...&amp;amp;apos;, column =&amp;gt; att
&amp;lt;jdcryans&amp;gt; ribute:html, value =&amp;gt; &amp;amp;apos;...&amp;amp;apos;, column =&amp;gt; attribute:crawled, value =&amp;gt; &amp;amp;apos;...&amp;amp;apos;}) from 192.168.1.96:50102: error: org.apache.hadoop.hbase.NotServingRegionException: web_pages,http://www.senior-community.net/michigan/charlevoix.htm,1219939934794
&amp;lt;jdcryans&amp;gt; org.apache.hadoop.hbase.NotServingRegionException: web_pages,http://www.senior-community.net/michigan/charlevoix.htm,1219939934794

NSRE for a hundred times


Restarting the cluster cleared the issue but this is a nasty bug. Proposed bandaid would be that if we have a NSRE after the retries, asked the master to scan the HRS to see if it&amp;amp;apos;s located somewhere else. If not, assign it somewhere. Finally update META.</description>
			<version>0.2.0</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.ProcessRegionClose.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ServerManager.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">921</link>
		</links>
	</bug>
	<bug id="950" opendate="2008-10-22 21:59:43" fixdate="2008-10-22 23:49:10" resolution="Fixed">
		<buginformation>
			<summary>HTable.commit no longer works with existing RowLocks though it&amp;apos;s still in API</summary>
			<description>Introduced by HBASE-748, the RowLock passed into HTable.commit is now ignored.
This causes the update the hang until that rowlock expires, and then it proceeds with getting a new row lock.</description>
			<version>0.19.0</version>
			<fixedVersion>0.19.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.BatchUpdate.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
		</fixedFiles>
	</bug>
	<bug id="982" opendate="2008-11-04 20:56:15" fixdate="2008-11-04 21:40:29" resolution="Fixed">
		<buginformation>
			<summary>Deleting a column in MapReduce fails</summary>
			<description>In latest trunk, deleting a column in BatchUpdate causes exception because BatchUpdate&amp;amp;apos;s copy constructor (or whatever they are called in java) directly calls BatchUpdate#put even in delete-s thus causing put to throw IllegalArgumentException("Passed value cannot be null").</description>
			<version>0.19.0</version>
			<fixedVersion>0.19.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.BatchUpdate.java</file>
		</fixedFiles>
	</bug>
	<bug id="984" opendate="2008-11-07 04:15:44" fixdate="2008-11-11 23:02:39" resolution="Fixed">
		<buginformation>
			<summary>Fix javadoc warnings</summary>
			<description>There are a number of javadoc warnings: @see pointing to the wrong place, etc. These need to be fixed before 0.19 is released.</description>
			<version>0.19.0</version>
			<fixedVersion>0.19.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.HalfMapFileReader.java</file>
			<file type="M">org.apache.hadoop.hbase.util.InfoServer.java</file>
		</fixedFiles>
	</bug>
	<bug id="994" opendate="2008-11-11 19:38:11" fixdate="2008-11-11 23:10:11" resolution="Fixed">
		<buginformation>
			<summary>IPC interfaces with different versions can cause problems</summary>
			<description>This morning we ran into a situation in which some 0.2.x region servers started up and joined a 0.18.1 cluster. 
This &amp;amp;apos;sort of&amp;amp;apos; worked in that the hrs could communicate with the master, but clients could not communicate with the 0.2 region servers because the api version changed (the master wouldn&amp;amp;apos;t have liked it if it had deployed root or meta there).
Suggestion is that we have a single api version that gets bumped when any of the interfaces changes.</description>
			<version>0.2.1</version>
			<fixedVersion>0.19.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.TransactionalRegionInterface.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.HRegionInterface.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.HMasterInterface.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.HMasterRegionInterface.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
		</fixedFiles>
	</bug>
	<bug id="602" opendate="2008-04-29 00:28:06" fixdate="2008-11-12 20:45:24" resolution="Fixed">
		<buginformation>
			<summary>HBase Crash when network card has a IPv6 address</summary>
			<description>I&amp;amp;apos;ve met a problem startup HBase.
I setup hbase with hdfs,
My server&amp;amp;apos;s network card has a ipv4 address and also a ipv6 address.
When I first startup hbase with default configuration file,
I found that the region server can&amp;amp;apos;t 
register to master. And I found lots of 127.0.0.1 in log.
So I suppose interface "default" would not work and add following:
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;dfs.datanode.dns.interface&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;eth0&amp;lt;/value&amp;gt;
  &amp;lt;description&amp;gt;The name of the Network Interface from which a data node should 
  report its IP address.
  &amp;lt;/description&amp;gt;
 &amp;lt;/property&amp;gt;
However, when this is done. HBase master crashes;
And I see ipv6 addresses in the log.
So I dig into the source code,
found that HBase fails to deal with IPv6 address.
Details is in following:
In class  org.apache.hadoop.hbase.HRegionServer
the method getThisIP() invoke the method of class belongs to Hadoop-core package
The class is: org.apache.hadoop.net.DNS
the method is: getDefaultIP(String strInterface)
This method invokes another method in the same class: getIPs(String strInterface)
Method getIPs always returns the first ip address  no matter it is ipv4 or ipv6
I have fixed it by modifying method of org.apache.hadoop.net.DNS.getIPs(String
strInterface)
Such that it always returns ipv4 address
It is working now for me.
But when hadoop upgrades, I have to modify again.
In order to avoid the problem,
I modify a method in class: org.apache.hadoop.net.DNS
The following is the modified code of this method, it would not return IPv6
address now.
/**

Returns all the IPs associated with the provided interface, if any, in
textual form.

@param strInterface
The name of the network interface to query (e.g. eth0)
@return A string vector of all the IPs associated with the provided
interface
@throws UnknownHostException
If an UnknownHostException is encountered in querying the
default interface
   */
  public static String[] getIPs(String strInterface)
  throws UnknownHostException {
	    try {
	      NetworkInterface netIF = NetworkInterface.getByName(strInterface);
	      if (netIF == null)
	        return new String[] 
{ InetAddress.getLocalHost()
	                              .getHostAddress() }
;
	      else {
	        Vector&amp;lt;String&amp;gt; ips = new Vector&amp;lt;String&amp;gt;();
	        Enumeration e = netIF.getInetAddresses();
	        while (e.hasMoreElements())
	          				{
	        	String addr=((InetAddress) e.nextElement()).getHostAddress();
	        	if(addr.length()&amp;lt;=15)//only when it is a IPv4 address
	        		ips.add(addr);
	        	//ips.add(((InetAddress) e.nextElement()).getHostAddress());
	          				}
	        return ips.toArray(new String[] {});
	      }
	    } catch (SocketException e) 
Unknown macro: {	      return new String[] { InetAddress.getLocalHost().getHostAddress() };	    } 
  }

</description>
			<version>0.1.1</version>
			<fixedVersion>0.19.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HLog.java</file>
			<file type="M">org.apache.hadoop.hbase.HServerAddress.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ProcessServerShutdown.java</file>
		</fixedFiles>
	</bug>
	<bug id="938" opendate="2008-10-20 02:25:15" fixdate="2008-11-15 00:36:42" resolution="Fixed">
		<buginformation>
			<summary>major compaction period is not checked periodically</summary>
			<description>The major compaction period, hbase.hregion.majorcompaction, is not checked periodically. Currently, we only request major compaction when the region is open or split at which point we check whether the major compaction period is due.</description>
			<version>0.18.0</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStoreFile.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MemcacheFlusher.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.util.Threads.java</file>
		</fixedFiles>
	</bug>
	<bug id="714" opendate="2008-06-26 07:23:05" fixdate="2008-11-23 22:16:21" resolution="Fixed">
		<buginformation>
			<summary>Showing bytes in log when should be string (2)</summary>
			<description>See HBASE-701 - spotted some more byte output:

regionserver.CompactSplitThread: "Compaction failed for region ..." [twice in run()]


regionserver.CompactSplitThread: "Updating ... with region split info" [l.157]


util.SoftSortedMap: "Reference for key ... has been cleared" [l.181]


master.BaseScanner: "no longer has references to ... " [l.339]


INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 60020, call batchUpdate([B@11b8a00, org.apache.hadoop.hbase.io.BatchUpdate@10134ba) from 127.0.0.2:59620: error:

</description>
			<version>0.2.0</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
			<file type="M">org.apache.hadoop.hbase.util.SoftSortedMap.java</file>
			<file type="M">org.apache.hadoop.hbase.master.BaseScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.io.BatchOperation.java</file>
			<file type="M">org.apache.hadoop.hbase.HRegionInfo.java</file>
			<file type="M">org.apache.hadoop.hbase.io.BatchUpdate.java</file>
		</fixedFiles>
	</bug>
	<bug id="1039" opendate="2008-11-30 18:44:38" fixdate="2008-12-03 23:14:28" resolution="Fixed">
		<buginformation>
			<summary>Compaction fails if bloomfilters are enabled</summary>
			<description>From Thibaut up on the list.
As soon as hbase tries to compact the table, the following exception appears in the logfile: (Other compactations also work fine without any errors)
2008-11-30 00:55:57,769 ERROR
org.apache.hadoop.hbase.regionserver.CompactSplitThread: Compaction failed for region mytable,,1228002541526
java.lang.IllegalArgumentException: maxValue must be &amp;gt; 0
    at org.onelab.filter.HashFunction.&amp;lt;init&amp;gt;(HashFunction.java:84)
    at org.onelab.filter.Filter.&amp;lt;init&amp;gt;(Filter.java:97)
    at org.onelab.filter.BloomFilter.&amp;lt;init&amp;gt;(BloomFilter.java:102)
    at org.apache.hadoop.hbase.regionserver.HStoreFile$BloomFilterMapFile$Writer.&amp;lt;init&amp;gt;(HStoreFile.java:829)
    at org.apache.hadoop.hbase.regionserver.HStoreFile.getWriter(HStoreFile.java:436)
    at org.apache.hadoop.hbase.regionserver.HStore.compact(HStore.java:889)
    at org.apache.hadoop.hbase.regionserver.HRegion.compactStores(HRegion.java:902)
    at org.apache.hadoop.hbase.regionserver.HRegion.compactStores(HRegion.java:860)
    at org.apache.hadoop.hbase.regionserver.CompactSplitThread.run(CompactSplitThread.java:83)
Because the region cannot compact and/or split, it is soon dead after (re)assignment.</description>
			<version>0.18.1</version>
			<fixedVersion>0.19.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.MemcacheFlusher.java</file>
			<file type="M">org.apache.hadoop.hbase.io.BloomFilterMapFile.java</file>
			<file type="M">org.onelab.filter.Filter.java</file>
		</fixedFiles>
		<links>
			<link type="Incorporates" description="is part of">1047</link>
		</links>
	</bug>
	<bug id="900" opendate="2008-09-24 23:53:29" fixdate="2008-12-19 19:03:46" resolution="Fixed">
		<buginformation>
			<summary>Regionserver memory leak causing OOME during relatively modest bulk importing</summary>
			<description>I have recreated this issue several times and it appears to have been introduced in 0.2.
During an import to a single table, memory usage of individual region servers grows w/o bounds and when set to the default 1GB it will eventually die with OOME.  This has happened to me as well as Daniel Ploeg on the mailing list.  In my case, I have 10 RS nodes and OOME happens w/ 1GB heap at only about 30-35 regions per RS.  In previous versions, I have imported to several hundred regions per RS with default heap size.
I am able to get past this by increasing the max heap to 2GB.  However, the appearance of this in newer versions leads me to believe there is now some kind of memory leak happening in the region servers during import.</description>
			<version>0.18.1</version>
			<fixedVersion>0.19.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.SoftValueMap.java</file>
			<file type="D">org.apache.hadoop.hbase.util.ReferenceQueueUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.io.HBaseMapFile.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.io.BlockFSInputStream.java</file>
			<file type="M">org.apache.hadoop.hbase.util.SoftValueSortedMap.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.util.Bytes.java</file>
			<file type="M">org.apache.hadoop.hbase.HStoreKey.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.io.BatchOperation.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Memcache.java</file>
			<file type="M">org.apache.hadoop.hbase.io.BatchUpdate.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="D">org.apache.hadoop.ipc.HBaseClient.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.HBaseRPCProtocolVersion.java</file>
			<file type="D">org.apache.hadoop.hbase.ipc.HbaseRPC.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">1019</link>
			<link type="Reference" description="relates to">1018</link>
		</links>
	</bug>
	<bug id="1052" opendate="2008-12-09 17:01:07" fixdate="2008-12-21 02:45:32" resolution="Fixed">
		<buginformation>
			<summary>Stopping a HRegionServer with unflushed cache causes data loss from org.apache.hadoop.hbase.DroppedSnapshotException </summary>
			<description> 1.  Start a Hbase cluster
 2.  Create a table t1: create &amp;amp;apos;t1&amp;amp;apos;, 
{NAME =&amp;gt; &amp;amp;apos;f1&amp;amp;apos;}
 3.  Put a cell in the table: put &amp;amp;apos;t1&amp;amp;apos;, &amp;amp;apos;r1&amp;amp;apos;, &amp;amp;apos;f1:&amp;amp;apos;, &amp;amp;apos;value&amp;amp;apos;
 4.  Scan it, see it&amp;amp;apos;s fine
 5.  Stop the HRegionSever hosting the t1 region: hbase/bin/hbase-daemon.sh stop regionserver.
 6.  Watch the region being reassigned from the original HRegionServer
 7.  Scan the t1 table again. It&amp;amp;apos;s empty now.
If between step 4 and step 5 the cache is flushed (e.g. Hbase cluster restart) no data is loss. However it means that if you stop a region server with dirty cache you will loose some data. 
HRegionServer log after issuing hbase-daemon.sh stop regionserver:
2008-12-09 06:37:46,873 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 60020: exiting
2008-12-09 06:37:46,873 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 60020: exiting
2008-12-09 06:37:46,873 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 60020: exiting
2008-12-09 06:37:46,873 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 60020: exiting
2008-12-09 06:37:46,874 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Stopping infoServer
2008-12-09 06:37:46,874 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2008-12-09 06:37:46,874 INFO org.mortbay.util.ThreadedServer: Stopping Acceptor ServerSocket[addr=0.0.0.0/0.0.0.0,port=0,localport=60030]
2008-12-09 06:37:46,886 INFO org.mortbay.http.SocketListener: Stopped SocketListener on 0.0.0.0:60030
2008-12-09 06:37:46,948 INFO org.mortbay.util.Container: Stopped HttpContext[/static,/static]
2008-12-09 06:37:47,007 INFO org.mortbay.util.Container: Stopped HttpContext[/logs,/logs]
2008-12-09 06:37:47,007 INFO org.mortbay.util.Container: Stopped org.mortbay.jetty.servlet.WebApplicationHandler@60ded0f0
2008-12-09 06:37:47,094 INFO org.mortbay.util.Container: Stopped WebApplicationContext[/,/]
2008-12-09 06:37:47,094 INFO org.mortbay.util.Container: Stopped org.mortbay.jetty.Server@6490832e
2008-12-09 06:37:47,094 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: closing region t1,,1228833363456
2008-12-09 06:37:47,094 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Compactions and cache flushes disabled for region t1,,1228833363456
2008-12-09 06:37:47,094 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Scanners disabled for region t1,,1228833363456
2008-12-09 06:37:47,094 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: No more active scanners for region t1,,1228833363456
2008-12-09 06:37:47,095 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Updates disabled for region t1,,1228833363456
2008-12-09 06:37:47,095 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: No more row locks outstanding on region t1,,1228833363456
2008-12-09 06:37:47,095 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Started memcache flush for region t1,,1228833363456. Current region memcache size 18.0
2008-12-09 06:37:47,095 INFO org.apache.hadoop.hbase.regionserver.Flusher: regionserver/0:0:0:0:0:0:0:0:60020.cacheFlusher exiting
2008-12-09 06:37:47,096 INFO org.apache.hadoop.hbase.regionserver.LogRoller: LogRoller exiting.
2008-12-09 06:37:47,096 INFO org.apache.hadoop.hbase.regionserver.CompactSplitThread: regionserver/0:0:0:0:0:0:0:0:60020.compactor exiting
2008-12-09 06:37:47,099 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: error closing region t1,,1228833363456
org.apache.hadoop.hbase.DroppedSnapshotException: region: t1,,1228833363456
    at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1071)
    at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:619)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.closeAllRegions(HRegionServer.java:951)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:459)
    at java.lang.Thread.run(Thread.java:619)
Caused by: java.io.IOException: Filesystem closed
    at org.apache.hadoop.dfs.DFSClient.checkOpen(DFSClient.java:196)
    at org.apache.hadoop.dfs.DFSClient.getFileInfo(DFSClient.java:564)
    at org.apache.hadoop.dfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:390)
    at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:667)
    at org.apache.hadoop.hbase.regionserver.HStoreFile.&amp;lt;init&amp;gt;(HStoreFile.java:152)
    at org.apache.hadoop.hbase.regionserver.HStore.internalFlushCache(HStore.java:599)
    at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:577)
    at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1058)
    ... 4 more
2008-12-09 06:37:47,100 DEBUG org.apache.hadoop.hbase.regionserver.HLog: closing log writer in hdfs://h1:54310/hbase/log_10.131.237.51_1228833326838_60020
2008-12-09 06:37:47,101 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: Close and delete failed
java.io.IOException: Filesystem closed
    at org.apache.hadoop.dfs.DFSClient.checkOpen(DFSClient.java:196)
    at org.apache.hadoop.dfs.DFSClient.access$600(DFSClient.java:59)
    at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.closeInternal(DFSClient.java:2689)
    at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.close(DFSClient.java:2655)
    at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:59)
    at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:79)
    at org.apache.hadoop.io.SequenceFile$Writer.close(SequenceFile.java:962)
    at org.apache.hadoop.hbase.regionserver.HLog.close(HLog.java:349)
    at org.apache.hadoop.hbase.regionserver.HLog.closeAndDelete(HLog.java:333)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:461)
    at java.lang.Thread.run(Thread.java:619)
2008-12-09 06:37:47,102 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: telling master that region server is shutting down at: 10.131.237.51:60020
2008-12-09 06:37:47,104 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: stopping server at: 10.131.237.51:60020
2008-12-09 06:37:47,882 INFO org.apache.hadoop.hbase.Leases: regionserver/0:0:0:0:0:0:0:0:60020.leaseChecker closing leases
2008-12-09 06:37:47,882 INFO org.apache.hadoop.hbase.Leases: regionserver/0:0:0:0:0:0:0:0:60020.leaseChecker closed leases
2008-12-09 06:37:54,919 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: worker thread exiting
2008-12-09 06:37:54,920 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: regionserver/0:0:0:0:0:0:0:0:60020 exiting
2008-12-09 06:37:54,920 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Shutdown thread complete</description>
			<version>0.18.0</version>
			<fixedVersion>0.19.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
		</fixedFiles>
	</bug>
	<bug id="1079" opendate="2008-12-22 13:31:05" fixdate="2008-12-22 13:37:55" resolution="Fixed">
		<buginformation>
			<summary>Dumb NPE in ServerCallable hides the RetriesExhausted exception.</summary>
			<description>From the list (and this is something I&amp;amp;apos;ve already seen) :
NativeException: java.lang.NullPointerException: null
       from org/apache/hadoop/hbase/client/ServerCallable.java:71:in `getRegio
Name&amp;amp;apos;
       from org/apache/hadoop/hbase/client/HConnectionManager.java:863:in `get
egionServerWithRetries&amp;amp;apos;
       from org/apache/hadoop/hbase/client/MetaScanner.java:56:in `metaScan&amp;amp;apos;
       from org/apache/hadoop/hbase/client/MetaScanner.java:30:in `metaScan&amp;amp;apos;
       from org/apache/hadoop/hbase/client/HConnectionManager.java:297:in `lis
Tables&amp;amp;apos;
       from org/apache/hadoop/hbase/client/HBaseAdmin.java:117:in `listTables&amp;amp;apos;
This is </description>
			<version>0.18.1</version>
			<fixedVersion>0.19.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.ServerCallable.java</file>
		</fixedFiles>
	</bug>
	<bug id="543" opendate="2008-03-24 22:26:42" fixdate="2008-12-24 01:38:25" resolution="Fixed">
		<buginformation>
			<summary>A region&amp;apos;s state is kept in several places in the master opening the possibility for race conditions</summary>
			<description>A region&amp;amp;apos;s state exists in multiple maps in the RegionManager: unassignedRegions, pendingRegions, regionsToClose, closingRegions, regionsToDelete, etc.
One of these race conditions was found in HBASE-534.
For HBase-0.1.x, we should just patch the holes we find.
The ultimate solution (which requires a lot of changes in HMaster) should be applied to HBase trunk.
Proposed solution:
Create a class that encapsulates a region&amp;amp;apos;s state and provide synchronized access to the class that validates state changes.
There should be a single structure that holds regions in these transitional states and it should be a synchronized collection of some kind.</description>
			<version>0.1.0</version>
			<fixedVersion>0.19.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.MetaScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.master.RegionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ServerManager.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="M">org.apache.hadoop.hbase.master.BaseScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ServerConnection.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ChangeTableState.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ProcessRegionClose.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ProcessServerShutdown.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ProcessRegionOpen.java</file>
		</fixedFiles>
		<links>
			<link type="Blocker" description="blocks">546</link>
			<link type="Blocker" description="blocks">504</link>
			<link type="Reference" description="relates to">599</link>
			<link type="Reference" description="is related to">549</link>
			<link type="Reference" description="is related to">1077</link>
		</links>
	</bug>
	<bug id="1087" opendate="2008-12-23 18:36:46" fixdate="2008-12-26 20:21:58" resolution="Fixed">
		<buginformation>
			<summary>DFS failures did not shutdown regionserver</summary>
			<description>I lost three Datanodes, reasons of which are still being investigated, but it has left a number of regions unable to be written to.
Relevant logs:
2008-12-23 02:35:59,591 WARN org.apache.hadoop.hdfs.DFSClient: DataStreamer Exception: java.io.IOException: Connection reset by peer
        at sun.nio.ch.FileDispatcher.write0(Native Method)
        at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
        at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:122)
        at sun.nio.ch.IOUtil.write(IOUtil.java:93)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:352)
        at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)
        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:140)
        at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)
        at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)
        at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
        at java.io.DataOutputStream.write(DataOutputStream.java:107)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2209)
2008-12-23 02:35:59,591 WARN org.apache.hadoop.hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block blk_3615512604618056881_86411java.io.EOFException
        at java.io.DataInputStream.readFully(DataInputStream.java:197)
        at java.io.DataInputStream.readLong(DataInputStream.java:416)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:2318)
2008-12-23 02:35:59,591 WARN org.apache.hadoop.hdfs.DFSClient: Error Recovery for block blk_3615512604618056881_86411 bad datanode[0] 72.34.249.214:50010
2008-12-23 02:35:59,595 WARN org.apache.hadoop.hdfs.DFSClient: Error Recovery for block blk_3615512604618056881_86411 in pipeline 72.34.249.214:50010, 72.34.249.213:50010, 72.34.249.219:50010: bad datanode 72.34.249.214:50010
2008-12-23 02:38:27,698 INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream java.net.ConnectException: Connection refused
2008-12-23 02:38:27,698 INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_-3678518999439029831_86910
2008-12-23 02:38:27,711 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: Row lock 5392007859847346106 has been explicitly released by client
2008-12-23 02:38:30,048 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: Row lock -5905479324505886709 explicitly acquired by client
2008-12-23 02:38:33,700 INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream java.net.ConnectException: Connection refused
2008-12-23 02:38:33,700 INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_-226119866881174578_86911
2008-12-23 02:38:34,908 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: Row lock 346704317670569896 explicitly acquired by client
2008-12-23 02:38:39,702 INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream java.net.ConnectException: Connection refused
2008-12-23 02:38:39,702 INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_1719395740576248920_86913
2008-12-23 02:38:40,945 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: Row lock 3819942931078736534 explicitly acquired by client
2008-12-23 02:38:45,572 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: Row lock 254119037927296402 explicitly acquired by client
2008-12-23 02:38:45,703 INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream java.net.ConnectException: Connection refused
2008-12-23 02:38:45,703 INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_2443399503093377808_86915
2008-12-23 02:38:49,092 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: Row lock 8573046623144113301 explicitly acquired by client
2008-12-23 02:38:49,385 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: Row lock 7686739650257547105 explicitly acquired by client
2008-12-23 02:38:49,512 DEBUG org.apache.hadoop.hbase.regionserver.HRegionServer: Row lock 5582966798894532276 explicitly acquired by client
2008-12-23 02:38:51,704 WARN org.apache.hadoop.hdfs.DFSClient: DataStreamer Exception: java.io.IOException: Unable to create new block.
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.nextBlockOutputStream(DFSClient.java:2723)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2000(DFSClient.java:1997)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2183)
2008-12-23 02:38:51,704 WARN org.apache.hadoop.hdfs.DFSClient: Error Recovery for block blk_2443399503093377808_86915 bad datanode[0] nodes == null
2008-12-23 02:38:51,704 WARN org.apache.hadoop.hdfs.DFSClient: Could not get block locations. Aborting...
2008-12-23 02:38:51,704 FATAL org.apache.hadoop.hbase.regionserver.HLog: Could not append. Requesting close of log
java.net.ConnectException: Connection refused
        at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
        at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:592)
        at sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:118)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.createBlockOutputStream(DFSClient.java:2748)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.nextBlockOutputStream(DFSClient.java:2704)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2000(DFSClient.java:1997)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2183)
2008-12-23 02:38:51,706 ERROR org.apache.hadoop.hbase.regionserver.LogRoller: Log rolling failed with ioe:
java.net.ConnectException: Connection refused
        at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
        at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:592)
        at sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:118)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.createBlockOutputStream(DFSClient.java:2748)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.nextBlockOutputStream(DFSClient.java:2704)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2000(DFSClient.java:1997)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2183)
2008-12-23 02:38:51,706 ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: java.net.ConnectException: Connection refused</description>
			<version>0.19.0</version>
			<fixedVersion>0.19.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.LogRoller.java</file>
		</fixedFiles>
	</bug>
	<bug id="921" opendate="2008-10-11 06:48:37" fixdate="2008-12-30 22:16:36" resolution="Fixed">
		<buginformation>
			<summary>region close and open processed out of order; makes for disagreement between master and regionserver on region state</summary>
			<description>Master assigns region X successfully.  It then decides to close it because it wants it opened elsewhere as part of region rebalancing.  Both the open and close operations are reported back to the master.  Both have operation processing components that are added to the todo list to be processed in another thread outside of the master&amp;amp;apos;s main loop.
The close operation does the bulk of its work inline with the master main processing loop.  Its todo component does some work if the region is offlined but otherwise nothing of consequence whereas the open in its todo does the important meta catalog table update with the new location information.
Its been fairly common here on our cluster where the master todo queue is occupied processing the shutdown of a regionserver.  It takes a long time to process the shutdown of a regionserver when thousands of regions   This latter delays the processing of the open and close todos.  In effect the open is running after the close.  The region goes into limbo.  Only a restart of the &amp;amp;apos;hosting&amp;amp;apos; regionserver &amp;amp;apos;fixes&amp;amp;apos; this state.
This is a particular case of the general HBASE-543 issue.  Its happening alot here on our cluster so will hack up a fix for this and get it into TRUNK and backport it to 0.18.1.
Jim Firby here had a good idea for conditions like this.  Clients should be able to say "I&amp;amp;apos;ve asked for a regions location 10 times now and Mr. Master, you&amp;amp;apos;ve given me the same response ten times in a row and each time, the answer was wrong.  Revisit any notion that said region is at said location".  Mr. Master would then go off and do something drastic like close and reassign the region.
</description>
			<version>0.18.0</version>
			<fixedVersion></fixedVersion>
			<type>Sub-task</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.ProcessRegionClose.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ServerManager.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">851</link>
		</links>
	</bug>
	<bug id="876" opendate="2008-09-07 08:09:55" fixdate="2009-01-22 05:44:39" resolution="Fixed">
		<buginformation>
			<summary>There are a large number of Java warnings in HBase</summary>
			<description>There are a large number of Java warnings in the current HBase code base including:

exceptions that do not define serialVersionUID
classes that use the raw type WritableComparable instead of WritableComparable&amp;lt;T&amp;gt;
classes or interfaces that declare public members that are not a part of the public API. In this case they should be moved to a place where their visibility needs not be public. Additionally, there are a number of classes that declare public members that need not be. Make them protected or private or default as needed
methods that have unnecessary else clauses
potential null pointer access
inner classes that are public that should be default or protected (e.g. RegionHistoryInformation)
assignment to an input parameter

</description>
			<version>0.18.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapred.IndexConfiguration.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.transactional.TransactionalHLogManager.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="M">org.apache.hadoop.hbase.util.MurmurHash.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.LogFlusher.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.RowCounter.java</file>
			<file type="M">org.apache.hadoop.hbase.master.RootScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.master.metrics.MasterMetrics.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.TableInputFormat.java</file>
			<file type="M">org.onelab.filter.RetouchedBloomFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HLogKey.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.TableMap.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.IdentityTableReduce.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.GroupingTableMap.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.TableOutputFormat.java</file>
			<file type="M">org.apache.hadoop.hbase.util.MetaUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.LuceneDocumentWrapper.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.HRegionPartitioner.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Memcache.java</file>
			<file type="M">org.apache.hadoop.hbase.util.Pair.java</file>
			<file type="M">org.onelab.filter.BloomFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.TableInputFormatBase.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.IdentityTableMap.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ModifyTableMeta.java</file>
			<file type="M">org.apache.hadoop.hbase.util.SoftValueMap.java</file>
			<file type="M">org.onelab.filter.Key.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.metrics.RegionServerMetrics.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.IndexOutputFormat.java</file>
			<file type="M">org.apache.hadoop.hbase.util.JenkinsHash.java</file>
			<file type="M">org.apache.hadoop.hbase.util.SoftValue.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HLog.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.IndexTableReduce.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ServerManager.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TableDelete.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.tableindexed.IndexedRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.master.NotAllMetaRegionsOnlineException.java</file>
			<file type="M">org.apache.hadoop.hbase.util.Bytes.java</file>
			<file type="M">org.apache.hadoop.hbase.metrics.file.TimeStampingFileContext.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.HBaseRpcMetrics.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ColumnOperation.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.TableSplit.java</file>
			<file type="M">org.onelab.filter.DynamicBloomFilter.java</file>
			<file type="M">org.onelab.filter.CountingBloomFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.util.SoftValueSortedMap.java</file>
			<file type="M">org.apache.hadoop.hbase.client.tableindexed.IndexedTableAdmin.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ScannerTimeoutException.java</file>
			<file type="M">org.apache.hadoop.hbase.io.RowResult.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.PageRowFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.io.HbaseMapWritable.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.PrefixRowFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.RegExpRowFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.io.BlockFSInputStream.java</file>
			<file type="M">org.apache.hadoop.hbase.client.tableindexed.IndexSpecification.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.ColumnValueFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.client.UnmodifyableHTableDescriptor.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.client.transactional.UnknownTransactionException.java</file>
			<file type="M">org.apache.hadoop.hbase.io.ImmutableBytesWritable.java</file>
			<file type="M">org.apache.hadoop.hbase.client.tableindexed.IndexedTable.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.StopRowFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.io.BloomFilterMapFile.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
			<file type="M">org.apache.hadoop.hbase.client.UnmodifyableHColumnDescriptor.java</file>
			<file type="M">org.apache.hadoop.hbase.io.HalfMapFileReader.java</file>
			<file type="M">org.apache.hadoop.hbase.io.HBaseMapFile.java</file>
			<file type="M">org.apache.hadoop.hbase.io.HbaseObjectWritable.java</file>
			<file type="M">org.apache.hadoop.hbase.client.MetaScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.client.transactional.CommitUnsuccessfulException.java</file>
			<file type="M">org.apache.hadoop.hbase.HServerLoad.java</file>
			<file type="M">org.apache.hadoop.hbase.LeaseException.java</file>
			<file type="M">org.apache.hadoop.hbase.HColumnDescriptor.java</file>
			<file type="M">org.apache.hadoop.hbase.HServerAddress.java</file>
			<file type="M">org.apache.hadoop.hbase.ColumnNameParseException.java</file>
			<file type="M">org.apache.hadoop.hbase.RegionHistorian.java</file>
			<file type="M">org.apache.hadoop.hbase.HStoreKey.java</file>
			<file type="M">org.apache.hadoop.hbase.HServerInfo.java</file>
			<file type="M">org.apache.hadoop.hbase.ValueOverMaxLengthException.java</file>
			<file type="M">org.apache.hadoop.hbase.HRegionLocation.java</file>
			<file type="M">org.apache.hadoop.hbase.HRegionInfo.java</file>
			<file type="M">org.apache.hadoop.hbase.HConstants.java</file>
			<file type="M">org.apache.hadoop.hbase.DroppedSnapshotException.java</file>
			<file type="M">org.apache.hadoop.hbase.DoNotRetryIOException.java</file>
			<file type="M">org.apache.hadoop.hbase.RemoteExceptionHandler.java</file>
		</fixedFiles>
	</bug>
	<bug id="1148" opendate="2009-01-23 01:50:00" fixdate="2009-01-23 23:11:27" resolution="Fixed">
		<buginformation>
			<summary>Always flush HLog on root or meta region updates</summary>
			<description>Flushing an HLog does not currently guarantee that the updates will be visible (see HADOOP-4379), however in the case of root or meta region updates, this is critical.
I was able to create a situation by killing both the root and meta region servers, from which the cluster recovered, but because of the missed edits, clients found the old parent region rather than the new child regions because the fact that the parent region had split was not in the HLog of the crashed region servers (the master knew because of the MSG_REGION_SPLIT message it received) but the clients read the meta table and because that change was lost, clients were trying to find the parent region.
So, when a SequenceFile.Writer.sync() guarantees that what has been written will be visible to new readers, we need to modify HLog so that if it is writing an update to the root or meta regions, that it immediately flushes (syncs) the log file so that the changes will be visible when the log file is recovered.
</description>
			<version>0.19.0</version>
			<fixedVersion>0.19.1, 0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HLog.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHLog.java</file>
		</fixedFiles>
		<links>
			<link type="Blocker" description="is blocked by">200</link>
		</links>
	</bug>
	<bug id="1175" opendate="2009-02-02 23:54:43" fixdate="2009-02-05 05:56:08" resolution="Fixed">
		<buginformation>
			<summary>HBA administrative tools do not work when specifying regionName</summary>
			<description>HBaseAdmin administrative functions allow tableName or regionName through the API.  Things are okay if we pass tableName, but when using regionName the code in HMaster is incorrect.  It is expecting to be passed tableName and startRow, but we are passing null and regionName.  Patch will fix master to handle this case properly.
Log for good measure:

[hbase@mb0 StyBase]$ java TableMaintenance chunks
Running maintenance on table &amp;amp;apos;chunks&amp;amp;apos;
Table contains 2 regions
  &amp;gt; Flushing region {chunks,,1229390225893}
EXCEPTION FLUSHING REGION! [org.apache.hadoop.ipc.RemoteException: java.io.IOException: Invalid arguments to openScanner
        at org.apache.hadoop.hbase.regionserver.HRegionServer.openScanner(HRegionServer.java:1695)
        at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:616)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:632)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:895)
Caused by: java.lang.NullPointerException: firstRow for scanner is null
        at org.apache.hadoop.hbase.regionserver.HRegionServer.openScanner(HRegionServer.java:1692)
        ... 5 more

        at org.apache.hadoop.hbase.ipc.HBaseClient.call(HBaseClient.java:701)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Invoker.invoke(HBaseRPC.java:321)
        at $Proxy2.openScanner(Unknown Source)
        at org.apache.hadoop.hbase.master.HMaster.getTableRegionClosest(HMaster.java:725)
        at org.apache.hadoop.hbase.master.HMaster.modifyTable(HMaster.java:804)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:616)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:632)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:895)
]

</description>
			<version>0.19.0</version>
			<fixedVersion>0.19.1, 0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.HRegionInfo.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
		</fixedFiles>
	</bug>
	<bug id="1191" opendate="2009-02-08 05:19:54" fixdate="2009-02-08 18:38:34" resolution="Fixed">
		<buginformation>
			<summary>ZooKeeper ensureParentExists calls fail on absolute path</summary>
			<description>If user specifies absolute path for one of the files in ZooKeeper, the following will not do what it&amp;amp;apos;s supposed to:
if (!ensureZNodeExists(parentZNode)) {
  ...
Because the user specified path is not a child of parentZNode, all operations on it will fail.</description>
			<version>0.19.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.TestZooKeeper.java</file>
			<file type="M">org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper.java</file>
		</fixedFiles>
	</bug>
	<bug id="1187" opendate="2009-02-06 20:43:01" fixdate="2009-02-08 18:48:06" resolution="Fixed">
		<buginformation>
			<summary>After disabling/enabling a table, the regions seems to be assigned to only 1-2 region servers</summary>
			<description>After disabling/enabling a small table (20 regions), we see that the master tend to assign the regions to only 1-2 region servers. Unfortunately, that table is extensively used in random reads which really kills those RS when they hold those regions. As a fix, we have to restart HBase...</description>
			<version>0.19.0</version>
			<fixedVersion>0.19.1, 0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.TestZooKeeper.java</file>
			<file type="M">org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper.java</file>
		</fixedFiles>
	</bug>
	<bug id="1190" opendate="2009-02-08 01:51:01" fixdate="2009-02-08 19:39:00" resolution="Fixed">
		<buginformation>
			<summary>TableInputFormatBase with row filters scan too far </summary>
			<description>When TableInputFormatBase has a non-null RowFilterInterface to apply, it creates combines the row filter with a StopRowFilter to get a scanner for each input split.  However, the StopRowFilter never indicates that fitlerAllRemaining is true, so each input split will end up scanning to the end of the table.  (Contrast with HTable.getScanner(byte[][] columns, byte[] starRow, byte[] stopRow, long timestamp) which uses a StopRowFilter wrapped in a WhileMatchRowFilter to ensure that scanning ends at the stop row.</description>
			<version>0.19.0</version>
			<fixedVersion>0.19.1, 0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapred.TableInputFormatBase.java</file>
		</fixedFiles>
	</bug>
	<bug id="1142" opendate="2009-01-20 22:27:16" fixdate="2009-02-26 06:07:50" resolution="Fixed">
		<buginformation>
			<summary>Cleanup thrift server; remove Text and profuse DEBUG messaging</summary>
			<description>Ambiguous issue name.. sorry.
The thrift server has loads of getText(..) calls. Which is a local function that checks for utf8 compliance, we don&amp;amp;apos;t need them anywhere, because we don&amp;amp;apos;t use Text anymore.
There is probably other things we missed last time we updated the api, that we should also clean up while we&amp;amp;apos;re at it. Open to suggestions.</description>
			<version>0.18.0</version>
			<fixedVersion>0.19.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.ThriftUtilities.java</file>
		</fixedFiles>
		<links>
			<link type="Blocker" description="blocks">889</link>
		</links>
	</bug>
	<bug id="1185" opendate="2009-02-05 17:29:06" fixdate="2009-03-05 14:10:12" resolution="Fixed">
		<buginformation>
			<summary>wrong request/sec in the gui reporting wrong</summary>
			<description>I am seeing lower number of request in the masters gui then I have seen in 0.18.0 while scanning.
I thank part of it is we moved to report per sec request not per 3 secs so the request should be 1/3 of the old numbers I was getting.
hbase.client.scanner.caching is not the reason the request are under reported.
I set hbase.client.scanner.caching = 1 and still get about 2K request a sec in the gui
but when the job is done I take records / job time and get 36,324/ records /sec. So
there must be some caching out side of the hbase.client.scanner.caching making the
request per sec lower then it should be. I know it running faster then reported just thought
it might give some new users the wrong impression that request/sec = read/write /sec.</description>
			<version>0.19.0</version>
			<fixedVersion>0.19.1, 0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
		</fixedFiles>
	</bug>
	<bug id="1239" opendate="2009-03-04 20:42:50" fixdate="2009-03-06 06:42:22" resolution="Fixed">
		<buginformation>
			<summary>input buffer reading in the REST interface does not correctly clear the character buffer each iteration</summary>
			<description>when reading the input buffer in the REST interface the character buffer is not cleared for each iteration of the loop.  This can cause malformed data to be read from the input stream in cases where the input is greater than 640 characters.
See lines numbered 366-376 in org.apache.hadoop.hbase.rest.Dispatcher.java
I have prepared a patch for this.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.rest.Dispatcher.java</file>
		</fixedFiles>
	</bug>
	<bug id="1245" opendate="2009-03-06 06:15:57" fixdate="2009-03-06 06:47:25" resolution="Fixed">
		<buginformation>
			<summary>hfile meta block handling bugs</summary>
			<description>HFile doesn&amp;amp;apos;t handle &amp;amp;apos;get meta block&amp;amp;apos; when there are no meta blocks.  It throws an unhelpful exception "meta index not loaded", which is not the case.  No meta blocks = no meta index.  It should return null instead.
Additionally, hfile doesn&amp;amp;apos;t even get all meta names properly, due to the incorrect use of the file&amp;amp;apos;s comparator, instead of using just a bytes comparator in the index.  This is manifested by NPEs in some tests.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFile.java</file>
			<file type="M">org.apache.hadoop.hbase.util.Bytes.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.TestHFile.java</file>
		</fixedFiles>
	</bug>
	<bug id="1238" opendate="2009-03-04 18:56:55" fixdate="2009-03-06 20:01:40" resolution="Fixed">
		<buginformation>
			<summary>Under upload, region servers are unable to compact when loaded with hundreds of regions</summary>
			<description>We have a situation where each region server is loaded with 100+ regions, most of them in the same table. During a long upload of webpages, each memcache gets filled near equally fast so that the global memcache limit is usually triggered before the max memcache size. Since that emergency flush does not trigger compactions, the number of store files just keeps growing until it fails on all kinds of errors.
We need a better story for this as this is a "normal" situation.</description>
			<version>0.19.0</version>
			<fixedVersion>0.19.1, 0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.MemcacheFlusher.java</file>
		</fixedFiles>
	</bug>
	<bug id="1243" opendate="2009-03-06 00:29:15" fixdate="2009-03-06 21:30:53" resolution="Fixed">
		<buginformation>
			<summary>oldlogfile.dat is screwed, so is it&amp;apos;s region</summary>
			<description>Getting this when a node dies (happens frequently lately):

2009-03-05 04:15:03,251 INFO org.apache.hadoop.hbase.master.RegionManager: assigning region web_pages,http://fortcollins.gaymonkey.com/,1235836722125 to server 192.168.1.106:62020
2009-03-05 04:15:15,263 INFO org.apache.hadoop.hbase.master.ServerManager: Received MSG_REPORT_CLOSE: web_pages,http://fortcollins.gaymonkey.com/,1235836722125: java.io.IOException: Could not obtain block: blk_5568212401457404905_251597 file=/hbase/amsterdam_factory/web_pages/1263377107/oldlogfile.log
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.chooseDataNode(DFSClient.java:1708)
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.blockSeekTo(DFSClient.java:1536)
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:1663)
        at java.io.DataInputStream.readFully(DataInputStream.java:178)
        at java.io.DataInputStream.readFully(DataInputStream.java:152)
        at org.apache.hadoop.hbase.io.SequenceFile$Reader.init(SequenceFile.java:1464)
        at org.apache.hadoop.hbase.io.SequenceFile$Reader.&amp;lt;init&amp;gt;(SequenceFile.java:1442)
        at org.apache.hadoop.hbase.io.SequenceFile$Reader.&amp;lt;init&amp;gt;(SequenceFile.java:1431)
        at org.apache.hadoop.hbase.io.SequenceFile$Reader.&amp;lt;init&amp;gt;(SequenceFile.java:1426)
        at org.apache.hadoop.hbase.regionserver.HStore.doReconstructionLog(HStore.java:342)
        at org.apache.hadoop.hbase.regionserver.HStore.runReconstructionLog(HStore.java:297)
        at org.apache.hadoop.hbase.regionserver.HStore.&amp;lt;init&amp;gt;(HStore.java:237)
        at org.apache.hadoop.hbase.regionserver.HRegion.instantiateHStore(HRegion.java:1764)
        at org.apache.hadoop.hbase.regionserver.HRegion.initialize(HRegion.java:276)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.instantiateRegion(HRegionServer.java:1367)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.openRegion(HRegionServer.java:1338)
        at org.apache.hadoop.hbase.regionserver.HRegionServer$Worker.run(HRegionServer.java:1253)
        at java.lang.Thread.run(Thread.java:619)
 from 192.168.1.106:62020
2009-03-05 04:15:18,266 INFO org.apache.hadoop.hbase.master.RegionManager: assigning region web_pages,http://fortcollins.gaymonkey.com/,1235836722125 to server 192.168.1.106:62020
2009-03-05 04:15:30,150 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner scanning meta region {regionname: .META.,,1, startKey: &amp;lt;&amp;gt;, server: 192.168.1.106:62020}
2009-03-05 04:15:30,276 INFO org.apache.hadoop.hbase.master.ServerManager: Received MSG_REPORT_CLOSE: web_pages,http://fortcollins.gaymonkey.com/,1235836722125: java.io.IOException: Could not obtain block: blk_5568212401457404905_251597 file=/hbase/amsterdam_factory/web_pages/1263377107/oldlogfile.log
...


It does not recover, I have to manually delete the file.</description>
			<version>0.19.0</version>
			<fixedVersion>0.19.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
		</fixedFiles>
	</bug>
	<bug id="1169" opendate="2009-01-31 18:41:22" fixdate="2009-03-07 02:23:24" resolution="Fixed">
		<buginformation>
			<summary>When a shutdown is requested, stop scanning META regions immediately</summary>
			<description>During shutdown of cluster, half way through quiescing servers there is a META scan in the master.  The regions from servers whose leases are already canceled show up as invalid.  (72.34.249.208 is hosting META)

2009-01-31 10:25:42,571 INFO org.apache.hadoop.hbase.master.HMaster: Cluster shutdown requested. Starting to quiesce servers
2009-01-31 10:25:45,868 INFO org.apache.hadoop.hbase.master.ServerManager: Cancelling lease for 72.34.249.211:60020
2009-01-31 10:25:45,868 INFO org.apache.hadoop.hbase.master.ServerManager: Region server 72.34.249.211:60020: MSG_REPORT_EXITING -- lease cancelled
2009-01-31 10:25:47,480 INFO org.apache.hadoop.hbase.master.ServerManager: Cancelling lease for 72.34.249.216:60020
2009-01-31 10:25:47,480 INFO org.apache.hadoop.hbase.master.ServerManager: Region server 72.34.249.216:60020: MSG_REPORT_EXITING -- lease cancelled
2009-01-31 10:25:47,840 INFO org.apache.hadoop.hbase.master.ServerManager: Region server 72.34.249.210:60020 quiesced
2009-01-31 10:25:47,944 INFO org.apache.hadoop.hbase.master.ServerManager: Cancelling lease for 72.34.249.215:60020
2009-01-31 10:25:47,944 INFO org.apache.hadoop.hbase.master.ServerManager: Region server 72.34.249.215:60020: MSG_REPORT_EXITING -- lease cancelled
2009-01-31 10:25:48,403 INFO org.apache.hadoop.hbase.master.ServerManager: Cancelling lease for 72.34.249.213:60020
2009-01-31 10:25:48,403 INFO org.apache.hadoop.hbase.master.ServerManager: Region server 72.34.249.213:60020: MSG_REPORT_EXITING -- lease cancelled
2009-01-31 10:25:49,378 INFO org.apache.hadoop.hbase.master.ServerManager: Region server 72.34.249.218:60020 quiesced
2009-01-31 10:25:50,465 INFO org.apache.hadoop.hbase.master.ServerManager: Cancelling lease for 72.34.249.214:60020
2009-01-31 10:25:50,465 INFO org.apache.hadoop.hbase.master.ServerManager: Region server 72.34.249.214:60020: MSG_REPORT_EXITING -- lease cancelled
2009-01-31 10:25:59,531 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner scanning meta region {regionname: .META.,,1, startKey: &amp;lt;&amp;gt;, server: 72.34.249.218:60020}
2009-01-31 10:25:59,544 DEBUG org.apache.hadoop.hbase.master.BaseScanner: Current assignment of activitydupehash,,1229364212541 is not valid;  Server &amp;amp;apos;72.34.249.214:60020&amp;amp;apos; unknown.
2009-01-31 10:25:59,545 DEBUG org.apache.hadoop.hbase.master.BaseScanner: Current assignment of api,,1229364235220 is not valid;  Server &amp;amp;apos;72.34.249.216:60020&amp;amp;apos; unknown.
2009-01-31 10:25:59,552 DEBUG org.apache.hadoop.hbase.master.BaseScanner: Current assignment of apps,,1229364222879 is not valid;  Server &amp;amp;apos;72.34.249.215:60020&amp;amp;apos; unknown.
2009-01-31 10:25:59,552 DEBUG org.apache.hadoop.hbase.master.BaseScanner: Current assignment of assigners,,1229364037757 is not valid;  Server &amp;amp;apos;72.34.249.214:60020&amp;amp;apos; unknown.
2009-01-31 10:25:59,554 DEBUG org.apache.hadoop.hbase.master.BaseScanner: Current assignment of canoncache,,1229364041955 is not valid;  Server &amp;amp;apos;72.34.249.215:60020&amp;amp;apos; unknown.
2009-01-31 10:25:59,555 DEBUG org.apache.hadoop.hbase.master.BaseScanner: Current assignment of chunks,,1229390225893 is not valid;  Server &amp;amp;apos;72.34.249.211:60020&amp;amp;apos; unknown.


Shutdown then continues as the last servers are quiesced, but at the same time the Master expires the lease on the regionserver that was hosting META and that it just scanned.  It then starts to replay the logs for that regionserver in the middle of the shutdown.

2009-01-31 10:25:59,799 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner scan of 512 row(s) of meta region {regionname: .META.,,1, startKey: &amp;lt;&amp;gt;, server: 72.34.249.218:60020}
 complete
2009-01-31 10:25:59,799 INFO org.apache.hadoop.hbase.master.BaseScanner: All 1 .META. region(s) scanned
2009-01-31 10:26:59,530 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner scanning meta region {regionname: .META.,,1, startKey: &amp;lt;&amp;gt;, server: 72.34.249.218:60020}
2009-01-31 10:26:59,720 INFO org.apache.hadoop.hbase.master.BaseScanner: RegionManager.metaScanner scan of 512 row(s) of meta region {regionname: .META.,,1, startKey: &amp;lt;&amp;gt;, server: 72.34.249.218:60020}
 complete
2009-01-31 10:26:59,720 INFO org.apache.hadoop.hbase.master.BaseScanner: All 1 .META. region(s) scanned
2009-01-31 10:27:40,374 INFO org.apache.hadoop.hbase.master.ServerManager: 72.34.249.218:60020 lease expired
2009-01-31 10:27:40,375 DEBUG org.apache.hadoop.hbase.master.HMaster: Processing todo: ProcessServerShutdown of 72.34.249.218:60020
2009-01-31 10:27:40,375 INFO org.apache.hadoop.hbase.master.RegionServerOperation: process shutdown of server 72.34.249.218:60020: logSplit: false, rootRescanned: false, numberOfMetaRegions: 1, onlin
eMetaRegions.size(): 1
2009-01-31 10:27:40,387 INFO org.apache.hadoop.hbase.regionserver.HLog: Splitting 44 log(s) in hdfs://mb0:9000/hbase/log_72.34.249.218_1232996040351_60020
2009-01-31 10:27:40,387 DEBUG org.apache.hadoop.hbase.regionserver.HLog: Splitting 1 of 44: hdfs://mb0:9000/hbase/log_72.34.249.218_1232996040351_60020/hlog.dat.1232996040603
2009-01-31 10:27:40,443 DEBUG org.apache.hadoop.hbase.regionserver.HLog: Creating new log file writer for path hdfs://mb0:9000/hbase/.META./1028785192/oldlogfile.log and region .META.,,1
2009-01-31 10:27:40,575 DEBUG org.apache.hadoop.hbase.regionserver.HLog: Creating new log file writer for path hdfs://mb0:9000/hbase/sources/671225115/oldlogfile.log and region sources,,1229364117966
2009-01-31 10:27:41,171 DEBUG org.apache.hadoop.hbase.regionserver.HLog: Applied 100003 total edits from hdfs://mb0:9000/hbase/log_72.34.249.218_1232996040351_60020/hlog.dat.1232996040603
2009-01-31 10:27:41,173 DEBUG org.apache.hadoop.hbase.regionserver.HLog: Splitting 2 of 44: hdfs://mb0:9000/hbase/log_72.34.249.218_1232996040351_60020/hlog.dat.1233093726382
2009-01-31 10:27:41,429 DEBUG org.apache.hadoop.hbase.regionserver.HLog: Creating new log file writer for path hdfs://mb0:9000/hbase/dupehash/1607532582/oldlogfile.log and region dupehash,O&amp;lt;L;h,12
31779694744
2009-01-31 10:27:41,462 INFO org.apache.hadoop.hbase.master.ServerManager: 72.34.249.217:60020 lease expired
2009-01-31 10:27:41,499 INFO org.apache.hadoop.hbase.master.ServerManager: All user tables quiesced. Proceeding with shutdown
2009-01-31 10:27:41,499 DEBUG org.apache.hadoop.hbase.master.RegionManager: telling root scanner to stop
2009-01-31 10:27:41,499 DEBUG org.apache.hadoop.hbase.master.RegionManager: telling meta scanner to stop
2009-01-31 10:27:41,499 DEBUG org.apache.hadoop.hbase.master.RegionManager: meta and root scanners notified
2009-01-31 10:27:41,499 INFO org.apache.hadoop.hbase.master.RootScanner: RegionManager.rootScanner exiting
2009-01-31 10:27:41,499 INFO org.apache.hadoop.hbase.master.MetaScanner: RegionManager.metaScanner exiting
2009-01-31 10:27:41,780 DEBUG org.apache.hadoop.hbase.regionserver.HLog: Applied 100001 total edits from hdfs://mb0:9000/hbase/log_72.34.249.218_1232996040351_60020/hlog.dat.1233093726382
2009-01-31 10:27:41,781 DEBUG org.apache.hadoop.hbase.regionserver.HLog: Splitting 3 of 44: hdfs://mb0:9000/hbase/log_72.34.249.218_1232996040351_60020/hlog.dat.1233101015153
2009-01-31 10:27:41,838 INFO org.apache.hadoop.hbase.master.ServerManager: 72.34.249.210:60020 lease expired
2009-01-31 10:27:41,866 INFO org.apache.hadoop.hbase.master.ServerManager: All user tables quiesced. Proceeding with shutdown
2009-01-31 10:27:41,866 DEBUG org.apache.hadoop.hbase.master.RegionManager: telling root scanner to stop
2009-01-31 10:27:41,866 DEBUG org.apache.hadoop.hbase.master.RegionManager: telling meta scanner to stop
2009-01-31 10:27:41,866 DEBUG org.apache.hadoop.hbase.master.RegionManager: meta and root scanners notified
2009-01-31 10:27:42,557 INFO org.apache.hadoop.hbase.master.ServerManager: 72.34.249.212:60020 lease expired
2009-01-31 10:27:42,581 INFO org.apache.hadoop.hbase.master.ServerManager: All user tables quiesced. Proceeding with shutdown
2009-01-31 10:27:42,581 DEBUG org.apache.hadoop.hbase.master.RegionManager: telling root scanner to stop
2009-01-31 10:27:42,581 DEBUG org.apache.hadoop.hbase.master.RegionManager: telling meta scanner to stop
2009-01-31 10:27:42,581 DEBUG org.apache.hadoop.hbase.master.RegionManager: meta and root scanners notified
2009-01-31 10:27:42,615 DEBUG org.apache.hadoop.hbase.regionserver.HLog: Applied 100002 total edits from hdfs://mb0:9000/hbase/log_72.34.249.218_1232996040351_60020/hlog.dat.1233101015153
2009-01-31 10:27:42,618 DEBUG org.apache.hadoop.hbase.regionserver.HLog: Splitting 4 of 44: hdfs://mb0:9000/hbase/log_72.34.249.218_1232996040351_60020/hlog.dat.1233111791302
2009-01-31 10:27:43,356 DEBUG org.apache.hadoop.hbase.regionserver.HLog: Applied 100001 total edits from hdfs://mb0:9000/hbase/log_72.34.249.218_1232996040351_60020/hlog.dat.1233111791302
2009-01-31 10:27:43,359 DEBUG org.apache.hadoop.hbase.regionserver.HLog: Splitting 5 of 44: hdfs://mb0:9000/hbase/log_72.34.249.218_1232996040351_60020/hlog.dat.1233122447841
2009-01-31 10:27:43,404 INFO org.apache.hadoop.hbase.master.ServerManager: All user tables quiesced. Proceeding with shutdown
2009-01-31 10:27:43,404 DEBUG org.apache.hadoop.hbase.master.RegionManager: telling root scanner to stop
2009-01-31 10:27:43,404 DEBUG org.apache.hadoop.hbase.master.RegionManager: telling meta scanner to stop
2009-01-31 10:27:43,404 DEBUG org.apache.hadoop.hbase.master.RegionManager: meta and root scanners notified
2009-01-31 10:27:43,991 DEBUG org.apache.hadoop.hbase.regionserver.HLog: Applied 100001 total edits from hdfs://mb0:9000/hbase/log_72.34.249.218_1232996040351_60020/hlog.dat.1233122447841


During the log replay, a log file was missing from HDFS.  Not sure why, there was a Datanode crash that could be related.  More importantly, once it trips on the missing file it stops the replay (even though there&amp;amp;apos;s another 37 logs).

2009-01-31 10:27:43,992 DEBUG org.apache.hadoop.hbase.regionserver.HLog: Splitting 6 of 44: hdfs://mb0:9000/hbase/log_72.34.249.218_1232996040351_60020/hlog.dat.1233132556827
2009-01-31 10:27:44,022 WARN org.apache.hadoop.hbase.master.HMaster: Processing pending operations: ProcessServerShutdown of 72.34.249.218:60020
java.io.FileNotFoundException: File does not exist: hdfs://mb0:9000/hbase/log_72.34.249.218_1232996040351_60020/hlog.dat.1233132556827
        at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:394)
        at org.apache.hadoop.fs.FileSystem.getLength(FileSystem.java:679)
        at org.apache.hadoop.io.SequenceFile$Reader.&amp;lt;init&amp;gt;(SequenceFile.java:1417)
        at org.apache.hadoop.io.SequenceFile$Reader.&amp;lt;init&amp;gt;(SequenceFile.java:1412)
        at org.apache.hadoop.hbase.regionserver.HLog.splitLog(HLog.java:742)
        at org.apache.hadoop.hbase.regionserver.HLog.splitLog(HLog.java:705)
        at org.apache.hadoop.hbase.master.ProcessServerShutdown.process(ProcessServerShutdown.java:249)
        at org.apache.hadoop.hbase.master.HMaster.processToDoQueue(HMaster.java:427)
        at org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:360)
2009-01-31 10:27:44,022 DEBUG org.apache.hadoop.hbase.master.RegionManager: telling root scanner to stop
2009-01-31 10:27:44,022 DEBUG org.apache.hadoop.hbase.master.RegionManager: telling meta scanner to stop
2009-01-31 10:27:44,022 DEBUG org.apache.hadoop.hbase.master.RegionManager: meta and root scanners notified
2009-01-31 10:27:44,023 DEBUG org.apache.hadoop.hbase.RegionHistorian: Offlined
2009-01-31 10:27:44,023 INFO org.apache.hadoop.hbase.master.HMaster: Stopping infoServer
2009-01-31 10:27:44,023 INFO org.mortbay.util.ThreadedServer: Stopping Acceptor ServerSocket[addr=0.0.0.0/0.0.0.0,port=0,localport=60010]
2009-01-31 10:27:44,026 INFO org.mortbay.http.SocketListener: Stopped SocketListener on 0.0.0.0:60010

</description>
			<version>0.19.0</version>
			<fixedVersion>0.19.1, 0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.MetaScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.master.RegionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.master.RootScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ServerManager.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
		</fixedFiles>
	</bug>
	<bug id="1251" opendate="2009-03-10 13:29:32" fixdate="2009-03-13 16:07:59" resolution="Fixed">
		<buginformation>
			<summary>HConnectionManager.getConnection(HBaseConfiguration) returns same HConnection for different HBaseConfigurations </summary>
			<description>This occurs when the following happens:
1. Consider a client that invokes HBaseAdmin.checkHBaseAvailable(config) before doing anything. Although this method copies the HBaseConfiguration object and sets hbase.client.retries.number to 1 (see HBaseAdmin, line 751), it creates an HBaseAdmin object, which invokes HConnectionManager.getConnection(conf). Please notice that this conf is that with hbase.client.retries.number equals to 1. 
2. HConnectionManager.getConnection then creates a HConnection using this conf and puts it into a static map (see HConnectionManager, line 93) indexed by hbase.rootdir. 
3. Then, if the same client now creates a HTable object (using, for instance, a HBaseConfiguration with  hbase.client.retries.number equals to 10 but the same hbase.rootdir), it will invoke HConnectionManager.getConnection(conf) again (see HTable, line 109). However, when it checks the static map for a HConnection it finds one - the one previously created by the HBaseAdmin object and using hbase.client.retries.number 1 - and returns it without creating a new one with the correct HBaseConfiguration.
However, the expected behavior is: HConnectionManager must return different HConnections for different HBaseConfigurations.  </description>
			<version>0.19.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseConfiguration.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">2027</link>
			<link type="Reference" description="relates to">2925</link>
			<link type="Reference" description="is related to">1976</link>
		</links>
	</bug>
	<bug id="1258" opendate="2009-03-12 00:19:40" fixdate="2009-03-14 06:05:53" resolution="Fixed">
		<buginformation>
			<summary>ganglia metrics for &amp;apos;requests&amp;apos; is confusing</summary>
			<description>the &amp;amp;apos;requests&amp;amp;apos; metric is incremented for every request, but it is reset and published every interval.  Which means the number is actually &amp;amp;apos;requests per interval&amp;amp;apos; which is a config value in hbase.  
HBase should export &amp;amp;apos;requests/second&amp;amp;apos; instead.
</description>
			<version>0.19.0</version>
			<fixedVersion>0.19.1, 0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.metrics.RegionServerMetrics.java</file>
		</fixedFiles>
	</bug>
	<bug id="1267" opendate="2009-03-19 00:47:47" fixdate="2009-03-19 08:52:31" resolution="Fixed">
		<buginformation>
			<summary>binary keys broken in trunk (again).</summary>
			<description>Binary keys, specifically ones where the first byte of the key is nul &amp;amp;apos;\0&amp;amp;apos; don&amp;amp;apos;t work:

Splits happen
Logfile indicates everything normal

But the .META. doesnt list all the regions.  It only lists the &amp;amp;apos;basic&amp;amp;apos; regions: &amp;amp;apos;table,,1234&amp;amp;apos;.  The other regions with the binary keys in the middle just dont seem to be in .META....</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.Memcache.java</file>
			<file type="M">org.apache.hadoop.hbase.HStoreKey.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
		</fixedFiles>
	</bug>
	<bug id="1277" opendate="2009-03-20 09:42:48" fixdate="2009-03-20 09:55:10" resolution="Fixed">
		<buginformation>
			<summary>HStoreKey: Wrong comparator logic</summary>
			<description>During fixing fail of TestCompaction JUnit was found error in removing of row Cells. Reason was a error in comparator logic of HStoreKey.
Fix of HStoreKey also fixed removing of row Cell and and TestCompaction.</description>
			<version>0.19.1</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="M">org.apache.hadoop.hbase.HStoreKey.java</file>
		</fixedFiles>
	</bug>
	<bug id="1275" opendate="2009-03-20 09:03:46" fixdate="2009-03-20 09:55:56" resolution="Fixed">
		<buginformation>
			<summary>TestTable.testCreateTable broken</summary>
			<description>Test is broken, we seem to be able to create the same table 10x over.  ouch!</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="M">org.apache.hadoop.hbase.HStoreKey.java</file>
		</fixedFiles>
	</bug>
	<bug id="1107" opendate="2009-01-02 01:37:45" fixdate="2009-03-20 20:33:45" resolution="Fixed">
		<buginformation>
			<summary>NPE in HStoreScanner.updateReaders</summary>
			<description>2009-01-01 23:55:41,629 FATAL org.apache.hadoop.hbase.regionserver.MemcacheFlusher: Replay of hlog required. Forcing server shutdown
org.apache.hadoop.hbase.DroppedSnapshotException: region: content,cff13605e2ea6ce0b221ac864687bf08,1230777531253
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:880)
        at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:773)
        at org.apache.hadoop.hbase.regionserver.MemcacheFlusher.flushRegion(MemcacheFlusher.java:227)
        at org.apache.hadoop.hbase.regionserver.MemcacheFlusher.run(MemcacheFlusher.java:137)
Caused by: java.lang.NullPointerException
        at org.apache.hadoop.hbase.regionserver.HStoreScanner.updateReaders(HStoreScanner.java:322)
        at org.apache.hadoop.hbase.regionserver.HStore.notifyChangedReadersObservers(HStore.java:737)
        at org.apache.hadoop.hbase.regionserver.HStore.updateReaders(HStore.java:725)
        at org.apache.hadoop.hbase.regionserver.HStore.internalFlushCache(HStore.java:694)
        at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:630)
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:865)
        ... 3 more</description>
			<version>0.19.1</version>
			<fixedVersion>0.19.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStoreScanner.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">1076</link>
		</links>
	</bug>
	<bug id="1290" opendate="2009-03-25 21:28:06" fixdate="2009-03-26 01:14:23" resolution="Fixed">
		<buginformation>
			<summary>table.jsp either 500s out or doesnt list the regions</summary>
			<description>The table.jsp page either 500 errors out if you are viewing a .META. or ROOT table, or for user tables it doesn&amp;amp;apos;t list the regions.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.ServerManager.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
		</fixedFiles>
	</bug>
	<bug id="1157" opendate="2009-01-27 02:55:58" fixdate="2009-03-27 06:09:28" resolution="Fixed">
		<buginformation>
			<summary>If we do not take start code as a part of region server recovery, we could inadvertantly try to reassign regions assigned to a restarted server with a different start code</summary>
			<description></description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.RegionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ServerManager.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TableOperation.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TableDelete.java</file>
			<file type="M">org.apache.hadoop.hbase.HServerInfo.java</file>
			<file type="M">org.apache.hadoop.hbase.master.BaseScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ModifyTableMeta.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ChangeTableState.java</file>
			<file type="M">org.apache.hadoop.hbase.HRegionInfo.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ColumnOperation.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ProcessServerShutdown.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ProcessRegionOpen.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HLog.java</file>
		</fixedFiles>
		<links>
			<link type="Blocker" description="blocks">1144</link>
			<link type="Reference" description="relates to">1156</link>
			<link type="Reference" description="relates to">1158</link>
		</links>
	</bug>
	<bug id="1293" opendate="2009-03-27 22:56:18" fixdate="2009-03-28 00:39:06" resolution="Fixed">
		<buginformation>
			<summary>hfile doesn&amp;apos;t recycle decompressors</summary>
			<description>The Compression codec stuff from hadoop has the concept of recycling compressors and decompressors - this is because a compression codec uses "direct buffers" which reside outside the JVM regular heap space.  There is a risk that under heavy concurrent load we could run out of that &amp;amp;apos;direct buffer&amp;amp;apos; heap space in the JVM.
HFile does not call algorithm.returnDecompressor and returnCompressor.  We should fix that.
I found this bug via OOM crashes under jdk 1.7 - it appears to be partially due to the size of my cluster (200gb, 800 regions, 19 servers) and partially due to weaknesses in JVM 1.7.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFile.java</file>
		</fixedFiles>
	</bug>
	<bug id="1303" opendate="2009-04-01 01:39:10" fixdate="2009-04-02 07:33:22" resolution="Fixed">
		<buginformation>
			<summary>Secondary index configuration prevents HBase from starting</summary>
			<description>HBase does not start up when configured to use the IndexedRegionServer with the following properties in hbase-site.xml


 &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;hbase.regionserver.class&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;org.apache.hadoop.hbase.ipc.IndexedRegionInterface&amp;lt;/value&amp;gt;
     &amp;lt;description&amp;gt;Indexing is enabled for this hbase server.  &amp;lt;/description&amp;gt;
 &amp;lt;/property&amp;gt;
 &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.regionserver.impl&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;org.apache.hadoop.hbase.regionserver.tableindexed.IndexedRegionServer&amp;lt;/value&amp;gt;
    &amp;lt;description&amp;gt;Indexing is enabled for this hbase server.&amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;


This results in the following exception in the log:

2009-03-31 12:33:35,993 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 8 on 45026, call getProtocolVersion(org.apache.hadoop.hbase.ipc.IndexedRegionInterface, 16) from 127.0.0.1:60854: error: java.io.IOException: Unknown protocol to name node: org.apache.hadoop.hbase.ipc.IndexedRegionInterface
java.io.IOException: Unknown protocol to name node: org.apache.hadoop.hbase.ipc.IndexedRegionInterface
    at org.apache.hadoop.hbase.regionserver.HRegionServer.getProtocolVersion(HRegionServer.java:2146)
    at org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegionServer.getProtocolVersion(TransactionalRegionServer.java:92)
    at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:632)
    at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:912)
2009-03-31 12:33:35,994 WARN org.apache.hadoop.hbase.master.BaseScanner: Scan ROOT region
java.io.IOException: java.io.IOException: Unknown protocol to name node: org.apache.hadoop.hbase.ipc.IndexedRegionInterface
    at org.apache.hadoop.hbase.regionserver.HRegionServer.getProtocolVersion(HRegionServer.java:2146)
    at org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegionServer.getProtocolVersion(TransactionalRegionServer.java:92)
    at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:632)
    at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:912)


There is also a mailing list post on this problem:
http://markmail.org/message/6pugle5uegiijjbc?q=Secondary+Indexes+problem
I think the solution is to implement public long getProtocolVersion(final String protocol, final long clientVersion) in org.apache.hadoop.hbase.regionserver.tableindexed.IndexedRegionServer as follows:


  @Override
  public long getProtocolVersion(final String protocol, final long clientVersion)
      throws IOException {
    if (protocol.equals(IndexedRegionInterface.class.getName())) {
      return HBaseRPCProtocolVersion.versionID;
    }
    return super.getProtocolVersion(protocol, clientVersion);
  }

</description>
			<version>0.19.1</version>
			<fixedVersion>0.19.2, 0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.tableindexed.IndexedRegionServer.java</file>
		</fixedFiles>
	</bug>
	<bug id="1309" opendate="2009-04-05 02:18:31" fixdate="2009-04-07 18:23:08" resolution="Fixed">
		<buginformation>
			<summary>HFile rejects key in Memcache with empty value</summary>
			<description>2009-04-05 02:12:56,497 FATAL org.apache.hadoop.hbase.regionserver.MemcacheFlusher: Replay of hlog required. Forcing server shutdown
org.apache.hadoop.hbase.DroppedSnapshotException: region: content,,1238896745127
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:878)
	at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:771)
	at org.apache.hadoop.hbase.regionserver.MemcacheFlusher.flushRegion(MemcacheFlusher.java:229)
	at org.apache.hadoop.hbase.regionserver.MemcacheFlusher.run(MemcacheFlusher.java:139)
Caused by: java.io.IOException: Value cannot be null or empty
	at org.apache.hadoop.hbase.io.hfile.HFile$Writer.checkValue(HFile.java:485)
	at org.apache.hadoop.hbase.io.hfile.HFile$Writer.append(HFile.java:447)
	at org.apache.hadoop.hbase.regionserver.Store.internalFlushCache(Store.java:501)
	at org.apache.hadoop.hbase.regionserver.Store.flushCache(Store.java:463)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:863)
	... 3 more</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFile.java</file>
		</fixedFiles>
	</bug>
	<bug id="1202" opendate="2009-02-17 04:12:20" fixdate="2009-04-10 20:00:08" resolution="Fixed">
		<buginformation>
			<summary>getRow does not always work when specifying number of versions</summary>
			<description>When a cell that exists is updated, getRow specifying number of versions does not work.
What is returned is the original value at that timestamp, instead of the updated value.
Note that this only applies when more than one version is specified. getRow with (implied) timestamp = latest does work.</description>
			<version>0.19.0</version>
			<fixedVersion>0.19.2, 0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.Cell.java</file>
		</fixedFiles>
	</bug>
	<bug id="1330" opendate="2009-04-20 06:09:50" fixdate="2009-04-20 07:11:17" resolution="Fixed">
		<buginformation>
			<summary>binary keys broken on trunk</summary>
			<description>The symptom is commits fail with &amp;amp;apos;table not found&amp;amp;apos; exception - even though the table does in fact exist!
Digging in a little with debug logs indicate that getClosestRowBefore() is returning NULL, which for a table that exists should never be!  A key always falls into a region - either the first or the last one at the very least.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.KeyValue.java</file>
		</fixedFiles>
	</bug>
	<bug id="1332" opendate="2009-04-21 07:37:46" fixdate="2009-04-21 08:14:28" resolution="Fixed">
		<buginformation>
			<summary>regionserver carrying .META. starts sucking all cpu, drives load up - infinite loop?</summary>
			<description>the symptom is the cluster comes to a dead halt.  Lookups on meta don&amp;amp;apos;t seem to work, and the regionserver carrying .META. goes hot - using 800% CPU or more, driving system LA up really really high (I&amp;amp;apos;ve seen it as high as 26).  Thread dumps seem to indicate every IPC handler is stuck in Bytes.binarySearch().
</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
		</fixedFiles>
	</bug>
	<bug id="1334" opendate="2009-04-21 20:45:15" fixdate="2009-04-21 23:53:56" resolution="Fixed">
		<buginformation>
			<summary>.META. region running into hfile errors</summary>
			<description>my .META. region refuses to do anything, I get this snippet of a error in the log file:
Caused by: java.lang.IllegalArgumentException at 
                java.nio.Buffer.position(Buffer.java:236) at 
org.apache.hadoop.hbase.io.hfile.HFile$Reader$Scanner.blockSeek(HFile.java:1121)
Looks like the seek code is breaking somehow - seeking before the beginning of the block maybe?</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFile.java</file>
			<file type="M">org.apache.hadoop.hbase.client.Scanner.java</file>
		</fixedFiles>
	</bug>
	<bug id="1301" opendate="2009-03-31 10:10:01" fixdate="2009-04-23 16:20:56" resolution="Fixed">
		<buginformation>
			<summary>HTable.getRow() returns null if the row does no exist</summary>
			<description>The HBase API docs says when the row does not exist, getRow() returns
    RowResult is empty if row does not exist. 
However, in regionserver/HRegionServer.java&amp;amp;apos;s getRow():
      if (result == null || result.isEmpty())
        return null;
      return new RowResult(row, result);
It actually returns null. Either fix the code or the document.</description>
			<version>0.19.0</version>
			<fixedVersion>0.19.2, 0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">1028</link>
			<link type="Reference" description="is related to">1292</link>
			<link type="Reference" description="is related to">1837</link>
		</links>
	</bug>
	<bug id="1292" opendate="2009-03-27 14:17:20" fixdate="2009-04-23 20:39:39" resolution="Fixed">
		<buginformation>
			<summary>php thrift&amp;apos;s getRow() would throw an exception if the row does not exist</summary>
			<description>I&amp;amp;apos;ve been played with thrift recently, and observed an unexpected behavior: when getRow() encounters an non-existent row key, it throws an exception like this:
PHP Fatal error:  Uncaught exception &amp;amp;apos;Exception&amp;amp;apos; with message &amp;amp;apos;getRow failed: unknown result&amp;amp;apos; in pear/thrift/packages/Hbase/Hbase.php:715
Stack trace:
#0 pear/thrift/packages/Hbase/Hbase.php(666): HbaseClient-&amp;gt;recv_getRow()
#1 htdocs/hbase/DemoClient.php(174): HbaseClient-&amp;gt;getRow(&amp;amp;apos;demo_table&amp;amp;apos;, &amp;amp;apos;00100-XXXX&amp;amp;apos;)
#2 
{main}
 thrown in pear/thrift/packages/Hbase/Hbase.php on line 715
I would expect when we pass a non-existent key, it can throw something like NotFound (as in scanner) or one can test with RowResult.isEmpty() just like in java api.</description>
			<version>0.19.0</version>
			<fixedVersion>0.19.2, 0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.generated.Hbase.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.DisabledTestThriftServer.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.ThriftUtilities.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">1301</link>
		</links>
	</bug>
	<bug id="1365" opendate="2009-05-01 15:47:51" fixdate="2009-05-02 23:56:40" resolution="Fixed">
		<buginformation>
			<summary>Typo in TableInputFormatBase.setInputColums</summary>
			<description>Typo in method name.  TableInputFormatBase.getInputColums should be .getInputColumns.</description>
			<version>0.19.1</version>
			<fixedVersion>0.19.2, 0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapred.TableInputFormat.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.TableInputFormatBase.java</file>
		</fixedFiles>
	</bug>
	<bug id="1318" opendate="2009-04-10 00:42:45" fixdate="2009-05-03 17:00:41" resolution="Fixed">
		<buginformation>
			<summary>Thrift server doesnt know about atomicIncrement</summary>
			<description>the thrift server needs the atomicIncrement API implemented</description>
			<version>0.19.1</version>
			<fixedVersion>0.19.2, 0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.generated.Hbase.java</file>
			<file type="M">org.apache.hadoop.hbase.KeyValue.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HAbstractScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
			<file type="M">org.apache.hadoop.hbase.util.MetaUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.TestKeyValue.java</file>
		</fixedFiles>
	</bug>
	<bug id="1279" opendate="2009-03-20 14:48:24" fixdate="2009-05-04 18:35:01" resolution="Fixed">
		<buginformation>
			<summary>Fix the way hostnames and IPs are handled</summary>
			<description>From the list by Yabo-Arber Xu,

Yes, I&amp;amp;apos;ve unlocked the port, and i am actually able to access from the web
UI with a client not running on EC2 to HBase at example.com:60010. It shows
all User Tables, but the Region Servers Address is the EC2 internal address:
domU-12-31-39-00-65-E5.compute-1.internal:60020.
I guess the client fails because it can not connect region server, which
serves only for an internal IP. However, in hbase-site.xml, I did configure
with region server explicitly in its external IP.
&amp;lt;property&amp;gt;
   &amp;lt;name&amp;gt;hbase.regionserver&amp;lt;/name&amp;gt;
   &amp;lt;value&amp;gt;ec2-67-202-57-127.compute-1.amazonaws.com:60020&amp;lt;/value&amp;gt;
   &amp;lt;description&amp;gt;The host and port a HBase region server runs at.
   &amp;lt;/description&amp;gt;
 &amp;lt;/property&amp;gt;
In fact we completely bypass the hostname set in hbase.regionserver, also the hostnames in the web UI are not the good ones. We should do that part like hadoop does.</description>
			<version>0.19.1</version>
			<fixedVersion>0.19.2, 0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.TestSerialization.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.HServerInfo.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
		</fixedFiles>
	</bug>
	<bug id="889" opendate="2008-09-18 20:52:03" fixdate="2009-05-05 03:58:51" resolution="Fixed">
		<buginformation>
			<summary>The current Thrift API does not allow a new scanner to be created without supplying a column list unlike the other APIs.</summary>
			<description>The current Thrift API does not allow a new scanner to be created without supplying a column list, unlike the REST api. I posted this on the HBase-Users mailing list. Others concurred that it appears to have been an oversight in the Thrift API. 
Its quite significant as there is no easy work around, unless you already know which the column families names then list them all when you open the scanner.</description>
			<version>0.2.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
		</fixedFiles>
		<links>
			<link type="Blocker" description="blocks">1153</link>
			<link type="Blocker" description="is blocked by">1142</link>
		</links>
	</bug>
	<bug id="1336" opendate="2009-04-22 20:31:34" fixdate="2009-05-06 00:37:13" resolution="Fixed">
		<buginformation>
			<summary>Splitting up the compare of family+column into 2 different compares</summary>
			<description>When comparing family+column you can end up in  a situation like column1 is "abcd:efg" and column2 is "abc:defg" which in the current implementation of
KeyValue.KeyComparator.compare will result in a faulty result.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.TestKeyValue.java</file>
			<file type="M">org.apache.hadoop.hbase.util.MetaUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
			<file type="M">org.apache.hadoop.hbase.KeyValue.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HAbstractScanner.java</file>
		</fixedFiles>
	</bug>
	<bug id="1370" opendate="2009-05-05 07:04:35" fixdate="2009-05-06 21:26:32" resolution="Fixed">
		<buginformation>
			<summary>re-enable LZO using hadoop-gpl-compression library</summary>
			<description>now that hadoop-gpl-compression has been released, we can add an optional run time dependency to allow LZO compression again.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.hfile.Compression.java</file>
			<file type="M">org.apache.hadoop.hbase.HColumnDescriptor.java</file>
		</fixedFiles>
	</bug>
	<bug id="1392" opendate="2009-05-08 05:59:06" fixdate="2009-05-08 15:40:25" resolution="Fixed">
		<buginformation>
			<summary>change how we build/configure lzocodec</summary>
			<description>i got a reply to my proposed patch for lzocodec:
Instead of deriving from DefaultCodec, you probably want to do the followng:
CompressionCodec lzoCodec = (CompressionCodec)
ReflectionUtils.newInstance(Class.forName("com.hadoop.compression.lzo.LzoCodec"), conf);
setConf is automatically handled by RefletionUtils.newInstance.
We should do that.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.hfile.Compression.java</file>
		</fixedFiles>
	</bug>
	<bug id="1398" opendate="2009-05-09 05:58:35" fixdate="2009-05-09 06:12:29" resolution="Fixed">
		<buginformation>
			<summary>TableOperation doesnt format keys for meta scan properly</summary>
			<description>to scan the meta table, the start row must be in the format &amp;amp;apos;table_name,,&amp;amp;apos; - the commas are not optional.
I found another place in TableOperation which was missing this, causing hbase to close too many regions from unrelated tables (ouch!)</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.TableOperation.java</file>
		</fixedFiles>
	</bug>
	<bug id="1264" opendate="2009-03-16 15:45:41" fixdate="2009-05-13 17:04:09" resolution="Fixed">
		<buginformation>
			<summary>Wrong return values of comparators for ColumnValueFilter</summary>
			<description>The return values of the compareTo() method have to be changed against each other. The method has to return 0 if the regex matches and 1 if it does not.</description>
			<version>0.19.1</version>
			<fixedVersion>0.19.2, 0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.filter.ColumnValueFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.TestColumnValueFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.RegexStringComparator.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.SubstringComparator.java</file>
		</fixedFiles>
	</bug>
	<bug id="1431" opendate="2009-05-16 23:13:19" fixdate="2009-05-18 05:19:45" resolution="Fixed">
		<buginformation>
			<summary>NPE in HTable.checkAndSave when row doesn&amp;apos;t exist</summary>
			<description>To reproduce, just invoke htable.checkAndSave(batchUpdate, expectedValues, lock) using a batchUpdate of a row that doesn&amp;amp;apos;t exist. 
</description>
			<version>0.19.2</version>
			<fixedVersion>0.20.0, 0.19.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestHTable.java</file>
		</fixedFiles>
	</bug>
	<bug id="1401" opendate="2009-05-10 22:32:26" fixdate="2009-05-18 17:44:34" resolution="Fixed">
		<buginformation>
			<summary>close HLog (and open new one) if there hasnt been edits in N minutes/hours</summary>
			<description>this will help narrow the write hole on clusters with periods of light load.  </description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0, 0.19.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.LogRoller.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HLog.java</file>
		</fixedFiles>
	</bug>
	<bug id="1435" opendate="2009-05-18 18:59:14" fixdate="2009-05-19 04:57:06" resolution="Fixed">
		<buginformation>
			<summary>HRegionServer is using wrong info bind address from hbase-site.xml</summary>
			<description>From HRegionServer.java, lines 1149+ (on current trunk):


    if (port &amp;gt;= 0) {
      String addr = this.conf.get("hbase.master.info.bindAddress", "0.0.0.0");
      // check if auto port bind enabled
      boolean auto = this.conf.getBoolean("hbase.regionserver.info.port.auto",
          false);


The above line needs to be changed to


      String addr = this.conf.get("hbase.regionserver.info.bindAddress", "0.0.0.0");

</description>
			<version>0.19.2</version>
			<fixedVersion>0.19.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
		</fixedFiles>
	</bug>
	<bug id="1162" opendate="2009-01-28 22:45:32" fixdate="2009-05-20 21:47:50" resolution="Fixed">
		<buginformation>
			<summary>CME in Master in RegionManager.applyActions</summary>
			<description>CME in Master in RegionManager.applyActions
I believe a region server reported during while a manual compaction request was being processed.
hbase&amp;gt; compact &amp;amp;apos;content&amp;amp;apos;
followed within seconds by...
2009-01-28 22:41:00,822 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 7 on 60000, call regionServerReport(address: 10.30.94.34:60020, startcode: 1233137135818, load: (requests=11, regions=257, usedHeap=1013, maxHeap=1774), [Lorg.apache.hadoop.hbase.HMsg;@6cf8f20d, [Lorg.apache.hadoop.hbase.HRegionInfo;@4bdb6b5f) from 10.30.94.34:58823: error: java.io.IOException: java.util.ConcurrentModificationException
java.io.IOException: java.util.ConcurrentModificationException
        at java.util.TreeMap$PrivateEntryIterator.nextEntry(TreeMap.java:1100)
        at java.util.TreeMap$ValueIterator.next(TreeMap.java:1145)
        at org.apache.hadoop.hbase.master.RegionManager.applyActions(RegionManager.java:1015)
        at org.apache.hadoop.hbase.master.RegionManager.applyActions(RegionManager.java:996)
        at org.apache.hadoop.hbase.master.ServerManager.processMsgs(ServerManager.java:452)
        at org.apache.hadoop.hbase.master.ServerManager.processRegionServerAllsWell(ServerManager.java:388)
        at org.apache.hadoop.hbase.master.ServerManager.regionServerReport(ServerManager.java:292)
        at org.apache.hadoop.hbase.master.HMaster.regionServerReport(HMaster.java:569)
        at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:632)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:895)</description>
			<version>0.19.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.RegionManager.java</file>
		</fixedFiles>
	</bug>
	<bug id="1457" opendate="2009-05-29 05:46:07" fixdate="2009-05-31 16:29:44" resolution="Fixed">
		<buginformation>
			<summary>Taking down ROOT/META regionserver can result in cluster becoming in-operational</summary>
			<description>Take down a regionserver via controlled or uncontrolled shutdown, the master doesn&amp;amp;apos;t properly reassign the root/meta regions. </description>
			<version>0.20.0</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.ProcessRegionStatusChange.java</file>
			<file type="M">org.apache.hadoop.hbase.master.RegionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.master.RegionServerOperation.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ServerManager.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.HBaseClient.java</file>
			<file type="M">org.apache.hadoop.hbase.master.RetryableMetaOperation.java</file>
			<file type="M">org.apache.hadoop.hbase.master.RootScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.master.MetaRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ProcessServerShutdown.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ProcessRegionOpen.java</file>
		</fixedFiles>
	</bug>
	<bug id="1471" opendate="2009-06-01 19:08:35" fixdate="2009-06-01 23:05:47" resolution="Fixed">
		<buginformation>
			<summary>During cluster shutdown, deleting zookeeper regionserver nodes causes exceptions</summary>
			<description>Exception happens during some unit tests:

2009-06-01 11:05:18,075 INFO  [RegionServer:0] regionserver.HRegionServer(665): stopping server at: 192.168.249.1:41463
2009-06-01 11:05:18,076 INFO  [RegionServer:0] regionserver.HRegionServer(679): RegionServer:0 exiting
2009-06-01 11:05:18,077 DEBUG [HMaster] zookeeper.ZooKeeperWrapper(531): Deleting node: 1243883037682
Exception in thread "HMaster" java.lang.IllegalArgumentException: Path must start with / character
	at org.apache.zookeeper.ZooKeeper.validatePath(ZooKeeper.java:537)
	at org.apache.zookeeper.ZooKeeper.delete(ZooKeeper.java:642)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper.clearRSDirectory(ZooKeeperWrapper.java:532)
	at org.apache.hadoop.hbase.master.RegionManager.stop(RegionManager.java:620)
	at org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:425)
2009-06-01 11:05:19,077 INFO  [main] hbase.LocalHBaseCluster(294): Shutdown HMaster 1 region server(s)
2009-06-01 11:05:19,081 INFO  [main] hbase.HBaseTestCase(592): Shutting down FileSystem
2009-06-01 11:05:19,081 INFO  [main] hbase.HBaseTestCase(599): Shutting down Mini DFS 
Shutting down the Mini HDFS Cluster
Shutting down DataNode 1
2009-06-01 11:05:19,178 DEBUG [HMaster-EventThread] client.HConnectionManager$TableServers(203): Got ZooKeeper event, state: Disconnected, type: None, path: null
2009-06-01 11:05:19,178 DEBUG [RegionManager.rootScanner-EventThread] client.HConnectionManager$TableServers(203): Got ZooKeeper event, state: Disconnected, type: None, path: null
2009-06-01 11:05:19,179 DEBUG [main-EventThread] client.HConnectionManager$TableServers(203): Got ZooKeeper event, state: Disconnected, type: None, path: null
2009-06-01 11:05:19,179 INFO  [main-EventThread] regionserver.HRegionServer(367): Got ZooKeeper event, state: Disconnected, type: None, path: null
2009-06-01 11:05:19,179 DEBUG [main-EventThread] regionserver.HRegionServer(372): Ignoring ZooKeeper event while shutting down
2009-06-01 11:05:19,185 WARN  [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@d522de2] datanode.DataXceiverServer(137): DatanodeRegistration(127.0.0.1:36486, storageID=DS-350082559-192.168.249.1-36486-1243883037153, infoPort=58600, ipcPort=57545):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:170)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:102)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:130)
	at java.lang.Thread.run(Thread.java:636)

Shutting down DataNode 0
2009-06-01 11:05:20,293 WARN  [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@42238016] datanode.DataXceiverServer(137): DatanodeRegistration(127.0.0.1:37436, storageID=DS-1878503705-192.168.249.1-37436-1243883036827, infoPort=41289, ipcPort=36123):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:170)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:102)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:130)
	at java.lang.Thread.run(Thread.java:636)

2009-06-01 11:05:21,395 WARN  [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$ReplicationMonitor@286e4365] namenode.FSNamesystem$ReplicationMonitor(2306): ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2009-06-01 11:05:21,399 INFO  [Thread-121] regionserver.HRegionServer$ShutdownThread(951): Starting shutdown thread.
2009-06-01 11:05:21,400 INFO  [Thread-121] regionserver.HRegionServer$ShutdownThread(959): Shutdown thread complete


This is from the test org.apache.hadoop.hbase.client.TestHTable.testHTable()</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper.java</file>
		</fixedFiles>
	</bug>
	<bug id="1357" opendate="2009-04-29 18:38:29" fixdate="2009-06-02 17:54:25" resolution="Fixed">
		<buginformation>
			<summary>If one sets the hbase.master to 0.0.0.0 non local regionservers can&amp;apos;t find the master</summary>
			<description>(2:11:20 PM) posix4e: so i want to run a back master on each node
(2:11:29 PM) posix4e: and i have my hbase.master set to 0.0.0.0
(2:14:59 PM) posix4e: each master only gets the local regionserver connecting
(2:15:08 PM) posix4e: as it must be using that variable to know what to connect to
(2:15:32 PM) nitay: the RS don&amp;amp;apos;t use hbase.master* anymore
(2:15:36 PM) nitay: ohhh i think i know th eproblem
(2:15:44 PM) nitay: so the RS use ZK to get the master address
(2:15:49 PM) nitay: but the masters are writing 0.0.0.0 to it
(2:15:58 PM) nitay: b/c they write whatever was in their conf
(2:16:20 PM) posix4e: yea
(2:16:42 PM) nitay: can u do a zookeeper dump of that node to verify my thinking?
(2:16:55 PM) posix4e: yea
(2:17:12 PM) nitay: it should be /hbase/master, unless u&amp;amp;apos;ve changed the defaults
(2:17:59 PM) nitay: hmm s o ye this is a problem, we solved this in RS (allowing 0.0.0.0) by having master actually write RS&amp;amp;apos;s address to ZK when it gets contacted
(2:18:21 PM) nitay: so now we need to find a way to find out the actual address the master has bound to
(2:19:47 PM) posix4e: is their a way to do that?
(2:20:16 PM) nitay: i dont know, good question
(2:20:18 PM) posix4e: or does it require code changes i.e. regionserver checking zk
(2:20:27 PM) nitay: did u verify the master address?
(2:20:48 PM) posix4e: one sec
(2:21:03 PM) nitay: its almost like we want ZK to be able to tell us what address we&amp;amp;apos;re using to talk to it
(2:21:20 PM) nitay: that assumes u dont have different NICs to talk to ZK vs. HBase
(2:21:59 PM) nitay: posix4e, u can&amp;amp;apos;t really use the RS as far as i can tell b/c the RS knows nothing about the master until the master address appears in ZK
(2:22:25 PM) posix4e: 0:0:0:0:0:0:0:0:60000
(2:22:40 PM) nitay: yep that&amp;amp;apos;s the magic
(2:22:45 PM) nitay: k thx for verifying
(2:22:54 PM) nitay: u want to open up a JIRA?
(2:22:57 PM) posix4e: but if i could tell hbase.site to just use my hostname:port it would work ok
(2:22:58 PM) posix4e: yea
(2:23:09 PM) posix4e: can i quote this conversation?
(2:23:18 PM) nitay: yes please do
(2:23:45 PM) nitay: also, to fix this here and now for u, u&amp;amp;apos;d essentially need to actually set hbase.master* to the ip/host u&amp;amp;apos;re using
(2:23:55 PM) nitay: and change it on each backup master to that guy&amp;amp;apos;s host/ip
(2:24:02 PM) nitay: i know, its a royal PITA
(2:24:59 PM) posix4e: yea
(2:25:03 PM) posix4e: no problem
(2:25:20 PM) nitay: but that should work till we find a better solution
(2:25:21 PM) posix4e: I am trying to think how a patch would work
(2:25:25 PM) posix4e: have a masters file?
(2:25:44 PM) nitay: yeah if u have any ideas please offer them
(2:25:46 PM) nitay: hmm interesting idea
(2:26:16 PM) nitay: and then do some local gethostbyname() type thing checking against masters file?
(2:26:26 PM) posix4e: yea
(2:28:23 PM) nitay: one thing to note is we&amp;amp;apos;ve talked about eventually getting to a place where any RS can be master
(2:28:30 PM) nitay: but i like your idea
(2:28:37 PM) nitay: post it on the JIRA
(2:30:24 PM) nitay: i gotta run, thanks for the info posix4e - very helpful, its great to hear from people actually using this stuff
(2:32:56 PM) posix4e: yep
I also solved this by manually setting the hbase.master  on each host to point to the local hostname, which sucks.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ServerManager.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="M">org.apache.hadoop.hbase.zookeeper.HQuorumPeer.java</file>
			<file type="M">org.apache.hadoop.hbase.LocalHBaseCluster.java</file>
			<file type="M">org.apache.hadoop.hbase.HConstants.java</file>
			<file type="M">org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">1445</link>
			<link type="dependent" description="is depended upon by">1448</link>
		</links>
	</bug>
	<bug id="1462" opendate="2009-05-31 09:07:29" fixdate="2009-06-03 16:48:03" resolution="Fixed">
		<buginformation>
			<summary>hclient still seems to depend on master</summary>
			<description>during a master down, but cluster up event, my clients seem to not work.
clients shouldnt need to talk to the master anymore in 0.20.  We should double check this.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionManager.java</file>
		</fixedFiles>
	</bug>
	<bug id="1466" opendate="2009-06-01 08:26:20" fixdate="2009-06-08 02:56:52" resolution="Fixed">
		<buginformation>
			<summary>Binary keys are not first class citizens</summary>
			<description>If you use binary keys, you don&amp;amp;apos;t get full features as if you were not using binary keys.  Some things that are broken:

grep/less cant search in logfiles with binary data
displays are unreadable due to weird utf8/other issues
can&amp;amp;apos;t use the region historian
etc

</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.TestTable.java</file>
			<file type="M">org.apache.hadoop.hbase.KeyValue.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TableOperation.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestStoreFile.java</file>
			<file type="M">org.apache.hadoop.hbase.master.RegionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.io.HeapSize.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFile.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.HMsg.java</file>
			<file type="M">org.apache.hadoop.hbase.HFilePerformanceEvaluation.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.TestHFile.java</file>
			<file type="M">org.apache.hadoop.hbase.master.BaseScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ProcessRegionClose.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ServerManager.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.HStoreKey.java</file>
			<file type="M">org.apache.hadoop.hbase.RegionHistorian.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
			<file type="M">org.apache.hadoop.hbase.util.Bytes.java</file>
			<file type="M">org.apache.hadoop.hbase.HRegionInfo.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.TableSplit.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TableDelete.java</file>
		</fixedFiles>
	</bug>
	<bug id="1518" opendate="2009-06-13 23:51:01" fixdate="2009-06-14 03:17:51" resolution="Fixed">
		<buginformation>
			<summary>Delete Trackers using compareRow, should just use raw binary comparator</summary>
			<description>Doesn&amp;amp;apos;t matter when using a normal table, but this is using a special comparator on columns for the catalog tables.  Replace comparator.compareRows with Bytes.compareTo</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestGetDeleteTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.GetDeleteTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.QueryMatcher.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.ScanDeleteTracker.java</file>
		</fixedFiles>
	</bug>
	<bug id="1522" opendate="2009-06-15 05:40:06" fixdate="2009-06-15 05:45:43" resolution="Fixed">
		<buginformation>
			<summary>We delete splits before their time occasionally</summary>
			<description>the master logfile says:
2009-06-13 01:47:50,993 DEBUG org.apache.hadoop.hbase.master.BaseScanner: Looking for reference files in: hdfs://borg13:9000/hbase-1304/table/582659871/default2009-06-13 01:47:50,994 DEBUG org.apache.hadoop.hbase.master.BaseScanner: isReference: hdfs://borg13:9000/hbase-1304/table/582659871/default/7693630986938671024
2009-06-13 01:47:50,995 DEBUG org.apache.hadoop.hbase.master.BaseScanner: table,,1244880487129/582659871 no longer has references to table,,1244877673805
2009-06-13 01:47:51,007 DEBUG org.apache.hadoop.hbase.master.BaseScanner: Looking for reference files in: hdfs://borg13:9000/hbase-1304/table/582659871/default2009-06-13 01:47:51,007 DEBUG org.apache.hadoop.hbase.master.BaseScanner: isReference: hdfs://borg13:9000/hbase-1304/table/582659871/default/7693630986938671024
2009-06-13 01:47:51,008 DEBUG org.apache.hadoop.hbase.master.BaseScanner: table,,1244880487129/582659871 no longer has references to table,,12448776738
052009-06-13 01:47:51,009 INFO org.apache.hadoop.hbase.master.BaseScanner: Deleting region table,,1244877673805 (encoded=1481906432) because daughter splits no longe
r hold references2009-06-13 01:47:51,009 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: DELETING region hdfs://borg13:9000/hbase-1304/table/1481906432
As you can see, apparently splitA and splitB point to the same region!</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
		</fixedFiles>
	</bug>
	<bug id="1500" opendate="2009-06-08 23:00:50" fixdate="2009-06-15 05:48:04" resolution="Fixed">
		<buginformation>
			<summary>KeyValue$KeyComparator array overrun</summary>
			<description>

09/06/08 22:58:47 INFO zookeeper.ZooKeeper: Initiating client connection, host=B
OA03:2181,BOA02:2181,BOA01:2181,BOA04:2181 sessionTimeout=10000 watcher=org.apac
he.hadoop.hbase.zookeeper.WatcherWrapper@518bf072
09/06/08 22:58:47 INFO zookeeper.ClientCnxn: zookeeper.disableAutoWatchReset is
false
09/06/08 22:58:47 INFO zookeeper.ClientCnxn: Attempting connection to server BOA
04/172.20.3.231:2181
09/06/08 22:58:47 INFO zookeeper.ClientCnxn: Priming connection to java.nio.chan
nels.SocketChannel[connected local=/172.20.3.232:40296 remote=BOA04/172.20.3.231
:2181]
09/06/08 22:58:47 INFO zookeeper.ClientCnxn: Server connection successful
09/06/08 22:58:47 WARN mapred.JobClient: Use GenericOptionsParser for parsing th
e arguments. Applications should implement Tool for the same.
09/06/08 22:58:47 WARN mapred.JobClient: No job jar file set.  User classes may
not be found. See JobConf(Class) or JobConf#setJar(String).
09/06/08 22:58:47 INFO zookeeper.ZooKeeper: Initiating client connection, host=B
OA03:2181,BOA02:2181,BOA01:2181,BOA04:2181 sessionTimeout=10000 watcher=org.apac
he.hadoop.hbase.zookeeper.WatcherWrapper@362f0d54
09/06/08 22:58:47 INFO zookeeper.ClientCnxn: Attempting connection to server BOA
03/172.20.3.230:2181
09/06/08 22:58:47 INFO zookeeper.ClientCnxn: Priming connection to java.nio.chan
nels.SocketChannel[connected local=/172.20.3.232:42792 remote=BOA03/172.20.3.230
:2181]
09/06/08 22:58:47 INFO zookeeper.ClientCnxn: Server connection successful
09/06/08 22:58:48 INFO mapred.TableInputFormatBase: split: 0-&amp;gt;BOA04.trendmicro.c
om:,01e33c601a7a9dd0ddb5c8427438f2f1
Exception in thread "main" java.lang.ArrayIndexOutOfBoundsException: 32
        at org.apache.hadoop.hbase.util.Bytes.compareTo(Bytes.java:798)
        at org.apache.hadoop.hbase.KeyValue$KeyComparator.compareRows(KeyValue.j
ava:1760)
        at org.apache.hadoop.hbase.KeyValue$KeyComparator.compare(KeyValue.java:
1696)
        at org.apache.hadoop.hbase.KeyValue$KeyComparator.compare(KeyValue.java:
1755)
        at org.apache.hadoop.hbase.KeyValue$KeyComparator.compare(KeyValue.java:
1687)
        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getCac
hedLocation(HConnectionManager.java:697)
        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locate
RegionInMeta(HConnectionManager.java:541)
        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locate
Region(HConnectionManager.java:525)
        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locate
Region(HConnectionManager.java:488)
        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getReg
ionLocation(HConnectionManager.java:342)
        at org.apache.hadoop.hbase.client.HTable.getRegionLocation(HTable.java:1
91)
        at org.apache.hadoop.hbase.mapred.TableInputFormatBase.getSplits(TableIn
putFormatBase.java:296)
        at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:742)
        at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:1026)
        at net.iridiant.crawler.mapred.DocumentParser.main(Unknown Source)

</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.KeyValue.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
			<file type="M">org.apache.hadoop.hbase.io.HalfHFileReader.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MinorCompactingStoreScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.ScanQueryMatcher.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionManager.java</file>
		</fixedFiles>
	</bug>
	<bug id="1525" opendate="2009-06-15 19:20:38" fixdate="2009-06-15 20:18:38" resolution="Fixed">
		<buginformation>
			<summary>HTable.incrementColumnValue hangs() </summary>
			<description>In the following code, 
   @Test
    public void usingIncrement() throws Exception 
    {
        long siteId = 1234;
        long publisherId = 5678;
        Date eventTime = DATE_INPUT_FORMAT.parse("2009-06-15 13:08:54");
        long[] metrics = new long[] 
{ 10, 22, 32 }
;
        byte[] rowKey = Bytes.toBytes(siteId + "_" + ROW_KEY_FORMAT.format(eventTime));
        byte[] family = Bytes.toBytes(FAMILY_PUBLISHER);
        byte[] qualifier = Bytes.toBytes(publisherId);
        HTable table = getTable();
        for (int i1 = 0, n1 = metrics.length; n1 &amp;gt; 0; i1++, n1--) {
            LOGGER.info("processing [
{0}] ...", i1);
            table.incrementColumnValue(rowKey, family, qualifier, metrics[i1]);
            LOGGER.info("processing [{0}
] completed", i1);
        }
        table.close();
        queryMetrics(table, siteId, publisherId, eventTime);
    }
The call table.incrementColumnValue hangs. Have to kill the hbase client and the master processes to get around the problem.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
		</fixedFiles>
	</bug>
	<bug id="1523" opendate="2009-06-15 06:14:48" fixdate="2009-06-15 21:23:30" resolution="Fixed">
		<buginformation>
			<summary>NPE in BaseScanner</summary>
			<description>ever since HBASE-1522 I get this in master:
2009-06-14 23:09:33,043 ERROR org.apache.hadoop.hbase.master.BaseScanner: Unexpected exception
java.lang.NullPointerException
        at org.apache.hadoop.hbase.util.Writables.getWritable(Writables.java:74)
        at org.apache.hadoop.hbase.util.Writables.getHRegionInfo(Writables.java:118)
        at org.apache.hadoop.hbase.master.BaseScanner.hasReferences(BaseScanner.java:300)
        at org.apache.hadoop.hbase.master.BaseScanner.cleanupSplits(BaseScanner.java:267)
        at org.apache.hadoop.hbase.master.BaseScanner.scanRegion(BaseScanner.java:229)
        at org.apache.hadoop.hbase.master.MetaScanner.scanOneMetaRegion(MetaScanner.java:73)
        at org.apache.hadoop.hbase.master.MetaScanner.maintenanceScan(MetaScanner.java:129)
        at org.apache.hadoop.hbase.master.BaseScanner.chore(BaseScanner.java:136)
        at org.apache.hadoop.hbase.Chore.run(Chore.java:68)
preventing ROOT/etc from getting assigned. ouch!</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.BaseScanner.java</file>
		</fixedFiles>
	</bug>
	<bug id="1536" opendate="2009-06-17 20:56:42" fixdate="2009-06-17 22:28:07" resolution="Fixed">
		<buginformation>
			<summary>Controlled crash of regionserver not hosting meta/root leaves master in spinning state, regions not reassigned</summary>
			<description>Testing for HBASE-867 uncovered some nastiness introduced from HBASE-1304 when a regionserver goes down.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.ProcessServerShutdown.java</file>
		</fixedFiles>
	</bug>
	<bug id="1541" opendate="2009-06-18 06:10:24" fixdate="2009-06-18 23:17:10" resolution="Fixed">
		<buginformation>
			<summary>Scanning multiple column families in the presence of deleted families results in bad scans</summary>
			<description>This unit test fails:

  public void testScanner_DeleteOneFamilyNotAnother() throws IOException {
    byte [] tableName = Bytes.toBytes("test_table");
    byte [] fam1 = Bytes.toBytes("columnA");
    byte [] fam2 = Bytes.toBytes("columnB");
    initHRegion(tableName, getName(), fam1, fam2);

    byte [] rowA = Bytes.toBytes("rowA");
    byte [] rowB = Bytes.toBytes("rowB");

    byte [] value = Bytes.toBytes("value");

    Delete delete = new Delete(rowA);
    delete.deleteFamily(fam1);

    region.delete(delete, null, true);

    // now create data.
    Put put = new Put(rowA);
    put.add(fam2, null, value);
    region.put(put);

    put = new Put(rowB);
    put.add(fam1, null, value);
    put.add(fam2, null, value);
    region.put(put);

    Scan scan = new Scan();
    scan.addFamily(fam1).addFamily(fam2);
    InternalScanner s = region.getScanner(scan);
    List&amp;lt;KeyValue&amp;gt; results = new ArrayList&amp;lt;KeyValue&amp;gt;();
    s.next(results);
    assertTrue(Bytes.equals(rowA, results.get(0).getRow()));

    results.clear();
    s.next(results);
    assertTrue(Bytes.equals(rowB, results.get(0).getRow()));

  }

</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestStoreScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.DeleteCompare.java</file>
			<file type="M">org.apache.hadoop.hbase.client.Result.java</file>
			<file type="M">org.apache.hadoop.hbase.client.Delete.java</file>
			<file type="D">org.apache.hadoop.hbase.thrift.DisabledTestThriftServer.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Memcache.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestMemcache.java</file>
		</fixedFiles>
	</bug>
	<bug id="1545" opendate="2009-06-19 07:50:08" fixdate="2009-06-19 22:02:23" resolution="Fixed">
		<buginformation>
			<summary>atomicIncrements creating new values with Long.MAX_VALUE</summary>
			<description>Atomic increment is creating new key values with timestamp of Long.MAX_VALUE.  This is not good, makes it hard to do range queries (as most of Thrift queries are).
</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
		</fixedFiles>
	</bug>
	<bug id="1547" opendate="2009-06-19 08:26:22" fixdate="2009-06-19 22:15:10" resolution="Fixed">
		<buginformation>
			<summary>atomicIncrement doesnt increase hregion.memcacheSize</summary>
			<description>this prevents flushing!  </description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">1557</link>
		</links>
	</bug>
	<bug id="1561" opendate="2009-06-22 07:50:29" fixdate="2009-06-22 17:23:31" resolution="Fixed">
		<buginformation>
			<summary>HTable Mismatch between javadoc and what it actually does</summary>
			<description>The code is:
  /** 

Delete all cells that match the passed row and column and whose
timestamp is equal-to or older than the passed timestamp, using an
existing row lock.
@param row Row to update
@param column name of column whose value is to be deleted
@param ts Delete all cells of the same timestamp or older.
@param rl Existing row lock
@throws IOException
@deprecated As of hbase 0.20.0, replaced by 
{@link #delete(Delete)}
   */
  public void deleteAll(final byte [] row, final byte [] column, final long ts,
      final RowLock rl)
  throws IOException 
{
    Delete d = new Delete(row, ts, rl);
    d.deleteColumn(column);
    delete(d);
  }

The code should call deleteColumns() instead.
</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.Delete.java</file>
			<file type="M">org.apache.hadoop.hbase.client.Get.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.RowWhileMatchFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.package-info.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
		</fixedFiles>
	</bug>
	<bug id="1558" opendate="2009-06-21 03:42:47" fixdate="2009-06-22 18:10:11" resolution="Fixed">
		<buginformation>
			<summary>deletes use &amp;apos;HConstants.LATEST_TIMESTAMP&amp;apos; but no one translates that into &amp;apos;now&amp;apos;</summary>
			<description>Deletes don&amp;amp;apos;t update MAX_TIMESTAMP -&amp;gt; now like puts do.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TableInputFormat.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseTestCase.java</file>
		</fixedFiles>
	</bug>
	<bug id="1508" opendate="2009-06-10 08:26:48" fixdate="2009-06-22 23:39:26" resolution="Fixed">
		<buginformation>
			<summary>Shell "close_region" reveals a Master&lt;&gt;HRS problem, regions are not reassigned</summary>
			<description>When issuing a "close_region" on the shell the Master logs these entries:


...
2009-06-09 22:11:31,141 DEBUG org.apache.hadoop.hbase.master.RegionManager: Applying operation in tasklists to region
2009-06-09 22:11:33,557 DEBUG org.apache.hadoop.hbase.master.HMaster: Attempting to close region: TestTable,0000291328,1244572849139
2009-06-09 22:11:33,560 INFO org.apache.hadoop.hbase.master.HMaster: Marking TestTable,0000291328,1244572849139 as closed on 192.168.2.103:63745; cleaning SERVER + STARTCODE; master will tell regionserver to close region on next heartbeat
2009-06-09 22:11:34,156 DEBUG org.apache.hadoop.hbase.master.RegionManager: Applying operation in tasklists to region
...


But that is it, no further processing is done. The regions stays closed, and even across a restart it stays closed. 
According to what I got told the region should be automatically reassigned to a new server. Please confirm that this is what is expected. If not and the above seems right, then please disregard and close issue.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.BaseScanner.java</file>
		</fixedFiles>
	</bug>
	<bug id="1568" opendate="2009-06-23 02:24:13" fixdate="2009-06-23 16:19:48" resolution="Fixed">
		<buginformation>
			<summary>Client doesnt consult old row filter interface in filterSaysStop() - could result in NPE or excessive scanning</summary>
			<description>The implementation of HTable.ClientScanner.filterSaysStop() doesnt refer to the old filter, which could result in an NPE if you use an old-style filter.
It also ignores the old style filter, so if you want to use old filters only, you dont get the effect you need.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
		</fixedFiles>
	</bug>
	<bug id="1567" opendate="2009-06-23 02:18:43" fixdate="2009-06-24 05:34:47" resolution="Fixed">
		<buginformation>
			<summary>cant serialize new filters: </summary>
			<description>09/06/22 19:14:28 ERROR io.HbaseObjectWritable: Unsupported type interface org.apache.hadoop.hbase.filter.Filter
09/06/22 19:14:28 ERROR io.HbaseObjectWritable: writeClassCode
09/06/22 19:14:28 ERROR io.HbaseObjectWritable: writeObject
09/06/22 19:14:28 ERROR io.HbaseObjectWritable: write
09/06/22 19:14:28 ERROR io.HbaseObjectWritable: writeObject
09/06/22 19:14:28 ERROR io.HbaseObjectWritable: write
09/06/22 19:14:28 ERROR io.HbaseObjectWritable: sendParam
09/06/22 19:14:28 ERROR io.HbaseObjectWritable: call
ooooopsy</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.TestHbaseObjectWritable.java</file>
			<file type="M">org.apache.hadoop.hbase.io.HbaseObjectWritable.java</file>
		</fixedFiles>
	</bug>
	<bug id="1576" opendate="2009-06-23 21:00:58" fixdate="2009-06-24 06:02:57" resolution="Fixed">
		<buginformation>
			<summary>TIF needs to be able to set scanner caching size for smaller row tables &amp; performance</summary>
			<description>TIF goes with the default scanner caching size (1).  When each row is processed very fast and is small, this limits the overall performance.  By setting a higher scanner caching level you can achieve 100x+ the performance with the exact same map-reduce and table.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapred.TableMapReduceUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
		</fixedFiles>
	</bug>
	<bug id="1562" opendate="2009-06-22 16:51:37" fixdate="2009-06-24 20:03:33" resolution="Fixed">
		<buginformation>
			<summary>How to handle the setting of 32 bit versus 64 bit machines</summary>
			<description>After adding the tests to verify the correctness of the HeapSize calculations the question of where to set the type of machines that are in the cluster arose.
I would think that most people are using 64 bit machines but we still need to support the use of 32 bit. So the way I see it we can solve this problem in two ways,
we can either have a settable parameter the the user sets when starting up the cluster or we can try to figure it out ourselves. I think that the second solution would
be the best, to make it as easy as possible on the user. 
That means that we need to add extra sizes to HeapSize and maybe even to Bytes.
Thoughts, comments?</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.KeyValue.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HLogKey.java</file>
			<file type="M">org.apache.hadoop.hbase.io.HeapSize.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.TestHFile.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFile.java</file>
			<file type="M">org.apache.hadoop.hbase.io.TestHeapSize.java</file>
			<file type="M">org.apache.hadoop.hbase.util.ClassSize.java</file>
			<file type="M">org.apache.hadoop.hbase.client.Put.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.LruHashMap.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">1554</link>
		</links>
	</bug>
	<bug id="1563" opendate="2009-06-22 17:26:07" fixdate="2009-06-25 22:12:55" resolution="Fixed">
		<buginformation>
			<summary>incrementColumnValue does not write to WAL</summary>
			<description>Incrementing never writes to the WAL.  Under failure scenarios, you will lose all increments since the last flush.
Do we want to expose the option to the client as to whether to write to WAL or not?</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.HRegionInterface.java</file>
			<file type="M">org.apache.hadoop.hbase.KeyValue.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestStore.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
		</fixedFiles>
	</bug>
	<bug id="1566" opendate="2009-06-23 02:14:15" fixdate="2009-06-25 23:56:50" resolution="Fixed">
		<buginformation>
			<summary>using Scan(startRow,stopRow) will cause you to iterate the entire table</summary>
			<description>Right now the only way for the client scanner to know that we are at the &amp;amp;apos;end&amp;amp;apos; of a scan is to client-side-wise use the filter to figure this out. 
This is not easy to fix because the server is unable to indicate the difference between &amp;amp;apos;done with this region&amp;amp;apos;, and &amp;amp;apos;you&amp;amp;apos;re at the end of your scan&amp;amp;apos;.  In both cases we return 0 results, and the client can&amp;amp;apos;t figure out what it means.
Right now the best solution is to use filters, which is tricky since there is no StopRowFilter because that functionality is built in 
We might have to hack the &amp;amp;apos;stop row&amp;amp;apos; functionality as a filter until we can improve the client-server API/RPC.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
		</fixedFiles>
	</bug>
	<bug id="1569" opendate="2009-06-23 07:42:47" fixdate="2009-06-25 23:57:37" resolution="Fixed">
		<buginformation>
			<summary>rare race condition can take down a regionserver. </summary>
			<description>this happened after &amp;gt; 24 hours of heavy import load on my cluster.  Luckily the shutdown seemed to be clean:
java.lang.IllegalAccessError: Call open first
        at org.apache.hadoop.hbase.regionserver.StoreFile.getReader(StoreFile.java:356)
        at org.apache.hadoop.hbase.regionserver.Store.getStorefilesIndexSize(Store.java:1378)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.doMetrics(HRegionServer.java:1075)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:454)
        at java.lang.Thread.run(Thread.java:619)</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
		</fixedFiles>
	</bug>
	<bug id="1560" opendate="2009-06-22 02:24:59" fixdate="2009-06-26 00:00:00" resolution="Fixed">
		<buginformation>
			<summary>TIF (and other clients?) cant seem to find one region (getClosestRowBefore issue?)</summary>
			<description>running a full TIF-mr on a table, it eventually fails, all on 1 of the splits, and all with the same exception set, which is:
org.apache.hadoop.hbase.client.RetriesExhaustedException: Trying to contact region server null for region , row &amp;amp;apos;&amp;amp;apos;, but failed after 10 attempts.
Exceptions:
java.lang.NullPointerException
java.lang.NullPointerException
java.lang.NullPointerException
java.lang.NullPointerException
java.lang.NullPointerException
java.lang.NullPointerException
java.lang.NullPointerException
java.lang.NullPointerException
java.lang.NullPointerException
java.lang.NullPointerException
	at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.getRegionServerWithRetries(HConnectionManager.java:935)
	at org.apache.hadoop.hbase.client.HTable$ClientScanner.nextScanner(HTable.java:1842)
	at org.apache.hadoop.hbase.client.HTable$ClientScanner.initialize(HTable.java:1790)
	at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:369)
	at org.apache.hadoop.hbase.mapred.TableInputFormatBase$TableRecordReader.restart(TableInputFormatBase.java:121)
	at org.apache.hadoop.hbase.mapred.TableInputFormatBase$TableRecordReader.next(TableInputFormatBase.java:222)
	at org.apache.hadoop.hbase.mapred.TableInputFormatBase$TableRecordReader.next(TableInputFormatBase.java:90)
	at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.moveToNext(MapTask.java:191)
	at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.next(MapTask.java:175)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:48)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:356)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:305)
	at org.apache.hadoop.mapred.Child.main(Child.java:170)
Suspicion: We can&amp;amp;apos;t locate the &amp;amp;apos;root&amp;amp;apos; region with key &amp;amp;apos;&amp;amp;apos; or null.  Probably an issue with getClosestRowBefore.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.Scan.java</file>
		</fixedFiles>
	</bug>
	<bug id="1580" opendate="2009-06-24 19:59:41" fixdate="2009-06-26 05:26:49" resolution="Fixed">
		<buginformation>
			<summary>Store scanner does not consult filter.filterRow at end of scan</summary>
			<description>I have impelemented a columnValueFilter (with new interface) that should filter out the last of two rows in a table. However, I notice that filterRow is only being called on the first row, and the second row is returned.
This patch fixes it, but needs review. My first attempt at adding the call in the DONE_SCAN case did not fix it, but still seems right. The second addition at the end of the method fixed it.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
		</fixedFiles>
	</bug>
	<bug id="1591" opendate="2009-06-30 01:04:03" fixdate="2009-06-30 02:43:03" resolution="Fixed">
		<buginformation>
			<summary>HBASE-1554 broke org.apache.hadoop.hbase.io.hfile.TestLruBlockCache.testResizeBlockCache</summary>
			<description>Modification of LRU heap size calculations altered some of the test expectations in the LRU test.

Error Message
expected:&amp;lt;0&amp;gt; but was:&amp;lt;1&amp;gt;

Stacktrace
junit.framework.AssertionFailedError: expected:&amp;lt;0&amp;gt; but was:&amp;lt;1&amp;gt;
	at org.apache.hadoop.hbase.io.hfile.TestLruBlockCache.testResizeBlockCache(TestLruBlockCache.java:435)


Patch coming...</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.hfile.TestLruBlockCache.java</file>
			<file type="M">org.apache.hadoop.hbase.io.TestHeapSize.java</file>
			<file type="M">org.apache.hadoop.hbase.util.ClassSize.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
		</fixedFiles>
	</bug>
	<bug id="1597" opendate="2009-07-01 05:01:28" fixdate="2009-07-03 18:41:12" resolution="Fixed">
		<buginformation>
			<summary>Prevent unnecessary caching of blocks during compactions</summary>
			<description>When running any kind of compaction, we read every block of every storefile being compacted into the block cache.
We would like to reuse any already cached blocks, if available, but otherwise we should not bog down the LRU with unnecessary blocks.
This is not as bad as it was with the old LRU because the latest LRU implementation (HBASE-1460) is scan-resistant.  This ensures that we are not causing massive eviction of the blocks that are being read multiple times or from in-memory tables.  However, this does add to the GC-woes of an import because each block gets further referenced, and for longer periods of time.  There is also overhead in running the LRU evictions.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFile.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
			<file type="M">org.apache.hadoop.hbase.io.HalfHFileReader.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
			<file type="M">org.apache.hadoop.hbase.KeyValue.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">3976</link>
		</links>
	</bug>
	<bug id="1607" opendate="2009-07-02 20:54:13" fixdate="2009-07-03 19:44:33" resolution="Fixed">
		<buginformation>
			<summary>Redo MemStore heap sizing to be accurate, testable, and more like new LruBlockCache</summary>
			<description>MemStore sizing is inaccurate and does not include all overhead.
I&amp;amp;apos;m going to make it look like the LruBlockCache does.  Will provide a MemStore.heapSize() method that includes ALL overhead of the MemStore itself.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HLog.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.RegionHistorian.java</file>
			<file type="M">org.apache.hadoop.hbase.io.TestHeapSize.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
			<file type="M">org.apache.hadoop.hbase.util.ClassSize.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MemStore.java</file>
		</fixedFiles>
	</bug>
	<bug id="1600" opendate="2009-07-01 17:19:52" fixdate="2009-07-03 23:53:07" resolution="Fixed">
		<buginformation>
			<summary>Multiple HBase clients to multiple indpendent HBase clusters from the same jvm should be allowed</summary>
			<description>ZK quorum servers list is static in ZooKeeperWrapper and is coupled to zoo.cfg. 
This prevents multiple clients from connecting to multiple distinct HBase clusters and requires zoo.cfg to exist on a cluster that needs to connect to a remote HBase cluster.</description>
			<version>0.20.0</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.Table.java</file>
		</fixedFiles>
	</bug>
	<bug id="1620" opendate="2009-07-07 07:29:40" fixdate="2009-07-07 18:10:00" resolution="Fixed">
		<buginformation>
			<summary>Need to use special StoreScanner constructor for major compactions (passed sf, no caching, etc)</summary>
			<description>Should not cache blocks during major compactions like with minor compactions.
Also, need to only work on passed StoreFiles.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
		</fixedFiles>
	</bug>
	<bug id="1625" opendate="2009-07-07 23:46:48" fixdate="2009-07-08 04:04:37" resolution="Fixed">
		<buginformation>
			<summary>Adding check to Put.add(KeyValue kv), to see that it has the same row as when instantiated</summary>
			<description>When using the add(KeyValue kv) in Put there is no check to see if the kv has the same row as the row already in the put.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.Put.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestPut.java</file>
		</fixedFiles>
	</bug>
	<bug id="1635" opendate="2009-07-09 17:48:41" fixdate="2009-07-09 17:56:07" resolution="Fixed">
		<buginformation>
			<summary>PerformanceEvaluation should use scanner prefetching</summary>
			<description>Right now default scanner prefetching is set to 1.  In PerformanceEvaluation, this leads to basically benchmarking RPC round-trip performance.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
		</fixedFiles>
	</bug>
	<bug id="1629" opendate="2009-07-08 20:23:57" fixdate="2009-07-09 23:05:08" resolution="Fixed">
		<buginformation>
			<summary>HRS unable to contact master</summary>
			<description>HRS unable to contact master for initialization after expiration from ZK. Master thinks HRS is still up whereas HRS went down and now cannot restart. The RS logs have a flurry of the following warning messages:
2009-07-08 12:53:19,547 WARN org.apache.hadoop.hbase.regionserver.HRegionServer: Unable to get master for initialization
More logs from the RS and the Master attached.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">1601</link>
		</links>
	</bug>
	<bug id="1627" opendate="2009-07-08 11:43:32" fixdate="2009-07-10 19:07:55" resolution="Fixed">
		<buginformation>
			<summary>TableInputFormatBase#nextKeyValue catches the wrong exception</summary>
			<description>TableInputFormatBase#nextKeyValue only catches UnknownScannerException from Scanner.next. However, scanner may throw other exceptions:


/* from HTable.ClientScanner#next */
          try {
            values = getConnection().getRegionServerWithRetries(callable);
          } catch (IOException e) {
            if (e instanceof UnknownScannerException &amp;amp;&amp;amp;
                lastNext + scannerTimeout &amp;lt; System.currentTimeMillis()) {
              ScannerTimeoutException ex = new ScannerTimeoutException();
              ex.initCause(e);
              throw ex;
            }
            throw e;
          }



Is there any reason why TIFB does not catch ScannerTimeoutException?</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.java</file>
		</fixedFiles>
	</bug>
	<bug id="1644" opendate="2009-07-10 21:26:02" fixdate="2009-07-10 21:34:36" resolution="Fixed">
		<buginformation>
			<summary>Result.row is cached in getRow; this breaks MapReduce</summary>
			<description>In Result#getRow row field is computed (if row is null) and then is cached for further uses. But since MapReduce uses the same Result instance through different map()/reduce() calls, row field is not updated when Result instance changes.</description>
			<version>0.20.0</version>
			<fixedVersion>0.95.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.Result.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.java</file>
		</fixedFiles>
	</bug>
	<bug id="1646" opendate="2009-07-11 11:26:21" fixdate="2009-07-12 23:22:52" resolution="Fixed">
		<buginformation>
			<summary>Scan-s can&amp;apos;t set a Filter</summary>
			<description>Scan#write:


      HbaseObjectWritable.writeObject(out, this.filter, Filter.class, null);


Because of the third argument (Filter.class), HbaseObjectWritable can not write or read the filter (as Filter is not instantiable).</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.Scan.java</file>
			<file type="M">org.apache.hadoop.hbase.TestSerialization.java</file>
		</fixedFiles>
		<links>
			<link type="Cloners" description="is cloned by">1957</link>
		</links>
	</bug>
	<bug id="1649" opendate="2009-07-12 22:36:11" fixdate="2009-07-13 18:10:29" resolution="Fixed">
		<buginformation>
			<summary>ValueFilter may not reset its internal state</summary>
			<description>ValueFilter#reset is empty even though the class uses two internal variables. These values are reset in filterRow, however there are instances where filterRow may not be called. For example, if you chain two filters through FilterList (with PASS_ALL and the second filter being a ValueFilter) then during FilterList#filterRow if the first filter#filterRow returns true then ValueFilter#filterRow will not be called.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.filter.ValueFilter.java</file>
		</fixedFiles>
	</bug>
	<bug id="698" opendate="2008-06-19 00:36:10" fixdate="2009-07-14 16:49:11" resolution="Fixed">
		<buginformation>
			<summary>HLog recovery is not performed after master failure</summary>
			<description>I have a local cluster running, and its logging to
&amp;lt;hbase&amp;gt;/log_X.X.X.X_1213228101021_60020/
Then I kill both master and regionserver, and restart. Looking through
the logs I don&amp;amp;apos;t see anything about trying to recover from this hlog,
it just creates a new hlog alongside the existing one (with a new
startcode).  The older hlog seems to be ignored, and the tables
created in the inital session are all gone.</description>
			<version>0.1.2</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.BaseScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
		</fixedFiles>
		<links>
			<link type="Blocker" description="is blocked by">728</link>
			<link type="Blocker" description="is blocked by">546</link>
			<link type="Blocker" description="is blocked by">1302</link>
		</links>
	</bug>
	<bug id="1651" opendate="2009-07-14 01:41:06" fixdate="2009-07-14 18:10:05" resolution="Fixed">
		<buginformation>
			<summary>client is broken, it requests ROOT region location from ZK too much</summary>
			<description>something bad happened to the client, now it requests the ROOT region location literally a hundred times a second:
09/07/13 18:39:59 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:00 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020
09/07/13 18:40:01 DEBUG zookeeper.ZooKeeperWrapper: Read ZNode /hbase/root-region-server got 10.20.20.158:60020</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ServerConnectionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
		</fixedFiles>
	</bug>
	<bug id="1659" opendate="2009-07-15 00:34:52" fixdate="2009-07-15 00:49:14" resolution="Fixed">
		<buginformation>
			<summary>merge tool doesnt take binary regions with \x escape format</summary>
			<description>as per short</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestStoreScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.util.Merge.java</file>
		</fixedFiles>
	</bug>
	<bug id="1661" opendate="2009-07-15 14:19:12" fixdate="2009-07-15 14:28:19" resolution="Fixed">
		<buginformation>
			<summary>HBASE-1215 partial commit broke trunk, does not compile</summary>
			<description>
compile-core:
    [javac] Compiling 309 source files to /home/hbase20/src/hbase-0.20.0-trunk/build/classes
    [javac] /home/hbase20/src/hbase-0.20.0-trunk/src/java/org/apache/hadoop/hbase/util/FSUtils.java:300: missing return statement
    [javac]   }
    [javac]   ^
    [javac] /home/hbase20/src/hbase-0.20.0-trunk/src/java/org/apache/hadoop/hbase/util/Migrate.java:220: cannot find symbol
    [javac] symbol  : method allMajorCompacted()
    [javac] location: class org.apache.hadoop.hbase.util.Migrate
    [javac]     if (!allMajorCompacted()) {
    [javac]          ^
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
    [javac] 2 errors

</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.Migrate.java</file>
			<file type="M">org.apache.hadoop.hbase.util.FSUtils.java</file>
		</fixedFiles>
	</bug>
	<bug id="1702" opendate="2009-07-24 16:58:46" fixdate="2009-07-25 16:00:11" resolution="Fixed">
		<buginformation>
			<summary>TestMergeUtil fails on trunk</summary>
			<description>Last hudson reports a failed test on TestMergeUtil.  Same failure when run locally.

junit.framework.AssertionFailedError: &amp;amp;apos;merging regions 0 and 1&amp;amp;apos; failed
	at org.apache.hadoop.hbase.util.TestMergeTool.mergeAndVerify(TestMergeTool.java:178)
	at org.apache.hadoop.hbase.util.TestMergeTool.testMergeTool(TestMergeTool.java:253)

</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.MetaUtils.java</file>
		</fixedFiles>
	</bug>
	<bug id="1686" opendate="2009-07-23 00:39:27" fixdate="2009-07-27 17:22:03" resolution="Fixed">
		<buginformation>
			<summary>major compaction can create empty store files, causing AIOOB when trying to read</summary>
			<description>here is the backtrace:
Caused by: java.lang.ArrayIndexOutOfBoundsException: 0
        at org.apache.hadoop.hbase.io.hfile.HFile$Reader.getFirstKey(HFile.java:991)
        at org.apache.hadoop.hbase.regionserver.StoreFileGetScan.getStoreFile(StoreFileGetScan.java:84)
        at org.apache.hadoop.hbase.regionserver.StoreFileGetScan.get(StoreFileGetScan.java:65)
        at org.apache.hadoop.hbase.regionserver.Store.get(Store.java:1548)
        at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:2263)
        at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:2252)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.get(HRegionServer.java:1739)
This can happen if your table only has deletes, and everything evaporates during a major compaction.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.KeyValue.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFileGetScan.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.TestHFile.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestStore.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFile.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
		</fixedFiles>
	</bug>
	<bug id="1714" opendate="2009-07-27 22:30:20" fixdate="2009-07-27 23:48:34" resolution="Fixed">
		<buginformation>
			<summary>convenience functions in Scan and the thrift API along with a few other bug fixes</summary>
			<description>a number of handy things i&amp;amp;apos;ve added to my own repo recently</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.thrift.generated.TRowResult.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.TestThriftServer.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.generated.IOError.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.generated.IllegalArgument.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.generated.Hbase.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.DeleteCompare.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.TableInputFormatBase.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.generated.Mutation.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.generated.BatchMutation.java</file>
			<file type="M">org.apache.hadoop.hbase.client.Delete.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.generated.TCell.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.generated.ColumnDescriptor.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.generated.TRegionInfo.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.generated.AlreadyExists.java</file>
		</fixedFiles>
	</bug>
	<bug id="1703" opendate="2009-07-24 20:43:55" fixdate="2009-07-28 08:51:31" resolution="Fixed">
		<buginformation>
			<summary>ICVs across /during a flush can cause multiple keys with the same TS (bad)</summary>
			<description>We noticed a bug whereby the value in a hbase ICV&amp;amp;apos;ed counter was lower, and the bug turned out to be that during a flush, the ICV will grab the KeyValue from &amp;amp;apos;memcache&amp;amp;apos; and reuse the timestamp... if we grab the KeyValue from the snapshot we end up with 2 key values, one in memcache, one in a hfile, both with the same timestamp, but one with a lower value than the other.
The fix is to not reuse timestamps if they come out of the snapshot.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestStore.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MemStore.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.QueryMatcher.java</file>
		</fixedFiles>
	</bug>
	<bug id="1717" opendate="2009-07-28 19:36:38" fixdate="2009-07-28 20:12:17" resolution="Fixed">
		<buginformation>
			<summary>Put on client-side uses passed-in byte[]s rather than always using copies</summary>
			<description>During review of Put with ryan, found that we are using a passed in reference to family in add() rather than a local copy.  If the backing array changed values, this could cause trouble.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.Put.java</file>
		</fixedFiles>
	</bug>
	<bug id="1647" opendate="2009-07-11 12:04:10" fixdate="2009-07-28 20:29:34" resolution="Fixed">
		<buginformation>
			<summary>Filter#filterRow is called too often, filters rows it shouldn&amp;apos;t have</summary>
			<description>Filter#filterRow is called from ScanQueryMatcher#filterEntireRow which is called from StoreScanner.next. However, if I understood the code correctly, StoreScanner processes KeyValue-s in a column-oriented order (i.e. after row1-col1 comes row2-col1, not row1-col2). Thus, when filterEntireRow is called, in reality, the filter only processed (via filterKeyValue) only one column of a row.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestStoreScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.ScanQueryMatcher.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.QueryMatcher.java</file>
		</fixedFiles>
	</bug>
	<bug id="1718" opendate="2009-07-28 23:46:10" fixdate="2009-07-29 00:59:53" resolution="Fixed">
		<buginformation>
			<summary>Reuse of KeyValue during log replay could cause the wrong data to be used</summary>
			<description>Our meta table got a row key of METAROW in it.  Hard to explain how it happened, but under code inspection stack found that we are reusing the same KV instance for each replayed key.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
		</fixedFiles>
	</bug>
	<bug id="1604" opendate="2009-07-02 12:02:21" fixdate="2009-08-02 23:30:41" resolution="Fixed">
		<buginformation>
			<summary>HBaseClient.getConnection() may return a broken connection without throwing an exception</summary>
			<description>Consider the code of HBaseClient.getConnection():


    connection.setupIOstreams();
    return connection;
  }


Now consider the setupIOstreams() method:


      } catch (IOException e) {
        markClosed(e);
        close(); // Removes the connection from pool
      }


So, if something goes wrong inside of setupIOstreams, then after its invocation the connection will be broken (will have its .in and .out streams nulls, for example) and will not be in pool, but will still be returned from the getConnection method and cause further harm (for example, cause a NullPointerException in further calls such as sendCall, which use the in and out streams).
Suggested fix: make the setupIOstreams method rethrow the IOException inside that catch block.
Reproduction: Restart the hbase master and/or regionserver while a client program is running, and put a breakpoint into that catch block.
I actually observed a situation where the broken connection stayed in the pool, but I don&amp;amp;apos;t yet know how to reproduce it or what is the reason. I am investigating the issue, but for now at least the aforementioned bug should be fixed.</description>
			<version>0.19.2</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.HBaseClient.java</file>
		</fixedFiles>
	</bug>
	<bug id="1738" opendate="2009-08-03 23:15:40" fixdate="2009-08-17 22:22:04" resolution="Fixed">
		<buginformation>
			<summary>Scanner doesnt reset when a snapshot is created, could miss new updates into the &amp;apos;kvset&amp;apos; (active part)</summary>
			<description>when a Scanner is created, it creates 2 MemStoreScanners on the kvset and the snapshot (internal names of Memstore)... if the snapshot is originally empty, it only creates the 1, for kvset.  When the snapshot is created, the outstanding Scanners now have a pointer to the tree that is now the snapshot, but no pointer to the kvset.
When the flush completes, the scanner will reset the memstore scanners and &amp;amp;apos;see&amp;amp;apos; the new values again.
If there is a large delay between snapshot and finalization of the flush, there can be a large period of time a scanner doesnt see &amp;amp;apos;new&amp;amp;apos; values that are being inserted. the canonical &amp;amp;apos;bad&amp;amp;apos; case where this can do things is the META scanner, and we end up with double assignment.
The snapshot is really lightweight, it only takes out a small lock in memstore, so im not sure there is an easy mechanism to hook to without building out a bit more code or restructuring the memstore scanner.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.TestHeapSize.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MemStore.java</file>
			<file type="M">org.apache.hadoop.hbase.util.ClassSize.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestMemStore.java</file>
		</fixedFiles>
	</bug>
	<bug id="1791" opendate="2009-08-25 16:27:57" fixdate="2009-08-25 18:33:27" resolution="Fixed">
		<buginformation>
			<summary>Timeout in IndexRecordWriter</summary>
			<description>A MapReduce job to generate Lucene Indexes from HBase will fail on sufficiently large tables. After the indexing finished, the close() method of IndexRecordWriter is called.  The  writer.optimize() call in this method can take many minutes, forcing most MapReduce tasks to timeout. There is a HeartBeatsThread, but it does not seem to send progress updates. 
A suggested fix may be to add context.progress(); in the HeardbeatsThread run() method, after the context.setStatus call. Not sure why context.setStatus is not "good enough". </description>
			<version>0.20.0</version>
			<fixedVersion>0.20.1, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.IndexRecordWriter.java</file>
		</fixedFiles>
	</bug>
	<bug id="1737" opendate="2009-08-03 21:10:15" fixdate="2009-08-25 23:18:28" resolution="Fixed">
		<buginformation>
			<summary>Regions unbalanced when adding new node</summary>
			<description>When adding a new RegionServer to a cluster, the new RS will receive some regions but not enough to actually be considered balanced.
To recreate, just take an RS offline, allow regions to be reassigned, and then bring it back up.
Master will get itself into a broken, stuck state where it continuously outputs a line like this:

2009-08-03 12:54:57,812 DEBUG org.apache.hadoop.hbase.master.RegionManager: Server dn4,60020,1249329081079 will be unloaded for balance. Server load: 341 avg: 318.0, regions can be moved: 55


This line is output every 3 seconds and never stops until another RS joins/leaves the cluster.
Making this a blocker because when your new RS only gets some regions (in my case, about half as many as it should have), then all new regions will be assigned to that RS.  This basically destroys any possibility for good load distribution with new data.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.RegionManager.java</file>
		</fixedFiles>
	</bug>
	<bug id="1793" opendate="2009-08-25 19:37:10" fixdate="2009-08-26 00:05:08" resolution="Fixed">
		<buginformation>
			<summary>[Regression] HTable.get/getRow with a ts is broken</summary>
			<description>If using the old API with 0.20, the behavior of get and getRow is changed when setting a timestamp. Previously, setting a ts was working like a time range and now it works like an exact time.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
		</fixedFiles>
	</bug>
	<bug id="1792" opendate="2009-08-25 18:32:19" fixdate="2009-08-26 00:05:57" resolution="Fixed">
		<buginformation>
			<summary>[Regression] Cannot save timestamp in the future</summary>
			<description>0.20, compared to previous versions, doesn&amp;amp;apos;t let you save with a timestamp in the future and will set it to current time without telling you. This is really bad for users upgrading to 0.20 that were using those timestamps.
Example:
 hbase(main):004:0&amp;gt; put &amp;amp;apos;testtable&amp;amp;apos;, &amp;amp;apos;r1&amp;amp;apos;, &amp;amp;apos;f1:c1&amp;amp;apos;, &amp;amp;apos;val&amp;amp;apos;, 5373965335336911168
 0 row(s) in 0.0070 seconds
 hbase(main):005:0&amp;gt; scan &amp;amp;apos;testtable&amp;amp;apos;
 ROW                          COLUMN+CELL                                                                      
  r1                          column=f1:c1, timestamp=1251223892010, value=val                                 
 1 row(s) in 0.0380 seconds</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
		</fixedFiles>
	</bug>
	<bug id="1798" opendate="2009-08-26 18:20:48" fixdate="2009-08-27 00:58:09" resolution="Fixed">
		<buginformation>
			<summary>[Regression] Unable to delete a row in the future</summary>
			<description>Deleting in the future doesn&amp;amp;apos;t work because KV resets everything to now.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.KeyValue.java</file>
		</fixedFiles>
	</bug>
	<bug id="1784" opendate="2009-08-21 19:52:02" fixdate="2009-09-01 19:56:20" resolution="Fixed">
		<buginformation>
			<summary>Missing rows after medium intensity insert</summary>
			<description>This bug was uncovered by Mathias in his mail "Issue on data load with 0.20.0-rc2". Basically, somehow, after a medium intensity insert a lot of rows goes missing. Easy way to reproduce : PE. Doing a PE scan or randomRead afterwards won&amp;amp;apos;t uncover anything since it doesn&amp;amp;apos;t bother about null rows. Simply do a count in the shell, easy to test (I changed my scanner caching in the shell to do it faster).
I tested some light insertions with force flush/compact/split in the shell and it doesn&amp;amp;apos;t break.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFile.java</file>
			<file type="M">org.apache.hadoop.hbase.master.BaseScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ServerManager.java</file>
		</fixedFiles>
	</bug>
	<bug id="1810" opendate="2009-09-02 10:39:54" fixdate="2009-09-02 16:40:26" resolution="Fixed">
		<buginformation>
			<summary>ConcurrentModificationException in region assignment</summary>
			<description>

2009-09-01 11:28:24,106 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 16 on 60000, call regionServerReport(address: 192.168.105.39:60020, startcode: 1251828463043, load: (requests=0, regions=21, usedHeap=135, maxHeap=4093), [Lorg.apache.hadoop.hbase.HMsg;@6556c280, [Lorg.apache.hadoop.hbase.HRegionInfo;@22fb957a) from 192.168.105.39:60281: error: java.io.IOException: java.util.ConcurrentModificationException
java.io.IOException: java.util.ConcurrentModificationException
        at java.util.TreeMap$PrivateEntryIterator.nextEntry(TreeMap.java:1100)
        at java.util.TreeMap$ValueIterator.next(TreeMap.java:1145)
        at org.apache.hadoop.hbase.master.RegionManager.isMetaServer(RegionManager.java:837)
        at org.apache.hadoop.hbase.master.RegionManager.regionsAwaitingAssignment(RegionManager.java:405)
        at org.apache.hadoop.hbase.master.RegionManager.assignRegions(RegionManager.java:202)
        at org.apache.hadoop.hbase.master.ServerManager.processMsgs(ServerManager.java:481)
        at org.apache.hadoop.hbase.master.ServerManager.processRegionServerAllsWell(ServerManager.java:415)
        at org.apache.hadoop.hbase.master.ServerManager.regionServerReport(ServerManager.java:324)
        at org.apache.hadoop.hbase.master.HMaster.regionServerReport(HMaster.java:722)
        at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:650)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:915)


and 


2009-09-01 11:28:25,713 INFO org.apache.hadoop.ipc.HBaseServer: IPC Server handler 23 on 60000, call regionServerReport(address: 192.168.105.37:60020, startcode: 1251828463132, load: (requests=0, regions=14, usedHeap=141, maxHeap=4093), [Lorg.apache.hadoop.hbase.HMsg;@68345260, [Lorg.apache.hadoop.hbase.HRegionInfo;@430c5212) from 192.168.105.37:35432: error: java.io.IOException: java.util.ConcurrentModificationException
java.io.IOException: java.util.ConcurrentModificationException
        at java.util.TreeMap$PrivateEntryIterator.nextEntry(TreeMap.java:1100)
        at java.util.TreeMap$ValueIterator.next(TreeMap.java:1145)
        at org.apache.hadoop.hbase.master.RegionManager.regionsAwaitingAssignment(RegionManager.java:428)
        at org.apache.hadoop.hbase.master.RegionManager.assignRegions(RegionManager.java:202)
        at org.apache.hadoop.hbase.master.ServerManager.processMsgs(ServerManager.java:481)
        at org.apache.hadoop.hbase.master.ServerManager.processRegionServerAllsWell(ServerManager.java:415)
        at org.apache.hadoop.hbase.master.ServerManager.regionServerReport(ServerManager.java:324)
        at org.apache.hadoop.hbase.master.HMaster.regionServerReport(HMaster.java:722)
        at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:650)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:915)


As discussed with Mathias on IRC:
&amp;lt;hbs&amp;gt; regionsInTransition is a synchronized map so accesses to it are synchronized but not looping over it
&amp;lt;hbs&amp;gt; as stated in http://java.sun.com/j2se/1.5.0/docs/api/java/util/Collections.html#synchronizedMap%28java.util.Map%29
&amp;lt;hbs&amp;gt; so there is a missing synchronized(regionsInTransition) wherever regionsInTransition is iterated over.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.RegionManager.java</file>
		</fixedFiles>
	</bug>
	<bug id="1804" opendate="2009-08-31 19:52:15" fixdate="2009-09-02 18:58:51" resolution="Fixed">
		<buginformation>
			<summary>Puts are permitted (and stored) when including an appended colon</summary>
			<description>If I have a table with family "testFamily", currently I can do Puts using the new API by specifying the family name with or without a colon.  The KV is then stored w/ or w/o depending on how the Put was done.
If you try to Put.add("testFamily:", "qualifier", "value") this should throw a NoSuchColumnFamilyException</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.KeyValue.java</file>
			<file type="M">org.apache.hadoop.hbase.HTableDescriptor.java</file>
		</fixedFiles>
	</bug>
	<bug id="1790" opendate="2009-08-24 07:24:32" fixdate="2009-09-02 23:24:23" resolution="Fixed">
		<buginformation>
			<summary>filters are not working correctly</summary>
			<description>Filters used in Scanning the table are not working correctly. For example a table with three rows:
1. rowkey = adminbackslash-nb0, desc:temp = "temp"
2. rowkey = adminbackslash-nb1, desc:temp = "temp"
3. rowkey = adminkleptoman, desc:temp = "temp"
If I scan all rows in the table without filter I get all the rows as expected. But applying a simple prefixfilter with parameter "adminbackslash" will return only first row. I searched it down to HRegion::nextInternal method, which will not output one passed row before denied row(by filter). </description>
			<version>0.20.0</version>
			<fixedVersion>0.20.0, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.filter.PrefixFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.TestInclusiveStopFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.PageFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.ValueFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.TestValueFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.RegexStringComparator.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.InclusiveStopFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.io.HbaseObjectWritable.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.TestFilterList.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.TestPageFilter.java</file>
		</fixedFiles>
		<links>
			<link type="Incorporates" description="incorporates">1353</link>
			<link type="Incorporates" description="incorporates">1710</link>
			<link type="Incorporates" description="incorporates">1807</link>
		</links>
	</bug>
	<bug id="1779" opendate="2009-08-19 09:36:35" fixdate="2009-09-04 05:02:17" resolution="Fixed">
		<buginformation>
			<summary>ThriftServer logged error if getVer() result is empty</summary>
			<description>Null pointer exception is logged by thrift server process if a client calls getVer() through thrift server and its result is empty.
The easiest fix is to check if result is empty or not.
09/08/18 15:58:30 ERROR server.TThreadPoolServer: Error occurred during processing of message.
java.lang.NullPointerException
        at org.apache.hadoop.hbase.thrift.ThriftServer$HBaseHandler.getVer(ThriftServer.java:281)
        at org.apache.hadoop.hbase.thrift.ThriftServer$HBaseHandler.getVer(ThriftServer.java:269)
        at org.apache.hadoop.hbase.thrift.generated.Hbase$Processor$getVer.process(Hbase.java:2096)
        at org.apache.hadoop.hbase.thrift.generated.Hbase$Processor.process(Hbase.java:1859)
        at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:252)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
		</fixedFiles>
	</bug>
	<bug id="1795" opendate="2009-08-26 01:02:32" fixdate="2009-09-11 19:53:39" resolution="Fixed">
		<buginformation>
			<summary>log recovery doesnt reset the max sequence id, new logfiles can get tossed as &amp;apos;duplicates&amp;apos;</summary>
			<description>during log recovery, we dont reset Store.maxSeqId, thus new log entries are stamped starting off from the old files.  This can cause a problem if we fail and recover again, since the new mutations are deemed "old" and shouldnt be applied in a subsequent recovery scenario.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.1, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
		</fixedFiles>
	</bug>
	<bug id="1794" opendate="2009-08-25 23:36:26" fixdate="2009-09-11 19:54:04" resolution="Fixed">
		<buginformation>
			<summary>recovered log files are not inserted into the storefile map</summary>
			<description>after a log recovery, the resulting flushed file is not introduced into the store.storefiles map. The new data isnt available until the region is closed or compacted.
</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.1, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
		</fixedFiles>
	</bug>
	<bug id="1740" opendate="2009-08-04 00:00:29" fixdate="2009-09-11 21:46:31" resolution="Fixed">
		<buginformation>
			<summary>ICV has a subtle race condition only visible under high load</summary>
			<description>ICV demonstrates a race condition under high load.  The result is a duplicate KeyValue with the same timestamp, at first in the memcache, and in hfile, then both in hfile.  The get/scan code doesnt know which one to read, and picks one arbitrarily.  One of the keyvalues is correct, one is incorrect.
What happens at a deeper level:

we start an ICV
a snapshot happens and moves the memstore to the snapshot
the ICV code puts a key-value into memstore that has the same timestamp as a keyvalue in the snapshot.

This is a deep race condition and several attempts to fix it failed in production here at SU.  This issue is about a more permanent fix.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestStore.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MemStore.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
		</fixedFiles>
	</bug>
	<bug id="1828" opendate="2009-09-11 03:10:23" fixdate="2009-09-12 01:02:39" resolution="Fixed">
		<buginformation>
			<summary>CompareFilters are broken from client-side</summary>
			<description>Some filters pass region-level tests but seem to freeze client-side.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.1, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.TestClient.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.CompareFilter.java</file>
		</fixedFiles>
	</bug>
	<bug id="1840" opendate="2009-09-15 19:29:23" fixdate="2009-09-15 20:23:27" resolution="Fixed">
		<buginformation>
			<summary>RowLock fails when used with IndexTable</summary>
			<description>The following exception is thrown when using RowLock to update a row in an IndexedTable:
 [junit] java.io.IOException: java.io.IOException: Invalid row lock
[junit] at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1640)
[junit] at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:1244)
[junit] at org.apache.hadoop.hbase.regionserver.tableindexed.IndexedRegion.put(IndexedRegion.java:97)
[junit] at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:1216)
[junit] at org.apache.hadoop.hbase.regionserver.HRegionServer.put(HRegionServer.java:1818)
[junit] at sun.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)
[junit] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
[junit] at java.lang.reflect.Method.invoke(Method.java:597)
[junit] at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:650)
[junit] at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:915)
NOTE #1: Line numbers in stacktrace may not make sense because I&amp;amp;apos;ve been hacking in loads of debug info. 
NOTE #2: I attaching a fix which includes unit tests</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.1, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.tableindexed.TestIndexedTable.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.tableindexed.IndexedRegion.java</file>
		</fixedFiles>
	</bug>
	<bug id="1574" opendate="2009-06-23 18:51:37" fixdate="2009-09-15 20:30:26" resolution="Fixed">
		<buginformation>
			<summary>Client and server APIs to do batch deletes.</summary>
			<description>in 880 there is no way to do a batch delete (anymore?).  We should add one back in.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.1, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.HRegionInterface.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestClient.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HConnection.java</file>
			<file type="M">org.apache.hadoop.hbase.client.Delete.java</file>
			<file type="M">org.apache.hadoop.hbase.io.HbaseObjectWritable.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.client.Put.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
		</fixedFiles>
	</bug>
	<bug id="1847" opendate="2009-09-17 00:44:04" fixdate="2009-09-17 21:17:18" resolution="Fixed">
		<buginformation>
			<summary>Delete latest of a null qualifier when non-null qualifiers exist throws a RuntimeException</summary>
			<description>Bug in delete latest code when deleting the null qualifier column when other columns also exist.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.1, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.TestClient.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
		</fixedFiles>
	</bug>
	<bug id="1815" opendate="2009-09-03 22:25:49" fixdate="2009-09-22 16:34:45" resolution="Fixed">
		<buginformation>
			<summary>HBaseClient can get stuck in an infinite loop while attempting to contact a failed regionserver</summary>
			<description>While using HBase Thrift server, if a regionserver goes down due to shutdown or failure clients will timeout because the thrift server cannot contact the dead regionserver.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.client.RetriesExhaustedException.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.HBaseClient.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.HBaseRPC.java</file>
		</fixedFiles>
	</bug>
	<bug id="1856" opendate="2009-09-22 08:31:34" fixdate="2009-09-22 18:49:02" resolution="Fixed">
		<buginformation>
			<summary>HBASE-1765 broke MapReduce when using Result.list()</summary>
			<description>Not sure if it is just me, but using MR over HBase employing a TableReducer is not working. After the first row is read all subsequent rows get the same Result&amp;amp;apos;s of that very first row. After tracing this from the Map phase I found the culprit in Result and the HBASE-1765 delayed field parsing change.
This is the code I use in the reduce():


   @Override
    protected void reduce(ImmutableBytesWritable key, Iterable&amp;lt;Result&amp;gt; values,
        Context context) throws IOException, InterruptedException {
      String skey = Bytes.toString(key.get());
      context.getCounter(CountersTotals.ROWS).increment(1);
      for (Result result : values) {
        for (KeyValue kv: result.list()) {
          try {
            if (LOG.isDebugEnabled()) LOG.debug("reduce: key -&amp;gt; " + skey + ", kv -&amp;gt; " + kv);
            ...


Here is the current list() implementation:


  public List&amp;lt;KeyValue&amp;gt; list() {
    if(this.kvs == null) {
      readFields();
    }
    return isEmpty()? null: Arrays.asList(sorted());
  }


The problem is that readFields(DataInput) does not clear kvs!


  public void readFields(final DataInput in)
  throws IOException {
    familyMap = null;
    row = null;
    int totalBuffer = in.readInt();
    if(totalBuffer == 0) {
      bytes = null;
      return;
    }
    byte [] raw = new byte[totalBuffer];
    in.readFully(raw, 0, totalBuffer);
    bytes = new ImmutableBytesWritable(raw, 0, totalBuffer);
  }


The above is called by the MR framework&amp;amp;apos;s WritableSerialization for each map output. But since "kvs" is already set "list()" returns the old data!
I assume the only change needed is clearing kvs as well:


  public void readFields(final DataInput in)
  throws IOException {
    familyMap = null;
    row = null;
    kvs = null;
    ....


I&amp;amp;apos;ll test that now and report.</description>
			<version>0.20.1</version>
			<fixedVersion>0.20.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.Result.java</file>
		</fixedFiles>
	</bug>
	<bug id="1857" opendate="2009-09-22 16:25:43" fixdate="2009-09-22 19:23:17" resolution="Fixed">
		<buginformation>
			<summary>WrongRegionException when setting region online after .META. split</summary>
			<description>After splitting .META. when updating region information in .META. (e.g. ProcessRegionOpen) the wrong .META. region was retrieved in RegionManager from onlineMetaRegions map. 
This is due to a bug in RegionManager.getFirstMetaRegionForRegion that was using the wrong key to get data out of the map (the table name instead of the region name) 
return onlineMetaRegions.get(onlineMetaRegions.headMap(newRegion.getTableDesc().getName()).lastKey());
and when adding the region to the map it was added with 
onlineMetaRegions.put(metaRegion.getStartKey(), metaRegion);
so it&amp;amp;apos;s supposed to be taken out with: 
return onlineMetaRegions.get(onlineMetaRegions.headMap(newRegion.getRegionName()).lastKey());</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.RegionManager.java</file>
		</fixedFiles>
	</bug>
	<bug id="1865" opendate="2009-09-24 21:02:25" fixdate="2009-09-24 23:06:26" resolution="Fixed">
		<buginformation>
			<summary>0.20.0 TableInputFormatBase NPE</summary>
			<description>Spot the bug in this code:
public List&amp;lt;InputSplit&amp;gt; getSplits(JobContext context) throws IOException {
    byte [][] startKeys = table.getStartKeys();
    if (startKeys == null || startKeys.length == 0) 
{
      throw new IOException("Expecting at least one region.");
    }
    if (table == null) 
{
      throw new IOException("No table was provided.");
    }
...
}
Should check if the table is null before calling a method on it.
Admittedly, this isn&amp;amp;apos;t the worst bug in the world, it&amp;amp;apos;s really just more of a nuisance in that the "No table was provided" message becomes an NPE
This bug is in both
org.apache.hadoop.hbase.mapred.TableInputFormatBase
org.apache.hadoop.hbase.mapreduce.TableInputFormatBase</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.1, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.java</file>
		</fixedFiles>
	</bug>
	<bug id="1866" opendate="2009-09-24 22:49:49" fixdate="2009-09-24 23:20:52" resolution="Fixed">
		<buginformation>
			<summary>Scan(Scan) copy constructor does not copy value of cacheBlocks</summary>
			<description></description>
			<version>0.20.0</version>
			<fixedVersion>0.20.1, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.Scan.java</file>
		</fixedFiles>
	</bug>
	<bug id="1869" opendate="2009-09-25 19:46:24" fixdate="2009-09-25 23:22:21" resolution="Fixed">
		<buginformation>
			<summary>IndexedTable delete fails when used in conjunction with RowLock()</summary>
			<description>Created the following test in TestIndexedTable,
  public void testLockedRowDelete() throws IOException 
{
    writeInitalRows();
    // Delete the first row;
    byte[] row = PerformanceEvaluation.format(0);
    RowLock lock = table.lockRow(row);
    table.delete(new Delete(row, HConstants.LATEST_TIMESTAMP, lock));
    table.unlockRow(lock);    

    assertRowDeleted(NUM_ROWS - 1);  
  }
}
which fails and throws the following exception,
java.io.IOException: java.io.IOException: Invalid row lock
	at org.apache.hadoop.hbase.regionserver.HRegion.getLock(HRegion.java:1621)
	at org.apache.hadoop.hbase.regionserver.HRegion.delete(HRegion.java:1094)
	at org.apache.hadoop.hbase.regionserver.tableindexed.IndexedRegion.delete(IndexedRegion.java:269)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.delete(HRegionServer.java:2014)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:648)
	at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:915)
Patch coded for the latest version in SVN (looks like 0.21.0) , just going through final testing and packaging. Will attach shortly.</description>
			<version>0.20.0</version>
			<fixedVersion>0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.tableindexed.TestIndexedTable.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.tableindexed.IndexedRegion.java</file>
		</fixedFiles>
	</bug>
	<bug id="1871" opendate="2009-09-26 20:23:19" fixdate="2009-09-26 21:23:34" resolution="Fixed">
		<buginformation>
			<summary>Wrong type used in TableMapReduceUtil.initTableReduceJob()</summary>
			<description>Since we changed it so that TableOutputFormat can handle Put and Delete it is necessary to set the output value class to Writable.


  public static void initTableReducerJob(String table,
    Class&amp;lt;? extends TableReducer&amp;gt; reducer, Job job, Class partitioner)
  throws IOException {
    job.setOutputFormatClass(TableOutputFormat.class);
    if (reducer != null) job.setReducerClass(reducer);
    job.getConfiguration().set(TableOutputFormat.OUTPUT_TABLE, table);
    job.setOutputKeyClass(ImmutableBytesWritable.class);
    job.setOutputValueClass(Put.class);
   ....


The last line should be 


    job.setOutputValueClass(Writable.class);

</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.1, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
		</fixedFiles>
	</bug>
	<bug id="1883" opendate="2009-10-02 22:14:10" fixdate="2009-10-03 05:07:56" resolution="Fixed">
		<buginformation>
			<summary>HRegion passes the wrong minSequenceNumber to doReconstructionLog</summary>
			<description>HRegion initializes by opens up all store files which may recover from the WAL. It then calls protected doReconstructionLog which THBase uses to go through the log and look for pending transactions that may need to be recovered. Currently HRegion is passing down the minSequenceNumber after WAL recovery. What we want is the lowest sequence number before the wal recovery.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.1, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
		</fixedFiles>
	</bug>
	<bug id="1879" opendate="2009-10-01 21:03:17" fixdate="2009-10-03 05:17:31" resolution="Fixed">
		<buginformation>
			<summary>ReadOnly transactions generate WAL activity.</summary>
			<description>Currently we write a start entry in the WAL each time a transaction starts, and a commit/abort at the end of the transaction. This means read-only transactions unnecessarily generate two WAL entries per region.
Can avoid this by removing the start entry from the WAL (this is implicit in the first trx OP entry we see), and only writing commit/abort when the transaction has a write.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.1, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.transactional.TestTHLog.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.transactional.THLog.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.transactional.THLogRecoveryManager.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.transactional.THLogKey.java</file>
		</fixedFiles>
	</bug>
	<bug id="1831" opendate="2009-09-12 01:06:29" fixdate="2009-10-06 03:26:26" resolution="Fixed">
		<buginformation>
			<summary>Scanning API must be reworked to allow for fully functional Filters client-side</summary>
			<description>Right now, a client replays part of the Filter locally by calling filterRowKey() and filterAllRemaining() to determine whether it should continue to the next region.
A number of new filters rely on filterKeyValue() and other calls to alter state.  It&amp;amp;apos;s also a false assumption that all rows/keys affecting a filter returning true for FAR will be seen client-side (what about those that failed the filter).
This issue is about dealing with Filters properly from the client-side.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.1, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.HRegionInterface.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestClient.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.BinaryComparator.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.package-info.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ScannerCallable.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
		</fixedFiles>
	</bug>
	<bug id="1896" opendate="2009-10-09 03:40:43" fixdate="2009-10-15 06:48:47" resolution="Fixed">
		<buginformation>
			<summary>WhileMatchFilter.reset should call encapsulated filter reset  </summary>
			<description>Bumped into this when trying to encapsulate a SingleValueColumnFilter in a WhileMatchFilter. 
A scanner would grab all the rows after the first matched row in the table </description>
			<version>0.20.1</version>
			<fixedVersion>0.20.2, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.filter.WhileMatchFilter.java</file>
		</fixedFiles>
	</bug>
	<bug id="1912" opendate="2009-10-16 10:08:13" fixdate="2009-10-18 16:30:46" resolution="Fixed">
		<buginformation>
			<summary>When adding a secondary index to an existing table, it will cause NPE during re-indexing. </summary>
			<description>When adding a secondary index to an existing table, an IndexSpecification must be constructed.
If we construct a simple index using the following constructor: IndexSpecification(String indexId, byte[] indexedColumn), then the program will cause NPE during re-indexing. 
Exception in thread "main" java.lang.NullPointerException
        at org.apache.hadoop.hbase.regionserver.tableindexed.IndexMaintenanceUtils.createIndexUpdate(IndexMaintenanceUtils.java:57)
        at org.apache.hadoop.hbase.client.tableindexed.IndexedTableAdmin.reIndexTable(IndexedTableAdmin.java:144)
        at org.apache.hadoop.hbase.client.tableindexed.IndexedTableAdmin.addIndex(IndexedTableAdmin.java:132)
        at MyIndexedTable.addSecondaryIndexToExistingTable(MyIndexedTable.java:256)
        at MyIndexedTable.main(MyIndexedTable.java:276)</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.2, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.tableindexed.IndexSpecification.java</file>
		</fixedFiles>
	</bug>
	<bug id="1908" opendate="2009-10-15 18:23:24" fixdate="2009-10-20 00:08:34" resolution="Fixed">
		<buginformation>
			<summary>ROOT not reassigned if only one regionserver left</summary>
			<description>Yannis on the list uncovered an assignment bug:

I performed additional testing with some alternate configurations and the problem arises (ONLY) when there is only one regionserver left which has the META table already assigned to it. 
In this case the ROOT table does not get assigned to the last regionserver (which holds the META table).
Interestingly enough though when there is only one regionserver left that has the ROOT table already assign to it then it can also have the META table re-assigned to it (if again is the only server - i.e. in this scenario you can have one regionserver holding both the META and ROOT tables).
Unless I am missing something I cannot find any reason why we cannot assign the ROOT table to the regionserver that manages the META table if it is the only one remaining (again it is an extreme case I agree that this can happen).
I applied and tested a fix (at the hbase-0.20.0 codebase) in the RegionManager::regionsAwaitingAssignment where I add the root table in the regionstoAssign set if the it is the metaServer and also the only server.</description>
			<version>0.20.1</version>
			<fixedVersion>0.20.2, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.RegionManager.java</file>
		</fixedFiles>
	</bug>
	<bug id="1777" opendate="2009-08-18 19:10:11" fixdate="2009-10-21 23:38:03" resolution="Fixed">
		<buginformation>
			<summary>column length is not checked before saved to memstore</summary>
			<description>I added some debuging to line 511 in HFile.java and found that the column is causing my problem it was &amp;gt; max size
we should check this before saving the record to memstore
As of 0.20.0-RC2 the server dies and cause the hlogs to be read again by the next region server that gets the region in the end it cause the whole cluster to go down sense the bad data is in the hlog at this point.


2009-08-18 12:54:16,572 FATAL 
org.apache.hadoop.hbase.regionserver.MemStoreFlusher: Replay of hlog 
required. Forcing server shutdown
org.apache.hadoop.hbase.DroppedSnapshotException: region: 
webdata,http:\x2F\x2Fanaal-genomen.isporno.nl\x2F,1250569930062
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:950)
        at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:843)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:241)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.run(MemStoreFlusher.java:149)
Caused by: java.io.IOException: Key length 183108 &amp;gt; 65536
        at org.apache.hadoop.hbase.io.hfile.HFile$Writer.checkKey(HFile.java:511)
        at org.apache.hadoop.hbase.io.hfile.HFile$Writer.append(HFile.java:479)
        at org.apache.hadoop.hbase.io.hfile.HFile$Writer.append(HFile.java:447)
        at org.apache.hadoop.hbase.regionserver.Store.internalFlushCache(Store.java:525)
        at org.apache.hadoop.hbase.regionserver.Store.flushCache(Store.java:489)
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:935)
        ... 3 more

</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.2, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFile.java</file>
		</fixedFiles>
	</bug>
	<bug id="1929" opendate="2009-10-22 18:36:12" fixdate="2009-10-22 18:42:44" resolution="Fixed">
		<buginformation>
			<summary>If hbase-default.xml is not in CP, zk session timeout is 10 secs!</summary>
			<description>In ZKW:


 int sessionTimeout = conf.getInt("zookeeper.session.timeout", 10 * 1000);


If hbase-default.xml is not in the path, that means potential trouble.</description>
			<version>0.20.1</version>
			<fixedVersion>0.20.2, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.zookeeper.ZooKeeperWrapper.java</file>
		</fixedFiles>
	</bug>
	<bug id="1927" opendate="2009-10-22 07:31:02" fixdate="2009-10-22 18:54:12" resolution="Fixed">
		<buginformation>
			<summary>Scanners not closed properly in certain circumstances (memory leak)</summary>
			<description>Scanners are sometimes leaked by the KeyValueHeap class. The constructor adds each scanner to a heap, but only if the scanner&amp;amp;apos;s peek() method returns not null (line 58). Otherwise the scanner is dropped without being closed.
Unfortunately some scanners (like StoreScanner and MemStoreScanner) register themselves to some global list when constructed and only deregister on close(). This can cause a memory leak, for example with MemStoreScanners on an empty memory store.
The quick fix is to add an else clause to the if on line 58:
} else 
{
  scanner.close()
}

The root cause is that ownership of the scanners is transferred from the caller to the KeyValueHeap on construction. Maybe this should be made clear in the documentation or changed.</description>
			<version>0.20.1</version>
			<fixedVersion>0.20.2, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.KeyValueHeap.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestKeyValueHeap.java</file>
		</fixedFiles>
	</bug>
	<bug id="1930" opendate="2009-10-22 20:39:49" fixdate="2009-10-23 20:00:30" resolution="Fixed">
		<buginformation>
			<summary>Put.setTimeStamp misleading (doesn&amp;apos;t change timestamp on existing KeyValues, not copied in copy constructor)</summary>
			<description>In the process of migrating some code from 0.19, and was changing BatchUpdate&amp;amp;apos;s to Put&amp;amp;apos;s.  I was hit by a bit of a gotcha.  In the old code, I populated the BatchUpdate, then set the timestamp.  However, this doesn&amp;amp;apos;t wotk for Put, because Put creates KeyValue&amp;amp;apos;s with the currently set timestamp when adding values.  Setting the timestamp at the end has no effect.  Also, the copy constructor doesn&amp;amp;apos;t copy the timestamp (or writeToWAL) setting.
One option would be to simply update the javadoc to make it clear that the timestamp needs to be set prior to adding values.  I&amp;amp;apos;m attaching a proposed patch which moves the timestamp setting to constructor only so that it isn&amp;amp;apos;t possible to trigger the confusing case at all.</description>
			<version>0.20.0</version>
			<fixedVersion>0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseTestCase.java</file>
			<file type="M">org.apache.hadoop.hbase.TimestampTestBase.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestGetRowVersions.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
			<file type="M">org.apache.hadoop.hbase.client.Put.java</file>
			<file type="M">org.apache.hadoop.hbase.TestScanMultipleVersions.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">1941</link>
		</links>
	</bug>
	<bug id="1934" opendate="2009-10-25 21:01:51" fixdate="2009-10-26 05:31:34" resolution="Fixed">
		<buginformation>
			<summary>NullPointerException in ClientScanner</summary>
			<description>The following stack trace was observed whilst loading a large volume of data into Hbase:
Caused by: java.lang.NullPointerException
 at org.apache.hadoop.hbase.client.HTable$ClientScanner.next(HTable.java:2008)
 at org.apache.hadoop.hbase.client.HTable$ClientScanner$1.hasNext(HTable.java:2089)
It appears that lastResult is initialized to be null, however in the exception handling code there isn&amp;amp;apos;t any null checking before the field is accessed for get row:
            this.scan.setStartRow(this.lastResult.getRow());
There should be some additional null checking logic here.</description>
			<version>0.20.1</version>
			<fixedVersion>0.20.2, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
		</fixedFiles>
	</bug>
	<bug id="1921" opendate="2009-10-20 03:08:31" fixdate="2009-10-29 02:14:12" resolution="Fixed">
		<buginformation>
			<summary>When the Master&amp;apos;s session times out and there&amp;apos;s only one, cluster is wedged</summary>
			<description>On IRC, some fella had a session expiration on his Master and had only one. Maybe in this case the Master should first try to re-get the znode?</description>
			<version>0.20.1</version>
			<fixedVersion>0.20.2, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="M">org.apache.hadoop.hbase.master.AssignmentManager.java</file>
			<file type="M">org.apache.hadoop.hbase.TestZooKeeper.java</file>
			<file type="M">org.apache.hadoop.hbase.master.RegionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ZKMasterAddressWatcher.java</file>
		</fixedFiles>
	</bug>
	<bug id="1946" opendate="2009-10-30 16:39:31" fixdate="2009-10-30 17:26:07" resolution="Fixed">
		<buginformation>
			<summary>Unhandled exception at regionserver</summary>
			<description>While starting hbase I get following exception:

java.lang.NullPointerException
  at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:459)
   at java.lang.Thread.run(Thread.java:619)
in region server&amp;amp;apos;s log on the second machine whereas at first machine all going well.
We&amp;amp;apos;ve discussed with larsgeorge this problem at IRC channel and seems problem is in HRegionServer implementation.
Patch which fixies that problem attached to this message, but it should be not a final variant, because I cannot stop hbase with this fix.</description>
			<version>0.20.1</version>
			<fixedVersion>0.20.2, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
		</fixedFiles>
	</bug>
	<bug id="1954" opendate="2009-11-03 19:17:06" fixdate="2009-11-03 19:41:15" resolution="Fixed">
		<buginformation>
			<summary>Transactional scans do not see newest put.</summary>
			<description>In a transaction, if I do a put, then a put, then a scan. I will not see the latest put.
The fix is to set the timestamp at put time.</description>
			<version>0.20.1</version>
			<fixedVersion>0.20.2, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.transactional.TestTransactions.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.transactional.TransactionState.java</file>
		</fixedFiles>
	</bug>
	<bug id="1919" opendate="2009-10-19 21:54:35" fixdate="2009-11-03 23:48:32" resolution="Fixed">
		<buginformation>
			<summary>code: HRS.delete seems to ignore exceptions it shouldnt</summary>
			<description>the code is:
      region.delete(delete, lid, writeToWAL);
      this.hlog.sync(region.getRegionInfo().isMetaRegion());
    } catch (WrongRegionException ex) {
    } catch (NotServingRegionException ex) 
{
      // ignore                                                                                                                                                                          
    }
 catch (Throwable t) 
{
      throw convertThrowableToIOE(cleanup(t));
    }

we ignore those 2 exceptions... weird... should not be!</description>
			<version>0.20.1</version>
			<fixedVersion>0.20.2, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
		</fixedFiles>
	</bug>
	<bug id="1951" opendate="2009-11-02 15:09:18" fixdate="2009-11-04 01:29:40" resolution="Fixed">
		<buginformation>
			<summary>Stack overflow when calling HTable.checkAndPut() when deleting a lot of values</summary>
			<description>We get a stackoverflow when calling HTable.checkAndPut() from a map-reduce job though the client API after doing a large number of deletes.
Our mapred job is a periodic job (which extends TableMapper) that merges the versions for a value in a column into a new value/version and then deletes the older versions. This is because we use versions to store data so we can do append-only insertion. Our rows can have large/huge (from 1 till &amp;gt; 1M) numbers of columns (aka key-values).
The problem seems to be that the org.apache.hadoop.hbase.regionserver.GetDeleteTracker.isDeleted() method is implemented with recursion but since Java has no tail recursion optimization, this fails for cases where the number of deletes that are being tracked is bigger than the stack size. I&amp;amp;apos;m not sure why recursion is used here but it is not safe without tail-call optimization and it should be optimized into a simple loop.
I&amp;amp;apos;ll attach the stacktrace.</description>
			<version>0.20.1</version>
			<fixedVersion>0.20.2, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.GetDeleteTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestGetDeleteTracker.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">1781</link>
		</links>
	</bug>
	<bug id="1781" opendate="2009-08-20 16:41:14" fixdate="2009-11-04 05:25:22" resolution="Fixed">
		<buginformation>
			<summary>Weird behavior of WildcardColumnTracker.checkColumn(), looks like recursive loop</summary>
			<description>I got a weird error twice on a MR job which eventually though completed


...
09/08/19 11:28:31 INFO mapreduce.TableInputFormatBase: split: 2591-&amp;gt;foo.bar.net:1fff99f02088fe,1fffdcbdb0476b
09/08/19 11:28:31 INFO mapreduce.TableInputFormatBase: split: 2592-&amp;gt;foo.bar.net:1fffdcbdb0476b,
09/08/19 11:28:31 INFO mapred.JobClient: Running job: job_200908120615_0015
09/08/19 11:28:32 INFO mapred.JobClient:  map 0% reduce 0%
09/08/19 11:35:43 INFO mapred.JobClient:  map 1% reduce 0%
09/08/19 11:39:53 INFO mapred.JobClient:  map 2% reduce 0%
09/08/19 11:42:58 INFO mapred.JobClient:  map 3% reduce 0%
09/08/19 11:47:02 INFO mapred.JobClient:  map 4% reduce 0%
09/08/19 11:50:41 INFO mapred.JobClient:  map 5% reduce 0%
09/08/19 11:54:25 INFO mapred.JobClient:  map 6% reduce 0%
09/08/19 11:58:31 INFO mapred.JobClient:  map 7% reduce 0%
09/08/19 12:02:36 INFO mapred.JobClient:  map 8% reduce 0%
09/08/19 12:06:12 INFO mapred.JobClient:  map 9% reduce 0%
09/08/19 12:10:01 INFO mapred.JobClient:  map 10% reduce 0%
09/08/19 12:13:40 INFO mapred.JobClient:  map 11% reduce 0%
09/08/19 12:17:04 INFO mapred.JobClient:  map 12% reduce 0%
09/08/19 12:21:07 INFO mapred.JobClient:  map 13% reduce 0%
09/08/19 12:24:46 INFO mapred.JobClient:  map 14% reduce 0%
09/08/19 12:29:27 INFO mapred.JobClient:  map 15% reduce 0%
09/08/19 12:33:42 INFO mapred.JobClient:  map 16% reduce 0%
09/08/19 12:38:04 INFO mapred.JobClient:  map 17% reduce 0%
09/08/19 12:44:16 INFO mapred.JobClient:  map 18% reduce 0%
09/08/19 12:50:20 INFO mapred.JobClient:  map 19% reduce 0%
09/08/19 12:55:44 INFO mapred.JobClient:  map 20% reduce 0%
09/08/19 13:01:11 INFO mapred.JobClient:  map 21% reduce 0%
09/08/19 13:06:21 INFO mapred.JobClient:  map 22% reduce 0%
09/08/19 13:11:24 INFO mapred.JobClient:  map 23% reduce 0%
09/08/19 13:15:39 INFO mapred.JobClient:  map 24% reduce 0%
09/08/19 13:20:33 INFO mapred.JobClient:  map 25% reduce 0%
09/08/19 13:25:58 INFO mapred.JobClient:  map 26% reduce 0%
09/08/19 13:29:52 INFO mapred.JobClient:  map 27% reduce 0%
09/08/19 13:34:44 INFO mapred.JobClient:  map 28% reduce 0%
09/08/19 13:38:19 INFO mapred.JobClient:  map 29% reduce 0%
09/08/19 13:41:53 INFO mapred.JobClient:  map 30% reduce 0%
09/08/19 13:45:09 INFO mapred.JobClient:  map 31% reduce 0%
09/08/19 13:49:06 INFO mapred.JobClient:  map 32% reduce 0%
09/08/19 13:52:47 INFO mapred.JobClient:  map 33% reduce 0%
09/08/19 13:56:37 INFO mapred.JobClient:  map 34% reduce 0%
09/08/19 13:59:48 INFO mapred.JobClient:  map 35% reduce 0%
09/08/19 14:04:14 INFO mapred.JobClient:  map 36% reduce 0%
09/08/19 14:09:32 INFO mapred.JobClient:  map 37% reduce 0%
09/08/19 14:14:00 INFO mapred.JobClient:  map 38% reduce 0%
09/08/19 14:17:42 INFO mapred.JobClient:  map 39% reduce 0%
09/08/19 14:21:50 INFO mapred.JobClient:  map 40% reduce 0%
09/08/19 14:25:17 INFO mapred.JobClient:  map 41% reduce 0%
09/08/19 14:28:57 INFO mapred.JobClient:  map 42% reduce 0%
09/08/19 14:33:03 INFO mapred.JobClient:  map 43% reduce 0%
09/08/19 14:36:51 INFO mapred.JobClient:  map 44% reduce 0%
09/08/19 14:40:49 INFO mapred.JobClient:  map 45% reduce 0%
09/08/19 14:44:44 INFO mapred.JobClient:  map 46% reduce 0%
09/08/19 14:48:37 INFO mapred.JobClient:  map 47% reduce 0%
09/08/19 14:52:15 INFO mapred.JobClient:  map 48% reduce 0%
09/08/19 14:55:57 INFO mapred.JobClient:  map 49% reduce 0%
09/08/19 14:59:21 INFO mapred.JobClient:  map 50% reduce 0%
09/08/19 15:02:58 INFO mapred.JobClient:  map 51% reduce 0%
09/08/19 15:07:23 INFO mapred.JobClient:  map 52% reduce 0%
09/08/19 15:10:19 INFO mapred.JobClient:  map 53% reduce 0%
09/08/19 15:13:19 INFO mapred.JobClient:  map 54% reduce 0%
09/08/19 15:16:38 INFO mapred.JobClient:  map 55% reduce 0%
09/08/19 15:19:36 INFO mapred.JobClient:  map 56% reduce 0%
09/08/19 15:22:41 INFO mapred.JobClient:  map 57% reduce 0%
09/08/19 15:25:35 INFO mapred.JobClient:  map 58% reduce 0%
09/08/19 15:30:07 INFO mapred.JobClient:  map 59% reduce 0%
09/08/19 15:37:41 INFO mapred.JobClient:  map 60% reduce 0%
09/08/19 15:42:04 WARN zookeeper.ClientCnxn: Exception closing session 0x422d8cc8cbb310e to sun.nio.ch.SelectionKeyImpl@4737371
java.io.IOException: TIMED OUT
        at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:858)
09/08/19 15:42:05 INFO zookeeper.ClientCnxn: Attempting connection to server tr-bt-dal-03/10.12.205.194:2181
09/08/19 15:42:05 INFO zookeeper.ClientCnxn: Priming connection to java.nio.channels.SocketChannel[connected local=/10.16.182.238:41125 remote=tr-bt-dal-03/10.12.205.194:2181]
09/08/19 15:42:05 INFO zookeeper.ClientCnxn: Server connection successful
09/08/19 15:43:08 INFO mapred.JobClient:  map 61% reduce 0%
09/08/19 15:49:24 INFO mapred.JobClient:  map 62% reduce 0%
09/08/19 15:54:04 INFO mapred.JobClient:  map 63% reduce 0%
09/08/19 15:57:01 INFO mapred.JobClient:  map 64% reduce 0%
09/08/19 16:00:42 INFO mapred.JobClient:  map 65% reduce 0%
09/08/19 16:03:20 INFO mapred.JobClient:  map 66% reduce 0%
09/08/19 16:06:53 INFO mapred.JobClient:  map 67% reduce 0%
09/08/19 16:09:20 INFO mapred.JobClient:  map 68% reduce 0%
09/08/19 16:12:02 INFO mapred.JobClient:  map 69% reduce 0%
09/08/19 16:14:35 INFO mapred.JobClient:  map 70% reduce 0%
09/08/19 16:17:26 INFO mapred.JobClient:  map 71% reduce 0%
09/08/19 16:20:19 INFO mapred.JobClient:  map 72% reduce 0%
09/08/19 16:23:14 INFO mapred.JobClient:  map 73% reduce 0%
09/08/19 16:25:56 INFO mapred.JobClient:  map 74% reduce 0%
09/08/19 16:30:16 INFO mapred.JobClient:  map 75% reduce 0%
09/08/19 16:34:14 INFO mapred.JobClient:  map 76% reduce 0%
09/08/19 16:37:45 INFO mapred.JobClient:  map 77% reduce 0%
09/08/19 16:41:38 INFO mapred.JobClient:  map 78% reduce 0%
09/08/19 16:44:33 INFO mapred.JobClient:  map 79% reduce 0%
09/08/19 16:47:54 INFO mapred.JobClient:  map 80% reduce 0%
09/08/19 16:52:20 INFO mapred.JobClient:  map 81% reduce 0%
09/08/19 16:56:44 INFO mapred.JobClient:  map 82% reduce 0%
09/08/19 17:00:50 INFO mapred.JobClient:  map 83% reduce 0%
09/08/19 17:02:57 INFO mapred.JobClient: Task Id : attempt_200908120615_0015_m_002231_0, Status : FAILED
org.apache.hadoop.hbase.client.RetriesExhaustedException: Trying to contact region server 10.16.182.240:60020 for region segmentdata,79d34f17-9b48-4835-bf03-971c9e21ff2f,1250687021375, row &amp;amp;apos;7c78ca95-4d82-420f-ab2f-495fe139bad0&amp;amp;apos;, but failed after 10 attempts.
Exceptions:
java.io.IOException: java.io.IOException: java.lang.StackOverflowError
        at org.apache.hadoop.hbase.regionserver.HRegionServer.convertThrowableToIOE(HRegionServer.java:847)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.convertThrowableToIOE(HRegionServer.java:837)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.get(HRegionServer.java:1770)
        at sun.reflect.GeneratedMethodAccessor39.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:650)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:913)
Caused by: java.lang.StackOverflowError
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:136)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracke
09/08/19 17:04:01 INFO mapred.JobClient:  map 84% reduce 0%
09/08/19 17:07:16 INFO mapred.JobClient:  map 85% reduce 0%
09/08/19 17:10:38 INFO mapred.JobClient:  map 86% reduce 0%
09/08/19 17:13:44 INFO mapred.JobClient:  map 87% reduce 0%
09/08/19 17:16:12 INFO mapred.JobClient:  map 88% reduce 0%
09/08/19 17:19:29 INFO mapred.JobClient:  map 89% reduce 0%
09/08/19 17:23:00 INFO mapred.JobClient:  map 90% reduce 0%
09/08/19 17:29:25 INFO mapred.JobClient: Task Id : attempt_200908120615_0015_m_002231_1, Status : FAILED
org.apache.hadoop.hbase.client.RetriesExhaustedException: Trying to contact region server 10.16.182.240:60020 for region segmentdata,79d34f17-9b48-4835-bf03-971c9e21ff2f,1250687021375, row &amp;amp;apos;7c78ca95-4d82-420f-ab2f-495fe139bad0&amp;amp;apos;, but failed after 10 attempts.
Exceptions:
java.io.IOException: java.io.IOException: java.lang.StackOverflowError
        at org.apache.hadoop.hbase.regionserver.HRegionServer.convertThrowableToIOE(HRegionServer.java:847)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.convertThrowableToIOE(HRegionServer.java:837)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.get(HRegionServer.java:1770)
        at sun.reflect.GeneratedMethodAccessor39.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:650)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:913)
Caused by: java.lang.StackOverflowError
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:136)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracke
09/08/19 17:31:22 INFO mapred.JobClient:  map 91% reduce 0%
09/08/19 17:43:27 INFO mapred.JobClient:  map 92% reduce 0%
09/08/19 17:57:27 INFO mapred.JobClient:  map 93% reduce 0%
09/08/19 18:09:43 INFO mapred.JobClient:  map 94% reduce 0%
09/08/19 18:19:16 INFO mapred.JobClient:  map 95% reduce 0%
09/08/19 18:21:49 INFO mapred.JobClient: Task Id : attempt_200908120615_0015_m_002231_2, Status : FAILED
org.apache.hadoop.hbase.client.RetriesExhaustedException: Trying to contact region server 10.16.182.240:60020 for region segmentdata,79d34f17-9b48-4835-bf03-971c9e21ff2f,1250687021375, row &amp;amp;apos;7c78ca95-4d82-420f-ab2f-495fe139bad0&amp;amp;apos;, but failed after 10 attempts.
Exceptions:
java.io.IOException: java.io.IOException: java.lang.StackOverflowError
        at org.apache.hadoop.hbase.regionserver.HRegionServer.convertThrowableToIOE(HRegionServer.java:847)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.convertThrowableToIOE(HRegionServer.java:837)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.get(HRegionServer.java:1770)
        at sun.reflect.GeneratedMethodAccessor39.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:650)
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:913)
Caused by: java.lang.StackOverflowError
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:136)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.checkColumn(WildcardColumnTracker.java:158)
        at org.apache.hadoop.hbase.regionserver.WildcardColumnTracke
09/08/19 18:31:22 INFO mapred.JobClient:  map 96% reduce 0%
09/08/19 18:42:54 INFO mapred.JobClient:  map 97% reduce 0%
09/08/19 18:43:02 INFO mapred.JobClient: Job complete: job_200908120615_0015
09/08/19 18:43:02 INFO mapred.JobClient: Counters: 11
09/08/19 18:43:02 INFO mapred.JobClient:   Job Counters
09/08/19 18:43:02 INFO mapred.JobClient:     Rack-local map tasks=30
09/08/19 18:43:02 INFO mapred.JobClient:     Launched map tasks=2530
09/08/19 18:43:02 INFO mapred.JobClient:     Data-local map tasks=2500
09/08/19 18:43:02 INFO mapred.JobClient:     Failed map tasks=1
09/08/19 18:43:02 INFO mapred.JobClient:   net.foo.hadoop.hbase.mapred.SetCurrentData$SetCurrentMapper$Counters
09/08/19 18:43:02 INFO mapred.JobClient:     ROWS=22692113
09/08/19 18:43:02 INFO mapred.JobClient:     NETWORK=101481740
09/08/19 18:43:02 INFO mapred.JobClient:     ASSOC=231471790
09/08/19 18:43:02 INFO mapred.JobClient:     CURR_NETWORK=23944682
09/08/19 18:43:02 INFO mapred.JobClient:     CURR_PROVIDER=1801150
09/08/19 18:43:02 INFO mapred.JobClient:   Map-Reduce Framework
09/08/19 18:43:02 INFO mapred.JobClient:     Map input records=22692113
09/08/19 18:43:02 INFO mapred.JobClient:     Spilled Records=0

</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.2, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestWildcardColumnTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.WildcardColumnTracker.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">1951</link>
		</links>
	</bug>
	<bug id="1949" opendate="2009-10-30 22:17:41" fixdate="2009-11-05 21:52:39" resolution="Fixed">
		<buginformation>
			<summary>KeyValue expiration by Time-to-Live during major compaction is broken</summary>
			<description>During a major compaction on a region in a column family with a configured TTL, it looks like all KeyValues in a row after the first expired KeyValue are skipping and thrown out of the newly written file (regardless of whether the would have been expired or not).
The StoreScanner is skipping to the next row, even when other columns with a non-expirable timestamp exists.  Unless I&amp;amp;apos;m misunderstanding it, it seems like it should just seek to the next column instead.  I discovered this when altering a table to lower the TTL for a column family and force the expiration of some data which led to the entire row being expired in some instances.</description>
			<version>0.20.1</version>
			<fixedVersion>0.20.2, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestStoreScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.ScanQueryMatcher.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.QueryMatcher.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestQueryMatcher.java</file>
		</fixedFiles>
	</bug>
	<bug id="1957" opendate="2009-11-06 08:40:14" fixdate="2009-11-06 19:12:27" resolution="Fixed">
		<buginformation>
			<summary>Get-s can&amp;apos;t set a Filter</summary>
			<description>This is an issue directly related to HBASE-1646. Get#write and Get#readFields both use  HbaseObjectWritable to write filters and when it comes to custom filters or filters in general that are not hardcoded in HbaseObjectWritable , an exception is thrown. 
It has been fixed in the issue noted above for Scan. Attached patch fixes it fot Get too.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.2, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.Get.java</file>
		</fixedFiles>
		<links>
			<link type="Cloners" description="is a clone of">1646</link>
		</links>
	</bug>
	<bug id="1928" opendate="2009-10-22 17:32:22" fixdate="2009-11-07 23:43:24" resolution="Fixed">
		<buginformation>
			<summary>ROOT and META tables stay in transition state (making the system not usable) if the designated regionServer dies before the assignment is complete</summary>
			<description>During a ROOT or META table re-assignment if the designated regionServer dies before the assignment is complete then the whole cluster becomes unavailble since the ROOT or META tables cannot be accessed (and never recover since they are kept in a transition state).
These are the 4 steps to replicate this issue (this is the easiest way to replicate. You can imagine that the following can occur in any real system).
Pre condition
============
1. a cluster of 3 nodes (cache01, cache02, search01).
2. start the system (start-hbase)
3. cache02 has META, search01 has ROOT, cache01 has regionServer and Master.
Case 1:
=======
1. kill cache01
2. kill cache02
3. now search01 has both ROOT and META.
4. re-start RegionServers on cache01 and cache02
5. Tail the master logs and grep for "Assigning region ROOT" and also "Assigning region .META." (need to windows for easiness)
6. kill search01
7. wait to see to which server the ROOT will be assigned (from the tail)
8. quickly kill that server
9. you should notice that the ROOT server never gets re-assigned (because it is stuck in the regionsInTransitions)
The termination occurs through the ServerManager::removeServerInfo since the regionServer sends back to the master in a report that it is shutting down.
Case 2:
========
Repeat Case1 and in step 7 and 8 kill the server that has the META region assigned to it. Again the cluster becomes unavailble because the META region stays in the regionsInTransitions.
The termination occurs through the ServerManager::removeServerInfo since the regionServer sends back to the master in a report that it is shutting down.
Case 3:
========
Repeat Case1 and in step 7 and 8 kill the server with kill -9 instead of kill. This will not give the opportunity to the regionServer to send back the master in the report that it is terminating. The master will realize this because the znode will expire (but it is a different code path from before - it goes to the ProcessServerShutdown).
Case 4:
========
Repeat Case3 and in step 7 and 8 kill the server with kill -9 instead of kill. This will not give the opportunity to the regionServer to send back the master in the report that it is terminating. The master will realize this because the znode will expire (but it is a different code path from before - it goes to the ProcessServerShutdown).
The solution would be to check the in the ServerManager:removeServerInfo and in  ProcessServerShutdown::closeMetaRegions whether the server that has been terminated has been assigned either the ROOT or META table. And if they have make sure we make those table ready to be re-assigned again.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.2, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.RegionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ServerManager.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ProcessServerShutdown.java</file>
		</fixedFiles>
	</bug>
	<bug id="1966" opendate="2009-11-10 01:27:59" fixdate="2009-11-10 01:40:49" resolution="Fixed">
		<buginformation>
			<summary>Apply the fix from site/ to remove the forrest dependency on java5 </summary>
			<description>Fix forrest with:

forrest.validate=false

</description>
			<version>0.20.1</version>
			<fixedVersion>0.20.2, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.transactional.TestTransactions.java</file>
		</fixedFiles>
	</bug>
	<bug id="1979" opendate="2009-11-13 11:47:45" fixdate="2009-11-24 19:29:42" resolution="Fixed">
		<buginformation>
			<summary>MurmurHash does not yield the same results as the reference C++ implementation when size % 4 &gt;= 2</summary>
			<description>Last rounds of MurmurHash are done in reverse order. data[length - 3], data[length - 2] and data[length - 1] in the block processing the remaining bytes should be data[len_m +2], data[len_m + 1], data[len_m].</description>
			<version>0.20.1</version>
			<fixedVersion>0.20.3, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.MurmurHash.java</file>
		</fixedFiles>
		<links>
			<link type="Cloners" description="is cloned by">6372</link>
		</links>
	</bug>
	<bug id="2018" opendate="2009-11-30 22:32:19" fixdate="2009-12-04 04:34:31" resolution="Fixed">
		<buginformation>
			<summary>Updates to .META. blocked under high MemStore load</summary>
			<description>I discovered this on Lars&amp;amp;apos; cluster. The symptom was the good old:


09/11/30 08:10:26 INFO mapred.JobClient: Task Id : attempt_200911250121_0011_r_000010_1, Status : FAILED
org.apache.hadoop.hbase.client.RetriesExhaustedException: Trying to contact region server Some server, retryOnlyOne=true, index=0, islastrow=false, tries=9, numtries=10, i=14, listsize=20, region=prev-docs,de68fb97795ef3d936a3f10ff8790253,1259573366564 for region prev-docs,ccea967e66ccb53d83c48849c3a23f21,1259542138868, row &amp;amp;apos;ccff8cd4ca871c41f4fa7d44cffed962&amp;amp;apos;, but failed after 10 attempts.
Exceptions:
        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers$Batch.process(HConnectionManager.java:1120)
        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.processBatchOfRows(HConnectionManager.java:1201)
        at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:605)
        at org.apache.hadoop.hbase.client.HTable.put(HTable.java:470)
        at org.apache.hadoop.hbase.mapreduce.TableOutputFormat$TableRecordW


But the load wasn&amp;amp;apos;t that heavy, just lots of splitting going on. Looking at the logs, I see a split taking more than 4 minutes which is explained by this happening on the RS hosting .META. :


2009-11-30 08:08:39,922 INFO org.apache.hadoop.hbase.regionserver.MemStoreFlusher: Forced flushing of prev-docs,2c9d51e57b20decd5c6419d23ede822b,1259542273901 because global memstore limit of 1.6g exceeded; currently 1.6g and flushing till 1021.9m
...
2009-11-30 08:12:33,743 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Finished memstore flush of ~22.9m for region prev-docs,c8fea4fbbc41e746d960854ed4d41dd6,1259587143838 in 14160ms, sequence id=13677, compaction requested=false
2009-11-30 08:12:33,744 INFO org.apache.hadoop.hbase.regionserver.MemStoreFlusher: Forced flushing of prev-docs,39c2995d955c041d21f4dc4a0d0dbf6c,1259587061295 because global memstore limit of 1.6g exceeded; currently 1.0g and flushing till 1021.9m


So we should not block updates to .META. for any reason. I&amp;amp;apos;m pretty sure this issue explains other issues we&amp;amp;apos;ve seen on the mailing list.</description>
			<version>0.20.2</version>
			<fixedVersion>0.20.3, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
		</fixedFiles>
	</bug>
	<bug id="1994" opendate="2009-11-19 14:22:10" fixdate="2009-12-04 18:38:28" resolution="Fixed">
		<buginformation>
			<summary>Master will lose hlog entries while splitting if region has empty oldlogfile.log</summary>
			<description>I don&amp;amp;apos;t know yet how an empty oldlogfile.log can exist, however it happened.
Master will fail to put the splits in the region oldlogfile.log if an empty oldlogfile.log already exists there.
This is the master log after I artificially reproduced it by placing an empty oldlogfile.log in /hbase/.META./1028785192/oldlogfile.log and then killed the regionserver that was holding the .META. table
2009-11-19 09:08:36,012 INFO org.apache.hadoop.hbase.regionserver.wal.HLog: Splitting 1 hlog(s) in hdfs://b0:9000/hbase/.logs/b4,60020,1258637492773
2009-11-19 09:08:36,012 DEBUG org.apache.hadoop.hbase.regionserver.wal.HLog: Splitting hlog 1 of 1: hdfs://b0:9000/hbase/.logs/b4,60020,1258637492773/hlog.dat.1258637493128, length=0
2009-11-19 09:08:36,019 DEBUG org.apache.hadoop.hbase.regionserver.wal.HLog: Adding queue for .META.,,1
2009-11-19 09:08:36,037 DEBUG org.apache.hadoop.hbase.regionserver.wal.HLog: Pushed=795 entries from hdfs://b0:9000/hbase/.logs/b4,60020,1258637492773/hlog.dat.1258637493128
2009-11-19 09:08:36,038 DEBUG org.apache.hadoop.hbase.regionserver.wal.HLog: Thread got 795 to process
2009-11-19 09:08:36,043 WARN org.apache.hadoop.hbase.regionserver.wal.HLog: Old hlog file hdfs://b0:9000/hbase/.META./1028785192/oldlogfile.log already exists. Copying existing file to new file
2009-11-19 09:08:36,079 WARN org.apache.hadoop.hbase.regionserver.wal.HLog: Got while writing region .META.,,1 log java.io.EOFException
2009-11-19 09:08:36,081 INFO org.apache.hadoop.hbase.regionserver.wal.HLog: hlog file splitting completed in 70 millis for hdfs://b0:9000/hbase/.logs/b4,60020,1258637492773</description>
			<version>0.90.0</version>
			<fixedVersion>0.20.3, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">2358</link>
			<link type="Reference" description="is related to">1364</link>
		</links>
	</bug>
	<bug id="2022" opendate="2009-12-01 18:28:54" fixdate="2009-12-07 23:48:45" resolution="Fixed">
		<buginformation>
			<summary>NPE in housekeeping kills RS</summary>
			<description>Saw this on Zhenyu&amp;amp;apos;s 0.20.1 cluster (which for some weird reason seems to have many issues):


2009-11-30 16:44:48,170 FATAL org.apache.hadoop.hbase.regionserver.HRegionServer: Unhandled exception. Aborting...
java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.HRegionServer.housekeeping(HRegionServer.java:1280)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:590)
	at java.lang.Thread.run(Thread.java:619)


This reminds me of HBASE-1386 and in fact this could be the same issue (but I can&amp;amp;apos;t confirm). Searching on the web gives me some hits and this is particularly interesting http://forums.sun.com/thread.jspa?threadID=5379669</description>
			<version>0.20.2</version>
			<fixedVersion>0.20.3, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
		</fixedFiles>
	</bug>
	<bug id="2027" opendate="2009-12-03 01:27:55" fixdate="2009-12-08 00:25:39" resolution="Fixed">
		<buginformation>
			<summary>HConnectionManager.HBASE_INSTANCES leaks TableServers</summary>
			<description>HConnectionManager.HBASE_INSTANCES is a WeakHashMap from HBaseConfiguration to TableServers.  However, each TableServers has a strong reference back to the HBaseConfiguration key so they are never freed.  (See note at http://java.sun.com/javase/6/docs/api/java/util/WeakHashMap.html : "Implementation note: The value objects in a WeakHashMap are held by ordinary strong references. Thus care should be taken to ensure that value objects do not strongly refer to their own keys, either directly or indirectly, since that will prevent the keys from being discarded.")
Moreover, HBaseConfiguration implements hashCode() but not equals() so identical HBaseConfiguration objects each get their own TableServers object.
We had a long running HBase client process that was creating new HTable() objects, each creating a new HBaseConfiguration() and thus a new TableServers object.  It eventually went OOM, and gave a heap dump indicating 360 MB of data retained by HBASE_INSTANCES.</description>
			<version>0.20.0</version>
			<fixedVersion>0.20.3, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseConfiguration.java</file>
		</fixedFiles>
		<links>
			<link type="Cloners" description="is cloned by">2925</link>
			<link type="Reference" description="is related to">1251</link>
			<link type="Reference" description="is related to">1976</link>
		</links>
	</bug>
	<bug id="2048" opendate="2009-12-15 01:31:34" fixdate="2009-12-15 02:04:31" resolution="Fixed">
		<buginformation>
			<summary>Small inconsistency in the "Example API Usage"</summary>
			<description>The example uses "myLittleRow" but refers to "myRow" in one of the comments.</description>
			<version>0.20.2</version>
			<fixedVersion>0.20.3, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.package-info.java</file>
		</fixedFiles>
	</bug>
	<bug id="2049" opendate="2009-12-15 21:24:49" fixdate="2009-12-17 19:03:54" resolution="Fixed">
		<buginformation>
			<summary>Cleanup HLog binary log output </summary>
			<description>HLog still logs binary region names.</description>
			<version>0.20.2</version>
			<fixedVersion>0.20.3, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
		</fixedFiles>
	</bug>
	<bug id="2026" opendate="2009-12-02 22:53:55" fixdate="2009-12-28 18:43:06" resolution="Fixed">
		<buginformation>
			<summary>NPE in StoreScanner on compaction</summary>
			<description>From Zhenyu:


2009-12-01 00:35:05,321 INFO org.apache.hadoop.hbase.regionserver.HRegion: Starting compaction on region ip_info_238,41.214.148.221,1259132082707
2009-12-01 00:35:05,572 WARN org.apache.hadoop.hbase.regionserver.Store: Not in setorg.apache.hadoop.hbase.regionserver.StoreScanner@7f821a6c
2009-12-01 00:35:05,572 WARN org.apache.hadoop.hbase.regionserver.Store: Not in setorg.apache.hadoop.hbase.regionserver.StoreScanner@7f821a6c
2009-12-01 00:35:05,572 ERROR org.apache.hadoop.hbase.regionserver.CompactSplitThread: Compaction failed for region ip_info_238,41.214.148.221,1259132082707
java.lang.NullPointerException
	at org.apache.hadoop.hbase.regionserver.StoreScanner.updateReaders(StoreScanner.java:250)
	at org.apache.hadoop.hbase.regionserver.Store.notifyChangedReadersObservers(Store.java:628)
...

</description>
			<version>0.20.2</version>
			<fixedVersion>0.20.3, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
		</fixedFiles>
	</bug>
	<bug id="2280" opendate="2010-03-03 11:06:12" fixdate="2010-03-03 13:21:04" resolution="Duplicate">
		<buginformation>
			<summary>HFileOutputFormat writes output to "unsafe" directory</summary>
			<description>HFileOutputFormat writes data direct to output folder. It&amp;amp;apos;s incorrect as failed (or killed, or interrupted) reducers leaves inconsistent files in output folder.
The convinient way to ouput data from OutputFormat is to use "working directory". The content of this directory is being moved to output directory at the end of reducer process if only reducer succeeded (this process is called "output commit" or "atomic commit").
If means that instead of
 final Path outputdir = FileOutputFormat.getOutputPath(context);
hbase should use
 final Path outputdir = FileOutputFormat.getWorkOutputPath(context);</description>
			<version>0.20.3</version>
			<fixedVersion>0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.HFileOutputFormat.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">2063</link>
		</links>
	</bug>
	<bug id="2063" opendate="2009-12-21 16:35:49" fixdate="2010-03-04 16:39:55" resolution="Fixed">
		<buginformation>
			<summary>For hfileoutputformat, on timeout/failure/kill clean up half-written hfile</summary>
			<description>Below is from mailing list.  Read from bottom to top:


 I was going to write that perhaps you needed to turn mapred.reduce.tasks.speculative.execution off, but if enabling it and things work, that would seem to indicate that a our reducer first takes longer than the task timeout maximum and secondly, on failure, we should clean up the hfile.

On the first issue, you are using KeyValueSortReducer?  Are your values large?  We set reducer status every 100 values.  Maybe this is not enough?  We should set status more frequently?  If you call context setstatus more frequently, do things work w/o speculative execution?
 
On the second, HFileOutputFormat close will set the metadata on the hfile and then close it.  On kill, this code is not being called.   Let me see if can do something about that (e.g. register a shutdown hook to clean away incomplete files -- ).

Thanks,
St.Ack


On Sun, Dec 20, 2009 at 11:26 PM, ChingShen &amp;lt;chingshenchen@gmail.com&amp;gt; wrote:
I think I found a way.
I set the "mapred.reduce.tasks.speculative.execution" to true and output
hfiles again, then successfully load hfiles into hbase.
Is it best solution? or HFileOutputFormat bug?

Shen

On Mon, Dec 21, 2009 at 8:25 AM, ChingShen &amp;lt;chingshenchen@gmail.com&amp;gt; wrote:

&amp;gt; Thanks, stack.
&amp;gt;
&amp;gt; I checked this file that isn&amp;amp;apos;t empty. But I found that as long as the
&amp;gt; "Killed Task Attempts" &amp;gt; 0 in reduce phase, and run the loadtable.rb script
&amp;gt; to load hfiles then failed.
&amp;gt; How to avoid this problem?
&amp;gt;
&amp;gt; Thanks.
&amp;gt;
&amp;gt; Shen
&amp;gt;
&amp;gt;
&amp;gt; On Sat, Dec 19, 2009 at 3:49 AM, stack &amp;lt;stack@duboce.net&amp;gt; wrote:
&amp;gt;
&amp;gt;&amp;gt; Check the
&amp;gt;&amp;gt; file
&amp;gt;&amp;gt; hdfs://domU-12-31-39-09-C5-54.compute-1.internal/osm2_hfile/Level4/197894389945760574.
&amp;gt;&amp;gt;  Is it empty?  Was there an error during running of your MR job?  Perhaps
&amp;gt;&amp;gt; a
&amp;gt;&amp;gt; task failed?
&amp;gt;&amp;gt;
&amp;gt;&amp;gt; St.Ack
&amp;gt;&amp;gt;
&amp;gt;&amp;gt;
&amp;gt;&amp;gt;
&amp;gt;&amp;gt; On Thu, Dec 17, 2009 at 9:46 PM, ChingShen &amp;lt;chingshenchen@gmail.com&amp;gt;
&amp;gt;&amp;gt; wrote:
&amp;gt;&amp;gt;
&amp;gt;&amp;gt; &amp;gt; Hi,
&amp;gt;&amp;gt; &amp;gt;  I use the script loadtable.rb to load my hfiles into hbase, but I got
&amp;gt;&amp;gt; an
&amp;gt;&amp;gt; &amp;gt; exception as below.
&amp;gt;&amp;gt; &amp;gt;  Does anyone have any suggestions?
&amp;gt;&amp;gt; &amp;gt;
&amp;gt;&amp;gt; &amp;gt; 09/12/17 23:59:33 INFO loadtable: 18 read firstkey of -3.9290_52.5534
&amp;gt;&amp;gt; from
&amp;gt;&amp;gt; &amp;gt;
&amp;gt;&amp;gt; &amp;gt;
&amp;gt;&amp;gt; hdfs://domU-12-31-39-09-C5-54.compute-1.internal/osm2_hfile/Level4/1978943899457605747
&amp;gt;&amp;gt; &amp;gt; org/apache/hadoop/hbase/io/hfile/HFile.java:1335:in `deserialize&amp;amp;apos;:
&amp;gt;&amp;gt; &amp;gt; java.io.IOException: Trailer &amp;amp;apos;header&amp;amp;apos; is wrong; does the trailer size
&amp;gt;&amp;gt; match
&amp;gt;&amp;gt; &amp;gt; content? (NativeException)
&amp;gt;&amp;gt; &amp;gt;    from org/apache/hadoop/hbase/io/hfile/HFile.java:813:in `readTrailer&amp;amp;apos;
&amp;gt;&amp;gt; &amp;gt;    from org/apache/hadoop/hbase/io/hfile/HFile.java:758:in
&amp;gt;&amp;gt; `loadFileInfo&amp;amp;apos;
&amp;gt;&amp;gt; &amp;gt;    from sun.reflect.GeneratedMethodAccessor7:-1:in `invoke&amp;amp;apos;
&amp;gt;&amp;gt; &amp;gt;    from sun/reflect/DelegatingMethodAccessorImpl.java:25:in `invoke&amp;amp;apos;
&amp;gt;&amp;gt; &amp;gt;    from java/lang/reflect/Method.java:597:in `invoke&amp;amp;apos;
&amp;gt;&amp;gt; &amp;gt;    from org/jruby/javasupport/JavaMethod.java:298:in
&amp;gt;&amp;gt; &amp;gt; `invokeWithExceptionHandling&amp;amp;apos;
&amp;gt;&amp;gt; &amp;gt;    from org/jruby/javasupport/JavaMethod.java:259:in `invoke&amp;amp;apos;
&amp;gt;&amp;gt; &amp;gt;    from org/jruby/java/invokers/InstanceMethodInvoker.java:36:in `call&amp;amp;apos;
&amp;gt;&amp;gt; &amp;gt;     ... 18 levels...
&amp;gt;&amp;gt; &amp;gt;    from org/jruby/Main.java:94:in `main&amp;amp;apos;
&amp;gt;&amp;gt; &amp;gt;    from loadtable.rb:83:in `each&amp;amp;apos;
&amp;gt;&amp;gt; &amp;gt;    from loadtable.rb:83
&amp;gt;&amp;gt; &amp;gt; Complete Java stackTrace
&amp;gt;&amp;gt; &amp;gt; java.io.IOException: Trailer &amp;amp;apos;header&amp;amp;apos; is wrong; does the trailer size
&amp;gt;&amp;gt; match
&amp;gt;&amp;gt; &amp;gt; content?
&amp;gt;&amp;gt; &amp;gt;    at
&amp;gt;&amp;gt; &amp;gt;
&amp;gt;&amp;gt; &amp;gt;
&amp;gt;&amp;gt; org.apache.hadoop.hbase.io.hfile.HFile$FixedFileTrailer.deserialize(HFile.java:1335)
&amp;gt;&amp;gt; &amp;gt;    at
&amp;gt;&amp;gt; &amp;gt;
&amp;gt;&amp;gt; org.apache.hadoop.hbase.io.hfile.HFile$Reader.readTrailer(HFile.java:813)
&amp;gt;&amp;gt; &amp;gt;    at
&amp;gt;&amp;gt; &amp;gt;
&amp;gt;&amp;gt; org.apache.hadoop.hbase.io.hfile.HFile$Reader.loadFileInfo(HFile.java:758)
&amp;gt;&amp;gt; &amp;gt;    at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
&amp;gt;&amp;gt; &amp;gt;    at
&amp;gt;&amp;gt; &amp;gt;
&amp;gt;&amp;gt; &amp;gt;
&amp;gt;&amp;gt; sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
&amp;gt;&amp;gt; &amp;gt;    at java.lang.reflect.Method.invoke(Method.java:597)
&amp;gt;&amp;gt; &amp;gt;    at
&amp;gt;&amp;gt; &amp;gt;
&amp;gt;&amp;gt; &amp;gt;
&amp;gt;&amp;gt; org.jruby.javasupport.JavaMethod.invokeWithExceptionHandling(JavaMethod.java:298)
&amp;gt;&amp;gt; &amp;gt;    at org.jruby.javasupport.JavaMethod.invoke(JavaMethod.java:259)
&amp;gt;&amp;gt; &amp;gt;    at
&amp;gt;&amp;gt; &amp;gt;
&amp;gt;&amp;gt; &amp;gt;
&amp;gt;&amp;gt; org.jruby.java.invokers.InstanceMethodInvoker.call(InstanceMethodInvoker.java:36)
&amp;gt;&amp;gt; &amp;gt;    at
&amp;gt;&amp;gt; &amp;gt; org.jruby.runtime.callsite.CachingCallSite.call(CachingCallSite.java:70)
&amp;gt;&amp;gt; &amp;gt;    at loadtable.ensure_1$RUBY$__ensure___2(loadtable.rb:86)
&amp;gt;&amp;gt; &amp;gt;    at loadtable.block_0$RUBY$__for__(loadtable.rb:85)
&amp;gt;&amp;gt; &amp;gt;    at loadtableBlockCallback$block_0$RUBY$__for__xx1.call(Unknown
&amp;gt;&amp;gt; Source)
&amp;gt;&amp;gt; &amp;gt;    at org.jruby.runtime.CompiledBlock.yield(CompiledBlock.java:102)
&amp;gt;&amp;gt; &amp;gt;    at org.jruby.runtime.Block.yield(Block.java:100)
&amp;gt;&amp;gt; &amp;gt;    at
&amp;gt;&amp;gt; org.jruby.java.proxies.ArrayJavaProxy.each(ArrayJavaProxy.java:112)
&amp;gt;&amp;gt; &amp;gt;    at
&amp;gt;&amp;gt; &amp;gt;
&amp;gt;&amp;gt; &amp;gt;
&amp;gt;&amp;gt; org.jruby.java.proxies.ArrayJavaProxy$i_method_0_0$RUBYINVOKER$each.call(org/jruby/java/proxies/ArrayJavaProxy$i_method_0_0$RUBYINVOKER$each.gen)
&amp;gt;&amp;gt; &amp;gt;    at
&amp;gt;&amp;gt; &amp;gt;
&amp;gt;&amp;gt; &amp;gt;
&amp;gt;&amp;gt; org.jruby.runtime.callsite.CachingCallSite.cacheAndCall(CachingCallSite.java:263)
&amp;gt;&amp;gt; &amp;gt;    at
&amp;gt;&amp;gt; &amp;gt;
&amp;gt;&amp;gt; &amp;gt;
&amp;gt;&amp;gt; org.jruby.runtime.callsite.CachingCallSite.callBlock(CachingCallSite.java:81)
&amp;gt;&amp;gt; &amp;gt;    at
&amp;gt;&amp;gt; &amp;gt;
&amp;gt;&amp;gt; &amp;gt;
&amp;gt;&amp;gt; org.jruby.runtime.callsite.CachingCallSite.callIter(CachingCallSite.java:96)
&amp;gt;&amp;gt; &amp;gt;    at loadtable.__file__(loadtable.rb:83)
&amp;gt;&amp;gt; &amp;gt;    at loadtable.load(loadtable.rb)
&amp;gt;&amp;gt; &amp;gt;    at org.jruby.Ruby.runScript(Ruby.java:577)
&amp;gt;&amp;gt; &amp;gt;    at org.jruby.Ruby.runNormally(Ruby.java:480)
&amp;gt;&amp;gt; &amp;gt;    at org.jruby.Ruby.runFromMain(Ruby.java:354)
&amp;gt;&amp;gt; &amp;gt;    at org.jruby.Main.run(Main.java:229)
&amp;gt;&amp;gt; &amp;gt;    at org.jruby.Main.run(Main.java:110)
&amp;gt;&amp;gt; &amp;gt;    at org.jruby.Main.main(Main.java:94)
&amp;gt;&amp;gt; &amp;gt;
&amp;gt;&amp;gt;
&amp;gt;
&amp;gt;
&amp;gt;
&amp;gt;


--
*****************************************************
Ching-Shen Chen
Advanced Technology Center,
Information &amp;amp; Communications Research Lab.
E-mail: chenchingshen@itri.org.tw
Tel:+886-3-5915542
*****************************************************


</description>
			<version>0.20.3</version>
			<fixedVersion>0.20.4, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.HFileOutputFormat.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">2280</link>
		</links>
	</bug>
	<bug id="2023" opendate="2009-12-01 22:21:04" fixdate="2010-03-12 07:24:05" resolution="Fixed">
		<buginformation>
			<summary>Client sync block can cause 1 thread of a multi-threaded client to block all others</summary>
			<description>Take a highly multithreaded client, processing a few thousand requests a second.  If a table goes offline, one thread will get stuck in "locateRegionInMeta" which is located inside the following sync block:
        synchronized(userRegionLock)
{
          return locateRegionInMeta(META_TABLE_NAME, tableName, row, useCache);
        }

So when other threads need to find a region (EVEN IF ITS CACHED!!!) it will encounter this sync and wait. 
This can become an issue on a busy thrift server (where I first noticed the problem), one region offline can prevent access to all other regions!
Potential solution: narrow this lock, or perhaps just get rid of it completely.</description>
			<version>0.20.2</version>
			<fixedVersion>0.20.4, 0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionManager.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">2458</link>
		</links>
	</bug>
	<bug id="1876" opendate="2009-09-30 16:48:43" fixdate="2010-07-17 15:38:05" resolution="Fixed">
		<buginformation>
			<summary>DroppedSnapshotException when flushing memstore after a datanode dies</summary>
			<description>A dead datanode in the cluster can lead to multiple HRegionServer failures and corrupted data. The HRegionServer failures can be reproduced  consistently on a 7 machines cluster with approx 2000 regions.
Steps to reproduce
The easiest and safest way is to reproduce it for the .META. table, however it will work with any table. 
Locate a datanode that stores the .META. files and kill -9 it. 
In order to get multiple writes to the .META. table bring up or shut down a region server this will eventually cause a flush on the memstore
2009-09-25 09:26:17,775 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Flush requested on .META.,demo__assets,asset_283132172,1252898166036,1253265069920
2009-09-25 09:26:17,775 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Started memstore flush for region .META.,demo__assets,asset_283132172,1252898166036,1253265069920. Current region memstore si
ze 16.3k
2009-09-25 09:26:17,791 INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream java.io.IOException: Bad connect ack with firstBadLink 10.72.79.108:50010
2009-09-25 09:26:17,791 INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_-8767099282771605606_176852
The DFSClient will retry for 3 times, but there&amp;amp;apos;s a high chance it will try on the same failed datanode (it takes around 10 minutes for dead datanode to be removed from cluster)
2009-09-25 09:26:41,810 WARN org.apache.hadoop.hdfs.DFSClient: DataStreamer Exception: java.io.IOException: Unable to create new block.
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.nextBlockOutputStream(DFSClient.java:2814)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2000(DFSClient.java:2078)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2264)
2009-09-25 09:26:41,810 WARN org.apache.hadoop.hdfs.DFSClient: Error Recovery for block blk_5317304716016587434_176852 bad datanode[2] nodes == null
2009-09-25 09:26:41,810 WARN org.apache.hadoop.hdfs.DFSClient: Could not get block locations. Source file "/hbase/.META./225980069/info/5573114819456511457" - Aborting...
2009-09-25 09:26:41,810 FATAL org.apache.hadoop.hbase.regionserver.MemStoreFlusher: Replay of hlog required. Forcing server shutdown
org.apache.hadoop.hbase.DroppedSnapshotException: region: .META.,demo__assets,asset_283132172,1252898166036,1253265069920
        at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:942)
        at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:835)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:241)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.run(MemStoreFlusher.java:149)
Caused by: java.io.IOException: Bad connect ack with firstBadLink 10.72.79.108:50010
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.createBlockOutputStream(DFSClient.java:2872)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.nextBlockOutputStream(DFSClient.java:2795)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2000(DFSClient.java:2078)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2264)
After the HRegionServer shuts down itself the regions will be reassigned however you might hit this 
2009-09-26 08:04:23,646 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Worker: MSG_REGION_OPEN: .META.,demo__assets,asset_283132172,1252898166036,1253265069920
2009-09-26 08:04:23,684 WARN org.apache.hadoop.hbase.regionserver.Store: Skipping hdfs://b0:9000/hbase/.META./225980069/historian/1432202951743803786 because its empty. HBASE-646 DATA LOSS?
...
2009-09-26 08:04:23,776 INFO org.apache.hadoop.hbase.regionserver.HRegion: region .META.,demo__assets,asset_283132172,1252898166036,1253265069920/225980069 available; sequence id is 1331458484
We ended up with corrupted data in .META. "info:server" after master got confirmation that it was updated from the HRegionServer that got DroppedSnapshotException
Since after a cluster restart server:info will be correct, .META. is safer to test with. Also to detect data corruption you can just scan .META. get the start key for each region and attempt to retrieve it from the corresponding table. If .META. is corrupted you get a NotServingRegionException. 
This issue is related to https://issues.apache.org/jira/browse/HDFS-630 
I attached a patch for HDFS-630 https://issues.apache.org/jira/secure/attachment/12420919/HDFS-630.patch that fixes this problem. </description>
			<version>0.20.0</version>
			<fixedVersion>0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.HTablePool.java</file>
			<file type="M">org.apache.hadoop.hbase.KeyValue.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.CompareFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.SingleColumnValueFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.RegexStringComparator.java</file>
			<file type="M">org.apache.hadoop.hbase.client.Result.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.package-info.java</file>
		</fixedFiles>
		<links>
			<link type="Blocker" description="is blocked by">630</link>
		</links>
	</bug>
	<bug id="1485" opendate="2009-06-05 18:08:05" fixdate="2010-09-08 17:23:06" resolution="Fixed">
		<buginformation>
			<summary>Wrong or indeterminate behavior when there are duplicate versions of a column</summary>
			<description>As of now, both gets and scanners will end up returning all duplicate versions of a column.  The ordering of them is indeterminate.
We need to decide what the desired/expected behavior should be and make it happen.
Note:  It&amp;amp;apos;s nearly impossible for this to work with Gets as they are now implemented in 1304 so this is really a Scanner issue.  To implement this correctly with Gets, we would have to undo basically all the optimizations that Gets do and making them far slower than a Scanner.</description>
			<version>0.20.0</version>
			<fixedVersion>0.90.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.MemStore.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.ColumnTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestKeyValueHeap.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.ScanQueryMatcher.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.ScanWildcardColumnTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.KeyValueScanFixture.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.KeyValueHeap.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.ExplicitColumnTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MinorCompactingStoreScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestExplicitColumnTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestScanWildcardColumnTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.KeyValueScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
		</fixedFiles>
		<links>
			<link type="Blocker" description="is blocked by">2265</link>
			<link type="Blocker" description="is blocked by">2406</link>
			<link type="Reference" description="relates to">997</link>
		</links>
	</bug>
	<bug id="1888" opendate="2009-10-06 14:27:41" fixdate="2010-12-07 22:36:25" resolution="Fixed">
		<buginformation>
			<summary>KeyValue methods throw NullPointerException instead of IllegalArgumentException during parameter sanity check</summary>
			<description>Methods of org.apache.hadoop.hbase.KeyValue
public static int getDelimiter(final byte [] b, int offset, final int length, final int delimiter)
public static int getDelimiterInReverse(final byte [] b, final int offset, final int length, final int delimiter)
throw NullPointerException instead of IllegalArgumentException when byte array b is check for null  - which is very bad practice!
Please refactor this because this can be very misleading.  </description>
			<version>0.20.0</version>
			<fixedVersion>0.92.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.KeyValue.java</file>
		</fixedFiles>
	</bug>
	<bug id="3604" opendate="2011-03-04 11:30:44" fixdate="2011-03-04 19:02:58" resolution="Duplicate">
		<buginformation>
			<summary>Two region servers think that they own the same region: data loss</summary>
			<description>I observed this on a 100 node cluster that is constantly doing about 500K ops/second.
The region server on machine A was servicing IOs for a particular region. Then the machine went into a bad state where it is ping-able but not ssh-able. The master detected that there is a problem with machine A and reassigned the region to machine B. The regionserver on machine B opened the region and opened all the required HFiles for this region. After two hours, the NameNode received a delete request for one of the HFiles from machine A and happily renamed the file to HDFS-Trash. After another 3 hours or so, the regionserver on machine B tried to read contents from that HFile but failed because the file was renamed earlier. The region server on B in now stuck, and possible data loss. 
The problems stems from the fact that although the master-and-ZK reassigned the region, the old regionserver was not possibly dead.</description>
			<version>0.90.0</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.HLogUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.util.FSUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.TestRowProcessorEndpoint.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.WALEdit.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.MiniHBaseCluster.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.WALPlayer.java</file>
			<file type="M">org.apache.hadoop.hbase.TestFullLogReconstruction.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">2231</link>
		</links>
	</bug>
	<bug id="3636" opendate="2011-03-14 18:31:52" fixdate="2011-03-14 21:55:23" resolution="Fixed">
		<buginformation>
			<summary>a bug about deciding whether this key is a new key for the ROWCOL bloomfilter</summary>
			<description>When ROWCOL bloomfilter needs to decide whether this key is a new key or not,
it will call the matchingRowColumn function, which will compare the timestamp offset between this kv and last kv.
But when checking the timestamp offset, it didn&amp;amp;apos;t deduct the original offset of the keyvalue itself.
For example, when 2 keyvalue objects have the same row key and col key, but from different storefiles. It is highly likely that these 2 keyvalue objects have different offset value. So the timestamp offset of these 2 objects are totally different. They will be regard as new keys to add into bloomfilters.
So after compaction, the key count of bloomfilter will increase immediately, which is almost equal to the number of entries.
The solution is straightforward. Just compare the relevant timestamp offset, which is the timestamp offset - key_value offset.
This also may explain this jira: https://issues.apache.org/jira/browse/HBASE-3007</description>
			<version>0.89.20100621</version>
			<fixedVersion>0.90.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.KeyValue.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">3007</link>
			<link type="Incorporates" description="incorporates">3665</link>
		</links>
	</bug>
	<bug id="3007" opendate="2010-09-16 19:49:41" fixdate="2011-03-17 19:35:40" resolution="Duplicate">
		<buginformation>
			<summary>StoreFile Blooms are Being Stored Undersized</summary>
			<description>While looking through error logs today, I noticed the following line.


 2010-09-16 04:12:26,401 INFO org.apache.hadoop.hbase.regionserver.StoreFile: Bloom added to HFile.  9600B, 10292/6933 (148%) 


The last 3 numbers are: # of keys in bloom, # of keys preallocated for bloom, % full.  The last number should never be &amp;gt; 100%.  Oversized blooms will cause increased false positives.  Note that this occurred on a Row+Col bloom.  Will provide more details after further instrumentation.</description>
			<version>0.89.20100621</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.KeyValue.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">3636</link>
		</links>
	</bug>
	<bug id="3497" opendate="2011-02-01 22:32:02" fixdate="2011-03-24 21:03:47" resolution="Fixed">
		<buginformation>
			<summary>TableMapReduceUtil.initTableReducerJob broken due to setConf method in TableOutputFormat</summary>
			<description>setConf() method in TableOutputFormat gets called and it replaces the hbase.zookeeper.quorum address in the job conf xml when you run a CopyTable job from one cluster to another. The conf gets set to the peer.addr that is specified, which makes the job read and write from/to the peer cluster instead of reading from the original cluster and writing to the peer.
Possibly caused due to the change in https://issues.apache.org/jira/browse/HBASE-3111</description>
			<version>0.90.0</version>
			<fixedVersion>0.90.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TableOutputFormat.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">4834</link>
		</links>
	</bug>
	<bug id="3920" opendate="2011-05-24 21:52:43" fixdate="2011-05-25 04:50:21" resolution="Fixed">
		<buginformation>
			<summary>HLog hbase.regionserver.flushlogentries no longer supported</summary>
			<description>While searching for config options on syncing the HLog, I was a bit confused by hbase.regionserver.flushlogentries which is still in the code and in hbase-default.xml but isn&amp;amp;apos;t actually used.</description>
			<version>0.92.0</version>
			<fixedVersion>0.90.4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestWALReplay.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.TestWALObserver.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestHLogSplit.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestHLog.java</file>
			<file type="M">org.apache.hadoop.hbase.TestFullLogReconstruction.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">3885</link>
		</links>
	</bug>
	<bug id="3885" opendate="2011-05-14 03:48:54" fixdate="2011-05-31 20:08:28" resolution="Duplicate">
		<buginformation>
			<summary>Remove hbase.regionserver.flushlogentries, its not used</summary>
			<description></description>
			<version>0.92.0</version>
			<fixedVersion>0.90.4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestWALReplay.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.TestWALObserver.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestHLogSplit.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestHLog.java</file>
			<file type="M">org.apache.hadoop.hbase.TestFullLogReconstruction.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">3920</link>
		</links>
	</bug>
	<bug id="4055" opendate="2011-07-01 23:50:42" fixdate="2011-07-05 16:58:35" resolution="Duplicate">
		<buginformation>
			<summary>Client region location caches redundant HTableDescriptor&amp;apos;s</summary>
			<description>While examining the heap of a map task in a MapReduce job that writes directly to HBase, I noticed that the HRegionLocation instances were taking up 90 MB (out of a 700 MB heap for each map task) to cache the locations for 15K regions.  As the number of regions in the cluster continues to grow, this continues to grow as well.
Of that, it appears that about 80 MB were going to 15K HTableDescriptor instances.  There are only 5 tables that it&amp;amp;apos;s writing to, so it seems to be wasting a great deal of memory with a separate copy of the table descriptor for each region.</description>
			<version>0.90.3</version>
			<fixedVersion>0.92.0</fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegionInfo.java</file>
			<file type="M">org.apache.hadoop.hbase.HRegionInfo.java</file>
			<file type="M">org.apache.hadoop.hbase.util.FSUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestFSTableDescriptors.java</file>
			<file type="M">org.apache.hadoop.hbase.MultiRegionTable.java</file>
			<file type="M">org.apache.hadoop.hbase.avro.AvroServer.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestMergeTable.java</file>
			<file type="M">org.apache.hadoop.hbase.avro.TestAvroServer.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestMergeTool.java</file>
			<file type="M">org.apache.hadoop.hbase.master.handler.TableAddFamilyHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="M">org.apache.hadoop.hbase.TestRegionRebalancing.java</file>
			<file type="M">org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
			<file type="M">org.apache.hadoop.hbase.master.MasterServices.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.java</file>
			<file type="M">org.apache.hadoop.hbase.util.HMerge.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestSplitTransaction.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
			<file type="M">org.apache.hadoop.hbase.master.CatalogJanitor.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.master.handler.ModifyTableHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.handler.OpenMetaHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.handler.OpenRootHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.handler.TestOpenRegionHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestStore.java</file>
			<file type="M">org.apache.hadoop.hbase.master.AssignmentManager.java</file>
			<file type="M">org.apache.hadoop.hbase.util.MetaUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.master.handler.DeleteTableHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestWALReplay.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseTestCase.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestCompactSelection.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.TestCoprocessorInterface.java</file>
			<file type="M">org.apache.hadoop.hbase.master.handler.TableModifyFamilyHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.master.handler.TableDeleteFamilyHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.util.Merge.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.TestWALObserver.java</file>
			<file type="M">org.apache.hadoop.hbase.master.SplitLogManager.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestWALObserver.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
			<file type="M">org.apache.hadoop.hbase.util.HBaseFsck.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
			<file type="M">org.apache.hadoop.hbase.catalog.MetaEditor.java</file>
			<file type="M">org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestWideScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.TestColumnPrefixFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestScannerTimeout.java</file>
			<file type="M">org.apache.hadoop.hbase.util.Writables.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HConnection.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
			<file type="M">org.apache.hadoop.hbase.master.handler.OpenedRegionHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.master.handler.ClosedRegionHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestRSStatusServlet.java</file>
			<file type="M">org.apache.hadoop.hbase.HConstants.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestMasterStatusServlet.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestTimestamp.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestHLog.java</file>
			<file type="M">org.apache.hadoop.hbase.client.MetaScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.Replication.java</file>
			<file type="M">org.apache.hadoop.hbase.client.UnmodifyableHRegionInfo.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.LogRoller.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManager.java</file>
			<file type="M">org.apache.hadoop.hbase.io.HbaseObjectWritable.java</file>
			<file type="M">org.apache.hadoop.hbase.TimestampTestBase.java</file>
			<file type="M">org.apache.hadoop.hbase.TestCompare.java</file>
			<file type="M">org.apache.hadoop.hbase.TestScanMultipleVersions.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.TestRegionObserverStacking.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.TestDependentColumnFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.WALObserver.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestMultipleTimestamps.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestResettingCounters.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
			<file type="M">org.apache.hadoop.hbase.TestSerialization.java</file>
			<file type="M">org.apache.hadoop.hbase.util.RegionSplitter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.TestFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.catalog.MetaReader.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestColumnSeeking.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.TestRegionObserverInterface.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestGetClosestAtOrBefore.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestLoadBalancer.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.model.TestTableRegionModel.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.HMasterInterface.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">451</link>
		</links>
	</bug>
	<bug id="451" opendate="2008-02-15 01:16:21" fixdate="2011-07-14 22:55:26" resolution="Fixed">
		<buginformation>
			<summary>Remove HTableDescriptor from HRegionInfo</summary>
			<description>There is an HRegionInfo for every region in HBase. Currently HRegionInfo also contains the HTableDescriptor (the schema). That means we store the schema n times where n is the number of regions in the table.
Additionally, for every region of the same table that the region server has open, there is a copy of the schema. Thus it is stored in memory once for each open region.
If HRegionInfo merely contained the table name the HTableDescriptor could be stored in a separate file and easily found.</description>
			<version>0.2.0</version>
			<fixedVersion>0.92.0</fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegionInfo.java</file>
			<file type="M">org.apache.hadoop.hbase.HRegionInfo.java</file>
			<file type="M">org.apache.hadoop.hbase.util.FSUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestFSTableDescriptors.java</file>
			<file type="M">org.apache.hadoop.hbase.MultiRegionTable.java</file>
			<file type="M">org.apache.hadoop.hbase.avro.AvroServer.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestMergeTable.java</file>
			<file type="M">org.apache.hadoop.hbase.avro.TestAvroServer.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestMergeTool.java</file>
			<file type="M">org.apache.hadoop.hbase.master.handler.TableAddFamilyHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="M">org.apache.hadoop.hbase.TestRegionRebalancing.java</file>
			<file type="M">org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
			<file type="M">org.apache.hadoop.hbase.master.MasterServices.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter.java</file>
			<file type="M">org.apache.hadoop.hbase.util.HMerge.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestSplitTransaction.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.SplitTransaction.java</file>
			<file type="M">org.apache.hadoop.hbase.master.CatalogJanitor.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.master.handler.ModifyTableHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.handler.OpenMetaHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.handler.OpenRootHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.handler.TestOpenRegionHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestStore.java</file>
			<file type="M">org.apache.hadoop.hbase.master.AssignmentManager.java</file>
			<file type="M">org.apache.hadoop.hbase.util.MetaUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.master.handler.DeleteTableHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestWALReplay.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseTestCase.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestCompactSelection.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.TestCoprocessorInterface.java</file>
			<file type="M">org.apache.hadoop.hbase.master.handler.TableModifyFamilyHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.master.handler.TableDeleteFamilyHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.util.Merge.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.TestWALObserver.java</file>
			<file type="M">org.apache.hadoop.hbase.master.SplitLogManager.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestWALObserver.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
			<file type="M">org.apache.hadoop.hbase.util.HBaseFsck.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
			<file type="M">org.apache.hadoop.hbase.catalog.MetaEditor.java</file>
			<file type="M">org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestWideScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.TestColumnPrefixFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestScannerTimeout.java</file>
			<file type="M">org.apache.hadoop.hbase.util.Writables.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HConnection.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
			<file type="M">org.apache.hadoop.hbase.master.handler.OpenedRegionHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.master.handler.ClosedRegionHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestRSStatusServlet.java</file>
			<file type="M">org.apache.hadoop.hbase.HConstants.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestMasterStatusServlet.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestTimestamp.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestHLog.java</file>
			<file type="M">org.apache.hadoop.hbase.client.MetaScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.Replication.java</file>
			<file type="M">org.apache.hadoop.hbase.client.UnmodifyableHRegionInfo.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.LogRoller.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManager.java</file>
			<file type="M">org.apache.hadoop.hbase.io.HbaseObjectWritable.java</file>
			<file type="M">org.apache.hadoop.hbase.TimestampTestBase.java</file>
			<file type="M">org.apache.hadoop.hbase.TestCompare.java</file>
			<file type="M">org.apache.hadoop.hbase.TestScanMultipleVersions.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.TestRegionObserverStacking.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.TestDependentColumnFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.WALObserver.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestMultipleTimestamps.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestResettingCounters.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
			<file type="M">org.apache.hadoop.hbase.TestSerialization.java</file>
			<file type="M">org.apache.hadoop.hbase.util.RegionSplitter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.TestFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.catalog.MetaReader.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestColumnSeeking.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.TestRegionObserverInterface.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestGetClosestAtOrBefore.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestLoadBalancer.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.model.TestTableRegionModel.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.HMasterInterface.java</file>
		</fixedFiles>
		<links>
			<link type="Blocker" description="blocks">922</link>
			<link type="Blocker" description="blocks">3970</link>
			<link type="Blocker" description="blocks">484</link>
			<link type="Blocker" description="is blocked by">546</link>
			<link type="Duplicate" description="is duplicated by">565</link>
			<link type="Duplicate" description="is duplicated by">4055</link>
			<link type="Incorporates" description="is part of">1816</link>
			<link type="Reference" description="is related to">4032</link>
			<link type="Reference" description="is related to">5204</link>
		</links>
	</bug>
	<bug id="4536" opendate="2011-10-03 23:10:56" fixdate="2011-10-21 19:55:30" resolution="Fixed">
		<buginformation>
			<summary>Allow CF to retain deleted rows</summary>
			<description>Parent allows for a cluster to retain rows for a TTL or keep a minimum number of versions.
However, if a client deletes a row all version older than the delete tomb stone will be remove at the next major compaction (and even at memstore flush - see HBASE-4241).
There should be a way to retain those version to guard against software error.
I see two options here:
1. Add a new flag HColumnDescriptor. Something like "RETAIN_DELETED".
2. Folds this into the parent change. I.e. keep minimum-number-of-versions of versions even past the delete marker.
#1 would allow for more flexibility. #2 comes somewhat naturally with parent (from a user viewpoint)
Comments? Any other options?</description>
			<version>0.92.0</version>
			<fixedVersion>0.94.0</fixedVersion>
			<type>New Feature</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestMinVersions.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestQueryMatcher.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.ExplicitColumnTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestStoreScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.client.Attributes.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.ScanQueryMatcher.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.ScanWildcardColumnTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.client.Scan.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestExplicitColumnTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.ColumnTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.KeyValue.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestScanWildcardColumnTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestMemStore.java</file>
			<file type="M">org.apache.hadoop.hbase.HColumnDescriptor.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseTestCase.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">848</link>
			<link type="Reference" description="relates to">3443</link>
			<link type="Reference" description="relates to">2376</link>
			<link type="Reference" description="relates to">4721</link>
		</links>
	</bug>
	<bug id="3939" opendate="2011-06-01 01:53:13" fixdate="2011-11-06 21:49:57" resolution="Fixed">
		<buginformation>
			<summary>Some crossports of Hadoop IPC fixes</summary>
			<description>A few fixes from Hadoop IPC that we should probably cross-port into our copy:

HADOOP-7227: remove the protocol version check at call time
HADOOP-7146: fix a socket leak in server
HADOOP-7121: fix behavior when response serialization throws an exception
HADOOP-7346: send back nicer error response when client is using an out of date IPC version

</description>
			<version>0.92.0</version>
			<fixedVersion>0.92.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.CoprocessorProtocol.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.AggregateProtocol.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.Invocation.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.WritableRpcEngine.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.HBaseClient.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.TestDelayedRpc.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestServerCustomProtocol.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.VersionedProtocol.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.AggregateImplementation.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.BaseEndpointCoprocessor.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.HBaseServer.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">1913</link>
			<link type="Reference" description="is related to">4777</link>
		</links>
	</bug>
	<bug id="4627" opendate="2011-10-19 21:54:43" fixdate="2011-11-11 00:47:07" resolution="Fixed">
		<buginformation>
			<summary>Ability to specify a custom start/end to RegionSplitter</summary>
			<description>HBASE-4489 changed the default endKey on HexStringSplit from 7FFF... to FFFF...  While this is correct, existing users of 0.90 RegionSplitter have 7FFF as the end key in their schema and the last region will not split properly under this new code.  We need to let the user specify a custom start/end key range for when situations like this arise.  Optimally, we should also write the start/end key in META so we could figure this out implicitly instead of requiring the user to explicitly specify it.</description>
			<version>0.94.0</version>
			<fixedVersion>0.94.0</fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.RegionSplitter.java</file>
			<file type="M">org.apache.hadoop.hbase.util.Bytes.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestRegionSplitter.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">3778</link>
			<link type="Reference" description="relates to">4489</link>
		</links>
	</bug>
	<bug id="4834" opendate="2011-11-20 17:57:09" fixdate="2011-11-20 19:01:23" resolution="Duplicate">
		<buginformation>
			<summary>CopyTable: Cannot have ZK source to destination</summary>
			<description>During a Copy Table, involving --peer.adr, we found the following block of code:
if (address != null) 
{
        ZKUtil.applyClusterKeyToConf(this.conf, address);
   }

When we set ZK conf in setConf method, that also gets called in frontend when MR initializes TOF, so there&amp;amp;apos;s no way now to have two ZK points for a single job, cause source gets reset before job is submitted.</description>
			<version>0.90.1</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TableOutputFormat.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">3497</link>
		</links>
	</bug>
	<bug id="5062" opendate="2011-12-18 00:42:51" fixdate="2011-12-19 16:26:53" resolution="Fixed">
		<buginformation>
			<summary>Missing logons if security is enabled</summary>
			<description>Somehow the attached changes are missing from the security integration. </description>
			<version>0.92.0</version>
			<fixedVersion>0.92.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
			<file type="M">org.apache.hadoop.hbase.util.Strings.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.Main.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">4099</link>
			<link type="Duplicate" description="is duplicated by">4100</link>
		</links>
	</bug>
	<bug id="848" opendate="2008-08-27 20:40:46" fixdate="2012-01-02 03:02:46" resolution="Duplicate">
		<buginformation>
			<summary>API to inspect cell deletions</summary>
			<description>If a cell gets deleted, I&amp;amp;apos;d like to have some API that gives me the deletion timestamp, as well as any versions that predate the deletion.  
One possibility might be to add a boolean flag to HTable.get</description>
			<version>0.2.0</version>
			<fixedVersion></fixedVersion>
			<type>New Feature</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestMinVersions.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestQueryMatcher.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.ExplicitColumnTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestStoreScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.client.Attributes.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.ScanQueryMatcher.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.ScanWildcardColumnTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.client.Scan.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestExplicitColumnTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.ColumnTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.KeyValue.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestScanWildcardColumnTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestMemStore.java</file>
			<file type="M">org.apache.hadoop.hbase.HColumnDescriptor.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseTestCase.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">4981</link>
			<link type="Duplicate" description="is duplicated by">4536</link>
		</links>
	</bug>
	<bug id="5128" opendate="2012-01-05 02:37:28" fixdate="2012-03-23 23:56:03" resolution="Fixed">
		<buginformation>
			<summary>[uber hbck] Online automated repair of table integrity and region consistency problems</summary>
			<description>The current (0.90.5, 0.92.0rc2) versions of hbck detects most of region consistency and table integrity invariant violations.  However with &amp;amp;apos;-fix&amp;amp;apos; it can only automatically repair region consistency cases having to do with deployment problems.  This updated version should be able to handle all cases (including a new orphan regiondir case).  When complete will likely deprecate the OfflineMetaRepair tool and subsume several open META-hole related issue.
Here&amp;amp;apos;s the approach (from the comment of at the top of the new version of the file).


/**
 * HBaseFsck (hbck) is a tool for checking and repairing region consistency and
 * table integrity.  
 * 
 * Region consistency checks verify that META, region deployment on
 * region servers and the state of data in HDFS (.regioninfo files) all are in
 * accordance. 
 * 
 * Table integrity checks verify that that all possible row keys can resolve to
 * exactly one region of a table.  This means there are no individual degenerate
 * or backwards regions; no holes between regions; and that there no overlapping
 * regions. 
 * 
 * The general repair strategy works in these steps.
 * 1) Repair Table Integrity on HDFS. (merge or fabricate regions)
 * 2) Repair Region Consistency with META and assignments
 * 
 * For table integrity repairs, the tables their region directories are scanned
 * for .regioninfo files.  Each table&amp;amp;apos;s integrity is then verified.  If there 
 * are any orphan regions (regions with no .regioninfo files), or holes, new 
 * regions are fabricated.  Backwards regions are sidelined as well as empty
 * degenerate (endkey==startkey) regions.  If there are any overlapping regions,
 * a new region is created and all data is merged into the new region.  
 * 
 * Table integrity repairs deal solely with HDFS and can be done offline -- the
 * hbase region servers or master do not need to be running.  These phase can be
 * use to completely reconstruct the META table in an offline fashion. 
 * 
 * Region consistency requires three conditions -- 1) valid .regioninfo file 
 * present in an hdfs region dir,  2) valid row with .regioninfo data in META,
 * and 3) a region is deployed only at the regionserver that is was assigned to.
 * 
 * Region consistency requires hbck to contact the HBase master and region
 * servers, so the connect() must first be called successfully.  Much of the
 * region consistency information is transient and less risky to repair.
 */


</description>
			<version>0.90.5</version>
			<fixedVersion>0.94.0, 0.95.0</fixedVersion>
			<type>New Feature</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildHole.java</file>
			<file type="M">org.apache.hadoop.hbase.master.AssignmentManager.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFile.java</file>
			<file type="M">org.apache.hadoop.hbase.util.hbck.OfflineMetaRepair.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
			<file type="M">org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildBase.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.HMasterInterface.java</file>
			<file type="M">org.apache.hadoop.hbase.util.HBaseFsck.java</file>
			<file type="M">org.apache.hadoop.hbase.util.HBaseFsckRepair.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestHBaseFsckComparator.java</file>
			<file type="M">org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildOverlap.java</file>
			<file type="M">org.apache.hadoop.hbase.util.hbck.HbckTestingUtil.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">4094</link>
			<link type="Reference" description="relates to">5599</link>
			<link type="Reference" description="relates to">5719</link>
			<link type="Reference" description="relates to">5628</link>
			<link type="Reference" description="relates to">5630</link>
			<link type="Reference" description="is related to">1621</link>
			<link type="Reference" description="is related to">4379</link>
			<link type="Required" description="requires">5563</link>
			<link type="Required" description="requires">5588</link>
			<link type="Required" description="requires">5589</link>
			<link type="dependent" description="is depended upon by">5781</link>
			<link type="dependent" description="is depended upon by">5634</link>
		</links>
	</bug>
	<bug id="4094" opendate="2011-07-14 08:39:34" fixdate="2012-04-14 12:51:08" resolution="Duplicate">
		<buginformation>
			<summary>improve hbck tool to fix more hbase problem</summary>
			<description>The hbck tool(org.apache.hadoop.hbase.util.HBaseFsck) can check and repair consistency problem.
some error just be checked but not supply the way to repair, I plan to fix it by other tool(close_region...)or by new method.
First, list it and discuss that is it right?
Part A:check meta info
1.errors.reportError(ERROR_CODE.NULL_ROOT_REGION,"Root Region or some of its attributes are null."); 
		 ------&amp;gt; after delete the root table,execute hbck tool to check but the tool run error. how to reproduce this error?
2.errors.reportError(ERROR_CODE.NO_META_REGION, ".META. is not found on any region.");
         ------&amp;gt;after delete the meta table,execute hbck tool to check but the tool run error. how to reproduce this error?
3.errors.reportError(ERROR_CODE.MULTI_META_REGION, ".META. is found on more than one region.");
		 -----&amp;gt;the logic:scan the root table to get META table regioninfo,if META table&amp;amp;apos;s regions is more than one,throw the error.
					  HBase allow META table has more than one region,is it?
Part B:check Consistency
4.ERROR_CODE.NOT_IN_META_HDFS----&amp;gt;close it from regionserver.
5.ERROR_CODE.NOT_IN_META_OR_DEPLOYED----&amp;gt;do nothing,maybe it will be used to fix the chain hole in part C.
6.ERROR_CODE.NOT_IN_META----&amp;gt;close it from regionserver.
7.ERROR_CODE.NOT_IN_HDFS_OR_DEPLOYED----&amp;gt;delete it from META table,it will make a chain hole, when check chain integrity(in part C) to fix it.
8.ERROR_CODE.NOT_IN_HDFS----&amp;gt;delete it from META table and close it from regionserver,when check chain integrity(in part C) to fix it.
9.ERROR_CODE.NOT_DEPLOYED----&amp;gt;assign it.
10.ERROR_CODE.SHOULD_NOT_BE_DEPLOYED----&amp;gt;delete if from META table and close it from regionserver.
11.ERROR_CODE.MULTI_DEPLOYED---&amp;gt;close all from regionservers,and reassign it.
12.ERROR_CODE.SERVER_DOES_NOT_MATCH_META----&amp;gt;close all from regionservers,and reassign it.
Part C:check chain Integrity
13.ERROR_CODE.FIRST_REGION_STARTKEY_NOT_EMPTY---&amp;gt;treat it as a hole problem(ERROR_CODE.HOLE_IN_REGION_CHAIN).
14.ERROR_CODE.LAST_REGION_ENDKEY_NOT_EMPTY(new add)---&amp;gt;treat it as a hole problem(ERROR_CODE.HOLE_IN_REGION_CHAIN).
15.ERROR_CODE.REGION_CYCLE----&amp;gt;shut down cluster and merge two region by merge tool(org.apache.hadoop.hbase.util.Merge)
16.ERROR_CODE.DUPE_STARTKEYS---&amp;gt;shut down cluster and merge two region by merge tool(org.apache.hadoop.hbase.util.Merge)
17.ERROR_CODE.OVERLAP_IN_REGION_CHAIN---&amp;gt;shut down cluster and merge two region by merge tool(org.apache.hadoop.hbase.util.Merge)
18.ERROR_CODE.HOLE_IN_REGION_CHAIN---&amp;gt;write a new method to fix it,the logic is:for recover the data,collect the regionfo from regionserver and hdfs.if a region&amp;amp;apos;s key range is overlaping with the hole range,put it in META table and assign it,maybe it will create overlapping problem,we can fix it by merge tool.if no region be collected,create a new region by the hole key range to fix it.</description>
			<version>0.90.3</version>
			<fixedVersion></fixedVersion>
			<type>New Feature</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildHole.java</file>
			<file type="M">org.apache.hadoop.hbase.master.AssignmentManager.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFile.java</file>
			<file type="M">org.apache.hadoop.hbase.util.hbck.OfflineMetaRepair.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
			<file type="M">org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildBase.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.HMasterInterface.java</file>
			<file type="M">org.apache.hadoop.hbase.util.HBaseFsck.java</file>
			<file type="M">org.apache.hadoop.hbase.util.HBaseFsckRepair.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestHBaseFsckComparator.java</file>
			<file type="M">org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildOverlap.java</file>
			<file type="M">org.apache.hadoop.hbase.util.hbck.HbckTestingUtil.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">5128</link>
		</links>
	</bug>
	<bug id="5337" opendate="2012-02-05 05:58:36" fixdate="2012-05-09 05:17:06" resolution="Duplicate">
		<buginformation>
			<summary>AM.updateTimers() delays the timeout monitor from assigning regions.</summary>
			<description>AM.updateTimers() is necessary when the new RS has joined the cluster and there are more regions to be assigned to it.  The updateTimer will help the TM from not picking up these regions because they are still in the process of assignment.
But if in 0.90 we have 30min as TM period then this step of updating the timers further delays the assignment.
I think we can remove the call for updateTimer in 0.90 till we decide to change the TM period.</description>
			<version>0.90.5</version>
			<fixedVersion>0.90.7</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.AssignmentManager.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">5970</link>
		</links>
	</bug>
	<bug id="6086" opendate="2012-05-24 04:55:39" fixdate="2012-05-25 04:53:13" resolution="Duplicate">
		<buginformation>
			<summary>Admin operations on a table should be authorized against table permissions instead of global permissions.</summary>
			<description>Still some inconsistency exists after HBASE-6061. We actually need to authorize against table permissions instead of global permissions here.


+  private void requireTableAdminPermission(MasterCoprocessorEnvironment e,
+      byte[] tableName) throws IOException {
+    if (isActiveUserTableOwner(e, tableName)) {
+      requirePermission(Permission.Action.CREATE);
+    } else {
+      requirePermission(Permission.Action.ADMIN);
+    }
+  }

</description>
			<version>0.94.0</version>
			<fixedVersion></fixedVersion>
			<type>Sub-task</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.security.access.AccessController.java</file>
			<file type="M">org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">5372</link>
			<link type="Reference" description="relates to">6068</link>
		</links>
	</bug>
	<bug id="5970" opendate="2012-05-09 04:44:58" fixdate="2012-05-31 05:48:17" resolution="Fixed">
		<buginformation>
			<summary>Improve the AssignmentManager#updateTimer and speed up handling opened event</summary>
			<description>We found handing opened event very slow in the environment with lots of regions.
The problem is the slow AssignmentManager#updateTimer.
We do the test for bulk assigning 10w (i.e. 100k) regions, the whole process of bulk assigning took 1 hours.
2012-05-06 20:31:49,201 INFO org.apache.hadoop.hbase.master.AssignmentManager: Bulk assigning 100000 region(s) round-robin across 5 server(s)
2012-05-06 21:26:32,103 INFO org.apache.hadoop.hbase.master.AssignmentManager: Bulk assigning done
I think we could do the improvement for the AssignmentManager#updateTimer: Make a thread do this work.
After the improvement, it took only 4.5mins
2012-05-07 11:03:36,581 INFO org.apache.hadoop.hbase.master.AssignmentManager: Bulk assigning 100000 region(s) across 5 server(s), retainAssignment=true 
2012-05-07 11:07:57,073 INFO org.apache.hadoop.hbase.master.AssignmentManager: Bulk assigning done </description>
			<version>0.90.5</version>
			<fixedVersion>0.95.0</fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.AssignmentManager.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">5337</link>
			<link type="Reference" description="relates to">7038</link>
			<link type="Reference" description="is related to">5843</link>
		</links>
	</bug>
	<bug id="5372" opendate="2012-02-09 23:16:20" fixdate="2012-06-09 18:16:20" resolution="Fixed">
		<buginformation>
			<summary>Table mutation operations should check table level rights, not global rights </summary>
			<description>drop/modify/disable/enable etc table operations should not check for global CREATE/ADMIN rights, but table CREATE/ADMIN rights. Since we check for global permissions first for table permissions, configuring table access using global permissions will continue to work. </description>
			<version>0.94.0</version>
			<fixedVersion>0.94.1, 0.95.0</fixedVersion>
			<type>Sub-task</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.security.access.AccessController.java</file>
			<file type="M">org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">6086</link>
			<link type="Reference" description="is related to">6209</link>
		</links>
	</bug>
	<bug id="6166" opendate="2012-06-05 21:16:29" fixdate="2012-06-26 18:41:31" resolution="Duplicate">
		<buginformation>
			<summary>Allow thrift to start wih the server type specified in config</summary>
			<description>Currently the thrift server type must be specified on the command line.  If it&amp;amp;apos;s already in config it shouldn&amp;amp;apos;t be needed.</description>
			<version>0.94.0</version>
			<fixedVersion></fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">6263</link>
		</links>
	</bug>
	<bug id="6265" opendate="2012-06-25 11:16:04" fixdate="2012-07-02 08:39:03" resolution="Fixed">
		<buginformation>
			<summary>Calling getTimestamp() on a KV in cp.prePut() causes KV not to be flushed</summary>
			<description>There is an issue when you call getTimestamp() on any KV handed into a Coprocessor&amp;amp;apos;s prePut(). It initializes the internal "timestampCache" variable. 
When you then pass it to the normal processing, the region server sets the time to the server time in case you have left it unset from the client side (updateLatestStamp() call). 
The TimeRangeTracker then calls getTimestamp() later on to see if it has to include the KV, but instead of getting the proper time it sees the cached timestamp from the prePut() call.</description>
			<version>0.92.0</version>
			<fixedVersion>0.94.1, 0.95.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.TestKeyValue.java</file>
			<file type="M">org.apache.hadoop.hbase.KeyValue.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">7774</link>
		</links>
	</bug>
	<bug id="6196" opendate="2012-06-11 07:19:46" fixdate="2012-07-02 18:21:07" resolution="Duplicate">
		<buginformation>
			<summary>MR testcases TestImportExport does not run in Trunk with hadoop2.0</summary>
			<description>TEstImportExport test cases does not run in trunk when compiled with hadoop 2.0</description>
			<version>0.94.0</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.MapreduceTestingShim.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TestImportExport.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">5876</link>
		</links>
	</bug>
	<bug id="5876" opendate="2012-04-25 19:03:00" fixdate="2012-07-05 07:31:41" resolution="Fixed">
		<buginformation>
			<summary>TestImportExport has been failing against hadoop 0.23 profile</summary>
			<description>TestImportExport has been failing against hadoop 0.23 profile</description>
			<version>0.94.0</version>
			<fixedVersion>0.94.1, 0.95.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.MapreduceTestingShim.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TestImportExport.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">6196</link>
			<link type="Reference" description="relates to">5870</link>
			<link type="dependent" description="is depended upon by">6307</link>
		</links>
	</bug>
	<bug id="6151" opendate="2012-06-02 00:51:46" fixdate="2012-07-13 00:48:01" resolution="Duplicate">
		<buginformation>
			<summary>Master can die if RegionServer throws ServerNotRunningYet</summary>
			<description>See, for example:

2012-05-23 16:49:22,745 FATAL org.apache.hadoop.hbase.master.HMaster: Unhandled exception. Starting shutdown.
org.apache.hadoop.hbase.ipc.ServerNotRunningException: org.apache.hadoop.hbase.ipc.ServerNotRunningException: Server is not running yet
	at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1038)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.hbase.RemoteExceptionHandler.decodeRemoteException(RemoteExceptionHandler.java:96)
	at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getHRegionConnection(HConnectionManager.java:1240)
	at org.apache.hadoop.hbase.catalog.CatalogTracker.getCachedConnection(CatalogTracker.java:444)
	at org.apache.hadoop.hbase.catalog.CatalogTracker.getMetaServerConnection(CatalogTracker.java:343)
	at org.apache.hadoop.hbase.catalog.CatalogTracker.verifyMetaRegionLocation(CatalogTracker.java:540)
	at org.apache.hadoop.hbase.master.HMaster.assignRootAndMeta(HMaster.java:474)
	at org.apache.hadoop.hbase.master.HMaster.finishInitialization(HMaster.java:412)


The HRegionServer calls HBaseServer:


  public void start() {
    startThreads();
    openServer();
  }


but the server can start accepting RPCs once the threads have been started, but if they do, they throw ServerNotRunningException until openServer runs.  We should probably
1) Catch the remote exception and retry on the master
2) Look into whether the start() behavior of HBaseServer makes any sense.  Why would you start accepting RPCs only to throw back ServerNotRunningException?</description>
			<version>0.90.7</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.catalog.TestCatalogTracker.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">4470</link>
		</links>
	</bug>
	<bug id="4470" opendate="2011-09-23 17:54:15" fixdate="2012-07-23 07:21:41" resolution="Fixed">
		<buginformation>
			<summary>ServerNotRunningException coming out of assignRootAndMeta kills the Master</summary>
			<description>I&amp;amp;apos;m surprised we still have issues like that and I didn&amp;amp;apos;t get a hit while googling so forgive me if there&amp;amp;apos;s already a jira about it.
When the master starts it verifies the locations of root and meta before assigning them, if the server is started but not running you&amp;amp;apos;ll get this:

2011-09-23 04:47:44,859 WARN org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation: RemoteException connecting to RS
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.hbase.ipc.ServerNotRunningException: Server is not running yet
        at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1038)
        at org.apache.hadoop.hbase.ipc.HBaseClient.call(HBaseClient.java:771)
        at org.apache.hadoop.hbase.ipc.HBaseRPC$Invoker.invoke(HBaseRPC.java:257)
        at $Proxy6.getProtocolVersion(Unknown Source)
        at org.apache.hadoop.hbase.ipc.HBaseRPC.getProxy(HBaseRPC.java:419)
        at org.apache.hadoop.hbase.ipc.HBaseRPC.getProxy(HBaseRPC.java:393)
        at org.apache.hadoop.hbase.ipc.HBaseRPC.getProxy(HBaseRPC.java:444)
        at org.apache.hadoop.hbase.ipc.HBaseRPC.waitForProxy(HBaseRPC.java:349)
        at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getHRegionConnection(HConnectionManager.java:969)
        at org.apache.hadoop.hbase.catalog.CatalogTracker.getCachedConnection(CatalogTracker.java:388)
        at org.apache.hadoop.hbase.catalog.CatalogTracker.getMetaServerConnection(CatalogTracker.java:287)
        at org.apache.hadoop.hbase.catalog.CatalogTracker.verifyMetaRegionLocation(CatalogTracker.java:484)
        at org.apache.hadoop.hbase.master.HMaster.assignRootAndMeta(HMaster.java:441)
        at org.apache.hadoop.hbase.master.HMaster.finishInitialization(HMaster.java:388)
        at org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:282)
I hit that 3-4 times this week while debugging something else. The worst is that when you restart the master it sees that as a failover, but none of the regions are assigned so it takes an eternity to get back fully online.</description>
			<version>0.90.4</version>
			<fixedVersion>0.92.2, 0.94.1, 0.95.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.catalog.TestCatalogTracker.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">6151</link>
			<link type="Reference" description="relates to">5883</link>
		</links>
	</bug>
	<bug id="6263" opendate="2012-06-22 23:33:41" fixdate="2012-08-15 19:31:34" resolution="Fixed">
		<buginformation>
			<summary>Use default mode for HBase Thrift gateway if not specified</summary>
			<description>The Thrift gateway should start with a default mode if one is not selected. Currently, instead we see:

Exception in thread "main" java.lang.AssertionError: Exactly one option out of [-hsha, -nonblocking, -threadpool, -threadedselector] has to be specified
	at org.apache.hadoop.hbase.thrift.ThriftServerRunner$ImplType.setServerImpl(ThriftServerRunner.java:201)
	at org.apache.hadoop.hbase.thrift.ThriftServer.processOptions(ThriftServer.java:169)
	at org.apache.hadoop.hbase.thrift.ThriftServer.doMain(ThriftServer.java:85)
	at org.apache.hadoop.hbase.thrift.ThriftServer.main(ThriftServer.java:192)


See also BIGTOP-648. </description>
			<version>0.94.0</version>
			<fixedVersion>0.94.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">6166</link>
			<link type="Reference" description="relates to">648</link>
			<link type="dependent" description="is depended upon by">960</link>
		</links>
	</bug>
	<bug id="6565" opendate="2012-08-13 06:18:42" fixdate="2012-08-16 18:49:09" resolution="Fixed">
		<buginformation>
			<summary>Coprocessor exec result Map is not thread safe</summary>
			<description>I develop a coprocessor program ,but found some different results in repeated tests.for example,normally,the result&amp;amp;apos;s size is 10.but sometimes it appears 9.
I read the HTable.java code,found a TreeMap(thread-unsafe) be used in multithreading environment.It cause the bug happened</description>
			<version>0.92.2</version>
			<fixedVersion>0.94.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">6280</link>
		</links>
	</bug>
	<bug id="5820" opendate="2012-04-18 13:47:47" fixdate="2012-08-17 15:49:41" resolution="Duplicate">
		<buginformation>
			<summary>hbck should check fs owner/permissions.</summary>
			<description>In some cases, hbck needs to be run as a user that has write perms to the file system.  If it writes data to hbase&amp;amp;apos;s directories, it may write new files/dirs that the hbase processes&amp;amp;apos;s user does not have permissions to.  We should alert the user of this situation.</description>
			<version>0.90.6</version>
			<fixedVersion></fixedVersion>
			<type>New Feature</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.FSUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.util.HBaseFsck.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">5714</link>
		</links>
	</bug>
	<bug id="5714" opendate="2012-04-04 16:33:06" fixdate="2012-08-20 21:37:33" resolution="Fixed">
		<buginformation>
			<summary>Add write permissions check before any hbck run that modifies hdfs.</summary>
			<description>We encoutered a situation where hbck was run by an under-privileged user that was unable to write/modify/merge regions due to hdfs perms.  Unfortunately, this user was alerted of this  after several minutes of read-only operations.  hbck should fail early by having a write perm check and providing actionable advice to the hbase admin.
Maybe something like: "Current user yy does not have write perms to &amp;lt;hbase home&amp;gt;. Please run hbck as hdfs user xxx"</description>
			<version>0.90.6</version>
			<fixedVersion>0.94.2</fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.FSUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.util.HBaseFsck.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">5820</link>
			<link type="Reference" description="is related to">5734</link>
		</links>
	</bug>
	<bug id="5333" opendate="2012-02-04 01:04:30" fixdate="2012-08-23 04:31:10" resolution="Duplicate">
		<buginformation>
			<summary>Introduce Memstore "backpressure" for writes</summary>
			<description>Currently if the memstore/flush/compaction cannot keep up with the writeload, we block writers up to hbase.hstore.blockingWaitTime milliseconds (default is 90000).
Would be nice if there was a concept of a soft "backpressure" that slows writing clients gracefully before we reach this condition.
From the log:
"2012-02-04 00:00:06,963 WARN org.apache.hadoop.hbase.regionserver.MemStoreFlusher: Region &amp;lt;table&amp;gt;,,1328313512779.c2761757621ddf8fb78baf5288d71271. has too many store files; delaying flush up to 90000ms"</description>
			<version>0.92.0</version>
			<fixedVersion></fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestClientPushback.java</file>
			<file type="M">org.apache.hadoop.hbase.client.RpcRetryingCallerFactory.java</file>
			<file type="M">org.apache.hadoop.hbase.client.StatsTrackingRpcRetryingCaller.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.ClientProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.HConstants.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
			<file type="M">org.apache.hadoop.hbase.client.RpcRetryingCaller.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ClusterConnection.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.WALEditsReplaySink.java</file>
			<file type="M">org.apache.hadoop.hbase.client.Result.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestAsyncProcess.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.TestRegionReplicaReplicationEndpoint.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ConnectionAdapter.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.ResponseConverter.java</file>
			<file type="M">org.apache.hadoop.hbase.client.AsyncProcess.java</file>
			<file type="M">org.apache.hadoop.hbase.client.MultiAction.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ConnectionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionTestingUtility.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestReplicasClient.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestFastFailWithoutTestUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.RegionCoprocessorRpcChannel.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">5162</link>
			<link type="Reference" description="relates to">2981</link>
			<link type="Reference" description="is related to">6423</link>
		</links>
	</bug>
	<bug id="6529" opendate="2012-08-09 07:08:41" fixdate="2012-08-25 04:45:24" resolution="Fixed">
		<buginformation>
			<summary>With HFile v2, the region server will always perform an extra copy of source files</summary>
			<description>With HFile v2 implementation in HBase 0.94 &amp;amp; 0.96, the region server will use HFileSystem as its fs. When it performs bulk load in Store.bulkLoadHFile(), it checks if its fs is the same as srcFs, which however will be DistributedFileSystem. Consequently, it will always perform an extra copy of source files.</description>
			<version>0.94.0</version>
			<fixedVersion>0.94.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">5640</link>
			<link type="Reference" description="is related to">5640</link>
		</links>
	</bug>
	<bug id="4100" opendate="2011-07-14 18:06:28" fixdate="2012-08-31 16:46:30" resolution="Duplicate">
		<buginformation>
			<summary>Authentication for REST clients</summary>
			<description>Like Thrift, the REST gateway is not currently integrated into the authentication used for HBase RPC.  Currently this means the REST gateway cannot even be used when HBase security is active.
For the REST gateway to be able to interoperate with HBase security:

the REST server needs to be able to login from a keytab on startup with its own server principal
REST clients need to be able to authenticate security with the REST server
the REST server needs to be able to act as a trusted proxy for the original client identities, so that the HBase authorization checks can be performed against the original client request

Like Thrift, implementing step #1 as a bare minimum would at least allow deploying a REST server configured to login as the application user on startup.  Even without authenticating REST clients, this would allow the gateway to work when HBase security is active.
For step #2, we can make use of SPNEGO to provide Kerberos/GSSAPI authentication of clients over HTTP.  The Alfredo library from Cloudera would hopefully make this relatively easy to do:
http://cloudera.github.com/alfredo/docs/latest/index.html</description>
			<version>0.92.0</version>
			<fixedVersion></fixedVersion>
			<type>Sub-task</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
			<file type="M">org.apache.hadoop.hbase.util.Strings.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.Main.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">5062</link>
		</links>
	</bug>
	<bug id="4099" opendate="2011-07-14 17:56:13" fixdate="2012-08-31 16:47:10" resolution="Duplicate">
		<buginformation>
			<summary>Authentication for ThriftServer clients</summary>
			<description>The current implementation of HBase client authentication only works with the Java API.  Alternate access gateways, like Thrift and REST are left out and will not work.
For the ThriftServer to be able to fully interoperate with the security implementation:

the ThriftServer should be able to login from a keytab file with it&amp;amp;apos;s own server principal on startup
thrift clients should be able to authenticate securely when connecting to the server
the ThriftServer should be able to act as a proxy for those clients so that the RPCs it issues will be correctly authorized as the original client identities

There is already some support for step 3 in UserGroupInformation and related classes.
For step #2, we really need to look at what thrift itself supports.
At a bare minimum, we need to implement step #1.  If we do this, even without steps 2 &amp;amp; 3, this would at least allow deployments to use a ThriftServer per application user, and have the server login as that user on startup.  Thrift clients may not be directly authenticated, but authorization checks for HBase could still be handled correctly this way.</description>
			<version>0.92.0</version>
			<fixedVersion></fixedVersion>
			<type>Sub-task</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
			<file type="M">org.apache.hadoop.hbase.util.Strings.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.Main.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">5062</link>
			<link type="Reference" description="is related to">4460</link>
			<link type="Reference" description="is related to">4475</link>
		</links>
	</bug>
	<bug id="6260" opendate="2012-06-22 20:30:08" fixdate="2012-09-14 22:37:09" resolution="Fixed">
		<buginformation>
			<summary>balancer state should be stored in ZK</summary>
			<description>See: https://issues.apache.org/jira/browse/HBASE-5953?focusedCommentId=13270200&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13270200
And: https://issues.apache.org/jira/browse/HBASE-5630?focusedCommentId=13399225&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13399225
In short, we need to move the balancer state to ZK so that it won&amp;amp;apos;t have to be restarted if the master dies.</description>
			<version>0.95.2</version>
			<fixedVersion></fixedVersion>
			<type>Task</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.zookeeper.LoadBalancerTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
			<file type="M">org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">3816</link>
		</links>
	</bug>
	<bug id="6422" opendate="2012-07-18 19:11:54" fixdate="2012-10-02 04:39:35" resolution="Duplicate">
		<buginformation>
			<summary>Add switch in LoadIncrementalHFiles API to allow for programatically changing perms on output directory</summary>
			<description>Hbase bulk load often requires manual chown and permission changes.
Usually it goes something like try to run completebulkload and it fails with the following hdfs error:
org.apache.hadoop.security.AccessControlException:
org.apache.hadoop.security.AccessControlException:
Permission denied:  user=hbase, access=WRITE, inode="mydata":
hadoop:supergroup:rwxr-xr-x
To work around this mismatch between Hadoop and HBase user permissions, you can make both users share a group: that is, the user where you run the MapReduce jobs and the user running HBase. Then, after running your MapReduce job, you can chgrp the output directory to the HBase group, and run chmod g+w. This allows the bulk loader to move the files into the HBase data directory.
It would be useful if there was a way to do this in the LoadIncrementalHFiles API
It is the case of linux permissions too:
If we have:
file owner:me group:me
We can chown to group:x and owner:x, without needing special permissions
chown x:x file
Then when we trigger bulk load, HBase does the fs -mv, and finds that the owner is itself, so no permission hitches. Goes smooth.
We are thinking that a switch to turn this on/off (default off) would be nice to have.
</description>
			<version>0.94.0</version>
			<fixedVersion></fixedVersion>
			<type>New Feature</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.security.access.SecureTestUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFilesSplitRecovery.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
			<file type="M">org.apache.hadoop.hbase.security.access.AccessController.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFiles.java</file>
			<file type="M">org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">5498</link>
		</links>
	</bug>
	<bug id="5498" opendate="2012-03-01 00:20:46" fixdate="2013-01-15 23:54:10" resolution="Fixed">
		<buginformation>
			<summary>Secure Bulk Load</summary>
			<description>Design doc: https://cwiki.apache.org/confluence/display/HCATALOG/HBase+Secure+Bulk+Load
Short summary:
Security as it stands does not cover the bulkLoadHFiles() feature. Users calling this method will bypass ACLs. Also loading is made more cumbersome in a secure setting because of hdfs privileges. bulkLoadHFiles() moves the data from user&amp;amp;apos;s directory to the hbase directory, which would require certain write access privileges set.
Our solution is to create a coprocessor which makes use of AuthManager to verify if a user has write access to the table. If so, launches a MR job as the hbase user to do the importing (ie rewrite from text to hfiles). One tricky part this job will have to do is impersonate the calling user when reading the input files. We can do this by expecting the user to pass an hdfs delegation token as part of the secureBulkLoad() coprocessor call and extend an inputformat to make use of that token. The output is written to a temporary directory accessible only by hbase and then bulkloadHFiles() is called.
</description>
			<version>0.94.0</version>
			<fixedVersion>0.94.5, 0.95.0</fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.security.access.SecureTestUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFilesSplitRecovery.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
			<file type="M">org.apache.hadoop.hbase.security.access.AccessController.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFiles.java</file>
			<file type="M">org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
		</fixedFiles>
		<links>
			<link type="Blocker" description="is blocked by">6432</link>
			<link type="Duplicate" description="is duplicated by">6422</link>
			<link type="Incorporates" description="is part of">6101</link>
			<link type="Incorporates" description="is part of">6096</link>
		</links>
	</bug>
	<bug id="7580" opendate="2013-01-16 12:38:21" fixdate="2013-01-16 16:58:10" resolution="Duplicate">
		<buginformation>
			<summary>TestAccessController fails in trunk</summary>
			<description>It failed in build #3756.
I can reproduce the failure locally:


testReadWrite(org.apache.hadoop.hbase.security.access.TestAccessController)  Time elapsed: 39.306 sec  &amp;lt;&amp;lt;&amp;lt; ERROR!
org.apache.hadoop.hbase.client.RetriesExhaustedException: Failed after attempts=10, exceptions:
Wed Jan 16 04:31:13 PST 2013, org.apache.hadoop.hbase.client.HTable$10@124d998e, java.io.IOException: java.io.IOException: java.lang.NullPointerException
Wed Jan 16 04:31:14 PST 2013, org.apache.hadoop.hbase.client.HTable$10@124d998e, java.io.IOException: java.io.IOException: java.lang.NullPointerException
Wed Jan 16 04:31:16 PST 2013, org.apache.hadoop.hbase.client.HTable$10@124d998e, java.io.IOException: java.io.IOException: java.lang.NullPointerException
Wed Jan 16 04:31:17 PST 2013, org.apache.hadoop.hbase.client.HTable$10@124d998e, java.io.IOException: java.io.IOException: java.lang.NullPointerException
Wed Jan 16 04:31:19 PST 2013, org.apache.hadoop.hbase.client.HTable$10@124d998e, java.io.IOException: java.io.IOException: java.lang.NullPointerException
Wed Jan 16 04:31:21 PST 2013, org.apache.hadoop.hbase.client.HTable$10@124d998e, java.io.IOException: java.io.IOException: java.lang.NullPointerException
Wed Jan 16 04:31:25 PST 2013, org.apache.hadoop.hbase.client.HTable$10@124d998e, java.io.IOException: java.io.IOException: java.lang.NullPointerException
Wed Jan 16 04:31:29 PST 2013, org.apache.hadoop.hbase.client.HTable$10@124d998e, java.io.IOException: java.io.IOException: java.lang.NullPointerException
Wed Jan 16 04:31:37 PST 2013, org.apache.hadoop.hbase.client.HTable$10@124d998e, java.io.IOException: java.io.IOException: java.lang.NullPointerException
Wed Jan 16 04:31:53 PST 2013, org.apache.hadoop.hbase.client.HTable$10@124d998e, java.io.IOException: java.io.IOException: java.lang.NullPointerException

  at org.apache.hadoop.hbase.client.ServerCallable.withRetries(ServerCallable.java:186)
  at org.apache.hadoop.hbase.client.HTable.checkAndDelete(HTable.java:843)
  at org.apache.hadoop.hbase.security.access.TestAccessController$27.run(TestAccessController.java:668)

</description>
			<version>0.95.2</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
			<file type="M">org.apache.hadoop.hbase.client.RetriesExhaustedException.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">7581</link>
		</links>
	</bug>
	<bug id="5640" opendate="2012-03-27 01:30:09" fixdate="2013-01-16 17:54:00" resolution="Duplicate">
		<buginformation>
			<summary>bulk load runs slowly than before</summary>
			<description>I am loading data from an external system into hbase. There are many prints of the form. This is possibly a regression caused by a recent patch.
....on different filesystem than destination store - moving to this filesystem</description>
			<version>0.94.0</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">6529</link>
			<link type="Reference" description="relates to">6529</link>
		</links>
	</bug>
	<bug id="7581" opendate="2013-01-16 14:00:51" fixdate="2013-01-16 18:37:08" resolution="Fixed">
		<buginformation>
			<summary>TestAccessController depends on the execution order</summary>
			<description></description>
			<version>0.95.2</version>
			<fixedVersion>0.94.5, 0.95.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
			<file type="M">org.apache.hadoop.hbase.client.RetriesExhaustedException.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">7580</link>
			<link type="Required" description="is required by">7574</link>
		</links>
	</bug>
	<bug id="7591" opendate="2013-01-16 22:32:12" fixdate="2013-01-21 02:59:39" resolution="Duplicate">
		<buginformation>
			<summary>HColumnDescriptor equals method should not rely on HashCode</summary>
			<description>I wanted to change the way this is implemented so that we can accept different orderings of attributes as being the same.
This was implemented using HashMap equality.</description>
			<version>0.94.4</version>
			<fixedVersion></fixedVersion>
			<type>Sub-task</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.TestHTableDescriptor.java</file>
			<file type="M">org.apache.hadoop.hbase.HTableDescriptor.java</file>
			<file type="M">org.apache.hadoop.hbase.HColumnDescriptor.java</file>
			<file type="M">org.apache.hadoop.hbase.TestHColumnDescriptor.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">7579</link>
		</links>
	</bug>
	<bug id="7693" opendate="2013-01-28 09:23:33" fixdate="2013-01-28 18:43:44" resolution="Fixed">
		<buginformation>
			<summary>Hostname returned by TableInputFormatBase.reverseDNS contains trailing period</summary>
			<description>TableInputFormatBase.reverseDNS makes a call to org.apache.hadoop.net.DNS.reverseDns which (at least in Hadoop 1.0.4) returns a PTR record.  PTR records contain a trailing period, which then shows up in the input split location causing the JobTracker to incorrectly match map jobs to data-local map slots.</description>
			<version>0.94.3</version>
			<fixedVersion>0.94.5, 0.95.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">2535</link>
			<link type="Reference" description="relates to">4109</link>
			<link type="Reference" description="is related to">9369</link>
		</links>
	</bug>
	<bug id="6280" opendate="2012-06-27 08:23:48" fixdate="2013-01-29 19:13:04" resolution="Duplicate">
		<buginformation>
			<summary>why using treeMap at default implement with class  Batch.Callback</summary>
			<description>public &amp;lt;T extends CoprocessorProtocol, R&amp;gt; Map&amp;lt;byte[],R&amp;gt; coprocessorExec(
      Class&amp;lt;T&amp;gt; protocol, byte[] startKey, byte[] endKey,
      Batch.Call&amp;lt;T,R&amp;gt; callable)
      throws IOException, Throwable {
    final Map&amp;lt;byte[],R&amp;gt; results = new TreeMap&amp;lt;byte[],R&amp;gt;(
        Bytes.BYTES_COMPARATOR);
    coprocessorExec(protocol, startKey, endKey, callable,
        new Batch.Callback&amp;lt;R&amp;gt;(){
      public void update(byte[] region, byte[] row, R value) 
{
        results.put(region, value);
      }
    });
    return results;
  }
when mulit region  call the Batch.Callback ,the treemap should lockup.
we meet this situation after we run 3 month.</description>
			<version>0.92.0</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">6565</link>
		</links>
	</bug>
	<bug id="7385" opendate="2012-12-19 00:35:04" fixdate="2013-01-30 22:57:17" resolution="Duplicate">
		<buginformation>
			<summary>Do not abort regionserver if StoreFlusher.flushCache() fails</summary>
			<description>A rare NN failover may cause RS abort, in the following sequence of events: 

RS tries to flush the memstore
Create a file, start block, and acquire a lease
Block is complete, lease removed, but before we send the RPC response back to the client, NN is killed.
New NN comes up, client retries the block complete again, the new NN throws lease expired since the block was already complete.
RS receives the exception, and aborts.

This is actually a NN+DFSClient issue that, the dfs client from RS does not receive the rpc response about the block close, and upon retry on the new NN, it gets the exception, since the file was already closed. However, although this is DFS client specific, we can also make RS more resilient by not aborting the RS upon exception from the flushCache(). We can change StoreFlusher so that: 
StoreFlusher.prepare() will become idempotent (so will Memstore.snapshot())
StoreFlusher.flushCache() will throw with IOException upon DFS exception, but we catch IOException, and just abort the flush request (not RS).
StoreFlusher.commit() still cause RS abort on exception. This is also debatable. If dfs is alive, and we can undo the flush changes, than we should not abort. 
logs: 


org.apache.hadoop.hbase.DroppedSnapshotException: region: loadtest_ha,e6666658,1355820729877.298bcbd550b80507a379fe67eefbe5ea.
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1485)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1364)
	at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:896)
	at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:845)
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:119)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:169)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
Caused by: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException: No lease on /apps/hbase/data/loadtest_ha/298bcbd550b80507a379fe67eefbe5ea/.tmp/5cf8951ee12449ce8e4e6dd0bf1645c2 File is not open for writing. [Lease.  Holder: DFSClient_hb_rs_XXX,60020,1355813552066_203591774_25, pendingcreates: 1]
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:1724)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:1707)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:1762)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:1750)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.complete(NameNode.java:779)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:578)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1393)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1389)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1136)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1387)

	at org.apache.hadoop.ipc.Client.call(Client.java:1107)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at $Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:85)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:62)
	at $Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.closeInternal(DFSClient.java:4087)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.close(DFSClient.java:3988)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:61)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:86)
	at org.apache.hadoop.hbase.io.hfile.AbstractHFileWriter.finishClose(AbstractHFileWriter.java:255)
	at org.apache.hadoop.hbase.io.hfile.HFileWriterV2.close(HFileWriterV2.java:432)
	at org.apache.hadoop.hbase.regionserver.StoreFile$Writer.close(StoreFile.java:1214)
	at org.apache.hadoop.hbase.regionserver.Store.internalFlushCache(Store.java:762)
	at org.apache.hadoop.hbase.regionserver.Store.flushCache(Store.java:674)
	at org.apache.hadoop.hbase.regionserver.Store.access$400(Store.java:109)
	at org.apache.hadoop.hbase.regionserver.Store$StoreFlusherImpl.flushCache(Store.java:2286)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1460)

</description>
			<version>0.94.6</version>
			<fixedVersion></fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.HConstants.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">7507</link>
		</links>
	</bug>
	<bug id="7774" opendate="2013-02-05 19:55:47" fixdate="2013-02-06 05:27:07" resolution="Duplicate">
		<buginformation>
			<summary>RegionObserver.prePut() cannot rely on the Put&amp;apos;s timestamps, can even cause data loss</summary>
			<description>We had a user that had code that looked like this in a coprocessor&amp;amp;apos;s prePut():


if (put.has(expectedKv))
  put.add(kvSayingIFoundIt);
else
  put.add(kvSayingNotFound);


If you have MSLAB turned off, and you have the expectedKv in your Put, doing a Get following your insert will only return kvSayingIFoundIt and not the KV you were actually inserting.
More so, if you only do put.has(expectedKv), you will not get anything back. Your data seems to be gone.
The reason is that in prePut() the timestamp hasn&amp;amp;apos;t been set yet, so calling kv.getTimestamp() during the comparisons in put.has() will populate kv.timestampCache with Long.MAX_VALUE. Then it will stay in the MemStore with that big timestamp and be filtered out because TimeRange will compare Long.MAX_VALUE &amp;gt;= Long.MAX_VALUE and return SKIP.
And the reason it works correctly with MSLAB on is that the KV is cloned in maybeCloneWithAllocator() and the cache is reset.
Now, I think this has bigger implications. Basically, you can&amp;amp;apos;t rely on the timestamp at all in prePut(). I&amp;amp;apos;m sure this can screw someone else in a creative way later.</description>
			<version>0.92.2</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.TestKeyValue.java</file>
			<file type="M">org.apache.hadoop.hbase.KeyValue.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">6265</link>
			<link type="Reference" description="is related to">7279</link>
			<link type="Reference" description="is related to">4210</link>
		</links>
	</bug>
	<bug id="7507" opendate="2013-01-07 10:30:22" fixdate="2013-02-25 20:55:38" resolution="Fixed">
		<buginformation>
			<summary>Make memstore flush be able to retry after exception</summary>
			<description>We will abort regionserver if memstore flush throws exception.
I thinks we could do retry to make regionserver more stable because file system may be not ok in a transient time. e.g. Switching namenode in the NamenodeHA environment


HRegion#internalFlushcache(){

...
try {
...
}catch(Throwable t){
DroppedSnapshotException dse = new DroppedSnapshotException("region: " +
          Bytes.toStringBinary(getRegionName()));
dse.initCause(t);
throw dse;
}
...

}

MemStoreFlusher#flushRegion(){
...
region.flushcache();
...
 try {
}catch(DroppedSnapshotException ex){
server.abort("Replay of HLog required. Forcing server shutdown", ex);
}

...
}

</description>
			<version>0.94.6</version>
			<fixedVersion>0.94.6, 0.95.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.HConstants.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">7385</link>
			<link type="Reference" description="relates to">7929</link>
		</links>
	</bug>
	<bug id="5492" opendate="2012-02-29 16:19:59" fixdate="2013-03-08 02:11:45" resolution="Duplicate">
		<buginformation>
			<summary>Caching StartKeys and EndKeys of Regions</summary>
			<description>Each call for HTable.getStartEndKeys will read meta table.
In particular, 
in the case of client side multi-threaded concurrency statistics, 
we must call HTable.coprocessorExec== &amp;gt; getStartKeysInRange ==&amp;gt; getStartEndKeys,
resulting in the need to always scan the meta table.
This is not necessary,
we can implement the HConnectionManager.HConnectionImplementation.locateRegions(byte[] tableName) method,
then, get the StartKeys and EndKeys from the cachedRegionLocations of HConnectionImplementation.
Combined with https://issues.apache.org/jira/browse/HBASE-5491, can improve the performance of statistical</description>
			<version>0.92.0</version>
			<fixedVersion></fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">6870</link>
			<link type="Reference" description="relates to">5489</link>
		</links>
	</bug>
	<bug id="8044" opendate="2013-03-08 18:51:48" fixdate="2013-03-15 16:47:25" resolution="Duplicate">
		<buginformation>
			<summary>split/flush/compact/major_compact from hbase shell does not work for region key with \x format</summary>
			<description>the conversion between bytes and string is incorrect</description>
			<version>0.94.5</version>
			<fixedVersion>0.98.0, 0.94.7, 0.95.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
		</fixedFiles>
		<links>
			<link type="Blocker" description="is blocked by">8085</link>
			<link type="Reference" description="relates to">6643</link>
		</links>
	</bug>
	<bug id="8136" opendate="2013-03-18 16:12:07" fixdate="2013-03-18 16:29:12" resolution="Duplicate">
		<buginformation>
			<summary>coprocessor service requires .meta. to be available all the time.</summary>
			<description>
HTable#getRegionLocations does not use a cache: all the calls to this function go to .META.
So:

we&amp;amp;apos;re missing an opportunity to reuse/update the location cache in the HConnection.
this method is called by the coprocessor service. So, for people using this features, they have .meta. on their execution path, and it&amp;amp;apos;s not good for performances, scalability and reliability.

I&amp;amp;apos;m not totally clear on the fix. I think it should be possible to use the cache to see if we have all regions for the table. But it means we won&amp;amp;apos;t always have the last version when calling getRegionLocations.
Any thought on this?</description>
			<version>0.95.2</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">6870</link>
		</links>
	</bug>
	<bug id="6446" opendate="2012-07-24 10:21:22" fixdate="2013-03-19 22:48:50" resolution="Duplicate">
		<buginformation>
			<summary>Replication source will throw EOF exception when hlog size is 0</summary>
			<description>when master cluster startup new hlog which size is 0 will be created. if we start replication, replication source will print many EOF exception when openreader. I think we need to ignore this case and do not print so many exception warning log .</description>
			<version>0.94.0</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">7122</link>
		</links>
	</bug>
	<bug id="8212" opendate="2013-03-28 08:04:27" fixdate="2013-03-28 08:29:36" resolution="Duplicate">
		<buginformation>
			<summary>Introduce a new separator instead of hyphen(&amp;apos;-&amp;apos;) for renaming recovered queues&amp;apos; znodes</summary>
			<description>hyphen is frequently used in the HostName. Likes we have one regionserver named "160-172-0-1", so under this scenario, 160-172-0-1 will be splited to 4 Strings and will be considered for 4 possible dead servers.
It won&amp;amp;apos;t find all the logs for "160-172-0-1" any more, so causes data-loss.</description>
			<version>0.94.6</version>
			<fixedVersion>0.94.7, 0.95.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.FSHDFSUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestHLog.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManager.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.ReplicationZookeeper.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">8207</link>
		</links>
	</bug>
	<bug id="8207" opendate="2013-03-28 00:17:53" fixdate="2013-03-29 17:36:18" resolution="Fixed">
		<buginformation>
			<summary>Replication could have data loss when machine name contains hyphen "-"</summary>
			<description>In the recent test case TestReplication* failures, I&amp;amp;apos;m finally able to find the cause(or one of causes) for its intermittent failures.
When a machine name contains "-", it breaks the function ReplicationSource.checkIfQueueRecovered. It causes the following issue:
deadRegionServers list is way off so that replication doesn&amp;amp;apos;t wait for log splitting finish for a wal file and move on to the next one(data loss)
You can see that replication use those weird paths constructed from deadRegionServers to check a file existence


2013-03-26 21:26:51,385 INFO  [ReplicationExecutor-0.replicationSource,2-ip-10-197-0-156.us-west-1.compute.internal,52170,1364333181125] regionserver.ReplicationSource(524): Possible location hdfs://localhost:52882/user/ec2-user/hbase/.logs/1.compute.internal,52170,1364333181125/ip-10-197-0-156.us-west-1.compute.internal%252C52170%252C1364333181125.1364333199540
2013-03-26 21:26:51,386 INFO  [ReplicationExecutor-0.replicationSource,2-ip-10-197-0-156.us-west-1.compute.internal,52170,1364333181125] regionserver.ReplicationSource(524): Possible location hdfs://localhost:52882/user/ec2-user/hbase/.logs/1.compute.internal,52170,1364333181125-splitting/ip-10-197-0-156.us-west-1.compute.internal%252C52170%252C1364333181125.1364333199540
2013-03-26 21:26:51,387 INFO  [ReplicationExecutor-0.replicationSource,2-ip-10-197-0-156.us-west-1.compute.internal,52170,1364333181125] regionserver.ReplicationSource(524): Possible location hdfs://localhost:52882/user/ec2-user/hbase/.logs/west/ip-10-197-0-156.us-west-1.compute.internal%252C52170%252C1364333181125.1364333199540
2013-03-26 21:26:51,389 INFO  [ReplicationExecutor-0.replicationSource,2-ip-10-197-0-156.us-west-1.compute.internal,52170,1364333181125] regionserver.ReplicationSource(524): Possible location hdfs://localhost:52882/user/ec2-user/hbase/.logs/west-splitting/ip-10-197-0-156.us-west-1.compute.internal%252C52170%252C1364333181125.1364333199540
2013-03-26 21:26:51,391 INFO  [ReplicationExecutor-0.replicationSource,2-ip-10-197-0-156.us-west-1.compute.internal,52170,1364333181125] regionserver.ReplicationSource(524): Possible location hdfs://localhost:52882/user/ec2-user/hbase/.logs/156.us/ip-10-197-0-156.us-west-1.compute.internal%252C52170%252C1364333181125.1364333199540
2013-03-26 21:26:51,394 INFO  [ReplicationExecutor-0.replicationSource,2-ip-10-197-0-156.us-west-1.compute.internal,52170,1364333181125] regionserver.ReplicationSource(524): Possible location hdfs://localhost:52882/user/ec2-user/hbase/.logs/156.us-splitting/ip-10-197-0-156.us-west-1.compute.internal%252C52170%252C1364333181125.1364333199540
2013-03-26 21:26:51,396 INFO  [ReplicationExecutor-0.replicationSource,2-ip-10-197-0-156.us-west-1.compute.internal,52170,1364333181125] regionserver.ReplicationSource(524): Possible location hdfs://localhost:52882/user/ec2-user/hbase/.logs/0/ip-10-197-0-156.us-west-1.compute.internal%252C52170%252C1364333181125.1364333199540
2013-03-26 21:26:51,398 INFO  [ReplicationExecutor-0.replicationSource,2-ip-10-197-0-156.us-west-1.compute.internal,52170,1364333181125] regionserver.ReplicationSource(524): Possible location hdfs://localhost:52882/user/ec2-user/hbase/.logs/0-splitting/ip-10-197-0-156.us-west-1.compute.internal%252C52170%252C1364333181125.1364333199540


This happened in the recent test failure in http://54.241.6.143/job/HBase-0.94/org.apache.hbase$hbase/21/testReport/junit/org.apache.hadoop.hbase.replication/TestReplicationQueueFailover/queueFailover/?auto_refresh=false
Search for 


File does not exist: hdfs://localhost:52882/user/ec2-user/hbase/.oldlogs/ip-10-197-0-156.us-west-1.compute.internal%2C52170%2C1364333181125.1364333199540


After 10 times retries, replication source gave up and move on to the next file. Data loss happens. 
Since lots of EC2 machine names contain "-" including our Jenkin servers, this is a high impact issue.</description>
			<version>0.94.6</version>
			<fixedVersion>0.98.0, 0.94.7, 0.95.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.FSHDFSUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestHLog.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManager.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.ReplicationZookeeper.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">8212</link>
		</links>
	</bug>
	<bug id="5834" opendate="2012-04-19 22:44:32" fixdate="2013-04-02 22:26:08" resolution="Duplicate">
		<buginformation>
			<summary>CopyTable usage is incorrect</summary>
			<description>The example given here is outdated:
http://hbase.apache.org/book/ops_mgt.html#copytable
The classes for rs.class and rs.impl don&amp;amp;apos;t exist.
Example in Java code needs to be updated as well.</description>
			<version>0.90.4</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.CopyTable.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">4931</link>
		</links>
	</bug>
	<bug id="6330" opendate="2012-07-05 06:25:27" fixdate="2013-04-09 21:54:57" resolution="Fixed">
		<buginformation>
			<summary>TestImportExport has been failing against hadoop 0.23/2.0 profile</summary>
			<description>See HBASE-5876.  I&amp;amp;apos;m going to commit the v3 patches under this name since there has been two months (my bad) since the first half was committed and found to be incomplte.

4/9/13 Updated - this will take the patch from HBASE-8258 to fix this specific problem.  The umbrella that used to be HBASE-8258 is now handled with HBASE-6891.</description>
			<version>0.94.1</version>
			<fixedVersion>0.98.0, 0.95.1</fixedVersion>
			<type>Sub-task</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.Export.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TestImportExport.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.MapreduceTestingShim.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">8258</link>
			<link type="Duplicate" description="is duplicated by">6601</link>
			<link type="dependent" description="is depended upon by">6307</link>
		</links>
	</bug>
	<bug id="8258" opendate="2013-04-03 18:59:11" fixdate="2013-04-09 21:56:42" resolution="Duplicate">
		<buginformation>
			<summary>Make mapreduce tests pass on hadoop2</summary>
			<description>HBASE-7904 was a first attempt at making this work but it got lost in the weeds.
This is a new attempt at making hbase mapreduce jobs run on hadoop2 (w/o breaking mapreduce on hadoop1)</description>
			<version>0.94.1</version>
			<fixedVersion></fixedVersion>
			<type>Sub-task</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.Export.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TestImportExport.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.MapreduceTestingShim.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">6891</link>
			<link type="Duplicate" description="is duplicated by">6330</link>
			<link type="Reference" description="relates to">7904</link>
		</links>
	</bug>
	<bug id="6870" opendate="2012-09-24 05:36:11" fixdate="2013-04-22 02:39:42" resolution="Fixed">
		<buginformation>
			<summary>HTable#coprocessorExec always scan the whole table </summary>
			<description>In current logic, HTable#coprocessorExec always scans the entire META table, loading it into memory and then filters the keys to return only those that fall in specified range.  The version after the patch only scans the portions of meta that are in the specified key range, and returns them.  Put simply  before we did a load-all-then-filter; afterwards we only-scan-what-is-needed.
The former has low efficiency and greatly impacts the Regionserver carrying .META. when there are many coprocessorExec requests.
</description>
			<version>0.94.1</version>
			<fixedVersion>0.98.0, 0.94.8, 0.95.1</fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">8136</link>
			<link type="Duplicate" description="is duplicated by">5492</link>
			<link type="Required" description="is required by">5843</link>
		</links>
	</bug>
	<bug id="7122" opendate="2012-11-08 00:20:42" fixdate="2013-04-24 05:34:51" resolution="Fixed">
		<buginformation>
			<summary>Proper warning message when opening a log file with no entries (idle cluster)</summary>
			<description>In case the cluster is idle and the log has rolled (offset to 0), replicationSource tries to open the log and gets an EOF exception. This gets printed after every 10 sec until an entry is inserted in it.


2012-11-07 15:47:40,924 DEBUG regionserver.ReplicationSource (ReplicationSource.java:openReader(487)) - Opening log for replication c0315.hal.cloudera.com%2C40020%2C1352324202860.1352327804874 at 0
2012-11-07 15:47:40,926 WARN  regionserver.ReplicationSource (ReplicationSource.java:openReader(543)) - 1 Got: 
java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:180)
	at java.io.DataInputStream.readFully(DataInputStream.java:152)
	at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1508)
	at org.apache.hadoop.io.SequenceFile$Reader.&amp;lt;init&amp;gt;(SequenceFile.java:1486)
	at org.apache.hadoop.io.SequenceFile$Reader.&amp;lt;init&amp;gt;(SequenceFile.java:1475)
	at org.apache.hadoop.io.SequenceFile$Reader.&amp;lt;init&amp;gt;(SequenceFile.java:1470)
	at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogReader$WALReader.&amp;lt;init&amp;gt;(SequenceFileLogReader.java:55)
	at org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogReader.init(SequenceFileLogReader.java:175)
	at org.apache.hadoop.hbase.regionserver.wal.HLog.getReader(HLog.java:716)
	at org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.openReader(ReplicationSource.java:491)
	at org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.run(ReplicationSource.java:290)
2012-11-07 15:47:40,927 WARN  regionserver.ReplicationSource (ReplicationSource.java:openReader(547)) - Waited too long for this file, considering dumping
2012-11-07 15:47:40,927 DEBUG regionserver.ReplicationSource (ReplicationSource.java:sleepForRetries(562)) - Unable to open a reader, sleeping 1000 times 10



We should reduce the log spewing in this case (or some informative message, based on the offset).</description>
			<version>0.94.2</version>
			<fixedVersion>0.98.0, 0.94.8, 0.95.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">6446</link>
		</links>
	</bug>
	<bug id="2231" opendate="2010-02-17 05:37:27" fixdate="2013-04-26 22:15:37" resolution="Fixed">
		<buginformation>
			<summary>Compaction events should be written to HLog</summary>
			<description>The sequence for a compaction should look like this:

Compact region to "new" files
Write a "Compacted Region" entry to the HLog
Delete "old" files

This deals with a case where the RS has paused between step 1 and 2 and the regions have since been reassigned.</description>
			<version>0.90.0</version>
			<fixedVersion>0.98.0, 0.95.1</fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.HLogUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.util.FSUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.HLog.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.TestRowProcessorEndpoint.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.WALEdit.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.MiniHBaseCluster.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.WALPlayer.java</file>
			<file type="M">org.apache.hadoop.hbase.TestFullLogReconstruction.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">3604</link>
			<link type="Reference" description="relates to">2519</link>
			<link type="Reference" description="is related to">2238</link>
			<link type="Regression" description="breaks">8478</link>
		</links>
	</bug>
	<bug id="3816" opendate="2011-04-22 20:38:45" fixdate="2013-05-07 22:35:20" resolution="Duplicate">
		<buginformation>
			<summary>Put the balancer switch in ZK</summary>
			<description>Currently the balancer switch lives only in the master&amp;amp;apos;s memory. Yesterday we had one master that died (in a strange way) and the one we restarted started balancing again. It&amp;amp;apos;s only a test cluster so it really wasn&amp;amp;apos;t a big deal, but I can imagine ways this could screw people&amp;amp;apos;s life.</description>
			<version>0.90.2</version>
			<fixedVersion></fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.zookeeper.LoadBalancerTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
			<file type="M">org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">6260</link>
		</links>
	</bug>
	<bug id="8781" opendate="2013-06-21 07:09:47" fixdate="2013-07-04 16:44:54" resolution="Fixed">
		<buginformation>
			<summary>ImmutableBytesWritable constructor with another IBW as param need to consider the offset of the passed IBW</summary>
			<description>

/**
   * Set the new ImmutableBytesWritable to the contents of the passed
   * &amp;lt;code&amp;gt;ibw&amp;lt;/code&amp;gt;.
   * @param ibw the value to set this ImmutableBytesWritable to.
   */
  public ImmutableBytesWritable(final ImmutableBytesWritable ibw) {
    this(ibw.get(), 0, ibw.getSize());
  }


It should be this(ibw.get(), ibw.getOffset(), ibw.getSize());</description>
			<version>0.94.8</version>
			<fixedVersion>0.98.0, 0.95.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.ImmutableBytesWritable.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">9427</link>
		</links>
	</bug>
	<bug id="8923" opendate="2013-07-10 22:40:57" fixdate="2013-07-11 01:47:46" resolution="Duplicate">
		<buginformation>
			<summary>ChaosMonkey test teardown may fail due to race with ChaosMonkey</summary>
			<description>If chaosmonkey restarts RS at the last moment before test teardown happens, cluster recovery may not see it in cluster status; however, RS process is already running, so when cluster recovery also tries to start it, it gets ExitCodeException. Boom! </description>
			<version>0.94.9</version>
			<fixedVersion></fixedVersion>
			<type>Test</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
			<file type="M">org.apache.hadoop.hbase.DistributedHBaseCluster.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">7770</link>
		</links>
	</bug>
	<bug id="7770" opendate="2013-02-05 17:50:05" fixdate="2013-07-12 17:22:26" resolution="Fixed">
		<buginformation>
			<summary>minor integration test framework fixes</summary>
			<description>
made FileSystem on HBaseTestingUtil.createMulti() not expect mini cluster
added check if server is not running before deciding to restore a server

</description>
			<version>0.94.9</version>
			<fixedVersion>0.98.0, 0.95.2, 0.94.10</fixedVersion>
			<type>Test</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
			<file type="M">org.apache.hadoop.hbase.DistributedHBaseCluster.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">8923</link>
		</links>
	</bug>
	<bug id="8962" opendate="2013-07-16 19:09:05" fixdate="2013-07-18 20:50:06" resolution="Fixed">
		<buginformation>
			<summary>Clean up code and remove regular log splitting</summary>
			<description>Distributed log splitting has been out there for a while and it is kind of stable. It&amp;amp;apos;s about time to get rid of the regular log splitting and clean up the code a little bit.</description>
			<version>0.95.2</version>
			<fixedVersion>0.98.0, 0.95.2</fixedVersion>
			<type>Task</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestHLogSplit.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestSplitLogManager.java</file>
			<file type="M">org.apache.hadoop.hbase.HConstants.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
			<file type="M">org.apache.hadoop.hbase.master.SplitLogManager.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.TestWALObserver.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestHLogMethods.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
			<file type="M">org.apache.hadoop.hbase.exceptions.OrphanHLogAfterSplitException.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestHLog.java</file>
			<file type="M">org.apache.hadoop.hbase.zookeeper.ZKSplitLog.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestWALReplay.java</file>
			<file type="M">org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">7825</link>
		</links>
	</bug>
	<bug id="8992" opendate="2013-07-18 21:14:10" fixdate="2013-07-18 21:29:29" resolution="Duplicate">
		<buginformation>
			<summary>TestMasterFailover.testMasterFailoverWithMockedRITOnDeadRS fails</summary>
			<description>This one fails rare enough.  It is a very long test.
http://54.241.6.143/job/HBase-0.95-Hadoop-2/org.apache.hbase$hbase-server/645/testReport/org.apache.hadoop.hbase.master/TestMasterFailover/testMasterFailoverWithMockedRITOnDeadRS/
Fails like this:


java.lang.AssertionError: region=enabledTable,e\xDC\xB4,1374137106469.efad8aaaf052f839fdbf5abc2e04af4c., [{ENCODED =&amp;gt; 1028785192, NAME =&amp;gt; &amp;amp;apos;.META.,,1&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;&amp;amp;apos;}, {ENCODED =&amp;gt; 1e14e83d175bb4dc82a6eac427b0397c, NAME =&amp;gt; &amp;amp;apos;disabledTable,,1374137107108.1e14e83d175bb4dc82a6eac427b0397c.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;aaa&amp;amp;apos;}, {ENCODED =&amp;gt; 2ce3188d9e655c74aeed8627699d198b, NAME =&amp;gt; &amp;amp;apos;disabledTable,aaa,1374137107131.2ce3188d9e655c74aeed8627699d198b.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;aaa&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;bF\xD8&amp;amp;apos;}, {ENCODED =&amp;gt; a87139be050d4e945fc4523cf2bd1467, NAME =&amp;gt; &amp;amp;apos;disabledTable,bF\xD8,1374137107163.a87139be050d4e945fc4523cf2bd1467.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;bF\xD8&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;c,O&amp;amp;apos;}, {ENCODED =&amp;gt; 822ce4ce69d81d4e1d6e5e8200887240, NAME =&amp;gt; &amp;amp;apos;disabledTable,c,O,1374137107170.822ce4ce69d81d4e1d6e5e8200887240.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;c,O&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;d\x11\xC6&amp;amp;apos;}, {ENCODED =&amp;gt; ad4209578ff51f67e975135f23b7ac13, NAME =&amp;gt; &amp;amp;apos;disabledTable,d\x11\xC6,1374137107176.ad4209578ff51f67e975135f23b7ac13.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;d\x11\xC6&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;d\xF7=&amp;amp;apos;}, {ENCODED =&amp;gt; 20c540d9d7213cf8dbf4b4b90007e7ad, NAME =&amp;gt; &amp;amp;apos;disabledTable,d\xF7=,1374137107182.20c540d9d7213cf8dbf4b4b90007e7ad.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;d\xF7=&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;e\xDC\xB4&amp;amp;apos;}, {ENCODED =&amp;gt; 04d860ad0b8e0ae5a0147a6bccea46f4, NAME =&amp;gt; &amp;amp;apos;enabledTable,,1374137106279.04d860ad0b8e0ae5a0147a6bccea46f4.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;aaa&amp;amp;apos;}, {ENCODED =&amp;gt; b5486e3cf48aa50ca1cba30d0d6ab662, NAME =&amp;gt; &amp;amp;apos;enabledTable,aaa,1374137106428.b5486e3cf48aa50ca1cba30d0d6ab662.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;aaa&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;bF\xD8&amp;amp;apos;}, {ENCODED =&amp;gt; c11af1f6d1aa422916caf6e6ac17eeeb, NAME =&amp;gt; &amp;amp;apos;enabledTable,bF\xD8,1374137106437.c11af1f6d1aa422916caf6e6ac17eeeb.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;bF\xD8&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;c,O&amp;amp;apos;}, {ENCODED =&amp;gt; 5e4dffd62115d6745b589e40136179c7, NAME =&amp;gt; &amp;amp;apos;enabledTable,c,O,1374137106444.5e4dffd62115d6745b589e40136179c7.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;c,O&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;d\x11\xC6&amp;amp;apos;}, {ENCODED =&amp;gt; 0a7dc5f03fa7db89e2ed3aa7512bc6cd, NAME =&amp;gt; &amp;amp;apos;enabledTable,d\x11\xC6,1374137106455.0a7dc5f03fa7db89e2ed3aa7512bc6cd.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;d\x11\xC6&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;d\xF7=&amp;amp;apos;}, {ENCODED =&amp;gt; 8f406facf525870443e93345a3172fbb, NAME =&amp;gt; &amp;amp;apos;enabledTable,d\xF7=,1374137106463.8f406facf525870443e93345a3172fbb.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;d\xF7=&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;e\xDC\xB4&amp;amp;apos;}, {ENCODED =&amp;gt; 9daab73408eb240c4780493b6661eb7b, NAME =&amp;gt; &amp;amp;apos;enabledTable,f\xC2+,1374137106475.9daab73408eb240c4780493b6661eb7b.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;f\xC2+&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;g\xA7\xA2&amp;amp;apos;}, {ENCODED =&amp;gt; 47911855a8362112a57c3767d6864ced, NAME =&amp;gt; &amp;amp;apos;enabledTable,g\xA7\xA2,1374137106482.47911855a8362112a57c3767d6864ced.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;g\xA7\xA2&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;h\x8D\x19&amp;amp;apos;}, {ENCODED =&amp;gt; e6c71e364bfc9766c1336c9c912b9466, NAME =&amp;gt; &amp;amp;apos;enabledTable,h\x8D\x19,1374137106488.e6c71e364bfc9766c1336c9c912b9466.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;h\x8D\x19&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;ir\x90&amp;amp;apos;}, {ENCODED =&amp;gt; 63ae8de95f8149c04a18c90ac0ba99db, NAME =&amp;gt; &amp;amp;apos;enabledTable,ir\x90,1374137106494.63ae8de95f8149c04a18c90ac0ba99db.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;ir\x90&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;jX\x07&amp;amp;apos;}, {ENCODED =&amp;gt; f477cc9a5378ef9ac464c5ffccf5d295, NAME =&amp;gt; &amp;amp;apos;enabledTable,jX\x07,1374137106500.f477cc9a5378ef9ac464c5ffccf5d295.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;jX\x07&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;k=~&amp;amp;apos;}, {ENCODED =&amp;gt; d366f300dffeae98f6c0ace8222dc3e4, NAME =&amp;gt; &amp;amp;apos;enabledTable,k=~,1374137106506.d366f300dffeae98f6c0ace8222dc3e4.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;k=~&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;l"\xF5&amp;amp;apos;}, {ENCODED =&amp;gt; ca8b5a676edb14a42bf80de8c6eb2f84, NAME =&amp;gt; &amp;amp;apos;enabledTable,m\x08l,1374137106518.ca8b5a676edb14a42bf80de8c6eb2f84.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;m\x08l&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;m\xED\xE3&amp;amp;apos;}]
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.apache.hadoop.hbase.master.TestMasterFailover.testMasterFailoverWithMockedRITOnDeadRS(TestMasterFailover.java:815)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
...


Am tempted to disable.  This test should be broken into smaller pieces.  Leaving for now.  Will keep an eye on it.</description>
			<version>0.95.2</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">8991</link>
		</links>
	</bug>
	<bug id="9033" opendate="2013-07-23 23:51:59" fixdate="2013-07-24 17:40:46" resolution="Fixed">
		<buginformation>
			<summary>Add tracing to ReplicationSource and enable it in tests</summary>
			<description>We used to have a lot of logging in ReplicationSource but most of it went away, but debugging the big replication tests is still pretty hard. I think we should add that logging back but at the TRACE level, and enable it only for the unit tests.</description>
			<version>0.94.10</version>
			<fixedVersion>0.98.0, 0.95.2</fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.TestReplicationKillRS.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">9076</link>
		</links>
	</bug>
	<bug id="9076" opendate="2013-07-29 21:16:31" fixdate="2013-07-29 21:45:59" resolution="Duplicate">
		<buginformation>
			<summary>Throttle log messages for missing peer cluster</summary>
			<description>If the replication peer is not available, then RS logs get flooded by messages similar to the following:
2013-07-19 11:55:27,964 INFO org.apache.hadoop.hbase.replication.regionserver.ReplicationSource: Getting 0 rs from peer cluster # Indexer_hbaseIndexer
2013-07-19 11:55:28,670 INFO org.apache.hadoop.hbase.replication.regionserver.ReplicationSource: Getting 0 rs from peer cluster # Indexer_hbaseIndexer
2013-07-19 11:55:28,966 INFO org.apache.hadoop.hbase.replication.regionserver.ReplicationSource: Getting 0 rs from peer cluster # Indexer_hbaseIndexer
2013-07-19 11:55:29,672 INFO org.apache.hadoop.hbase.replication.regionserver.ReplicationSource: Getting 0 rs from peer cluster # Indexer_hbaseIndexer
2013-07-19 11:55:29,969 INFO org.apache.hadoop.hbase.replication.regionserver.ReplicationSource: Getting 0 rs from peer cluster # Indexer_hbaseIndexer
It would be better to change the log level to DEBUG in order to avoid these messages showing up in the default case.</description>
			<version>0.94.10</version>
			<fixedVersion></fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.TestReplicationKillRS.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">9033</link>
		</links>
	</bug>
	<bug id="9178" opendate="2013-08-09 20:28:38" fixdate="2013-08-10 19:06:33" resolution="Duplicate">
		<buginformation>
			<summary>Hanging tests from Jenkins build job since namespaces went in</summary>
			<description>Below are list hanging tests from various build jobs(which aren&amp;amp;apos;t reported as failures).
From hbase-0.95 last three runs
======= 420 skipped(Or don&amp;amp;apos;t have) following tests =======
org.apache.hadoop.hbase.client.testadmin
org.apache.hadoop.hbase.mapreduce.testsecureloadincrementalhfilessplitrecovery
org.apache.hadoop.hbase.mapreduce.testsecureloadincrementalhfiles
======= 421 skipped(Or don&amp;amp;apos;t have) following tests =======
org.apache.hadoop.hbase.mapreduce.testsecureloadincrementalhfilessplitrecovery
org.apache.hadoop.hbase.mapreduce.testsecureloadincrementalhfiles
======= 422 skipped(Or don&amp;amp;apos;t have) following tests =======
org.apache.hadoop.hbase.client.testadmin
org.apache.hadoop.hbase.mapreduce.testsecureloadincrementalhfilessplitrecovery
org.apache.hadoop.hbase.mapreduce.testsecureloadincrementalhfiles
From hbase-0.95-on-hadoop2
======= 225 skipped(Or don&amp;amp;apos;t have) following tests =======
org.apache.hadoop.hbase.catalog.testmetamigrationconvertingtopb
org.apache.hadoop.hbase.mapreduce.testsecureloadincrementalhfilessplitrecovery
org.apache.hadoop.hbase.mapreduce.testsecureloadincrementalhfiles
======= 226 skipped(Or don&amp;amp;apos;t have) following tests =======
org.apache.hadoop.hbase.client.testadmin
org.apache.hadoop.hbase.catalog.testmetamigrationconvertingtopb
org.apache.hadoop.hbase.mapreduce.testsecureloadincrementalhfilessplitrecovery
org.apache.hadoop.hbase.mapreduce.testsecureloadincrementalhfiles
======= 227 skipped(Or don&amp;amp;apos;t have) following tests =======
org.apache.hadoop.hbase.client.testadmin
org.apache.hadoop.hbase.catalog.testmetamigrationconvertingtopb
org.apache.hadoop.hbase.mapreduce.testsecureloadincrementalhfilessplitrecovery
org.apache.hadoop.hbase.mapreduce.testsecureloadincrementalhfiles</description>
			<version>0.95.2</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">8939</link>
		</links>
	</bug>
	<bug id="1913" opendate="2009-10-16 16:07:21" fixdate="2013-08-19 22:46:30" resolution="Duplicate">
		<buginformation>
			<summary>Regionserver accepts connections, doesn&amp;apos;t handle them after bad filter request</summary>
			<description>I deployed some new regionservers but forgot to include a library that one of my filters used.  When a client used that filter, the HBaseServer listener thread attempted to deserialize it, and threw a NoClassDefFoundError.  This killed the listener thread without cleaning up the socket (only Exception and OOME are caught, not other Error subclasses).  New clients continued to successfully open TCP connections, but the regionserver would never handle them, never shutdown, and the master would never expire it, so all of its regions were effectively unavailable until we intervened.</description>
			<version>0.19.3</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.CoprocessorProtocol.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.AggregateProtocol.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.Invocation.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.WritableRpcEngine.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.HBaseClient.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.TestDelayedRpc.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestServerCustomProtocol.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.VersionedProtocol.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.AggregateImplementation.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.BaseEndpointCoprocessor.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.HBaseServer.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">3939</link>
		</links>
	</bug>
	<bug id="9427" opendate="2013-09-04 00:17:18" fixdate="2013-09-04 00:30:52" resolution="Duplicate">
		<buginformation>
			<summary>Copy constructor of ImmutableBytesWritable needs to consider the offset</summary>
			<description>A simple test below


    byte[] bytes = {&amp;amp;apos;a&amp;amp;apos;,&amp;amp;apos;b&amp;amp;apos;,&amp;amp;apos;c&amp;amp;apos;,&amp;amp;apos;d&amp;amp;apos;,&amp;amp;apos;e&amp;amp;apos;,&amp;amp;apos;f&amp;amp;apos;};
    ImmutableBytesWritable writable1 = new ImmutableBytesWritable(bytes, 1, bytes.length);
    ImmutableBytesWritable writable2 = new ImmutableBytesWritable(writable1);
    Assert.assertTrue("Mismatch", writable1.equals(writable2));


would fail with AssertionFailedError.
The reason for this is 


  public ImmutableBytesWritable(final ImmutableBytesWritable ibw) {
    this(ibw.get(), 0, ibw.getSize());
  }


the constructor would always assume 0 as the offset while it can get it from ibw.getOffset() method.</description>
			<version>0.94.8</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.ImmutableBytesWritable.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">8781</link>
		</links>
	</bug>
	<bug id="10020" opendate="2013-11-23 02:29:39" fixdate="2013-11-28 00:03:49" resolution="Fixed">
		<buginformation>
			<summary>Add maven compile-protobuf profile</summary>
			<description>Ad a maven profile to compile protobufs instead of the dev-support script which is only for hbase-protocol module. 


mvn test-compile -Dcompile-protobuf 

</description>
			<version>0.95.2</version>
			<fixedVersion>0.98.0, 0.96.1</fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.rest.protobuf.generated.ColumnSchemaMessage.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.example.generated.BulkDeleteProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.example.generated.ExampleProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.protobuf.generated.VersionMessage.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.protobuf.generated.PingProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.protobuf.generated.ScannerMessage.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.protobuf.generated.TestProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.protobuf.generated.TableSchemaMessage.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.protobuf.generated.TableInfoMessage.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">7557</link>
		</links>
	</bug>
	<bug id="7825" opendate="2013-02-12 00:46:26" fixdate="2014-01-14 17:34:53" resolution="Duplicate">
		<buginformation>
			<summary>Retire non distributed log splitting related code</summary>
			<description>I think we only use distributed log splitting now and the legacy code before distributed log splitting should be retired. Any objections?
Thanks,
-Jeffrey</description>
			<version>0.95.2</version>
			<fixedVersion></fixedVersion>
			<type>Wish</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestHLogSplit.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestSplitLogManager.java</file>
			<file type="M">org.apache.hadoop.hbase.HConstants.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestDistributedLogSplitting.java</file>
			<file type="M">org.apache.hadoop.hbase.master.SplitLogManager.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.TestWALObserver.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestHLogMethods.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.java</file>
			<file type="M">org.apache.hadoop.hbase.exceptions.OrphanHLogAfterSplitException.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestHLog.java</file>
			<file type="M">org.apache.hadoop.hbase.zookeeper.ZKSplitLog.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestWALReplay.java</file>
			<file type="M">org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">8962</link>
			<link type="Reference" description="relates to">7006</link>
		</links>
	</bug>
	<bug id="10371" opendate="2014-01-17 03:25:42" fixdate="2014-01-27 19:51:12" resolution="Fixed">
		<buginformation>
			<summary>Compaction creates empty hfile, then selects this file for compaction and creates empty hfile and over again</summary>
			<description>(1) Select HFile for compaction


2014-01-16 01:01:25,111 INFO org.apache.hadoop.hbase.regionserver.compactions.CompactSelection: Deleting the expired store file by compaction: hdfs://dump002002.cm6:9000/hbase-0.90/storagetable/7d8941661904fb99a41f79a1fce47767/a/f3e38d10d579420494079e17a2557f0b whose maxTimeStamp is -1 while the max expired timestamp is 1389632485111


(2) Compact


2014-01-16 01:01:26,042 DEBUG org.apache.hadoop.hbase.regionserver.Compactor: Compacting hdfs://dump002002.cm6:9000/hbase-0.90/storagetable/7d8941661904fb99a41f79a1fce47767/a/f3e38d10d579420494079e17a2557f0b, keycount=0, bloomtype=NONE, size=534, encoding=NONE
2014-01-16 01:01:26,045 DEBUG org.apache.hadoop.hbase.util.FSUtils: Creating file=hdfs://dump002002.cm6:9000/hbase-0.90/storagetable/7d8941661904fb99a41f79a1fce47767/.tmp/40de5d79f80e4fb197e409fb99ab0fd8 with permission=rwxrwxrwx
2014-01-16 01:01:26,076 INFO org.apache.hadoop.hbase.regionserver.Store: Renaming compacted file at hdfs://dump002002.cm6:9000/hbase-0.90/storagetable/7d8941661904fb99a41f79a1fce47767/.tmp/40de5d79f80e4fb197e409fb99ab0fd8 to hdfs://dump002002.cm6:9000/hbase-0.90/storagetable/7d8941661904fb99a41f79a1fce47767/a/40de5d79f80e4fb197e409fb99ab0fd8
2014-01-16 01:01:26,142 INFO org.apache.hadoop.hbase.regionserver.Store: Completed compaction of 1 file(s) in a of storagetable,01:,1369377609136.7d8941661904fb99a41f79a1fce47767. into 40de5d79f80e4fb197e409fb99ab0fd8, size=534; total size for store is 399.0 M
2014-01-16 01:01:26,142 INFO org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest: completed compaction: regionName=storagetable,01:,1369377609136.7d8941661904fb99a41f79a1fce47767., storeName=a, fileCount=1, fileSize=534, priority=16, time=18280340606333745; duration=0sec


(3) Select HFile for compaction


2014-01-16 03:48:05,120 INFO org.apache.hadoop.hbase.regionserver.compactions.CompactSelection: Deleting the expired store file by compaction: hdfs://dump002002.cm6:9000/hbase-0.90/storagetable/7d8941661904fb99a41f79a1fce47767/a/40de5d79f80e4fb197e409fb99ab0fd8 whose maxTimeStamp is -1 while the max expired timestamp is 1389642485120


(4) Compact


2014-01-16 03:50:17,731 DEBUG org.apache.hadoop.hbase.regionserver.Compactor: Compacting hdfs://dump002002.cm6:9000/hbase-0.90/storagetable/7d8941661904fb99a41f79a1fce47767/a/40de5d79f80e4fb197e409fb99ab0fd8, keycount=0, bloomtype=NONE, size=534, encoding=NONE
2014-01-16 03:50:17,732 DEBUG org.apache.hadoop.hbase.util.FSUtils: Creating file=hdfs://dump002002.cm6:9000/hbase-0.90


... 
this loop for ever.</description>
			<version>0.94.1</version>
			<fixedVersion>0.98.0, 0.96.2, 0.99.0, 0.94.17</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestDefaultCompactSelection.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.compactions.RatioBasedCompactionPolicy.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MockStoreFile.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">6749</link>
		</links>
	</bug>
	<bug id="10448" opendate="2014-01-31 18:24:55" fixdate="2014-02-01 23:05:10" resolution="Fixed">
		<buginformation>
			<summary>ZKUtil create and watch methods don&amp;apos;t set watch in some cases</summary>
			<description>While using the ZKUtil methods during testing, I found that watch was not set when it should be set based on the methods and method comments:
createNodeIfNotExistsAndWatch
createEphemeralNodeAndWatch
For example, in createNodeIfNotExistsAndWatch():


 public static boolean createNodeIfNotExistsAndWatch(
      ZooKeeperWatcher zkw, String znode, byte [] data)
  throws KeeperException {
    try {
      zkw.getRecoverableZooKeeper().create(znode, data, createACL(zkw, znode),
          CreateMode.PERSISTENT);
    } catch (KeeperException.NodeExistsException nee) {
      try {
        zkw.getRecoverableZooKeeper().exists(znode, zkw);
      } catch (InterruptedException e) {
        zkw.interruptedException(e);
        return false;
      }
      return false;
    } catch (InterruptedException e) {
      zkw.interruptedException(e);
      return false;
    }
    return true;
  }


The watch is only set via exists() call when the node already exists.
Similarly in createEphemeralNodeAndWatch():


  public static boolean createEphemeralNodeAndWatch(ZooKeeperWatcher zkw,
      String znode, byte [] data)
  throws KeeperException {
    try {
      zkw.getRecoverableZooKeeper().create(znode, data, createACL(zkw, znode),
          CreateMode.EPHEMERAL);
    } catch (KeeperException.NodeExistsException nee) {
      if(!watchAndCheckExists(zkw, znode)) {
        // It did exist but now it doesn&amp;amp;apos;t, try again
        return createEphemeralNodeAndWatch(zkw, znode, data);
      }
      return false;
    } catch (InterruptedException e) {
      LOG.info("Interrupted", e);
      Thread.currentThread().interrupt();
    }
    return true;
  }

</description>
			<version>0.96.0</version>
			<fixedVersion>0.98.0, 0.96.2, 0.99.0, 0.94.17</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">8937</link>
		</links>
	</bug>
	<bug id="8937" opendate="2013-07-12 04:25:27" fixdate="2014-02-02 05:43:06" resolution="Duplicate">
		<buginformation>
			<summary>createEphemeralNodeAndWatch don&amp;apos;t set watcher if the node is created successfully</summary>
			<description>CreateEphemeralNodeAndWatch in zkUtil don&amp;amp;apos;t set watcher if the node is created successfully. This is not consistent with the comment and may causes the ActiveMasterManager cannot get events that master node is deleted or changed.


  public static boolean createEphemeralNodeAndWatch(ZooKeeperWatcher zkw,
      String znode, byte [] data)
  throws KeeperException {
    try {
      zkw.getRecoverableZooKeeper().create(znode, data, createACL(zkw, znode),
          CreateMode.EPHEMERAL);
    } catch (KeeperException.NodeExistsException nee) {
      if(!watchAndCheckExists(zkw, znode)) {
        // It did exist but now it doesn&amp;amp;apos;t, try again
        return createEphemeralNodeAndWatch(zkw, znode, data);
      }
      return false;
    } catch (InterruptedException e) {
      LOG.info("Interrupted", e);
      Thread.currentThread().interrupt();
    }
    return true;
  }


</description>
			<version>0.96.0</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">10448</link>
		</links>
	</bug>
	<bug id="10622" opendate="2014-02-27 00:24:03" fixdate="2014-03-04 11:21:37" resolution="Fixed">
		<buginformation>
			<summary>Improve log and Exceptions in Export Snapshot </summary>
			<description>from the logs of export snapshot is not really clear what&amp;amp;apos;s going on,
adding some extra information useful to debug, and in some places the real exception can be thrown</description>
			<version>0.96.0</version>
			<fixedVersion>0.96.2, 0.98.1, 0.99.0, 0.94.18</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.snapshot.ExportSnapshot.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">10913</link>
		</links>
	</bug>
	<bug id="10169" opendate="2013-12-16 02:18:08" fixdate="2014-03-12 15:59:12" resolution="Fixed">
		<buginformation>
			<summary>Batch coprocessor</summary>
			<description>This is designed to improve the coprocessor invocation in the client side. 
Currently the coprocessor invocation is to send a call to each region. If theres one region server, and 100 regions are located in this server, each coprocessor invocation will send 100 calls, each call uses a single thread in the client side. The threads will run out soon when the coprocessor invocations are heavy. 
In this design, all the calls to the same region server will be grouped into one in a single coprocessor invocation. This call will be spread into each region in the server side.</description>
			<version>0.99.0</version>
			<fixedVersion>0.98.1, 0.99.0</fixedVersion>
			<type>Sub-task</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.RegionCoprocessorServiceExec.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.ClientProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTableWrapper.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTablePool.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.ResponseConverter.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.client.RemoteHTable.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.ColumnAggregationEndpoint.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.CoprocessorHost.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTableInterface.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">3726</link>
			<link type="Reference" description="relates to">10721</link>
			<link type="Required" description="is required by">10170</link>
		</links>
	</bug>
	<bug id="3726" opendate="2011-04-01 21:47:05" fixdate="2014-03-14 23:57:25" resolution="Duplicate">
		<buginformation>
			<summary>Allow coprocessor callback RPC calls to be batched at region server level</summary>
			<description>Cuurently the Callback.update() method is called for each Call.call() return value obtained from each region.  Each Call.call() invocation is a separate RPC, so there is currently one RPC per region. So there&amp;amp;apos;s no place at the moment for the region server to be involved in any aggregation across regions.
There is some preliminary support in HConnectionManager.HConnectionImplementation.processBatch() that would allow doing 1 RPC per region server, same as we do for multi-get and multi-put.
We should provide ability to batch callback RPC calls.</description>
			<version>0.99.0</version>
			<fixedVersion></fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.RegionCoprocessorServiceExec.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.ClientProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTableWrapper.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTablePool.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.ResponseConverter.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.client.RemoteHTable.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.ColumnAggregationEndpoint.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.CoprocessorHost.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTableInterface.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">10169</link>
		</links>
	</bug>
	<bug id="10913" opendate="2014-04-05 02:16:27" fixdate="2014-04-05 03:04:19" resolution="Duplicate">
		<buginformation>
			<summary>Print exception of why a copy failed during ExportSnapshot</summary>
			<description>Currently we print a vague "Failed to copy the snapshot directory from X to Y" whenever X pre-exists on Y. Users have to figure this out by themselves.</description>
			<version>0.96.0</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.snapshot.ExportSnapshot.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">10622</link>
		</links>
	</bug>
	<bug id="8991" opendate="2013-07-18 21:00:31" fixdate="2014-04-23 17:35:00" resolution="Fixed">
		<buginformation>
			<summary>TestMasterFailover.testMasterFailoverWithMockedRITOnDeadRS failed again</summary>
			<description>It failed again http://54.241.6.143/job/HBase-0.95-Hadoop-2/org.apache.hbase$hbase-server/645/testReport/junit/org.apache.hadoop.hbase.master/TestMasterFailover/testMasterFailoverWithMockedRITOnDeadRS/

Stacktrace

java.lang.AssertionError: region=enabledTable,e\xDC\xB4,1374137106469.efad8aaaf052f839fdbf5abc2e04af4c., [{ENCODED =&amp;gt; 1028785192, NAME =&amp;gt; &amp;amp;apos;.META.,,1&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;&amp;amp;apos;}, {ENCODED =&amp;gt; 1e14e83d175bb4dc82a6eac427b0397c, NAME =&amp;gt; &amp;amp;apos;disabledTable,,1374137107108.1e14e83d175bb4dc82a6eac427b0397c.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;aaa&amp;amp;apos;}, {ENCODED =&amp;gt; 2ce3188d9e655c74aeed8627699d198b, NAME =&amp;gt; &amp;amp;apos;disabledTable,aaa,1374137107131.2ce3188d9e655c74aeed8627699d198b.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;aaa&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;bF\xD8&amp;amp;apos;}, {ENCODED =&amp;gt; a87139be050d4e945fc4523cf2bd1467, NAME =&amp;gt; &amp;amp;apos;disabledTable,bF\xD8,1374137107163.a87139be050d4e945fc4523cf2bd1467.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;bF\xD8&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;c,O&amp;amp;apos;}, {ENCODED =&amp;gt; 822ce4ce69d81d4e1d6e5e8200887240, NAME =&amp;gt; &amp;amp;apos;disabledTable,c,O,1374137107170.822ce4ce69d81d4e1d6e5e8200887240.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;c,O&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;d\x11\xC6&amp;amp;apos;}, {ENCODED =&amp;gt; ad4209578ff51f67e975135f23b7ac13, NAME =&amp;gt; &amp;amp;apos;disabledTable,d\x11\xC6,1374137107176.ad4209578ff51f67e975135f23b7ac13.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;d\x11\xC6&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;d\xF7=&amp;amp;apos;}, {ENCODED =&amp;gt; 20c540d9d7213cf8dbf4b4b90007e7ad, NAME =&amp;gt; &amp;amp;apos;disabledTable,d\xF7=,1374137107182.20c540d9d7213cf8dbf4b4b90007e7ad.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;d\xF7=&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;e\xDC\xB4&amp;amp;apos;}, {ENCODED =&amp;gt; 04d860ad0b8e0ae5a0147a6bccea46f4, NAME =&amp;gt; &amp;amp;apos;enabledTable,,1374137106279.04d860ad0b8e0ae5a0147a6bccea46f4.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;aaa&amp;amp;apos;}, {ENCODED =&amp;gt; b5486e3cf48aa50ca1cba30d0d6ab662, NAME =&amp;gt; &amp;amp;apos;enabledTable,aaa,1374137106428.b5486e3cf48aa50ca1cba30d0d6ab662.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;aaa&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;bF\xD8&amp;amp;apos;}, {ENCODED =&amp;gt; c11af1f6d1aa422916caf6e6ac17eeeb, NAME =&amp;gt; &amp;amp;apos;enabledTable,bF\xD8,1374137106437.c11af1f6d1aa422916caf6e6ac17eeeb.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;bF\xD8&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;c,O&amp;amp;apos;}, {ENCODED =&amp;gt; 5e4dffd62115d6745b589e40136179c7, NAME =&amp;gt; &amp;amp;apos;enabledTable,c,O,1374137106444.5e4dffd62115d6745b589e40136179c7.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;c,O&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;d\x11\xC6&amp;amp;apos;}, {ENCODED =&amp;gt; 0a7dc5f03fa7db89e2ed3aa7512bc6cd, NAME =&amp;gt; &amp;amp;apos;enabledTable,d\x11\xC6,1374137106455.0a7dc5f03fa7db89e2ed3aa7512bc6cd.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;d\x11\xC6&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;d\xF7=&amp;amp;apos;}, {ENCODED =&amp;gt; 8f406facf525870443e93345a3172fbb, NAME =&amp;gt; &amp;amp;apos;enabledTable,d\xF7=,1374137106463.8f406facf525870443e93345a3172fbb.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;d\xF7=&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;e\xDC\xB4&amp;amp;apos;}, {ENCODED =&amp;gt; 9daab73408eb240c4780493b6661eb7b, NAME =&amp;gt; &amp;amp;apos;enabledTable,f\xC2+,1374137106475.9daab73408eb240c4780493b6661eb7b.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;f\xC2+&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;g\xA7\xA2&amp;amp;apos;}, {ENCODED =&amp;gt; 47911855a8362112a57c3767d6864ced, NAME =&amp;gt; &amp;amp;apos;enabledTable,g\xA7\xA2,1374137106482.47911855a8362112a57c3767d6864ced.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;g\xA7\xA2&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;h\x8D\x19&amp;amp;apos;}, {ENCODED =&amp;gt; e6c71e364bfc9766c1336c9c912b9466, NAME =&amp;gt; &amp;amp;apos;enabledTable,h\x8D\x19,1374137106488.e6c71e364bfc9766c1336c9c912b9466.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;h\x8D\x19&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;ir\x90&amp;amp;apos;}, {ENCODED =&amp;gt; 63ae8de95f8149c04a18c90ac0ba99db, NAME =&amp;gt; &amp;amp;apos;enabledTable,ir\x90,1374137106494.63ae8de95f8149c04a18c90ac0ba99db.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;ir\x90&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;jX\x07&amp;amp;apos;}, {ENCODED =&amp;gt; f477cc9a5378ef9ac464c5ffccf5d295, NAME =&amp;gt; &amp;amp;apos;enabledTable,jX\x07,1374137106500.f477cc9a5378ef9ac464c5ffccf5d295.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;jX\x07&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;k=~&amp;amp;apos;}, {ENCODED =&amp;gt; d366f300dffeae98f6c0ace8222dc3e4, NAME =&amp;gt; &amp;amp;apos;enabledTable,k=~,1374137106506.d366f300dffeae98f6c0ace8222dc3e4.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;k=~&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;l"\xF5&amp;amp;apos;}, {ENCODED =&amp;gt; ca8b5a676edb14a42bf80de8c6eb2f84, NAME =&amp;gt; &amp;amp;apos;enabledTable,m\x08l,1374137106518.ca8b5a676edb14a42bf80de8c6eb2f84.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;m\x08l&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;m\xED\xE3&amp;amp;apos;}]
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.apache.hadoop.hbase.master.TestMasterFailover.testMasterFailoverWithMockedRITOnDeadRS(TestMasterFailover.java:815)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

</description>
			<version>0.95.2</version>
			<fixedVersion></fixedVersion>
			<type>Test</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestMasterFailover.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">8992</link>
			<link type="Reference" description="relates to">8295</link>
		</links>
	</bug>
	<bug id="10960" opendate="2014-04-10 22:31:53" fixdate="2014-04-25 22:50:22" resolution="Fixed">
		<buginformation>
			<summary>Enhance HBase Thrift 1 to include "append" and "checkAndPut" operations</summary>
			<description>Both append, and checkAndPut functionalities are available in Thrift 2 interface, but not in Thrift. So, adding the support for these functionalities in Thrift1 too.</description>
			<version>0.89.20100924</version>
			<fixedVersion>0.99.0</fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.thrift.ThriftUtilities.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.TestThriftServer.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.generated.Hbase.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">3307</link>
		</links>
	</bug>
	<bug id="11089" opendate="2014-04-28 14:22:59" fixdate="2014-04-28 16:32:56" resolution="Duplicate">
		<buginformation>
			<summary>Use proxy user for security integration test where multiple users are needed</summary>
			<description>We have seen the following test failure:


2014-02-06 02:58:25,315|beaver.machine|INFO|RUNNING: /usr/bin/kinit -c /grid/0/hadoopqe/artifacts/kerberosTickets/hbase.kerberos.ticket -k -t /home/hrt_qa/hadoopqa/keytabs/hbase.headless.keytab hbase
2014-02-06 02:58:25,325|beaver.machine|INFO|RUNNING: /usr/lib/hbase/bin/hbase --config /tmp/hbaseConf org.apache.hadoop.hbase.IntegrationTestsDriver -regex IntegrationTestIngestWithACL

2014-02-06 02:58:34,489|beaver.machine|INFO|2014-02-06 02:58:34,489 DEBUG HBaseWriterThreadWithACL_1 token.AuthenticationTokenSelector: No matching token found
2014-02-06 02:58:34,493|beaver.machine|INFO|2014-02-06 02:58:34,489 DEBUG HBaseWriterThreadWithACL_1 security.HBaseSaslRpcClient: Creating SASL GSSAPI client. Server&amp;amp;apos;s Kerberos principal name is hbase/h2-ubuntu12-sec-1391405488-hbase-7.cs1cloud.internal@EXAMPLE.COM
2014-02-06 02:58:34,493|beaver.machine|INFO|2014-02-06 02:58:34,491 WARN HBaseWriterThreadWithACL_1 security.UserGroupInformation: PriviledgedActionException as:owner (auth:SIMPLE) cause:javax.security.sasl.SaslException: GSS initiate failed Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)
2014-02-06 02:58:34,493|beaver.machine|INFO|2014-02-06 02:58:34,492 WARN HBaseWriterThreadWithACL_1 ipc.RpcClient: Exception encountered while connecting to the server : javax.security.sasl.SaslException: GSS initiate failed Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)
2014-02-06 02:58:34,498|beaver.machine|INFO|2014-02-06 02:58:34,493 FATAL HBaseWriterThreadWithACL_1 ipc.RpcClient: SASL authentication failed. The most likely cause is missing or invalid credentials. Consider &amp;amp;apos;kinit&amp;amp;apos;.
2014-02-06 02:58:34,499|beaver.machine|INFO|javax.security.sasl.SaslException: GSS initiate failed Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)
2014-02-06 02:58:34,499|beaver.machine|INFO|at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:194)
2014-02-06 02:58:34,499|beaver.machine|INFO|at org.apache.hadoop.hbase.security.HBaseSaslRpcClient.saslConnect(HBaseSaslRpcClient.java:152)
2014-02-06 02:58:34,500|beaver.machine|INFO|at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupSaslConnection(RpcClient.java:762)


The above test failure was due to the second user in the test not being able to authenticate using kerberos.
This can be solved using impersonation which is described here : http://hadoop.apache.org/docs/r1.2.1/Secure_Impersonation.html
The superuser needs to authenticate using kerberos. The superuser can impersonate any member of the specified groups.</description>
			<version>0.98.1</version>
			<fixedVersion></fixedVersion>
			<type>Task</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.MultiThreadedReaderWithACL.java</file>
			<file type="M">org.apache.hadoop.hbase.util.MultiThreadedUpdaterWithACL.java</file>
			<file type="M">org.apache.hadoop.hbase.IntegrationTestIngestWithACL.java</file>
			<file type="M">org.apache.hadoop.hbase.util.LoadTestTool.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">10831</link>
		</links>
	</bug>
	<bug id="11222" opendate="2014-05-21 11:23:59" fixdate="2014-05-21 15:30:46" resolution="Duplicate">
		<buginformation>
			<summary>Add integration test for visibility deletes</summary>
			<description>Once HBASE-10885 gets checked in, create integration tests to verify the same.  </description>
			<version>0.98.1</version>
			<fixedVersion></fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.Import.java</file>
			<file type="M">org.apache.hadoop.hbase.security.access.AccessControlClient.java</file>
			<file type="M">org.apache.hadoop.hbase.security.visibility.CellVisibility.java</file>
			<file type="M">org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">11039</link>
			<link type="dependent" description="depends upon">10885</link>
		</links>
	</bug>
	<bug id="10831" opendate="2014-03-25 18:48:32" fixdate="2014-05-23 02:01:58" resolution="Fixed">
		<buginformation>
			<summary>IntegrationTestIngestWithACL is not setting up LoadTestTool correctly</summary>
			<description>IntegrationTestIngestWithACL is not setting up LoadTestTool correctly.

Tests run: 1, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 601.709 sec &amp;lt;&amp;lt;&amp;lt; FAILURE!
testIngest(org.apache.hadoop.hbase.IntegrationTestIngestWithACL)  Time elapsed: 601.489 sec  &amp;lt;&amp;lt;&amp;lt; FAILURE!
java.lang.AssertionError: Failed to initialize LoadTestTool expected:&amp;lt;0&amp;gt; but was:&amp;lt;1&amp;gt;
        at org.junit.Assert.fail(Assert.java:88)
        at org.junit.Assert.failNotEquals(Assert.java:743)
        at org.junit.Assert.assertEquals(Assert.java:118)
        at org.junit.Assert.assertEquals(Assert.java:555)
        at org.apache.hadoop.hbase.IntegrationTestIngest.initTable(IntegrationTestIngest.java:74)
        at org.apache.hadoop.hbase.IntegrationTestIngest.setUpCluster(IntegrationTestIngest.java:69)
        at org.apache.hadoop.hbase.IntegrationTestIngestWithACL.setUpCluster(IntegrationTestIngestWithACL.java:58)
        at org.apache.hadoop.hbase.IntegrationTestBase.setUp(IntegrationTestBase.java:89)


Could be related to HBASE-10675?</description>
			<version>0.98.1</version>
			<fixedVersion>0.99.0, 0.98.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.MultiThreadedReaderWithACL.java</file>
			<file type="M">org.apache.hadoop.hbase.util.MultiThreadedUpdaterWithACL.java</file>
			<file type="M">org.apache.hadoop.hbase.IntegrationTestIngestWithACL.java</file>
			<file type="M">org.apache.hadoop.hbase.util.LoadTestTool.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">11089</link>
		</links>
	</bug>
	<bug id="11052" opendate="2014-04-23 08:18:10" fixdate="2014-06-18 16:09:01" resolution="Fixed">
		<buginformation>
			<summary>Sending random data crashes thrift service</summary>
			<description>Upstream thrift library has a know issue (THRIFT-601) causing the thrift server to crash with an Out-of-Memory Error when bogus requests are sent.
This reproduces when a very large request size is sent in the request header, making the thrift server to allocate a large memory segment leading to OOM.
LoadBalancer health checks are the first "candidate" for bogus requests
Thrift developers admit this is a known issue with TBinaryProtocol and their recommandation is to use TCompactProtocol/TFramedTransport but this requires all thrift clients to be updated (might not be feasible atm)
So we need a fix similar to CASSANDRA-475.</description>
			<version>0.94.18</version>
			<fixedVersion>0.99.0, 0.94.21, 0.98.4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.thrift2.ThriftServer.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">11420</link>
		</links>
	</bug>
	<bug id="11374" opendate="2014-06-18 09:42:39" fixdate="2014-06-20 08:20:27" resolution="Fixed">
		<buginformation>
			<summary>RpcRetryingCaller#callWithoutRetries has a timeout of zero</summary>
			<description>This code is called by the client on the "multi" path.
As zero is detected as infinite value, we fallback to 2 seconds, which may not may correct.
Typically, you can see this kind of message in the client (see the SocketTimeoutException: 2000)

2014-08-08 17:22:43 o.a.h.h.c.AsyncProcess [INFO] #105158,
table=rt_global_monthly_campaign_deliveries, attempt=10/35 failed 500 ops,
last exception: java.net.SocketTimeoutException: Call to
ip-10-201-128-23.us-west-1.compute.internal/10.201.128.23:60020 failed
because java.net.SocketTimeoutException: 2000 millis timeout while waiting
for channel to be ready for read. ch :
java.nio.channels.SocketChannel[connected local=/10.248.130.152:46014
remote=ip-10-201-128-23.us-west-1.compute.internal/10.201.128.23:60020] on
ip-10-201-128-23.us-west-1.compute.internal,60020,1405642103651, tracking
started Fri Aug 08 17:21:55 UTC 2014, retrying after 10043 ms, replay 500
ops.

</description>
			<version>0.98.3</version>
			<fixedVersion>0.99.0, 0.98.4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.AsyncProcess.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">11714</link>
		</links>
	</bug>
	<bug id="11420" opendate="2014-06-27 10:53:15" fixdate="2014-07-01 03:53:12" resolution="Duplicate">
		<buginformation>
			<summary>ThriftServer (version 1) may crash on OOME</summary>
			<description>When using ThriftServer as a gateway for php &amp;amp; c/c++ applications, I found it very easy to crash of OOME. I analyzed the jprof file and found that the ThriftServer had a 1.2G size byte array before it crashed. It seems to be a memory leak. But when did it happen? I checked the huge byte array and realized that it was a HTTP request string. That means a request in protocols other than Thrift may cause memory allocation exception. 
We cound easily recur the bug by wget/curl the ThriftServer. And we can check the memory usage infomation using TOP command.</description>
			<version>0.98.2</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.thrift2.ThriftServer.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">11052</link>
		</links>
	</bug>
	<bug id="4931" opendate="2011-12-01 23:36:52" fixdate="2014-07-10 08:50:05" resolution="Fixed">
		<buginformation>
			<summary>CopyTable instructions could be improved.</summary>
			<description>The book and the usage instructions could be improved to include more details, things caveats and to better explain usage.
One example in particular, could be updated to refer to ReplicationRegionInterface and ReplicationRegionServer in thier current locations (o.a.h.h.client.replication and o.a.h.h.replication.regionserver), and better explain why one would use particular arguments.


$ bin/hbase org.apache.hadoop.hbase.mapreduce.CopyTable
--rs.class=org.apache.hadoop.hbase.ipc.ReplicationRegionInterface
--rs.impl=org.apache.hadoop.hbase.regionserver.replication.ReplicationRegionServer
--starttime=1265875194289 --endtime=1265878794289
--peer.adr=server1,server2,server3:2181:/hbase TestTable

</description>
			<version>0.90.4</version>
			<fixedVersion>0.99.0, 2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.CopyTable.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">5834</link>
			<link type="Reference" description="is related to">4614</link>
		</links>
	</bug>
	<bug id="11039" opendate="2014-04-19 14:18:22" fixdate="2014-07-14 06:36:53" resolution="Fixed">
		<buginformation>
			<summary>[VisibilityController] Integration test for labeled data set mixing and filtered excise</summary>
			<description>Create an integration test for the VisibilityController that:
1. Create several tables of test data
2. Assign a set of auths to each table. Label all entries in the table with appropriate visibility expressions. Insure that some data in every table overlaps with data in other tables at common row/family/qualifier coordinates. Generate data like ITBLL so we can verify all data present later.
3. Mix the data from the different tables into a new common table
4. Verify for each set of auths defined in step #2 that all entries found in the source table can be found in the common table. Like the ITBLL verification step but done N times for each set of auths defined in step #2.
5. Choose one of the source tables. Get its set of auths. Perform a deletion with visibility expression from the common table using those auths.
6. Verify that no data in the common table with the auth set chosen in #5 remains. A simple row count with the set of auths chosen in #5 that should return 0.</description>
			<version>0.98.1</version>
			<fixedVersion>0.98.4</fixedVersion>
			<type>Test</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.Import.java</file>
			<file type="M">org.apache.hadoop.hbase.security.access.AccessControlClient.java</file>
			<file type="M">org.apache.hadoop.hbase.security.visibility.CellVisibility.java</file>
			<file type="M">org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">11222</link>
			<link type="Reference" description="relates to">11509</link>
		</links>
	</bug>
	<bug id="11612" opendate="2014-07-30 00:16:23" fixdate="2014-07-30 00:23:17" resolution="Duplicate">
		<buginformation>
			<summary>Remove MetaMigrationConvertingToPB </summary>
			<description>Can MetaMigrationConvertingToPB be removed now from 0.98 onwards? The javadoc says it should be removed on a major release after 0.96. It does a full Meta scan which takes quite some time especially if there are around 1M regions.</description>
			<version>0.98.4</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="D">org.apache.hadoop.hbase.MetaMigrationConvertingToPB.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="D">org.apache.hadoop.hbase.TestMetaMigrationConvertingToPB.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">11333</link>
		</links>
	</bug>
	<bug id="11333" opendate="2014-06-11 22:59:41" fixdate="2014-08-07 20:10:14" resolution="Fixed">
		<buginformation>
			<summary>Remove deprecated class MetaMigrationConvertingToPB</summary>
			<description>MetaMigrationConvertingToPB is marked deprecated and to be deleted next major release after 0.96. Is that the time?</description>
			<version>0.99.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="D">org.apache.hadoop.hbase.MetaMigrationConvertingToPB.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="D">org.apache.hadoop.hbase.TestMetaMigrationConvertingToPB.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">11612</link>
			<link type="Reference" description="relates to">6052</link>
		</links>
	</bug>
	<bug id="11714" opendate="2014-08-09 08:57:02" fixdate="2014-08-11 08:54:03" resolution="Duplicate">
		<buginformation>
			<summary>RpcRetryingCaller#callWithoutRetries set rpc timeout to 2 seconds incorrectly</summary>
			<description>Discussed on the user@hbase mailing list (http://markmail.org/thread/w3cqjxwo2smkn2jw)

"Recently switched from 0.94 and 0.98, and finding that periodically things
are having issues - lots of retry exceptions" :
client log:

2014-08-08 17:22:43 o.a.h.h.c.AsyncProcess [INFO] #105158,
table=rt_global_monthly_campaign_deliveries, attempt=10/35 failed 500 ops,
last exception: java.net.SocketTimeoutException: Call to
ip-10-201-128-23.us-west-1.compute.internal/10.201.128.23:60020 failed
because java.net.SocketTimeoutException: 2000 millis timeout while waiting
for channel to be ready for read. ch :
java.nio.channels.SocketChannel[connected local=/10.248.130.152:46014
remote=ip-10-201-128-23.us-west-1.compute.internal/10.201.128.23:60020] on
ip-10-201-128-23.us-west-1.compute.internal,60020,1405642103651, tracking
started Fri Aug 08 17:21:55 UTC 2014, retrying after 10043 ms, replay 500
ops.
analysis:
there are 2 methods in RpcRetryingCaller: callWithRetries and callWithoutRetries.
it looks the timeout setup of callWithRetries is good, while callWithoutRetries is wrong(multi RPC for this user): caller cannot specify a valid timeout, but callWithoutRetries still calls beforeCall, which looks a method for callWithRetries only,  to set timeout. since RpcRetryingCaller#callTimeout  is not set, thread local timeout is set to 2s(MIN_RPC_TIMEOUT) via RpcClient.setRpcTimeout, which is the final pinginterval set to the socket.
when there are heavy write workload and the rpc cannot complete in 2s, the client close the connection, so the server side connection is reset and finally exposes the problem in HBASE-11705</description>
			<version>0.98.3</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.AsyncProcess.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">11374</link>
			<link type="Reference" description="relates to">11705</link>
		</links>
	</bug>
	<bug id="7557" opendate="2013-01-14 19:58:34" fixdate="2014-08-21 21:23:58" resolution="Duplicate">
		<buginformation>
			<summary>Add a maven command to generate protobuf files</summary>
			<description>We can add a maven target / profile to generate the protofiles for us. </description>
			<version>0.95.2</version>
			<fixedVersion></fixedVersion>
			<type>New Feature</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.rest.protobuf.generated.ColumnSchemaMessage.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.example.generated.BulkDeleteProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.example.generated.ExampleProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.protobuf.generated.VersionMessage.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.protobuf.generated.PingProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.protobuf.generated.ScannerMessage.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.protobuf.generated.TestProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.protobuf.generated.TableSchemaMessage.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.protobuf.generated.TableInfoMessage.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">10020</link>
		</links>
	</bug>
	<bug id="12198" opendate="2014-10-07 22:37:42" fixdate="2014-10-10 03:45:13" resolution="Fixed">
		<buginformation>
			<summary>Fix the bug of not updating location cache</summary>
			<description>Fix the bug of not updating location cache.
Add a testcase for it.</description>
			<version>0.98.7</version>
			<fixedVersion>2.0.0, 0.98.8, 0.99.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.AsyncProcess.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTableMultiplexer.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">15221</link>
		</links>
	</bug>
	<bug id="12469" opendate="2014-11-13 14:32:31" fixdate="2014-11-13 18:46:53" resolution="Duplicate">
		<buginformation>
			<summary>Way to view current labels</summary>
			<description>There is currently no way to get the available labels for a system even if you are the super user.  You have to run a scan of hbase:labels and then interpret the output.</description>
			<version>0.98.6.1</version>
			<fixedVersion></fixedVersion>
			<type>New Feature</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.security.visibility.VisibilityController.java</file>
			<file type="M">org.apache.hadoop.hbase.security.visibility.VisibilityClient.java</file>
			<file type="M">org.apache.hadoop.hbase.security.visibility.DefaultVisibilityLabelServiceImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.VisibilityLabelsProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.security.visibility.VisibilityLabelService.java</file>
			<file type="M">org.apache.hadoop.hbase.security.visibility.ExpAsStringVisibilityLabelServiceImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithDefaultVisLabelService.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">12373</link>
		</links>
	</bug>
	<bug id="12491" opendate="2014-11-17 16:28:36" fixdate="2014-11-29 17:42:24" resolution="Fixed">
		<buginformation>
			<summary>TableMapReduceUtil.findContainingJar() NPE</summary>
			<description>Adding a bootclasspath library causes an NPE when running hbase map reduce jobs in TableMapReduceUtil.findContainingJar().  Classes in the library added to the bootclasspath get a null classpathLoader.   Check for a null loader in  TableMapReduceUtil.findContainingJar().</description>
			<version>0.99.2</version>
			<fixedVersion>2.0.0, 0.94.26, 0.98.9, 0.99.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">9913</link>
		</links>
	</bug>
	<bug id="12373" opendate="2014-10-29 05:49:29" fixdate="2014-12-11 23:25:22" resolution="Fixed">
		<buginformation>
			<summary>Provide a command to list visibility labels</summary>
			<description>A command to list visibility labels that are in place would be handy.
This is also in line with many of the other hbase list commands.</description>
			<version>0.98.7</version>
			<fixedVersion>1.0.0, 2.0.0, 0.98.9</fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.security.visibility.VisibilityController.java</file>
			<file type="M">org.apache.hadoop.hbase.security.visibility.VisibilityClient.java</file>
			<file type="M">org.apache.hadoop.hbase.security.visibility.DefaultVisibilityLabelServiceImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.VisibilityLabelsProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.security.visibility.VisibilityLabelService.java</file>
			<file type="M">org.apache.hadoop.hbase.security.visibility.ExpAsStringVisibilityLabelServiceImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithDefaultVisLabelService.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">12469</link>
			<link type="Reference" description="is related to">7663</link>
		</links>
	</bug>
	<bug id="5162" opendate="2012-01-10 00:35:44" fixdate="2014-12-17 20:48:34" resolution="Fixed">
		<buginformation>
			<summary>Basic client pushback mechanism</summary>
			<description>The current blocking we do when we are close to some limits (memstores over the multiplier factor, too many store files, global memstore memory) is bad, too coarse and confusing. After hitting HBASE-5161, it really becomes obvious that we need something better.
I did a little brainstorm with Stack, we came up quickly with two solutions:

Send some exception to the client, like OverloadedException, that&amp;amp;apos;s thrown when some situation happens like getting past the low memory barrier. It would be thrown when the client gets a handler and does some check while putting or deleting. The client would treat this a retryable exception but ideally wouldn&amp;amp;apos;t check .META. for a new location. It could be fancy and have multiple levels of pushback, like send the exception to 25% of the clients, and then go up if the situation persists. Should be "easy" to implement but we&amp;amp;apos;ll be using a lot more IO to send the payload over and over again (but at least it wouldn&amp;amp;apos;t sit in the RS&amp;amp;apos;s memory).
Send a message alongside a successful put or delete to tell the client to slow down a little, this way we don&amp;amp;apos;t have to do back and forth with the payload between the client and the server. It&amp;amp;apos;s a cleaner (I think) but more involved solution.

In every case the RS should do very obvious things to notify the operators of this situation, through logs, web UI, metrics, etc.
Other ideas?</description>
			<version>0.92.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>New Feature</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestClientPushback.java</file>
			<file type="M">org.apache.hadoop.hbase.client.RpcRetryingCallerFactory.java</file>
			<file type="M">org.apache.hadoop.hbase.client.StatsTrackingRpcRetryingCaller.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.ClientProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.HConstants.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
			<file type="M">org.apache.hadoop.hbase.client.RpcRetryingCaller.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ClusterConnection.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.WALEditsReplaySink.java</file>
			<file type="M">org.apache.hadoop.hbase.client.Result.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestAsyncProcess.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.TestRegionReplicaReplicationEndpoint.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ConnectionAdapter.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.ResponseConverter.java</file>
			<file type="M">org.apache.hadoop.hbase.client.AsyncProcess.java</file>
			<file type="M">org.apache.hadoop.hbase.client.MultiAction.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ConnectionManager.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionTestingUtility.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestReplicasClient.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestFastFailWithoutTestUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.RegionCoprocessorRpcChannel.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">5333</link>
			<link type="Reference" description="relates to">12703</link>
			<link type="Reference" description="relates to">12217</link>
			<link type="Reference" description="relates to">12841</link>
			<link type="Reference" description="relates to">12840</link>
			<link type="Reference" description="relates to">12986</link>
			<link type="Reference" description="relates to">14693</link>
			<link type="Reference" description="relates to">14756</link>
			<link type="Reference" description="relates to">12906</link>
			<link type="Reference" description="relates to">12702</link>
			<link type="Reference" description="is related to">6423</link>
			<link type="Reference" description="is related to">12911</link>
			<link type="Reference" description="is related to">12731</link>
			<link type="Reference" description="is related to">2981</link>
		</links>
	</bug>
	<bug id="12716" opendate="2014-12-18 13:54:00" fixdate="2014-12-28 15:52:08" resolution="Fixed">
		<buginformation>
			<summary>A bug in RegionSplitter.UniformSplit algorithm</summary>
			<description>Welcome to the review board: https://reviews.apache.org/r/29424/diff/#
I`m working for another issues HBASE-12590 and trying to use the UniformSplit algorithm in RegionSplitter. When the last bytes of start key and end key are adjacent in alphabetical order or ASCII order, the UniformSplit algorithm meet an NPE.
Like startkey: aaa, endkey :aab
       startkey:1111 endkey: 1112
For example, we write this simple test code:


import org.apache.hadoop.hbase.util.RegionSplitter.UniformSplit;
......
byte[] a1 = { &amp;amp;apos;a&amp;amp;apos;, &amp;amp;apos;a&amp;amp;apos;, &amp;amp;apos;a&amp;amp;apos; };
byte[] a2 = { &amp;amp;apos;a&amp;amp;apos;, &amp;amp;apos;a&amp;amp;apos;, &amp;amp;apos;b&amp;amp;apos; };
UniformSplit us = new UniformSplit();
byte[] mid = us.split(a1, a2);
......


We will get the ERROR:


Exception in thread "main" java.lang.NullPointerException
	at org.apache.hadoop.hbase.util.RegionSplitter$UniformSplit.split(RegionSplitter.java:986)


We hope this algorithm should be able to calculate the split point with an additional byte. for example:
"aaa" and "aab", split point= "aaaP"
"1111" and "1112", split point ="1111P" 
review board:https://reviews.apache.org/r/29424/
</description>
			<version>0.98.6</version>
			<fixedVersion>1.0.0, 2.0.0, 0.98.10, 1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.Bytes.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestBytes.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestRegionSplitter.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">12717</link>
		</links>
	</bug>
	<bug id="12717" opendate="2014-12-18 14:13:40" fixdate="2014-12-29 06:42:15" resolution="Duplicate">
		<buginformation>
			<summary>Pre-split algorithm in HBaseAdmin.create() can not find the split point</summary>
			<description>
When we set the start key and the end key in the function:
createTable(HTableDescriptor desc, byte[] startKey, byte[] endKey, int numRegions)
The current pre-split algorithm could not find a split point between the keys like "aaa" and "aab", "1111" and "1112". 
Example Code for this bug:
admin.createTable(htd, Bytes.toBytes("aaa"), Bytes.toBytes("aab"), 4);
we will get the following ERROR:
Exception in thread "main" java.lang.IllegalArgumentException: Unable to split key range into enough regions
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:473)
	at test.JavaTest.main(JavaTest.java:28)
We hope this pre-split algorithm should be able to calculate the split point with an additional byte. for example:
"aaa" and "aab", split point= "aaaP"
"1111" and "1112", split point ="1111P" 
</description>
			<version>0.98.6</version>
			<fixedVersion>2.0.0, 1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.Bytes.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestBytes.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestRegionSplitter.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">12716</link>
		</links>
	</bug>
	<bug id="12178" opendate="2014-10-06 16:18:20" fixdate="2015-01-09 19:25:26" resolution="Duplicate">
		<buginformation>
			<summary>Failed splits are kept in transition</summary>
			<description>When a region split fails ( took too long to write the reference files ) the region stays int SPLITTING_NEW state and in transition on the master forever. This will block balancer invocations.</description>
			<version>0.98.6.1</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.HBaseFsck.java</file>
			<file type="M">org.apache.hadoop.hbase.master.RegionStates.java</file>
			<file type="M">org.apache.hadoop.hbase.util.FSUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">12791</link>
		</links>
	</bug>
	<bug id="12821" opendate="2015-01-08 06:53:47" fixdate="2015-01-10 01:13:30" resolution="Duplicate">
		<buginformation>
			<summary>Describe on table doesn&amp;apos;t show table attributes on hbase shell</summary>
			<description>1) hbase(main):003:0&amp;gt; create &amp;amp;apos;test&amp;amp;apos;,&amp;amp;apos;CF&amp;amp;apos;
2) hbase(main):006:0&amp;gt; alter &amp;amp;apos;test&amp;amp;apos;, METADATA =&amp;gt; 
{&amp;amp;apos;TEST_PROPERTY&amp;amp;apos; =&amp;gt; &amp;amp;apos;TEST_VALUE&amp;amp;apos;}
3) hbase(main):007:0&amp;gt; describe &amp;amp;apos;test&amp;amp;apos;
{NAME =&amp;gt; &amp;amp;apos;CF&amp;amp;apos;, DATA_BLOCK_ENCODING =&amp;gt; &amp;amp;apos;NONE&amp;amp;apos;, BLOOMFILTER =&amp;gt; &amp;amp;apos;ROW&amp;amp;apos;, REPLICATION_SCOPE =&amp;gt; &amp;amp;apos;0&amp;amp;apos;, VERSIONS =&amp;gt; &amp;amp;apos;1&amp;amp;apos;, COMPRESSION =&amp;gt; &amp;amp;apos;NONE&amp;amp;apos;, MIN_VERSIONS =&amp;gt; &amp;amp;apos;0&amp;amp;apos;, TTL =&amp;gt; &amp;amp;apos;FOREVER&amp;amp;apos;, KEEP_DELETED_CELLS =&amp;gt; &amp;amp;apos;FALSE&amp;amp;apos;, BLOCKSIZE =&amp;gt; &amp;amp;apos;65536&amp;amp;apos;, IN_MEMORY =&amp;gt; &amp;amp;apos;false&amp;amp;apos;, BLOCKCACHE =&amp;gt; &amp;amp;apos;true&amp;amp;apos;}   

Issue : The added property , table attribute, isn&amp;amp;apos;t getting displayed.
Note : If we check the table description from master page, we can see the changed property.
&amp;amp;apos;test&amp;amp;apos;, {TABLE_ATTRIBUTES =&amp;gt; {METADATA =&amp;gt; {&amp;amp;apos;TEST_PROPERTY&amp;amp;apos; =&amp;gt; &amp;amp;apos;TEST_VALUE&amp;amp;apos;}}, 
{NAME =&amp;gt; &amp;amp;apos;CF&amp;amp;apos;}
 </description>
			<version>0.98.8</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.HTableDescriptor.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">12832</link>
		</links>
	</bug>
	<bug id="12791" opendate="2014-12-31 04:12:23" fixdate="2015-01-12 01:54:20" resolution="Fixed">
		<buginformation>
			<summary>HBase does not attempt to clean up an aborted split when the regionserver shutting down</summary>
			<description>HBase not cleaning the daughter region directories from HDFS  if region server shut down after creating the daughter region directories during the split.
Here the logs.
-&amp;gt; RS shutdown after creating the daughter regions.


2014-12-31 09:05:41,406 DEBUG [regionserver60020-splits-1419996941385] zookeeper.ZKAssign: regionserver:60020-0x14a9701e53100d1, quorum=localhost:2181, baseZNode=/hbase Transitioned node 80c665138d4fa32da4d792d8ed13206f from RS_ZK_REQUEST_REGION_SPLIT to RS_ZK_REQUEST_REGION_SPLIT
2014-12-31 09:05:41,514 DEBUG [regionserver60020-splits-1419996941385] regionserver.HRegion: Closing t,,1419996880699.80c665138d4fa32da4d792d8ed13206f.: disabling compactions &amp;amp; flushes
2014-12-31 09:05:41,514 DEBUG [regionserver60020-splits-1419996941385] regionserver.HRegion: Updates disabled for region t,,1419996880699.80c665138d4fa32da4d792d8ed13206f.
2014-12-31 09:05:41,516 INFO  [StoreCloserThread-t,,1419996880699.80c665138d4fa32da4d792d8ed13206f.-1] regionserver.HStore: Closed f
2014-12-31 09:05:41,518 INFO  [regionserver60020-splits-1419996941385] regionserver.HRegion: Closed t,,1419996880699.80c665138d4fa32da4d792d8ed13206f.
2014-12-31 09:05:49,922 DEBUG [regionserver60020-splits-1419996941385] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table t dd9731ee43b104da565257ca1539aa8c
2014-12-31 09:05:49,922 DEBUG [regionserver60020-splits-1419996941385] regionserver.HRegion: Instantiated t,,1419996941401.dd9731ee43b104da565257ca1539aa8c.
2014-12-31 09:05:49,929 DEBUG [regionserver60020-splits-1419996941385] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table t 2e40a44511c0e187d357d651f13a1dab
2014-12-31 09:05:49,929 DEBUG [regionserver60020-splits-1419996941385] regionserver.HRegion: Instantiated t,row2,1419996941401.2e40a44511c0e187d357d651f13a1dab.
Wed Dec 31 09:06:30 IST 2014 Terminating regionserver
2014-12-31 09:06:30,465 INFO  [Thread-8] regionserver.ShutdownHook: Shutdown hook starting; hbase.shutdown.hook=true; fsShutdownHook=org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer@42d2282e


-&amp;gt; Skipping rollback if RS stopped or stopping so we end up in dirty daughter regions in HDFS.


2014-12-31 09:07:49,547 INFO  [regionserver60020-splits-1419996941385] regionserver.SplitRequest: Skip rollback/cleanup of failed split of t,,1419996880699.80c665138d4fa32da4d792d8ed13206f. because server is stopped
java.io.InterruptedIOException: Interrupted after 0 tries  on 350
        at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:156)


Because of this hbck always showing inconsistencies. 


ERROR: Region { meta =&amp;gt; null, hdfs =&amp;gt; hdfs://localhost:9000/hbase/data/default/t/2e40a44511c0e187d357d651f13a1dab, deployed =&amp;gt;  } on HDFS, but not listed in hbase:meta or deployed on any region server
ERROR: Region { meta =&amp;gt; null, hdfs =&amp;gt; hdfs://localhost:9000/hbase/data/default/t/dd9731ee43b104da565257ca1539aa8c, deployed =&amp;gt;  } on HDFS, but not listed in hbase:meta or deployed on any region server


If we try to repair then we end up in overlap regions in hbase:meta. and both daughter regions and parent are online.</description>
			<version>0.98.0</version>
			<fixedVersion>1.0.0, 2.0.0, 0.98.10, 1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.HBaseFsck.java</file>
			<file type="M">org.apache.hadoop.hbase.master.RegionStates.java</file>
			<file type="M">org.apache.hadoop.hbase.util.FSUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestSplitTransactionOnCluster.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">12178</link>
		</links>
	</bug>
	<bug id="12828" opendate="2015-01-09 05:30:31" fixdate="2015-01-12 20:05:13" resolution="Duplicate">
		<buginformation>
			<summary>Add getTableAttributes API to HBaseAdmin class. </summary>
			<description>At present, there is no api/function to get table attributes. It would be nice to have a function that returns table attributes given the table name.</description>
			<version>0.98.8</version>
			<fixedVersion></fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.HTableDescriptor.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">12832</link>
		</links>
	</bug>
	<bug id="12832" opendate="2015-01-09 19:46:41" fixdate="2015-01-12 22:10:11" resolution="Fixed">
		<buginformation>
			<summary>Describe table from shell no longer shows Table&amp;apos;s attributes, only CF attributes</summary>
			<description>When you describe a table with some attributes at the table level, it is not shown from shell any more:


hbase(main):010:0&amp;gt; create &amp;amp;apos;usertable2&amp;amp;apos;, &amp;amp;apos;family&amp;amp;apos;, {REGION_REPLICATION =&amp;gt; 2, CONFIGURATION =&amp;gt; {&amp;amp;apos;hbase.hregion.scan.loadColumnFamiliesOnDemand&amp;amp;apos; =&amp;gt; &amp;amp;apos;true&amp;amp;apos;}}
hbase(main):011:0&amp;gt; describe &amp;amp;apos;usertable2&amp;amp;apos; 
Table usertable2 is ENABLED                                                                                                                                                                                 
COLUMN FAMILIES DESCRIPTION                                                                                                                                                                                 
{NAME =&amp;gt; &amp;amp;apos;family&amp;amp;apos;, DATA_BLOCK_ENCODING =&amp;gt; &amp;amp;apos;NONE&amp;amp;apos;, BLOOMFILTER =&amp;gt; &amp;amp;apos;ROW&amp;amp;apos;, REPLICATION_SCOPE =&amp;gt; &amp;amp;apos;0&amp;amp;apos;, VERSIONS =&amp;gt; &amp;amp;apos;1&amp;amp;apos;, COMPRESSION =&amp;gt; &amp;amp;apos;NONE&amp;amp;apos;, MIN_VERSIONS =&amp;gt; &amp;amp;apos;0&amp;amp;apos;, TTL =&amp;gt; &amp;amp;apos;FOREVER&amp;amp;apos;, KEEP_DELETED_CELLS =&amp;gt; &amp;amp;apos;FALS
E&amp;amp;apos;, BLOCKSIZE =&amp;gt; &amp;amp;apos;65536&amp;amp;apos;, IN_MEMORY =&amp;gt; &amp;amp;apos;false&amp;amp;apos;, BLOCKCACHE =&amp;gt; &amp;amp;apos;true&amp;amp;apos;}                                                                                                                                       
1 row(s) in 0.0200 seconds


Master UI shows: 


&amp;amp;apos;usertable2&amp;amp;apos;, {TABLE_ATTRIBUTES =&amp;gt; {REGION_REPLICATION =&amp;gt; &amp;amp;apos;2&amp;amp;apos;, CONFIGURATION =&amp;gt; {&amp;amp;apos;hbase.hregion.scan.loadColumnFamiliesOnDemand&amp;amp;apos; =&amp;gt; &amp;amp;apos;true&amp;amp;apos;}}, {NAME =&amp;gt; &amp;amp;apos;family&amp;amp;apos;}


HBASE-10082 changed the formatting from shell for one line per CF. We should add the table level attributes back to the formatting.</description>
			<version>0.98.8</version>
			<fixedVersion>1.0.0, 2.0.0, 0.98.10, 1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.HTableDescriptor.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">12821</link>
			<link type="Duplicate" description="duplicates">12828</link>
		</links>
	</bug>
	<bug id="12393" opendate="2014-10-31 09:40:56" fixdate="2015-01-22 01:43:58" resolution="Fixed">
		<buginformation>
			<summary>The regionserver web will throw exception if we disable block cache</summary>
			<description>The CacheConfig.getBlockCache() will return the null point when we set hfile.block.cache.size to zero.
The BlockCacheTmpl.jamon doesn&amp;amp;apos;t make a check on null blockcache.


&amp;lt;%if cacheConfig == null %&amp;gt;
&amp;lt;p&amp;gt;CacheConfig is null&amp;lt;/p&amp;gt;
&amp;lt;%else&amp;gt;
&amp;lt;table class="table table-striped"&amp;gt;
    &amp;lt;tr&amp;gt;
        &amp;lt;th&amp;gt;Attribute&amp;lt;/th&amp;gt;
        &amp;lt;th&amp;gt;Value&amp;lt;/th&amp;gt;
        &amp;lt;th&amp;gt;Description&amp;lt;/th&amp;gt;
    &amp;lt;/tr&amp;gt;
    &amp;lt;tr&amp;gt;
        &amp;lt;td&amp;gt;Size&amp;lt;/td&amp;gt;
        &amp;lt;td&amp;gt;&amp;lt;% StringUtils.humanReadableInt(cacheConfig.getBlockCache().size()) %&amp;gt;&amp;lt;/td&amp;gt;
        &amp;lt;td&amp;gt;Total size of Block Cache (bytes)&amp;lt;/td&amp;gt;
    &amp;lt;/tr&amp;gt;
    &amp;lt;tr&amp;gt;
        &amp;lt;td&amp;gt;Free&amp;lt;/td&amp;gt;
        &amp;lt;td&amp;gt;&amp;lt;% StringUtils.humanReadableInt(cacheConfig.getBlockCache().getFreeSize()) %&amp;gt;&amp;lt;/td&amp;gt;
        &amp;lt;td&amp;gt;Free space in Block Cache (bytes)&amp;lt;/td&amp;gt;
    &amp;lt;/tr&amp;gt;
    &amp;lt;tr&amp;gt;
        &amp;lt;td&amp;gt;Count&amp;lt;/td&amp;gt;
        &amp;lt;td&amp;gt;&amp;lt;% String.format("%,d", cacheConfig.getBlockCache().getBlockCount()) %&amp;gt;&amp;lt;/td&amp;gt;
        &amp;lt;td&amp;gt;Number of blocks in Block Cache&amp;lt;/td&amp;gt;
    &amp;lt;/tr&amp;gt;
    &amp;lt;tr&amp;gt;
        &amp;lt;td&amp;gt;Evicted&amp;lt;/td&amp;gt;
        &amp;lt;td&amp;gt;&amp;lt;% String.format("%,d", cacheConfig.getBlockCache().getStats().getEvictedCount()) %&amp;gt;&amp;lt;/td&amp;gt;
        &amp;lt;td&amp;gt;Number of blocks evicted&amp;lt;/td&amp;gt;
    &amp;lt;/tr&amp;gt;
    &amp;lt;tr&amp;gt;
        &amp;lt;td&amp;gt;Evictions&amp;lt;/td&amp;gt;
        &amp;lt;td&amp;gt;&amp;lt;% String.format("%,d", cacheConfig.getBlockCache().getStats().getEvictionCount()) %&amp;gt;&amp;lt;/td&amp;gt;
        &amp;lt;td&amp;gt;Number of times an eviction occurred&amp;lt;/td&amp;gt;
    &amp;lt;/tr&amp;gt;
    &amp;lt;tr&amp;gt;
        &amp;lt;td&amp;gt;Hits&amp;lt;/td&amp;gt;
        &amp;lt;td&amp;gt;&amp;lt;% String.format("%,d", cacheConfig.getBlockCache().getStats().getHitCount()) %&amp;gt;&amp;lt;/td&amp;gt;
        &amp;lt;td&amp;gt;Number requests that were cache hits&amp;lt;/td&amp;gt;
    &amp;lt;/tr&amp;gt;
    &amp;lt;tr&amp;gt;
        &amp;lt;td&amp;gt;Hits Caching&amp;lt;/td&amp;gt;
        &amp;lt;td&amp;gt;&amp;lt;% String.format("%,d", cacheConfig.getBlockCache().getStats().getHitCachingCount()) %&amp;gt;&amp;lt;/td&amp;gt;
        &amp;lt;td&amp;gt;Cache hit block requests but only requests set to use Block Cache&amp;lt;/td&amp;gt;
    &amp;lt;/tr&amp;gt;
    &amp;lt;tr&amp;gt;
        &amp;lt;td&amp;gt;Misses&amp;lt;/td&amp;gt;
        &amp;lt;td&amp;gt;&amp;lt;% String.format("%,d", cacheConfig.getBlockCache().getStats().getMissCount()) %&amp;gt;&amp;lt;/td&amp;gt;
        &amp;lt;td&amp;gt;Number of requests that were cache misses&amp;lt;/td&amp;gt;
    &amp;lt;/tr&amp;gt;
    &amp;lt;tr&amp;gt;
        &amp;lt;td&amp;gt;Misses Caching&amp;lt;/td&amp;gt;
        &amp;lt;td&amp;gt;&amp;lt;% String.format("%,d", cacheConfig.getBlockCache().getStats().getMissCount()) %&amp;gt;&amp;lt;/td&amp;gt;
        &amp;lt;td&amp;gt;Block requests that were cache misses but only requests set to use Block Cache&amp;lt;/td&amp;gt;
    &amp;lt;/tr&amp;gt;
    &amp;lt;tr&amp;gt;
        &amp;lt;td&amp;gt;Hit Ratio&amp;lt;/td&amp;gt;
        &amp;lt;td&amp;gt;&amp;lt;% String.format("%,.2f", cacheConfig.getBlockCache().getStats().getHitRatio() * 100) %&amp;gt;&amp;lt;% "%" %&amp;gt;&amp;lt;/td&amp;gt;
        &amp;lt;td&amp;gt;Hit Count divided by total requests count&amp;lt;/td&amp;gt;
    &amp;lt;/tr&amp;gt;


</description>
			<version>0.98.7</version>
			<fixedVersion>1.0.0, 2.0.0, 0.98.10, 1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestRSStatusServlet.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">12942</link>
		</links>
	</bug>
	<bug id="12942" opendate="2015-01-29 04:40:30" fixdate="2015-01-29 04:55:16" resolution="Duplicate">
		<buginformation>
			<summary>After disabling the hfile block cache, Regionserver UI is throwing java.lang.NullPointerException</summary>
			<description>Regionserver UI throws java.lang.NullPointerException
if hfile.block.cache.size is disabled


java.lang.NullPointerException
        at org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmplImpl.__jamon_innerUnit__bc_stats(BlockCacheTmplImpl.java:121)
        at org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmplImpl.renderNoFlush(BlockCacheTmplImpl.java:84)
        at org.apache.hadoop.hbase.tmpl.regionserver.BlockCacheTmpl.renderNoFlush(BlockCacheTmpl.java:140)
        at org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmplImpl.renderNoFlush(RSStatusTmplImpl.java:146)
        at org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.renderNoFlush(RSStatusTmpl.java:220)
        at org.apache.hadoop.hbase.tmpl.regionserver.RSStatusTmpl.render(RSStatusTmpl.java:211)
        at org.apache.hadoop.hbase.regionserver.RSStatusServlet.doGet(RSStatusServlet.java:58)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1221)
        at org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter.doFilter(StaticUserWebFilter.java:113)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
        at org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter.doFilter(HttpServer.java:1351)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
        at org.apache.hadoop.hbase.http.NoCacheFilter.doFilter(NoCacheFilter.java:49)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
        at org.apache.hadoop.hbase.http.NoCacheFilter.doFilter(NoCacheFilter.java:49)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)
        at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
        at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)
        at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)
        at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
        at org.mortbay.jetty.Server.handle(Server.java:326)
        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
        at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)
        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)
        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
        at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)
        at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)

</description>
			<version>1.0.0</version>
			<fixedVersion>1.0.0, 2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestRSStatusServlet.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">12393</link>
		</links>
	</bug>
	<bug id="12897" opendate="2015-01-21 21:08:11" fixdate="2015-02-07 00:20:05" resolution="Fixed">
		<buginformation>
			<summary>Minimum memstore size is a percentage</summary>
			<description>We have a cluster which is optimized for random reads.  Thus we have a large block cache and a small memstore.  Currently our heap is 20GB and we wanted to configure the memstore to take 4% or 800MB.  Right now the minimum memstore size is 5%.  What do you guys think about reducing the minimum size to 1%?  Suppose we log a warning if the memstore is below 5% but allow it?
What do you folks think? 
</description>
			<version>0.98.10</version>
			<fixedVersion>1.0.0, 2.0.0, 1.1.0, 0.98.11</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.util.HeapMemorySizeUtil.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">9472</link>
		</links>
	</bug>
	<bug id="6749" opendate="2012-09-10 13:10:12" fixdate="2015-02-23 12:42:50" resolution="Duplicate">
		<buginformation>
			<summary>Compact one expired HFile all the time</summary>
			<description>It&amp;amp;apos;s an interesting issue. We found there&amp;amp;apos;s 1 HFile keeped changing its name all the time. After dig in more, we found one strange behavior in compaction flow.
Here&amp;amp;apos;s the problem(We set the TTL property in our table):
There were 10 HFiles and only 1 expired HFile when this problem occured:

2012-09-07 02:21:05,298 DEBUG org.apache.hadoop.hbase.regionserver.Store: loaded hdfs://hacluster/hbase/fhtest/97ac7ea6f732b7c10fe504a54ab02441/value/221f56905cbd4bf09bd4d5d9dceb113a.3ed2e43476ca2c614e33d0e1255c79a9, isReference=true, isBulkLoadResult=false, seqid=118730, majorCompaction=false
2012-09-07 02:21:05,309 DEBUG org.apache.hadoop.hbase.regionserver.Store: loaded hdfs://hacluster/hbase/fhtest/97ac7ea6f732b7c10fe504a54ab02441/value/297b45a6c5f541dca05105ab098dab8d, isReference=false, isBulkLoadResult=false, seqid=122018, majorCompaction=false
2012-09-07 02:21:05,326 DEBUG org.apache.hadoop.hbase.regionserver.Store: loaded hdfs://hacluster/hbase/fhtest/97ac7ea6f732b7c10fe504a54ab02441/value/4a4a4598bc0443c9be087812052d6796.3ed2e43476ca2c614e33d0e1255c79a9, isReference=true, isBulkLoadResult=false, seqid=119850, majorCompaction=false
2012-09-07 02:21:05,348 DEBUG org.apache.hadoop.hbase.regionserver.Store: loaded hdfs://hacluster/hbase/fhtest/97ac7ea6f732b7c10fe504a54ab02441/value/8c6d56c9bafb4b0eb0dd6e04e41ca5b7, isReference=false, isBulkLoadResult=false, seqid=123135, majorCompaction=false
2012-09-07 02:21:05,357 DEBUG org.apache.hadoop.hbase.regionserver.Store: loaded hdfs://hacluster/hbase/fhtest/97ac7ea6f732b7c10fe504a54ab02441/value/a6c2873a646c425f87a6a8a271a9904e, isReference=false, isBulkLoadResult=false, seqid=76561, majorCompaction=false
2012-09-07 02:21:05,370 DEBUG org.apache.hadoop.hbase.regionserver.Store: loaded hdfs://hacluster/hbase/fhtest/97ac7ea6f732b7c10fe504a54ab02441/value/a712a2f79bd247f48405d2c6a91757ab.3ed2e43476ca2c614e33d0e1255c79a9, isReference=true, isBulkLoadResult=false, seqid=120951, majorCompaction=false
2012-09-07 02:21:05,381 DEBUG org.apache.hadoop.hbase.regionserver.Store: loaded hdfs://hacluster/hbase/fhtest/97ac7ea6f732b7c10fe504a54ab02441/value/a717c63214534cb0aaf8e695147fde46, isReference=false, isBulkLoadResult=false, seqid=122763, majorCompaction=false
2012-09-07 02:21:05,431 DEBUG org.apache.hadoop.hbase.regionserver.Store: loaded hdfs://hacluster/hbase/fhtest/97ac7ea6f732b7c10fe504a54ab02441/value/c456f3831b094ac3a0590678acbf27a5.3ed2e43476ca2c614e33d0e1255c79a9, isReference=true, isBulkLoadResult=false, seqid=120579, majorCompaction=false
2012-09-07 02:21:05,518 DEBUG org.apache.hadoop.hbase.regionserver.Store: loaded hdfs://hacluster/hbase/fhtest/97ac7ea6f732b7c10fe504a54ab02441/value/dde4e56b131a4ffdaec8f9574bffa5ab.3ed2e43476ca2c614e33d0e1255c79a9, isReference=true, isBulkLoadResult=false, seqid=121651, majorCompaction=false
2012-09-07 02:21:05,593 DEBUG org.apache.hadoop.hbase.regionserver.Store: loaded hdfs://hacluster/hbase/fhtest/97ac7ea6f732b7c10fe504a54ab02441/value/ee62844594f2474e88186dbde673c802.3ed2e43476ca2c614e33d0e1255c79a9, isReference=true, isBulkLoadResult=false, seqid=119478, majorCompaction=false


Compaction was triggered during Region-Opening . As we know, compaction should choose the expired HFiles to compact first, so that 1 expired HFile was choosed. 
Since no KeyValue was there, compaction deleted the old HFile and created a new one with minimumTimestamp = -1 &amp;amp;&amp;amp; maximumTimestamp = -1.
So after the first compaction, there were still 10 HFiles. It triggered compaction again and again.....

2012-09-07 02:21:06,079 INFO org.apache.hadoop.hbase.regionserver.compactions.CompactSelection: Deleting the expired store file by compaction: hdfs://hacluster/hbase/fhtest/97ac7ea6f732b7c10fe504a54ab02441/value/72468dff1cd94c4fb9cf9196cc3183b7 whose maxTimeStamp is -1 while the max expired timestamp is 1344824466079
....
2012-09-07 02:21:06,080 DEBUG org.apache.hadoop.hbase.regionserver.Store: Compacting hdfs://hacluster/hbase/fhtest/97ac7ea6f732b7c10fe504a54ab02441/value/72468dff1cd94c4fb9cf9196cc3183b7, keycount=0, bloomtype=NONE, size=558, encoding=NONE
2012-09-07 02:21:06,082 DEBUG org.apache.hadoop.hbase.util.FSUtils: Creating file:hdfs://hacluster/hbase/fhtest/97ac7ea6f732b7c10fe504a54ab02441/.tmp/8239019ff92f49bfab26b02ca43bc26a with permission:rwxrwxrwx

</description>
			<version>0.94.1</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestDefaultCompactSelection.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.compactions.RatioBasedCompactionPolicy.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MockStoreFile.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">10371</link>
		</links>
	</bug>
	<bug id="13317" opendate="2015-03-23 16:42:19" fixdate="2015-04-01 06:06:29" resolution="Fixed">
		<buginformation>
			<summary>Region server reportForDuty stuck looping if there is a master change</summary>
			<description>During cluster startup, region server reportForDuty gets stuck looping if there is a master change.

2015-03-22 11:15:16,186 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=bigaperf274,60000,1427045883965 with port=60020, startcode=1427048115174
2015-03-22 11:15:16,272 WARN  [regionserver60020] regionserver.HRegionServer: error telling master we are up
com.google.protobuf.ServiceException: java.net.ConnectException: Connection refused
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1678)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1719)
	at org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$RegionServerStatusService$BlockingStub.regionServerStartup(RegionServerStatusProtos.java:8277)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.reportForDuty(HRegionServer.java:2137)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:896)
	at java.lang.Thread.run(Thread.java:745)
2015-03-22 11:15:16,274 WARN  [regionserver60020] regionserver.HRegionServer: reportForDuty failed; sleeping and then retrying.
2015-03-22 11:15:19,274 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=bigaperf273,60000,1427048108439 with port=60020, startcode=1427048115174
2015-03-22 11:15:19,275 WARN  [regionserver60020] regionserver.HRegionServer: error telling master we are up
com.google.protobuf.ServiceException: java.net.ConnectException: Connection refused
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1678)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1719)
	at org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$RegionServerStatusService$BlockingStub.regionServerStartup(RegionServerStatusProtos.java:8277)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.reportForDuty(HRegionServer.java:2137)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:896)
	at java.lang.Thread.run(Thread.java:745)
2015-03-22 11:15:19,276 WARN  [regionserver60020] regionserver.HRegionServer: reportForDuty failed; sleeping and then retrying.
2015-03-22 11:15:22,276 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=bigaperf273,60000,1427048108439 with port=60020, startcode=1427048115174
2015-03-22 11:15:22,296 DEBUG [regionserver60020] regionserver.HRegionServer: Master is not running yet
2015-03-22 11:15:22,296 WARN  [regionserver60020] regionserver.HRegionServer: reportForDuty failed; sleeping and then retrying.
2015-03-22 11:15:25,296 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=bigaperf273,60000,1427048108439 with port=60020, startcode=1427048115174
2015-03-22 11:15:25,299 DEBUG [regionserver60020] regionserver.HRegionServer: Master is not running yet
2015-03-22 11:15:25,299 WARN  [regionserver60020] regionserver.HRegionServer: reportForDuty failed; sleeping and then retrying.
2015-03-22 11:15:28,299 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=bigaperf273,60000,1427048108439 with port=60020, startcode=1427048115174
2015-03-22 11:15:28,302 DEBUG [regionserver60020] regionserver.HRegionServer: Master is not running yet
2015-03-22 11:15:28,302 WARN  [regionserver60020] regionserver.HRegionServer: reportForDuty failed; sleeping and then retrying.


What happended is the region server first got master=bigaperf274,60000,1427045883965.  Before it was able to report successfully, the maser changed to bigaperf273,60000,1427048108439.
We were supposed to open a new connection to the new master. But we never did, looping and trying to old address forever.</description>
			<version>0.98.12</version>
			<fixedVersion>2.0.0, 1.0.1, 1.1.0, 0.98.12</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.LocalHBaseCluster.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">12813</link>
			<link type="Reference" description="relates to">13345</link>
		</links>
	</bug>
	<bug id="12813" opendate="2015-01-07 00:22:22" fixdate="2015-04-01 16:23:29" resolution="Duplicate">
		<buginformation>
			<summary>Reporting region in transition shouldn&amp;apos;t loop forever</summary>
			<description>We had an issue where a region server wasn&amp;amp;apos;t able to send the report region in transition request. Well after failing it just retries forever.
At some point it would have been better to just abort the region server if it can&amp;amp;apos;t talk to master.</description>
			<version>0.98.12</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.LocalHBaseCluster.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">13317</link>
		</links>
	</bug>
	<bug id="12006" opendate="2014-09-17 16:36:21" fixdate="2015-04-15 16:58:41" resolution="Fixed">
		<buginformation>
			<summary>[JDK 8] KeyStoreTestUtil#generateCertificate fails due to "subject class type invalid"</summary>
			<description>Running tests on Java 8. All unit tests for branch 0.98 pass. On master branch some variation in the security API is causing a failure in TestSSLHttpServer:

Tests run: 2, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 0.181 sec &amp;lt;&amp;lt;&amp;lt; FAILURE! - in org.apache.hadoop.hbase.http.TestSSLHttpServer
org.apache.hadoop.hbase.http.TestSSLHttpServer  Time elapsed: 0.181 sec  &amp;lt;&amp;lt;&amp;lt; ERROR!
java.security.cert.CertificateException: Subject class type invalid.
	at sun.security.x509.X509CertInfo.setSubject(X509CertInfo.java:888)
	at sun.security.x509.X509CertInfo.set(X509CertInfo.java:415)
	at org.apache.hadoop.hbase.http.ssl.KeyStoreTestUtil.generateCertificate(KeyStoreTestUtil.java:94)
	at org.apache.hadoop.hbase.http.ssl.KeyStoreTestUtil.setupSSLConfig(KeyStoreTestUtil.java:246)
	at org.apache.hadoop.hbase.http.TestSSLHttpServer.setup(TestSSLHttpServer.java:72)

org.apache.hadoop.hbase.http.TestSSLHttpServer  Time elapsed: 0.181 sec  &amp;lt;&amp;lt;&amp;lt; ERROR!
java.lang.NullPointerException: null
	at org.apache.hadoop.hbase.http.TestSSLHttpServer.cleanup(TestSSLHttpServer.java:100)

Tests in error: 
  TestSSLHttpServer.setup:72  Certificate Subject class type invalid.
  TestSSLHttpServer.cleanup:100 NullPointer

</description>
			<version>0.99.0</version>
			<fixedVersion>2.0.0, 1.0.1, 1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.http.ssl.KeyStoreTestUtil.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">11542</link>
			<link type="Reference" description="relates to">7614</link>
			<link type="Reference" description="relates to">11090</link>
			<link type="dependent" description="depends upon">11230</link>
		</links>
	</bug>
	<bug id="11542" opendate="2014-07-18 09:38:12" fixdate="2015-04-16 17:36:15" resolution="Duplicate">
		<buginformation>
			<summary>Unit Test  KeyStoreTestUtil.java compilation failure in IBM JDK </summary>
			<description>In trunk,  jira HBase-10336 added a utility test KeyStoreTestUtil.java, which leverages the following sun classes:
 import sun.security.x509.AlgorithmId;
 import sun.security.x509.CertificateAlgorithmId;
 ....
this cause hbase compiler failure if using IBM JDK,  
There are similar classes like below in IBM jdk: 
import com.ibm.security.x509.AlgorithmId;
import com.ibm.security.x509.CertificateAlgorithmId; 
This jira is to add handling of the x509 references. 
</description>
			<version>0.99.0</version>
			<fixedVersion>2.0.0, 1.0.1, 1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.http.ssl.KeyStoreTestUtil.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">12006</link>
		</links>
	</bug>
	<bug id="13601" opendate="2015-04-30 15:50:54" fixdate="2015-05-01 00:12:32" resolution="Fixed">
		<buginformation>
			<summary>Connection leak during log splitting</summary>
			<description>Ran into an issue where Region server died with the following exception

2015-04-29 17:10:11,856 WARN  [nector@0.0.0.0:60030] mortbay.log - EXCEPTION
java.io.IOException: Too many open files
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:241)
        at org.mortbay.jetty.nio.SelectChannelConnector$1.acceptChannel(SelectChannelConnector.java:75)
        at org.mortbay.io.nio.SelectorManager$SelectSet.doSelect(SelectorManager.java:686)
        at org.mortbay.io.nio.SelectorManager.doSelect(SelectorManager.java:192)
        at org.mortbay.jetty.nio.SelectChannelConnector.accept(SelectChannelConnector.java:124)
        at org.mortbay.jetty.AbstractConnector$Acceptor.run(AbstractConnector.java:708)
        at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)


Realized that all the tcp sockets on the system were used out due to the regionserver trying to split the log and failing multiple times and leaving a connection open -

java.io.IOException: Got error for OP_READ_BLOCK, self=/10..99.3:50695, remote=/10.232.99.36:50010, for file /hbase/WALs/host1,60020,1425930917890-splitting/host1%2C60020%2C1425930917890.1429358890944, for pool BP-181199659-10.232.99.2-1411124363096 block 1074497051_756497
        at org.apache.hadoop.hdfs.RemoteBlockReader2.checkSuccess(RemoteBlockReader2.java:432)
        at org.apache.hadoop.hdfs.RemoteBlockReader2.newBlockReader(RemoteBlockReader2.java:397)
        at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:786)
        at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:665)
        at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:325)
        at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:567)
        at org.apache.hadoop.hdfs.DFSInputStream.seekToNewSource(DFSInputStream.java:1446)
        at org.apache.hadoop.hdfs.DFSInputStream.readBuffer(DFSInputStream.java:769)
        at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:799)
        at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:840)
        at java.io.DataInputStream.read(DataInputStream.java:100)
        at org.apache.hadoop.hbase.regionserver.wal.HLogFactory.createReader(HLogFactory.java:124)
        at org.apache.hadoop.hbase.regionserver.wal.HLogFactory.createReader(HLogFactory.java:91)
        at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.getReader(HLogSplitter.java:660)
        at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.getReader(HLogSplitter.java:569)
        at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.splitLogFile(HLogSplitter.java:282)
        at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.splitLogFile(HLogSplitter.java:225)
        at org.apache.hadoop.hbase.regionserver.SplitLogWorker$1.exec(SplitLogWorker.java:143)
        at org.apache.hadoop.hbase.regionserver.handler.HLogSplitterHandler.process(HLogSplitterHandler.java:82)
        at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:745)


</description>
			<version>0.98.10</version>
			<fixedVersion>2.0.0, 0.98.13, 1.0.2, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.wal.WALFactory.java</file>
		</fixedFiles>
	</bug>
	<bug id="13608" opendate="2015-05-01 18:25:33" fixdate="2015-05-01 21:32:21" resolution="Fixed">
		<buginformation>
			<summary>413 Error with Stargate through Knox, using AD, SPNEGO, and Pre-Auth</summary>
			<description>Jody Steadman reported that attempts to access Stargate via Apache Knox using curl ends with 413 error when the following conditions are met:
AD is being used directly for Kerberos
The knox principal is configured to require Kerberos pre-auth
Stargate is using SPNEGO
Pre-auth errors exist in Kerberos debug log output
Sumit Gupta found that the gateway logs in the environment provided by Jody Steadman has the following error:


2015-04-20 14:24:21,660 DEBUG http.headers (DefaultClientConnection.java:sendRequestHeader(273)) - &amp;gt;&amp;gt; GET /version?doAs=jsteadman HTTP/1.1
2015-04-20 14:24:21,661 DEBUG http.headers (DefaultClientConnection.java:sendRequestHeader(276)) - &amp;gt;&amp;gt; Host: node1.jodylaptop.net:60080
2015-04-20 14:24:21,661 DEBUG http.headers (DefaultClientConnection.java:sendRequestHeader(276)) - &amp;gt;&amp;gt; Connection: Keep-Alive
2015-04-20 14:24:21,661 DEBUG http.headers (DefaultClientConnection.java:sendRequestHeader(276)) - &amp;gt;&amp;gt; User-Agent: Apache-HttpClient/4.2.5 (java 1.5)
2015-04-20 14:24:21,661 DEBUG http.headers (DefaultClientConnection.java:sendRequestHeader(276)) - &amp;gt;&amp;gt; Authorization: Negotiate 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
2015-04-20 14:24:21,664 DEBUG http.wire (Wire.java:wire(63)) - &amp;lt;&amp;lt; "HTTP/1.1 413 FULL head[\r][\n]"
2015-04-20 14:24:21,665 DEBUG http.wire (Wire.java:wire(63)) - &amp;lt;&amp;lt; "Connection: close[\r][\n]"
2015-04-20 14:24:21,666 DEBUG http.wire (Wire.java:wire(63)) - &amp;lt;&amp;lt; "[\r][\n]"


Sumit suggested using large buffer size in hbase REST Server to get rid of the "FULL Head" error</description>
			<version>0.98.12</version>
			<fixedVersion>2.0.0, 0.98.13, 1.0.2, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.rest.RESTServer.java</file>
		</fixedFiles>
	</bug>
	<bug id="13607" opendate="2015-05-01 17:09:18" fixdate="2015-05-02 14:14:48" resolution="Fixed">
		<buginformation>
			<summary>TestSplitLogManager.testGetPreviousRecoveryMode consistently failing</summary>
			<description>From Nick&amp;amp;apos;s 1.1.0 rc0 call for UT help:
https://builds.apache.org/job/HBase-1.1.0RC0-JDK7/72/testReport/org.apache.hadoop.hbase.master/TestSplitLogManager/testGetPreviousRecoveryMode/

java.lang.AssertionError: Mode4=LOG_SPLITTING
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.apache.hadoop.hbase.master.TestSplitLogManager.testGetPreviousRecoveryMode(TestSplitLogManager.java:661)


This is repeatedly failing locally for me.</description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.TestSplitLogManager.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">13623</link>
			<link type="Regression" description="is broken by">13584</link>
		</links>
	</bug>
	<bug id="13617" opendate="2015-05-04 23:59:42" fixdate="2015-05-05 00:17:54" resolution="Fixed">
		<buginformation>
			<summary>TestReplicaWithCluster.testChangeTable timeout</summary>
			<description>In our internal test TestReplicaWithCluster.testChangeTable got a timeout.  
HBASE-12170 bumped TestReplicaWithCluster.testReplicaAndReplication timeout from 2 minutes to 5 minutes, but leaves other tests in the same package unchanged.
When I run the test in my fast Mac, the run time of TestReplicaWithCluster.testChangeTable (~16 seconds) is about half of TestReplicaWithCluster.testReplicaAndReplication (~31 seconds).  
We should increase the timeout in TestReplicaWithCluster.testChangeTable to avoid test failure in slow environment.
</description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.TestReplicaWithCluster.java</file>
		</fixedFiles>
	</bug>
	<bug id="13623" opendate="2015-05-05 19:05:07" fixdate="2015-05-05 19:10:41" resolution="Duplicate">
		<buginformation>
			<summary>TestSplitLogManager.testGetPreviousRecoveryMode is still flaky</summary>
			<description>Even with retry failing tests, I&amp;amp;apos;m seeing

org.apache.hadoop.hbase.master.TestSplitLogManager.testGetPreviousRecoveryMode(org.apache.hadoop.hbase.master.TestSplitLogManager)
  Run 1: TestSplitLogManager.testGetPreviousRecoveryMode:661 Mode4=LOG_SPLITTING
  Run 2: TestSplitLogManager.testGetPreviousRecoveryMode:661 Mode4=LOG_SPLITTING
  Run 3: TestSplitLogManager.testGetPreviousRecoveryMode:661 Mode4=LOG_SPLITTING

java.lang.AssertionError: Mode4=LOG_SPLITTING
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.apache.hadoop.hbase.master.TestSplitLogManager.testGetPreviousRecoveryMode(TestSplitLogManager.java:661)


Let me give Duo Zhang&amp;amp;apos;s test procedure from HBASE-13136 a spin.</description>
			<version>1.1.0</version>
			<fixedVersion></fixedVersion>
			<type>Test</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.TestSplitLogManager.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">13607</link>
		</links>
	</bug>
	<bug id="13625" opendate="2015-05-05 23:05:03" fixdate="2015-05-06 17:11:36" resolution="Fixed">
		<buginformation>
			<summary>Use HDFS for HFileOutputFormat2 partitioner&amp;apos;s path</summary>
			<description>HBASE-13010 changed hard-coded &amp;amp;apos;/tmp&amp;amp;apos; in HFileOutputFormat2 partitioner&amp;amp;apos;s path to &amp;amp;apos;hadoop.tmp.dir&amp;amp;apos;.  This breaks unit test in Windows.


   static void configurePartitioner(Job job, List&amp;lt;ImmutableBytesWritable&amp;gt; splitPoints)
     ...
     // create the partitions file
-    FileSystem fs = FileSystem.get(job.getConfiguration());
-    Path partitionsPath = new Path("/tmp", "partitions_" + UUID.randomUUID());
+    FileSystem fs = FileSystem.get(conf);
+    Path partitionsPath = new Path(conf.get("hadoop.tmp.dir"), "partitions_" + UUID.randomUUID());


Here is the exception from 1 of the UTs when running against Windows (from branch-1.1) - The &amp;amp;apos;:&amp;amp;apos; is an invalid character in windows file path:


java.lang.IllegalArgumentException: Pathname /C:/hbase-server/target/test-data/d25e2228-8959-43ee-b413-4fa69cdb8032/hadoop_tmp/partitions_fb96c0a0-41e6-4964-a391-738cb761ee3e from C:/hbase-server/target/test-data/d25e2228-8959-43ee-b413-4fa69cdb8032/hadoop_tmp/partitions_fb96c0a0-41e6-4964-a391-738cb761ee3e is not a valid DFS filename.
	at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:197)
	at org.apache.hadoop.hdfs.DistributedFileSystem.access$000(DistributedFileSystem.java:106)
	at org.apache.hadoop.hdfs.DistributedFileSystem$7.doCall(DistributedFileSystem.java:448)
	at org.apache.hadoop.hdfs.DistributedFileSystem$7.doCall(DistributedFileSystem.java:444)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:444)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:387)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:909)
	at org.apache.hadoop.io.SequenceFile$Writer.&amp;lt;init&amp;gt;(SequenceFile.java:1074)
	at org.apache.hadoop.io.SequenceFile$RecordCompressWriter.&amp;lt;init&amp;gt;(SequenceFile.java:1374)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:275)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:297)
	at org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2.writePartitions(HFileOutputFormat2.java:335)
	at org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2.configurePartitioner(HFileOutputFormat2.java:593)
	at org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2.configureIncrementalLoad(HFileOutputFormat2.java:440)
	at org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2.configureIncrementalLoad(HFileOutputFormat2.java:405)
	at org.apache.hadoop.hbase.mapreduce.ImportTsv.createSubmittableJob(ImportTsv.java:539)
	at org.apache.hadoop.hbase.mapreduce.ImportTsv.run(ImportTsv.java:720)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.hadoop.hbase.mapreduce.TestImportTsv.doMROnTableTest(TestImportTsv.java:313)
	at org.apache.hadoop.hbase.mapreduce.TestImportTsv.testBulkOutputWithoutAnExistingTable(TestImportTsv.java:168)


The proposed fix is to use a config to point to a hdfs directory.</description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0, 0.98.13, 1.0.2, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.security.SecureBulkLoadUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat2.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">13010</link>
		</links>
	</bug>
	<bug id="13630" opendate="2015-05-06 05:48:55" fixdate="2015-05-08 03:46:46" resolution="Fixed">
		<buginformation>
			<summary>Remove dead code in BufferedDataEncoder</summary>
			<description>Remove the dead code pointed out in HBASE-10800 as part of high prioirty findbugs.
https://issues.apache.org/jira/browse/HBASE-10800?focusedCommentId=14529659&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14529659</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.encoding.BufferedDataBlockEncoder.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">10800</link>
		</links>
	</bug>
	<bug id="1989" opendate="2009-11-18 21:27:49" fixdate="2015-05-11 16:47:36" resolution="Fixed">
		<buginformation>
			<summary>Admin (et al.) not accurate with Column vs. Column-Family usage</summary>
			<description>Consider the classes Admin and HColumnDescriptor.
HColumnDescriptor is really referring to a "column family" and not a "column" (i.e., family:qualifer).
Likewise, in Admin there is a method called "addColumn" that takes an HColumnDescriptor instance.
I labeled this a bug in the sense that it produces conceptual confusion because there is a big difference between a column and column-family in HBase and these terms should be used consistently.  The code works, though.
</description>
			<version>0.20.1</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.rest.SchemaResource.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestSnapshotCloneIndependence.java</file>
			<file type="M">org.apache.hadoop.hbase.backup.TestHFileArchiving.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestRestoreSnapshotFromClient.java</file>
			<file type="M">org.apache.hadoop.hbase.util.LoadTestTool.java</file>
			<file type="M">org.apache.hadoop.hbase.io.encoding.TestLoadAndSwitchEncodeOnDisk.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestEncryptionKeyRotation.java</file>
			<file type="M">org.apache.hadoop.hbase.master.handler.TestTableDescriptorModification.java</file>
			<file type="M">org.apache.hadoop.hbase.master.handler.TestTableDeleteFamilyHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.TestMasterObserver.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestTableLockManager.java</file>
			<file type="M">org.apache.hadoop.hbase.security.visibility.TestVisibilityLabels.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestSnapshotMetadata.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
			<file type="M">org.apache.hadoop.hbase.io.encoding.TestChangingEncoding.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestAdmin1.java</file>
			<file type="M">org.apache.hadoop.hbase.IntegrationTestIngestWithEncryption.java</file>
			<file type="M">org.apache.hadoop.hbase.client.Admin.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">2704</link>
			<link type="Reference" description="relates to">13645</link>
		</links>
	</bug>
	<bug id="13635" opendate="2015-05-06 16:33:54" fixdate="2015-05-11 22:27:01" resolution="Fixed">
		<buginformation>
			<summary>Regions stuck in transition because master is incorrectly assumed dead</summary>
			<description>On master I see:


15/05/05 20:56:38 INFO master.HMaster: balance hri=hbase:meta,,1.1588230740, src=hbase1375.prn2.facebook.com,16020,1430858968368, dest=hbase1377.prn2.facebook.com,16020,1430884264554
15/05/05 20:56:38 INFO master.RegionStates: Transition {1588230740 state=OPEN, ts=1430876450098, server=hbase1375.prn2.facebook.com,16020,1430858968368} to {1588230740 state=PENDING_CLOSE, ts=1430884598277, server=hbase1375.prn2.facebook.com,16020,1430858968368}
Tue May 05 21:01:54 PDT 2015, null, java.net.SocketTimeoutException: callTimeout=60000, callDuration=60724: row &amp;amp;apos;&amp;amp;apos; on table &amp;amp;apos;hbase:meta&amp;amp;apos; at region=hbase:meta,,1.1588230740, hostname=hbase1375.prn2.facebook.com,16020,1430858968368, seqNum=0
Caused by: java.net.SocketTimeoutException: callTimeout=60000, callDuration=60724: row &amp;amp;apos;&amp;amp;apos; on table &amp;amp;apos;hbase:meta&amp;amp;apos; at region=hbase:meta,,1.1588230740, hostname=hbase1375.prn2.facebook.com,16020,1430858968368, seqNum=0


On the regionserver I see the following log spew:


15/05/06 09:30:11 INFO regionserver.HRegionServer: Failed to report region transition, will retry
org.apache.hadoop.hbase.ipc.FailedServerException: This server is in the failed servers list: hbasectrl054.prn2.facebook.com/10.104.157.28:16020
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.setupIOstreams(RpcClientImpl.java:694)
	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.writeRequest(RpcClientImpl.java:880)
	at or^Cg.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.tracedWriteRequest(RpcClientImpl.java:849)
	at org.apache.hadoop.hbase.ipc.RpcClientImpl.call(RpcClientImpl.java:1173)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(AbstractRpcClient.java:216)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$BlockingRpcChannelImplementation.callBlockingMethod(AbstractRpcClient.java:300)
	at org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$RegionServerStatusService$BlockingStub.reportRegionStateTransition(RegionServerStatusProtos.java:8325)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.reportRegionStateTransition(HRegionServer.java:1863)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.reportRegionStateTransition(HRegionServer.java:1837)
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:157)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

</description>
			<version>1.0.0</version>
			<fixedVersion>2.0.0, 0.98.13, 1.0.2, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestQosFunction.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.AnnotationReadingPriorityFunction.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor.java</file>
		</fixedFiles>
	</bug>
	<bug id="13606" opendate="2015-05-01 07:44:58" fixdate="2015-05-11 23:18:00" resolution="Fixed">
		<buginformation>
			<summary>AssignmentManager.assign() is not sync in both path</summary>
			<description>from the comment and the expected behavior AssignmentManager.assign() should be sync


/** Assigns specified regions round robin, if any.
 * This is a synchronous call and will return once every region has been
public void assign(List&amp;lt;HRegionInfo&amp;gt; regions)


but the code has two path. 1 sync and the async


if (servers == 1 || (regions &amp;lt; bulkAssignThresholdRegions
        &amp;amp;&amp;amp; servers &amp;lt; bulkAssignThresholdServers)) {
   for (HRegionInfo region: plan.getValue()) {
     ...
        invokeAssign(region);  // &amp;lt;-- this is async threadPool.submit(assign)
     ...
  }
} else {
  BulkAssigner ba = new GeneralBulkAssigner(...);
  ba.bulkAssign();  // &amp;lt;-- this is sync, calls BulkAssign.waitUntilDone()
}


https://builds.apache.org/job/HBase-1.1/452/ TestCreateTableProcedure is flaky because of this async behavior</description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.AssignmentManager.java</file>
			<file type="M">org.apache.hadoop.hbase.master.GeneralBulkAssigner.java</file>
		</fixedFiles>
	</bug>
	<bug id="13662" opendate="2015-05-11 18:00:26" fixdate="2015-05-12 16:48:38" resolution="Fixed">
		<buginformation>
			<summary>RSRpcService.scan() throws an OutOfOrderScannerNext if the scan has a retriable failure</summary>
			<description>while fixing HBASE-13651 I noticed that if we have a failure inside the RSRpcService.scan(), when the request has a hasNextCallSeq()  the nextCallSeq is incremented and not rolledback, which means that the client retry will send a request with a nextCallSeq not up to date, which result in an OutOfOrderScannerNextException.


if (rows &amp;gt; 0) {
  if (request.hasNextCallSeq()) {
    if (request.getNextCallSeq() != rsh.nextCallSeq) {
      throw new OutOfOrderScannerNextException(...)
    }
    // Increment the nextCallSeq value which is the next expected from client.
    rsh.nextCallSeq++;
  }
}
try {
  ...scan code...
}


after the scanner heartbeat patches HBASE-13090, we seems to be able to recover from that OutOfOrder exception, but the error show up anyway.
After a discussion with Stack we ended up saying that decrementing the callSeq on exception seems to be fine. but we had the open question about having that nextCallSeq to be atomic, if that was supposed to prevent concurrent requests with the same id. any thoughts?</description>
			<version>0.98.10.1</version>
			<fixedVersion>2.0.0, 0.98.13, 1.0.2, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">16604</link>
		</links>
	</bug>
	<bug id="13663" opendate="2015-05-11 18:54:10" fixdate="2015-05-12 18:38:23" resolution="Fixed">
		<buginformation>
			<summary>HMaster fails to restart &amp;apos;HMaster: Failed to become active master&amp;apos;</summary>
			<description>HMaster fails to restart &amp;amp;apos;HMaster: Failed to become active master&amp;amp;apos;
from Master log:


2015-05-08 11:25:14,020 FATAL [MasterNOde:16000.activeMasterManager] master.HMaster: Failed to become active master
java.lang.NullPointerException
	at org.apache.hadoop.hbase.master.AssignmentManager.rebuildUserRegions(AssignmentManager.java:2885)
	at org.apache.hadoop.hbase.master.AssignmentManager.joinCluster(AssignmentManager.java:483)
	at org.apache.hadoop.hbase.master.HMaster.finishActiveMasterInitialization(HMaster.java:763)
	at org.apache.hadoop.hbase.master.HMaster.access$500(HMaster.java:182)
	at org.apache.hadoop.hbase.master.HMaster$1.run(HMaster.java:1632)
	at java.lang.Thread.run(Thread.java:745)
2015-05-08 11:25:14,023 FATAL [MasterNOde:16000.activeMasterManager] master.HMaster: Master server abort: loaded coprocessors are: []
2015-05-08 11:25:14,023 FATAL [MasterNOde:16000.activeMasterManager] master.HMaster: Unhandled exception. Starting shutdown.
java.lang.NullPointerException
	at org.apache.hadoop.hbase.master.AssignmentManager.rebuildUserRegions(AssignmentManager.java:2885)
	at org.apache.hadoop.hbase.master.AssignmentManager.joinCluster(AssignmentManager.java:483)
	at org.apache.hadoop.hbase.master.HMaster.finishActiveMasterInitialization(HMaster.java:763)
	at org.apache.hadoop.hbase.master.HMaster.access$500(HMaster.java:182)
	at org.apache.hadoop.hbase.master.HMaster$1.run(HMaster.java:1632)
	at java.lang.Thread.run(Thread.java:745)

</description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.AssignmentManager.java</file>
		</fixedFiles>
	</bug>
	<bug id="13651" opendate="2015-05-08 22:35:33" fixdate="2015-05-15 18:15:51" resolution="Fixed">
		<buginformation>
			<summary>Handle StoreFileScanner FileNotFoundException</summary>
			<description>Example:

Machine-1 is serving Region-X and start compaction
Machine-1 goes in GC pause
Region-X gets reassigned to Machine-2
Machine-1 exit from the GC pause
Machine-1 (re)moves the compacted files
Machine-1 get the lease expired and shutdown

Machine-2 has now tons of FileNotFoundException on scan. If we reassign the region everything is ok, because we pickup the files compacted by Machine-1.
This problem doesn&amp;amp;apos;t happen in the new code 1.0+  (i think but I haven&amp;amp;apos;t checked, it may be 1.1) where we write on the WAL the compaction event before (re)moving the files.
A workaround is handling FileNotFoundException and refresh the store files, or shutdown the region and reassign. the first one is easy in 1.0+ the second one requires more work because at the moment we don&amp;amp;apos;t have the code to notify the master that the RS is closing the region, alternatively we can shutdown the entire RS (it is not a good solution but the case is rare enough)</description>
			<version>0.94.27</version>
			<fixedVersion>2.0.0, 0.94.28, 0.98.13, 1.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
		</fixedFiles>
	</bug>
	<bug id="13668" opendate="2015-05-12 02:06:53" fixdate="2015-05-16 23:47:27" resolution="Fixed">
		<buginformation>
			<summary>TestFlushRegionEntry is flaky</summary>
			<description>
Flaked tests: 
org.apache.hadoop.hbase.regionserver.TestFlushRegionEntry.test
    (org.apache.hadoop.hbase.regionserver.TestFlushRegionEntry)
  Run 1: TestFlushRegionEntry.test:41 expected:
       org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushRegionEntry&amp;lt;[flush region null]&amp;gt;
     but was:
       org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushRegionEntry&amp;lt;[flush region null]&amp;gt;
  Run 2: PASS

</description>
			<version>0.98.13</version>
			<fixedVersion>2.0.0, 0.98.13, 1.0.2, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestFlushRegionEntry.java</file>
		</fixedFiles>
	</bug>
	<bug id="13694" opendate="2015-05-15 07:55:44" fixdate="2015-05-19 16:26:21" resolution="Fixed">
		<buginformation>
			<summary>CallQueueSize is incorrectly decremented until the response is sent</summary>
			<description>We should decrement the CallQueueSize as soon as we no longer need the call around, e.g. after RpcServer.CurCall.set(null) otherwise we will be only pushing back other client requests while we send the response back to the client that originated the call.</description>
			<version>0.98.12</version>
			<fixedVersion>2.0.0, 1.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.CallRunner.java</file>
		</fixedFiles>
	</bug>
	<bug id="13693" opendate="2015-05-15 06:38:52" fixdate="2015-05-19 23:18:00" resolution="Fixed">
		<buginformation>
			<summary>[HBase MOB] Mob files are not encrypting.</summary>
			<description>Mob HFiles are not encrypting.
steps to reproduce:
===============
1.create a table and for column family with mob enabled and enable AES encryption for the column family.
2. Insert mob data into the table.
3. Flush the mob table.
4. check hfiles for mob data is created or not.
5. check hfiles in hdfs is encrypted or not using hfile tool.


hfile tool output for mob reference hfile meta

Block index size as per heapsize: 392
reader=/hbase/data/default/mobTest/1587e00c3e257969c48d9872994ce57c/mobcf/8c33ab9e8201449e9ac709eb9e4263d6,
Trailer:
    fileinfoOffset=527,
    loadOnOpenDataOffset=353,
    dataIndexCount=1,
    metaIndexCount=0,
    totalUncomressedBytes=5941,
    entryCount=9,
    compressionCodec=GZ,
    uncompressedDataIndexSize=34,
    numDataIndexLevels=1,
    firstDataBlockOffset=0,
    lastDataBlockOffset=0,
    comparatorClassName=org.apache.hadoop.hbase.KeyValue$KeyComparator,
    encryptionKey=PRESENT,
    majorVersion=3,
    minorVersion=0





hfile tool output for mob hfile meta
Block index size as per heapsize: 872
reader=/hbase/mobdir/data/default/mobTest/46844d8b9f699e175a4d7bd57848c576/mobcf/d41d8cd98f00b204e9800998ecf8427e20150512bf18fa62a98c40d7bd6e810f790c6291,

Trailer:
    fileinfoOffset=1018180,
    loadOnOpenDataOffset=1017959,
    dataIndexCount=9,
    metaIndexCount=0,
    totalUncomressedBytes=1552619,
    entryCount=9,
    compressionCodec=GZ,
    uncompressedDataIndexSize=266,
    numDataIndexLevels=1,
    firstDataBlockOffset=0,
    lastDataBlockOffset=904852,
    comparatorClassName=org.apache.hadoop.hbase.KeyValue$KeyComparator,
    encryptionKey=NONE,
    majorVersion=3,
    minorVersion=0


</description>
			<version>10000.0</version>
			<fixedVersion>hbase-11339</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHMobStore.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HMobStore.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
		</fixedFiles>
	</bug>
	<bug id="13717" opendate="2015-05-19 22:42:33" fixdate="2015-05-20 02:47:38" resolution="Fixed">
		<buginformation>
			<summary>TestBoundedRegionGroupingProvider#setMembershipDedups need to set HDFS diretory for WAL</summary>
			<description>org.apache.hadoop.hbase.wal.TestBoundedRegionGroupingProvider#setMembershipDedups() fails during testing in windows:

java.lang.IllegalArgumentException: Pathname /C:/tmp/hbase-myuser/hbase/WALs/setMembershipDedups from hdfs://127.0.0.1:61737/C:/tmp/hbase-myuser/hbase/WALs/setMembershipDedups is not a valid DFS filename.
	at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:197)
	at org.apache.hadoop.hdfs.DistributedFileSystem.access$000(DistributedFileSystem.java:106)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1305)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1424)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.&amp;lt;init&amp;gt;(FSHLog.java:477)
	at org.apache.hadoop.hbase.wal.DefaultWALProvider.init(DefaultWALProvider.java:97)
	at org.apache.hadoop.hbase.wal.WALFactory.getProvider(WALFactory.java:147)
	at org.apache.hadoop.hbase.wal.BoundedRegionGroupingProvider.init(BoundedRegionGroupingProvider.java:56)
	at org.apache.hadoop.hbase.wal.WALFactory.getProvider(WALFactory.java:147)
	at org.apache.hadoop.hbase.wal.WALFactory.&amp;lt;init&amp;gt;(WALFactory.java:179)
	at org.apache.hadoop.hbase.wal.TestBoundedRegionGroupingProvider.setMembershipDedups(TestBoundedRegionGroupingProvider.java:161)


This is due to using the local file system path as root directory.  We should set the HDFS directory as the root directory.</description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0, 1.0.2, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.wal.TestBoundedRegionGroupingProvider.java</file>
		</fixedFiles>
	</bug>
	<bug id="13704" opendate="2015-05-18 09:05:21" fixdate="2015-05-20 03:23:38" resolution="Fixed">
		<buginformation>
			<summary>Hbase throws OutOfOrderScannerNextException when MultiRowRangeFilter is used</summary>
			<description>When using filter MultiRowRangeFilter with ranges closed to each other that there are no rows between ranges, then OutOfOrderScannerNextException is throwed.
In filterRowKey method when range is switched to the next range, currentReturnCode is set to SEEK_NEXT_USING_HINT (MultiRowRangeFilter: 118 in v1.1.0). But if new range is already contain this row, then we should include this row, not to seek for another one.
Replacing line 118 to this code seems to be working fine:


if (range.contains(buffer, offset, length)) {
    currentReturnCode = ReturnCode.INCLUDE;
} else {
    currentReturnCode = ReturnCode.SEEK_NEXT_USING_HINT;
}

</description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.1.1, 0.98.21</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.filter.MultiRowRangeFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.TestMultiRowRangeFilter.java</file>
		</fixedFiles>
	</bug>
	<bug id="13722" opendate="2015-05-20 13:06:35" fixdate="2015-05-20 16:49:37" resolution="Fixed">
		<buginformation>
			<summary>Avoid non static method from BloomFilterUtil</summary>
			<description>This is an unused method and slipped into this Util class from ByteBloomFilter during the cleanup.
boolean contains(byte[] buf, ByteBuffer bloom)</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.BloomFilterUtil.java</file>
		</fixedFiles>
	</bug>
	<bug id="13711" opendate="2015-05-19 07:59:18" fixdate="2015-05-20 18:51:20" resolution="Fixed">
		<buginformation>
			<summary>Provide an API to set min and max versions in HColumnDescriptor</summary>
			<description>In org.apache.hadoop.hbase.chaos.actions.ChangeVersionsAction#perform(), it tries to update the max and min versions in a column descriptor: 


     for(HColumnDescriptor descriptor:columnDescriptors) {
       descriptor.setMaxVersions(versions);
       descriptor.setMinVersions(versions);
     }


If the current minimum version is greater than the new max version, an IllegalArgumentException would throw from org.apache.hadoop.hbase.HColumnDescriptor#setMaxVersions().  
Here is an example (trying to set max version to 1 while currently min version is 2):

java.lang.IllegalArgumentException: Set MaxVersion to 1 while minVersion is 2. Maximum versions must be &amp;gt;= minimum versions
at org.apache.hadoop.hbase.HColumnDescriptor.setMaxVersions(HColumnDescriptor.java:634)
at org.apache.hadoop.hbase.chaos.actions.ChangeVersionsAction.perform(ChangeVersionsAction.java:62)


One solution is to change the order of set - set min version first and then set max version (note: the current implement of org.apache.hadoop.hbase.HColumnDescriptor#setMinVersions() does not check the min version value and blindly set the version.  Not sure whether this is by-design).
Another solution is to provide an API to set both min and max version in one function call.  </description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0, 0.98.13, 1.0.2, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.HColumnDescriptor.java</file>
			<file type="M">org.apache.hadoop.hbase.chaos.actions.ChangeVersionsAction.java</file>
		</fixedFiles>
	</bug>
	<bug id="13731" opendate="2015-05-20 22:59:15" fixdate="2015-05-21 18:14:12" resolution="Fixed">
		<buginformation>
			<summary>TestReplicationAdmin should clean up MiniZKCluster resource</summary>
			<description>org.apache.hadoop.hbase.client.replication.TestReplicationAdmin Unit test has a @BeforeClass component to start MiniZKCluster, but it does not have a @AfterClass component to shut down MiniZKCluster and clean up the resources from MiniZKCluster.  In Jenkins machine that continuously run tests, the resource leak could affect other tests. 
The solution is trivial.</description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0, 0.98.13, 1.0.2, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.replication.TestReplicationAdmin.java</file>
		</fixedFiles>
	</bug>
	<bug id="13741" opendate="2015-05-21 17:50:24" fixdate="2015-05-21 20:59:50" resolution="Fixed">
		<buginformation>
			<summary>Disable TestRegionObserverInterface#testRecovery and testLegacyRecovery</summary>
			<description>This is related to HBASE-13391.  
When testing 1.1 release in Windows environment, both org.apache.hadoop.hbase.coprocessor.TestRegionObserverInterface.testRecovery and org.apache.hadoop.hbase.coprocessor.TestRegionObserverInterface.testLegacyRecovery failed frequently. testLegacyRecovery fails more frequently.

java.lang.AssertionError: Result of org.apache.hadoop.hbase.coprocessor.SimpleRegionObserver.getCtPreWALRestore is expected to be 1, while we get 0
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.apache.hadoop.hbase.coprocessor.TestRegionObserverInterface.verifyMethodResult(TestRegionObserverInterface.java:746)
	at org.apache.hadoop.hbase.coprocessor.TestRegionObserverInterface.testRecovery(TestRegionObserverInterface.java:630)


java.lang.AssertionError: Result of org.apache.hadoop.hbase.coprocessor.SimpleRegionObserver$Legacy.getCtPreWALRestore is expected to be 1, while we get 0
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.apache.hadoop.hbase.coprocessor.TestRegionObserverInterface.verifyMethodResult(TestRegionObserverInterface.java:746)
	at org.apache.hadoop.hbase.coprocessor.TestRegionObserverInterface.testLegacyRecovery(TestRegionObserverInterface.java:680)


Base on Andrew Purtell, "we&amp;amp;apos;re not waiting for recovery to complete, just hoping we race behind it so the test passes. These test cases need a redo (or a rip out)" - the HBASE-13391 tracks the real fix; this JIRA (based on suggestion of Sean Busbey) disable these two tests so that we will not run into false alarm frequently.</description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.coprocessor.TestRegionObserverInterface.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">13391</link>
		</links>
	</bug>
	<bug id="13733" opendate="2015-05-21 01:43:29" fixdate="2015-05-21 21:05:08" resolution="Fixed">
		<buginformation>
			<summary>Failed MiniZooKeeperCluster startup did not shutdown ZK servers</summary>
			<description>MiniZooKeeperCluster#startup() starts servers one-by-one, if everything is good, it would declare success of start:


  public int startup(File baseDir, int numZooKeeperServers) 
    ...
    // running all the ZK servers
    for (int i = 0; i &amp;lt; numZooKeeperServers; i++) {
    ...===&amp;gt; could throw exception in the loop and end the startup
      // Start up this ZK server
      standaloneServerFactory.startup(server);
      ...
      standaloneServerFactoryList.add(standaloneServerFactory);
      zooKeeperServers.add(server);
    }
   ...
    started = true;
    ...
  }



However, if exception throws in the middle of start up (eg. some servers already started), the MiniZooKeeperCluster#shutdown() would not shut down them and clean up resources.  


  public void shutdown() throws IOException {
    if (!started) {
      return;
    }
    ...
  }

</description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.java</file>
		</fixedFiles>
	</bug>
	<bug id="13734" opendate="2015-05-21 04:41:46" fixdate="2015-05-25 08:30:30" resolution="Fixed">
		<buginformation>
			<summary>Improper timestamp checking with VisibilityScanDeleteTracker</summary>
			<description>3 issues
1. When VC is used and all the put cells and delete cells are not having any visibility associated with them, we are not correctly checking put cells ts against that of delete cell resulting in deletion of cells coming in after the delete ts
2. Have a row r1 with 2 cells of same TS but different visibility. In order to delete both cells we have to apply 2 deletes with these 2 visibility being set to Delete. We are trying to do this using delete full row option or delete cf way. But only one cell is getting deleted.
3. Same case as in #2 when I try to delete using family version delete, only one cell is getting deleted.</description>
			<version>0.98.4</version>
			<fixedVersion>2.0.0, 0.98.13, 1.0.2, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.security.visibility.VisibilityScanDeleteTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithDeletes.java</file>
		</fixedFiles>
	</bug>
	<bug id="13767" opendate="2015-05-25 16:42:49" fixdate="2015-05-27 17:46:41" resolution="Fixed">
		<buginformation>
			<summary>Allow ZKAclReset to set and not just clear ZK ACLs</summary>
			<description>The ZKAclReset tool allows to clear ZK ACLs, which is useful if you are migrating from a secure to unsecure cluster setup.
If you want to make sure that your znode ACLs are correct, a -set-acls option, which allows to enforce the proper ACLs on the znodes in a secure setup, can be useful too.</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 0.98.13, 1.0.2, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.zookeeper.ZkAclReset.java</file>
		</fixedFiles>
	</bug>
	<bug id="13732" opendate="2015-05-21 00:12:04" fixdate="2015-05-28 01:29:10" resolution="Fixed">
		<buginformation>
			<summary>TestHBaseFsck#testParallelWithRetriesHbck fails intermittently</summary>
			<description>TestHBaseFsck#testParallelWithRetriesHbck failed intermittently (especially in Windows environment) with "java.io.IOException: Duplicate hbck - Abort"

java.util.concurrent.ExecutionException: java.io.IOException: Duplicate hbck - Abort
	at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:252)
	at java.util.concurrent.FutureTask.get(FutureTask.java:111)
	at org.apache.hadoop.hbase.util.TestHBaseFsck.testParallelWithRetriesHbck(TestHBaseFsck.java:644)
Caused by: java.io.IOException: Duplicate hbck - Abort
	at org.apache.hadoop.hbase.util.HBaseFsck.connect(HBaseFsck.java:484)
	at org.apache.hadoop.hbase.util.hbck.HbckTestingUtil.doFsck(HbckTestingUtil.java:53)
	at org.apache.hadoop.hbase.util.hbck.HbckTestingUtil.doFsck(HbckTestingUtil.java:43)
	at org.apache.hadoop.hbase.util.hbck.HbckTestingUtil.doFsck(HbckTestingUtil.java:38)
	at org.apache.hadoop.hbase.util.TestHBaseFsck$2RunHbck.call(TestHBaseFsck.java:635)
	at org.apache.hadoop.hbase.util.TestHBaseFsck$2RunHbck.call(TestHBaseFsck.java:628)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
	at java.util.concurrent.FutureTask.run(FutureTask.java:166)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:722)


HBASE-13591 tried to address this issue.  It did improve the pass rate in Linux environment (after the fix, I could not repro in my machine); however, the test still failed intermittently in Windows environment during testing of 1.1 release.
Looking at the code, it uses the ExponentialBackoffPolicy (starting with 200ms sleep time after first failed attempt to acquire the lock in ZK, then 400ms, then 800ms, etc.) in between retries.  Therefore, even the first hbck run completes, the second hbck run would still fail due to long sleep time.  
the proposal to fix the problem is to use ExponentialBackoffPolicyWithLimit and cap the max sleep time to some small number (eg. 5 seconds, it should be configurable).  This would make the test more robust.  </description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
			<file type="M">org.apache.hadoop.hbase.util.HBaseFsck.java</file>
			<file type="M">org.apache.hadoop.hbase.util.RetryCounterFactory.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">13574</link>
			<link type="Reference" description="is related to">13574</link>
		</links>
	</bug>
	<bug id="13778" opendate="2015-05-26 16:50:35" fixdate="2015-05-28 06:28:53" resolution="Fixed">
		<buginformation>
			<summary>BoundedByteBufferPool incorrectly increasing runningAverage buffer length</summary>
			<description>I was testing HBASE-13158 and noticed this. In BoundedByteBufferPool, we are having an intial value for &amp;amp;apos;runningAverage&amp;amp;apos; which defaults to 16K. So the pool will make initial buffers of this size. This buffer may grow while used in ByteBufferOuputStream as the data has to be written is getting more. On return back the BB to the pool, we try to adjust this &amp;amp;apos;runningAverage&amp;amp;apos; size by considering the capacity of the returned BB. We lack proper synchronization here and this makes this runningAverage to grow till its max (1 MB)
I am testing with PE tool with randomRead and having 20 client threads. So each get op returns one cell with almost like 1KB data. The default size of the BB created by Pool is 16K and ideally there is no room for getting this resized.


2015-05-26 20:12:21,965 INFO  [PriorityRpcServer.handler=5,queue=1,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=16384, totalCapacity=0, count=0, alloctions=2
2015-05-26 20:12:21,966 INFO  [PriorityRpcServer.handler=2,queue=0,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=16384, totalCapacity=0, count=0, alloctions=4
2015-05-26 20:12:21,966 INFO  [PriorityRpcServer.handler=8,queue=0,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=16384, totalCapacity=0, count=0, alloctions=6
2015-05-26 20:12:21,966 INFO  [PriorityRpcServer.handler=12,queue=0,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=16384, totalCapacity=0, count=0, alloctions=9
2015-05-26 20:12:21,966 INFO  [PriorityRpcServer.handler=13,queue=1,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=16384, totalCapacity=0, count=0, alloctions=10
2015-05-26 20:12:21,966 INFO  [PriorityRpcServer.handler=18,queue=0,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=16384, totalCapacity=0, count=0, alloctions=12
2015-05-26 20:12:21,966 INFO  [PriorityRpcServer.handler=16,queue=0,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=16384, totalCapacity=0, count=0, alloctions=14
2015-05-26 20:12:21,966 INFO  [PriorityRpcServer.handler=7,queue=1,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=16384, totalCapacity=0, count=0, alloctions=5
2015-05-26 20:12:21,966 INFO  [PriorityRpcServer.handler=19,queue=1,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=16384, totalCapacity=0, count=0, alloctions=15
2015-05-26 20:12:21,966 INFO  [PriorityRpcServer.handler=1,queue=1,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=16384, totalCapacity=0, count=0, alloctions=4
2015-05-26 20:12:21,965 INFO  [PriorityRpcServer.handler=11,queue=1,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=16384, totalCapacity=0, count=0, alloctions=2
2015-05-26 20:12:21,966 INFO  [PriorityRpcServer.handler=3,queue=1,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=16384, totalCapacity=0, count=0, alloctions=13
2015-05-26 20:12:21,966 INFO  [PriorityRpcServer.handler=9,queue=1,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=16384, totalCapacity=0, count=0, alloctions=11
2015-05-26 20:12:21,966 INFO  [PriorityRpcServer.handler=6,queue=0,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=16384, totalCapacity=0, count=0, alloctions=8
2015-05-26 20:12:21,966 INFO  [PriorityRpcServer.handler=15,queue=1,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=16384, totalCapacity=0, count=0, alloctions=7
2015-05-26 20:12:21,966 INFO  [PriorityRpcServer.handler=4,queue=0,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=16384, totalCapacity=0, count=0, alloctions=16
2015-05-26 20:12:21,967 INFO  [PriorityRpcServer.handler=10,queue=0,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=16384, totalCapacity=0, count=0, alloctions=17
2015-05-26 20:12:21,967 INFO  [PriorityRpcServer.handler=14,queue=0,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=16384, totalCapacity=0, count=0, alloctions=19
2015-05-26 20:12:21,967 INFO  [PriorityRpcServer.handler=17,queue=1,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=16384, totalCapacity=0, count=0, alloctions=18
2015-05-26 20:12:22,146 INFO  [PriorityRpcServer.handler=18,queue=0,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=16384, totalCapacity=-16384, count=2, alloctions=20
2015-05-26 20:12:22,707 INFO  [PriorityRpcServer.handler=9,queue=1,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=212992, totalCapacity=-32768, count=4, alloctions=21
2015-05-26 20:12:23,208 INFO  [PriorityRpcServer.handler=3,queue=1,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=212992, totalCapacity=-81920, count=1, alloctions=22
2015-05-26 20:12:29,567 INFO  [PriorityRpcServer.handler=0,queue=0,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=234837, totalCapacity=-49152, count=6, alloctions=23
2015-05-26 20:12:29,974 INFO  [PriorityRpcServer.handler=0,queue=0,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=311296, totalCapacity=442368, count=6, alloctions=24
2015-05-26 20:12:31,356 INFO  [PriorityRpcServer.handler=7,queue=1,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=606208, totalCapacity=1054037, count=9, alloctions=25
2015-05-26 20:12:31,894 INFO  [PriorityRpcServer.handler=3,queue=1,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=901120, totalCapacity=742741, count=1, alloctions=26
2015-05-26 20:12:32,961 INFO  [PriorityRpcServer.handler=11,queue=1,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=920234, totalCapacity=2479445, count=12, alloctions=27
2015-05-26 20:12:36,965 INFO  [PriorityRpcServer.handler=2,queue=0,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=1037653, totalCapacity=3836586, count=18, alloctions=28
2015-05-26 20:12:42,212 INFO  [PriorityRpcServer.handler=6,queue=0,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=1048120, totalCapacity=11203921, count=12, alloctions=29
2015-05-26 20:12:45,387 INFO  [PriorityRpcServer.handler=13,queue=1,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=1048302, totalCapacity=10174915, count=1, alloctions=30
2015-05-26 20:12:46,171 INFO  [PriorityRpcServer.handler=1,queue=1,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=1048302, totalCapacity=14177342, count=7, alloctions=31
2015-05-26 20:12:52,401 INFO  [PriorityRpcServer.handler=13,queue=1,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=1048495, totalCapacity=19454171, count=8, alloctions=32
2015-05-26 20:12:52,541 INFO  [PriorityRpcServer.handler=2,queue=0,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=1048495, totalCapacity=16778574, count=1, alloctions=33
2015-05-26 20:12:56,631 INFO  [PriorityRpcServer.handler=5,queue=1,port=16020] io.BoundedByteBufferPool: Allocated new BB runningAverage=1048495, totalCapacity=28925990, count=2, alloctions=34
...
..


getBuffer()  on 1st line removes the BB from the Queue. putBuffer() put it back 1st and then in next line checks the size of the buffer. During this time period many other threads might have taken buffers. 
putBuffer(ByteBuffer bb)


	int size = this.buffers.size(); // This size may be inexact.
	this.totalReservoirCapacity += bb.capacity();
	int average = 0;
	if (size != 0) {
	  average = this.totalReservoirCapacity / size;
	}
	if (average &amp;gt; this.runningAverage &amp;amp;&amp;amp; average &amp;lt; this.maxByteBufferSizeToCache) {
	  this.runningAverage = average;
	}


getBuffer() 


	ByteBuffer bb = this.buffers.poll();
    if (bb != null) {
      // Clear sets limit == capacity.  Postion == 0.
      bb.clear();
      this.totalReservoirCapacity -= bb.capacity();
    } 


totalReservoirCapacity might not have reduced while do above division for calc avg.  From above log lines it is clear.
As a result we will create much bigger sized buffers and we will not allow GC it as we keep them in pool.</description>
			<version>0.98.12</version>
			<fixedVersion>2.0.0, 0.98.13, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.BoundedByteBufferPool.java</file>
			<file type="M">org.apache.hadoop.hbase.io.TestBoundedByteBufferPool.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">13142</link>
		</links>
	</bug>
	<bug id="13800" opendate="2015-05-28 23:26:20" fixdate="2015-05-29 02:31:23" resolution="Fixed">
		<buginformation>
			<summary>TestStore#testDeleteExpiredStoreFiles should create unique data/log directory for each call</summary>
			<description>When TestStore#init() was called twice in TestStore#testDeleteExpiredStoreFiles, it did not use different base directory for each call (other tests in the same test suite do).  If the first call did not release the handle of WAL files fast enough, the second init() call would fail.  
This is constantly seen in Windows environment:

java.io.IOException: Target WAL already exists within directory file:/C:/hbase/hbase-server/target/test-data/f39ecdde-1d04-4332-93c7-4c8df1e08e67/TestStoretestDeleteExpiredStoreFiles/WALs/testDeleteExpiredStoreFiles
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.&amp;lt;init&amp;gt;(FSHLog.java:525)
	at org.apache.hadoop.hbase.wal.DefaultWALProvider.init(DefaultWALProvider.java:97)
	at org.apache.hadoop.hbase.wal.WALFactory.getProvider(WALFactory.java:147)
	at org.apache.hadoop.hbase.wal.WALFactory.&amp;lt;init&amp;gt;(WALFactory.java:179)
	at org.apache.hadoop.hbase.regionserver.TestStore.init(TestStore.java:185)
	at org.apache.hadoop.hbase.regionserver.TestStore.init(TestStore.java:162)
	at org.apache.hadoop.hbase.regionserver.TestStore.testDeleteExpiredStoreFiles(TestStore.java:307)
	at org.apache.hadoop.hbase.regionserver.TestStore.testDeleteExpiredStoreFiles(TestStore.java:286)


The fix is trivial: just like other tests in the same test suite, use different base directory for multiple init() calls in the same test.</description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestStore.java</file>
		</fixedFiles>
	</bug>
	<bug id="13802" opendate="2015-05-29 06:00:33" fixdate="2015-05-29 09:40:26" resolution="Fixed">
		<buginformation>
			<summary>Procedure V2: Master fails to come up due to rollback of create namespace table</summary>
			<description>In Procedure V2 (HBASE-13203) implementation, Rollback of a CreateTableProcedure would call the Quota Manager to remove the table from namespace quota.


protected static void deleteTableStates(final MasterProcedureEnv env, final TableName tableName)  {
 ProcedureSyncWait.getMasterQuotaManager(env).removeTableFromNamespaceQuota(tableName);
}


This could lead to a &amp;amp;apos;deadlock&amp;amp;apos;-like situation during master starting up:
(1) The create namespace table procedure failed in the middle of master crash/failover. When master re-started, it tried to rollback, one step of rollback is to call QuotaManager to remove the table from NameSpaceQuota, but the QuotaManager has NOT started - so the rollback has to wait.
(2). The QuotaManager would start in master after Namespace Manager starts.
(3). The Namespace Manager is waiting for the table lock to be released by rollback of create namespace table procedure so that it can create namespace table as part of Namespace Manager initialization.


HMaster#finishActiveMasterInitialization() {
   ...
   status.setStatus("Starting namespace manager");
   initNamespace();
    ...
   status.setStatus("Starting quota manager");
   initQuotaManager();
   ...
}


(4). Now (1) waits for (2), which waits for (3), which waits for (1) - no one make progress &amp;amp; master could not complete initialization and fails to come up.

2015-05-28 10:01:26,890 INFO  [ip-111-22-33-444:16000.activeMasterManager] master.TableNamespaceManager: Namespace table not found. Creating...
2015-05-28 10:06:22,016 WARN  [ProcedureExecutorThread-0] procedure.CreateTableProcedure: Failed rollback attempt step=CREATE_TABLE_PRE_OPERATION table=hbase:namespace
org.apache.hadoop.hbase.exceptions.TimeoutIOException: Timed out while waiting on quota manager to be available
	at org.apache.hadoop.hbase.master.procedure.ProcedureSyncWait.waitFor(ProcedureSyncWait.java:122)
	at org.apache.hadoop.hbase.master.procedure.ProcedureSyncWait.waitFor(ProcedureSyncWait.java:102)
	at org.apache.hadoop.hbase.master.procedure.ProcedureSyncWait.getMasterQuotaManager(ProcedureSyncWait.java:184)
	at org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure.deleteTableStates(DeleteTableProcedure.java:408)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.rollbackState(CreateTableProcedure.java:169)
	at org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.rollbackState(CreateTableProcedure.java:58)
	at org.apache.hadoop.hbase.procedure2.StateMachineProcedure.rollback(StateMachineProcedure.java:121)
	at org.apache.hadoop.hbase.procedure2.Procedure.doRollback(Procedure.java:414)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.executeRollback(ProcedureExecutor.java:808)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.executeRollback(ProcedureExecutor.java:773)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execLoop(ProcedureExecutor.java:653)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execLoop(ProcedureExecutor.java:626)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.access$200(ProcedureExecutor.java:70)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor$1.run(ProcedureExecutor.java:413)
2015-05-28 10:06:22,169 WARN  [ProcedureExecutorThread-1] procedure.CreateTableProcedure: The table hbase:namespace does not exist in meta but has a znode. run hbck to fix inconsistencies.
2015-05-28 10:06:27,292 FATAL [ip-111-22-33-444:16000.activeMasterManager] master.HMaster: Failed to become active master
java.io.IOException: Timedout 300000ms waiting for namespace table to be assigned
	at org.apache.hadoop.hbase.master.TableNamespaceManager.start(TableNamespaceManager.java:104)
	at org.apache.hadoop.hbase.master.HMaster.initNamespace(HMaster.java:980)
	at org.apache.hadoop.hbase.master.HMaster.finishActiveMasterInitialization(HMaster.java:779)
	at org.apache.hadoop.hbase.master.HMaster.access$500(HMaster.java:182)
	at org.apache.hadoop.hbase.master.HMaster$1.run(HMaster.java:1632)
	at java.lang.Thread.run(Thread.java:745)
2015-05-28 10:06:27,293 FATAL [ip-111-22-33-444:16000.activeMasterManager] master.HMaster: Master server abort: loaded coprocessors are: [org.apache.ranger.authorization.hbase.RangerAuthorizationCoprocessor]
2015-05-28 10:06:27,293 FATAL [ip-111-22-33-444:16000.activeMasterManager] master.HMaster: Unhandled exception. Starting shutdown.
java.io.IOException: Timedout 300000ms waiting for namespace table to be assigned
	at org.apache.hadoop.hbase.master.TableNamespaceManager.start(TableNamespaceManager.java:104)
	at org.apache.hadoop.hbase.master.HMaster.initNamespace(HMaster.java:980)
	at org.apache.hadoop.hbase.master.HMaster.finishActiveMasterInitialization(HMaster.java:779)
	at org.apache.hadoop.hbase.master.HMaster.access$500(HMaster.java:182)
	at org.apache.hadoop.hbase.master.HMaster$1.run(HMaster.java:1632)
	at java.lang.Thread.run(Thread.java:745)

</description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.java</file>
			<file type="M">org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure.java</file>
		</fixedFiles>
	</bug>
	<bug id="13776" opendate="2015-05-26 04:05:42" fixdate="2015-05-29 18:38:15" resolution="Fixed">
		<buginformation>
			<summary>Setting illegal versions for HColumnDescriptor does not throw IllegalArgumentException </summary>
			<description>HColumnDescriptor hcd = new HColumnDescriptor(
        new HColumnDescriptor(HConstants.CATALOG_FAMILY)
            .setInMemory(true)
            .setScope(HConstants.REPLICATION_SCOPE_LOCAL)
            .setBloomFilterType(BloomType.NONE)
            .setCacheDataInL1(true));
    final int minVersions = 123;
    final int maxVersions = 234;
    hcd.setMaxVersions(minVersions);
    hcd.setMinVersions(maxVersions);
//no exception throw</description>
			<version>0.98.14</version>
			<fixedVersion>2.0.0, 0.98.13, 1.0.2, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
		</fixedFiles>
	</bug>
	<bug id="13813" opendate="2015-05-30 00:44:24" fixdate="2015-05-30 03:51:49" resolution="Fixed">
		<buginformation>
			<summary>Fix Javadoc warnings in Procedure.java</summary>
			<description>[WARNING] Javadoc Warnings
[WARNING] /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/hbase-procedure/src/main/java/org/apache/hadoop/hbase/procedure2/Procedure.java:90: warning - @throw is an unknown tag.
[WARNING] /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/hbase-procedure/src/main/java/org/apache/hadoop/hbase/procedure2/Procedure.java:90: warning - @throw is an unknown tag.
[WARNING] /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/hbase-procedure/src/main/java/org/apache/hadoop/hbase/procedure2/Procedure.java:104: warning - @throw is an unknown tag.</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.procedure2.Procedure.java</file>
		</fixedFiles>
	</bug>
	<bug id="13809" opendate="2015-05-29 20:36:31" fixdate="2015-05-31 00:37:56" resolution="Fixed">
		<buginformation>
			<summary>TestRowTooBig should use HDFS directory for its region directory</summary>
			<description>TestRowTooBig uses local directory to create region, which does not work well in Windows, and the code path expects s DFS file path

java.lang.Exception: Unexpected exception, expected&amp;lt;org.apache.hadoop.hbase.regionserver.RowTooBigException&amp;gt; but was&amp;lt;java.lang.IllegalArgumentException&amp;gt;
	at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:197)
	at org.apache.hadoop.hdfs.DistributedFileSystem.access$000(DistributedFileSystem.java:106)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1305)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1424)
	at org.apache.hadoop.hbase.regionserver.HRegionFileSystem.createRegionOnFileSystem(HRegionFileSystem.java:875)
	at org.apache.hadoop.hbase.regionserver.HRegion.createHRegion(HRegion.java:5921)
	at org.apache.hadoop.hbase.regionserver.HRegion.createHRegion(HRegion.java:5892)
	at org.apache.hadoop.hbase.regionserver.HRegion.createHRegion(HRegion.java:5867)
	at org.apache.hadoop.hbase.regionserver.HRegion.createHRegion(HRegion.java:5949)
	at org.apache.hadoop.hbase.regionserver.HRegion.createHRegion(HRegion.java:5828)
	at org.apache.hadoop.hbase.HBaseTestingUtility.createLocalHRegion(HBaseTestingUtility.java:1877)
	at org.apache.hadoop.hbase.regionserver.TestRowTooBig.testScannersSeekOnFewLargeCells(TestRowTooBig.java:83)


java.lang.Exception: Unexpected exception, expected&amp;lt;org.apache.hadoop.hbase.regionserver.RowTooBigException&amp;gt; but was&amp;lt;java.lang.IllegalArgumentException&amp;gt;
	at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:197)
	at org.apache.hadoop.hdfs.DistributedFileSystem.access$000(DistributedFileSystem.java:106)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1305)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1424)
	at org.apache.hadoop.hbase.regionserver.HRegionFileSystem.createRegionOnFileSystem(HRegionFileSystem.java:875)
	at org.apache.hadoop.hbase.regionserver.HRegion.createHRegion(HRegion.java:5921)
	at org.apache.hadoop.hbase.regionserver.HRegion.createHRegion(HRegion.java:5892)
	at org.apache.hadoop.hbase.regionserver.HRegion.createHRegion(HRegion.java:5867)
	at org.apache.hadoop.hbase.regionserver.HRegion.createHRegion(HRegion.java:5949)
	at org.apache.hadoop.hbase.regionserver.HRegion.createHRegion(HRegion.java:5828)
	at org.apache.hadoop.hbase.HBaseTestingUtility.createLocalHRegion(HBaseTestingUtility.java:1877)
	at org.apache.hadoop.hbase.regionserver.TestRowTooBig.testScanAcrossManySmallColumns(TestRowTooBig.java:125)

</description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0, 1.0.2, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestRowTooBig.java</file>
		</fixedFiles>
	</bug>
	<bug id="13820" opendate="2015-06-01 08:23:32" fixdate="2015-06-02 06:53:21" resolution="Fixed">
		<buginformation>
			<summary>Zookeeper is failing to start</summary>
			<description>bin/start-hbase.sh fails to start zookeeper and throws below exception

Exception in thread "main" java.lang.NullPointerException
        at org.apache.hadoop.hbase.zookeeper.ZKServerTool.main(ZKServerTool.java:45)


This have been broken with HBASE-13636</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.zookeeper.ZKServerTool.java</file>
		</fixedFiles>
		<links>
			<link type="Regression" description="is broken by">13636</link>
		</links>
	</bug>
	<bug id="13647" opendate="2015-05-08 10:41:50" fixdate="2015-06-02 10:04:59" resolution="Fixed">
		<buginformation>
			<summary>Default value for hbase.client.operation.timeout is too high</summary>
			<description>Default value for hbase.client.operation.timeout is too high, it is LONG.Max.
That value will block any service calls to coprocessor endpoints indefinitely.
Should we introduce better default value for that?</description>
			<version>0.98.13</version>
			<fixedVersion>2.0.0, 0.98.13, 1.0.2, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.HConstants.java</file>
		</fixedFiles>
	</bug>
	<bug id="13824" opendate="2015-06-02 06:11:26" fixdate="2015-06-02 17:02:39" resolution="Fixed">
		<buginformation>
			<summary>TestGenerateDelegationToken: Master fails to start in Windows environment</summary>
			<description>Master fails to start in the unit test org.apache.hadoop.hbase.security.token.TestGenerateDelegationToken in Windows environment:

java.lang.RuntimeException: Master not initialized after 200000ms seconds
	at org.apache.hadoop.hbase.util.JVMClusterUtil.startup(JVMClusterUtil.java:225)
	at org.apache.hadoop.hbase.LocalHBaseCluster.startup(LocalHBaseCluster.java:445)
	at org.apache.hadoop.hbase.security.token.TestGenerateDelegationToken.setUp(TestGenerateDelegationToken.java:125)


This is due to incorrect HDFS path:

2015-06-01 07:40:11,072 FATAL [myjenkins-win:59214.activeMasterManager] master.MasterFileSystem(465): Please fix invalid configuration for hbase.rootdir hdfs://127.0.0.1:59154/C:/tmp/hbase-jenkins/hbase
java.lang.IllegalArgumentException: Pathname /C:/tmp/hbase-jenkins/hbase from hdfs://127.0.0.1:59154/C:/tmp/hbase-jenkins/hbase is not a valid DFS filename.
	at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:197)
	at org.apache.hadoop.hdfs.DistributedFileSystem.access$000(DistributedFileSystem.java:106)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1305)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1424)
	at org.apache.hadoop.hbase.master.MasterFileSystem.checkRootDir(MasterFileSystem.java:424)
	at org.apache.hadoop.hbase.master.MasterFileSystem.createInitialFileSystemLayout(MasterFileSystem.java:146)
	at org.apache.hadoop.hbase.master.MasterFileSystem.&amp;lt;init&amp;gt;(MasterFileSystem.java:126)
	at org.apache.hadoop.hbase.master.HMaster.finishActiveMasterInitialization(HMaster.java:649)
	at org.apache.hadoop.hbase.master.HMaster.access$500(HMaster.java:182)
	at org.apache.hadoop.hbase.master.HMaster$1.run(HMaster.java:1646)
	at java.lang.Thread.run(Thread.java:722)

</description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.security.token.TestGenerateDelegationToken.java</file>
		</fixedFiles>
	</bug>
	<bug id="13574" opendate="2015-04-27 12:16:30" fixdate="2015-06-03 01:21:57" resolution="Duplicate">
		<buginformation>
			<summary>Broken TestHBaseFsck in master with hadoop 2.6.0</summary>
			<description>Got following exception and it reproducible (I can see it in recent tests runs from other patches).

Running org.apache.hadoop.hbase.util.TestHBaseFsck
Tests run: 51, Failures: 0, Errors: 1, Skipped: 1, Time elapsed: 348.628 sec &amp;lt;&amp;lt;&amp;lt; FAILURE! - in org.apache.hadoop.hbase.util.TestHBaseFsck
testParallelWithRetriesHbck(org.apache.hadoop.hbase.util.TestHBaseFsck)  Time elapsed: 30.052 sec  &amp;lt;&amp;lt;&amp;lt; ERROR!
java.util.concurrent.ExecutionException: java.io.IOException: Duplicate hbck - Abort
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:188)
	at org.apache.hadoop.hbase.util.TestHBaseFsck.testParallelWithRetriesHbck(TestHBaseFsck.java:634)
Caused by: java.io.IOException: Duplicate hbck - Abort
	at org.apache.hadoop.hbase.util.HBaseFsck.connect(HBaseFsck.java:473)
	at org.apache.hadoop.hbase.util.hbck.HbckTestingUtil.doFsck(HbckTestingUtil.java:53)
	at org.apache.hadoop.hbase.util.hbck.HbckTestingUtil.doFsck(HbckTestingUtil.java:43)
	at org.apache.hadoop.hbase.util.hbck.HbckTestingUtil.doFsck(HbckTestingUtil.java:38)
	at org.apache.hadoop.hbase.util.TestHBaseFsck$2RunHbck.call(TestHBaseFsck.java:625)
	at org.apache.hadoop.hbase.util.TestHBaseFsck$2RunHbck.call(TestHBaseFsck.java:621)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

</description>
			<version>2.0.0</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
			<file type="M">org.apache.hadoop.hbase.util.HBaseFsck.java</file>
			<file type="M">org.apache.hadoop.hbase.util.RetryCounterFactory.java</file>
		</fixedFiles>
		<links>
			<link type="Blocker" description="blocks">13339</link>
			<link type="Blocker" description="is blocked by">8270</link>
			<link type="Duplicate" description="duplicates">13732</link>
			<link type="Reference" description="relates to">13732</link>
			<link type="Reference" description="relates to">13591</link>
			<link type="Regression" description="is broken by">13339</link>
			<link type="Regression" description="is broken by">6478</link>
		</links>
	</bug>
	<bug id="13826" opendate="2015-06-02 22:52:50" fixdate="2015-06-03 05:44:33" resolution="Fixed">
		<buginformation>
			<summary>Unable to create table when group acls are appropriately set.</summary>
			<description>Steps for reproducing the issue.

Create user &amp;amp;apos;test&amp;amp;apos; and group &amp;amp;apos;hbase-admin&amp;amp;apos;.
Grant global create permissions to &amp;amp;apos;hbase-admin&amp;amp;apos;.
Add user &amp;amp;apos;test&amp;amp;apos; to &amp;amp;apos;hbase-admin&amp;amp;apos; group.
Create table operation for &amp;amp;apos;test&amp;amp;apos; user will throw ADE.

</description>
			<version>0.98.13</version>
			<fixedVersion>2.0.0, 0.98.13, 1.0.2, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.security.access.TestAccessController2.java</file>
			<file type="M">org.apache.hadoop.hbase.security.access.TableAuthManager.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">13828</link>
		</links>
	</bug>
	<bug id="13831" opendate="2015-06-03 18:59:06" fixdate="2015-06-03 22:47:19" resolution="Fixed">
		<buginformation>
			<summary>TestHBaseFsck#testParallelHbck is flaky against hadoop 2.6+</summary>
			<description>Running TestHBaseFsck#testParallelHbck is flaky against HADOOP-2.6+ environment.  The idea of the test is that with when 2 HBCK operations are running simultaneously, the 2nd HBCK would fail with no-retry because creating lock file would fail due to the 1st HBCK already created.  However, with HADOOP-2.6+, the FileSystem#createFile call internally retries with AlreadyBeingCreatedException (see HBASE-13574 for more details: "It seems that test is broken due of the new create retry policy in hadoop 2.6. Namenode proxy now created with custom RetryPolicy for AlreadyBeingCreatedException which is implies timeout on this operations up to HdfsConstants.LEASE_SOFTLIMIT_PERIOD (60seconds).")
When I run the TestHBaseFsck#testParallelHbck test against HADOOP-2.7 in a Windows environment (HBASE is branch-1.1) multiple times, the result is unpredictable (sometime succeeded, sometime failed - more failure than succeeded).  
The fix is trivial: Leverage the change in HBASE-13732 and reduce the max wait time to a smaller number.   </description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
		</fixedFiles>
	</bug>
	<bug id="13779" opendate="2015-05-26 16:53:29" fixdate="2015-06-05 19:39:51" resolution="Fixed">
		<buginformation>
			<summary>Calling table.exists() before table.get() end up with an empty Result</summary>
			<description>If we call exists() before a get() the result returned by the get() will be empty.
simple test to verify it:


Put put = new Put(ROW);
put.add(FAMILY, QUALIFIER, VALUE);
table.put(put);

Get get = new Get(ROW);

boolean exist = table.exists(get);
exist = table.exists(get);
assertEquals(true, exist);

Result result = table.get(get);
// this will fail saying that the Result is empty
// if we remove the exist everything is fine
assertEquals(false, result.isEmpty()); 
assertTrue(Bytes.equals(VALUE, result.getValue(FAMILY, QUALIFIER)));


if we use a different Get instance for the get everything works


...
get = new Get(ROW);
Result result = table.get(get);
assertEquals(false, result.isEmpty()); 


HTable.exists() set the checkExistenceOnly flag in the Get so that object is not reusable by a table.get()


  public boolean exists(final Get get) throws IOException {
    get.setCheckExistenceOnly(true);
    Result r = get(get);
    assert r.getExists() != null;
    return r.getExists();
  }

</description>
			<version>0.98.12.1</version>
			<fixedVersion>2.0.0, 0.98.13, 1.0.2, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
			<file type="M">org.apache.hadoop.hbase.client.Get.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestGet.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestFromClientSide3.java</file>
			<file type="M">org.apache.hadoop.hbase.client.Scan.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">13799</link>
		</links>
	</bug>
	<bug id="13789" opendate="2015-05-28 00:10:42" fixdate="2015-06-05 19:40:57" resolution="Fixed">
		<buginformation>
			<summary>ForeignException should not be sent to the client</summary>
			<description>ForeignException is in hbase-server so the client will not be able to deserialize it, and also it will hide the DoNotRetryException of the cause.
I haven&amp;amp;apos;t found an easy way to test it, aside manually looking at the logs. and this stuff will go away with proc-v2. so for now the easy workaround is catch the ForeignException in the master which are just the few places related to proc-v1 and throw the cause to the client</description>
			<version>0.98.13</version>
			<fixedVersion>2.0.0, 0.98.13, 1.0.2, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
		</fixedFiles>
	</bug>
	<bug id="13834" opendate="2015-06-04 00:12:37" fixdate="2015-06-06 02:55:55" resolution="Fixed">
		<buginformation>
			<summary>Evict count not properly passed to HeapMemoryTuner.</summary>
			<description>Evict count calculated inside the HeapMemoryManager class in tune function that is passed to HeapMemoryTuner via TunerContext is miscalculated. It is supposed to be Evict count between two intervals but its not. </description>
			<version>1.0.0</version>
			<fixedVersion>2.0.0, 1.0.2, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HeapMemoryManager.java</file>
		</fixedFiles>
	</bug>
	<bug id="13686" opendate="2015-05-14 03:53:27" fixdate="2015-06-07 17:00:25" resolution="Fixed">
		<buginformation>
			<summary>Fail to limit rate in RateLimiter</summary>
			<description>While using the patch in HBASE-11598 , I found that RateLimiter can&amp;amp;apos;t to limit the rate right.

 
 /**
   * given the time interval, are there enough available resources to allow execution?
   * @param now the current timestamp
   * @param lastTs the timestamp of the last update
   * @param amount the number of required resources
   * @return true if there are enough available resources, otherwise false
   */
  public synchronized boolean canExecute(final long now, final long lastTs, final long amount) {
    return avail &amp;gt;= amount ? true : refill(now, lastTs) &amp;gt;= amount;
  }


When avail &amp;gt;= amount, avail can&amp;amp;apos;t be refill. But in the next time to call canExecute, lastTs maybe update. So avail will waste some time to refill. Even we use smaller rate than the limit, the canExecute will return false. </description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.quotas.RateLimiter.java</file>
			<file type="M">org.apache.hadoop.hbase.quotas.TestRateLimiter.java</file>
			<file type="M">org.apache.hadoop.hbase.quotas.FixedIntervalRateLimiter.java</file>
			<file type="M">org.apache.hadoop.hbase.quotas.AverageIntervalRateLimiter.java</file>
			<file type="M">org.apache.hadoop.hbase.quotas.TimeBasedLimiter.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">11598</link>
		</links>
	</bug>
	<bug id="13811" opendate="2015-05-30 00:17:16" fixdate="2015-06-08 20:50:51" resolution="Fixed">
		<buginformation>
			<summary>Splitting WALs, we are filtering out too many edits -&gt; DATALOSS</summary>
			<description>I&amp;amp;apos;ve been running ITBLLs against branch-1 around HBASE-13616 (move of ServerShutdownHandler to pv2). I have come across an instance of dataloss. My patch for HBASE-13616 was in place so can only think it the cause (but cannot see how). When we split the logs, we are skipping legit edits. Digging.</description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.wal.WALSplitter.java</file>
			<file type="M">org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestGetLastFlushedSequenceId.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
			<file type="M">org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination.java</file>
			<file type="M">org.apache.hadoop.hbase.master.RegionStates.java</file>
			<file type="M">org.apache.hadoop.hbase.wal.WAL.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestFSHLog.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.FlushLargeStoresPolicy.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Region.java</file>
			<file type="M">org.apache.hadoop.hbase.wal.DisabledWALProvider.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ServerManager.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.TestCallRunner.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">13853</link>
			<link type="Reference" description="relates to">13877</link>
		</links>
	</bug>
	<bug id="13847" opendate="2015-06-04 19:52:13" fixdate="2015-06-09 03:40:10" resolution="Fixed">
		<buginformation>
			<summary>getWriteRequestCount function in HRegionServer uses int variable to return the count.</summary>
			<description>Variable used to return the value of getWriteRequestCount is int, must be long. I think it causes cluster UI to show negative Write Request Count.</description>
			<version>1.0.0</version>
			<fixedVersion>2.0.0, 1.0.1, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
		</fixedFiles>
	</bug>
	<bug id="13873" opendate="2015-06-09 14:47:19" fixdate="2015-06-10 14:37:35" resolution="Fixed">
		<buginformation>
			<summary>LoadTestTool addAuthInfoToConf throws UnsupportedOperationException</summary>
			<description>When run IntegrationTestIngestWithACL on distributed clusters with kerberos security enabled, the method addAuthInfoToConf() in LoadTestTool will be invoked and throws UnsupportedOperationException, stack as follows:


2015-06-09 22:15:33,605 ERROR [main] util.AbstractHBaseTool: Error running command-line tool
java.lang.UnsupportedOperationException
        at java.util.AbstractList.add(AbstractList.java:148)
        at java.util.AbstractList.add(AbstractList.java:108)
        at org.apache.hadoop.hbase.util.LoadTestTool.addAuthInfoToConf(LoadTestTool.java:811)
        at org.apache.hadoop.hbase.util.LoadTestTool.loadTable(LoadTestTool.java:516)
        at org.apache.hadoop.hbase.util.LoadTestTool.doWork(LoadTestTool.java:479)
        at org.apache.hadoop.hbase.util.AbstractHBaseTool.run(AbstractHBaseTool.java:112)
        at org.apache.hadoop.hbase.IntegrationTestIngest.runIngestTest(IntegrationTestIngest.java:151)
        at org.apache.hadoop.hbase.IntegrationTestIngest.internalRunIngestTest(IntegrationTestIngest.java:114)
        at org.apache.hadoop.hbase.IntegrationTestIngest.runTestFromCommandLine(IntegrationTestIngest.java:97)
        at org.apache.hadoop.hbase.IntegrationTestBase.doWork(IntegrationTestBase.java:115)
        at org.apache.hadoop.hbase.util.AbstractHBaseTool.run(AbstractHBaseTool.java:112)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
        at org.apache.hadoop.hbase.IntegrationTestIngestWithACL.main(IntegrationTestIngestWithACL.java:136)


The corresponding code is below and the reason is obvious. Arrays.asList return a java.util.Arrays$ArrayList but not java.util.ArrayList. Both of them are inherited from java.util.AbstractList, but the former didn&amp;amp;apos;t override the method add(), so the parent method java.util.AbstractList.add() will be invoked and the exception threw.


private void addAuthInfoToConf(Properties authConfig, Configuration conf, String owner,
      String userList) throws IOException {
    List&amp;lt;String&amp;gt; users = Arrays.asList(userList.split(","));
    users.add(owner);
    ...
  }


Does anyone occurred on this? I think it&amp;amp;apos;s an obvious bug but no one report it, so please tell me if I misunderstanding it. If it&amp;amp;apos;s actually a bug here, then it can be fixed very easy as below:


 List&amp;lt;String&amp;gt; users = new ArrayList&amp;lt;String&amp;gt;(Arrays.asList(userList.split(",")));

</description>
			<version>0.98.13</version>
			<fixedVersion>2.0.0, 0.98.13, 1.0.2, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.LoadTestTool.java</file>
		</fixedFiles>
	</bug>
	<bug id="13878" opendate="2015-06-09 22:05:13" fixdate="2015-06-10 23:37:30" resolution="Fixed">
		<buginformation>
			<summary>Set hbase.fs.tmp.dir config in HBaseTestingUtility.java for Phoenix UT to use</summary>
			<description>HBASE-13625 changed the HFileOutputFormat2 partitioner&amp;amp;apos;s path from using the hadoop.tmp.dir config to hbase.fs.tmp.dir config.  However, some Apache Phoenix unit tests (org.apache.phoenix.mapreduce.CsvBulkLoadToolIT and org.apache.phoenix.mapreduce.IndexToolIT) fail due to null value in the hbase.fs.tmp.dir config.  They were relied on the hadoop.tmp.dir set  from HBaseTestingUtility.  

java.lang.IllegalArgumentException: Can not create a Path from a null string
	at org.apache.hadoop.fs.Path.checkPathArg(Path.java:122)
	at org.apache.hadoop.fs.Path.&amp;lt;init&amp;gt;(Path.java:134)
	at org.apache.hadoop.fs.Path.&amp;lt;init&amp;gt;(Path.java:88)
	at org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2.configurePartitioner(HFileOutputFormat2.java:591)
	at org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2.configureIncrementalLoad(HFileOutputFormat2.java:440)
	at org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2.configureIncrementalLoad(HFileOutputFormat2.java:405)
	at org.apache.hadoop.hbase.mapreduce.HFileOutputFormat.configureIncrementalLoad(HFileOutputFormat.java:91)
	at org.apache.phoenix.mapreduce.CsvBulkLoadTool$TableLoader.call(CsvBulkLoadTool.java:505)
	at org.apache.phoenix.mapreduce.CsvBulkLoadTool$TableLoader.call(CsvBulkLoadTool.java:466)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
	at java.util.concurrent.FutureTask.run(FutureTask.java:166)
	at org.apache.phoenix.job.JobManager$InstrumentedJobFutureTask.run(JobManager.java:172)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)


The proposal is to set hbase.fs.tmp.dir in HBaseTestingUtility#setupDataTestDir().</description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0, 0.98.14, 1.0.2, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
		</fixedFiles>
	</bug>
	<bug id="13892" opendate="2015-06-12 00:05:15" fixdate="2015-06-12 02:28:14" resolution="Fixed">
		<buginformation>
			<summary>Scanner with all results filtered out results in NPE</summary>
			<description>Saw a failure during some testing with region_mover.rb


NativeException: java.lang.NullPointerException: null
        __ensure__ at /usr/hdp/current/hbase-master/bin/region_mover.rb:110
  isSuccessfulScan at /usr/hdp/current/hbase-master/bin/region_mover.rb:109
  isSuccessfulScan at /usr/hdp/current/hbase-master/bin/region_mover.rb:104
     unloadRegions at /usr/hdp/current/hbase-master/bin/region_mover.rb:328


To try to get a real stacktrace, I wrote a simple test. Turns out, it was really simple to just produce the NPE within ClientScanner.


java.lang.NullPointerException: null
	at org.apache.hadoop.hbase.client.ClientScanner.getResultsToAddToCache(ClientScanner.java:576)
	at org.apache.hadoop.hbase.client.ClientScanner.loadCache(ClientScanner.java:492)
	at org.apache.hadoop.hbase.client.ClientScanner.next(ClientScanner.java:364)


Patch with fix and test incoming.</description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0, 0.98.14, 1.0.2, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ClientScanner.java</file>
		</fixedFiles>
	</bug>
	<bug id="13833" opendate="2015-06-03 23:01:20" fixdate="2015-06-15 19:26:25" resolution="Fixed">
		<buginformation>
			<summary>LoadIncrementalHFile.doBulkLoad(Path,HTable) doesn&amp;apos;t handle unmanaged connections when using SecureBulkLoad</summary>
			<description>Seems HBASE-13328 wasn&amp;amp;apos;t quite sufficient.

015-06-02 05:49:23,578|beaver.machine|INFO|2828|7140|MainThread|15/06/02 05:49:23 WARN mapreduce.LoadIncrementalHFiles: Skipping non-directory hdfs://dal-pqc1:8020/tmp/192f21dd-cc89-4354-8ba1-78d1f228e7c7/LARGE_TABLE/_SUCCESS
2015-06-02 05:49:23,720|beaver.machine|INFO|2828|7140|MainThread|15/06/02 05:49:23 INFO hfile.CacheConfig: CacheConfig:disabled
2015-06-02 05:49:23,859|beaver.machine|INFO|2828|7140|MainThread|15/06/02 05:49:23 INFO mapreduce.LoadIncrementalHFiles: Trying to load hfile=hdfs://dal-pqc1:8020/tmp/192f21dd-cc89-4354-8ba1-78d1f228e7c7/LARGE_TABLE/0/00870fd0a7544373b32b6f1e976bf47f first=\x80\x00\x00\x00 last=\x80LK?
2015-06-02 05:50:32,028|beaver.machine|INFO|2828|7140|MainThread|15/06/02 05:50:32 INFO client.RpcRetryingCaller: Call exception, tries=10, retries=35, started=68154 ms ago, cancelled=false, msg=row &amp;amp;apos;&amp;amp;apos; on table &amp;amp;apos;LARGE_TABLE&amp;amp;apos; at region=LARGE_TABLE,,1433222865285.e01e02483f30a060d3f7abb1846ea029., hostname=dal-pqc5,16020,1433222547221, seqNum=2
2015-06-02 05:50:52,128|beaver.machine|INFO|2828|7140|MainThread|15/06/02 05:50:52 INFO client.RpcRetryingCaller: Call exception, tries=11, retries=35, started=88255 ms ago, cancelled=false, msg=row &amp;amp;apos;&amp;amp;apos; on table &amp;amp;apos;LARGE_TABLE&amp;amp;apos; at region=LARGE_TABLE,,1433222865285.e01e02483f30a060d3f7abb1846ea029., hostname=dal-pqc5,16020,1433222547221, seqNum=2
...
...
2015-06-02 05:01:56,121|beaver.machine|INFO|7800|2276|MainThread|15/06/02 05:01:56 ERROR mapreduce.CsvBulkLoadTool: Import job on table=LARGE_TABLE failed due to exception.
2015-06-02 05:01:56,121|beaver.machine|INFO|7800|2276|MainThread|java.io.IOException: BulkLoad encountered an unrecoverable problem
2015-06-02 05:01:56,121|beaver.machine|INFO|7800|2276|MainThread|at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.bulkLoadPhase(LoadIncrementalHFiles.java:474)
2015-06-02 05:01:56,122|beaver.machine|INFO|7800|2276|MainThread|at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.doBulkLoad(LoadIncrementalHFiles.java:405)
2015-06-02 05:01:56,122|beaver.machine|INFO|7800|2276|MainThread|at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.doBulkLoad(LoadIncrementalHFiles.java:300)
2015-06-02 05:01:56,122|beaver.machine|INFO|7800|2276|MainThread|at org.apache.phoenix.mapreduce.CsvBulkLoadTool$TableLoader.call(CsvBulkLoadTool.java:517)
2015-06-02 05:01:56,122|beaver.machine|INFO|7800|2276|MainThread|at org.apache.phoenix.mapreduce.CsvBulkLoadTool$TableLoader.call(CsvBulkLoadTool.java:466)
2015-06-02 05:01:56,122|beaver.machine|INFO|7800|2276|MainThread|at java.util.concurrent.FutureTask.run(FutureTask.java:266)
2015-06-02 05:01:56,122|beaver.machine|INFO|7800|2276|MainThread|at org.apache.phoenix.job.JobManager$InstrumentedJobFutureTask.run(JobManager.java:172)
2015-06-02 05:01:56,122|beaver.machine|INFO|7800|2276|MainThread|at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
2015-06-02 05:01:56,124|beaver.machine|INFO|7800|2276|MainThread|at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
2015-06-02 05:01:56,124|beaver.machine|INFO|7800|2276|MainThread|at java.lang.Thread.run(Thread.java:745)
...
...
...
2015-06-02 05:58:34,993|beaver.machine|INFO|2828|7140|MainThread|Caused by: org.apache.hadoop.hbase.client.NeedUnmanagedConnectionException: The connection has to be unmanaged.
2015-06-02 05:58:34,993|beaver.machine|INFO|2828|7140|MainThread|at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.getTable(ConnectionManager.java:724)
2015-06-02 05:58:34,994|beaver.machine|INFO|2828|7140|MainThread|at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.getTable(ConnectionManager.java:708)
2015-06-02 05:58:34,994|beaver.machine|INFO|2828|7140|MainThread|at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.getTable(ConnectionManager.java:542)
2015-06-02 05:58:34,994|beaver.machine|INFO|2828|7140|MainThread|at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles$4.call(LoadIncrementalHFiles.java:733)
2015-06-02 05:58:34,994|beaver.machine|INFO|2828|7140|MainThread|at org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles$4.call(LoadIncrementalHFiles.java:720)
2015-06-02 05:58:34,994|beaver.machine|INFO|2828|7140|MainThread|at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:126)
2015-06-02 05:58:34,994|beaver.machine|INFO|2828|7140|MainThread|... 7 more
2015-06-02 05:58:35,000|beaver.machine|INFO|2828|7140|MainThread|15/06/02 05:58:35 INFO client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x14db2ae02800050
2015-06-02 05:58:35,006|beaver.machine|INFO|2828|7140|MainThread|15/06/02 05:58:35 INFO zookeeper.ZooKeeper: Session: 0x14db2ae02800050 closed
2015-06-02 05:58:35,007|beaver.machine|INFO|2828|7140|MainThread|15/06/02 05:58:35 INFO zookeeper.ClientCnxn: EventThread shut down

</description>
			<version>1.1.0.1</version>
			<fixedVersion>2.0.0, 1.0.2, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">13906</link>
			<link type="Reference" description="relates to">13328</link>
		</links>
	</bug>
	<bug id="13905" opendate="2015-06-15 17:09:18" fixdate="2015-06-16 00:42:25" resolution="Fixed">
		<buginformation>
			<summary>TestRecoveredEdits.testReplayWorksThoughLotsOfFlushing failing consistently on branch-1.1</summary>
			<description>
$ JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.79.x86_64 ../apache-maven-3.3.3/bin/mvn -PrunAllTests -DreuseForks=false clean install -Dmaven.test.redirectTestOutputToFile=true -Dsurefire.rerunFailingTestsCount=4 -Dit.test=noItTest
...
org.apache.hadoop.hbase.regionserver.TestRecoveredEdits.testReplayWorksThoughLotsOfFlushing(org.apache.hadoop.hbase.regionserver.TestRecoveredEdits)
  Run 1: TestRecoveredEdits.testReplayWorksThoughLotsOfFlushing:124-&amp;gt;verifyAllEditsMadeItIn:160 
  Run 2: TestRecoveredEdits.testReplayWorksThoughLotsOfFlushing:98  IO The specified r...
  Run 3: TestRecoveredEdits.testReplayWorksThoughLotsOfFlushing:98  IO The specified r...
  Run 4: TestRecoveredEdits.testReplayWorksThoughLotsOfFlushing:98  IO The specified r...
  Run 5: TestRecoveredEdits.testReplayWorksThoughLotsOfFlushing:98  IO The specified r...


The reruns failed because the test is not idempotent. Perhaps we should have the test startup clean up it&amp;amp;apos;s workspace before starting.

-------------------------------------------------------------------------------
Test set: org.apache.hadoop.hbase.regionserver.TestRecoveredEdits
-------------------------------------------------------------------------------
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 33.894 sec &amp;lt;&amp;lt;&amp;lt; FAILURE! - in org.apache.hadoop.hbase.regionserver.TestRecoveredEdits
testReplayWorksThoughLotsOfFlushing(org.apache.hadoop.hbase.regionserver.TestRecoveredEdits)  Time elapsed: 0 sec  &amp;lt;&amp;lt;&amp;lt; ERROR!
java.io.IOException: The specified region already exists on disk: /grid/0/hbase/hbase-server/target/test-data/0c8ee429-8588-41ab-8999-6754588cd4a6/data/default/testReplayWorksThoughLotsOfFlushing/4823016d8fca70b25503ee07f4c6d79f
        at org.apache.hadoop.hbase.regionserver.HRegionFileSystem.createRegionOnFileSystem(HRegionFileSystem.java:877)
        at org.apache.hadoop.hbase.regionserver.HRegion.createHRegion(HRegion.java:5923)
        at org.apache.hadoop.hbase.regionserver.HRegion.createHRegion(HRegion.java:5894)
        at org.apache.hadoop.hbase.regionserver.HRegion.createHRegion(HRegion.java:5869)
        at org.apache.hadoop.hbase.regionserver.HRegion.createHRegion(HRegion.java:5951)
        at org.apache.hadoop.hbase.regionserver.TestRecoveredEdits.testReplayWorksThoughLotsOfFlushing(TestRecoveredEdits.java:98)

</description>
			<version>1.1.1</version>
			<fixedVersion>2.0.0, 1.0.2, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestRecoveredEdits.java</file>
		</fixedFiles>
	</bug>
	<bug id="13888" opendate="2015-06-11 13:31:28" fixdate="2015-06-16 01:33:10" resolution="Fixed">
		<buginformation>
			<summary>Fix refill bug from HBASE-13686</summary>
			<description>As I report the RateLimiter fail to limit in HBASE-13686, then Ashish Singhi fix that problem by support two kinds of RateLimiter:  AverageIntervalRateLimiter and FixedIntervalRateLimiter. But in my use of the code, I found a new bug about refill() in AverageIntervalRateLimiter.


    long delta = (limit * (now - nextRefillTime)) / super.getTimeUnitInMillis();
    if (delta &amp;gt; 0) {
      this.nextRefillTime = now;
      return Math.min(limit, available + delta);
    }   


When delta &amp;gt; 0, refill maybe return available + delta. Then in the canExecute(), avail will add refillAmount again. So the new avail maybe 2 * avail + delta.


    long refillAmount = refill(limit, avail);
    if (refillAmount == 0 &amp;amp;&amp;amp; avail &amp;lt; amount) {
      return false;
    }   
    // check for positive overflow
    if (avail &amp;lt;= Long.MAX_VALUE - refillAmount) {
      avail = Math.max(0, Math.min(avail + refillAmount, limit));
    } else {
      avail = Math.max(0, limit);
    } 


I will add more unit tests for RateLimiter in the next days.
Review Board: https://reviews.apache.org/r/35384/</description>
			<version>1.1.1</version>
			<fixedVersion>2.0.0, 1.2.0, 1.1.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.quotas.RateLimiter.java</file>
			<file type="M">org.apache.hadoop.hbase.quotas.TestRateLimiter.java</file>
			<file type="M">org.apache.hadoop.hbase.quotas.FixedIntervalRateLimiter.java</file>
			<file type="M">org.apache.hadoop.hbase.quotas.AverageIntervalRateLimiter.java</file>
		</fixedFiles>
	</bug>
	<bug id="13821" opendate="2015-06-01 17:58:54" fixdate="2015-06-16 02:31:59" resolution="Fixed">
		<buginformation>
			<summary>WARN if hbase.bucketcache.percentage.in.combinedcache is set</summary>
			<description>HBASE-11520 improved configuration of bucket cache to no longer require hbase.bucketcache.percentage.in.combinedcache. This was done rather aggressively, with this previously mandatory configuration being ignored. This can result in RS crashes for unsuspecting users. We should add a WARN when hbase.bucketcache.percentage.in.combinedcache is set to make debugging the crash more straight forward.</description>
			<version>1.0.0</version>
			<fixedVersion>2.0.0, 1.0.2, 1.2.0, 1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.hfile.CacheConfig.java</file>
		</fixedFiles>
	</bug>
	<bug id="13737" opendate="2015-05-21 07:22:38" fixdate="2015-06-16 09:36:04" resolution="Fixed">
		<buginformation>
			<summary>[HBase MOB] MOBTable cloned from a snapshot leads to data loss, when that actual snapshot and main table is deleted.</summary>
			<description>clone snapshot on mob feature leads to data loss for mob data.
steps to reproduce:
===============
1. created MOB table with two column families like "mobcf" (mob is enabled) and "norcf"
2. insert mob data and normal data at a time into the table.
3. scan the MOB table.
4. take snapshot by specifying the table name.
5. clone the snapshot by specifying the new table name.
6. check the new table is created or not and try scan for the new table which have both mob data and normal data should give back to the client.
7. delete the snapshot which done in step 4.
8. delete the main table which done in step 1.
9. Now scan the new table again.
</description>
			<version>10000.0</version>
			<fixedVersion>hbase-11339</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.cleaner.HFileLinkCleaner.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestMobSnapshotCloneIndependence.java</file>
		</fixedFiles>
	</bug>
	<bug id="13885" opendate="2015-06-10 06:57:37" fixdate="2015-06-16 19:29:59" resolution="Fixed">
		<buginformation>
			<summary>ZK watches leaks during snapshots</summary>
			<description>When taking snapshot of a table a watcher over /hbase/online-snapshot/abort/snapshot-name is created which is never cleared when the snapshot is successful. If we use snapshots to take backups daily we accumulate a lot of watches.
Steps to reproduce -
1) Take snapshot of a table - snapshot &amp;amp;apos;table_1&amp;amp;apos;, &amp;amp;apos;abc&amp;amp;apos;
2) Run the following on zk node or alternatively observe zk watches metric
 echo "wchc" | nc localhost 2181
/hbase/online-snapshot/abort/abc can be found.</description>
			<version>0.98.12</version>
			<fixedVersion>2.0.0, 0.98.14, 1.0.2, 1.2.0, 1.1.1, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.procedure.ZKProcedureCoordinatorRpcs.java</file>
			<file type="M">org.apache.hadoop.hbase.procedure.ZKProcedureUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.procedure.ZKProcedureMemberRpcs.java</file>
		</fixedFiles>
	</bug>
	<bug id="13933" opendate="2015-06-18 12:26:36" fixdate="2015-06-22 05:42:21" resolution="Fixed">
		<buginformation>
			<summary>DBE&amp;apos;s seekBefore with tags corrupts the tag&amp;apos;s offset information thus leading to incorrect results</summary>
			<description>The problem occurs with moveToPrevious() case and incase of tags we copy the previous pointer&amp;amp;apos;s tag info to the current because already decoded the tags.
Will check once again before I post other details.  I have a test case to reproduce the problem. Found this while working with MultibyteBuffers and verified if this is present in trunk - it is in all branches where we have tags compression (I suppose) will verify</description>
			<version>0.98.13</version>
			<fixedVersion>2.0.0, 0.98.14, 1.0.2, 1.2.0, 1.1.1, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.hfile.TestSeekTo.java</file>
			<file type="M">org.apache.hadoop.hbase.io.encoding.BufferedDataBlockEncoder.java</file>
		</fixedFiles>
	</bug>
	<bug id="13843" opendate="2015-06-04 16:30:50" fixdate="2015-06-22 13:59:25" resolution="Fixed">
		<buginformation>
			<summary>Fix internal constant text in ReplicationManager.java</summary>
			<description>ReplicationAdmin.java:  
public static final String CFNAME = "columnFamlyName; (sic)
Fix.</description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.replication.ReplicationAdmin.java</file>
		</fixedFiles>
	</bug>
	<bug id="13958" opendate="2015-06-23 21:46:51" fixdate="2015-06-23 23:34:30" resolution="Fixed">
		<buginformation>
			<summary>RESTApiClusterManager calls kill() instead of suspend() and resume()</summary>
			<description>suspend() and resume() of the REST ClusterManager are calling the wrong method.


  @Override
  public void suspend(ServiceType service, String hostname, int port) throws IOException {
    hBaseClusterManager.kill(service, hostname, port);
  }

  @Override
  public void resume(ServiceType service, String hostname, int port) throws IOException {
    hBaseClusterManager.kill(service, hostname, port);
  }

</description>
			<version>1.0.1.1</version>
			<fixedVersion>2.0.0, 0.98.14, 1.0.2, 1.2.0, 1.1.2, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.RESTApiClusterManager.java</file>
		</fixedFiles>
	</bug>
	<bug id="13945" opendate="2015-06-22 09:17:45" fixdate="2015-06-24 03:50:58" resolution="Fixed">
		<buginformation>
			<summary>Prefix_Tree seekBefore() does not work correctly</summary>
			<description>This is related to the TestSeekTo test case where the seekBefore() does not work with Prefix_Tree because of an issue in getFirstKeyInBlock(). In the trunk and branch-1 changing the return type of getFirstKeyInBlock() from BB to Cell resolved the problem, but the same cannot be done in 0.98. Hence we need a change in the KvUtil.copyToNewBuffer API to handle this.  Since the limit is made as the position - in seekBefore when we do 


byte[] firstKeyInCurrentBlock = Bytes.getBytes(firstKey);


in HFileReaderV2.seekBefore() we end up in an empty byte array and it would not be the expected one based on which we try to seek to load a new block.</description>
			<version>0.98.2</version>
			<fixedVersion>2.0.0, 0.98.14, 1.0.2, 1.2.0, 1.1.2, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.hfile.TestSeekTo.java</file>
			<file type="M">org.apache.hadoop.hbase.io.encoding.DataBlockEncoder.java</file>
			<file type="M">org.apache.hadoop.hbase.KeyValueUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.io.encoding.BufferedDataBlockEncoder.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">13939</link>
		</links>
	</bug>
	<bug id="13923" opendate="2015-06-17 08:56:35" fixdate="2015-06-25 23:38:50" resolution="Fixed">
		<buginformation>
			<summary>Loaded region coprocessors are not reported in shell status command</summary>
			<description>I added a CP to a table using the shell&amp;amp;apos;s alter command. Now I tried to check if it was loaded (short of resorting to parsing the logs). I recalled the refguide mentioned the status &amp;amp;apos;detailed&amp;amp;apos; command, and tried that to no avail.
The UI shows the loaded class in the Software Attributes section, so the info is there. But a shell status command (even after waiting 12+ hours shows nothing. Here an example of a server that has it loaded according to describe and the UI, but the shell lists this:

    slave-1.internal.larsgeorge.com:16020 1434486031598
        requestsPerSecond=0.0, numberOfOnlineRegions=5, usedHeapMB=278, maxHeapMB=941, numberOfStores=5, numberOfStorefiles=3, storefileUncompressedSizeMB=2454, storefileSizeMB=2454, compressionRatio=1.0000, memstoreSizeMB=0, storefileIndexSizeMB=0, readRequestsCount=32070, writeRequestsCount=0, rootIndexSizeKB=0, totalStaticIndexSizeKB=2086, totalStaticBloomSizeKB=480, totalCompactingKVs=0, currentCompactedKVs=0, compactionProgressPct=NaN, coprocessors=[]
        "testqauat:usertable,,1433747062257.4db0d7d73cbaac45cb8568d5b185e1f2."
            numberOfStores=1, numberOfStorefiles=0, storefileUncompressedSizeMB=0, lastMajorCompactionTimestamp=0, storefileSizeMB=0, memstoreSizeMB=0, storefileIndexSizeMB=0, readRequestsCount=0, writeRequestsCount=0, rootIndexSizeKB=0, totalStaticIndexSizeKB=0, totalStaticBloomSizeKB=0, totalCompactingKVs=0, currentCompactedKVs=0, compactionProgressPct=NaN, completeSequenceId=-1, dataLocality=0.0
        "testqauat:usertable,user0,1433747062257.f7c7fe3c7d26910010f40101b20f8d06."
            numberOfStores=1, numberOfStorefiles=0, storefileUncompressedSizeMB=0, lastMajorCompactionTimestamp=0, storefileSizeMB=0, memstoreSizeMB=0, storefileIndexSizeMB=0, readRequestsCount=0, writeRequestsCount=0, rootIndexSizeKB=0, totalStaticIndexSizeKB=0, totalStaticBloomSizeKB=0, totalCompactingKVs=0, currentCompactedKVs=0, compactionProgressPct=NaN, completeSequenceId=-1, dataLocality=0.0
        "testqauat:usertable,user1,1433747062257.dcd5395044732242dfed39b09aa05c36."
            numberOfStores=1, numberOfStorefiles=1, storefileUncompressedSizeMB=820, lastMajorCompactionTimestamp=1434173025593, storefileSizeMB=820, compressionRatio=1.0000, memstoreSizeMB=0, storefileIndexSizeMB=0, readRequestsCount=32070, writeRequestsCount=0, rootIndexSizeKB=0, totalStaticIndexSizeKB=699, totalStaticBloomSizeKB=160, totalCompactingKVs=0, currentCompactedKVs=0, compactionProgressPct=NaN, completeSequenceId=-1, dataLocality=1.0
        "testqauat:usertable,user7,1433747062257.9277fd1d34909b0cb150707cbd7a3907."
            numberOfStores=1, numberOfStorefiles=1, storefileUncompressedSizeMB=816, lastMajorCompactionTimestamp=1434283025585, storefileSizeMB=816, compressionRatio=1.0000, memstoreSizeMB=0, storefileIndexSizeMB=0, readRequestsCount=0, writeRequestsCount=0, rootIndexSizeKB=0, totalStaticIndexSizeKB=690, totalStaticBloomSizeKB=160, totalCompactingKVs=0, currentCompactedKVs=0, compactionProgressPct=NaN, completeSequenceId=-1, dataLocality=1.0
        "testqauat:usertable,user8,1433747062257.d930b52db8c7f07f3c3ab3e12e61a085."
            numberOfStores=1, numberOfStorefiles=1, storefileUncompressedSizeMB=818, lastMajorCompactionTimestamp=1433771950960, storefileSizeMB=818, compressionRatio=1.0000, memstoreSizeMB=0, storefileIndexSizeMB=0, readRequestsCount=0, writeRequestsCount=0, rootIndexSizeKB=0, totalStaticIndexSizeKB=697, totalStaticBloomSizeKB=160, totalCompactingKVs=0, currentCompactedKVs=0, compactionProgressPct=NaN, completeSequenceId=-1, dataLocality=1.0


The refguide shows an example of an older HBase version that has the CP class listed properly. Something is broken.</description>
			<version>1.1.0.1</version>
			<fixedVersion>2.0.0, 0.98.14, 1.0.2, 1.2.0, 1.1.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.TestClassLoading.java</file>
		</fixedFiles>
	</bug>
	<bug id="13969" opendate="2015-06-25 08:29:50" fixdate="2015-06-26 00:47:58" resolution="Fixed">
		<buginformation>
			<summary>AuthenticationTokenSecretManager is never stopped in RPCServer</summary>
			<description>AuthenticationTokenSecretManager is never stopped in RPCServer.


    AuthenticationTokenSecretManager mgr = createSecretManager();
    if (mgr != null) {
      setSecretManager(mgr);
      mgr.start();
    }


It should be stopped during exit.</description>
			<version>0.98.13</version>
			<fixedVersion>2.0.0, 0.98.14, 1.0.2, 1.2.0, 1.1.2, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.RpcServer.java</file>
		</fixedFiles>
	</bug>
	<bug id="13974" opendate="2015-06-26 01:56:15" fixdate="2015-06-26 15:27:52" resolution="Fixed">
		<buginformation>
			<summary>TestRateLimiter#testFixedIntervalResourceAvailability may fail</summary>
			<description>Stacktrace
java.lang.AssertionError: null
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertFalse(Assert.java:64)
	at org.junit.Assert.assertFalse(Assert.java:74)
	at org.apache.hadoop.hbase.quotas.TestRateLimiter.testFixedIntervalResourceAvailability(TestRateLimiter.java:151)
The code of this ut.


     RateLimiter limiter = new FixedIntervalRateLimiter();
     limiter.set(10, TimeUnit.MILLISECONDS);
 
     assertTrue(limiter.canExecute(10));
     limiter.consume(3);
     assertEquals(7, limiter.getAvailable());
     assertFalse(limiter.canExecute(10));


The limiter will refill by MILLISECONDS. So if this unit test execute slowly or hang by others over 1 ms, the assertFalse(limiter.canExecute(10)) will fail.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.1.2, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.quotas.TestRateLimiter.java</file>
		</fixedFiles>
	</bug>
	<bug id="13863" opendate="2015-06-08 19:30:28" fixdate="2015-06-26 15:53:16" resolution="Fixed">
		<buginformation>
			<summary>Multi-wal feature breaks reported number and size of HLogs</summary>
			<description>When multi-wal is enabled the number and size of retained HLogs is always reported as zero.
We should fix this so that the numbers are the sum of all retained logs.</description>
			<version>1.0.0</version>
			<fixedVersion>2.0.0, 1.0.2, 1.2.0, 1.1.2, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.wal.BoundedRegionGroupingProvider.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.wal.DefaultWALProvider.java</file>
		</fixedFiles>
	</bug>
	<bug id="13959" opendate="2015-06-24 04:04:47" fixdate="2015-06-30 01:25:54" resolution="Fixed">
		<buginformation>
			<summary>Region splitting uses a single thread in most common cases</summary>
			<description>When storefiles need to be split as part of a region split, the current logic uses a threadpool with the size set to the size of the number of stores. Since most common table setup involves only a single column family, this translates to having a single store and so the threadpool is run with a single thread. However, in a write heavy workload, there could be several tens of storefiles in a store at the time of splitting, and with a threadpool size of one, these files end up getting split sequentially.
With a bit of tracing, I noticed that it takes on an average of 350ms to create a single reference file, and splitting each storefile involves creating two of these, so with a storefile count of 20, it takes about 14s just to get through this phase alone (2 reference files for each storefile), pushing the total time the region is offline to 18s or more. For environments that are setup to fail fast, this makes the client exhaust all retries and fail with NotServingRegionException.
The fix should increase the concurrency of this operation.</description>
			<version>0.98.12</version>
			<fixedVersion>2.0.0, 0.98.14, 1.0.2, 1.2.0, 1.1.2, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.SplitTransactionImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.HConstants.java</file>
		</fixedFiles>
	</bug>
	<bug id="13995" opendate="2015-06-30 01:25:33" fixdate="2015-07-01 16:43:56" resolution="Fixed">
		<buginformation>
			<summary>ServerName is not fully case insensitive</summary>
			<description>we ended up with two ServerName with different cases, AAA and aaa.
Trying to create a table, every once in a while, we ended up with the region lost and not assigned. 
BaseLoadBalancer.roundRobinAssignment() goes through each server and create a map with what to assign to them.
We had to server on the list AAA and aaa which are the same machine, the problem is that the round robin now is assigning an empty list to one of the two. so depending on the order we ended up with a region not assigned.
ServerName equals() does the case insensitive comparison but the hashCode() is done on a case sensitive server name, so the Map in ServerManager will never hit the item and compare it using equals, so we end up with two entries that are the same server. similar thing for ServerName.isSameHostnameAndPort() where we don&amp;amp;apos;t check for cases</description>
			<version>0.98.12.1</version>
			<fixedVersion>2.0.0, 0.98.14, 1.0.2, 1.2.0, 1.1.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ServerName.java</file>
			<file type="M">org.apache.hadoop.hbase.TestServerName.java</file>
		</fixedFiles>
	</bug>
	<bug id="13978" opendate="2015-06-26 20:26:18" fixdate="2015-07-01 18:30:07" resolution="Fixed">
		<buginformation>
			<summary>Variable never assigned in SimpleTotalOrderPartitioner.getPartition() </summary>
			<description>See https://github.com/apache/hbase/blob/master/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/SimpleTotalOrderPartitioner.java#L104, which has an if statement that tries to limit the code to run only once, but since it does not assign this.lastReduces it will always trigger and recompute the splits (and log them).</description>
			<version>1.1.0.1</version>
			<fixedVersion>2.0.0, 0.98.14, 1.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.SimpleTotalOrderPartitioner.java</file>
		</fixedFiles>
	</bug>
	<bug id="13895" opendate="2015-06-12 21:37:57" fixdate="2015-07-02 01:12:07" resolution="Fixed">
		<buginformation>
			<summary>DATALOSS: Region assigned before WAL replay when abort</summary>
			<description>Opening a place holder till finish analysis.
I have dataloss running ITBLL at 3B (testing HBASE-13877). Most obvious culprit is the double-assignment that I can see.</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.1.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
			<file type="M">org.apache.hadoop.hbase.master.AssignmentManager.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TestWALPlayer.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
			<file type="M">org.apache.hadoop.hbase.test.IntegrationTestLoadAndVerify.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.RegionServerStoppedException.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestAssignmentManagerOnCluster.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.WALPlayer.java</file>
			<file type="D">org.apache.hadoop.hbase.regionserver.RegionServerAbortedException.java</file>
		</fixedFiles>
	</bug>
	<bug id="13970" opendate="2015-06-25 10:28:02" fixdate="2015-07-02 13:45:56" resolution="Fixed">
		<buginformation>
			<summary>NPE during compaction in trunk</summary>
			<description>Updated the trunk.. Loaded the table with PE tool.  Trigger a flush to ensure all data is flushed out to disk. When the first compaction is triggered we get an NPE and this is very easy to reproduce


015-06-25 21:33:46,041 INFO  [main-EventThread] procedure.ZKProcedureMemberRpcs: Received procedure start children changed event: /hbase/flush-table-proc/acquired
2015-06-25 21:33:46,051 INFO  [rs(stobdtserver3,16040,1435248182301)-flush-proc-pool3-thread-1] regionserver.HRegion: Flushing 1/1 column families, memstore=76.91 MB
2015-06-25 21:33:46,159 ERROR [regionserver/stobdtserver3/10.224.54.70:16040-longCompactions-1435248183945] regionserver.CompactSplitThread: Compaction failed Request = regionName=TestTable,00000000000000000000283887,1435248198798.028fb0324cd6eb03d5022eb8c147b7c4., storeName=info, fileCount=3, fileSize=343.4 M (114.5 M, 114.5 M, 114.5 M), priority=3, time=7536968291719985
java.lang.NullPointerException
        at org.apache.hadoop.hbase.regionserver.compactions.PressureAwareCompactionThroughputController$ActiveCompaction.access$700(PressureAwareCompactionThroughputController.java:79)
        at org.apache.hadoop.hbase.regionserver.compactions.PressureAwareCompactionThroughputController.finish(PressureAwareCompactionThroughputController.java:238)
        at org.apache.hadoop.hbase.regionserver.compactions.Compactor.performCompaction(Compactor.java:306)
        at org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactor.compact(DefaultCompactor.java:106)
        at org.apache.hadoop.hbase.regionserver.DefaultStoreEngine$DefaultCompactionContext.compact(DefaultStoreEngine.java:112)
        at org.apache.hadoop.hbase.regionserver.HStore.compact(HStore.java:1202)
        at org.apache.hadoop.hbase.regionserver.HRegion.compact(HRegion.java:1792)
        at org.apache.hadoop.hbase.regionserver.CompactSplitThread$CompactionRunner.run(CompactSplitThread.java:524)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:745)
2015-06-25 21:33:46,745 INFO  [rs(stobdtserver3,16040,1435248182301)-flush-proc-pool3-thread-1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1534, memsize=76.9 M, hasBloomFilter=true, into tmp file hdfs://stobdtserver3:9010/hbase/data/default/TestTable/028fb0324cd6eb03d5022eb8c147b7c4/.tmp/942ba0831a0047a08987439e34361a0c
2015-06-25 21:33:46,772 INFO  [rs(stobdtserver3,16040,1435248182301)-flush-proc-pool3-thread-1] regionserver.HStore: Added hdfs://stobdtserver3:9010/hbase/data/default/TestTable/028fb0324cd6eb03d5022eb8c147b7c4/info/942ba0831a0047a08987439e34361a0c, entries=68116, sequenceid=1534, filesize=68.7 M
2015-06-25 21:33:46,773 INFO  [rs(stobdtserver3,16040,1435248182301)-flush-proc-pool3-thread-1] regionserver.HRegion: Finished memstore flush of ~76.91 MB/80649344, currentsize=0 B/0 for region TestTable,00000000000000000000283887,1435248198798.028fb0324cd6eb03d5022eb8c147b7c4. in 723ms, sequenceid=1534, compaction requested=true
2015-06-25 21:33:46,780 INFO  [main-EventThread] procedure.ZKProcedureMemberRpcs: Received created event:/hbase/flush-table-proc/reached/TestTable
2015-06-25 21:33:46,790 INFO  [main-EventThread] procedure.ZKProcedureMemberRpcs: Received created event:/hbase/flush-table-proc/abort/TestTable
2015-06-25 21:33:46,791 INFO  [main-EventThread] procedure.ZKProcedureMemberRpcs: Received procedure abort children changed event: /hbase/flush-table-proc/abort
2015-06-25 21:33:46,803 INFO  [main-EventThread] procedure.ZKProcedureMemberRpcs: Received procedure start children changed event: /hbase/flush-table-proc/acquired
2015-06-25 21:33:46,818 INFO  [main-EventThread] procedure.ZKProcedureMemberRpcs: Received procedure abort children changed event: /hbase/flush-table-proc/abort


Will check this on what is the reason behind it. </description>
			<version>0.98.13</version>
			<fixedVersion>2.0.0, 0.98.14, 1.2.0, 1.1.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.compactions.Compactor.java</file>
		</fixedFiles>
	</bug>
	<bug id="14011" opendate="2015-07-02 12:08:43" fixdate="2015-07-03 02:29:43" resolution="Fixed">
		<buginformation>
			<summary>MultiByteBuffer position based reads does not work correctly</summary>
			<description>The positional based reads in MBBs are having some issues when we try to read the first element from the 2nd BB when the MBB is formed with multiple BBs.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.nio.TestMultiByteBuffer.java</file>
			<file type="M">org.apache.hadoop.hbase.nio.MultiByteBuffer.java</file>
		</fixedFiles>
	</bug>
	<bug id="14012" opendate="2015-07-02 20:06:00" fixdate="2015-07-06 15:04:45" resolution="Fixed">
		<buginformation>
			<summary>Double Assignment and Dataloss when ServerCrashProcedure runs during Master failover</summary>
			<description>(Rewrite to be more explicit about what the problem is)
ITBLL. Master comes up (It is being killed every 1-5 minutes or so). It is joining a running cluster (all servers up except Master with most regions assigned out on cluster). ProcedureStore has two ServerCrashProcedures unfinished (RUNNABLE state) for two separate servers. One SCP is in the middle of the assign step when master crashes (SERVER_CRASH_ASSIGN). This SCP step has this comment on it:


        // Assign may not be idempotent. SSH used to requeue the SSH if we got an IOE assigning
        // which is what we are mimicing here but it looks prone to double assignment if assign
        // fails midway. TODO: Test.


This issue is 1.2+ only since it is ServerCrashProcedure (Added in HBASE-13616, post hbase-1.1.x).
Looking at ServerShutdownHandler, how we used to do crash processing before we moved over to the Pv2 framework, SSH may have (accidentally) avoided this issue since it does its processing in a big blob starting over if killed mid-crash. In particular, post-crash, SSH scans hbase:meta to find servers that were on the downed server. SCP scanneds Meta in one step, saves off the regions it finds into the ProcedureStore, and then in the next step, does actual assign. In this case, we crashed post-meta scan and during assign. Assign is a bulk assign. It mostly succeeded but got this:


 809622 2015-06-09 20:05:28,576 INFO  [ProcedureExecutorThread-9] master.GeneralBulkAssigner: Failed assigning 3 regions to server c2021.halxg.cloudera.com,16020,1433905510696, reassigning them


So, most regions actually made it to new locations except for a few stragglers. All of the successfully assigned regions then are reassigned on other side of master restart when we replay the SCP assign step.
Let me put together the scan meta and assign steps in SCP; this should do until we redo all of assign to run on Pv2.
A few other things I noticed:
In SCP, we only check if failover in first step, not for every step, which means ServerCrashProcedure will run if on reload it is beyond the first step.


    // Is master fully online? If not, yield. No processing of servers unless master is up
    if (!services.getAssignmentManager().isFailoverCleanupDone()) {
      throwProcedureYieldException("Waiting on master failover to complete");
    }


This means we are assigning while Master is still coming up, a no-no (though it does not seem to have caused problem here). Fix.
Also, I see that over the 8 hours of this particular log, each time the master crashes and comes back up, we queue a ServerCrashProcedure for c2022 because an empty dir never gets cleaned up:


 39 2015-06-09 22:15:33,074 WARN  [ProcedureExecutorThread-0] master.SplitLogManager: returning success without actually splitting and deleting all the log files in path hdfs://c2020.halxg.cloudera.com:8020/hbase/WALs/c2022.halxg.cloudera.com,16020,1433902151857-splitting


Fix this too.</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.procedure.ServerCrashProcedure.java</file>
			<file type="M">org.apache.hadoop.hbase.master.SplitLogManager.java</file>
			<file type="M">org.apache.hadoop.hbase.procedure2.ProcedureExecutor.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.master.RegionStateStore.java</file>
		</fixedFiles>
	</bug>
	<bug id="13646" opendate="2015-05-08 09:33:20" fixdate="2015-07-06 16:05:31" resolution="Fixed">
		<buginformation>
			<summary>HRegion#execService should not try to build incomplete messages</summary>
			<description>If some RPC service, called on region throws exception, execService still tries to build Message. In case of complex messages with required fields it complicates service code because service need to pass fake protobuf objects, so they can be barely buildable. 
To mitigate that I propose to check that controller was failed and return null from call instead of failing with exception.</description>
			<version>1.1.1</version>
			<fixedVersion>2.0.0, 0.98.14, 1.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.TestRegionServerCoprocessorEndpoint.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.TestCoprocessorEndpoint.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.protobuf.generated.DummyRegionServerEndpointProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.ResponseConverter.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
		</fixedFiles>
	</bug>
	<bug id="13988" opendate="2015-06-29 13:20:55" fixdate="2015-07-07 02:28:30" resolution="Fixed">
		<buginformation>
			<summary>Add exception handler for lease thread</summary>
			<description>In a prod cluster, a region server exited for some important 
threads were not alive. After excluding other threads from the log, we doubted the lease thread was the root. 
So we need to add an exception handler to the lease thread to debug why it exited in future.

2015-06-29,12:46:09,222 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: STOPPED: One or more threads are no longer alive  stop
2015-06-29,12:46:09,223 INFO org.apache.hadoop.ipc.HBaseServer: Stopping server on 21600
...
2015-06-29,12:46:09,330 INFO org.apache.hadoop.hbase.regionserver.LogRoller: LogRoller exiting.
2015-06-29,12:46:09,330 INFO org.apache.hadoop.hbase.regionserver.MemStoreFlusher: Thread-37 exiting
2015-06-29,12:46:09,330 INFO org.apache.hadoop.hbase.regionserver.HRegionServer$CompactionChecker: regionserver21600.compactionChecker exiting
2015-06-29,12:46:12,403 INFO org.apache.hadoop.hbase.regionserver.HRegionServer$PeriodicMemstoreFlusher: regionserver21600.periodicFlusher exiting</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0, 0.98.14, 1.0.2, 1.2.0, 1.1.2, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
		</fixedFiles>
	</bug>
	<bug id="14042" opendate="2015-07-08 16:58:35" fixdate="2015-07-09 00:49:27" resolution="Fixed">
		<buginformation>
			<summary>Fix FATAL level logging in FSHLog where logged for non fatal exceptions</summary>
			<description>We have FATAL level logging in FSHLog where an IOException causes a log roll to be requested. It isn&amp;amp;apos;t a fatal event. Drop the log level to WARN. (Could even be INFO.)</description>
			<version>0.98.13</version>
			<fixedVersion>2.0.0, 0.98.14, 1.0.2, 1.2.0, 1.1.2, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
		</fixedFiles>
	</bug>
	<bug id="13997" opendate="2015-06-30 10:29:18" fixdate="2015-07-11 03:52:34" resolution="Fixed">
		<buginformation>
			<summary>ScannerCallableWithReplicas cause Infinitely blocking</summary>
			<description>Bug in ScannerCallableWithReplicas.addCallsForOtherReplicas method  
code in ScannerCallableWithReplicas.addCallsForOtherReplicas

private int addCallsForOtherReplicas(
      BoundedCompletionService&amp;lt;Pair&amp;lt;Result[], ScannerCallable&amp;gt;&amp;gt; cs, RegionLocations rl, int min,
      int max) {
    if (scan.getConsistency() == Consistency.STRONG) {
      return 0; // not scheduling on other replicas for strong consistency
    }
    for (int id = min; id &amp;lt;= max; id++) {
      if (currentScannerCallable.getHRegionInfo().getReplicaId() == id) {
        continue; //this was already scheduled earlier
      }
      ScannerCallable s = currentScannerCallable.getScannerCallableForReplica(id);
      if (this.lastResult != null) {
        s.getScan().setStartRow(this.lastResult.getRow());
      }
      outstandingCallables.add(s);
      RetryingRPC retryingOnReplica = new RetryingRPC(s);
      cs.submit(retryingOnReplica);
    }
    return max - min + 1;	//bug? should be "max - min",because "continue"
                                        //always happen once
  }


It can cause completed &amp;lt; submitted always so that the following code will be infinitely blocked.
code in ScannerCallableWithReplicas.call

// submitted larger than the actual one
 submitted += addCallsForOtherReplicas(cs, rl, 0, rl.size() - 1);
    try {
      //here will be affected
      while (completed &amp;lt; submitted) {
        try {
          Future&amp;lt;Pair&amp;lt;Result[], ScannerCallable&amp;gt;&amp;gt; f = cs.take();
          Pair&amp;lt;Result[], ScannerCallable&amp;gt; r = f.get();
          if (r != null &amp;amp;&amp;amp; r.getSecond() != null) {
            updateCurrentlyServingReplica(r.getSecond(), r.getFirst(), done, pool);
          }
          return r == null ? null : r.getFirst(); // great we got an answer
        } catch (ExecutionException e) {
          // if not cancel or interrupt, wait until all RPC&amp;amp;apos;s are done
          // one of the tasks failed. Save the exception for later.
          if (exceptions == null) exceptions = new ArrayList&amp;lt;ExecutionException&amp;gt;(rl.size());
          exceptions.add(e);
          completed++;
        }
      }
    } catch (CancellationException e) {
      throw new InterruptedIOException(e.getMessage());
    } catch (InterruptedException e) {
      throw new InterruptedIOException(e.getMessage());
    } finally {
      // We get there because we were interrupted or because one or more of the
      // calls succeeded or failed. In all case, we stop all our tasks.
      cs.cancelAll(true);
    }


If all replica-RS occur ExecutionException ,it will be infinitely blocked in  cs.take()</description>
			<version>1.0.1.1</version>
			<fixedVersion>2.0.0, 1.2.0, 1.1.2, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.TestClientScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.java</file>
		</fixedFiles>
	</bug>
	<bug id="14073" opendate="2015-07-14 08:44:50" fixdate="2015-07-14 09:23:26" resolution="Fixed">
		<buginformation>
			<summary>TestRemoteTable.testDelete failed in the latest trunk code</summary>
			<description>TestRemoteTable.testDelete failed in the latest trunk code.


"excepted null, but was: &amp;lt;B@615c4156&amp;gt;"

</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.rest.client.RemoteHTable.java</file>
		</fixedFiles>
		<links>
			<link type="Regression" description="is broken by">14047</link>
		</links>
	</bug>
	<bug id="13897" opendate="2015-06-13 17:12:45" fixdate="2015-07-14 23:50:45" resolution="Fixed">
		<buginformation>
			<summary>OOM may occur when Import imports a row with too many KeyValues</summary>
			<description>When importing a row with too many KeyValues (may have too many columns or versions)KeyValueReducer will incur OOM.</description>
			<version>0.98.13</version>
			<fixedVersion>2.0.0, 0.98.14, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.Import.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">7743</link>
		</links>
	</bug>
	<bug id="14041" opendate="2015-07-08 05:33:41" fixdate="2015-07-15 08:42:51" resolution="Fixed">
		<buginformation>
			<summary>Client MetaCache is cleared if a ThrottlingException is thrown</summary>
			<description>During performance test with the request throttling, I saw that hbase:meta table had been read a lot. Currently the MetaCache of the client is cleared, if a ThrottlingException is thrown. It seems to be not needed.</description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
		</fixedFiles>
	</bug>
	<bug id="14077" opendate="2015-07-14 20:24:07" fixdate="2015-07-15 18:22:10" resolution="Fixed">
		<buginformation>
			<summary>Add package to hbase-protocol protobuf files.</summary>
			<description>c++ generated code is currently in the default namespace. That&amp;amp;apos;s bad practice; so lets fix it</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.ClientProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.example.generated.BulkDeleteProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.MapReduceProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.AdminProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.TracingProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.LoadBalancerProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.RPCProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.MasterProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.RowProcessorProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.FilterProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.AggregateProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.ProcedureProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.AuthenticationProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.CellProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.ErrorHandlingProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.example.generated.ExampleProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.FSProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.SecureBulkLoadProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.HFileProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.EncryptionProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.VisibilityLabelsProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.WALProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.MultiRowMutationProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.java</file>
		</fixedFiles>
	</bug>
	<bug id="14094" opendate="2015-07-15 21:26:18" fixdate="2015-07-15 22:53:24" resolution="Fixed">
		<buginformation>
			<summary>Procedure.proto can&amp;apos;t be compiled to C++</summary>
			<description>EOF is a defined symbol in c and C++.</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALFormatReader.java</file>
			<file type="M">org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALFormat.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.ProcedureProtos.java</file>
		</fixedFiles>
	</bug>
	<bug id="14050" opendate="2015-07-09 18:43:06" fixdate="2015-07-17 01:37:41" resolution="Fixed">
		<buginformation>
			<summary>NPE in org.apache.hadoop.hbase.ipc.RpcServer$Connection.readAndProcess</summary>
			<description>
2015-07-02 09:49:32,028 WARN  [.reader=4,port=60020] ipc.RpcServer - RpcServer.listener,port=60020: count of bytes read: 0
java.lang.NullPointerException
    at org.apache.hadoop.hbase.ipc.RpcServer$Connection.readAndProcess(RpcServer.java:1479)
    at org.apache.hadoop.hbase.ipc.RpcServer$Listener.doRead(RpcServer.java:854)
    at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.doRunLoop(RpcServer.java:645)
    at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.run(RpcServer.java:620)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)

</description>
			<version>0.98.12.1</version>
			<fixedVersion>2.0.0, 0.98.14, 1.0.2, 1.2.0, 1.1.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.RpcServer.java</file>
		</fixedFiles>
	</bug>
	<bug id="13971" opendate="2015-06-25 18:47:58" fixdate="2015-07-17 02:39:20" resolution="Fixed">
		<buginformation>
			<summary>Flushes stuck since 6 hours on a regionserver.</summary>
			<description>One region server stuck while flushing(possible deadlock). Its trying to flush two regions since last 6 hours (see the screenshot).
Caused while running IntegrationTestLoadAndVerify for 20 M rows with 600 mapper jobs and 100 back references. ~37 Million writes on each regionserver till now but no writes happening on any regionserver from past 6 hours  and their memstore size is zero(I dont know if this is related). But this particular regionserver has memstore size of 9GBs from past 6 hours.
Relevant snaps from debug dump:
Tasks:
===========================================================
Task: Flushing IntegrationTestLoadAndVerify,R\x9B\x1B\xBF\xAE\x08\xD1\xA2,1435179555993.8e2d075f94ce7699f416ec4ced9873cd.
Status: RUNNING:Preparing to flush by snapshotting stores in 8e2d075f94ce7699f416ec4ced9873cd
Running for 22034s
Task: Flushing IntegrationTestLoadAndVerify,\x93\xA385\x81Z\x11\xE6,1435179555993.9f8d0e01a40405b835bf6e5a22a86390.
Status: RUNNING:Preparing to flush by snapshotting stores in 9f8d0e01a40405b835bf6e5a22a86390
Running for 22033s
Executors:
===========================================================
...
Thread 139 (MemStoreFlusher.1):
  State: WAITING
  Blocked count: 139711
  Waited count: 239212
  Waiting on java.util.concurrent.CountDownLatch$Sync@b9c094a
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
    java.util.concurrent.CountDownLatch.await(CountDownLatch.java:231)
    org.apache.hadoop.hbase.wal.WALKey.getSequenceId(WALKey.java:305)
    org.apache.hadoop.hbase.regionserver.HRegion.getNextSequenceId(HRegion.java:2422)
    org.apache.hadoop.hbase.regionserver.HRegion.internalPrepareFlushCache(HRegion.java:2168)
    org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2047)
    org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2011)
    org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:1902)
    org.apache.hadoop.hbase.regionserver.HRegion.flush(HRegion.java:1828)
    org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:510)
    org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:471)
    org.apache.hadoop.hbase.regionserver.MemStoreFlusher.access$900(MemStoreFlusher.java:75)
    org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushHandler.run(MemStoreFlusher.java:259)
    java.lang.Thread.run(Thread.java:745)
Thread 137 (MemStoreFlusher.0):
  State: WAITING
  Blocked count: 138931
  Waited count: 237448
  Waiting on java.util.concurrent.CountDownLatch$Sync@53f41f76
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
    java.util.concurrent.CountDownLatch.await(CountDownLatch.java:231)
    org.apache.hadoop.hbase.wal.WALKey.getSequenceId(WALKey.java:305)
    org.apache.hadoop.hbase.regionserver.HRegion.getNextSequenceId(HRegion.java:2422)
    org.apache.hadoop.hbase.regionserver.HRegion.internalPrepareFlushCache(HRegion.java:2168)
    org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2047)
    org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2011)
    org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:1902)
    org.apache.hadoop.hbase.regionserver.HRegion.flush(HRegion.java:1828)
    org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:510)
    org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:471)
    org.apache.hadoop.hbase.regionserver.MemStoreFlusher.access$900(MemStoreFlusher.java:75)
    org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushHandler.run(MemStoreFlusher.java:259)
    java.lang.Thread.run(Thread.java:745)</description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.wal.WALKey.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">14317</link>
		</links>
	</bug>
	<bug id="14076" opendate="2015-07-14 18:39:14" fixdate="2015-07-17 16:27:13" resolution="Fixed">
		<buginformation>
			<summary>ResultSerialization and MutationSerialization can throw InvalidProtocolBufferException when serializing a cell larger than 64MB</summary>
			<description>This was reported in CRUNCH-534 but is a problem how we handle deserialization of large Cells (&amp;gt; 64MB) in ResultSerialization and MutationSerialization.
The fix is just re-using what it was done in HBASE-13230.</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, hbase-11339</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.MutationSerialization.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.ResultSerialization.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">534</link>
		</links>
	</bug>
	<bug id="14106" opendate="2015-07-16 17:13:28" fixdate="2015-07-17 17:42:29" resolution="Fixed">
		<buginformation>
			<summary>TestProcedureRecovery is flaky</summary>
			<description>Encountered this when running master tests locally using 7u79:

Tests run: 8, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 12.28 sec &amp;lt;&amp;lt;&amp;lt; FAILURE! - in org.apache.hadoop.hbase.procedure2.TestProcedureRecovery
testRunningProcWithSameNonce(org.apache.hadoop.hbase.procedure2.TestProcedureRecovery)  Time elapsed: 0.318 sec  &amp;lt;&amp;lt;&amp;lt; ERROR!
java.lang.IllegalArgumentException: null
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:76)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.submitProcedure(ProcedureExecutor.java:595)
	at org.apache.hadoop.hbase.procedure2.ProcedureTestingUtility.submitAndWait(ProcedureTestingUtility.java:137)
	at org.apache.hadoop.hbase.procedure2.TestProcedureRecovery.testRunningProcWithSameNonce(TestProcedureRecovery.java:321)



Flaked tests: 
org.apache.hadoop.hbase.procedure2.TestProcedureRecovery.testRunningProcWithSameNonce(org.apache.hadoop.hbase.procedure2.TestProcedureRecovery)
  Run 1: TestProcedureRecovery.testRunningProcWithSameNonce:321  IllegalArgument
  Run 2: PASS

</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.procedure2.TestProcedureRecovery.java</file>
		</fixedFiles>
	</bug>
	<bug id="9472" opendate="2013-09-09 17:35:04" fixdate="2015-07-21 17:29:42" resolution="Duplicate">
		<buginformation>
			<summary>If the memstore size is under .1 or greater than .9 the memstore size defaults to the default memstore size</summary>
			<description>In HbaseConfiguration.checkForClusterFreeMemoryLimit it does a check to see if the blockCache + memstore &amp;gt; .8 this threshold ensures we do not run out of memory.
But MemStoreFlusher.getMemStoreLimit does this check:


if (limit &amp;gt;= 0.9f || limit &amp;lt; 0.1f) {
      LOG.warn("Setting global memstore limit to default of " + defaultLimit +
        " because supplied value outside allowed range of 0.1 -&amp;gt; 0.9");
      effectiveLimit = defaultLimit;
    }


In our cluster we had the block cache set to an upper limit of 0.76 and the memstore upper limit was set to 0.04.  We noticed the memstore size was exceeding the limit we had set and after looking at the getMemStoreLimit code it seems that the memstore upper limit is sized to the default value if the configuration value is less than .1 or greater than .9.  This now makes the block cache and memstore greater than our available heap.
We can remove the check for the greater than 90% of the heap as this can never happen due to the check in HbaseConfiguration.checkForClusterFreeMemoryLimit()
This check doesn&amp;amp;apos;t seem necessary anymore as we have the HbaseConfiguration class checking for the cluster free limit.  Am I correct in this assumption?
</description>
			<version>0.94.5</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.util.HeapMemorySizeUtil.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">12897</link>
		</links>
	</bug>
	<bug id="14115" opendate="2015-07-17 07:52:25" fixdate="2015-07-22 13:01:42" resolution="Fixed">
		<buginformation>
			<summary>Fix resource leak in HMasterCommandLine</summary>
			<description>In HMasterCommandLine#stopMaster(), admin is not closed.
HMasterCommandLine.java

try (Connection connection = ConnectionFactory.createConnection(conf)) {
      try (Admin admin = connection.getAdmin()) {
        connection.getAdmin().shutdown();
      } catch (Throwable t) {
        LOG.error("Failed to stop master", t);
        return 1;
      }
    }

</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.HMasterCommandLine.java</file>
		</fixedFiles>
	</bug>
	<bug id="14146" opendate="2015-07-22 21:26:36" fixdate="2015-07-23 23:13:06" resolution="Fixed">
		<buginformation>
			<summary>Once replication sees an error it slows down forever</summary>
			<description>sleepMultiplier inside of HBaseInterClusterReplicationEndpoint and ReplicationSource never gets reset to zero.</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 0.98.14, 1.0.2, 1.2.0, 1.1.2, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
		</fixedFiles>
	</bug>
	<bug id="14156" opendate="2015-07-26 16:20:32" fixdate="2015-07-27 10:32:38" resolution="Fixed">
		<buginformation>
			<summary>Fix test failure in TestOpenTableInCoprocessor</summary>
			<description>This is after HBASE-12295 went in</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
		</fixedFiles>
	</bug>
	<bug id="14024" opendate="2015-07-04 18:44:00" fixdate="2015-07-28 18:53:25" resolution="Fixed">
		<buginformation>
			<summary>ImportTsv is not loading hbase-default.xml</summary>
			<description>ImportTsv job is failing with below exception

Exception in thread "main" java.lang.IllegalArgumentException: Can not create a Path from a null string
	at org.apache.hadoop.fs.Path.checkPathArg(Path.java:123)
	at org.apache.hadoop.fs.Path.&amp;lt;init&amp;gt;(Path.java:135)
	at org.apache.hadoop.fs.Path.&amp;lt;init&amp;gt;(Path.java:89)
	at org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2.configurePartitioner(HFileOutputFormat2.java:591)
	at org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2.configureIncrementalLoad(HFileOutputFormat2.java:441)
	at org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2.configureIncrementalLoad(HFileOutputFormat2.java:406)
	at org.apache.hadoop.hbase.mapreduce.ImportTsv.createSubmittableJob(ImportTsv.java:555)
	at org.apache.hadoop.hbase.mapreduce.ImportTsv.run(ImportTsv.java:763)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.hadoop.hbase.mapreduce.ImportTsv.main(ImportTsv.java:772)


hbase.fs.tmp.dir is set to a default value in hbase-default.xml. 
I found that hbase configuration resources from its xml are not loaded into conf object.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.IndexBuilder.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.ImportTsv.java</file>
		</fixedFiles>
		<links>
			<link type="Regression" description="is broken by">13728</link>
		</links>
	</bug>
	<bug id="14153" opendate="2015-07-23 23:41:09" fixdate="2015-07-29 22:50:38" resolution="Fixed">
		<buginformation>
			<summary>Typo in ProcedureManagerHost.MASTER_PROCEUDRE_CONF_KEY</summary>
			<description>The constant should read PROCE DU RE.</description>
			<version>1.0.1</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.procedure.ProcedureManagerHost.java</file>
			<file type="M">org.apache.hadoop.hbase.procedure.TestProcedureManager.java</file>
			<file type="M">org.apache.hadoop.hbase.procedure.MasterProcedureManagerHost.java</file>
		</fixedFiles>
	</bug>
	<bug id="14155" opendate="2015-07-25 18:14:42" fixdate="2015-07-30 01:47:20" resolution="Fixed">
		<buginformation>
			<summary>StackOverflowError in reverse scan</summary>
			<description>A stack overflow may occur when a reverse scan is done. To reproduce (on a Mac), use the following steps:

Download the Phoenix 4.5.0 RC here: https://dist.apache.org/repos/dist/dev/phoenix/phoenix-4.5.0-HBase-1.1-rc0/bin/
Copy the phoenix-4.5.0-HBase-1.1-server.jar into the HBase lib directory (removing any earlier Phoenix version if there was one installed)
Stop and restart HBase
From the bin directory of the Phoenix binary distribution, start sqlline like this: ./sqlline.py localhost
Create a new table and populate it like this:


create table desctest (k varchar primary key desc);
upsert into desctest values (&amp;amp;apos;a&amp;amp;apos;);
upsert into desctest values (&amp;amp;apos;ab&amp;amp;apos;);
upsert into desctest values (&amp;amp;apos;b&amp;amp;apos;);


Note that the following query works fine at this point:


select * from desctest order by k;
+------------------------------------------+
|                    K                     |
+------------------------------------------+
| a                                        |
| ab                                       |
| b                                        |
+------------------------------------------+


Stop and start HBase
Rerun the above query again and you&amp;amp;apos;ll get  a StackOverflowError at StoreFileScanner.seekToPreviousRow()


select * from desctest order by k;
java.lang.RuntimeException: org.apache.phoenix.exception.PhoenixIOException: org.apache.phoenix.exception.PhoenixIOException: org.apache.hadoop.hbase.DoNotRetryIOException: DESCTEST,,1437847235264.a74d70e6a8b36e24d1ea1a70edb0cdf7.: null
	at org.apache.phoenix.util.ServerUtil.createIOException(ServerUtil.java:84)
	at org.apache.phoenix.util.ServerUtil.throwIOException(ServerUtil.java:52)
	at org.apache.phoenix.coprocessor.BaseScannerRegionObserver$2.nextRaw(BaseScannerRegionObserver.java:352)
	at org.apache.phoenix.coprocessor.DelegateRegionScanner.nextRaw(DelegateRegionScanner.java:77)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.scan(RSRpcServices.java:2393)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:32205)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2112)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:101)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.StackOverflowError
	at org.apache.hadoop.hbase.io.hfile.ChecksumUtil.numChunks(ChecksumUtil.java:201)
	at org.apache.hadoop.hbase.io.hfile.ChecksumUtil.numBytes(ChecksumUtil.java:189)
	at org.apache.hadoop.hbase.io.hfile.HFileBlock.totalChecksumBytes(HFileBlock.java:1826)
	at org.apache.hadoop.hbase.io.hfile.HFileBlock.getBufferReadOnly(HFileBlock.java:356)
	at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$EncodedScannerV2.getEncodedBuffer(HFileReaderV2.java:1211)
	at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$EncodedScannerV2.getFirstKeyInBlock(HFileReaderV2.java:1307)
	at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.seekBefore(HFileReaderV2.java:657)
	at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.seekBefore(HFileReaderV2.java:646)
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekToPreviousRow(StoreFileScanner.java:425)
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekToPreviousRow(StoreFileScanner.java:449)
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekToPreviousRow(StoreFileScanner.java:449)
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekToPreviousRow(StoreFileScanner.java:449)



I&amp;amp;apos;ve attempted to reproduce this in a standalone HBase unit test, but have not been able to (but I&amp;amp;apos;ll attach my attempt which mimics what Phoenix is doing).</description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0, 1.0.2, 1.2.0, 1.1.2, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.encoding.BufferedDataBlockEncoder.java</file>
		</fixedFiles>
	</bug>
	<bug id="14178" opendate="2015-08-02 07:51:58" fixdate="2015-08-06 09:22:39" resolution="Fixed">
		<buginformation>
			<summary>regionserver blocks because of waiting for offsetLock</summary>
			<description>My regionserver blocks, and all client rpc timeout. 
I print the regionserver&amp;amp;apos;s jstack,  it seems a lot of threads were blocked for waiting offsetLock, detail infomation belows:
PS:  my table&amp;amp;apos;s block cache is off


"B.DefaultRpcServer.handler=2,queue=2,port=60020" #82 daemon prio=5 os_prio=0 tid=0x0000000001827000 nid=0x2cdc in Object.wait() [0x00007f3831b72000]
   java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.hadoop.hbase.util.IdLock.getLockEntry(IdLock.java:79)
        - locked &amp;lt;0x0000000773af7c18&amp;gt; (a org.apache.hadoop.hbase.util.IdLock$Entry)
        at org.apache.hadoop.hbase.io.hfile.HFileReaderV2.readBlock(HFileReaderV2.java:352)
        at org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexReader.loadDataBlockWithScanInfo(HFileBlockIndex.java:253)
        at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.seekTo(HFileReaderV2.java:524)
        at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.reseekTo(HFileReaderV2.java:572)
        at org.apache.hadoop.hbase.regionserver.StoreFileScanner.reseekAtOrAfter(StoreFileScanner.java:257)
        at org.apache.hadoop.hbase.regionserver.StoreFileScanner.reseek(StoreFileScanner.java:173)
        at org.apache.hadoop.hbase.regionserver.NonLazyKeyValueScanner.doRealSeek(NonLazyKeyValueScanner.java:55)
        at org.apache.hadoop.hbase.regionserver.KeyValueHeap.generalizedSeek(KeyValueHeap.java:313)
        at org.apache.hadoop.hbase.regionserver.KeyValueHeap.requestSeek(KeyValueHeap.java:269)
        at org.apache.hadoop.hbase.regionserver.StoreScanner.reseek(StoreScanner.java:695)
        at org.apache.hadoop.hbase.regionserver.StoreScanner.seekAsDirection(StoreScanner.java:683)
        at org.apache.hadoop.hbase.regionserver.StoreScanner.next(StoreScanner.java:533)
        at org.apache.hadoop.hbase.regionserver.KeyValueHeap.next(KeyValueHeap.java:140)
        at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.populateResult(HRegion.java:3889)
        at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.nextInternal(HRegion.java:3969)
        at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.nextRaw(HRegion.java:3847)
        at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.next(HRegion.java:3820)
        - locked &amp;lt;0x00000005e5c55ad0&amp;gt; (a org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl)
        at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.next(HRegion.java:3807)
        at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:4779)
        at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:4753)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.get(HRegionServer.java:2916)
        at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:29583)
        at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2027)
        at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:108)
        at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:114)
        at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:94)
        at java.lang.Thread.run(Thread.java:745)

   Locked ownable synchronizers:
        - &amp;lt;0x00000005e5c55c08&amp;gt; (a java.util.concurrent.locks.ReentrantLock$NonfairSync)


</description>
			<version>0.98.6</version>
			<fixedVersion>2.0.0, 0.98.14, 1.0.2, 1.2.0, 1.1.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFileReaderImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.CacheConfig.java</file>
		</fixedFiles>
	</bug>
	<bug id="13865" opendate="2015-06-08 19:56:54" fixdate="2015-08-06 18:18:41" resolution="Fixed">
		<buginformation>
			<summary>Increase the default value for hbase.hregion.memstore.block.multipler from 2 to 4 (part 2)</summary>
			<description>Its 4 in the book and 2 in a current master. </description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0, 0.98.14, 1.0.2, 1.2.0, 1.1.2, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestMajorCompaction.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestMinorCompaction.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestClientPushback.java</file>
			<file type="M">org.apache.hadoop.hbase.HConstants.java</file>
		</fixedFiles>
	</bug>
	<bug id="13825" opendate="2015-06-02 13:48:26" fixdate="2015-08-07 16:14:02" resolution="Fixed">
		<buginformation>
			<summary>Use ProtobufUtil#mergeFrom and ProtobufUtil#mergeDelimitedFrom in place of builder methods of same name</summary>
			<description>When performing a get operation on a column family with more than 64MB of data, the operation fails with:
Caused by: Portable(java.io.IOException): Call to host:port failed on local exception: com.google.protobuf.InvalidProtocolBufferException: Protocol message was too large.  May be malicious.  Use CodedInputStream.setSizeLimit() to increase the size limit.
        at org.apache.hadoop.hbase.ipc.RpcClient.wrapException(RpcClient.java:1481)
        at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1453)
        at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1653)
        at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1711)
        at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.get(ClientProtos.java:27308)
        at org.apache.hadoop.hbase.protobuf.ProtobufUtil.get(ProtobufUtil.java:1381)
        at org.apache.hadoop.hbase.client.HTable$3.call(HTable.java:753)
        at org.apache.hadoop.hbase.client.HTable$3.call(HTable.java:751)
        at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:120)
        at org.apache.hadoop.hbase.client.HTable.get(HTable.java:756)
        at org.apache.hadoop.hbase.client.HTable.get(HTable.java:765)
        at org.apache.hadoop.hbase.client.HTablePool$PooledHTable.get(HTablePool.java:395)
This may be related to https://issues.apache.org/jira/browse/HBASE-11747 but that issue is related to cluster status. 
Scan and put operations on the same data work fine
Tested on a 1.0.0 cluster with both 1.0.1 and 1.0.0 clients.
</description>
			<version>1.0.0</version>
			<fixedVersion>2.0.0, 0.98.14, 1.0.2, 1.2.0, 1.1.2, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.rest.model.ScannerModel.java</file>
			<file type="M">org.apache.hadoop.hbase.HTableDescriptor.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.model.CellModel.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.ReplicationPeersZKImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.MasterCoprocessorRpcChannel.java</file>
			<file type="M">org.apache.hadoop.hbase.ClusterId.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.model.TableInfoModel.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.model.TableSchemaModel.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
			<file type="M">org.apache.hadoop.hbase.HColumnDescriptor.java</file>
			<file type="M">org.apache.hadoop.hbase.util.ZKDataMigrator.java</file>
			<file type="M">org.apache.hadoop.hbase.security.access.AccessController.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.model.StorageClusterStatusModel.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.model.CellSetModel.java</file>
			<file type="M">org.apache.hadoop.hbase.types.PBCell.java</file>
			<file type="M">org.apache.hadoop.hbase.zookeeper.RegionServerTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.security.access.AccessControlLists.java</file>
			<file type="M">org.apache.hadoop.hbase.util.FSUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.security.token.AuthenticationTokenIdentifier.java</file>
			<file type="M">org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.RegionServerCoprocessorRpcChannel.java</file>
			<file type="M">org.apache.hadoop.hbase.security.visibility.VisibilityUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader.java</file>
			<file type="M">org.apache.hadoop.hbase.security.access.HbaseObjectWritableFor96Migration.java</file>
			<file type="M">org.apache.hadoop.hbase.TableDescriptor.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.ReplicationPeerZKImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.zookeeper.LoadBalancerTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.HRegionInfo.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TableLockManager.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.RpcServer.java</file>
			<file type="M">org.apache.hadoop.hbase.SplitLogTask.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.model.VersionModel.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.model.TableListModel.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.RegionCoprocessorRpcChannel.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">11747</link>
			<link type="Reference" description="is related to">11747</link>
		</links>
	</bug>
	<bug id="14092" opendate="2015-07-15 18:25:35" fixdate="2015-08-10 18:18:06" resolution="Fixed">
		<buginformation>
			<summary>hbck should run without locks by default and only disable the balancer when necessary</summary>
			<description>HBCK is sometimes used as a way to check the health of the cluster. When doing that it&amp;amp;apos;s not necessary to turn off the balancer. As such it&amp;amp;apos;s not needed to lock other runs of hbck out.
We should add the --no-lock and --no-balancer command line flags.</description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.HBaseFsck.java</file>
		</fixedFiles>
	</bug>
	<bug id="14206" opendate="2015-08-11 09:28:18" fixdate="2015-08-11 17:09:10" resolution="Fixed">
		<buginformation>
			<summary>MultiRowRangeFilter returns records whose rowKeys are out of allowed ranges</summary>
			<description>I haven&amp;amp;apos;t found a way to attach test program to JIRA issue, so put it below :


public class MultiRowRangeFilterTest {
 
    byte[] key1Start = new byte[] {-3};
    byte[] key1End  = new byte[] {-2};

    byte[] key2Start = new byte[] {5};
    byte[] key2End  = new byte[] {6};

    byte[] badKey = new byte[] {-10};

    @Test
    public void testRanges() throws IOException {
        MultiRowRangeFilter filter = new MultiRowRangeFilter(Arrays.asList(
                new MultiRowRangeFilter.RowRange(key1Start, true, key1End, false),
                new MultiRowRangeFilter.RowRange(key2Start, true, key2End, false)
        ));
        filter.filterRowKey(badKey, 0, 1);
        /*
        * FAILS -- includes BAD key!
        * Expected :SEEK_NEXT_USING_HINT
        * Actual   :INCLUDE
        * */
        assertEquals(Filter.ReturnCode.SEEK_NEXT_USING_HINT, filter.filterKeyValue(null));
    }
}


It seems to happen on 2.0.0-SNAPSHOT too, but I wasn&amp;amp;apos;t able to link one with included class.
I have played some time with algorithm, and found that quick fix may be applied to "getNextRangeIndex(byte[] rowKey)" method (hbase-client:1.1.0) :


if (insertionPosition == 0 &amp;amp;&amp;amp; !rangeList.get(insertionPosition).contains(rowKey)) {
        return ROW_BEFORE_FIRST_RANGE;
}
// FIX START
if(!this.initialized) {
    this.initialized = true;
}
// FIX END
return insertionPosition;


Thanks, hope it will help.</description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.1.2, 1.3.0, 0.98.21</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.filter.MultiRowRangeFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.TestMultiRowRangeFilter.java</file>
		</fixedFiles>
	</bug>
	<bug id="14208" opendate="2015-08-11 14:58:49" fixdate="2015-08-11 20:00:58" resolution="Fixed">
		<buginformation>
			<summary>Remove yarn dependencies on -common and -client</summary>
			<description>They aren&amp;amp;apos;t really needed since MR can&amp;amp;apos;t be used without server.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="D">org.apache.hadoop.hbase.security.token.TokenUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.security.User.java</file>
		</fixedFiles>
	</bug>
	<bug id="14201" opendate="2015-08-10 18:16:17" fixdate="2015-08-12 19:02:08" resolution="Fixed">
		<buginformation>
			<summary>hbck should not take a lock unless fixing errors</summary>
			<description>By default, hbck is run in a read-only checker mode. In this case, it is
sensible to let others run. By default, the balancer is left alone,
which may cause spurious errors, but cannot leave the balancer in a bad
state. It is dangerous to leave the balancer by accident, so it is only
ever enabled after fixing, it will never be forced off because of
racing.
When hbck is run in fixer mode, it must take an exclusive lock and
disable the balancer, or all havoc will break loose.
If you want to stop hbck from running in parallel, the -exclusive flag
will create the lock file. If you want to force -disableBalancer, that
option is available too. This makes more semantic sense than -noLock and
-noSwitchBalancer, respectively.
This task is related to HBASE-14092.</description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.hbck.HbckTestingUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestHBaseFsck.java</file>
			<file type="M">org.apache.hadoop.hbase.util.HBaseFsck.java</file>
		</fixedFiles>
	</bug>
	<bug id="14209" opendate="2015-08-11 16:54:03" fixdate="2015-08-12 20:25:56" resolution="Fixed">
		<buginformation>
			<summary>TestShell visibility tests failing</summary>
			<description>This is after HBASE-14105  but we&amp;amp;apos;ve seen this earlier where adding ruby units to the shell tests can cause the visibility tests to fail inexplicably. We can&amp;amp;apos;t just avoid adding ruby units to TestShell in 0.98 so figure out the root cause and fix or disable these. 

  1) Error:
test_The_get/put_methods_should_work_for_data_written_with_Visibility(Hbase::VisibilityLabelsAdminMethodsTest):
NativeException: junit.framework.AssertionFailedError: Waiting timed out after [10,000] msec
    junit/framework/Assert.java:57:in `fail&amp;amp;apos;
    org/apache/hadoop/hbase/Waiter.java:193:in `waitFor&amp;amp;apos;
    org/apache/hadoop/hbase/Waiter.java:128:in `waitFor&amp;amp;apos;
    org/apache/hadoop/hbase/HBaseTestingUtility.java:3514:in `waitFor&amp;amp;apos;
    org/apache/hadoop/hbase/HBaseTestingUtility.java:3576:in `waitLabelAvailable&amp;amp;apos;
    ./src/test/ruby/hbase/visibility_labels_admin_test.rb:73:in `test_The_get/put_methods_should_work_for_data_written_with_Visibility&amp;amp;apos;
    org/jruby/RubyProc.java:270:in `call&amp;amp;apos;
    org/jruby/RubyKernel.java:2105:in `send&amp;amp;apos;
    org/jruby/RubyArray.java:1620:in `each&amp;amp;apos;
    org/jruby/RubyArray.java:1620:in `each&amp;amp;apos;

  2) Error:
test_The_set/clear_methods_should_work_with_authorizations(Hbase::VisibilityLabelsAdminMethodsTest):
NativeException: junit.framework.AssertionFailedError: Waiting timed out after [10,000] msec
    junit/framework/Assert.java:57:in `fail&amp;amp;apos;
    org/apache/hadoop/hbase/Waiter.java:193:in `waitFor&amp;amp;apos;
    org/apache/hadoop/hbase/Waiter.java:128:in `waitFor&amp;amp;apos;
    org/apache/hadoop/hbase/HBaseTestingUtility.java:3514:in `waitFor&amp;amp;apos;
    org/apache/hadoop/hbase/HBaseTestingUtility.java:3576:in `waitLabelAvailable&amp;amp;apos;
    ./src/test/ruby/hbase/visibility_labels_admin_test.rb:52:in `test_The_set/clear_methods_should_work_with_authorizations&amp;amp;apos;
    org/jruby/RubyProc.java:270:in `call&amp;amp;apos;
    org/jruby/RubyKernel.java:2105:in `send&amp;amp;apos;
    org/jruby/RubyArray.java:1620:in `each&amp;amp;apos;
    org/jruby/RubyArray.java:1620:in `each&amp;amp;apos;

</description>
			<version>0.98.14</version>
			<fixedVersion>2.0.0, 0.98.14, 1.0.2, 1.2.0, 1.1.2, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.security.visibility.VisibilityLabelsCache.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">14105</link>
		</links>
	</bug>
	<bug id="14196" opendate="2015-08-07 18:29:00" fixdate="2015-08-13 00:39:54" resolution="Fixed">
		<buginformation>
			<summary>Thrift server idle connection timeout issue</summary>
			<description>When idle connection get cleaned from Thrift server, underlying table instances are still cached in a thread local cache.
This is the antipattern. Table objects are lightweight and should not be cached, besides this, underlying connections can be closed by periodic connection cleaner chore (ConnectionCache) and cached table instances may become invalid. This is Thrift1 specific issue. Thrift2 is OK.</description>
			<version>0.98.13</version>
			<fixedVersion>2.0.0, 0.98.14, 1.0.2, 1.2.0, 1.1.2, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.thrift.IncrementCoalescer.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">14195</link>
		</links>
	</bug>
	<bug id="14098" opendate="2015-07-16 08:44:02" fixdate="2015-08-13 02:48:41" resolution="Fixed">
		<buginformation>
			<summary>Allow dropping caches behind compactions</summary>
			<description></description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.hfile.TestCacheOnWrite.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestStripeCompactor.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactor.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFile.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFileInfo.java</file>
			<file type="M">org.apache.hadoop.hbase.io.FSDataInputStreamWrapper.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StripeStoreFlusher.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.compactions.Compactor.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.compactions.TestStripeCompactionPolicy.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.compactions.StripeCompactor.java</file>
			<file type="M">org.apache.hadoop.hbase.mob.DefaultMobStoreCompactor.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestReversibleScanners.java</file>
			<file type="M">org.apache.hadoop.hbase.mob.MobFile.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestMobStoreCompaction.java</file>
			<file type="M">org.apache.hadoop.hbase.mob.compactions.PartitionedMobCompactor.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.CacheConfig.java</file>
			<file type="M">org.apache.hadoop.hbase.mob.compactions.TestPartitionedMobCompactor.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestFSErrorsExposed.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">10052</link>
			<link type="Reference" description="is related to">14404</link>
			<link type="dependent" description="depends upon">4817</link>
		</links>
	</bug>
	<bug id="14054" opendate="2015-07-10 00:09:21" fixdate="2015-08-13 09:06:40" resolution="Fixed">
		<buginformation>
			<summary>Acknowledged writes may get lost if regionserver clock is set backwards</summary>
			<description>We experience a small amount of lost acknowledged writes in production on July 1st (~700 identified so far).
What happened was that we had NTP turned off since June 29th to prevent issues due to the leap second on June 30th. NTP was turned back on July 1st.
The next day, we noticed we were missing writes to a few of our higher throughput aggregation tables.
We found that this is caused by HBase taking the current time using System.currentTimeMillis, which may be set backwards by NTP, and using this without any checks to populate the timestamp of rows for which the client didn&amp;amp;apos;t supply a timestamp.
Our application uses a read-modify-write pattern using get+checkAndPut to perform aggregation as follows:
1. read version 1
2. mutate
3. write version 2
4. read version 2
5. mutate
6. write version 3
The application retries the full read-modify-write if the checkAndPut fails.
What must have happened on July 1st, after we started NTP back up, was this (timestamps added):
1. read version 1 (timestamp 10)
2. mutate
3. write version 2 (HBase-assigned timestamp 11)
4. read version 2 (timestamp 11)
5. mutate
6. write version 3 (HBase-assigned timestamp 10)
Hence, the last write was eclipsed by the first write, and hence, an acknowledged write was lost.
While this seems to match documented behavior (paraphrasing: "if timestamp is not specified HBase will assign a timestamp using System.currentTimeMillis" "the row with the highest timestamp will be returned by get"), I think it is very unintuitive and needs at least a big warning in the documentation, along the lines of "Acknowledged writes may not be visible unless the timestamp is explicitly specified and equal to or larger than the highest timestamp for that row".
I would also like to use this ticket to start a discussion on if we can make the behavior better:
Could HBase assign a timestamp of max(max timestamp for the row, System.currentTimeMillis()) in the checkAndPut write path, instead of blindly taking System.currentTimeMillis(), similar to what has been done in HBASE-12449 for increment and append?
Thoughts?</description>
			<version>0.98.6</version>
			<fixedVersion>2.0.0, 0.98.14, 1.0.2, 1.2.0, 1.1.2, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">14070</link>
		</links>
	</bug>
	<bug id="13706" opendate="2015-05-18 17:21:52" fixdate="2015-08-13 18:40:39" resolution="Fixed">
		<buginformation>
			<summary>CoprocessorClassLoader should not exempt Hive classes</summary>
			<description>CoprocessorClassLoader is used to load classes from the coprocessor jar.
Certain classes are exempt from being loaded by this ClassLoader, which means they will be ignored in the coprocessor jar, but loaded from parent classpath instead.
One problem is that we categorically exempt "org.apache.hadoop".
But it happens that Hive packages start with "org.apache.hadoop".
There is no reason to exclude hive classes from theCoprocessorClassLoader.
HBase does not even include Hive jars.</description>
			<version>0.98.12</version>
			<fixedVersion>2.0.0, 0.98.14, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.CoprocessorClassLoader.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">5070</link>
			<link type="Reference" description="relates to">15686</link>
		</links>
	</bug>
	<bug id="14166" opendate="2015-07-29 21:01:37" fixdate="2015-08-17 18:23:16" resolution="Fixed">
		<buginformation>
			<summary>Per-Region metrics can be stale</summary>
			<description>We&amp;amp;apos;re seeing some machines that are reporting only old region metrics. It seems like at some point the Hadoop metrics system decided which metrics to display and which not to. From then on it was not changing.</description>
			<version>1.1.0.1</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.metrics2.lib.DynamicMetricsRegistry.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegionAggregateSourceImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegionAggregateSource.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegionSourceImpl.java</file>
			<file type="M">org.apache.hadoop.metrics2.impl.JmxCacheBuster.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegionWrapper.java</file>
			<file type="M">org.apache.hadoop.metrics2.lib.MetricsExecutorImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestMetricsRegionSourceImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegionWrapperStub.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">14274</link>
		</links>
	</bug>
	<bug id="14228" opendate="2015-08-15 18:29:08" fixdate="2015-08-18 20:51:36" resolution="Fixed">
		<buginformation>
			<summary>Close BufferedMutator and connection in MultiTableOutputFormat</summary>
			<description>Close BufferedMutator and connection in MultiTableRecordWriter of MultiTableOutputFormat.</description>
			<version>1.1.1</version>
			<fixedVersion>2.0.0, 1.0.2, 1.2.0, 1.1.2, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.MultiTableOutputFormat.java</file>
		</fixedFiles>
	</bug>
	<bug id="14241" opendate="2015-08-18 19:20:50" fixdate="2015-08-19 16:02:05" resolution="Fixed">
		<buginformation>
			<summary>Fix deadlock during cluster shutdown due to concurrent connection close</summary>
			<description>Caught while testing branch-1.0, shutting down TestMasterMetricsWrapper.
Found one Java-level deadlock:
=============================
"MASTER_META_SERVER_OPERATIONS-ip-10-32-130-237:55342-0":
  waiting to lock monitor 0x00007f2a040051c8 (object 0x00000007e36108a8, a org.apache.hadoop.hbase.util.PoolMap),
  which is held by "M:0;ip-10-32-130-237:55342"
"M:0;ip-10-32-130-237:55342":
  waiting to lock monitor 0x00007f2a04005118 (object 0x00000007e3610b00, a org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection),
  which is held by "MASTER_META_SERVER_OPERATIONS-ip-10-32-130-237:55342-0"
Full stack dump and deadlock debug output attached.
Root cause:
In RpcClientImpl#close(), we obtain lock on connections first:


    synchronized (connections) {
      for (Connection conn : connections.values()) {


Then markClosed() tries to obtain lock on connection object:


        if (!conn.isAlive()) {
          conn.markClosed(new InterruptedIOException("RpcClient is closing"));
          conn.close();


Another thread, MetaServerShutdownHandler, calls RpcClientImpl$Connection#setupIOstreams() where :


        markClosed(e);
        close();


Lock on connection object is obtained first, then lock on connections is attempted, leading to deadlock:


      synchronized (connections) {
        connections.removeValue(remoteId, this);
      }

</description>
			<version>1.0.2</version>
			<fixedVersion>2.0.0, 1.0.2, 1.2.0, 1.1.2, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.RpcClientImpl.java</file>
		</fixedFiles>
	</bug>
	<bug id="14291" opendate="2015-08-22 04:28:46" fixdate="2015-08-23 01:33:07" resolution="Fixed">
		<buginformation>
			<summary>NPE On StochasticLoadBalancer Balance Involving RS With No Regions</summary>
			<description>When StochasticLoadBalancer attempts to balance a local RS with multiple regions with another local RS that had no regions the HBase shell call of &amp;amp;apos;balancer&amp;amp;apos; gets the following NPE:

ERROR: java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2175)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:106)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster.getLeastLoadedTopServerForRegion(BaseLoadBalancer.java:863)
	at org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer$LocalityBasedCandidateGenerator.generate(StochasticLoadBalancer.java:724)
	at org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.balanceCluster(StochasticLoadBalancer.java:325)
	at org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.balanceCluster(StochasticLoadBalancer.java:263)
	at org.apache.hadoop.hbase.master.HMaster.balance(HMaster.java:1264)
	at org.apache.hadoop.hbase.master.MasterRpcServices.balance(MasterRpcServices.java:413)
	at org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MasterService$2.callBlockingMethod(MasterProtos.java:52450)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2133)
	... 4 more


Issue only occurs when one of the RSs has no regions before balancing.  Also, unsure if distributed RSs would also have same issue.  Attached &amp;amp;apos;hbase-mwarhaftig-master-Matts-MBP.log&amp;amp;apos; is master&amp;amp;apos;s log of the error occurring.  
SimpleLoadBalancer rebalances correctly when used in the same situation.  </description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">14653</link>
		</links>
	</bug>
	<bug id="14224" opendate="2015-08-14 15:03:46" fixdate="2015-08-24 21:21:38" resolution="Fixed">
		<buginformation>
			<summary>Fix coprocessor handling of duplicate classes</summary>
			<description>While discussing with Misty Stanley-Jones over on HBASE-13907 we noticed some inconsistency when copros are loaded. Sometimes you can load them more than once, sometimes you can not. Need to consolidate.</description>
			<version>1.0.1</version>
			<fixedVersion>2.0.0, 1.0.2, 1.2.0, 1.3.0, 0.98.15, 1.1.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.TestHTableDescriptor.java</file>
			<file type="M">org.apache.hadoop.hbase.HTableDescriptor.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.CoprocessorHost.java</file>
			<file type="M">org.apache.hadoop.hbase.HConstants.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">13907</link>
		</links>
	</bug>
	<bug id="14078" opendate="2015-07-14 21:22:53" fixdate="2015-08-26 16:19:38" resolution="Fixed">
		<buginformation>
			<summary>improve error message when HMaster can&amp;apos;t bind to port</summary>
			<description>When the master fails to start becahse hbase.master.port is already taken, the log messages could make it easier to tell.

2015-07-14 13:10:02,667 INFO  [main] regionserver.RSRpcServices: master/master01.example.com/10.20.188.121:16000 server-side HConnection retries=350
2015-07-14 13:10:02,879 INFO  [main] ipc.SimpleRpcScheduler: Using deadline as user call queue, count=3
2015-07-14 13:10:02,895 ERROR [main] master.HMasterCommandLine: Master exiting
java.lang.RuntimeException: Failed construction of Master: class org.apache.hadoop.hbase.master.HMaster
        at org.apache.hadoop.hbase.master.HMaster.constructMaster(HMaster.java:2258)
        at org.apache.hadoop.hbase.master.HMasterCommandLine.startMaster(HMasterCommandLine.java:234)
        at org.apache.hadoop.hbase.master.HMasterCommandLine.run(HMasterCommandLine.java:140)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
        at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:126)
        at org.apache.hadoop.hbase.master.HMaster.main(HMaster.java:2272)
Caused by: java.net.BindException: Address already in use
        at sun.nio.ch.Net.bind0(Native Method)
        at sun.nio.ch.Net.bind(Net.java:444)
        at sun.nio.ch.Net.bind(Net.java:436)
        at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
        at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
        at org.apache.hadoop.hbase.ipc.RpcServer.bind(RpcServer.java:2513)
        at org.apache.hadoop.hbase.ipc.RpcServer$Listener.&amp;lt;init&amp;gt;(RpcServer.java:599)
        at org.apache.hadoop.hbase.ipc.RpcServer.&amp;lt;init&amp;gt;(RpcServer.java:2000)
        at org.apache.hadoop.hbase.regionserver.RSRpcServices.&amp;lt;init&amp;gt;(RSRpcServices.java:919)
        at org.apache.hadoop.hbase.master.MasterRpcServices.&amp;lt;init&amp;gt;(MasterRpcServices.java:211)
        at org.apache.hadoop.hbase.master.HMaster.createRpcServices(HMaster.java:509)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.&amp;lt;init&amp;gt;(HRegionServer.java:535)
        at org.apache.hadoop.hbase.master.HMaster.&amp;lt;init&amp;gt;(HMaster.java:351)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
        at org.apache.hadoop.hbase.master.HMaster.constructMaster(HMaster.java:2253)
        ... 5 more
I recognize that the "RSRpcServices" log message shows port 16000, but I don&amp;amp;apos;t know why a new operator would. Additionally, it&amp;amp;apos;d be nice to tell them that the port is controlled by hbase.master.port. Maybe give a hint on how to see what&amp;amp;apos;s using the port. Could be too os-dist specific?</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">14079</link>
		</links>
	</bug>
	<bug id="14313" opendate="2015-08-26 01:12:05" fixdate="2015-08-27 22:27:16" resolution="Fixed">
		<buginformation>
			<summary>After a Connection sees ConnectionClosingException it never recovers</summary>
			<description></description>
			<version>1.1.0.1</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.0.3, 1.1.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.RpcClientImpl.java</file>
		</fixedFiles>
	</bug>
	<bug id="14229" opendate="2015-08-17 04:22:56" fixdate="2015-09-02 21:00:55" resolution="Fixed">
		<buginformation>
			<summary>Flushing canceled by coprocessor still leads to memstoreSize set down</summary>
			<description>A Coprocessor override "public InternalScanner preFlush(final Store store, final InternalScanner scanner)" and return NULL when calling this method, will cancel flush request, leaving snapshot un-flushed, and no new storefile created. But the HRegion.internalFlushCache still set down memstoreSize to 0 by totalFlushableSize. 
If there&amp;amp;apos;s no write requests anymore, the memstoreSize will remaining as 0, and no more flush quests will be processed because of the checking of memstoreSize.get() &amp;lt;=0 at the beginning of internalFlushCache.
This issue may not cause data loss, but it will confuse coprocessor users. If we argree with this, I&amp;amp;apos;ll apply a patch later.</description>
			<version>0.98.13</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 0.98.15, 1.1.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
		</fixedFiles>
	</bug>
	<bug id="14359" opendate="2015-09-03 11:17:39" fixdate="2015-09-04 01:45:43" resolution="Fixed">
		<buginformation>
			<summary>HTable#close will hang forever if unchecked error/exception thrown in AsyncProcess#sendMultiAction</summary>
			<description>Currently in AsyncProcess#sendMultiAction, we only catch the RejectedExecutionException and let other error/exception go, which will cause decTaskCounter not invoked. Meanwhile, the recommendation for using HTable is to close the table in the finally clause, and HTable#close will call flushCommits and wait until all task done.
The problem is when unchecked error/exception like OutOfMemoryError thrown, taskSent will never be equal to taskDone, so AsyncProcess#waitUntilDone will never return. Especially, if autoflush is set thus no data to flush during table close, there would be no rpc call so rpcTimeOut will not break the call, and thread will wait there forever.
In our product env, the unchecked error we observed is "java.lang.OutOfMemoryError: unable to create new native thread", and we observed the client thread hang for hours</description>
			<version>0.98.14</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 0.98.15, 1.0.3, 1.1.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.AsyncProcess.java</file>
		</fixedFiles>
		<links>
			<link type="Container" description="contains">14758</link>
		</links>
	</bug>
	<bug id="14317" opendate="2015-08-26 18:46:09" fixdate="2015-09-07 04:55:24" resolution="Fixed">
		<buginformation>
			<summary>Stuck FSHLog: bad disk (HDFS-8960) and can&amp;apos;t roll WAL</summary>
			<description>hbase-1.1.1 and hadoop-2.7.1
We try to roll logs because can&amp;amp;apos;t append (See HDFS-8960) but we get stuck. See attached thread dump and associated log. What is interesting is that syncers are waiting to take syncs to run and at same time we want to flush so we are waiting on a safe point but there seems to be nothing in our ring buffer; did we go to roll log and not add safe point sync to clear out ringbuffer?
Needs a bit of study. Try to reproduce.</description>
			<version>1.1.1</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestFSErrorsExposed.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.SyncFuture.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestLogRolling.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.LogRoller.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestMultiVersionConcurrencyControl.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl.java</file>
			<file type="M">org.apache.hadoop.hbase.wal.WALKey.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.HLogKey.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.FSWALEntry.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFile.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">13971</link>
			<link type="Reference" description="relates to">16960</link>
			<link type="Reference" description="is related to">8960</link>
		</links>
	</bug>
	<bug id="14384" opendate="2015-09-09 01:01:23" fixdate="2015-09-09 19:44:01" resolution="Fixed">
		<buginformation>
			<summary>Trying to run canary locally with -regionserver option causes exception</summary>
			<description>Tried to run canary locally (on branch master) with command: 
bin/hbase org.apache.hadoop.hbase.tool.Canary -regionserver
Exception was thrown:
Exception in thread "main" java.lang.ClassCastException: org.apache.hadoop.hbase.tool.Canary$StdOutSink cannot be cast to org.apache.hadoop.hbase.tool.Canary$ExtendedSink
	at org.apache.hadoop.hbase.tool.Canary.newMonitor(Canary.java:640)
	at org.apache.hadoop.hbase.tool.Canary.run(Canary.java:551)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.hadoop.hbase.tool.Canary.main(Canary.java:1127)</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.tool.Canary.java</file>
		</fixedFiles>
	</bug>
	<bug id="14377" opendate="2015-09-07 14:42:39" fixdate="2015-09-11 05:35:58" resolution="Fixed">
		<buginformation>
			<summary>JavaHBaseContextSuite not being run</summary>
			<description>we haven&amp;amp;apos;t been running JavaHBaseContextSuite, because it&amp;amp;apos;s Java (so skipped by the ScalaTest framework) and not named according to the surefire naming rules.
rename to TestJavaHBaseContext and categorize it as a Medium test.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="D">org.apache.hadoop.hbase.spark.JavaHBaseContextSuite.java</file>
		</fixedFiles>
	</bug>
	<bug id="6617" opendate="2012-08-20 17:40:27" fixdate="2015-09-11 19:08:54" resolution="Fixed">
		<buginformation>
			<summary>ReplicationSourceManager should be able to track multiple WAL paths</summary>
			<description>Currently ReplicationSourceManager uses logRolled() to receive notification about new HLog and remembers it in latestPath.
When region server has multiple WAL support, we need to keep track of multiple Path&amp;amp;apos;s in ReplicationSourceManager</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.TestReplicationEndpoint.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.MetricsSource.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.LogRoller.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.ReplicationEndpoint.java</file>
			<file type="M">org.apache.hadoop.hbase.wal.DefaultWALProvider.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.TestRegionReplicaReplicationEndpointNoMaster.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.TestReplicationWALReaderManager.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManager.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
			<file type="M">org.apache.hadoop.hbase.wal.WALFactory.java</file>
		</fixedFiles>
		<links>
			<link type="Container" description="Is contained by">14457</link>
			<link type="Duplicate" description="is duplicated by">14699</link>
		</links>
	</bug>
	<bug id="14380" opendate="2015-09-08 12:26:56" fixdate="2015-09-15 14:39:55" resolution="Fixed">
		<buginformation>
			<summary>Correct data gets skipped along with bad data in importTsv bulk load thru TsvImporterTextMapper</summary>
			<description>Cosider the input data is as below 
ROWKEY, TIEMSTAMP, Col_Value
r1,1,v1	&amp;gt;&amp;gt; Correct line
r1	         &amp;gt;&amp;gt; Bad line
r1,3,v3	&amp;gt;&amp;gt; Correct line
r1,4,v4	&amp;gt;&amp;gt; Correct line
When data is bulk loaded using importTsv with mapper as TsvImporterTextMapper ,  All the lines are getting ignored even though skipBadLines is set to true. </description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.0.3, 1.1.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TestImportTsv.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TextSortReducer.java</file>
		</fixedFiles>
	</bug>
	<bug id="14145" opendate="2015-07-22 18:49:32" fixdate="2015-09-15 23:35:53" resolution="Fixed">
		<buginformation>
			<summary>Allow the Canary in regionserver mode to try all regions on the server, not just one</summary>
			<description>We want a pretty in-depth canary that will try every region on a cluster. When doing that for the whole cluster one machine is too slow, so we wanted to split it up and have each regionserver run a canary. That works however the canary does less work as it just tries one random region.
Lets add a flag that will allow the canary to try all regions on a regionserver.</description>
			<version>1.1.0.1</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.tool.Canary.java</file>
		</fixedFiles>
	</bug>
	<bug id="14431" opendate="2015-09-14 17:44:28" fixdate="2015-09-19 14:36:28" resolution="Fixed">
		<buginformation>
			<summary>AsyncRpcClient#removeConnection() never removes connection from connections pool if server fails</summary>
			<description>I was playing with master branch in distributed mode (3 rs + master + backup_master) and notice strange behavior when i was testing this sequence of events on single rs: /kill/start/run_balancer while client was writing data to cluster (LoadTestTool).
I have notice that LTT fails with following:


2015-09-09 11:05:58,364 INFO  [main] client.AsyncProcess: #2, waiting for some tasks to finish. Expected max=0, tasksInProgress=35
Exception in thread "main" org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException: Failed 1 action: BindException: 1 time, 
	at org.apache.hadoop.hbase.client.AsyncProcess$BatchErrors.makeException(AsyncProcess.java:228)
	at org.apache.hadoop.hbase.client.AsyncProcess$BatchErrors.access$1800(AsyncProcess.java:208)
	at org.apache.hadoop.hbase.client.AsyncProcess.waitForAllPreviousOpsAndReset(AsyncProcess.java:1697)
	at org.apache.hadoop.hbase.client.BufferedMutatorImpl.backgroundFlushCommits(BufferedMutatorImpl.java:211)


After some digging  and adding some more logging in code i have notice that following condition in  

AsyncRpcClient.removeConnection(AsyncRpcChannel connection) 

 is never true:


if (connectionInPool == connection) {


causing that  

AsyncRpcChannel

 connection is never removed from 

connections

 pool in case rs fails.
After changing this condition to:


if (connectionInPool.address.equals(connection.address)) {


issue was resolved and client was removing failed server from connections pool.
I will attach patch after running some more tests.</description>
			<version>1.0.2</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.1.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.AsyncRpcClient.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.AsyncRpcChannel.java</file>
		</fixedFiles>
	</bug>
	<bug id="14079" opendate="2015-07-14 22:53:37" fixdate="2015-09-21 22:25:45" resolution="Duplicate">
		<buginformation>
			<summary>improve error message when Master fails to connect to Hadoop-auth</summary>
			<description>Current error message at INFO level doesn&amp;amp;apos;t give any hint about what keytab and principle are in use

2015-07-14 13:32:48,514 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2015-07-14 13:32:48,640 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-07-14 13:32:48,640 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2015-07-14 13:32:48,776 ERROR [main] master.HMasterCommandLine: Master exiting
java.lang.RuntimeException: Failed construction of Master: class org.apache.hadoop.hbase.master.HMaster
        at org.apache.hadoop.hbase.master.HMaster.constructMaster(HMaster.java:2258)
        at org.apache.hadoop.hbase.master.HMasterCommandLine.startMaster(HMasterCommandLine.java:234)
        at org.apache.hadoop.hbase.master.HMasterCommandLine.run(HMasterCommandLine.java:140)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
        at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:126)
        at org.apache.hadoop.hbase.master.HMaster.main(HMaster.java:2272)
Caused by: javax.security.auth.login.LoginException: Unable to obtain password from user
        at com.sun.security.auth.module.Krb5LoginModule.promptForPass(Krb5LoginModule.java:856)
        at com.sun.security.auth.module.Krb5LoginModule.attemptAuthentication(Krb5LoginModule.java:719)
        at com.sun.security.auth.module.Krb5LoginModule.login(Krb5LoginModule.java:584)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at javax.security.auth.login.LoginContext.invoke(LoginContext.java:762)
        at javax.security.auth.login.LoginContext.access$000(LoginContext.java:203)
        at javax.security.auth.login.LoginContext$4.run(LoginContext.java:690)
        at javax.security.auth.login.LoginContext$4.run(LoginContext.java:688)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.login.LoginContext.invokePriv(LoginContext.java:687)
        at javax.security.auth.login.LoginContext.login(LoginContext.java:595)
        at org.apache.hadoop.security.UserGroupInformation.loginUserFromKeytab(UserGroupInformation.java:912)
        at org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:242)
        at org.apache.hadoop.hbase.security.User$SecureHadoopUser.login(User.java:385)
        at org.apache.hadoop.hbase.security.User.login(User.java:252)
        at org.apache.hadoop.hbase.security.UserProvider.login(UserProvider.java:115)
        at org.apache.hadoop.hbase.master.HMaster.login(HMaster.java:464)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.&amp;lt;init&amp;gt;(HRegionServer.java:553)
        at org.apache.hadoop.hbase.master.HMaster.&amp;lt;init&amp;gt;(HMaster.java:351)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
        at org.apache.hadoop.hbase.master.HMaster.constructMaster(HMaster.java:2253)
        ... 5 more
increasing to DEBUG also doesn&amp;amp;apos;t help.</description>
			<version>0.94.0</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">14078</link>
			<link type="Regression" description="is broken by">2692</link>
		</links>
	</bug>
	<bug id="14280" opendate="2015-08-21 12:06:18" fixdate="2015-09-22 16:23:42" resolution="Fixed">
		<buginformation>
			<summary>Bulk Upload from HA cluster to remote HA hbase cluster fails</summary>
			<description>Caused by: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(java.io.IOException): java.io.IOException: Wrong FS: hdfs://ha-aggregation-nameservice1/hbase_upload/82c89692-6e78-46ef-bbea-c9e825318bfe/A/1aaaa31358d641c69d6c34b803c187b0, expected: hdfs://ha-hbase-nameservice1
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2113)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:108)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:114)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:94)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: Wrong FS: hdfs://ha-aggregation-nameservice1/hbase_upload/82c89692-6e78-46ef-bbea-c9e825318bfe/A/1aaaa31358d641c69d6c34b803c187b0, expected: hdfs://ha-hbase-nameservice1
	at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:645)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:193)
	at org.apache.hadoop.hdfs.DistributedFileSystem.access$000(DistributedFileSystem.java:105)
	at org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:1136)
	at org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:1132)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1132)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:414)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1423)
	at org.apache.hadoop.hbase.regionserver.HRegionFileSystem.commitStoreFile(HRegionFileSystem.java:372)
	at org.apache.hadoop.hbase.regionserver.HRegionFileSystem.bulkLoadStoreFile(HRegionFileSystem.java:451)
	at org.apache.hadoop.hbase.regionserver.HStore.bulkLoadHFile(HStore.java:750)
	at org.apache.hadoop.hbase.regionserver.HRegion.bulkLoadHFiles(HRegion.java:4894)
	at org.apache.hadoop.hbase.regionserver.HRegion.bulkLoadHFiles(HRegion.java:4799)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.bulkLoadHFile(HRegionServer.java:3377)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:29996)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2078)
	... 4 more
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1498)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1684)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1737)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.bulkLoadHFile(ClientProtos.java:29276)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.bulkLoadHFile(ProtobufUtil.java:1548)
	... 11 more</description>
			<version>0.98.4</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.1.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.FSHDFSUtils.java</file>
		</fixedFiles>
	</bug>
	<bug id="14445" opendate="2015-09-16 19:04:53" fixdate="2015-09-22 20:13:37" resolution="Fixed">
		<buginformation>
			<summary>ExportSnapshot does not honor -chmod option</summary>
			<description>Create a snapshot of an existing HBase table, export the snapshot using the -chuser, -chgroup, -chmod options.
Look in hdfs filesystem for export. The files do not have the correct ownership, group, permissions
Thanks to Ian Roberts who first reported the issue.</description>
			<version>0.98.4</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.1.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.snapshot.ExportSnapshot.java</file>
		</fixedFiles>
	</bug>
	<bug id="14370" opendate="2015-09-05 16:15:16" fixdate="2015-09-26 01:25:28" resolution="Fixed">
		<buginformation>
			<summary>Use separate thread for calling ZKPermissionWatcher#refreshNodes()</summary>
			<description>I came off a support case (0.98.0) where main zk thread was seen doing the following:


  at org.apache.hadoop.hbase.security.access.ZKPermissionWatcher.refreshAuthManager(ZKPermissionWatcher.java:152)
  at org.apache.hadoop.hbase.security.access.ZKPermissionWatcher.refreshNodes(ZKPermissionWatcher.java:135)
  at org.apache.hadoop.hbase.security.access.ZKPermissionWatcher.nodeChildrenChanged(ZKPermissionWatcher.java:121)
  at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.process(ZooKeeperWatcher.java:348)
  at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:519)
  at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:495)


There were 62000 nodes under /acl due to lack of fix from HBASE-12635, leading to slowness in table creation because zk notification for region offline was blocked by the above.
The attached patch separates refreshNodes() call into its own thread.
Thanks to Enis and Devaraj for offline discussion.</description>
			<version>0.98.0</version>
			<fixedVersion>2.0.0, 1.3.0, 0.98.15</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.security.access.SecureTestUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.security.access.ZKPermissionWatcher.java</file>
			<file type="M">org.apache.hadoop.hbase.security.access.AccessController.java</file>
			<file type="M">org.apache.hadoop.hbase.security.access.TestZKPermissionsWatcher.java</file>
			<file type="M">org.apache.hadoop.hbase.security.access.TestTablePermissions.java</file>
			<file type="M">org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
			<file type="M">org.apache.hadoop.hbase.security.access.TableAuthManager.java</file>
		</fixedFiles>
	</bug>
	<bug id="14473" opendate="2015-09-23 18:57:12" fixdate="2015-09-29 20:55:02" resolution="Fixed">
		<buginformation>
			<summary>Compute region locality in parallel</summary>
			<description>Right now on large clusters it&amp;amp;apos;s necessary to turn off the locality balance cost as it takes too long to compute the region locality. This is because it&amp;amp;apos;s computed when need in serial.
We should compute this in parallel before it&amp;amp;apos;s needed.</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.balancer.RegionLocationFinder.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">16570</link>
			<link type="Reference" description="is related to">16393</link>
		</links>
	</bug>
	<bug id="14362" opendate="2015-09-03 22:29:35" fixdate="2015-09-29 21:54:35" resolution="Fixed">
		<buginformation>
			<summary>org.apache.hadoop.hbase.master.procedure.TestWALProcedureStoreOnHDFS is super duper flaky</summary>
			<description>As seen in Jenkins, this test has been super flaky and we should probably address it.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.1.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.procedure.TestWALProcedureStoreOnHDFS.java</file>
		</fixedFiles>
	</bug>
	<bug id="14510" opendate="2015-09-29 09:02:09" fixdate="2015-09-29 22:38:27" resolution="Fixed">
		<buginformation>
			<summary>Can not set coprocessor from Shell after HBASE-14224</summary>
			<description>I was able to set coprocessors for table by shell normally, but it didn&amp;amp;apos;t worked now.
Here&amp;amp;apos;s the shell output (omit really jar path and coprocessor classname)


HBase Shell; enter &amp;amp;apos;help&amp;lt;RETURN&amp;gt;&amp;amp;apos; for list of supported commands.
Type "exit&amp;lt;RETURN&amp;gt;" to leave the HBase Shell
Version 1.3.0-SNAPSHOT, 642273bc2a5a415eba6f1592a439a6b2b53a70a9, Tue Sep 29 15:58:28 CST 2015

hbase(main):001:0&amp;gt; describe &amp;amp;apos;test&amp;amp;apos;
Table test is ENABLED
test
COLUMN FAMILIES DESCRIPTION
{NAME =&amp;gt; &amp;amp;apos;f&amp;amp;apos;, DATA_BLOCK_ENCODING =&amp;gt; &amp;amp;apos;NONE&amp;amp;apos;, BLOOMFILTER =&amp;gt; &amp;amp;apos;ROW&amp;amp;apos;, REPLICATION_SCOPE =&amp;gt; &amp;amp;apos;0&amp;amp;apos;, VERSIONS =&amp;gt; &amp;amp;apos;1&amp;amp;apos;, COMPRESSION =&amp;gt; &amp;amp;apos;NONE&amp;amp;apos;, MIN_VERSIONS =&amp;gt; &amp;amp;apos;0&amp;amp;apos;, TTL =&amp;gt; &amp;amp;apos;FOREVER&amp;amp;apos;, KEEP_DELETED_CELLS =&amp;gt; &amp;amp;apos;FALSE&amp;amp;apos;, B
LOCKSIZE =&amp;gt; &amp;amp;apos;65536&amp;amp;apos;, IN_MEMORY =&amp;gt; &amp;amp;apos;false&amp;amp;apos;, BLOCKCACHE =&amp;gt; &amp;amp;apos;true&amp;amp;apos;}
1 row(s) in 0.4370 seconds

hbase(main):002:0&amp;gt; alter &amp;amp;apos;test&amp;amp;apos;, &amp;amp;apos;coprocessor&amp;amp;apos;=&amp;gt;&amp;amp;apos;hdfs:///some.jar|com.somepackage.SomeObserver|1001&amp;amp;apos;
Updating all regions with the new schema...
1/1 regions updated.
Done.
0 row(s) in 1.9760 seconds

hbase(main):003:0&amp;gt; describe &amp;amp;apos;test&amp;amp;apos;
Table test is ENABLED
test, {TABLE_ATTRIBUTES =&amp;gt; {coprocessor$1 =&amp;gt; &amp;amp;apos;|hdfs:///some.jar|com.somepackage.SomeObserver|1001|1073741823|&amp;amp;apos;}
COLUMN FAMILIES DESCRIPTION
{NAME =&amp;gt; &amp;amp;apos;f&amp;amp;apos;, DATA_BLOCK_ENCODING =&amp;gt; &amp;amp;apos;NONE&amp;amp;apos;, BLOOMFILTER =&amp;gt; &amp;amp;apos;ROW&amp;amp;apos;, REPLICATION_SCOPE =&amp;gt; &amp;amp;apos;0&amp;amp;apos;, VERSIONS =&amp;gt; &amp;amp;apos;1&amp;amp;apos;, COMPRESSION =&amp;gt; &amp;amp;apos;NONE&amp;amp;apos;, MIN_VERSIONS =&amp;gt; &amp;amp;apos;0&amp;amp;apos;, TTL =&amp;gt; &amp;amp;apos;FOREVER&amp;amp;apos;, KEEP_DELETED_CELLS =&amp;gt; &amp;amp;apos;FALSE&amp;amp;apos;, B
LOCKSIZE =&amp;gt; &amp;amp;apos;65536&amp;amp;apos;, IN_MEMORY =&amp;gt; &amp;amp;apos;false&amp;amp;apos;, BLOCKCACHE =&amp;gt; &amp;amp;apos;true&amp;amp;apos;}
1 row(s) in 0.0180 seconds


I checked the recent commits and found HBASE-14224 is related to. It&amp;amp;apos;s an important improvement, but made a mistake in alter() of admin.rb, line 587. As the value is coprocess spec string but not only class name, here should use htd.setCoprocessorWithSpec instead of htd.setCoprocessor.</description>
			<version>0.98.14</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 0.98.15, 1.0.3, 1.1.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.HTableDescriptor.java</file>
		</fixedFiles>
	</bug>
	<bug id="13770" opendate="2015-05-25 17:10:29" fixdate="2015-10-03 01:14:41" resolution="Fixed">
		<buginformation>
			<summary>Programmatic JAAS configuration option for secure zookeeper may be broken</summary>
			<description>While verifying the patch fix for HBASE-13768 we were unable to successfully test the programmatic JAAS configuration option for secure ZooKeeper integration. Unclear if that was due to a bug or incorrect test configuration.
Update the security section of the online book with clear instructions for setting up the programmatic JAAS configuration option for secure ZooKeeper integration.
Verify it works.
Fix as necessary.</description>
			<version>0.98.13</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 0.98.15, 1.0.3, 1.1.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.HConstants.java</file>
			<file type="M">org.apache.hadoop.hbase.zookeeper.HQuorumPeer.java</file>
			<file type="M">org.apache.hadoop.hbase.zookeeper.ZKUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.zookeeper.TestZooKeeperACL.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMasterCommandLine.java</file>
		</fixedFiles>
	</bug>
	<bug id="14545" opendate="2015-10-02 22:27:27" fixdate="2015-10-03 20:36:13" resolution="Fixed">
		<buginformation>
			<summary>TestMasterFailover often times out</summary>
			<description>Tests run: 7, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 301.644 sec &amp;lt;&amp;lt;&amp;lt; FAILURE! - in org.apache.hadoop.hbase.master.TestMasterFailover
testMasterFailoverWithMockedRIT(org.apache.hadoop.hbase.master.TestMasterFailover)  Time elapsed: 240.112 sec  &amp;lt;&amp;lt;&amp;lt; ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 240000 milliseconds
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hbase.util.Threads.sleep(Threads.java:146)
	at org.apache.hadoop.hbase.MiniHBaseCluster.waitForActiveAndReadyMaster(MiniHBaseCluster.java:535)
	at org.apache.hadoop.hbase.HBaseCluster.waitForActiveAndReadyMaster(HBaseCluster.java:280)
	at org.apache.hadoop.hbase.master.TestMasterFailover.testMasterFailoverWithMockedRIT(TestMasterFailover.java:400)
Results :
Tests in error:
  TestMasterFailover.testMasterFailoverWithMockedRIT:400  TestTimedOut test tim...
Tests run: 7, Failures: 0, Errors: 1, Skipped: 0</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.0.3, 1.1.3, 0.98.16</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.RegionStates.java</file>
			<file type="M">org.apache.hadoop.hbase.LocalHBaseCluster.java</file>
		</fixedFiles>
	</bug>
	<bug id="14367" opendate="2015-09-04 13:15:22" fixdate="2015-10-04 08:34:24" resolution="Fixed">
		<buginformation>
			<summary>Add normalization support to shell</summary>
			<description>https://issues.apache.org/jira/browse/HBASE-13103 adds support for setting a normalization flag per HTableDescriptor, along with the server side chore to do the work.
What is lacking is to easily set this from the shell, right now you need to use the Java API to modify the descriptor. This issue is to add the flag as a known attribute key and/or other means to toggle this per table.</description>
			<version>1.1.2</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
			<file type="M">org.apache.hadoop.hbase.HTableDescriptor.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
			<file type="M">org.apache.hadoop.hbase.zookeeper.TestZooKeeperWatcher.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.MasterProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="M">org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestAdmin2.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
			<file type="M">org.apache.hadoop.hbase.client.Admin.java</file>
			<file type="M">org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">15124</link>
			<link type="Reference" description="is related to">13103</link>
		</links>
	</bug>
	<bug id="14544" opendate="2015-10-02 21:18:38" fixdate="2015-10-05 17:04:21" resolution="Fixed">
		<buginformation>
			<summary>Allow HConnectionImpl to not refresh the dns on errors</summary>
			<description>Some clusters will have static ip addresses and forced dns lookup can cause extra instability. Allow users to tun that feature off, if wanted.</description>
			<version>1.1.2</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">13067</link>
		</links>
	</bug>
	<bug id="14347" opendate="2015-08-31 19:39:14" fixdate="2015-10-05 23:26:14" resolution="Fixed">
		<buginformation>
			<summary>Add a switch to DynamicClassLoader to disable it</summary>
			<description>Since HBASE-1936 we have the option to load jars dynamically by default from HDFS or the local filesystem, however hbase.dynamic.jars.dir points to a directory that could be world writable it potentially opens a security problem in both the client side and the RS. We should consider to have a switch to enable or disable this option and it should be off by default.</description>
			<version>0.98.15</version>
			<fixedVersion>2.0.0, 1.2.0, 1.0.3, 1.1.3, 0.98.16</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.DynamicClassLoader.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestDynamicClassLoader.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">14554</link>
		</links>
	</bug>
	<bug id="14555" opendate="2015-10-06 00:10:11" fixdate="2015-10-06 00:51:06" resolution="Fixed">
		<buginformation>
			<summary>Deadlock in MVCC branch-1.2 toString()</summary>
			<description>Just saw this in an IT test.


Thread 75 (PriorityRpcServer.handler=3,queue=1,port=16020):
  State: BLOCKED
  Blocked count: 691635
  Waited count: 1557446
  Blocked on java.util.LinkedList@32b53d9e
  Blocked by 81 (PriorityRpcServer.handler=9,queue=1,port=16020)
  Stack:
    org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl.toString(MultiVersionConcurrencyControl.java:234)
    java.lang.String.valueOf(String.java:2994)
    java.lang.StringBuilder.append(StringBuilder.java:131)
    org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl.waitForRead(MultiVersionConcurrencyControl.java:209)
    org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl.completeAndWait(MultiVersionConcurrencyControl.java:144)
    org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutation(HRegion.java:3191)
    org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2837)
    org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2779)
    org.apache.hadoop.hbase.regionserver.RSRpcServices.doBatchOp(RSRpcServices.java:697)
    org.apache.hadoop.hbase.regionserver.RSRpcServices.doNonAtomicRegionMutation(RSRpcServices.java:659)
    org.apache.hadoop.hbase.regionserver.RSRpcServices.multi(RSRpcServices.java:2047)
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:32594)
    org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2120)
    org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:106)
    org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)
    org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)
    java.lang.Thread.run(Thread.java:745)








Thread 81 (PriorityRpcServer.handler=9,queue=1,port=16020):
  State: BLOCKED
  Blocked count: 691858
  Waited count: 1558138
  Blocked on java.lang.Object@2a5e9ae8
  Blocked by 75 (PriorityRpcServer.handler=3,queue=1,port=16020)
  Stack:
    org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl.complete(MultiVersionConcurrencyControl.java:191)
    org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl.completeAndWait(MultiVersionConcurrencyControl.java:143)
    org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutation(HRegion.java:3191)
    org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2837)
    org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2779)
    org.apache.hadoop.hbase.regionserver.RSRpcServices.doBatchOp(RSRpcServices.java:697)
    org.apache.hadoop.hbase.regionserver.RSRpcServices.doNonAtomicRegionMutation(RSRpcServices.java:659)
    org.apache.hadoop.hbase.regionserver.RSRpcServices.multi(RSRpcServices.java:2047)
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:32594)
    org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2120)
    org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:106)
    org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)
    org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)
    java.lang.Thread.run(Thread.java:745)
Thread 80 (PriorityRpcServer.handler=8,queue=0,port=16020):


</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl.java</file>
		</fixedFiles>
	</bug>
	<bug id="14497" opendate="2015-09-27 11:17:19" fixdate="2015-10-08 13:58:09" resolution="Fixed">
		<buginformation>
			<summary>Reverse Scan threw StackOverflow caused by readPt checking</summary>
			<description>I met stack overflow error in StoreFileScanner.seekToPreviousRow using reversed scan. I searched and founded HBASE-14155, but it seems to be a different reason.
The seekToPreviousRow will fetch the row which closest before, and compare mvcc to the readPt, which acquired when scanner created. If the row&amp;amp;apos;s mvcc is bigger than readPt, an recursive call of seekToPreviousRow will invoked, to find the next closest before row.
Considering we created a scanner for reversed scan, and some data with smaller rows was written and flushed, before calling scanner next. When seekToPreviousRow was invoked, it would call itself recursively, until all rows which written after scanner created were iterated. The depth of recursive calling stack depends on the count of rows, the stack overflow error will be threw if the count of rows is large, like 10000.</description>
			<version>0.98.14</version>
			<fixedVersion>2.0.0, 1.3.0, 0.98.16</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.DefaultMemStore.java</file>
		</fixedFiles>
	</bug>
	<bug id="14525" opendate="2015-09-30 13:15:14" fixdate="2015-10-09 15:27:35" resolution="Fixed">
		<buginformation>
			<summary>Append and increment operation throws NullPointerException on non-existing column families.</summary>
			<description>When performing append operation on non-existing column families, NullPointerException is thrown in hbase shell as shown below:

hbase(main):007:0&amp;gt; append &amp;amp;apos;t1&amp;amp;apos;, &amp;amp;apos;r1&amp;amp;apos;, &amp;amp;apos;none:c1&amp;amp;apos;, &amp;amp;apos;123&amp;amp;apos;

ERROR: java.io.IOException
at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2175)
at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:106)
at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)
at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)
at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NullPointerException
at org.apache.hadoop.hbase.regionserver.HRegion.doGet(HRegion.java:6987)
at org.apache.hadoop.hbase.regionserver.HRegion.append(HRegion.java:7048)
at org.apache.hadoop.hbase.regionserver.RSRpcServices.append(RSRpcServices.java:580)
at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2206)
at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:32452)
at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2133)
... 4 more



This seems to be caused by absence of check for valid family names as done in other operations like &amp;amp;apos;Put&amp;amp;apos; in HRegion.java</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestAtomicOperation.java</file>
		</fixedFiles>
	</bug>
	<bug id="13858" opendate="2015-06-08 14:23:05" fixdate="2015-10-09 22:48:04" resolution="Fixed">
		<buginformation>
			<summary>RS/MasterDumpServlet dumps threads before its Stacks header</summary>
			<description>The stacktraces are captured using a Hadoop helper method, then its output is merged with the current. I presume there is a simple flush after outputing the "Stack" header missing, before then the caught output is dumped.</description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.MasterDumpServlet.java</file>
		</fixedFiles>
	</bug>
	<bug id="14578" opendate="2015-10-08 11:52:39" fixdate="2015-10-10 22:27:41" resolution="Fixed">
		<buginformation>
			<summary>URISyntaxException during snapshot restore for table with user defined namespace</summary>
			<description>Snapshot restore failed for a table which is created under user defined namespace,

java.io.IOException: java.util.concurrent.ExecutionException: java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: tag_namespace:tableName_XYZ
	at org.apache.hadoop.hbase.util.ModifyRegionUtils.createRegions(ModifyRegionUtils.java:133)
	at org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper.cloneHdfsRegions(RestoreSnapshotHelper.java:475)
	at org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper.restoreHdfsRegions(RestoreSnapshotHelper.java:208)
	at org.apache.hadoop.hbase.master.snapshot.CloneSnapshotHandler.handleCreateHdfsRegions(CloneSnapshotHandler.java:112)
	at org.apache.hadoop.hbase.master.handler.CreateTableHandler.handleCreateTable(CreateTableHandler.java:233)
	at org.apache.hadoop.hbase.master.handler.CreateTableHandler.process(CreateTableHandler.java:168)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.util.concurrent.ExecutionException: java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: tag_namespace:tableName_XYZ
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:188)
	at org.apache.hadoop.hbase.util.ModifyRegionUtils.createRegions(ModifyRegionUtils.java:126)
	... 9 more
Caused by: java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: tag_namespace:tableName_XYZ
	at org.apache.hadoop.fs.Path.initialize(Path.java:206)
	at org.apache.hadoop.fs.Path.&amp;lt;init&amp;gt;(Path.java:172)
	at org.apache.hadoop.fs.Path.&amp;lt;init&amp;gt;(Path.java:89)
	at org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper.restoreReferenceFile(RestoreSnapshotHelper.java:558)
	at org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper.restoreStoreFile(RestoreSnapshotHelper.java:531)
	at org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper.access$200(RestoreSnapshotHelper.java:106)
	at org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper$2.storeFile(RestoreSnapshotHelper.java:509)
	at org.apache.hadoop.hbase.util.FSVisitor.visitRegionStoreFiles(FSVisitor.java:136)
	at org.apache.hadoop.hbase.snapshot.SnapshotReferenceUtil.visitRegionStoreFiles(SnapshotReferenceUtil.java:127)
	at org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper.cloneRegion(RestoreSnapshotHelper.java:502)
	at org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper.access$100(RestoreSnapshotHelper.java:106)
	at org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper$1.fillRegion(RestoreSnapshotHelper.java:479)
	at org.apache.hadoop.hbase.util.ModifyRegionUtils.createRegion(ModifyRegionUtils.java:160)
	at org.apache.hadoop.hbase.util.ModifyRegionUtils$1.call(ModifyRegionUtils.java:118)
	at org.apache.hadoop.hbase.util.ModifyRegionUtils$1.call(ModifyRegionUtils.java:115)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	... 3 more
Caused by: java.net.URISyntaxException: Relative path in absolute URI: tag_namespace:tableName_XYZ
	at java.net.URI.checkPath(URI.java:1804)
	at java.net.URI.&amp;lt;init&amp;gt;(URI.java:752)
	at org.apache.hadoop.fs.Path.initialize(Path.java:203)
	... 20 more


After region split, new daughter regions contain the reference of the original HFile until compaction happens. 
In RestoreSnapshotHelper (while restoring snapshot file which have regions containing hfile references), path is initialized using the snapshot table name which has namespace separated by colon,


  private void restoreReferenceFile(final Path familyDir, final HRegionInfo regionInfo,
      final String hfileName) throws IOException {
    // Extract the referred information (hfile name and parent region)
    Path refPath = StoreFileInfo.getReferredToFile(new Path(new Path(new Path(
        snapshotTable.getNameAsString(), regionInfo.getEncodedName()), familyDir.getName()),
        hfileName));
  ---code---
  }

</description>
			<version>0.98.5</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.0.3, 1.1.3, 0.98.16</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.snapshot.TestSnapshotFileCache.java</file>
			<file type="M">org.apache.hadoop.hbase.snapshot.TestExportSnapshot.java</file>
			<file type="M">org.apache.hadoop.hbase.snapshot.SnapshotTestingUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.snapshot.TestRestoreSnapshotHelper.java</file>
			<file type="M">org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper.java</file>
		</fixedFiles>
	</bug>
	<bug id="14592" opendate="2015-10-12 09:52:43" fixdate="2015-10-12 21:52:59" resolution="Fixed">
		<buginformation>
			<summary>BatchRestartRsAction always restarts 0 RS when running SlowDeterministicMonkey</summary>
			<description>When running ITBLL, observed below log and found the ratio of batch restarting is always zero:

15/10/12 17:05:37 INFO actions.Action: Performing action: Batch restarting 0% of region servers


Checking code, found batchRestartRSRatio never got initialized in SlowDeterministicMonkeyFactory, and current ITBLL never check the case of batch RS restarting in actual.</description>
			<version>0.98.15</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.chaos.factories.SlowDeterministicMonkeyFactory.java</file>
		</fixedFiles>
	</bug>
	<bug id="14211" opendate="2015-08-11 20:37:29" fixdate="2015-10-13 00:08:03" resolution="Fixed">
		<buginformation>
			<summary>Add more rigorous integration tests of splits</summary>
			<description>Add a chaos action that will turn down region size.

Eventually this will cause regions to split a lot.
It will need to have a min region size.

Add a chaos monkey action that will change split policy

Change between Uniform and SplittingUpTo and back

Add chaos monkey action that will request splits of every region.

When regions all reach the size a the exact same time the compactions add a lot of work.
This simulates a very well distributed write pattern reaching the region size.

Add the ability to start with fewer regions than normal to ITBLL</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.chaos.factories.StressAssignmentManagerMonkeyFactory.java</file>
			<file type="M">org.apache.hadoop.hbase.chaos.factories.SlowDeterministicMonkeyFactory.java</file>
			<file type="M">org.apache.hadoop.hbase.chaos.factories.MonkeyConstants.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
			<file type="M">org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
			<file type="M">org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.java</file>
		</fixedFiles>
	</bug>
	<bug id="14591" opendate="2015-10-12 08:53:43" fixdate="2015-10-14 02:37:54" resolution="Fixed">
		<buginformation>
			<summary>Region with reference hfile may split after a forced split in IncreasingToUpperBoundRegionSplitPolicy</summary>
			<description>In the IncreasingToUpperBoundRegionSplitPolicy, a region with a store having hfile reference may split after a forced split. This will break many assumptions of design.</description>
			<version>0.98.15</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.0.3, 1.1.3, 0.98.16</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestRegionSplitPolicy.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.IncreasingToUpperBoundRegionSplitPolicy.java</file>
		</fixedFiles>
	</bug>
	<bug id="14598" opendate="2015-10-13 18:10:37" fixdate="2015-10-14 20:15:55" resolution="Fixed">
		<buginformation>
			<summary>ByteBufferOutputStream grows its HeapByteBuffer beyond JVM limitations</summary>
			<description>We noticed that in returning a Scan against a region containing particularly large (wide) rows that it is possible during ByteBufferOutputStream.checkSizeAndGrow() to attempt to create a new ByteBuffer larger than the JVM allows which then throws a OutOfMemoryError. The code currently caps it at Integer.MAX_VALUE which is actually larger than the JVM allows. This lead to us dealing with cascading region server death as the RegionServer hosting the region died, opened on a new server, the client retried the scan, and the new RS died as well. 
I believe ByteBufferOutputStream should not try to create ByteBuffers that large and instead throw an exception back up if it needs to grow any bigger. The limit should probably be something like Integer.MAX_VALUE-8, as that is what ArrayList uses. ref: http://grepcode.com/file/repository.grepcode.com/java/root/jdk/openjdk/8-b132/java/util/ArrayList.java#221</description>
			<version>0.98.12</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.0.3, 1.1.3, 0.98.16</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.IPCUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.io.ByteBufferOutputStream.java</file>
		</fixedFiles>
	</bug>
	<bug id="14521" opendate="2015-09-30 07:36:21" fixdate="2015-10-15 08:46:41" resolution="Fixed">
		<buginformation>
			<summary>Unify the semantic of hbase.client.retries.number</summary>
			<description>From name of the hbase.client.retries.number property, it should be the number of maximum retries, or say if we set the property to 1, there should be 2 attempts in total. However, there&amp;amp;apos;re two different semantics when using it in current code base.
For example, in ConnectionImplementation#locateRegionInMeta:


    int localNumRetries = (retry ? numTries : 1);

    for (int tries = 0; true; tries++) {
      if (tries &amp;gt;= localNumRetries) {
        throw new NoServerForRegionException("Unable to find region for "
            + Bytes.toStringBinary(row) + " in " + tableName +
            " after " + numTries + " tries.");
      }


the retries number is regarded as max times for tries
While in RpcRetryingCallerImpl#callWithRetries:


    for (int tries = 0;; tries++) {
      long expectedSleep;
      try {
        callable.prepare(tries != 0); // if called with false, check table status on ZK
        interceptor.intercept(context.prepare(callable, tries));
        return callable.call(getRemainingTime(callTimeout));
      } catch (PreemptiveFastFailException e) {
        throw e;
      } catch (Throwable t) {
        ...
        if (tries &amp;gt;= retries - 1) {
          throw new RetriesExhaustedException(tries, exceptions);
        }


it&amp;amp;apos;s regarded as exactly for REtry (try a call first with no condition and then check whether to retry or exceeds maximum retry number)
This inconsistency will cause misunderstanding in usage, such as one of our customer set the property to zero expecting one single call but finally received NoServerForRegionException.
We should unify the semantic of the property, and I suggest to keep the original one for retry rather than total tries.</description>
			<version>0.98.14</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.TestBlockEvictionFromClient.java</file>
			<file type="M">org.apache.hadoop.hbase.client.AsyncProcess.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestAsyncProcess.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTableMultiplexer.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestHCM.java</file>
			<file type="M">org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.client.RetriesExhaustedException.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMasterCommandLine.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">16291</link>
			<link type="Supercedes" description="supercedes">15829</link>
		</links>
	</bug>
	<bug id="14406" opendate="2015-09-11 04:59:55" fixdate="2015-10-16 18:26:13" resolution="Fixed">
		<buginformation>
			<summary>The dataframe datasource filter is wrong, and will result in data loss or unexpected behavior</summary>
			<description>Following condition will result in the same filter. It will have data loss with the current filter construction.
col1 &amp;gt; 4 &amp;amp;&amp;amp; col2 &amp;lt; 3
col1 &amp;gt; 4 || col2 &amp;lt; 3</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.FilterProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.spark.SparkSQLPushDownFilter.java</file>
		</fixedFiles>
		<links>
			<link type="dependent" description="is depended upon by">14160</link>
		</links>
	</bug>
	<bug id="14597" opendate="2015-10-13 15:28:09" fixdate="2015-10-16 22:21:22" resolution="Fixed">
		<buginformation>
			<summary>Fix Groups cache in multi-threaded env</summary>
			<description>UGI doesn&amp;amp;apos;t hash based on the user as expected so since we have lots of ugi potentially created the cache doesn&amp;amp;apos;t do it&amp;amp;apos;s job.</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 0.98.17</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.security.UserProvider.java</file>
			<file type="M">org.apache.hadoop.hbase.security.TestUser.java</file>
			<file type="M">org.apache.hadoop.hbase.security.User.java</file>
		</fixedFiles>
	</bug>
	<bug id="14625" opendate="2015-10-15 23:11:38" fixdate="2015-10-16 22:25:16" resolution="Fixed">
		<buginformation>
			<summary>Chaos Monkey should shut down faster</summary>
			<description>Right now we have a couple of tests clusters that are just cycling through IT tests. There&amp;amp;apos;s a pretty sizable gap between the last MR job stopping and the next one starting. It&amp;amp;apos;s almost always waiting on an action to finish.


"main" #1 prio=5 os_prio=0 tid=0x00007f455000d800 nid=0x2a2773 in Object.wait() [0x00007f4556e42000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1245)
	- locked &amp;lt;0x00000003ef054138&amp;gt; (a java.lang.Thread)
	at java.lang.Thread.join(Thread.java:1319)
	at org.apache.hadoop.hbase.chaos.monkies.PolicyBasedChaosMonkey.waitForStop(PolicyBasedChaosMonkey.java:149)
	at org.apache.hadoop.hbase.IntegrationTestBase.cleanUpMonkey(IntegrationTestBase.java:173)
	at org.apache.hadoop.hbase.IntegrationTestBase.cleanUpMonkey(IntegrationTestBase.java:167)
	at org.apache.hadoop.hbase.IntegrationTestBase.cleanUp(IntegrationTestBase.java:139)
	at org.apache.hadoop.hbase.IntegrationTestBase.doWork(IntegrationTestBase.java:125)
	at org.apache.hadoop.hbase.util.AbstractHBaseTool.run(AbstractHBaseTool.java:112)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.main(IntegrationTestBigLinkedList.java:1686)

</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.chaos.actions.ForceBalancerAction.java</file>
			<file type="M">org.apache.hadoop.hbase.chaos.actions.SnapshotTableAction.java</file>
			<file type="M">org.apache.hadoop.hbase.chaos.actions.MergeRandomAdjacentRegionsOfTableAction.java</file>
			<file type="M">org.apache.hadoop.hbase.chaos.actions.ChangeEncodingAction.java</file>
			<file type="M">org.apache.hadoop.hbase.chaos.actions.FlushTableAction.java</file>
			<file type="M">org.apache.hadoop.hbase.chaos.actions.Action.java</file>
			<file type="M">org.apache.hadoop.hbase.chaos.actions.TruncateTableAction.java</file>
			<file type="M">org.apache.hadoop.hbase.chaos.actions.DecreaseMaxHFileSizeAction.java</file>
			<file type="M">org.apache.hadoop.hbase.chaos.actions.RollingBatchRestartRsAction.java</file>
			<file type="M">org.apache.hadoop.hbase.chaos.actions.ChangeCompressionAction.java</file>
			<file type="M">org.apache.hadoop.hbase.chaos.actions.ChangeVersionsAction.java</file>
			<file type="M">org.apache.hadoop.hbase.chaos.actions.MoveRegionsOfTableAction.java</file>
			<file type="M">org.apache.hadoop.hbase.chaos.actions.ChangeBloomFilterAction.java</file>
			<file type="M">org.apache.hadoop.hbase.chaos.actions.SplitAllRegionOfTableAction.java</file>
			<file type="M">org.apache.hadoop.hbase.chaos.actions.UnbalanceKillAndRebalanceAction.java</file>
			<file type="M">org.apache.hadoop.hbase.chaos.actions.SplitRandomRegionOfTableAction.java</file>
			<file type="M">org.apache.hadoop.hbase.chaos.actions.CompactMobAction.java</file>
			<file type="M">org.apache.hadoop.hbase.chaos.actions.RestartActionBaseAction.java</file>
			<file type="M">org.apache.hadoop.hbase.chaos.policies.Policy.java</file>
			<file type="M">org.apache.hadoop.hbase.chaos.actions.AddColumnAction.java</file>
			<file type="M">org.apache.hadoop.hbase.chaos.actions.BatchRestartRsAction.java</file>
			<file type="M">org.apache.hadoop.hbase.chaos.actions.RemoveColumnAction.java</file>
		</fixedFiles>
	</bug>
	<bug id="14458" opendate="2015-09-21 19:19:15" fixdate="2015-10-19 03:49:53" resolution="Fixed">
		<buginformation>
			<summary>AsyncRpcClient#createRpcChannel() should check and remove dead channel before creating new one to same server</summary>
			<description>I have notice this issue while testing master branch in distributed mode. Reproduction steps:
1. Write some data with hbase ltt 
2. While ltt is writing execute $graceful_stop.sh --restart --reload [rs] 
3. Wait until script start to reload regions to restarted server. In that moment ltt will stop writing and eventually fail. 
After some digging i have notice that while ltt is working correctly there is single connection per regionserver (lsof for single connection, 27109 is  ltt PID )


java      27109   hbase  143u    210579579      0t0        TCP hnode1:40423-&amp;gt;hnode5:16020 (ESTABLISHED)


and when in this example hnode5 server is restarted and script starts to reload regions on this server ltt start creating thousands of new tcp connections to this server:


java      27109   hbase *623u              210674415      0t0        TCP hnode1:52948-&amp;gt;hnode5:16020 (ESTABLISHED)
java      27109   hbase *624u               210674416      0t0        TCP hnode1:52949-&amp;gt;hnode5:16020 (ESTABLISHED)
java      27109   hbase *625u               210674417      0t0        TCP hnode1:52950-&amp;gt;hnode5:16020 (ESTABLISHED)
java      27109   hbase *627u               210674419      0t0        TCP hnode1:52952-&amp;gt;hnode5:16020 (ESTABLISHED)
java      27109   hbase *628u               210674420      0t0        TCP hnode1:52953-&amp;gt;hnode5:16020 (ESTABLISHED)
java      27109   hbase *633u               210674425      0t0        TCP hnode1:52958-&amp;gt;hnode5:16020 (ESTABLISHED)
...


So here is what happened based on some additional logging and debugging:

AsyncRpcClient never detected that regionserver is restarted because regions were moved and there was no write/read requests to this server and  there is no some sort of heart-bit mechanism implemented
because of above dead 

AsyncRpcChannel

 stayed in 

PoolMap&amp;lt;Integer, AsyncRpcChannel&amp;gt; connections

when ltt detected that regions are moved back to hnode5  it tried to reconnect to hnode5  leading this issue
I was able to resolve this issue by adding following to AsyncRpcClient#createRpcChannel():


synchronized (connections) {
      if (closed) {
        throw new StoppedRpcClientException();
      }
      rpcChannel = connections.get(hashCode);
+    if (rpcChannel != null &amp;amp;&amp;amp; !rpcChannel.isAlive()) {
+        LOG.debug(Removing dead channel from "+ rpcChannel.address.toString());
+        connections.remove(hashCode);
+      }      

      if (rpcChannel == null || !rpcChannel.isAlive()) {
        rpcChannel = new AsyncRpcChannel(this.bootstrap, this, ticket, serviceName, location);
        connections.put(hashCode, rpcChannel);


 I will attach patch after some more testing.

</description>
			<version>1.1.3</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.AsyncRpcClient.java</file>
		</fixedFiles>
	</bug>
	<bug id="14653" opendate="2015-10-20 02:18:52" fixdate="2015-10-20 02:28:15" resolution="Duplicate">
		<buginformation>
			<summary>Balancer is getting NullPointerExceptions</summary>
			<description>
ERROR: java.io.IOException
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2165)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:106)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster.getLeastLoadedTopServerForRegion(BaseLoadBalancer.java:847)
	at org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer$LocalityBasedCandidateGenerator.generate(StochasticLoadBalancer.java:609)
	at org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.balanceCluster(StochasticLoadBalancer.java:267)
	at org.apache.hadoop.hbase.master.HMaster.balance(HMaster.java:1263)
	at org.apache.hadoop.hbase.master.MasterRpcServices.balance(MasterRpcServices.java:435)
	at org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MasterService$2.callBlockingMethod(MasterProtos.java:53616)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2120)
	... 4 more

</description>
			<version>2.0.0</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">14291</link>
		</links>
	</bug>
	<bug id="14604" opendate="2015-10-14 09:54:05" fixdate="2015-10-20 09:40:16" resolution="Fixed">
		<buginformation>
			<summary>Improve MoveCostFunction in StochasticLoadBalancer</summary>
			<description>The code in MoveCoseFunction:


return scale(0, cluster.numRegions + META_MOVE_COST_MULT, moveCost);


It uses cluster.numRegions + META_MOVE_COST_MULT as the max value when scale moveCost to [0,1]. But this should use maxMoves as the max value when cluster have a lot of regions.
Assume a cluster have 10000 regions, maxMoves is 2500, it only scale moveCost to [0, 0.25].
Improve moveCost by use Math.min(cluster.numRegions, maxMoves) as the max cost, so it can scale moveCost to [0,1].


return scale(0, Math.min(cluster.numRegions, maxMoves) + META_MOVE_COST_MULT, moveCost);

</description>
			<version>0.98.15</version>
			<fixedVersion>2.0.0, 1.3.0, 0.98.16</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
			<file type="M">org.apache.hadoop.hbase.master.balancer.TestStochasticLoadBalancer.java</file>
			<file type="M">org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.java</file>
		</fixedFiles>
	</bug>
	<bug id="14366" opendate="2015-09-04 09:48:40" fixdate="2015-10-20 11:11:34" resolution="Fixed">
		<buginformation>
			<summary>NPE in case visibility expression is not present in labels table during importtsv run</summary>
			<description>Below exception is shown in logs if visibility expression is not present in labels table during importtsv run. Appropriate exception / message should be logged for the user to take further action.


WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.lang.NullPointerException
        at org.apache.hadoop.hbase.mapreduce.DefaultVisibilityExpressionResolver$1.getLabelOrdinal(DefaultVisibilityExpressionResolver.java:127)
        at org.apache.hadoop.hbase.security.visibility.VisibilityUtils.getLabelOrdinals(VisibilityUtils.java:358)
        at org.apache.hadoop.hbase.security.visibility.VisibilityUtils.createVisibilityExpTags(VisibilityUtils.java:323)
        at org.apache.hadoop.hbase.mapreduce.DefaultVisibilityExpressionResolver.createVisibilityExpTags(DefaultVisibilityExpressionResolver.java:137)
        at org.apache.hadoop.hbase.mapreduce.TsvImporterMapper.populatePut(TsvImporterMapper.java:205)
        at org.apache.hadoop.hbase.mapreduce.TsvImporterMapper.map(TsvImporterMapper.java:165)
        at org.apache.hadoop.hbase.mapreduce.TsvImporterMapper.map(TsvImporterMapper.java:1)
        at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
        at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)

</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.0.3, 1.1.3, 0.98.16</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TestImportTSVWithVisibilityLabels.java</file>
			<file type="M">org.apache.hadoop.hbase.security.visibility.VisibilityConstants.java</file>
			<file type="M">org.apache.hadoop.hbase.security.visibility.VisibilityLabelsCache.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.DefaultVisibilityExpressionResolver.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TsvImporterMapper.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TextSortReducer.java</file>
		</fixedFiles>
	</bug>
	<bug id="14663" opendate="2015-10-21 18:28:28" fixdate="2015-10-22 05:00:36" resolution="Fixed">
		<buginformation>
			<summary>HStore::close does not honor config hbase.rs.evictblocksonclose</summary>
			<description>I noticed moving regions was slow and due to the wait for the bucket cache to clear.  I tried setting hbase.rs.evictblocksonclose and it did not help.
I see the HStore::close method has evictonclose hard coded to true instead of letting the config dictate:
// close each store file in parallel
CompletionService&amp;lt;Void&amp;gt; completionService =
   new ExecutorCompletionService&amp;lt;Void&amp;gt;(storeFileCloserThreadPool);
for (final StoreFile f : result) {
   completionService.submit(new Callable&amp;lt;Void&amp;gt;() {
     @Override
     public Void call() throws IOException 
{
       f.closeReader(true);
       return null;
     }
   });
}</description>
			<version>1.0.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.0.3, 1.1.3, 0.98.16</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
		</fixedFiles>
	</bug>
	<bug id="14603" opendate="2015-10-14 06:14:14" fixdate="2015-10-22 08:29:27" resolution="Fixed">
		<buginformation>
			<summary>Lots of work on the POM to enhance Javadocs, Xrefs</summary>
			<description>If we disable the timestamps (which are in HTML comments), then every Javadoc file won&amp;amp;apos;t show up as different every time we rebuild the site.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.HTableDescriptor.java</file>
		</fixedFiles>
	</bug>
	<bug id="14658" opendate="2015-10-21 01:21:32" fixdate="2015-10-22 15:57:12" resolution="Fixed">
		<buginformation>
			<summary>Allow loading a MonkeyFactory by class name</summary>
			<description>Users should be able to define their own chaos monkey that is loaded by class name.</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 0.98.16</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.chaos.factories.MonkeyFactory.java</file>
		</fixedFiles>
	</bug>
	<bug id="14343" opendate="2015-08-31 11:58:25" fixdate="2015-10-24 09:38:12" resolution="Fixed">
		<buginformation>
			<summary>Fix debug message in SimpleRegionNormalizer for small regions</summary>
			<description>The SimpleRegionNormalizer has this:


     if ((smallestRegion.getSecond() + smallestNeighborOfSmallestRegion.getSecond()
          &amp;lt; avgRegionSize)) {
        LOG.debug("Table " + table + ", smallest region size: " + smallestRegion.getSecond()
          + " and its smallest neighbor size: " + smallestNeighborOfSmallestRegion.getSecond()
          + ", less than half the avg size, merging them");


It does not check for "less than half the avg size" but only "less than the avg size", that is, drop the "half". Fix message.</description>
			<version>1.1.1</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.normalizer.SimpleRegionNormalizer.java</file>
		</fixedFiles>
	</bug>
	<bug id="14624" opendate="2015-10-15 21:54:24" fixdate="2015-10-25 01:54:30" resolution="Fixed">
		<buginformation>
			<summary>BucketCache.freeBlock is too expensive</summary>
			<description>Moving regions is unacceptably slow when using bucket cache, as it takes too long to free all the blocks.</description>
			<version>1.0.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.0.3, 1.1.3, 0.98.16</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator.java</file>
		</fixedFiles>
	</bug>
	<bug id="14257" opendate="2015-08-19 16:46:46" fixdate="2015-10-27 06:55:05" resolution="Fixed">
		<buginformation>
			<summary>Periodic flusher only handles hbase:meta, not other system tables</summary>
			<description>In HRegion.shouldFlush we have


    long modifiedFlushCheckInterval = flushCheckInterval;
    if (getRegionInfo().isMetaRegion() &amp;amp;&amp;amp;
        getRegionInfo().getReplicaId() == HRegionInfo.DEFAULT_REPLICA_ID) {
      modifiedFlushCheckInterval = META_CACHE_FLUSH_INTERVAL;
    }


That method is called by the PeriodicMemstoreFlusher thread, and prefers the hbase:meta only for faster flushing. It should be doing the same for other system tables. I suggest to use HRI.isSystemTable().</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestDefaultMemStore.java</file>
		</fixedFiles>
	</bug>
	<bug id="14705" opendate="2015-10-27 12:56:12" fixdate="2015-10-27 21:40:09" resolution="Fixed">
		<buginformation>
			<summary>Javadoc for KeyValue constructor is not correct.</summary>
			<description>

  /**
   * Constructs KeyValue structure filled with null value.
   * @param row - row key (arbitrary byte array)
   * @param family family name
   * @param qualifier column qualifier
   */
  public KeyValue(final byte [] row, final byte [] family,
      final byte [] qualifier, final byte [] value) {
    this(row, family, qualifier, HConstants.LATEST_TIMESTAMP, Type.Put, value);
  }


Value is not filled with null.</description>
			<version>1.1.2</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.0.3, 1.1.3, 0.98.16</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.KeyValue.java</file>
		</fixedFiles>
	</bug>
	<bug id="14660" opendate="2015-10-21 08:17:04" fixdate="2015-10-28 09:52:28" resolution="Fixed">
		<buginformation>
			<summary>AssertionError found when using offheap BucketCache with assertion enabled</summary>
			<description>During perf verification of HBASE-14463, found offheap BucketCache not working with assertion enabled in hbase-env.sh:

export HBASE_OPTS="-ea -XX:+HeapDumpOnOutOfMemoryError -XX:+UseConcMarkSweepGC"


And the error when running PE tool is like:

15/10/21 16:06:34 INFO client.AsyncProcess: #10, table=TestTable, attempt=10/21 failed=20ops, last exception: java.io.IOException: java.io.IOException
        at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2181)
        at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:106)
        at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)
        at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)
        at java.lang.Thread.run(Thread.java:744)
Caused by: java.lang.AssertionError
        at org.apache.hadoop.hbase.OffheapKeyValue.&amp;lt;init&amp;gt;(OffheapKeyValue.java:52)
        at org.apache.hadoop.hbase.io.hfile.HFileReaderImpl$HFileScannerImpl$ShareableMemoryOffheapKeyValue.&amp;lt;init&amp;gt;(HFileReaderImpl.java:1003)
        at org.apache.hadoop.hbase.io.hfile.HFileReaderImpl$HFileScannerImpl.getCell(HFileReaderImpl.java:949)
        at org.apache.hadoop.hbase.regionserver.StoreFileScanner.reseek(StoreFileScanner.java:201)
        at org.apache.hadoop.hbase.regionserver.NonLazyKeyValueScanner.doRealSeek(NonLazyKeyValueScanner.java:55)
        at org.apache.hadoop.hbase.regionserver.KeyValueHeap.generalizedSeek(KeyValueHeap.java:323)
        at org.apache.hadoop.hbase.regionserver.KeyValueHeap.requestSeek(KeyValueHeap.java:279)
        at org.apache.hadoop.hbase.regionserver.StoreScanner.reseek(StoreScanner.java:825)
        at org.apache.hadoop.hbase.regionserver.StoreScanner.seekAsDirection(StoreScanner.java:813)
        at org.apache.hadoop.hbase.regionserver.StoreScanner.next(StoreScanner.java:641)
        at org.apache.hadoop.hbase.regionserver.KeyValueHeap.next(KeyValueHeap.java:153)
        at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.populateResult(HRegion.java:5649)
        at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.nextInternal(HRegion.java:5795)
        at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.nextRaw(HRegion.java:5568)
        at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.next(HRegion.java:5544)
        at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.next(HRegion.java:5530)
        at org.apache.hadoop.hbase.regionserver.RSRpcServices.get(RSRpcServices.java:2044)
        at org.apache.hadoop.hbase.regionserver.RSRpcServices.doNonAtomicRegionMutation(RSRpcServices.java:663)
        at org.apache.hadoop.hbase.regionserver.RSRpcServices.multi(RSRpcServices.java:2156)


ramkrishna.s.vasudevan and Anoop Sam John, mind to take a look?</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFileReaderImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.TestSeekTo.java</file>
		</fixedFiles>
	</bug>
	<bug id="14699" opendate="2015-10-26 21:11:42" fixdate="2015-10-29 06:27:54" resolution="Duplicate">
		<buginformation>
			<summary>Replication crashes regionservers when hbase.wal.provider is set to multiwal</summary>
			<description>When the hbase.wal.provider is set to multiwal and replication is enabled, the regionservers start crashing with the following exception:


&amp;lt;hostname&amp;gt;,16020,1445495411258: Failed to write replication wal position (filename=&amp;lt;hostname&amp;gt;%2C16020%2C1445495411258.null0.1445495898373, position=1322399)
org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /hbase/replication/rs/&amp;lt;hostname&amp;gt;,16020,1445495411258/1/&amp;lt;hostname&amp;gt;%2C16020%2C1445495411258.null0.1445495898373
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.setData(ZooKeeper.java:1270)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.setData(RecoverableZooKeeper.java:429)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.setData(ZKUtil.java:940)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.setData(ZKUtil.java:990)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.setData(ZKUtil.java:984)
	at org.apache.hadoop.hbase.replication.ReplicationQueuesZKImpl.setLogPosition(ReplicationQueuesZKImpl.java:129)
	at org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.logPositionAndCleanOldLogs(ReplicationSourceManager.java:177)
	at org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.run(ReplicationSource.java:388)

</description>
			<version>1.2.0</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.TestReplicationEndpoint.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.MetricsSource.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.LogRoller.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.ReplicationEndpoint.java</file>
			<file type="M">org.apache.hadoop.hbase.wal.DefaultWALProvider.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.TestRegionReplicaReplicationEndpointNoMaster.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.TestReplicationWALReaderManager.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManager.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
			<file type="M">org.apache.hadoop.hbase.wal.WALFactory.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">6617</link>
		</links>
	</bug>
	<bug id="14557" opendate="2015-10-06 03:31:05" fixdate="2015-10-30 15:51:14" resolution="Fixed">
		<buginformation>
			<summary>MapReduce WALPlayer issue with NoTagsKeyValue</summary>
			<description>Running MapReduce WALPlayer to convert WAL into HFiles:

15/10/05 20:28:08 INFO mapred.JobClient: Task Id : attempt_201508031611_0029_m_000000_0, Status : FAILED
java.io.IOException: Type mismatch in value from map: expected org.apache.hadoop.hbase.KeyValue, recieved org.apache.hadoop.hbase.NoTagsKeyValue
        at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:997)
        at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:689)
        at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
        at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
        at org.apache.hadoop.hbase.mapreduce.WALPlayer$WALKeyValueMapper.map(WALPlayer.java:111)
        at org.apache.hadoop.hbase.mapreduce.WALPlayer$WALKeyValueMapper.map(WALPlayer.java:96)
        at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:140)
        at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:751)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:368)
        at org.apache.hadoop.mapred.Child$4.run(Child.java:255)
        at java.security.AccessController.doPrivileged(AccessController.java:369)
        at javax.security.auth.Subject.doAs(Subject.java:572)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1502)
        at org.apache.hadoop.mapred.Child.main(Child.java:249)

</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mob.mapreduce.SweepReducer.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFileBlockIndex.java</file>
			<file type="M">org.apache.hadoop.hbase.mob.mapreduce.MemStoreWrapper.java</file>
			<file type="M">org.apache.hadoop.hbase.KeyValueUtil.java</file>
		</fixedFiles>
	</bug>
	<bug id="14711" opendate="2015-10-28 18:43:12" fixdate="2015-11-01 12:33:58" resolution="Fixed">
		<buginformation>
			<summary>Remove or annotated deprecated methods in HRegionInfo</summary>
			<description>Several methods were deprecated in 1.0 and moved to MetaTableAccessor.  This removes them from the 2.0 branch and converts them to the MetaTableAccessor.
HRegionInfo#getComparator  was marked deprecated after 1.0 so needs to remain. (HBASE-13501)
</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
			<file type="M">org.apache.hadoop.hbase.util.HBaseFsck.java</file>
			<file type="M">org.apache.hadoop.hbase.util.HMerge.java</file>
			<file type="M">org.apache.hadoop.hbase.master.CatalogJanitor.java</file>
			<file type="M">org.apache.hadoop.hbase.HRegionInfo.java</file>
			<file type="M">org.apache.hadoop.hbase.TestMetaTableAccessorNoCluster.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="M">org.apache.hadoop.hbase.util.Merge.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestRegionMergeTransactionOnCluster.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestMasterTransitions.java</file>
			<file type="M">org.apache.hadoop.hbase.util.hbck.OfflineMetaRebuildTestCore.java</file>
			<file type="M">org.apache.hadoop.hbase.master.RegionStateStore.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
			<file type="M">org.apache.hadoop.hbase.MetaTableAccessor.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestMasterOperationsForRegionReplicas.java</file>
		</fixedFiles>
	</bug>
	<bug id="14742" opendate="2015-11-02 17:05:17" fixdate="2015-11-03 01:12:58" resolution="Fixed">
		<buginformation>
			<summary>TestHeapMemoryManager is flakey</summary>
			<description>On our internal build system we&amp;amp;apos;ve seen TestHeapMemoryManager fail twice.


Failed tests: 
  TestHeapMemoryManager.testWhenClusterIsReadHeavy:174-&amp;gt;assertHeapSpaceDelta:317 null
  TestHeapMemoryManager.testWhenClusterIsWriteHeavy:136-&amp;gt;assertHeapSpaceDelta:317 null

</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHeapMemoryManager.java</file>
		</fixedFiles>
	</bug>
	<bug id="14723" opendate="2015-10-29 20:51:41" fixdate="2015-11-04 19:58:41" resolution="Fixed">
		<buginformation>
			<summary>Fix IT tests split too many times</summary>
			<description>Splitting the whole table is happening too often. Lets make this happen less frequently as there are more regions.</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.chaos.actions.SplitAllRegionOfTableAction.java</file>
		</fixedFiles>
	</bug>
	<bug id="14755" opendate="2015-11-04 02:23:54" fixdate="2015-11-06 01:11:55" resolution="Fixed">
		<buginformation>
			<summary>Fix some broken links and HTML problems</summary>
			<description>Problems seen in https://builds.apache.org/view/H-L/view/HBase/job/HBase%20Website%20Link%20Ckecker/3/artifact/link_report/index.html</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.HRegionPartitioner.java</file>
		</fixedFiles>
	</bug>
	<bug id="14706" opendate="2015-10-27 14:40:08" fixdate="2015-11-06 14:18:28" resolution="Fixed">
		<buginformation>
			<summary>RegionLocationFinder should return multiple servernames by top host</summary>
			<description>Multiple RS can run on the same host. But in current RegionLocationFinder, mapHostNameToServerName map one host to only one server. This will make LocalityCostFunction get wrong locality about region.


    // create a mapping from hostname to ServerName for fast lookup
    HashMap&amp;lt;String, ServerName&amp;gt; hostToServerName = new HashMap&amp;lt;String, ServerName&amp;gt;();
    for (ServerName sn : regionServers) {
      hostToServerName.put(sn.getHostname(), sn);
    }

</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.1.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.balancer.RegionLocationFinder.java</file>
		</fixedFiles>
	</bug>
	<bug id="14759" opendate="2015-11-04 09:48:34" fixdate="2015-11-07 01:36:33" resolution="Fixed">
		<buginformation>
			<summary>Avoid using Math.abs when selecting SyncRunner in FSHLog</summary>
			<description>FSHLog.java

int index = Math.abs(this.syncRunnerIndex++) % this.syncRunners.length;
          try {
            this.syncRunners[index].offer(sequence, this.syncFutures, this.syncFuturesCount);
          } catch (Exception e) {
            // Should NEVER get here.
            requestLogRoll();
            this.exception = new DamagedWALException("Failed offering sync", e);
          }


Math.abs will return Integer.MIN_VALUE if you pass Integer.MIN_VALUE in since the actual absolute value of Integer.MIN_VALUE is out of range.
I think this.syncRunnerIndex++ will overflow eventually if we keep the regionserver running for enough time.</description>
			<version>1.0.2</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.0.3, 1.1.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestFSHLog.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
		</fixedFiles>
	</bug>
	<bug id="14781" opendate="2015-11-06 20:08:06" fixdate="2015-11-07 21:27:05" resolution="Fixed">
		<buginformation>
			<summary>Turn per cf flushing on for ITBLL by default</summary>
			<description></description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.test.IntegrationTestBigLinkedList.java</file>
		</fixedFiles>
	</bug>
	<bug id="14784" opendate="2015-11-07 00:23:36" fixdate="2015-11-10 19:55:49" resolution="Fixed">
		<buginformation>
			<summary>Port conflict is not resolved in HBaseTestingUtility.randomFreePort()</summary>
			<description>If takenRandomPorts.contains(port) == true, it means port conflict, so randomFreePort() should rerun the loop. But continue statement leads to exit the loop, because port != 0.
hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java

public static int randomFreePort() {
  int port = 0; 
  do { 
    port = randomPort();
    if (takenRandomPorts.contains(port)) {
      continue;
    }    
    takenRandomPorts.add(port);

    ...

  } while (port == 0);
  return port;
}

</description>
			<version>1.1.2</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
			<file type="M">org.apache.hadoop.hbase.TestHBaseTestingUtility.java</file>
		</fixedFiles>
	</bug>
	<bug id="14778" opendate="2015-11-06 17:58:06" fixdate="2015-11-10 21:59:07" resolution="Fixed">
		<buginformation>
			<summary>Make block cache hit percentages not integer in the metrics system</summary>
			<description>Once you&amp;amp;apos;re close to the 90%+ it&amp;amp;apos;s hard to see a difference because getting a full percent change is rare.</description>
			<version>1.1.2</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperStub.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapper.java</file>
		</fixedFiles>
	</bug>
	<bug id="14788" opendate="2015-11-09 16:33:33" fixdate="2015-11-11 02:42:22" resolution="Fixed">
		<buginformation>
			<summary>Splitting a region does not support the hbase.rs.evictblocksonclose config when closing source region</summary>
			<description>i have a table with bucket cache turned on and hbase.rs.evictblocksonclose set to false.  I split a region and watched that the closing of the source region did not complete until the bucketcache was flushed for that region.</description>
			<version>1.0.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 0.98.17</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionFileSystem.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
		</fixedFiles>
	</bug>
	<bug id="13982" opendate="2015-06-28 09:33:22" fixdate="2015-11-11 06:33:21" resolution="Fixed">
		<buginformation>
			<summary>Add info for visibility labels/cell TTLs to ImportTsv</summary>
			<description>HBASE-9832 added support for two more optional, special TSV columns, but no usage info was added. Add.</description>
			<version>1.1.0.1</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.1.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.ImportTsv.java</file>
		</fixedFiles>
	</bug>
	<bug id="14802" opendate="2015-11-12 22:09:50" fixdate="2015-11-15 23:02:42" resolution="Fixed">
		<buginformation>
			<summary>Replaying server crash recovery procedure after a failover causes incorrect handling of deadservers</summary>
			<description>The way dead servers are processed is that a ServerCrashProcedure is launched for a server after it is added to the dead servers list. 
Every time a server is added to the dead list, a counter "numProcessing" is incremented and it is decremented when a crash recovery procedure finishes. Since, adding a dead server and recovering it are two separate events, it can cause inconsistencies.
If a master failover occurs in the middle of the crash recovery, the numProcessing counter resets but the ServerCrashProcedure is replayed by the new master. This causes the counter to go negative and makes the master think that dead servers are still in process of recovery. 
This has ramifications on the balancer that the balancer ceases to run after such a failover.</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.TestDeadServer.java</file>
			<file type="M">org.apache.hadoop.hbase.master.procedure.ServerCrashProcedure.java</file>
			<file type="M">org.apache.hadoop.hbase.master.DeadServer.java</file>
		</fixedFiles>
	</bug>
	<bug id="14809" opendate="2015-11-13 20:09:54" fixdate="2015-11-16 17:36:32" resolution="Fixed">
		<buginformation>
			<summary>Grant / revoke Namespace admin permission to group </summary>
			<description>Hi, 
We are looking to roll out HBase and are in the process to design the security model. 
We are looking to implement global DBAs and Namespace specific administrators. 
So for example the global dba would create a namespace and grant a user/group admin privileges within that ns. 
So that a given ns admin can in turn create objects and grant permission within the given ns only. 
We have run into some issues at the ns admin level. It appears that a ns admin can NOT grant to a grop unless it also has global admin privilege. But once it has global admin privilege it can grant in any NS not just the one where it has admin privileges. 
Based on the HBase documentation at http://hbase.apache.org/book.html#appendix_acl_matrix 
Table 13. ACL Matrix 
Interface	Operation	Permissions 
AccessController grant(global level) global(A) 
grant(namespace level) global(A)|NS(A) 
grant at a namespace level should be possible for someone with global A OR (|) NS A permission. 
As you will see in our test it does not work if NS A permission is granted but global A permission is not. 
Here you can see that group hbaseappltest_ns1admin has XCA permission on ns1. 


hbase(main):011:0&amp;gt; scan &amp;amp;apos;hbase:acl&amp;amp;apos; 
ROW COLUMN+CELL 
@ns1 column=l:@hbaseappltest_ns1admin, timestamp=1446676679787, value=XCA 


However: 
Here you can see that a user who is member of the group hbaseappltest_ns1admin can not grant a WRX privilege to a group as it is missing global A privilege. 


$hbase shell 
15/11/13 10:02:23 INFO Configuration.deprecation: hadoop.native.lib is deprecated. Instead, use io.native.lib.available 
HBase Shell; enter &amp;amp;apos;help&amp;lt;RETURN&amp;gt;&amp;amp;apos; for list of supported commands. 
Type "exit&amp;lt;RETURN&amp;gt;" to leave the HBase Shell 
Version 1.0.0-cdh5.4.7, rUnknown, Thu Sep 17 02:25:03 PDT 2015 

hbase(main):001:0&amp;gt; whoami 
ns1admin@WLAB.NET (auth:KERBEROS) 
groups: hbaseappltest_ns1admin 

hbase(main):002:0&amp;gt; grant &amp;amp;apos;@hbaseappltest_ns1funct&amp;amp;apos; ,&amp;amp;apos;RWX&amp;amp;apos;,&amp;amp;apos;@ns1&amp;amp;apos; 

ERROR: org.apache.hadoop.hbase.security.AccessDeniedException: Insufficient permissions for user &amp;amp;apos;ns1admin&amp;amp;apos; (global, action=ADMIN) 


The way I read the documentation a NS admin should be able to grant as it has ns level A privilege not only object level permission.
CDH is a version 5.4.7 and Hbase is version 1.0. 
Regards, 
Steven</description>
			<version>1.0.2</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.1.3, 0.98.19</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.security.access.AccessController.java</file>
			<file type="M">org.apache.hadoop.hbase.security.access.TestNamespaceCommands.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">14870</link>
		</links>
	</bug>
	<bug id="14793" opendate="2015-11-10 18:56:05" fixdate="2015-11-17 18:45:48" resolution="Fixed">
		<buginformation>
			<summary>Allow limiting size of block into L1 block cache.</summary>
			<description>G1GC does really badly with long lived large objects. Lets allow limiting the size of a block that can be kept in the block cache.</description>
			<version>1.1.2</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 0.98.17</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestMetricsRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.CacheStats.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.TestLruBlockCache.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapper.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperStub.java</file>
		</fixedFiles>
		<links>
			<link type="Regression" description="breaks">16300</link>
		</links>
	</bug>
	<bug id="14812" opendate="2015-11-14 00:05:33" fixdate="2015-11-17 22:51:18" resolution="Fixed">
		<buginformation>
			<summary>Fix ResultBoundedCompletionService deadlock</summary>
			<description>

"thrift2-worker-0" #31 daemon prio=5 os_prio=0 tid=0x00007f5ad9c45000 nid=0x484 in Object.wait() [0x00007f5aa3832000]
   java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.hadoop.hbase.client.ResultBoundedCompletionService.take(ResultBoundedCompletionService.java:148)
        - locked &amp;lt;0x00000006b6ae7670&amp;gt; (a [Lorg.apache.hadoop.hbase.client.ResultBoundedCompletionService$QueueingFuture;)
        at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:188)
        at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:59)
        at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:200)
        at org.apache.hadoop.hbase.client.ClientSmallReversedScanner.loadCache(ClientSmallReversedScanner.java:212)
        at org.apache.hadoop.hbase.client.ClientSmallReversedScanner.next(ClientSmallReversedScanner.java:186)
        at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegionInMeta(ConnectionManager.java:1276)
        at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion(ConnectionManager.java:1182)
        at org.apache.hadoop.hbase.client.AsyncProcess.submit(AsyncProcess.java:370)
        at org.apache.hadoop.hbase.client.AsyncProcess.submit(AsyncProcess.java:321)
        at org.apache.hadoop.hbase.client.BufferedMutatorImpl.backgroundFlushCommits(BufferedMutatorImpl.java:194)
        at org.apache.hadoop.hbase.client.BufferedMutatorImpl.flush(BufferedMutatorImpl.java:171)
        - locked &amp;lt;0x00000006b6ae79c0&amp;gt; (a org.apache.hadoop.hbase.client.BufferedMutatorImpl)
        at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:1430)
        at org.apache.hadoop.hbase.client.HTable.put(HTable.java:1033)
        at org.apache.hadoop.hbase.thrift2.ThriftHBaseServiceHandler.putMultiple(ThriftHBaseServiceHandler.java:268)
        at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:497)
        at org.apache.hadoop.hbase.thrift2.ThriftHBaseServiceHandler$THBaseServiceMetricsProxy.invoke(ThriftHBaseServiceHandler.java:114)
        at com.sun.proxy.$Proxy10.putMultiple(Unknown Source)
        at org.apache.hadoop.hbase.thrift2.generated.THBaseService$Processor$putMultiple.getResult(THBaseService.java:1637)
        at org.apache.hadoop.hbase.thrift2.generated.THBaseService$Processor$putMultiple.getResult(THBaseService.java:1621)
        at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
        at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
        at org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:478)
        at org.apache.thrift.server.Invocation.run(Invocation.java:18)
        at org.apache.hadoop.hbase.thrift.CallQueue$Call.run(CallQueue.java:64)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)


</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.1.4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.ResultBoundedCompletionService.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">15140</link>
		</links>
	</bug>
	<bug id="14815" opendate="2015-11-15 07:13:10" fixdate="2015-11-18 17:06:42" resolution="Fixed">
		<buginformation>
			<summary>TestMobExportSnapshot.testExportFailure timeout occasionally</summary>
			<description>On master,  TestMobExportSnapshot.testExportFailure timeout occasionally.
See
https://builds.apache.org/job/PreCommit-HBASE-Build/16514//testReport/org.apache.hadoop.hbase.snapshot/TestMobExportSnapshot/testExportFailure/
https://builds.apache.org/job/PreCommit-HBASE-Build/16511//testReport/org.apache.hadoop.hbase.snapshot/TestMobExportSnapshot/testExportFailure/</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.snapshot.TestExportSnapshot.java</file>
		</fixedFiles>
	</bug>
	<bug id="14811" opendate="2015-11-13 21:01:23" fixdate="2015-11-19 00:48:07" resolution="Duplicate">
		<buginformation>
			<summary>HBaseInterClusterReplicationEndpoint retry logic is broken</summary>
			<description>In HBaseInterClusterReplicationEndpoint, we do something like this:


entryLists.remove(f.get());


where f.get() returns an ordinal number which represents the index of the element in the entryLists that just succeeded replicating. We remove these entries because we want to retry with remaining elements in the list in case of a failure. Since entryLists is an ArrayList, the subsequent elements are shifted left in case we remove an element. This breaks the intended functionality. The fix is to reverse sort the ordinals and then perform the deletion in one go.</description>
			<version>0.98.16</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.TestReplicationEndpoint.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.TestReplicationBase.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.TestReplicationChangingPeerRegionservers.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">14777</link>
		</links>
	</bug>
	<bug id="14782" opendate="2015-11-06 20:54:41" fixdate="2015-11-19 03:57:00" resolution="Fixed">
		<buginformation>
			<summary>FuzzyRowFilter skips valid rows</summary>
			<description>The issue may affect not only master branch, but previous releases as well.
This is from one of our customers:

We are experiencing a problem with the FuzzyRowFilter for HBase scan. We think that it is a bug. 
Fuzzy filter should pick a row if it matches filter criteria irrespective of other rows present in table but filter is dropping a row depending on some other row present in table. 
Details/Step to reproduce/Sample outputs below: 
Missing row key: \x9C\x00\x044\x00\x00\x00\x00 
Causing row key: \x9C\x00\x03\xE9e\xBB{X\x1Fwts\x1F\x15vRX 
Prerequisites 
1. Create a test table. HBase shell command  create &amp;amp;apos;fuzzytest&amp;amp;apos;,&amp;amp;apos;d&amp;amp;apos; 
2. Insert some test data. HBase shell commands: 
 put &amp;amp;apos;fuzzytest&amp;amp;apos;,"\x9C\x00\x044\x00\x00\x00\x00",&amp;amp;apos;d:a&amp;amp;apos;,&amp;amp;apos;junk&amp;amp;apos; 
 put &amp;amp;apos;fuzzytest&amp;amp;apos;,"\x9C\x00\x044\x01\x00\x00\x00",&amp;amp;apos;d:a&amp;amp;apos;,&amp;amp;apos;junk&amp;amp;apos; 
 put &amp;amp;apos;fuzzytest&amp;amp;apos;,"\x9C\x00\x044\x00\x01\x00\x00",&amp;amp;apos;d:a&amp;amp;apos;,&amp;amp;apos;junk&amp;amp;apos; 
 put &amp;amp;apos;fuzzytest&amp;amp;apos;,"\x9C\x00\x044\x00\x00\x01\x00",&amp;amp;apos;d:a&amp;amp;apos;,&amp;amp;apos;junk&amp;amp;apos; 
 put &amp;amp;apos;fuzzytest&amp;amp;apos;,"\x9C\x00\x044\x00\x01\x00\x01",&amp;amp;apos;d:a&amp;amp;apos;,&amp;amp;apos;junk&amp;amp;apos; 
 put &amp;amp;apos;fuzzytest&amp;amp;apos;,"\x9B\x00\x044e\xBB\xB2\xBB",&amp;amp;apos;d:a&amp;amp;apos;,&amp;amp;apos;junk&amp;amp;apos; 
 put &amp;amp;apos;fuzzytest&amp;amp;apos;,"\x9D\x00\x044e\xBB\xB2\xBB",&amp;amp;apos;d:a&amp;amp;apos;,&amp;amp;apos;junk&amp;amp;apos; 
Now when you run the code, you will find \x9C\x00\x044\x00\x00\x00\x00 in output because it matches filter criteria. (Refer how to run code below) 
Insert the row key causing bug: 
HBase shell command: put &amp;amp;apos;fuzzytest&amp;amp;apos;,"\x9C\x00\x03\xE9e\xBB{X\x1Fwts\x1F\x15vRX",&amp;amp;apos;d:a&amp;amp;apos;,&amp;amp;apos;junk&amp;amp;apos; 
Now when you run the code, you will not find \x9C\x00\x044\x00\x00\x00\x00 in output even though it still matches filter criteria. 
Verified the issue on master.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.1.3, 0.98.17</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.filter.FuzzyRowFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.TestFuzzyRowFilterEndToEnd.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.TestFuzzyRowFilter.java</file>
		</fixedFiles>
	</bug>
	<bug id="14761" opendate="2015-11-04 17:52:23" fixdate="2015-11-19 08:47:21" resolution="Fixed">
		<buginformation>
			<summary>Deletes with and without visibility expression do not delete the matching mutation</summary>
			<description>This is from the user list as reported by Anoop Sharma


 running into an issue related to visibility expressions and delete.
Example run from hbase shell is listed below.
Will appreciate any help on this issue.
thanks.
In the example below, user running queries has MANAGER authorization.
*First example:*

  add a column with visib expr MANAGER

  delete it by passing in visibility of MANAGER
  This works and scan doesnt return anything.
*Second example:*

  add a column with visib expr MANAGER

  delete it by not passing in any visibility.
  This doesnt delete the column.
  Scan doesnt return the row but RAW scan shows the column
  marked as deleteColumn.
  Now if delete is done again with visibility of MANAGER,
  it still doesnt delete it and scan returns the original column.

*Example 1:*
hbase(main):096:0&amp;gt; create &amp;amp;apos;HBT1&amp;amp;apos;, &amp;amp;apos;cf&amp;amp;apos;
hbase(main):098:0* *put &amp;amp;apos;HBT1&amp;amp;apos;, &amp;amp;apos;John&amp;amp;apos;, &amp;amp;apos;cf:a&amp;amp;apos;, &amp;amp;apos;CA&amp;amp;apos;,
{VISIBILITY=&amp;gt;&amp;amp;apos;MANAGER&amp;amp;apos;}*
hbase(main):099:0&amp;gt; *scan &amp;amp;apos;HBT1&amp;amp;apos;*
ROW
COLUMN+CELL

 John                 column=cf:a, timestamp=1446154722055,
value=CA
1 row(s) in 0.0030 seconds
hbase(main):100:0&amp;gt; *delete &amp;amp;apos;HBT1&amp;amp;apos;, &amp;amp;apos;John&amp;amp;apos;, &amp;amp;apos;cf:a&amp;amp;apos;, {VISIBILITY=&amp;gt;&amp;amp;apos;MANAGER&amp;amp;apos;}*
0 row(s) in 0.0030 seconds

hbase(main):101:0&amp;gt; *scan &amp;amp;apos;HBT1&amp;amp;apos;*
ROW
COLUMN+CELL
0 row(s) in 0.0030 seconds

*Example 2:*

hbase(main):010:0* *put &amp;amp;apos;HBT1&amp;amp;apos;, &amp;amp;apos;John&amp;amp;apos;, &amp;amp;apos;cf:a&amp;amp;apos;, &amp;amp;apos;CA&amp;amp;apos;,
{VISIBILITY=&amp;gt;&amp;amp;apos;MANAGER&amp;amp;apos;}*
0 row(s) in 0.0040 seconds

hbase(main):011:0&amp;gt; *scan &amp;amp;apos;HBT1&amp;amp;apos;*
ROW
COLUMN+CELL
 John                 column=cf:a, timestamp=1446155346473,
value=CA
1 row(s) in 0.0060 seconds

hbase(main):012:0&amp;gt; *delete &amp;amp;apos;HBT1&amp;amp;apos;, &amp;amp;apos;John&amp;amp;apos;, &amp;amp;apos;cf:a&amp;amp;apos;*
0 row(s) in 0.0090 seconds

hbase(main):013:0&amp;gt; *scan &amp;amp;apos;HBT1&amp;amp;apos;*
ROW
COLUMN+CELL
 John                 column=cf:a, timestamp=1446155346473,
value=CA
1 row(s) in 0.0050 seconds
hbase(main):014:0&amp;gt; *scan &amp;amp;apos;HBT1&amp;amp;apos;, {RAW =&amp;gt; true}*

ROW
COLUMN+CELL
 John                 column=cf:a, timestamp=1446155346519,
type=DeleteColumn
1 row(s) in 0.0060 seconds

hbase(main):015:0&amp;gt; *delete &amp;amp;apos;HBT1&amp;amp;apos;, &amp;amp;apos;John&amp;amp;apos;, &amp;amp;apos;cf:a&amp;amp;apos;, {VISIBILITY=&amp;gt;&amp;amp;apos;MANAGER&amp;amp;apos;}*
0 row(s) in 0.0030 seconds
hbase(main):016:0&amp;gt; *scan &amp;amp;apos;HBT1&amp;amp;apos;*
ROW
COLUMN+CELL
 John                 column=cf:a, timestamp=1446155346473,
value=CA
1 row(s) in 0.0040 seconds
hbase(main):017:0&amp;gt; *scan &amp;amp;apos;HBT1&amp;amp;apos;, {RAW =&amp;gt; true}*
ROW
COLUMN+CELL
 John                 column=cf:a, timestamp=1446155346601,
type=DeleteColumn

1 row(s) in 0.0060 seconds

</description>
			<version>0.98.15</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.0.3, 1.1.3, 0.98.17</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.security.visibility.VisibilityScanDeleteTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithDeletes.java</file>
		</fixedFiles>
	</bug>
	<bug id="14840" opendate="2015-11-19 08:37:03" fixdate="2015-11-20 10:32:56" resolution="Fixed">
		<buginformation>
			<summary>Sink cluster reports data replication request as success though the data is not replicated</summary>
			<description>Scenario:
Sink cluster is down
Create a table and enable table replication
Put some data
Now restart the sink cluster
Observance:
Data is not replicated in sink cluster but still source cluster updates the WAL log position in ZK, resulting in data loss in sink cluster.</description>
			<version>0.98.16</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.0.3, 1.1.3, 0.98.17</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.TestMasterReplication.java</file>
		</fixedFiles>
	</bug>
	<bug id="14861" opendate="2015-11-20 13:04:48" fixdate="2015-11-24 23:02:45" resolution="Fixed">
		<buginformation>
			<summary>HBASE_ZNODE_FILE on master server is overwritten by regionserver process in case of master-rs collocation </summary>
			<description>In case of master-rs collocation HBASE_ZNODE_FILE is overwritten by regionserver process in HRegionServer#handleReportForDutyResponse() here is how it looks on master server:


[hbase@hnode2 hbase]$ cat hbase-hbase-master.znode 
/hbase/rs/hnode2,16000,1448022074888


it contains regionserver znode path instead of String value of master&amp;amp;apos;s ServerName.  This affects ZNodeClearer#clear() in way that will not clear master znode in case we detect master crash. At end this will extend  failover time until master znode expires configured in zookeeper by maxSessionTimeout parameter (40s in my case).
I have notice this on mater branch but it can be case in other branches where we are collocating master and rs.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ZNodeClearer.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">14664</link>
		</links>
	</bug>
	<bug id="14463" opendate="2015-09-22 13:48:36" fixdate="2015-11-25 03:37:48" resolution="Fixed">
		<buginformation>
			<summary>Severe performance downgrade when parallel reading a single key from BucketCache</summary>
			<description>We store feature data of online items in HBase, do machine learning on these features, and supply the outputs to our online search engine. In such scenario we will launch hundreds of yarn workers and each worker will read all features of one item(i.e. single rowkey in HBase), so there&amp;amp;apos;ll be heavy parallel reading on a single rowkey.
We were using LruCache but start to try BucketCache recently to resolve gc issue, and just as titled we have observed severe performance downgrade. After some analytics we found the root cause is the lock in BucketCache#getBlock, as shown below


      try {
        lockEntry = offsetLock.getLockEntry(bucketEntry.offset());
        // ...
        if (bucketEntry.equals(backingMap.get(key))) {
          // ...
          int len = bucketEntry.getLength();
          Cacheable cachedBlock = ioEngine.read(bucketEntry.offset(), len,
              bucketEntry.deserializerReference(this.deserialiserMap));


Since ioEnging.read involves array copy, it&amp;amp;apos;s much more time-costed than the operation in LruCache. And since we&amp;amp;apos;re using synchronized in IdLock#getLockEntry, parallel read dropping on the same bucket would be executed in serial, which causes a really bad performance.
To resolve the problem, we propose to use ReentranceReadWriteLock in BucketCache, and introduce a new class called IdReadWriteLock to implement it.</description>
			<version>0.98.14</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.CacheTestUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.bucket.TestBucketCache.java</file>
		</fixedFiles>
		<links>
			<link type="dependent" description="depends upon">14268</link>
		</links>
	</bug>
	<bug id="14885" opendate="2015-11-25 19:49:58" fixdate="2015-11-26 00:11:57" resolution="Fixed">
		<buginformation>
			<summary>NullPointerException in HMaster#normalizeRegions() due to missing TableDescriptor</summary>
			<description>During system test on Windows, we observed the following in master log:


2015-11-23 11:31:38,853 ERROR org.apache.hadoop.hbase.master.normalizer.RegionNormalizerChore: Caught error^M
java.lang.NullPointerException^M
  at org.apache.hadoop.hbase.master.HMaster.normalizeRegions(HMaster.java:1396)^M
  at org.apache.hadoop.hbase.master.normalizer.RegionNormalizerChore.chore(RegionNormalizerChore.java:49)^M
  at org.apache.hadoop.hbase.ScheduledChore.run(ScheduledChore.java:185)^M
  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)^M
  at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)^M
  at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)^M
  at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)^M
  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)^M
  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)^M
  at java.lang.Thread.run(Thread.java:745)^M


The NullPointerException came from the second line below:


      for(TableName table : allEnabledTables) {
        if (table.isSystemTable() || !getTableDescriptors().get(table).isNormalizationEnabled()) {


It seems TableDescriptor for some table was absent.
normalizeRegions() should deal with such scenario without producing NPE.</description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
		</fixedFiles>
	</bug>
	<bug id="14777" opendate="2015-11-06 10:32:50" fixdate="2015-11-26 05:21:16" resolution="Fixed">
		<buginformation>
			<summary>Fix Inter Cluster Replication Future ordering issues</summary>
			<description>Replication fails with IndexOutOfBoundsException 


regionserver.ReplicationSource$ReplicationSourceWorkerThread(939): org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint threw unknown exception:java.lang.IndexOutOfBoundsException: Index: 1, Size: 1
	at java.util.ArrayList.rangeCheck(Unknown Source)
	at java.util.ArrayList.remove(Unknown Source)
	at org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint.replicate(HBaseInterClusterReplicationEndpoint.java:222)


Its happening due to incorrect removal of entries from the replication entries list. </description>
			<version>0.98.16</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.TestReplicationEndpoint.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.TestReplicationBase.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.TestReplicationChangingPeerRegionservers.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">14811</link>
			<link type="Regression" description="is broken by">12988</link>
		</links>
	</bug>
	<bug id="14896" opendate="2015-11-30 14:00:55" fixdate="2015-12-01 17:35:36" resolution="Fixed">
		<buginformation>
			<summary>Resolve Javadoc warnings in WALKey and RegionMover</summary>
			<description>As titled, observed below warnings in HadoopQA result for HBASE-14891:

[WARNING] Javadoc Warnings
[WARNING] /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/hbase/hbase-server/src/main/java/org/apache/hadoop/hbase/wal/WALKey.java:94: warning - Tag @see:illegal character: "123" in "{@link #setWriteEntry(MultiVersionConcurrencyControl.WriteEntry)}"
[WARNING] /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/hbase/hbase-server/src/main/java/org/apache/hadoop/hbase/wal/WALKey.java:94: warning - Tag @see:illegal character: "64" in "{@link #setWriteEntry(MultiVersionConcurrencyControl.WriteEntry)}"
[WARNING] /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/hbase/hbase-server/src/main/java/org/apache/hadoop/hbase/wal/WALKey.java:94: warning - Tag @see: reference not found: {@link #setWriteEntry(MultiVersionConcurrencyControl.WriteEntry)}
[WARNING] /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/hbase/hbase-server/src/main/java/org/apache/hadoop/hbase/util/RegionMover.java:111: warning - Tag @link: can&amp;amp;apos;t find RegionMover(String) in org.apache.hadoop.hbase.util.RegionMover.RegionMoverBuilder


This JIRA targets at resolving these warnings</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.wal.WALKey.java</file>
			<file type="M">org.apache.hadoop.hbase.util.RegionMover.java</file>
		</fixedFiles>
	</bug>
	<bug id="14905" opendate="2015-12-02 04:32:47" fixdate="2015-12-04 00:16:47" resolution="Fixed">
		<buginformation>
			<summary>VerifyReplication does not honour versions option</summary>
			<description>source:
hbase(main):001:0&amp;gt; scan &amp;amp;apos;t1&amp;amp;apos;, 
{RAW =&amp;gt; true, VERSIONS =&amp;gt; 100}
ROW                                      COLUMN+CELL                                                                                                           
 r1                                      column=f1:, timestamp=1449030102091, value=value1112                                                                  
 r1                                      column=f1:, timestamp=1449029774173, value=value1001                                                                  
 r1                                      column=f1:, timestamp=1449029709974, value=value1002                                                                  

target:
hbase(main):023:0&amp;gt; scan &amp;amp;apos;t1&amp;amp;apos;, {RAW =&amp;gt; true, VERSIONS =&amp;gt; 100}
ROW                                      COLUMN+CELL                                                                                                           
 r1                                      column=f1:, timestamp=1449030102091, value=value1112                                                                  
 r1                                      column=f1:, timestamp=1449030090758, value=value1112                                                                  
 r1                                      column=f1:, timestamp=1449029984282, value=value1111                                                                  
 r1                                      column=f1:, timestamp=1449029774173, value=value1001                                                                  
 r1                                      column=f1:, timestamp=1449029709974, value=value1002   
/bin/hbase org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication --versions=100 1 t1
org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication$Verifier$Counters
		GOODROWS=1
Does not show any mismatch. Ideally it should show. This is because in 
VerifyReplication Class maxVersion is not correctly set.</description>
			<version>0.98.16</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 0.98.17</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.TestReplicationSmallTests.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.TestReplicationBase.java</file>
		</fixedFiles>
	</bug>
	<bug id="13857" opendate="2015-06-08 14:16:44" fixdate="2015-12-04 01:02:06" resolution="Fixed">
		<buginformation>
			<summary>Slow WAL Append count in ServerMetricsTmpl.jamon is hardcoded to zero</summary>
			<description>The template has this:

 &amp;lt;tr&amp;gt;
        ...
        &amp;lt;th&amp;gt;Slow WAL Append Count&amp;lt;/th&amp;gt;
    &amp;lt;/tr&amp;gt;
    &amp;lt;tr&amp;gt;
        ....
        &amp;lt;td&amp;gt;&amp;lt;% 0 %&amp;gt;&amp;lt;/td&amp;gt;
    &amp;lt;/tr&amp;gt;

</description>
			<version>0.98.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.MetricsWALSourceImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.MetricsWALSource.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapper.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestMetricsWAL.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperStub.java</file>
		</fixedFiles>
		<links>
			<link type="Regression" description="is broken by">6410</link>
		</links>
	</bug>
	<bug id="14926" opendate="2015-12-04 06:25:45" fixdate="2015-12-04 22:06:34" resolution="Fixed">
		<buginformation>
			<summary>Hung ThriftServer; no timeout on read from client; if client crashes, worker thread gets stuck reading</summary>
			<description>Thrift server is hung. All worker threads are doing this:


"thrift-worker-0" daemon prio=10 tid=0x00007f0bb95c2800 nid=0xf6a7 runnable [0x00007f0b956e0000]
   java.lang.Thread.State: RUNNABLE
        at java.net.SocketInputStream.socketRead0(Native Method)
        at java.net.SocketInputStream.read(SocketInputStream.java:152)
        at java.net.SocketInputStream.read(SocketInputStream.java:122)
        at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)
        at java.io.BufferedInputStream.read1(BufferedInputStream.java:275)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
        - locked &amp;lt;0x000000066d859490&amp;gt; (a java.io.BufferedInputStream)
        at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:127)
        at org.apache.thrift.transport.TTransport.readAll(TTransport.java:84)
        at org.apache.thrift.transport.TFramedTransport.readFrame(TFramedTransport.java:129)
        at org.apache.thrift.transport.TFramedTransport.read(TFramedTransport.java:101)
        at org.apache.thrift.transport.TTransport.readAll(TTransport.java:84)
        at org.apache.thrift.protocol.TCompactProtocol.readByte(TCompactProtocol.java:601)
        at org.apache.thrift.protocol.TCompactProtocol.readMessageBegin(TCompactProtocol.java:470)
        at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:27)
        at org.apache.hadoop.hbase.thrift.TBoundedThreadPoolServer$ClientConnnection.run(TBoundedThreadPoolServer.java:289)
        at org.apache.hadoop.hbase.thrift.CallQueue$Call.run(CallQueue.java:64)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:745)


They never recover.
I don&amp;amp;apos;t have client side logs.
We&amp;amp;apos;ve been here before: HBASE-4967 "connected client thrift sockets should have a server side read timeout" but this patch only got applied to fb branch (and thrift has changed since then).
</description>
			<version>0.98.16</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 0.98.17</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.thrift.ThriftServer.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift2.ThriftServer.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
		</fixedFiles>
	</bug>
	<bug id="14922" opendate="2015-12-03 10:03:28" fixdate="2015-12-05 01:00:24" resolution="Fixed">
		<buginformation>
			<summary>Delayed flush doesn&amp;apos;t work causing flush storms.</summary>
			<description>Starting all regionservers at the same time will mean that most PeriodicMemstoreFlusher&amp;amp;apos;s will be running at the same time. So all of these threads will queue flushes at about the same time.
This was supposed to be mitigated by Delayed. However that isn&amp;amp;apos;t nearly enough. This results in the immediate filling up and then draining of the flush queues every hour.</description>
			<version>1.1.2</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.JitterScheduledThreadPoolExecutorImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.ChoreService.java</file>
			<file type="M">org.apache.hadoop.hbase.TestChoreService.java</file>
		</fixedFiles>
	</bug>
	<bug id="14923" opendate="2015-12-03 11:48:26" fixdate="2015-12-05 02:55:17" resolution="Fixed">
		<buginformation>
			<summary>VerifyReplication should not mask the exception during result comparison </summary>
			<description>hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/replication/VerifyReplication.java
Line:154
 } catch (Exception e) 
{
            logFailRowAndIncreaseCounter(context, Counters.CONTENT_DIFFERENT_ROWS, value);
          }

Just LOG.error needs to be added for more information for the failure.</description>
			<version>0.98.16</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.0.3, 1.1.3, 0.98.17</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication.java</file>
		</fixedFiles>
	</bug>
	<bug id="14954" opendate="2015-12-09 02:21:50" fixdate="2015-12-09 15:22:30" resolution="Fixed">
		<buginformation>
			<summary>IllegalArgumentException was thrown when doing online configuration change in CompactSplitThread</summary>
			<description>Online configuration change is a terrific feature for HBase administrators. However, when we use this feature to tune compaction thread pool size online, it triggered a IllegalArgumentException. The cause is the order of setMaximumPoolSize() and setCorePoolSize() of ThreadPoolExecutor: when turning parameters bigger, we should setMax first; when turning parameters smaller, we need to setCore first. Besides, there is also a copy-code bug in merge and split thread pool which I will fix together.</description>
			<version>1.1.2</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.1.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.CompactSplitThread.java</file>
		</fixedFiles>
	</bug>
	<bug id="14942" opendate="2015-12-07 18:29:02" fixdate="2015-12-09 23:40:23" resolution="Fixed">
		<buginformation>
			<summary>Allow turning off BoundedByteBufferPool</summary>
			<description>The G1 does a great job of compacting, there&amp;amp;apos;s no reason to use the BoundedByteBufferPool when the JVM can it for us. So we should allow turning this off for people who are running new jvm&amp;amp;apos;s where the G1 is working well.</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.RpcServer.java</file>
		</fixedFiles>
	</bug>
	<bug id="14901" opendate="2015-12-01 23:37:18" fixdate="2015-12-10 22:52:33" resolution="Fixed">
		<buginformation>
			<summary>There is duplicated code to create/manage encryption keys</summary>
			<description>There is duplicated code from MobUtils.createEncryptionContext in HStore, and there is a subset of that code in HFileReaderImpl.
Refactored key selection 
Moved both to EncryptionUtil.java
Can&amp;amp;apos;t figure out how to write a unit test for this, but there&amp;amp;apos;s no new code just refactoring.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.security.EncryptionUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.mob.compactions.PartitionedMobCompactor.java</file>
			<file type="M">org.apache.hadoop.hbase.security.TestEncryptionUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.mob.MobUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFileReaderImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.mob.mapreduce.MemStoreWrapper.java</file>
		</fixedFiles>
		<links>
			<link type="Cloners" description="is cloned by">14964</link>
		</links>
	</bug>
	<bug id="14953" opendate="2015-12-08 22:55:59" fixdate="2015-12-11 21:22:27" resolution="Fixed">
		<buginformation>
			<summary>HBaseInterClusterReplicationEndpoint: Do not retry the whole batch of edits in case of RejectedExecutionException</summary>
			<description>When we have wal provider set to multiwal, the ReplicationSource has multiple worker threads submitting batches to HBaseInterClusterReplicationEndpoint. In such a scenario, it is quite common to encounter RejectedExecutionException because it takes quite long for shipping edits to peer cluster compared to reading edits from source and submitting more batches to the endpoint. 
The logs are just filled with warnings due to this very exception.
Since we subdivide batches before actually shipping them, we don&amp;amp;apos;t need to fail and resend the whole batch if one of the sub-batches fails with RejectedExecutionException. Rather, we should just retry the failed sub-batches. </description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint.java</file>
		</fixedFiles>
	</bug>
	<bug id="14936" opendate="2015-12-07 09:54:17" fixdate="2015-12-14 10:56:41" resolution="Fixed">
		<buginformation>
			<summary>CombinedBlockCache should overwrite CacheStats#rollMetricsPeriod()</summary>
			<description>It seems CombinedBlockCache should overwrite CacheStats#rollMetricsPeriod() as


public void rollMetricsPeriod() {
  lruCacheStats.rollMetricsPeriod();
  bucketCacheStats.rollMetricsPeriod();
}


otherwise, CombinedBlockCache.getHitRatioPastNPeriods() and CombinedBlockCache.getHitCachingRatioPastNPeriods() will always return 0.</description>
			<version>1.1.2</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.0.3, 1.1.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.hfile.CacheStats.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.CombinedBlockCache.java</file>
		</fixedFiles>
	</bug>
	<bug id="14838" opendate="2015-11-19 02:45:19" fixdate="2015-12-16 15:01:01" resolution="Fixed">
		<buginformation>
			<summary>Clarify that SimpleRegionNormalizer does not merge empty (&lt;1MB) regions</summary>
			<description>SImpleRegionNormalizer does not merge empty region of a table
Steps to repro:

Create an empty table with few, say 5-6 regions without any data in any of them
Verify hbase:meta table to verify the regions for the table or check HMaster UI
Enable normalizer switch and normalization for this table
Run normalizer, by &amp;amp;apos;normalize&amp;amp;apos; command from hbase shell
Verify the regions for table by scanning hbase:meta table or checking HMaster web UI

The empty regions are not merged on running the region normalizer. This seems to be an edge case with completely empty regions since the Normalizer checks for: smallestRegion (in this case 0 size) + smallestNeighborOfSmallestRegion (in this case 0 size) &amp;gt; avg region size (in this case 0 size)
thanks to Josh Elser for verifying this from the source code side</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.normalizer.SimpleRegionNormalizer.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">13103</link>
		</links>
	</bug>
	<bug id="14843" opendate="2015-11-19 13:40:26" fixdate="2015-12-16 15:18:10" resolution="Fixed">
		<buginformation>
			<summary>TestWALProcedureStore.testLoad is flakey</summary>
			<description>I see it twice recently, 
see.
https://builds.apache.org/job/PreCommit-HBASE-Build/16589//testReport/org.apache.hadoop.hbase.procedure2.store.wal/TestWALProcedureStore/testLoad/
https://builds.apache.org/job/PreCommit-HBASE-Build/16532/testReport/org.apache.hadoop.hbase.procedure2.store.wal/TestWALProcedureStore/testLoad/
Let&amp;amp;apos;s see what&amp;amp;apos;s happening.
Update.
It failed once again today, 
https://builds.apache.org/job/PreCommit-HBASE-Build/16602/testReport/junit/org.apache.hadoop.hbase.procedure2.store.wal/TestWALProcedureStore/testLoad/
</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.1.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.java</file>
			<file type="M">org.apache.hadoop.hbase.procedure2.store.wal.TestWALProcedureStore.java</file>
		</fixedFiles>
	</bug>
	<bug id="15000" opendate="2015-12-17 05:42:45" fixdate="2015-12-17 17:20:38" resolution="Fixed">
		<buginformation>
			<summary>Fix javadoc warn in LoadIncrementalHFiles</summary>
			<description>[WARNING] Javadoc Warnings
[WARNING] /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/hbase/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java:430: warning - @param argument "hfilesDir" is not a parameter name</description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
		</fixedFiles>
	</bug>
	<bug id="14822" opendate="2015-11-17 01:05:46" fixdate="2015-12-19 18:50:52" resolution="Fixed">
		<buginformation>
			<summary>Renewing leases of scanners doesn&amp;apos;t work</summary>
			<description></description>
			<version>0.98.14</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.0.3, 1.1.3, 0.98.17</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.TestLeaseRenewal.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.ClientProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ClientScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestFromClientSide3.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ScannerCallable.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">13333</link>
		</links>
	</bug>
	<bug id="14654" opendate="2015-10-20 10:03:54" fixdate="2015-12-22 03:34:36" resolution="Fixed">
		<buginformation>
			<summary>Reenable TestMultiParallel#testActiveThreadsCount</summary>
			<description>It was disabled in HBASE-14642,  this issue should reenable it.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestMultiParallel.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">14642</link>
		</links>
	</bug>
	<bug id="15001" opendate="2015-12-17 21:27:57" fixdate="2015-12-22 06:48:24" resolution="Fixed">
		<buginformation>
			<summary>Thread Safety issues in ReplicationSinkManager and HBaseInterClusterReplicationEndpoint</summary>
			<description>ReplicationSinkManager is not thread-safe. This can cause problems in HBaseInterClusterReplicationEndpoint,  when the walprovider is multiwal. 
For example: 
1. When multiple threads report bad sinks, the sink list can be non-empty but report a negative size because the ArrayList itself is not thread-safe. 
2. HBaseInterClusterReplicationEndpoint depends on the number of sinks to batch edits for shipping. However, it&amp;amp;apos;s quite possible that the following code makes it assume that there are no batches to process (sink size is non-zero, but by the time we reach the "batching" part, sink size becomes zero.)


if (replicationSinkMgr.getSinks().size() == 0) {
    return false;
}
...
int n = Math.min(Math.min(this.maxThreads, entries.size()/100+1),
               replicationSinkMgr.getSinks().size());


[Update] This leads to ArithmeticException: division by zero at:


entryLists.get(Math.abs(Bytes.hashCode(e.getKey().getEncodedRegionName())%n)).add(e);


which is benign and will just lead to retries by the ReplicationSource.
The idea is to make all operations in ReplicationSinkManager thread-safe and do a verification on the size of replicated edits before we report success.</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.TestReplicationSinkManager.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.ReplicationSinkManager.java</file>
		</fixedFiles>
	</bug>
	<bug id="15014" opendate="2015-12-18 21:09:22" fixdate="2015-12-22 07:08:07" resolution="Fixed">
		<buginformation>
			<summary>Fix filterCellByStore in WALsplitter is awful for performance</summary>
			<description>Testing the latest 1.2 I see this when there is a regionserver that crashes.


Thread 921 (RS_LOG_REPLAY_OPS-hbase2698:16020-0-Writer-1):
  State: RUNNABLE
  Blocked count: 6354
  Waited count: 6249
  Stack:
    org.apache.hadoop.hbase.KeyValue.equals(KeyValue.java:1128)
    java.util.ArrayList.indexOf(ArrayList.java:317)
    java.util.ArrayList.contains(ArrayList.java:300)
    java.util.ArrayList.batchRemove(ArrayList.java:720)
    java.util.ArrayList.removeAll(ArrayList.java:690)
    org.apache.hadoop.hbase.wal.WALSplitter$LogRecoveredEditsOutputSink.filterCellByStore(WALSplitter.java:1529)
    org.apache.hadoop.hbase.wal.WALSplitter$LogRecoveredEditsOutputSink.append(WALSplitter.java:1557)
    org.apache.hadoop.hbase.wal.WALSplitter$WriterThread.writeBuffer(WALSplitter.java:1113)
    org.apache.hadoop.hbase.wal.WALSplitter$WriterThread.doRun(WALSplitter.java:1105)
    org.apache.hadoop.hbase.wal.WALSplitter$WriterThread.run(WALSplitter.java:1075)
Thread 920 (RS_LOG_REPLAY_OPS-hbase2698:16020-0-Writer-0):
  State: TIMED_WAITING
  Blocked count: 17560
  Waited count: 19695
  Stack:
    java.lang.Object.wait(Native Method)
    org.apache.hadoop.hbase.wal.WALSplitter$WriterThread.doRun(WALSplitter.java:1093)
    org.apache.hadoop.hbase.wal.WALSplitter$WriterThread.run(WALSplitter.java:1075)
Thread 919 (RS_LOG_REPLAY_OPS-hbase2698:16020-0):
  State: TIMED_WAITING
  Blocked count: 115
  Waited count: 976
  Stack:
    java.lang.Object.wait(Native Method)
    org.apache.hadoop.hbase.wal.WALSplitter$EntryBuffers.appendEntry(WALSplitter.java:944)
    org.apache.hadoop.hbase.wal.WALSplitter.splitLogFile(WALSplitter.java:365)
    org.apache.hadoop.hbase.wal.WALSplitter.splitLogFile(WALSplitter.java:236)
    org.apache.hadoop.hbase.regionserver.SplitLogWorker$1.exec(SplitLogWorker.java:104)
    org.apache.hadoop.hbase.regionserver.handler.WALSplitterHandler.process(WALSplitterHandler.java:72)
    org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
    java.lang.Thread.run(Thread.java:745)


This has been going on for &amp;gt;10 mins.</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.wal.WALSplitter.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.WALEdit.java</file>
		</fixedFiles>
	</bug>
	<bug id="15028" opendate="2015-12-22 09:06:32" fixdate="2015-12-22 14:49:54" resolution="Fixed">
		<buginformation>
			<summary>Minor fix on RegionGroupingProvider</summary>
			<description>Currently in RegionGroupingProvider#getWAL(String) we&amp;amp;apos;re trying to get a WAL instance from the cache using walCacheLock as the key (a typo when fixing HBASE-14306, my fault...), while actually we should have used group name. This won&amp;amp;apos;t cause any fatal error but will slightly affect the perf since it will always run into the succeeding synchronized code. Will get this fixed in this JIRA</description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.wal.RegionGroupingProvider.java</file>
		</fixedFiles>
	</bug>
	<bug id="15030" opendate="2015-12-22 12:45:03" fixdate="2015-12-23 17:59:36" resolution="Fixed">
		<buginformation>
			<summary>Deadlock in master TableNamespaceManager while running IntegrationTestDDLMasterFailover</summary>
			<description>I was running IntegrationTestDDLMasterFailover on distributed cluster when i notice this. Here is relevant part of master&amp;amp;apos;s jstack:


"ProcedureExecutor-1" daemon prio=10 tid=0x00007fd2d407f800 nid=0x3332 waiting for monitor entry [0x00007fd2c2834000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at org.apache.hadoop.hbase.master.TableNamespaceManager.releaseExclusiveLock(TableNamespaceManager.java:157)
        - waiting to lock &amp;lt;0x0000000725c36a48&amp;gt; (a org.apache.hadoop.hbase.master.TableNamespaceManager)
        at org.apache.hadoop.hbase.master.procedure.CreateNamespaceProcedure.releaseLock(CreateNamespaceProcedure.java:216)
        at org.apache.hadoop.hbase.master.procedure.CreateNamespaceProcedure.releaseLock(CreateNamespaceProcedure.java:43)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execLoop(ProcedureExecutor.java:842)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execLoop(ProcedureExecutor.java:794)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.access$400(ProcedureExecutor.java:75)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor$2.run(ProcedureExecutor.java:479)

   Locked ownable synchronizers:
        - &amp;lt;0x000000072574b330&amp;gt; (a java.util.concurrent.locks.ReentrantReadWriteLock$NonfairSync)

"ProcedureExecutor-3" daemon prio=10 tid=0x00007fd2d41e5800 nid=0x3334 waiting on condition [0x00007fd2c2632000]
   java.lang.Thread.State: TIMED_WAITING (parking)
        at sun.misc.Unsafe.park(Native Method)
        - parking to wait for  &amp;lt;0x000000072574b330&amp;gt; (a java.util.concurrent.locks.ReentrantReadWriteLock$NonfairSync)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireNanos(AbstractQueuedSynchronizer.java:929)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireNanos(AbstractQueuedSynchronizer.java:1245)
        at java.util.concurrent.locks.ReentrantReadWriteLock$WriteLock.tryLock(ReentrantReadWriteLock.java:1115)
        at org.apache.hadoop.hbase.master.TableNamespaceManager.acquireExclusiveLock(TableNamespaceManager.java:150)
        - locked &amp;lt;0x0000000725c36a48&amp;gt; (a org.apache.hadoop.hbase.master.TableNamespaceManager)
        at org.apache.hadoop.hbase.master.procedure.CreateNamespaceProcedure.acquireLock(CreateNamespaceProcedure.java:210)
        at org.apache.hadoop.hbase.master.procedure.CreateNamespaceProcedure.acquireLock(CreateNamespaceProcedure.java:43)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.executeRollback(ProcedureExecutor.java:941)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execLoop(ProcedureExecutor.java:821)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execLoop(ProcedureExecutor.java:794)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.access$400(ProcedureExecutor.java:75)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor$2.run(ProcedureExecutor.java:479)

   Locked ownable synchronizers:
        - None

Found one Java-level deadlock:
=============================
"ProcedureExecutor-3":
  waiting for ownable synchronizer 0x000000072574b330, (a java.util.concurrent.locks.ReentrantReadWriteLock$NonfairSync),
  which is held by "ProcedureExecutor-1"
"ProcedureExecutor-1":
  waiting to lock monitor 0x00007fd2cc328908 (object 0x0000000725c36a48, a org.apache.hadoop.hbase.master.TableNamespaceManager),
  which is held by "ProcedureExecutor-3"

Java stack information for the threads listed above:
===================================================
"ProcedureExecutor-3":
        at sun.misc.Unsafe.park(Native Method)
        - parking to wait for  &amp;lt;0x000000072574b330&amp;gt; (a java.util.concurrent.locks.ReentrantReadWriteLock$NonfairSync)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireNanos(AbstractQueuedSynchronizer.java:929)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireNanos(AbstractQueuedSynchronizer.java:1245)
        at java.util.concurrent.locks.ReentrantReadWriteLock$WriteLock.tryLock(ReentrantReadWriteLock.java:1115)
        at org.apache.hadoop.hbase.master.TableNamespaceManager.acquireExclusiveLock(TableNamespaceManager.java:150)
        - locked &amp;lt;0x0000000725c36a48&amp;gt; (a org.apache.hadoop.hbase.master.TableNamespaceManager)
        at org.apache.hadoop.hbase.master.procedure.CreateNamespaceProcedure.acquireLock(CreateNamespaceProcedure.java:210)
        at org.apache.hadoop.hbase.master.procedure.CreateNamespaceProcedure.acquireLock(CreateNamespaceProcedure.java:43)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.executeRollback(ProcedureExecutor.java:941)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execLoop(ProcedureExecutor.java:821)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execLoop(ProcedureExecutor.java:794)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.access$400(ProcedureExecutor.java:75)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor$2.run(ProcedureExecutor.java:479)
"ProcedureExecutor-1":
        at org.apache.hadoop.hbase.master.TableNamespaceManager.releaseExclusiveLock(TableNamespaceManager.java:157)
        - waiting to lock &amp;lt;0x0000000725c36a48&amp;gt; (a org.apache.hadoop.hbase.master.TableNamespaceManager)
        at org.apache.hadoop.hbase.master.procedure.CreateNamespaceProcedure.releaseLock(CreateNamespaceProcedure.java:216)
        at org.apache.hadoop.hbase.master.procedure.CreateNamespaceProcedure.releaseLock(CreateNamespaceProcedure.java:43)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execLoop(ProcedureExecutor.java:842)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execLoop(ProcedureExecutor.java:794)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.access$400(ProcedureExecutor.java:75)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor$2.run(ProcedureExecutor.java:479)

Found 1 deadlock.


I will try to dig more info about why this happened logs not showing much.</description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.TableNamespaceManager.java</file>
		</fixedFiles>
	</bug>
	<bug id="15034" opendate="2015-12-23 09:55:11" fixdate="2015-12-24 13:01:24" resolution="Fixed">
		<buginformation>
			<summary>IntegrationTestDDLMasterFailover does not clean created namespaces </summary>
			<description>I was running this test recently and notice that after every run there are new namespaces created by test and not cleared when test is finished. </description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.IntegrationTestDDLMasterFailover.java</file>
		</fixedFiles>
	</bug>
	<bug id="14717" opendate="2015-10-29 11:56:19" fixdate="2015-12-24 19:22:29" resolution="Fixed">
		<buginformation>
			<summary>enable_table_replication command should only create specified table for a peer cluster</summary>
			<description>For a peer only user specified tables should be created but enable_table_replication command is not honouring that.
eg:
like peer1 : t1:cf1, t2
create &amp;amp;apos;t3&amp;amp;apos;, &amp;amp;apos;d&amp;amp;apos;
enable_table_replication &amp;amp;apos;t3&amp;amp;apos; &amp;gt; should not create t3 in peer1
</description>
			<version>1.0.2</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.replication.TestReplicationAdminWithClusters.java</file>
			<file type="M">org.apache.hadoop.hbase.client.replication.ReplicationAdmin.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.ReplicationPeerZKImpl.java</file>
		</fixedFiles>
	</bug>
	<bug id="15035" opendate="2015-12-23 19:46:40" fixdate="2015-12-25 21:17:07" resolution="Fixed">
		<buginformation>
			<summary>bulkloading hfiles with tags that require splits do not preserve tags</summary>
			<description>When an hfile is created with cell tags present and it is bulk loaded into hbase the tags will be present when loaded into a single region.  If the bulk load hfile spans multiple regions, bulk load automatically splits the original hfile into a set of split hfiles corresponding to each of the regions that the original covers.  
Since 0.98, tags are not copied into the newly created split hfiles. (the default for "includeTags" of the HFileContextBuilder [1] is uninitialized which defaults to false).   This means acls, ttls, mob pointers and other tag stored values will not be bulk loaded in.
[1] https://github.com/apache/hbase/blob/master/hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContextBuilder.java#L40
</description>
			<version>0.98.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.0.3, 1.1.3, 0.98.17</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TestSecureLoadIncrementalHFiles.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFilesUseSecurityEndPoint.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
			<file type="M">org.apache.hadoop.hbase.util.HFileTestUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFileContextBuilder.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFiles.java</file>
		</fixedFiles>
	</bug>
	<bug id="15050" opendate="2015-12-29 11:52:40" fixdate="2015-12-30 09:10:47" resolution="Fixed">
		<buginformation>
			<summary>Block Ref counting does not work in Region Split cases.</summary>
			<description>The reference counting on the blocks does not work correctly when the HalfStorefileReader is used for compaction/scans. 
The reason is that getFirstKey and getLastKey API create a new scanner but does not do the needed close() call and because of that we do not decrement the count on the blocks. The same impact will also be observed on the ref count that we maintain on the reader. Issue found when I was trying to test some other feature with lot of evictions. </description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.TestBlockEvictionFromClient.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFileReaderImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.io.HalfStoreFileReader.java</file>
		</fixedFiles>
	</bug>
	<bug id="15018" opendate="2015-12-21 09:44:35" fixdate="2015-12-30 20:55:32" resolution="Fixed">
		<buginformation>
			<summary>Inconsistent way of handling TimeoutException in the rpc client implementations</summary>
			<description>If there is any rpc timeout when using RpcClientImpl then we wrap the exception in IOE and throw it,

2015-11-16 04:05:24,935 WARN [main-EventThread.replicationSource,peer2] regionserver.HBaseInterClusterReplicationEndpoint: Can&amp;amp;apos;t replicate because of a local or network error:
java.io.IOException: Call to host-XX:16040 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call id=510, waitTime=180001, operationTimeout=180000 expired.
at org.apache.hadoop.hbase.ipc.RpcClientImpl.wrapException(RpcClientImpl.java:1271)
at org.apache.hadoop.hbase.ipc.RpcClientImpl.call(RpcClientImpl.java:1239)
at org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(AbstractRpcClient.java:213)
at org.apache.hadoop.hbase.ipc.AbstractRpcClient$BlockingRpcChannelImplementation.callBlockingMethod(AbstractRpcClient.java:287)
at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.replicateWALEntry(AdminProtos.java:25690)
at org.apache.hadoop.hbase.protobuf.ReplicationProtbufUtil.replicateWALEntry(ReplicationProtbufUtil.java:77)
at org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint$Replicator.call(HBaseInterClusterReplicationEndpoint.java:322)
at org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint$Replicator.call(HBaseInterClusterReplicationEndpoint.java:308)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.hbase.ipc.CallTimeoutException: Call id=510, waitTime=180001, operationTimeout=180000 expired.
at org.apache.hadoop.hbase.ipc.Call.checkAndSetTimeout(Call.java:70)
at org.apache.hadoop.hbase.ipc.RpcClientImpl.call(RpcClientImpl.java:1213)
... 10 more


But that isn&amp;amp;apos;t case with AsyncRpcClient, we don&amp;amp;apos;t wrap and throw CallTimeoutException as it is.

2015-12-21 14:27:33,093 WARN  [RS_OPEN_REGION-host-XX:16201-0.replicationSource.host-XX%2C16201%2C1450687255593,1] regionserver.HBaseInterClusterReplicationEndpoint: Can&amp;amp;apos;t replicate because of a local or network error: 
org.apache.hadoop.hbase.ipc.CallTimeoutException: callId=2, method=ReplicateWALEntry, rpcTimeout=600000, param {TODO: class org.apache.hadoop.hbase.protobuf.generated.AdminProtos$ReplicateWALEntryRequest}
	at org.apache.hadoop.hbase.ipc.AsyncRpcClient.call(AsyncRpcClient.java:257)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(AbstractRpcClient.java:217)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$BlockingRpcChannelImplementation.callBlockingMethod(AbstractRpcClient.java:295)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.replicateWALEntry(AdminProtos.java:23707)
	at org.apache.hadoop.hbase.protobuf.ReplicationProtbufUtil.replicateWALEntry(ReplicationProtbufUtil.java:73)
	at org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint$Replicator.call(HBaseInterClusterReplicationEndpoint.java:387)
	at org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint$Replicator.call(HBaseInterClusterReplicationEndpoint.java:370)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)


I think we should have same behavior across both the implementations.</description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.1.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.AsyncRpcClient.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.AbstractRpcClient.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.AbstractTestIPC.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.RpcClientImpl.java</file>
		</fixedFiles>
		<links>
			<link type="Blocker" description="blocks">14937</link>
		</links>
	</bug>
	<bug id="15063" opendate="2016-01-01 11:31:35" fixdate="2016-01-01 17:43:10" resolution="Fixed">
		<buginformation>
			<summary>Bug in MultiByteBuf#toBytes</summary>
			<description>In MutliByteBuff there are couple of inconsistencies, one is in the toBytes function where the offset for copying in the initial element is not being reset with respect to the element


 public byte[] toBytes(int offset, int length) {
     byte[] output = new byte[length];
     int itemIndex = getItemIndex(offset);
     ByteBuffer item = this.items[itemIndex];
     // the offset has to be reset here to the items offset 
     // should be offset = offset - itemBeingPos[itemIndex]
     int toRead = item.limit() - offset;
     int destinationOffset = 0;
    .  .   .   .


Since there is already an existing function get to copy to an byte array it is better we reuse the function here, I attached a patch with a corresponding unit test. (HBASE-XXXX.patch)
Another inconsistency I noticed is that there is lack of some consistency in using the position marker of the bytebuffers passed, In the constructor we noting the beginning offsets of each bytebuffer in the itemBeginPos array we are using these position markers in most of the absolute index functions such as get(index), put(index, byte), toBytes, get(int,byte[],int,int) to find the current item to access. There are two problems with this

The array itemBeginPos is not being updated whenever there are some writes to internal bytebuffers (remember itemBeginPos depends on the bytebuffer.position() of the internal bytebuffers and the position marker is changed whenever some writes happen to bytebuffers)
Also the position marker is not being used in any of the index functions for example here in the get function
   

 @Override
  public byte get(int index) {
    int itemIndex = getItemIndex(index);
    return ByteBufferUtils.toByte(this.items[itemIndex], index - this.itemBeginPos[itemIndex]);
  } 
   

where the the index I think should be index - this.itemBeginPos[itemIndex] + items[itemIndex].position() because we are using the position marker to calculate the offsets.

There are two solutions I think for this 

The simple solution I feel for this should be probably ignoring the position marker while calculating the itemBeginPos array which will unify the semantics
Not use this array at all and iterate over bytebuffers every time for the getItemIndex function and also use the position marker before calling the ByteBufferUtils functions

I can put up a patch for the second part if we decide which way to go.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.nio.MultiByteBuff.java</file>
			<file type="M">org.apache.hadoop.hbase.nio.TestMultiByteBuff.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">11425</link>
		</links>
	</bug>
	<bug id="14867" opendate="2015-11-21 01:55:14" fixdate="2016-01-04 15:32:14" resolution="Fixed">
		<buginformation>
			<summary>SimpleRegionNormalizer needs to have better heuristics to trigger merge operation</summary>
			<description>SimpleRegionNormalizer needs to have better heuristics to trigger merge operation. SimpleRegionNormalizer is not able to trigger a merge action if the table&amp;amp;apos;s smallest region has neighboring regions that are larger than table&amp;amp;apos;s average region size, whereas there are other smaller regions whose combined size is less than the average region size. 
For example, 

Consider a table with six region, say r1 to r6.
Keep r1 as empty and create some data say, 100K rows of data for each of the regions r2, r3 and r4. Create smaller amount of data for regions r5 and r6, say about 27K rows of data.
Run the normalizer. Verify the number the regions for that table and also check the master log to see if any merge action was triggered as a result of normalization.

In such scenario, it would be better to have a merge action triggered for those two smaller regions r5 and r6 even though either of them is not the smallest one</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.normalizer.SimpleRegionNormalizer.java</file>
			<file type="M">org.apache.hadoop.hbase.master.normalizer.TestSimpleRegionNormalizer.java</file>
		</fixedFiles>
	</bug>
	<bug id="15070" opendate="2016-01-05 15:06:18" fixdate="2016-01-07 17:14:58" resolution="Fixed">
		<buginformation>
			<summary>DistributedHBaseCluster#restoreRegionServers() starts new RS process on master server</summary>
			<description>While running some integration test i have notices that new  RS process is started on master server after tests are finished  although RS was not running  before running IT.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.DistributedHBaseCluster.java</file>
		</fixedFiles>
	</bug>
	<bug id="15052" opendate="2015-12-30 00:23:05" fixdate="2016-01-11 18:03:02" resolution="Fixed">
		<buginformation>
			<summary>Use EnvironmentEdgeManager in ReplicationSource </summary>
			<description>ReplicationSource is passing System.currentTimeMillis() to MetricsSource.setAgeOfLastShippedOp() which is subtracting that from EnvironmentEdgeManager.currentTime().


// if there was nothing to ship and it&amp;amp;apos;s not an error
// set "ageOfLastShippedOp" to &amp;lt;now&amp;gt; to indicate that we&amp;amp;apos;re current
metrics.setAgeOfLastShippedOp(System.currentTimeMillis(), walGroupId);

public void setAgeOfLastShippedOp(long timestamp, String walGroup) {
    long age = EnvironmentEdgeManager.currentTime() - timestamp;


 we should just use EnvironmentEdgeManager.currentTime() in ReplicationSource</description>
			<version>0.98.16.1</version>
			<fixedVersion>2.0.0, 1.2.0, 1.0.3, 1.1.3, 0.98.17</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
		</fixedFiles>
	</bug>
	<bug id="15085" opendate="2016-01-09 14:14:45" fixdate="2016-01-12 09:17:05" resolution="Fixed">
		<buginformation>
			<summary>IllegalStateException was thrown when scanning on bulkloaded HFiles</summary>
			<description>IllegalStateException was thrown when we scanned from an HFile which was bulk loaded several minutes ago, as shown below:


2015-12-16 22:20:54,456 ERROR com.taobao.kart.coprocessor.server.KartCoprocessor: icbu_ae_ws_product,/0055,1450275490479.6a6a700f465ad074287fed720c950f7c. batchNotify exception
java.lang.IllegalStateException: EncodedScanner works only on encoded data blocks
        at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$EncodedScannerV2.updateCurrentBlock(HFileReaderV2.java:1042)
        at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$EncodedScannerV2.seekTo(HFileReaderV2.java:1093)
        at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekAtOrAfter(StoreFileScanner.java:244)
        at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seek(StoreFileScanner.java:152)
        at org.apache.hadoop.hbase.regionserver.StoreScanner.seekScanners(StoreScanner.java:329)
        at org.apache.hadoop.hbase.regionserver.StoreScanner.&amp;lt;init&amp;gt;(StoreScanner.java:188)
        at org.apache.hadoop.hbase.regionserver.HStore.getScanner(HStore.java:1879)
        at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.&amp;lt;init&amp;gt;(HRegion.java:4068)
        at org.apache.hadoop.hbase.regionserver.HRegion.instantiateRegionScanner(HRegion.java:2029)
        at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:2015)
        at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1992)


I used &amp;amp;apos;hbase hfile&amp;amp;apos; command to analyse the meta and block info of the hfile, finding that even through the DATA_BLOCK_ENCODING was &amp;amp;apos;DIFF&amp;amp;apos; in FileInfo, the actual data blocks was written without any encoding algorithms(BlockType was &amp;amp;apos;DATA&amp;amp;apos;, not &amp;amp;apos;ENCODED_DATA&amp;amp;apos;):


Fileinfo:
    BLOOM_FILTER_TYPE = ROW
    BULKLOAD_SOURCE_TASK = attempt_1442077249005_606706_r_000012_0
    BULKLOAD_TIMESTAMP = \x00\x00\x01R\x12$\x13\x12
    DATA_BLOCK_ENCODING = DIFF
...
DataBlock Header:
HFileBlock [ fileOffset=0 headerSize()=33 blockType=DATA onDiskSizeWithoutHeader=65591 uncompressedSizeWithoutHeader=65571 prevBlockOffset=-1 isUseHBaseChecksum()=true checksumType=CRC32 bytesPerChecksum=16384 onDiskDataSizeWithHeader=65604 getOnDiskSizeWithHeader()=65624 totalChecksumBytes()=20 isUnpacked()=true buf=[ java.nio.HeapByteBuffer[pos=0 lim=65624 cap=65657], array().length=65657, arrayOffset()=0 ] dataBeginsWith=\x00\x00\x003\x00\x00\x00\x0A\x00\x10/0008:1000000008\x01dprod fileContext=HFileContext [ usesHBaseChecksum=true checksumType=CRC32 bytesPerChecksum=16384 blocksize=65536 encoding=NONE includesMvcc=true includesTags=false compressAlgo=NONE compressTags=false cryptoContext=[ cipher=NONE keyHash=NONE ] ] ]


The data block encoding in file info was not consistent with the one in data block, which means there must be something wrong with the bulkload process.
After debugging on each step of bulkload, I found that LoadIncrementalHFiles had a bug when loading hfile into a splitted region. 


/**
   * Copy half of an HFile into a new HFile.
   */
  private static void copyHFileHalf(
      Configuration conf, Path inFile, Path outFile, Reference reference,
      HColumnDescriptor familyDescriptor)
  throws IOException {
    FileSystem fs = inFile.getFileSystem(conf);
    CacheConfig cacheConf = new CacheConfig(conf);
    HalfStoreFileReader halfReader = null;
    StoreFile.Writer halfWriter = null;
    try {
      halfReader = new HalfStoreFileReader(fs, inFile, cacheConf, reference, conf);
      Map&amp;lt;byte[], byte[]&amp;gt; fileInfo = halfReader.loadFileInfo();

      int blocksize = familyDescriptor.getBlocksize();
      Algorithm compression = familyDescriptor.getCompression();
      BloomType bloomFilterType = familyDescriptor.getBloomFilterType();
// use CF&amp;amp;apos;s DATA_BLOCK_ENCODING to initialize HFile writer
      HFileContext hFileContext = new HFileContextBuilder()
                                  .withCompression(compression)
                                  .withChecksumType(HStore.getChecksumType(conf))
                                  .withBytesPerCheckSum(HStore.getBytesPerChecksum(conf))
                                  .withBlockSize(blocksize)
                                  .withDataBlockEncoding(familyDescriptor.getDataBlockEncoding())
                                  .build();
      halfWriter = new StoreFile.WriterBuilder(conf, cacheConf,
          fs)
              .withFilePath(outFile)
              .withBloomType(bloomFilterType)
              .withFileContext(hFileContext)
              .build();
      HFileScanner scanner = halfReader.getScanner(false, false, false);
      scanner.seekTo();
      do {
        KeyValue kv = KeyValueUtil.ensureKeyValue(scanner.getKeyValue());
        halfWriter.append(kv);
      } while (scanner.next());

// force encoding setting with the original HFile&amp;amp;apos;s file info
      for (Map.Entry&amp;lt;byte[],byte[]&amp;gt; entry : fileInfo.entrySet()) {
        if (shouldCopyHFileMetaKey(entry.getKey())) {
          halfWriter.appendFileInfo(entry.getKey(), entry.getValue());
        }
      }
    } finally {
      if (halfWriter != null) halfWriter.close();
      if (halfReader != null) halfReader.close(cacheConf.shouldEvictOnClose());
    }
  }


As shown above, when an HFile which has a DIFF encoding is bulkloaded into a splitted region whose CF&amp;amp;apos;s DATA_BLOCK_ENCODING is NONE, the two new HFiles would have inconsistent encodings.
Besides, it would be OK if splitting region&amp;amp;apos;s DATA_BLOCK_ENCODING is DIFF and bulk loaded HFile has NONE, because the initial bulkloaded HFile would not write the encoding info into its meta (NoOpDataBlockEncoder.saveMetadata() is empty), and It then would not rewrite encoding in two generated Files in copyHFileHalf(). Two new HFiles&amp;amp;apos; meta info would be consistent with their block headers, which would all be DIFF. So, no Exception would be thrown when scanning these files.</description>
			<version>0.98.12</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.0.3, 1.1.3, 0.98.17</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFiles.java</file>
			<file type="M">org.apache.hadoop.hbase.util.HFileTestUtil.java</file>
		</fixedFiles>
	</bug>
	<bug id="15104" opendate="2016-01-14 01:56:07" fixdate="2016-01-15 15:30:37" resolution="Fixed">
		<buginformation>
			<summary>Occasional failures due to NotServingRegionException in IT tests</summary>
			<description>IntegrationTestAcidGuarantees fails when trying to cleanup with NotServerRegionExceptions giving up (after 36 attempts) .
5/11/09 09:19:24 INFO client.AsyncProcess: #33, waiting for some tasks to finish. Expected max=0, tasksInProgress=9
15/11/09 09:19:33 INFO client.AsyncProcess: #45, table=TestAcidGuarantees, attempt=10/35 failed=1ops, last exception: org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: Region TestAcidGuarantees,test_row_1,1447089367019.032439ef4f3353cb894d20337ba043bc. is not online on node-4.internal,22101,1447089152259
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2786)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegion(RSRpcServices.java:922)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.multi(RSRpcServices.java:1893)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:32213)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2035)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:107)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)
	at java.lang.Thread.run(Thread.java:745)
...
Caused by: org.apache.hadoop.hbase.client.RetriesExhaustedException: Failed after attempts=36, exceptions:
Mon Nov 09 09:19:53 PST 2015, null, java.net.SocketTimeoutException: callTimeout=60000, callDuration=68104: row &amp;amp;apos;test_row_1&amp;amp;apos;
Looked at the RS log, the following exception is found:
2015-11-10 10:07:49,091 ERROR org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler: Failed open of region=TestAcidGuarantees,,1447177733243.f1be6b850fe3958c5c9b5e330b5dfb00., starting to roll back the global memstore size.
org.apache.hadoop.hbase.DoNotRetryIOException: java.lang.RuntimeException: java.lang.ClassNotFoundException: com.hadoop.compression.lzo.LzoCodec
        at org.apache.hadoop.hbase.util.CompressionTest.testCompression(CompressionTest.java:102)
        at org.apache.hadoop.hbase.regionserver.HRegion.checkCompressionCodecs(HRegion.java:6011)
        at org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(HRegion.java:5995)
        at org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(HRegion.java:5967)
        at org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(HRegion.java:5938)
        at org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(HRegion.java:5894)
        at org.apache.hadoop.hbase.regionserver.HRegion.openHRegion(HRegion.java:5845)
        at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.openRegion(OpenRegionHandler.java:356)
        at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.process(OpenRegionHandler.java:126)
        at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:745)</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 0.94.28, 1.2.0, 1.0.3, 1.1.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.chaos.actions.ChangeCompressionAction.java</file>
		</fixedFiles>
	</bug>
	<bug id="14512" opendate="2015-09-29 21:00:28" fixdate="2016-01-16 03:28:08" resolution="Fixed">
		<buginformation>
			<summary>Cache UGI groups</summary>
			<description>Right now every call gets a new User object.
We should keep the same user for the life of a connection. We should also cache the group names. However we can&amp;amp;apos;t cache the groups for forever as that would mean groups don&amp;amp;apos;t get refreshed every 5 mins.</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 0.98.17</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.RpcServer.java</file>
			<file type="M">org.apache.hadoop.hbase.security.UserProvider.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.CallRunner.java</file>
			<file type="M">org.apache.hadoop.hbase.security.User.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">12450</link>
		</links>
	</bug>
	<bug id="14771" opendate="2015-11-05 13:29:54" fixdate="2016-01-16 03:28:12" resolution="Fixed">
		<buginformation>
			<summary>RpcServer#getRemoteAddress always returns null</summary>
			<description>RpcServer.getRemoteAddress always returns null, because Call object is getting initialized with null.This seems to be happening because of using RpcServer.getRemoteIp() in  Call object constructor before RpcServer thread local &amp;amp;apos;CurCall&amp;amp;apos; being set in CallRunner.run method:

// --- RpcServer.java ---
protected void processRequest(byte[] buf) throws IOException, InterruptedException {
 .................................
// Call object getting initialized here with address 
// obtained from RpcServer.getRemoteIp()
Call call = new Call(id, this.service, md, header, param, cellScanner, this, responder,
              totalRequestSize, traceInfo, RpcServer.getRemoteIp());
  scheduler.dispatch(new CallRunner(RpcServer.this, call));
 }

// getRemoteIp method gets address from threadlocal &amp;amp;apos;CurCall&amp;amp;apos; which 
// gets set in CallRunner.run and calling it before this as in above case, will return null
// --- CallRunner.java ---
public void run() {
  .........................   
  Pair&amp;lt;Message, CellScanner&amp;gt; resultPair = null;
  RpcServer.CurCall.set(call);
  ..............................
}

// Using &amp;amp;apos;this.addr&amp;amp;apos; in place of getRemoteIp method in RpcServer.java seems to be fixing this issue
Call call = new Call(id, this.service, md, header, param, cellScanner, this, responder,
              totalRequestSize, traceInfo, this.addr);

</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 0.98.17</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.RpcServer.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.AbstractTestIPC.java</file>
		</fixedFiles>
	</bug>
	<bug id="15102" opendate="2016-01-13 23:27:50" fixdate="2016-01-19 20:54:29" resolution="Fixed">
		<buginformation>
			<summary>HeapMemoryTuner can "overtune" memstore size and suddenly drop it into blocking zone</summary>
			<description>DefaultHeapMemoryTuner often resets the maximum step size for tuning to 8% of total heap size. Often, when the size of memstore is to be decreased while tuning, the 8% tuning can suddenly drop the memstore size below the low water mark of the previous memstore size (which could potentially be  the used size of the memstore)
This is problematic because suddenly it blocks all the updates by suddenly causing a situation where memstore used size is above high water mark. This has a very bad performance impact on an otherwise fine HBase cluster. </description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHeapMemoryManager.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.DefaultHeapMemoryTuner.java</file>
		</fixedFiles>
	</bug>
	<bug id="15101" opendate="2016-01-13 22:12:38" fixdate="2016-01-20 06:14:50" resolution="Fixed">
		<buginformation>
			<summary>Leaked References to StoreFile.Reader after HBASE-13082</summary>
			<description>We observed this production that after a region server dies there are huge number of hfiles in that region for the region server running the version with HBASE-13082, In the doc it is given that it is expected to happen, but we found a one place where scanners are not being closed. If the scanners are not closed their references are not decremented and that is leading to the issue of huge number of store files not being finalized
All I was able to find is in the selectScannersFrom, where we discard some of the scanners and we are not closing them. I am attaching a patch for that.
Also to avoid these issues should the files that are done be logged and finalized (moved to archive) as a part of region close operation. This will solve any leaks that can happen and does not cause any dire consequences?
</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
		</fixedFiles>
	</bug>
	<bug id="15098" opendate="2016-01-13 12:03:00" fixdate="2016-01-20 17:40:28" resolution="Fixed">
		<buginformation>
			<summary>Normalizer switch in configuration is not used</summary>
			<description>The newly added global switch to enable the new normalizer functionality is never used apparently, meaning it is always on. The hbase-default.xml has this:

  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.normalizer.enabled&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;false&amp;lt;/value&amp;gt;
    &amp;lt;description&amp;gt;If set to true, Master will try to keep region size
      within each table approximately the same.&amp;lt;/description&amp;gt;
  &amp;lt;/property&amp;gt;


But only a test class uses it to set the switch to "true". We should implement a proper if statement that checks this value and properly disables the feature cluster wide if not wanted.</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.HConstants.java</file>
			<file type="M">org.apache.hadoop.hbase.master.normalizer.TestSimpleRegionNormalizerOnCluster.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">13103</link>
		</links>
	</bug>
	<bug id="15139" opendate="2016-01-20 21:49:02" fixdate="2016-01-20 22:23:06" resolution="Fixed">
		<buginformation>
			<summary>Connection manager doesn&amp;apos;t pass client metrics to RpcClient</summary>
			<description></description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
		</fixedFiles>
	</bug>
	<bug id="15126" opendate="2016-01-18 01:18:00" fixdate="2016-01-21 15:52:05" resolution="Fixed">
		<buginformation>
			<summary>HBaseFsck&amp;apos;s checkRegionBoundaries function sets incorrect &amp;apos;storesFirstKey&amp;apos;</summary>
			<description>HBaseFsck&amp;amp;apos;s checkRegionBoundaries function set the &amp;amp;apos;currentRegionBoundariesInformation.storesFirstKey&amp;amp;apos;  was incorrect.I think it should be set like below,
currentRegionBoundariesInformation.storesFirstKey = keyOnly(storeFirstKey);
but current the &amp;amp;apos;currentRegionBoundariesInformation.storesFirstKey &amp;amp;apos; is just set to &amp;amp;apos;storeFirstKey&amp;amp;apos;,which will cause to comparator.compare(currentRegionBoundariesInformation.storesFirstKey,
            currentRegionBoundariesInformation.metaFirstKey)  get a wrong result.  Because it just compared the rowkey&amp;amp;apos;s length.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.TestHBaseFsckOneRS.java</file>
			<file type="M">org.apache.hadoop.hbase.util.HBaseFsck.java</file>
		</fixedFiles>
	</bug>
	<bug id="15152" opendate="2016-01-21 15:24:21" fixdate="2016-01-22 03:06:16" resolution="Fixed">
		<buginformation>
			<summary>Automatically include prefix-tree module in MR jobs if present</summary>
			<description>I was running some MR jobs tests and ended up with PrefixTreeCodec class not found in the YarnChildren processes.  


2016-01-21 06:24:26,844 WARN  [main] mapreduce.TableMapReduceUtil(785): The  hbase-prefix-tree module jar containing PrefixTreeCodec is not present.
java.lang.ClassNotFoundException: org.apache.hadoop.hbase.code.prefixtree.PrefixTreeCodec
        at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
        at java.net.URLClassLoader$1.run(URLClassLoader.java:355)


This is related to HBASE-7434 and HBASE-7936 which address compile time concerns.  This fix makes it so that jar inclusion is done at run time, and continues if it is not present (for mr unit tests that don&amp;amp;apos;t depend on it)</description>
			<version>1.0.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.1.4, 1.0.4, 0.98.18</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
		</fixedFiles>
	</bug>
	<bug id="15125" opendate="2016-01-17 12:26:01" fixdate="2016-01-23 20:48:16" resolution="Fixed">
		<buginformation>
			<summary>HBaseFsck&amp;apos;s adoptHdfsOrphan function creates region with wrong end key boundary</summary>
			<description>There is a bug in HBaseFsck&amp;amp;apos;s adoptHdfsOrphan function.At the last of this function will create a region,which want to cover all the orphan regions.But the end key of this new region was set incorrectly.Correct region&amp;amp;apos;s boundary should be [startKey,endKey),but this function create a region with boundary of [startKey,endKey],this bug will leads to scan operation omit some data.
I think we should create the region like bellow,
    // create new region on hdfs. move data into place.
    HRegionInfo hri = new HRegionInfo(template.getTableName(), orphanRegionRange.getFirst(),
        Bytes.add(orphanRegionRange.getSecond(), new byte[1]));</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0, 1.3.0, 0.98.18</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.TestHBaseFsckTwoRS.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestHBaseFsckOneRS.java</file>
			<file type="M">org.apache.hadoop.hbase.util.BaseTestHBaseFsck.java</file>
			<file type="M">org.apache.hadoop.hbase.util.HBaseFsck.java</file>
		</fixedFiles>
		<links>
			<link type="Required" description="is required by">15852</link>
			<link type="dependent" description="is depended upon by">15827</link>
		</links>
	</bug>
	<bug id="15162" opendate="2016-01-25 09:18:00" fixdate="2016-01-26 07:08:12" resolution="Duplicate">
		<buginformation>
			<summary>Add separate metrics for meta/data block hit ratio in cache</summary>
			<description>Currently we already have a metrics in name of blockCacheExpressHitPercent to indicate the cache hit ratio. However, since meta block is small and often cached in memory with a high hit ratio, this "mixed" metrics could not show the real data block hit ratio which is more concerned.
We propose to add two new metrics to show meta and data block cache hit ratio separately, while reserving the old metrics for backward compatibility.</description>
			<version>1.3.0</version>
			<fixedVersion></fixedVersion>
			<type>Sub-task</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.TestCombinedBlockCache.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFileWriterImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperStub.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.CacheStats.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFileReaderImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.CombinedBlockCache.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.BlockCacheKey.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.TestLruBlockCache.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapper.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFileBlockIndex.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.MemcachedBlockCache.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">14983</link>
			<link type="dependent" description="depends upon">15160</link>
		</links>
	</bug>
	<bug id="15146" opendate="2016-01-21 01:39:35" fixdate="2016-01-28 13:16:01" resolution="Fixed">
		<buginformation>
			<summary>Don&amp;apos;t block on Reader threads queueing to a scheduler queue</summary>
			<description>Blocking on the epoll thread is awful. The new rpc scheduler can have lots of different queues. Those queues have different capacity limits. Currently the dispatch method can block trying to add the the blocking queue in any of the schedulers.
This causes readers to block, tcp acks are delayed, and everything slows down.</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.AsyncProcess.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.BalancedQueueRpcExecutor.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestAsyncProcess.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.RpcScheduler.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestHCM.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.FifoRpcScheduler.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.RpcExecutor.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.RpcServer.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor.java</file>
		</fixedFiles>
	</bug>
	<bug id="15019" opendate="2015-12-21 16:15:11" fixdate="2016-01-28 18:12:53" resolution="Fixed">
		<buginformation>
			<summary>Replication stuck when HDFS is restarted</summary>
			<description>RS is normally working and writing on the WAL.
HDFS is killed and restarted, and the RS try to do a roll.
The close fail, but the roll succeed (because hdfs is now up) and everything works.

2015-12-11 21:52:28,058 ERROR org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter: Got IOException while writing trailer
java.io.IOException: All datanodes 10.51.30.152:50010 are bad. Aborting...
  at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1147)
  at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:945)
  at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:496)
2015-12-11 21:52:28,059 ERROR org.apache.hadoop.hbase.regionserver.wal.FSHLog: Failed close of HLog writer
java.io.IOException: All datanodes 10.51.30.152:50010 are bad. Aborting...
  at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1147)
  at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:945)
  at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:496)
2015-12-11 21:52:28,059 WARN org.apache.hadoop.hbase.regionserver.wal.FSHLog: Riding over HLog close failure! error count=1


The problem is on the replication side. that log we rolled and we were not able to close
is waiting for a lease recovery.

2015-12-11 21:16:31,909 ERROR org.apache.hadoop.hbase.regionserver.wal.HLogFactory: Can&amp;amp;apos;t open after 267 attempts and 301124ms 


the WALFactory notify us about that, but there is nothing on the RS side that perform the WAL recovery.

2015-12-11 21:11:30,921 WARN org.apache.hadoop.hbase.regionserver.wal.HLogFactory: Lease should have recovered. This is not expected. Will retry
java.io.IOException: Cannot obtain block length for LocatedBlock{BP-1547065147-10.51.30.152-1446756937665:blk_1073801614_61243; getBlockSize()=83; corrupt=false; offset=0; locs=[10.51.30.154:50010, 10.51.30.152:50010, 10.51.30.155:50010]}
  at org.apache.hadoop.hdfs.DFSInputStream.readBlockLength(DFSInputStream.java:358)
  at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:300)
  at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:237)
  at org.apache.hadoop.hdfs.DFSInputStream.&amp;lt;init&amp;gt;(DFSInputStream.java:230)
  at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1448)
  at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:301)
  at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:297)
  at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
  at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:297)
  at org.apache.hadoop.fs.FilterFileSystem.open(FilterFileSystem.java:161)
  at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:766)
  at org.apache.hadoop.hbase.regionserver.wal.HLogFactory.createReader(HLogFactory.java:116)
  at org.apache.hadoop.hbase.regionserver.wal.HLogFactory.createReader(HLogFactory.java:89)
  at org.apache.hadoop.hbase.regionserver.wal.HLogFactory.createReader(HLogFactory.java:77)
  at org.apache.hadoop.hbase.replication.regionserver.ReplicationHLogReaderManager.openReader(ReplicationHLogReaderManager.java:68)
  at org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.openReader(ReplicationSource.java:508)
  at org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.run(ReplicationSource.java:321)


the only way to trigger a WAL recovery is to restart and force the master to trigger the lease recovery on WAL split. 
but there is a case where restarting will not help. If the RS keeps going rolling and flushing the unclosed WAL will be moved in the archive, and at that point the master will never try to do a lease recovery on it. 
since we know that the RS is still going, should we try to recover the lease on the RS side?
is it better/safer to trigger an abort on the RS, so we have only the master doing lease recovery?</description>
			<version>0.98.16.1</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.1.4, 1.0.4, 0.98.18</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
			<file type="M">org.apache.hadoop.hbase.wal.WALFactory.java</file>
		</fixedFiles>
	</bug>
	<bug id="15200" opendate="2016-02-01 17:47:20" fixdate="2016-02-04 00:31:39" resolution="Fixed">
		<buginformation>
			<summary>ZooKeeper znode ACL checks should only compare the shortname</summary>
			<description>After HBASE-13768 we check at startup in secure configurations if our znodes have the correct ACLs. However when checking the ACL we compare the Kerberos fullname, which includes the host component. We should only compare the shortname, the principal. Otherwise in a multimaster configuration we will unnecessarily reset ACLs whenever any master running on a host other than the one that initialized the ACLs makes the check. You can imagine this happening multiple times in a rolling restart scenario.</description>
			<version>0.98.17</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.1.4, 1.0.4, 0.98.18</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.java</file>
		</fixedFiles>
	</bug>
	<bug id="15218" opendate="2016-02-05 07:00:26" fixdate="2016-02-05 18:37:00" resolution="Fixed">
		<buginformation>
			<summary>On RS crash and replay of WAL, loosing all Tags in Cells</summary>
			<description>The KeyValueCodec&amp;amp;apos;s Decoder makes NoTagsKeyValue. The WalCellCodec also makes this Decoder and so while reading Cells after RS crash, we will loose all tags in Cells.  (While writing to WAL using WALCellCodec, we are preserving Cell tags.)
In case of SecureWALCellCodec, we are not even writing Cell tags to WAL.</description>
			<version>0.98.13</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.1.4, 1.0.4, 0.98.18</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.security.visibility.TestVisibilityLabelsWithDefaultVisLabelService.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.SecureWALCellCodec.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.WALCellCodec.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">13579</link>
		</links>
	</bug>
	<bug id="14770" opendate="2015-11-05 06:53:23" fixdate="2016-02-06 05:43:07" resolution="Fixed">
		<buginformation>
			<summary>RowCounter argument input parse error</summary>
			<description>I&amp;amp;apos;m tried to use https://github.com/apache/hbase/blob/master/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/RowCounter.java code and package a new jar then excuted following shell script:


hadoop jar test.jar &amp;lt;tablename&amp;gt; --range=row001,row002 cf:c2


Then I got "NoSuchColumnFamilyException".
It seems input argument parsing problem.
And I tried to add 


continue; 


after #L123 to avoid "--range=*" string be appended to qualifer.
Then the problem seems solve.

data in table:


row
cf:c1
cf:c2
cf:c3
cf:c4


row001
v1
v2




row002

v2
v3



row003


v3
v4


row004
v1


v4


Exception Message:


org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException: org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException: Column family --range=row001,row002 does not exist in region frank_rowcounttest1,,1446191360354.6c52c71a82f0fa041c467002a2bf433c. in table &amp;amp;apos;frank_rowcounttest1&amp;amp;apos;, {NAME =&amp;gt; &amp;amp;apos;cf&amp;amp;apos;, DATA_BLOCK_ENCODING =&amp;gt; &amp;amp;apos;NONE&amp;amp;apos;, BLOOMFILTER =&amp;gt; &amp;amp;apos;ROW&amp;amp;apos;, REPLICATION_SCOPE =&amp;gt; &amp;amp;apos;0&amp;amp;apos;, COMPRESSION =&amp;gt; &amp;amp;apos;NONE&amp;amp;apos;, VERSIONS =&amp;gt; &amp;amp;apos;1&amp;amp;apos;, TTL =&amp;gt; &amp;amp;apos;FOREVER&amp;amp;apos;, MIN_VERSIONS =&amp;gt; &amp;amp;apos;0&amp;amp;apos;, KEEP_DELETED_CELLS =&amp;gt; &amp;amp;apos;false&amp;amp;apos;, BLOCKSIZE =&amp;gt; &amp;amp;apos;65536&amp;amp;apos;, IN_MEMORY =&amp;gt; &amp;amp;apos;false&amp;amp;apos;, BLOCKCACHE =&amp;gt; &amp;amp;apos;true&amp;amp;apos;}

</description>
			<version>1.0.3</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.RowCounter.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TestRowCounter.java</file>
		</fixedFiles>
	</bug>
	<bug id="15214" opendate="2016-02-04 11:49:08" fixdate="2016-02-06 07:15:27" resolution="Fixed">
		<buginformation>
			<summary>Valid mutate Ops fail with RPC Codec in use and region moves across</summary>
			<description>Test failures in HBASE-15198 lead to this bug. Till now we are not doing cell block (codec usage) for write requests. (Client -&amp;gt; server)  Once we enabled Codec usage by default, aw this issue.
A multi request came to RS with mutation for different regions. One of the region which was in this RS got unavailable now.  In RsRpcServices#multi, we will fail that entire RegionAction (with N mutations in it) in that MultiRequest.  Then we will continue with remaining RegionActions.  Those Regions might be available.  (The failed RegionAction will get retried from client after fetching latest region location).  This all works fine in pure PB requests world. When a Codec is used, we wont convert the Mutation Cell to PB Cells and pack them in PB Message. Instead we will pass all Cells serialized into one byte[] cellblock. Using Decoder we will iterate over these cells at server side. Each Mutation PB will know only the number of cells associated with it.  As in above case when an entire RegionAction was skipped, there might be N Mutations under that which might have corresponding Cells in the cellblock. We are not doing the skip in that Iterator. This makes the later Mutations (for other Regions) to refer to invalid Cells and try to put those into the a different region. This will make HRegion#checkRow() to throw WrongRegionException which will be treated as Sanity check failure and so throwing back a DNRIOE to client. So the op will get failed for the user code.</description>
			<version>0.98.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.1.4, 1.0.4, 0.98.18</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestMultiParallel.java</file>
		</fixedFiles>
	</bug>
	<bug id="15231" opendate="2016-02-08 17:06:42" fixdate="2016-02-08 23:36:02" resolution="Fixed">
		<buginformation>
			<summary>Make TableState.State private</summary>
			<description>TableState is private but TableState.State is evolving. This means that Javadoc links from TableState.State to TableState are broken. stack says that TableState.State should be private.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.TableState.java</file>
		</fixedFiles>
	</bug>
	<bug id="15216" opendate="2016-02-05 06:04:22" fixdate="2016-02-10 06:56:50" resolution="Fixed">
		<buginformation>
			<summary>Canary does not accept config params from command line</summary>
			<description>At present there are few configs which needs to be present in  hbase-site or default xml for it to work. following are the list.
hbase.canary.threads.num
hbase.canary.sink.class
hbase.client.keytab.file
hbase.client.kerberos.principal
Execution in secure expects keytab and princ to be present 

2016-02-05 05:58:44,024 ERROR [main] hbase.AuthUtil - Error while trying to perform the initial login: Running in secure mode, but config doesn&amp;amp;apos;t have a keytab
java.io.IOException: Running in secure mode, but config doesn&amp;amp;apos;t have a keytab
	at org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:236)
	at org.apache.hadoop.hbase.security.User$SecureHadoopUser.login(User.java:392)
	at org.apache.hadoop.hbase.security.User.login(User.java:259)
	at org.apache.hadoop.hbase.security.UserProvider.login(UserProvider.java:116)
	at org.apache.hadoop.hbase.AuthUtil.launchAuthChore(AuthUtil.java:64)
	at org.apache.hadoop.hbase.tool.Canary.main(Canary.java:1146)
Exception in thread "main" java.io.IOException: Running in secure mode, but config doesn&amp;amp;apos;t have a keytab
	at org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:236)
	at org.apache.hadoop.hbase.security.User$SecureHadoopUser.login(User.java:392)
	at org.apache.hadoop.hbase.security.User.login(User.java:259)
	at org.apache.hadoop.hbase.security.UserProvider.login(UserProvider.java:116)
	at org.apache.hadoop.hbase.AuthUtil.launchAuthChore(AuthUtil.java:64)
	at org.apache.hadoop.hbase.tool.Canary.main(Canary.java:1146)




public static void main(String[] args) throws Exception {
    final Configuration conf = HBaseConfiguration.create();
    AuthUtil.launchAuthChore(conf);
    int numThreads = conf.getInt("hbase.canary.threads.num", MAX_THREADS_NUM);
    ExecutorService executor = new ScheduledThreadPoolExecutor(numThreads);

    Class&amp;lt;? extends Sink&amp;gt; sinkClass =
        conf.getClass("hbase.canary.sink.class", StdOutSink.class, Sink.class);
    Sink sink = ReflectionUtils.newInstance(sinkClass);

    int exitCode = ToolRunner.run(conf, new Canary(executor, sink), args);
    executor.shutdown();
    System.exit(exitCode);
  }


In main class these params should be parsed and updated. else for any change to these value hbase-stie.xml needs to be updated </description>
			<version>0.98.16</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 0.98.18</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.tool.Canary.java</file>
		</fixedFiles>
	</bug>
	<bug id="14192" opendate="2015-08-06 19:01:41" fixdate="2016-02-10 20:36:49" resolution="Fixed">
		<buginformation>
			<summary>Fix REST Cluster constructor with String List</summary>
			<description>The HBase REST Cluster which takes a list of hostname colon port numbers is not setting the internal list of nodes correctly.
Existing method:
public Cluster(List&amp;lt;String&amp;gt; nodes) 
{
   nodes.addAll(nodes)
}

Corrected method:
public Cluster(List&amp;lt;String&amp;gt; nodes) 
{
   this.nodes.addAll(nodes)
}
</description>
			<version>0.98.13</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.1.4, 0.98.18</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.rest.client.Cluster.java</file>
		</fixedFiles>
	</bug>
	<bug id="15221" opendate="2016-02-05 20:20:25" fixdate="2016-02-12 04:48:31" resolution="Fixed">
		<buginformation>
			<summary>HTableMultiplexer improvements (stale region locations and resource leaks)</summary>
			<description>It looks like HTableMultiplexer has a couple of issues.
Upon failing to send a Put to the appropriate RS, the Put is re-queued back into the system. Normally this is fine as such an exception is transient and the Put would eventually succeed. However, in the case where the Put was rejected because of a NotServingRegionException (e.g. split, balance, merge), the re-queuing of the Put will end up using the same cached HRegionLocation. This means that the Put will just be repeatedly sent back to the same RS over and over again, eventually being dropped on the floor. Need to invalidate the location cache (or make sure we refresh it) when we re-queue the Put.
The internal ClusterConnection is also leaked. If a user creates many HTableMultiplexers, they&amp;amp;apos;ll eventually run into issues (memory, zk connections, etc) because they&amp;amp;apos;ll never get cleaned up. HTableMultiplexer needs a close method.</description>
			<version>0.98.7</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.1.4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.HTableMultiplexer.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">12198</link>
		</links>
	</bug>
	<bug id="15252" opendate="2016-02-11 03:40:10" fixdate="2016-02-12 13:21:39" resolution="Fixed">
		<buginformation>
			<summary>Data loss when replaying wal if HDFS timeout</summary>
			<description>This is a problem introduced by HBASE-13825 where we change the exception type in catch block in readNext method of ProtobufLogReader.
ProtobufLogReader.java

      try {
          ......
          ProtobufUtil.mergeFrom(builder, new LimitInputStream(this.inputStream, size),
            (int)size);
        } catch (IOException ipbe) { // &amp;lt;------ used to be InvalidProtocolBufferException
          throw (EOFException) new EOFException("Invalid PB, EOF? Ignoring; originalPosition=" +
            originalPosition + ", currentPosition=" + this.inputStream.getPos() +
            ", messageSize=" + size + ", currentAvailable=" + available).initCause(ipbe);
        }


Here if the inputStream throws an IOException due to timeout or something, we just convert it to an EOFException and at the bottom of this method, we ignore EOFException and return false. This cause the upper layer think we reach the end of file. So when replaying we will treat the HDFS timeout error as a normal end of file and cause data loss.</description>
			<version>0.98.17</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.1.4, 1.0.4, 0.98.18</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestWALReplay.java</file>
		</fixedFiles>
	</bug>
	<bug id="13839" opendate="2015-06-04 16:02:25" fixdate="2016-02-12 23:07:46" resolution="Fixed">
		<buginformation>
			<summary>Fix AssgnmentManagerTmpl.jamon issues (coloring, content etc.)</summary>
			<description>The template for the RIT in the Master status page, AssignmentManagerTmpl.jamon) has a few issues:

The oldest RIT should not be red, looks like a failed entry
The RIT entries should be for example yellow/amber when over the threshold time, and red if 2x the threshold - or red for the oldest once over the threshold.


Region count over RIT threshold should only be colored if &amp;gt; 0
The summary line (first of two) should not be colored unless there is a value &amp;gt; 0 in it.


Color is overriden by table-stripped CSS style!
The Bootstrap stylesheet cancels out the hardcoded coloring! The table-stripped resets the conditional coloring and should be fixed. Best is to use "alert-warning" etc. that come from the Bootstrap theme stylesheet. That should maybe already work in combination with the "table-stripped" from the same.


Should sort descending by time
Currently the list of regions is sorted by encoded region name. Better is to have the table sorted by RIT time descending.

We should also think about a pagination option for the currently hardcoded 100 entries max. Maybe a separate issue?
</description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.TestMasterStatusServlet.java</file>
			<file type="M">org.apache.hadoop.hbase.master.RegionStates.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">14975</link>
		</links>
	</bug>
	<bug id="15079" opendate="2016-01-07 21:05:20" fixdate="2016-02-13 07:49:43" resolution="Fixed">
		<buginformation>
			<summary>TestMultiParallel.validateLoadedData AssertionError: null</summary>
			<description>Saw this failure on internal rig:


Stack Trace:
java.lang.AssertionError: null
        at org.junit.Assert.fail(Assert.java:86)
        at org.junit.Assert.assertTrue(Assert.java:41)
        at org.junit.Assert.assertTrue(Assert.java:52)
        at org.apache.hadoop.hbase.client.TestMultiParallel.validateLoadedData(TestMultiParallel.java:676)
        at org.apache.hadoop.hbase.client.TestMultiParallel.doTestFlushCommits(TestMultiParallel.java:293)
        at org.apache.hadoop.hbase.client.TestMultiParallel.testFlushCommitsNoAbort(TestMultiParallel.java:241)


Heng Chen actually added a fix for this failure over in HBASE-14915 but we never committed it. Let me attach his patch here.</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.TestMultiParallel.java</file>
		</fixedFiles>
	</bug>
	<bug id="15198" opendate="2016-02-01 09:10:49" fixdate="2016-02-15 12:07:27" resolution="Fixed">
		<buginformation>
			<summary>RPC client not using Codec and CellBlock for puts by default</summary>
			<description>For puts we use MultiServerCallable. Here to decide whether to use cellBlock we have


private boolean isCellBlock() {
    // This is not exact -- the configuration could have changed on us after connection was set up
    // but it will do for now.
    HConnection connection = getConnection();
    if (connection == null) return true; // Default is to do cellblocks.
    Configuration configuration = connection.getConfiguration();
    if (configuration == null) return true;
    String codec = configuration.get(HConstants.RPC_CODEC_CONF_KEY, "");
    return codec != null &amp;amp;&amp;amp; codec.length() &amp;gt; 0;
  }


By default in hbase-default.xml, we dont have any Codec being specified.
Where as in AbstractRpcClient we have


Codec getCodec() {
    // For NO CODEC, "hbase.client.rpc.codec" must be configured with empty string AND
    // "hbase.client.default.rpc.codec" also -- because default is to do cell block encoding.
    String className = conf.get(HConstants.RPC_CODEC_CONF_KEY, getDefaultCodec(this.conf));
    if (className == null || className.length() == 0) return null;
    try {
      return (Codec)Class.forName(className).newInstance();
    } catch (Exception e) {
      throw new RuntimeException("Failed getting codec " + className, e);
    }
  }
.....
public static String getDefaultCodec(final Configuration c) {
    // If "hbase.client.default.rpc.codec" is empty string -- you can&amp;amp;apos;t set it to null because
    // Configuration will complain -- then no default codec (and we&amp;amp;apos;ll pb everything).  Else
    // default is KeyValueCodec
    return c.get(DEFAULT_CODEC_CLASS, KeyValueCodec.class.getCanonicalName());
  }


Our aim is to by def use Codec and it is KeyValueCodec.  
The codec finding in MultiServerCallable to be same way as in AbstractRpcClient and then only we will be doing cellblock stuff.</description>
			<version>0.98.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.1.4, 1.0.4, 0.98.18</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.TestAsyncProcess.java</file>
			<file type="M">org.apache.hadoop.hbase.client.MultiServerCallable.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.RequestConverter.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.AbstractRpcClient.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.RpcClient.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestFromClientSide3.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ClusterConnection.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
		</fixedFiles>
		<links>
			<link type="Required" description="is required by">15180</link>
		</links>
	</bug>
	<bug id="15100" opendate="2016-01-13 21:11:22" fixdate="2016-02-18 05:38:42" resolution="Fixed">
		<buginformation>
			<summary>Master WALProcs still never clean up</summary>
			<description>

bin/hdfs dfs -ls /hbase/MasterProcWALs | wc -l
218631

</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.1.4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ProcedureInfo.java</file>
			<file type="M">org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALFormat.java</file>
			<file type="M">org.apache.hadoop.hbase.procedure2.store.wal.TestWALProcedureStore.java</file>
			<file type="M">org.apache.hadoop.hbase.procedure2.store.ProcedureStoreTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.procedure2.ProcedureExecutor.java</file>
			<file type="M">org.apache.hadoop.hbase.procedure2.Procedure.java</file>
			<file type="M">org.apache.hadoop.hbase.procedure2.store.wal.ProcedureWALFormatReader.java</file>
			<file type="M">org.apache.hadoop.hbase.procedure2.store.ProcedureStore.java</file>
			<file type="M">org.apache.hadoop.hbase.procedure2.store.TestProcedureStoreTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">14783</link>
			<link type="dependent" description="depends upon">15113</link>
		</links>
	</bug>
	<bug id="15279" opendate="2016-02-17 04:31:18" fixdate="2016-02-18 17:13:06" resolution="Fixed">
		<buginformation>
			<summary>OrderedBytes.isEncodedValue does not check for int8 and int16 types</summary>
			<description>OrderedBytes.isEncodedValue does not check for int8 and int16 types.  This also means that OrderedBytes.length may return an incorrect result, since it calls OrderedBytes.isEncodedValue.</description>
			<version>1.1.3</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0, 1.1.4, 0.98.18</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.OrderedBytes.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestOrderedBytes.java</file>
		</fixedFiles>
	</bug>
	<bug id="15251" opendate="2016-02-11 01:08:42" fixdate="2016-02-20 00:28:27" resolution="Fixed">
		<buginformation>
			<summary>During a cluster restart, Hmaster thinks it is a failover by mistake</summary>
			<description>We often need to do cluster restart as part of release for a cluster of &amp;gt; 1000 nodes. We have tried our best to get clean shutdown but 50% of the time, hmaster still thinks it is a failover. This increases the restart time from 5 min to 30 min and decreases locality from 99% to 5% since we didn&amp;amp;apos;t use a locality-aware balancer. We had a bug HBASE-14129 but the fix didn&amp;amp;apos;t work. 
After adding more logging and inspecting the logs, we identified two things that trigger the failover handling:
1.  When Hmaster.AssignmentManager detects any dead servers on service manager during joinCluster(), it determines this is a failover without further check. I added a check whether there is even any region assigned to these servers. During a clean restart, the regions are not even assigned.
2. When there are some leftover empty folders for log and split directories or empty wal files, it is also treated as a failover. I added a check for that. Although this can be resolved by manual cleanup, it is still too tedious for restarting a large cluster.
Patch will follow shortly. The fix is tested and used in production now.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.AssignmentManager.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">14129</link>
		</links>
	</bug>
	<bug id="15285" opendate="2016-02-17 19:54:03" fixdate="2016-02-22 23:40:30" resolution="Fixed">
		<buginformation>
			<summary>Forward-port respect for isReturnResult from HBASE-15095</summary>
			<description>This issue is about forward-porting the bug fix done in HBASE-15095 so we respect the isReturnResult properly in append and increment.</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.2.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.client.Append.java</file>
			<file type="M">org.apache.hadoop.hbase.client.Mutation.java</file>
			<file type="M">org.apache.hadoop.hbase.client.Increment.java</file>
		</fixedFiles>
	</bug>
	<bug id="15247" opendate="2016-02-10 14:12:26" fixdate="2016-02-23 04:30:26" resolution="Fixed">
		<buginformation>
			<summary>InclusiveStopFilter does not respect reverse Filter property</summary>
			<description>InclusiveStopFilter only works with non-reversed Scans, it will not filter for reversed Scans, because it doesn&amp;amp;apos;t flip the cmp-operand in the reversed case. In fact, it doesn&amp;amp;apos;t even use the Filter.reverse flag.
it should be something like this:
if (reversed) {
            if (cmp &amp;gt; 0) 
{
                done = true;
            }
        }
        else {
            if (cmp &amp;lt; 0) {
                done = true;
            }
        }</description>
			<version>1.1.1</version>
			<fixedVersion>2.0.0, 1.3.0, 0.98.18</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.filter.TestFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.InclusiveStopFilter.java</file>
		</fixedFiles>
	</bug>
	<bug id="15319" opendate="2016-02-24 03:34:57" fixdate="2016-02-25 00:34:31" resolution="Fixed">
		<buginformation>
			<summary>clearJmxCache does not take effect actually</summary>
			<description>When trying to backport HBASE-14166 to 0.98.6, I find JmxCacheBuster::clearJmxCache() does no take effect actually. The related code are listed below:
org.apache.hadoop.metrics2.impl.JmxCacheBuster.java

// fut is initialized to null
private static AtomicReference&amp;lt;ScheduledFuture&amp;gt; fut = new AtomicReference&amp;lt;&amp;gt;(null);

public static void clearJmxCache() {
    // clearJmxCache return directly when fut is null, which is always true.
    // the actual intent is &amp;amp;apos;if (future != null &amp;amp;&amp;amp; !future.isDone ...)&amp;amp;apos; ?
    ScheduledFuture future = fut.get();
    if ((future == null || (!future.isDone() &amp;amp;&amp;amp; future.getDelay(TimeUnit.MILLISECONDS) &amp;gt; 100))) {
      return;
    }
    ......
}

</description>
			<version>1.1.0.1</version>
			<fixedVersion>2.0.0, 1.3.0, 1.2.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.metrics2.impl.JmxCacheBuster.java</file>
		</fixedFiles>
	</bug>
	<bug id="15290" opendate="2016-02-19 06:25:48" fixdate="2016-02-26 23:22:05" resolution="Fixed">
		<buginformation>
			<summary>Hbase Rest CheckAndAPI should save other cells along with compared cell</summary>
			<description>Java CheckAndPut API allows users to save Cells (C1..C5) while comparing a Cell C1.
But in Rest API, even though caller sent multiple cells, hbase rest code is ignoring all the cells except for compare cell.</description>
			<version>1.1.1</version>
			<fixedVersion>2.0.0, 1.3.0, 1.2.1, 1.1.4, 0.98.18</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.rest.RowResource.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.RowResourceBase.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.TestGetAndPutResource.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">15323</link>
		</links>
	</bug>
	<bug id="15358" opendate="2016-02-29 08:25:21" fixdate="2016-02-29 09:32:41" resolution="Fixed">
		<buginformation>
			<summary>canEnforceTimeLimitFromScope should use timeScope instead of sizeScope</summary>
			<description>A small but maybe critical bug</description>
			<version>1.1.3</version>
			<fixedVersion>2.0.0, 1.3.0, 1.2.1, 1.1.4, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.ScannerContext.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">13090</link>
		</links>
	</bug>
	<bug id="15315" opendate="2016-02-23 16:58:28" fixdate="2016-03-01 23:42:05" resolution="Fixed">
		<buginformation>
			<summary>Remove always set super user call as high priority</summary>
			<description>Current implementation set superuser call as ADMIN_QOS, but we have many customers use superuser to do normal table operation such as put/get data and so on. If client put much data during region assignment, RPC from HMaster may timeout because of no handle. so it is better to remove always set super user call as high priority. </description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.2.4</fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.AnnotationReadingPriorityFunction.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestPriorityRpc.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">16676</link>
			<link type="Reference" description="relates to">15295</link>
			<link type="Reference" description="relates to">16676</link>
			<link type="Regression" description="is broken by">13375</link>
		</links>
	</bug>
	<bug id="15397" opendate="2016-03-04 10:39:15" fixdate="2016-03-04 21:50:19" resolution="Fixed">
		<buginformation>
			<summary>Create bulk load replication znode(hfile-refs) in ZK replication queue by default</summary>
			<description>Create bulk load replication znode(hfile-refs) in ZK replication queue by default same as hbase replication znode. 
Otherwise the problem what happens is currently replication admin directly operates on ZK without routing through HM/RS. So suppose if a user enables the replication for bulk loaded data in server but fails to do the same in the client configurations then add peer will not add hfile-refs znode, resulting in replication failure for bulk loaded data.
So after fixing this the behavior will be same as mutation replication.</description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.replication.ReplicationStateZKBase.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.ReplicationQueuesZKImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.ReplicationPeersZKImpl.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">13153</link>
		</links>
	</bug>
	<bug id="15393" opendate="2016-03-04 07:24:46" fixdate="2016-03-07 13:05:37" resolution="Fixed">
		<buginformation>
			<summary>Enable table replication command will fail when parent znode is not default in peer cluster</summary>
			<description>Enable table replication command will fail when parent znode is not /hbase(default) in peer cluster and there is only one peer cluster added in the source cluster.</description>
			<version>0.98.17</version>
			<fixedVersion>2.0.0, 1.3.0, 1.2.1, 0.98.18</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.replication.ReplicationAdmin.java</file>
			<file type="M">org.apache.hadoop.hbase.client.replication.TestReplicationAdmin.java</file>
		</fixedFiles>
	</bug>
	<bug id="15137" opendate="2016-01-20 09:01:48" fixdate="2016-03-08 11:05:16" resolution="Fixed">
		<buginformation>
			<summary>CallTimeoutException and CallQueueTooBigException should trigger PFFE</summary>
			<description>If a region server is backed up enough that lots of calls are timing out then we should think about treating a server as failing.</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.exceptions.PreemptiveFastFailException.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestFastFail.java</file>
			<file type="M">org.apache.hadoop.hbase.client.PreemptiveFastFailInterceptor.java</file>
			<file type="M">org.apache.hadoop.hbase.client.FastFailInterceptorContext.java</file>
			<file type="M">org.apache.hadoop.hbase.exceptions.ClientExceptionsUtil.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">15390</link>
		</links>
	</bug>
	<bug id="15364" opendate="2016-02-29 23:50:44" fixdate="2016-03-09 00:44:51" resolution="Fixed">
		<buginformation>
			<summary>Fix unescaped &lt; characters in Javadoc</summary>
			<description>From https://builds.apache.org/job/HBase%20Website%20Link%20Ckecker/28/artifact/link_report/index.html: 


host: hbase.apache.org
date: Mon, 29-Feb-2016 12:06:21 (local)
Linklint version: 2.3.5_ingo_020

#------------------------------------------------------------
# warn    2 warnings (cross referenced)
#------------------------------------------------------------
unquoted "&amp;lt;" in &amp;lt;0.90.5, &amp;lt;0.90.5, &amp;lt;
occurred in
    /devapidocs/org/apache/hadoop/hbase/util/HBaseFsck.html

unquoted "&amp;lt;" in &amp;lt;0.92.0) a master
 res
occurred in
    /devapidocs/org/apache/hadoop/hbase/util/HBaseFsck.html


</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.HBaseFsck.java</file>
		</fixedFiles>
	</bug>
	<bug id="15378" opendate="2016-03-02 05:08:05" fixdate="2016-03-09 18:08:36" resolution="Fixed">
		<buginformation>
			<summary>Scanner cannot handle heartbeat message with no results</summary>
			<description>When a RS scanner get a TIME_LIMIT_REACHED_MID_ROW state, they will stop scanning and send back what it has read to client and mark the message as a heartbeat message. If there is no cell has been read, it will be an empty response. 
However, ClientScanner only handles the situation that the client gets an empty heartbeat and its cache is not empty. If the cache is empty too, it will be regarded as end-of-region and open a new scanner for next region.</description>
			<version>1.1.3</version>
			<fixedVersion>2.0.0, 1.3.0, 1.2.1, 1.1.4, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestScannerHeartbeatMessages.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ClientScanner.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">13090</link>
		</links>
	</bug>
	<bug id="15120" opendate="2016-01-15 10:00:00" fixdate="2016-03-10 04:28:32" resolution="Fixed">
		<buginformation>
			<summary>Backport HBASE-14883 to branch-1.1</summary>
			<description>When checking branch-1.1 UT in HBASE-13590, found TestSplitTransactionOnCluster#testFailedSplit will fail at a 12/50 chance. The issue is fixed by HBASE-14883 but the change didn&amp;amp;apos;t go into branch-1.1</description>
			<version>1.1.2</version>
			<fixedVersion>1.1.4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
		</fixedFiles>
		<links>
			<link type="Container" description="Is contained by">15168</link>
		</links>
	</bug>
	<bug id="15425" opendate="2016-03-08 12:07:21" fixdate="2016-03-10 15:23:54" resolution="Fixed">
		<buginformation>
			<summary>Failing to write bulk load event marker in the WAL is ignored</summary>
			<description>During LoadIncrementalHFiles process if we fail to write the bulk load event marker in the WAL, it is ignored. So this will lead to data mismatch issue in source and peer cluster in case of bulk loaded data replication scenario.</description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">15446</link>
			<link type="Reference" description="is related to">13153</link>
		</links>
	</bug>
	<bug id="15379" opendate="2016-03-02 05:32:31" fixdate="2016-03-13 16:35:41" resolution="Fixed">
		<buginformation>
			<summary>Fake cells created in read path not implementing SettableSequenceId</summary>
			<description>This issue found by Appy. In HBASE-14099  he says,
I was doing some testing when I hit a weird issue, seems related to this, so re-opening it (apologies in advance if it&amp;amp;apos;s not).  Here&amp;amp;apos;s the stack trace

java.io.IOException: java.lang.UnsupportedOperationException: Cell is not of type org.apache.hadoop.hbase.SettableSequenceId

	at org.apache.hadoop.hbase.CellUtil.setSequenceId(CellUtil.java:923)
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.setCurrentCell(StoreFileScanner.java:231)
	at org.apache.hadoop.hbase.regionserver.StoreFileScanner.requestSeek(StoreFileScanner.java:389)
	at org.apache.hadoop.hbase.regionserver.StoreScanner.seekScanners(StoreScanner.java:348)
	at org.apache.hadoop.hbase.regionserver.StoreScanner.&amp;lt;init&amp;gt;(StoreScanner.java:212)
	at org.apache.hadoop.hbase.regionserver.HStore.createScanner(HStore.java:1873)
	at org.apache.hadoop.hbase.regionserver.HStore.getScanner(HStore.java:1863)
	at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.&amp;lt;init&amp;gt;(HRegion.java:5487)
	at org.apache.hadoop.hbase.regionserver.HRegion.instantiateRegionScanner(HRegion.java:2577)
	at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:2563)
	at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:2544)
	at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:2534)
	at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:6659)
	at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:6624)
	at org.apache.hadoop.hbase.regionserver.TestWithSingleHRegion.test(TestWithSingleHRegion.java:48)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:117)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:234)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:74)


I think it&amp;amp;apos;s because of using changing from KeyValue to a different sub-class of Cell}}l which doesn&amp;amp;apos;t implement {{SettableSequenceId

-    this.startKey = KeyValueUtil.createFirstDeleteFamilyOnRow(scan.getStartRow(),
+    this.startKey = CellUtil.createFirstDeleteFamilyCellOnRow(scan.getStartRow(),


To replicate it, download the attached hfiles somewhere, copy the TestWithSingleHRegion class to regionserver tests, change the ROOT_DIR appropriately and run it.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.CellUtil.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">11425</link>
		</links>
	</bug>
	<bug id="15323" opendate="2016-02-25 03:22:12" fixdate="2016-03-16 06:22:27" resolution="Fixed">
		<buginformation>
			<summary>Hbase Rest CheckAndDeleteAPi should be able to delete more cells</summary>
			<description>Java CheckAndDelete API accepts Delete object which can be used to delete (a cell / cell version / multiple cells / column family or a row), but the rest api only allows to delete the cell (without any version)
Need to add this capability to rest api.</description>
			<version>1.1.1</version>
			<fixedVersion>2.0.0, 1.3.0, 1.2.1, 1.1.4, 0.98.18, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.rest.RowResource.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.RowResourceBase.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.TestGetAndPutResource.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.client.RemoteHTable.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">15290</link>
		</links>
	</bug>
	<bug id="15430" opendate="2016-03-09 01:10:24" fixdate="2016-03-16 16:35:53" resolution="Fixed">
		<buginformation>
			<summary>Failed taking snapshot - Manifest proto-message too large</summary>
			<description>the size of a protobuf message is 64MB (default). but the size of snapshot meta is over 64MB. 
Caused by: com.google.protobuf.InvalidProtocolBufferException via Failed taking snapshot 
{ ss=snapshot_xxx table=xxx type=FLUSH }
 due to exception:Protocol message was too large.  May be malicious.  Use CodedInputStream.setSizeLimit() to increase the size limit.:com.google.protobuf.InvalidProtocolBufferException: Protocol message was too large.  May be malicious.  Use CodedInputStream.setSizeLimit() to increase the size limit.
        at org.apache.hadoop.hbase.errorhandling.ForeignExceptionDispatcher.rethrowException(ForeignExceptionDispatcher.java:83)
        at org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler.rethrowExceptionIfFailed(TakeSnapshotHandler.java:307)
        at org.apache.hadoop.hbase.master.snapshot.SnapshotManager.isSnapshotDone(SnapshotManager.java:341)
        ... 10 more
Caused by: com.google.protobuf.InvalidProtocolBufferException: Protocol message was too large.  May be malicious.  Use CodedInputStream.setSizeLimit() to increase the size limit.
        at com.google.protobuf.InvalidProtocolBufferException.sizeLimitExceeded(InvalidProtocolBufferException.java:110)
        at com.google.protobuf.CodedInputStream.refillBuffer(CodedInputStream.java:755)
        at com.google.protobuf.CodedInputStream.readRawBytes(CodedInputStream.java:811)
        at com.google.protobuf.CodedInputStream.readBytes(CodedInputStream.java:329)
        at org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$RegionInfo.&amp;lt;init&amp;gt;(HBaseProtos.java:3767)
        at org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$RegionInfo.&amp;lt;init&amp;gt;(HBaseProtos.java:3699)
        at org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$RegionInfo$1.parsePartialFrom(HBaseProtos.java:3815)
        at org.apache.hadoop.hbase.protobuf.generated.HBaseProtos$RegionInfo$1.parsePartialFrom(HBaseProtos.java:3810)
        at com.google.protobuf.CodedInputStream.readMessage(CodedInputStream.java:309)
        at org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest.&amp;lt;init&amp;gt;(SnapshotProtos.java:1152)
        at org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest.&amp;lt;init&amp;gt;(SnapshotProtos.java:1094)
        at org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest$1.parsePartialFrom(SnapshotProtos.java:1201)
        at org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest$1.parsePartialFrom(SnapshotProtos.java:1196)
        at com.google.protobuf.CodedInputStream.readMessage(CodedInputStream.java:309)
        at org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotDataManifest.&amp;lt;init&amp;gt;(SnapshotProtos.java:3858)
        at org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotDataManifest.&amp;lt;init&amp;gt;(SnapshotProtos.java:3792)
        at org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotDataManifest$1.parsePartialFrom(SnapshotProtos.java:3894)
        at org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotDataManifest$1.parsePartialFrom(SnapshotProtos.java:3889)
        at com.google.protobuf.AbstractParser.parsePartialFrom(AbstractParser.java:200)
        at com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:217)
        at com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:223)
        at com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:49)
        at org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotDataManifest.parseFrom(SnapshotProtos.java:4094)
        at org.apache.hadoop.hbase.snapshot.SnapshotManifest.readDataManifest(SnapshotManifest.java:433)
        at org.apache.hadoop.hbase.snapshot.SnapshotManifest.load(SnapshotManifest.java:273)
        at org.apache.hadoop.hbase.snapshot.SnapshotManifest.open(SnapshotManifest.java:119)
        at org.apache.hadoop.hbase.master.snapshot.MasterSnapshotVerifier.verifySnapshot(MasterSnapshotVerifier.java:106</description>
			<version>0.98.11</version>
			<fixedVersion>2.0.0, 1.3.0, 1.2.1, 1.1.4, 0.98.18</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.snapshot.SnapshotManifest.java</file>
			<file type="M">org.apache.hadoop.hbase.snapshot.SnapshotTestingUtils.java</file>
		</fixedFiles>
	</bug>
	<bug id="15441" opendate="2016-03-10 21:29:29" fixdate="2016-03-16 23:38:03" resolution="Fixed">
		<buginformation>
			<summary>Fix WAL splitting when region has moved multiple times</summary>
			<description>Currently WAL splitting is broken when a region has been opened multiple times in recent minutes.
Region open and region close write event markers to the wal. These markers should have the sequence id in them. However it is currently getting 1. That means that if a region has moved multiple times in the last few mins then multiple split log workers will try and create the recovered edits file for sequence id 1. One of the workers will fail and on failing they will delete the recovered edits. Causing all split wal attempts to fail.
We need to:

make sure that close get the correct sequence id for open.
Filter all region events from recovered edits

It appears that the close event with a sequence id of one is coming from region warm up.</description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.2.1, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.WALEdit.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.wal.TestWALSplit.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.wal.WALSplitter.java</file>
		</fixedFiles>
	</bug>
	<bug id="15322" opendate="2016-02-25 02:11:19" fixdate="2016-03-17 02:25:26" resolution="Fixed">
		<buginformation>
			<summary>Operations using Unsafe path broken for platforms not having sun.misc.Unsafe</summary>
			<description>HBase crashes in standalone mode with the following log:
__________________________________________________________
2016-02-24 22:38:37,578 ERROR [main] master.HMasterCommandLine: Master exiting
java.lang.RuntimeException: Failed construction of Master: class org.apache.hadoop.hbase.master.HMaster
        at org.apache.hadoop.hbase.master.HMaster.constructMaster(HMaster.java:2341)
        at org.apache.hadoop.hbase.master.HMasterCommandLine.startMaster(HMasterCommandLine.java:233)
        at org.apache.hadoop.hbase.master.HMasterCommandLine.run(HMasterCommandLine.java:139)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
        at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:126)
        at org.apache.hadoop.hbase.master.HMaster.main(HMaster.java:2355)
Caused by: java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.hbase.util.Bytes$LexicographicalComparerHolder$UnsafeComparer
        at org.apache.hadoop.hbase.util.Bytes.putInt(Bytes.java:899)
        at org.apache.hadoop.hbase.KeyValue.createByteArray(KeyValue.java:1082)
        at org.apache.hadoop.hbase.KeyValue.&amp;lt;init&amp;gt;(KeyValue.java:652)
        at org.apache.hadoop.hbase.KeyValue.&amp;lt;init&amp;gt;(KeyValue.java:580)
        at org.apache.hadoop.hbase.KeyValue.&amp;lt;init&amp;gt;(KeyValue.java:483)
        at org.apache.hadoop.hbase.KeyValue.&amp;lt;init&amp;gt;(KeyValue.java:370)
        at org.apache.hadoop.hbase.KeyValue.&amp;lt;clinit&amp;gt;(KeyValue.java:267)
        at org.apache.hadoop.hbase.HConstants.&amp;lt;clinit&amp;gt;(HConstants.java:978)
        at org.apache.hadoop.hbase.HTableDescriptor.&amp;lt;clinit&amp;gt;(HTableDescriptor.java:1488)
        at org.apache.hadoop.hbase.util.FSTableDescriptors.&amp;lt;init&amp;gt;(FSTableDescriptors.java:124)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.&amp;lt;init&amp;gt;(HRegionServer.java:570)
        at org.apache.hadoop.hbase.master.HMaster.&amp;lt;init&amp;gt;(HMaster.java:365)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
        at org.apache.hadoop.hbase.master.HMaster.constructMaster(HMaster.java:2336)
__________________________________________________________
The class is in the hbase-common.jar and its there in the classpath as can be seen from the log:
_________________________________________________________
2016-02-24 22:38:32,538 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/home/hduser/hbase/hbase-1.1.3:/home/hduser/hbase/hbase-1.1.3/lib/activation-1.1.jar:/home/hduser/hbase/hbase-1.1.3/lib/aopalliance-1.0.jar:/home/hduser/hbase/hbase-1.1.3/lib/apacheds-i18n-2.0.0-M15.jar:/home/hduser/hbase/hbase-1.1.3/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hduser/hbase/hbase-1.1.3/lib/api-asn1-api-1.0.0-M20.jar:/home/hduser/hbase/hbase-1.1.3/lib/api-util-1.0.0-M20.jar:/home/hduser/hbase/hbase-1.1.3/lib/asm-3.1.jar:/home/hduser/hbase/hbase-1.1.3/lib/avro-1.7.4.jar:/home/hduser/hbase/hbase-1.1.3/lib/commons-beanutils-1.7.0.jar:/home/hduser/hbase/hbase-1.1.3/lib/commons-beanutils-core-1.8.0.jar:/home/hduser/hbase/hbase-1.1.3/lib/commons-cli-1.2.jar:/home/hduser/hbase/hbase-1.1.3/lib/commons-codec-1.9.jar:/home/hduser/hbase/hbase-1.1.3/lib/commons-collections-3.2.2.jar:/home/hduser/hbase/hbase-1.1.3/lib/commons-compress-1.4.1.jar:/home/hduser/hbase/hbase-1.1.3/lib/commons-configuration-1.6.jar:/home/hduser/hbase/hbase-1.1.3/lib/commons-daemon-1.0.13.jar:/home/hduser/hbase/hbase-1.1.3/lib/commons-digester-1.8.jar:/home/hduser/hbase/hbase-1.1.3/lib/commons-el-1.0.jar:/home/hduser/hbase/hbase-1.1.3/lib/commons-httpclient-3.1.jar:/home/hduser/hbase/hbase-1.1.3/lib/commons-io-2.4.jar:/home/hduser/hbase/hbase-1.1.3/lib/commons-lang-2.6.jar:/home/hduser/hbase/hbase-1.1.3/lib/commons-logging-1.2.jar:/home/hduser/hbase/hbase-1.1.3/lib/commons-math-2.2.jar:/home/hduser/hbase/hbase-1.1.3/lib/commons-math3-3.1.1.jar:/home/hduser/hbase/hbase-1.1.3/lib/commons-net-3.1.jar:/home/hduser/hbase/hbase-1.1.3/lib/disruptor-3.3.0.jar:/home/hduser/hbase/hbase-1.1.3/lib/findbugs-annotations-1.3.9-1.jar:/home/hduser/hbase/hbase-1.1.3/lib/guava-12.0.1.jar:/home/hduser/hbase/hbase-1.1.3/lib/guice-3.0.jar:/home/hduser/hbase/hbase-1.1.3/lib/guice-servlet-3.0.jar:/home/hduser/hbase/hbase-1.1.3/lib/hadoop-annotations-2.5.1.jar:/home/hduser/hbase/hbase-1.1.3/lib/hadoop-auth-2.5.1.jar:/home/hduser/hbase/hbase-1.1.3/lib/hadoop-client-2.5.1.jar:/home/hduser/hbase/hbase-1.1.3/lib/hadoop-common-2.5.1.jar:/home/hduser/hbase/hbase-1.1.3/lib/hadoop-hdfs-2.5.1.jar:/home/hduser/hbase/hbase-1.1.3/lib/hadoop-mapreduce-client-app-2.5.1.jar:/home/hduser/hbase/hbase-1.1.3/lib/hadoop-mapreduce-client-common-2.5.1.jar:/home/hduser/hbase/hbase-1.1.3/lib/hadoop-mapreduce-client-core-2.5.1.jar:/home/hduser/hbase/hbase-1.1.3/lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hduser/hbase/hbase-1.1.3/lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hduser/hbase/hbase-1.1.3/lib/hadoop-yarn-api-2.5.1.jar:/home/hduser/hbase/hbase-1.1.3/lib/hadoop-yarn-client-2.5.1.jar:/home/hduser/hbase/hbase-1.1.3/lib/hadoop-yarn-common-2.5.1.jar:/home/hduser/hbase/hbase-1.1.3/lib/hadoop-yarn-server-common-2.5.1.jar:/home/hduser/hbase/hbase-1.1.3/lib/hbase-annotations-1.1.3-tests.jar:/home/hduser/hbase/hbase-1.1.3/lib/hbase-annotations-1.1.3.jar:/home/hduser/hbase/hbase-1.1.3/lib/hbase-client-1.1.3.jar:/home/hduser/hbase/hbase-1.1.3/lib/hbase-common-1.1.3-tests.jar:/home/hduser/hbase/hbase-1.1.3/lib/hbase-common-1.1.3.jar:/home/hduser/hbase/hbase-1.1.3/lib/hbase-examples-1.1.3.jar:/home/hduser/hbase/hbase-1.1.3/lib/hbase-hadoop-compat-1.1.3.jar:/home/hduser/hbase/hbase-1.1.3/lib/hbase-hadoop2-compat-1.1.3.jar:/home/hduser/hbase/hbase-1.1.3/lib/hbase-it-1.1.3-tests.jar:/home/hduser/hbase/hbase-1.1.3/lib/hbase-it-1.1.3.jar:/home/hduser/hbase/hbase-1.1.3/lib/hbase-prefix-tree-1.1.3.jar:/home/hduser/hbase/hbase-1.1.3/lib/hbase-procedure-1.1.3.jar:/home/hduser/hbase/hbase-1.1.3/lib/hbase-protocol-1.1.3.jar:/home/hduser/hbase/hbase-1.1.3/lib/hbase-resource-bundle-1.1.3.jar:/home/hduser/hbase/hbase-1.1.3/lib/hbase-rest-1.1.3.jar:/home/hduser/hbase/hbase-1.1.3/lib/hbase-server-1.1.3-tests.jar:/home/hduser/hbase/hbase-1.1.3/lib/hbase-server-1.1.3.jar:/home/hduser/hbase/hbase-1.1.3/lib/hbase-shell-1.1.3.jar:/home/hduser/hbase/hbase-1.1.3/lib/hbase-thrift-1.1.3.jar:/home/hduser/hbase/hbase-1.1.3/lib/htrace-core-3.1.0-incubating.jar:/home/hduser/hbase/hbase-1.1.3/lib/httpclient-4.2.5.jar:/home/hduser/hbase/hbase-1.1.3/lib/httpcore-4.1.3.jar:/home/hduser/hbase/hbase-1.1.3/lib/jackson-core-asl-1.9.13.jar:/home/hduser/hbase/hbase-1.1.3/lib/jackson-jaxrs-1.9.13.jar:/home/hduser/hbase/hbase-1.1.3/lib/jackson-mapper-asl-1.9.13.jar:/home/hduser/hbase/hbase-1.1.3/lib/jackson-xc-1.9.13.jar:/home/hduser/hbase/hbase-1.1.3/lib/jamon-runtime-2.3.1.jar:/home/hduser/hbase/hbase-1.1.3/lib/jasper-compiler-5.5.23.jar:/home/hduser/hbase/hbase-1.1.3/lib/jasper-runtime-5.5.23.jar:/home/hduser/hbase/hbase-1.1.3/lib/java-xmlbuilder-0.4.jar:/home/hduser/hbase/hbase-1.1.3/lib/javax.inject-1.jar:/home/hduser/hbase/hbase-1.1.3/lib/jaxb-api-2.2.2.jar:/home/hduser/hbase/hbase-1.1.3/lib/jaxb-impl-2.2.3-1.jar:/home/hduser/hbase/hbase-1.1.3/lib/jcodings-1.0.8.jar:/home/hduser/hbase/hbase-1.1.3/lib/jersey-client-1.9.jar:/home/hduser/hbase/hbase-1.1.3/lib/jersey-core-1.9.jar:/home/hduser/hbase/hbase-1.1.3/lib/jersey-guice-1.9.jar:/home/hduser/hbase/hbase-1.1.3/lib/jersey-json-1.9.jar:/home/hduser/hbase/hbase-1.1.3/lib/jersey-server-1.9.jar:/home/hduser/hbase/hbase-1.1.3/lib/jets3t-0.9.0.jar:/home/hduser/hbase/hbase-1.1.3/lib/jettison-1.3.3.jar:/home/hduser/hbase/hbase-1.1.3/lib/jetty-6.1.26.jar:/home/hduser/hbase/hbase-1.1.3/lib/jetty-sslengine-6.1.26.jar:/home/hduser/hbase/hbase-1.1.3/lib/jetty-util-6.1.26.jar:/home/hduser/hbase/hbase-1.1.3/lib/joni-2.1.2.jar:/home/hduser/hbase/hbase-1.1.3/lib/jruby-complete-1.6.8.jar:/home/hduser/hbase/hbase-1.1.3/lib/jsch-0.1.42.jar:/home/hduser/hbase/hbase-1.1.3/lib/jsp-2.1-6.1.14.jar:/home/hduser/hbase/hbase-1.1.3/lib/jsp-api-2.1-6.1.14.jar:/home/hduser/hbase/hbase-1.1.3/lib/jsr305-1.3.9.jar:/home/hduser/hbase/hbase-1.1.3/lib/junit-4.12.jar:/home/hduser/hbase/hbase-1.1.3/lib/leveldbjni-all-1.8.jar:/home/hduser/hbase/hbase-1.1.3/lib/libthrift-0.9.0.jar:/home/hduser/hbase/hbase-1.1.3/lib/log4j-1.2.17.jar:/home/hduser/hbase/hbase-1.1.3/lib/metrics-core-2.2.0.jar:/home/hduser/hbase/hbase-1.1.3/lib/netty-3.2.4.Final.jar:/home/hduser/hbase/hbase-1.1.3/lib/netty-all-4.0.23.Final.jar:/home/hduser/hbase/hbase-1.1.3/lib/paranamer-2.3.jar:/home/hduser/hbase/hbase-1.1.3/lib/protobuf-java-2.5.0.jar:/home/hduser/hbase/hbase-1.1.3/lib/servlet-api-2.5-6.1.14.jar:/home/hduser/hbase/hbase-1.1.3/lib/servlet-api-2.5.jar:/home/hduser/hbase/hbase-1.1.3/lib/slf4j-api-1.7.7.jar:/home/hduser/hbase/hbase-1.1.3/lib/slf4j-log4j12-1.7.5.jar:/home/hduser/hbase/hbase-1.1.3/lib/snappy-java-1.0.4.1.jar:/home/hduser/hbase/hbase-1.1.3/lib/spymemcached-2.11.6.jar:/home/hduser/hbase/hbase-1.1.3/lib/xmlenc-0.52.jar:/home/hduser/hbase/hbase-1.1.3/lib/xz-1.0.jar:/home/hduser/hbase/hbase-1.1.3/lib/zookeeper-3.4.6.jar::/home/hduser/hbase/hbase-1.1.3/conf
__________________________________________________________
</description>
			<version>0.94.24</version>
			<fixedVersion>2.0.0, 1.3.0, 1.2.1, 1.1.4, 0.98.18, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.UnsafeAvailChecker.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.FuzzyRowFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.util.ByteBufferUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.util.UnsafeAccess.java</file>
			<file type="M">org.apache.hadoop.hbase.nio.SingleByteBuff.java</file>
			<file type="M">org.apache.hadoop.hbase.util.Bytes.java</file>
		</fixedFiles>
	</bug>
	<bug id="14963" opendate="2015-12-10 23:26:29" fixdate="2016-03-19 20:28:27" resolution="Fixed">
		<buginformation>
			<summary>Remove use of Guava Stopwatch from HBase client code</summary>
			<description>We ran into an issue where an application bundled its own Guava (and that happened to be in the classpath first) and HBase&amp;amp;apos;s MetaTableLocator threw an exception due to the fact that Stopwatch&amp;amp;apos;s constructor wasn&amp;amp;apos;t compatible... Might be better to not depend on Stopwatch at all in MetaTableLocator since the functionality is easily doable without.</description>
			<version>1.1.4</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0</fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.zookeeper.MetaTableLocator.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">16403</link>
		</links>
	</bug>
	<bug id="15433" opendate="2016-03-09 11:44:06" fixdate="2016-03-21 13:55:50" resolution="Fixed">
		<buginformation>
			<summary>SnapshotManager#restoreSnapshot not update table and region count quota correctly when encountering exception</summary>
			<description>In SnapshotManager#restoreSnapshot, the table and region quota will be checked and updated as:


      try {
        // Table already exist. Check and update the region quota for this table namespace
        checkAndUpdateNamespaceRegionQuota(manifest, tableName);
        restoreSnapshot(snapshot, snapshotTableDesc);
      } catch (IOException e) {
        this.master.getMasterQuotaManager().removeTableFromNamespaceQuota(tableName);
        LOG.error("Exception occurred while restoring the snapshot " + snapshot.getName()
            + " as table " + tableName.getNameAsString(), e);
        throw e;
      }


The &amp;amp;apos;checkAndUpdateNamespaceRegionQuota&amp;amp;apos; will fail if regions in the snapshot make the region count quota exceeded, then, the table will be removed in the &amp;amp;apos;catch&amp;amp;apos; block. This will make the current table count and region count decrease, following table creation or region split will succeed even if the actual quota is exceeded.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.2.1, 1.4.0, 1.1.5</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.snapshot.SnapshotManager.java</file>
			<file type="M">org.apache.hadoop.hbase.namespace.NamespaceStateManager.java</file>
			<file type="M">org.apache.hadoop.hbase.namespace.TestNamespaceAuditor.java</file>
			<file type="M">org.apache.hadoop.hbase.namespace.NamespaceAuditor.java</file>
			<file type="M">org.apache.hadoop.hbase.quotas.MasterQuotaManager.java</file>
		</fixedFiles>
	</bug>
	<bug id="15325" opendate="2016-02-25 06:18:37" fixdate="2016-03-22 12:59:01" resolution="Fixed">
		<buginformation>
			<summary>ResultScanner allowing partial result will miss the rest of the row if the region is moved between two rpc requests</summary>
			<description>HBASE-11544 allow scan rpc return partial of a row to reduce memory usage for one rpc request. And client can setAllowPartial or setBatch to get several cells in a row instead of the whole row.
However, the status of the scanner is saved on server and we need this to get the next part if there is a partial result before. If we move the region to another RS, client will get a NotServingRegionException and open a new scanner to the new RS which will be regarded as a new scan from the end of this row. So the rest cells of the row of last result will be missing.</description>
			<version>1.1.3</version>
			<fixedVersion>2.0.0, 1.3.0, 1.2.1, 1.4.0, 1.1.5</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.TestPartialResultsFromClientSide.java</file>
			<file type="M">org.apache.hadoop.hbase.CellComparator.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ClientScanner.java</file>
		</fixedFiles>
		<links>
			<link type="Blocker" description="is blocked by">15302</link>
			<link type="Reference" description="relates to">11544</link>
			<link type="Reference" description="is related to">15484</link>
			<link type="Reference" description="is related to">15485</link>
		</links>
	</bug>
	<bug id="15064" opendate="2016-01-02 00:26:01" fixdate="2016-03-23 09:34:49" resolution="Fixed">
		<buginformation>
			<summary>BufferUnderflowException after last Cell fetched from an HFile Block served from L2 offheap cache</summary>
			<description>While running the newer patches on our production system, I saw this error come couple of times 

ipc.RpcServer: Unexpected throwable object 
2016-01-01 16:42:56,090 ERROR [B.defaultRpcServer.handler=20,queue=20,port=60020] ipc.RpcServer: Unexpected throwable object 
java.nio.BufferUnderflowException
at java.nio.Buffer.nextGetIndex(Buffer.java:500)
at java.nio.DirectByteBuffer.get(DirectByteBuffer.java:249)
at org.apache.hadoop.hbase.nio.MultiByteBuff.get(MultiByteBuff.java:494)
at org.apache.hadoop.hbase.io.encoding.FastDiffDeltaEncoder$1.decode(FastDiffDeltaEncoder.java:402) 
at org.apache.hadoop.hbase.io.encoding.FastDiffDeltaEncoder$1.decodeNext(FastDiffDeltaEncoder.java:517) 
at org.apache.hadoop.hbase.io.encoding.BufferedDataBlockEncoder$BufferedEncodedSeeker.next(BufferedDataBlockEncoder.java:815)
at org.apache.hadoop.hbase.regionserver.StoreFileScanner.next(StoreFileScanner.java:138)


Looking at the get code 


if (this.curItem.remaining() == 0) {
      if (items.length - 1 == this.curItemIndex) {
        // means cur item is the last one and we wont be able to read a long. Throw exception
        throw new BufferUnderflowException();
      }
      this.curItemIndex++;
      this.curItem = this.items[this.curItemIndex];
    }
return this.curItem.get();


Can the new currentItem have zero elements (position == limit), does it make sense to change the if to while ? while (this.curItem.remaining() == 0). This logic is repeated may make sense abstract to a new function if we plan to change to  if to while</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.nio.MultiByteBuff.java</file>
			<file type="M">org.apache.hadoop.hbase.nio.TestMultiByteBuff.java</file>
			<file type="M">org.apache.hadoop.hbase.util.ByteBufferArray.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">11425</link>
		</links>
	</bug>
	<bug id="15520" opendate="2016-03-23 05:36:58" fixdate="2016-03-24 03:19:51" resolution="Fixed">
		<buginformation>
			<summary>Fix broken TestAsyncIPC</summary>
			<description>There are two problems
1. AsyncIPC will throw IOException when connection reset so we need to change the catch type in testRpcMaxRequestSize.
2. AsyncRpcChannel does not deal with channelInactive event in netty.</description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.AsyncServerResponseHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.AsyncRpcChannel.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.AbstractTestIPC.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">15212</link>
		</links>
	</bug>
	<bug id="14256" opendate="2015-08-19 15:43:59" fixdate="2016-03-24 17:16:26" resolution="Fixed">
		<buginformation>
			<summary>Flush task message may be confusing when region is recovered</summary>
			<description>In HRegion.setRecovering() we have this code:


    // force a flush only if region replication is set up for this region. Otherwise no need.
      boolean forceFlush = getTableDesc().getRegionReplication() &amp;gt; 1;

      // force a flush first
      MonitoredTask status = TaskMonitor.get().createStatus(
        "Flushing region " + this + " because recovery is finished");
      try {
        if (forceFlush) {
          internalFlushcache(status);
        }


So we only optionally force flush after a recovery of a region, but the message always is set to "Flushing...", which might be confusing. We should change the message based on forceFlush.</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.2.1, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
		</fixedFiles>
	</bug>
	<bug id="15515" opendate="2016-03-22 03:05:32" fixdate="2016-03-24 22:59:03" resolution="Fixed">
		<buginformation>
			<summary>Improve LocalityBasedCandidateGenerator in Balancer</summary>
			<description>There are some problems which need to fix.
1. LocalityBasedCandidateGenerator.getLowestLocalityRegionOnServer should skip empty region.
2. When use LocalityBasedCandidateGenerator to generate Cluster.Action, it should add random operation instead of pickLowestLocalityServer(cluster). Because the search function may stuck here if it always generate the same Cluster.Action.
3. getLeastLoadedTopServerForRegion should get least loaded server which have better locality than current server.</description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.balancer.RegionLocationFinder.java</file>
			<file type="M">org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer.java</file>
			<file type="M">org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.java</file>
		</fixedFiles>
	</bug>
	<bug id="15548" opendate="2016-03-28 18:18:54" fixdate="2016-03-28 23:53:59" resolution="Fixed">
		<buginformation>
			<summary>SyncTable: sourceHashDir is supposed to be optional but won&amp;apos;t work without </summary>
			<description>1) SyncTable code is contradictory. Usage said sourcehashdir is optional (https://github.com/apache/hbase/blob/ad3feaa44800f10d102255a240c38ccf23a82d49/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/SyncTable.java#L687). However, the command won&amp;amp;apos;t run if sourcehashdir is missing (https://github.com/apache/hbase/blob/ad3feaa44800f10d102255a240c38ccf23a82d49/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/SyncTable.java#L83-L85) 
2) There is no documentation on how to create the desired sourcehash</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 0.98.19, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.SyncTable.java</file>
		</fixedFiles>
	</bug>
	<bug id="15327" opendate="2016-02-25 13:08:23" fixdate="2016-03-30 16:01:41" resolution="Fixed">
		<buginformation>
			<summary>Canary will always invoke admin.balancer() in each sniffing period when writeSniffing is enabled</summary>
			<description>When Canary#writeSniffing is enabled, Canary#checkWriteTableDistribution will make sure the regions of write table distributed on all region servers as:


      int numberOfServers = admin.getClusterStatus().getServers().size();
      ......
      int numberOfCoveredServers = serverSet.size();
      if (numberOfCoveredServers &amp;lt; numberOfServers) {
        admin.balancer();
      }


The master will also work as a regionserver, so that ClusterStatus#getServers will contain the master. On the other hand, write table of Canary will not be assigned to master, making numberOfCoveredServers always smaller than numberOfServers and admin.balancer always be invoked in each sniffing period. This may cause frequent region moves. A simple fix is excluding master from numberOfServers.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.tool.Canary.java</file>
		</fixedFiles>
	</bug>
	<bug id="15559" opendate="2016-03-29 17:08:23" fixdate="2016-03-30 18:40:24" resolution="Fixed">
		<buginformation>
			<summary>BaseMasterAndRegionObserver doesn&amp;apos;t implement all the methods</summary>
			<description>It&amp;amp;apos;s supposed to be a class that allows someone to derive from that class and only need to implement the desired methods. However two methods aren&amp;amp;apos;t implemented.</description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.coprocessor.BaseMasterAndRegionObserver.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.BaseRegionObserver.java</file>
		</fixedFiles>
	</bug>
	<bug id="14983" opendate="2015-12-15 19:30:46" fixdate="2016-03-30 19:57:56" resolution="Fixed">
		<buginformation>
			<summary>Create metrics for per block type hit/miss ratios</summary>
			<description>Missing a root index block is worse than missing a data block. We should know the difference</description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.3.0, 0.98.19, 1.4.0</fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegionServerSource.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.LruBlockCache.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.TestCombinedBlockCache.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFileWriterImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperStub.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.CacheStats.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFileReaderImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.CombinedBlockCache.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.BlockCacheKey.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.TestLruBlockCache.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapper.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFileBlockIndex.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.MemcachedBlockCache.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">15162</link>
			<link type="Reference" description="is related to">15161</link>
		</links>
	</bug>
	<bug id="15324" opendate="2016-02-25 06:17:37" fixdate="2016-03-30 20:36:20" resolution="Fixed">
		<buginformation>
			<summary>Jitter may cause desiredMaxFileSize overflow in ConstantSizeRegionSplitPolicy and trigger unexpected split</summary>
			<description>We introduce jitter for region split decision in HBASE-13412, but the following line in ConstantSizeRegionSplitPolicy may cause long value overflow if MAX_FILESIZE is specified to Long.MAX_VALUE:


this.desiredMaxFileSize += (long)(desiredMaxFileSize * (RANDOM.nextFloat() - 0.5D) * jitter);


In our case we specify MAX_FILESIZE to Long.MAX_VALUE to prevent target region to split.</description>
			<version>1.1.3</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.2.5, 1.1.8</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.ConstantSizeRegionSplitPolicy.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestRegionSplitPolicy.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">17058</link>
		</links>
	</bug>
	<bug id="15424" opendate="2016-03-08 11:55:03" fixdate="2016-04-01 10:35:07" resolution="Fixed">
		<buginformation>
			<summary>Add bulk load hfile-refs for replication in ZK after the event is appended in the WAL</summary>
			<description>Currenlty hfile-refs znode used for tracking the bulk loaded data replication is added first and then the bulk load event in appended in the WAL. So this may lead to a issue where the znode is added in ZK but append to WAL is failed(due to some probelm in DN), so this znode will be left in ZK as it is and will not allow hfile to get deleted from archive directory. </description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.Replication.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.WALActionsListener.java</file>
			<file type="M">org.apache.hadoop.hbase.wal.DisabledWALProvider.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestMetricsWAL.java</file>
			<file type="M">org.apache.hadoop.hbase.wal.WALPerformanceEvaluation.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.MetricsWAL.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">13153</link>
		</links>
	</bug>
	<bug id="15582" opendate="2016-04-01 19:48:19" fixdate="2016-04-02 04:03:16" resolution="Fixed">
		<buginformation>
			<summary>SnapshotManifestV1 too verbose when there are no regions</summary>
			<description>swap the INFO for DEBUG in SnapshotManifestV1.loadRegionManifests() otherwise the cleaner will spam everyone for no reason</description>
			<version>0.98.16.1</version>
			<fixedVersion>2.0.0, 1.3.0, 1.0.4, 0.98.19, 1.1.5, 1.2.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.snapshot.SnapshotManifestV1.java</file>
		</fixedFiles>
	</bug>
	<bug id="15578" opendate="2016-04-01 11:55:04" fixdate="2016-04-04 09:43:41" resolution="Fixed">
		<buginformation>
			<summary>Handle HBASE-15234 for ReplicationHFileCleaner</summary>
			<description>HBASE-15234 is handled for ReplicationLogCleaner need to handle similarly for ReplicationHFileCleaner.</description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.cleaner.TestReplicationHFileCleaner.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.master.ReplicationHFileCleaner.java</file>
		</fixedFiles>
		<links>
			<link type="Regression" description="is broken by">13153</link>
		</links>
	</bug>
	<bug id="15485" opendate="2016-03-18 11:27:44" fixdate="2016-04-05 03:23:32" resolution="Fixed">
		<buginformation>
			<summary>Filter.reset() should not be called between batches</summary>
			<description>As discussed in HBASE-15325, now we will resetFilters if partial result not formed, but we should not reset filters when batch limit reached</description>
			<version>1.1.3</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.1.5, 1.2.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.ScannerContext.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">15325</link>
		</links>
	</bug>
	<bug id="15591" opendate="2016-04-04 22:42:23" fixdate="2016-04-11 04:42:29" resolution="Fixed">
		<buginformation>
			<summary>ServerCrashProcedure not yielding</summary>
			<description>ServerCrashProcedure is not propagating ProcedureYieldException to the ProcedureExecutor 
One symptom is that while ServerCrashProcedure is waiting for meta to be up the Procedure WALs get filled up rapidly with all the executions.</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.2.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.procedure.ServerCrashProcedure.java</file>
		</fixedFiles>
	</bug>
	<bug id="15093" opendate="2016-01-12 23:41:27" fixdate="2016-04-11 15:27:46" resolution="Fixed">
		<buginformation>
			<summary>Replication can report incorrect size of log queue for the global source when multiwal is enabled</summary>
			<description>Replication can  report incorrect size for the size of log queue for the global source when multiwal is enabled. This happens because the method MetricsSource#setSizeofLogQueue performs non-trivial operations in a multithreaded world, even though it is not synchronized. 
We can simply divide MetricsSource#setSizeofLogQueue into MetricsSource#incrSizeofLogQueue and MetricsSource#decrSizeofLogQueue. Not sure why we are currently directly setting the size instead of incrementing/decrementing it.</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.MetricsSource.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.MetricsReplicationGlobalSourceSource.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.MetricsReplicationSourceSourceImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.MetricsReplicationSourceSource.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">14457</link>
		</links>
	</bug>
	<bug id="15627" opendate="2016-04-11 00:48:32" fixdate="2016-04-11 17:50:16" resolution="Fixed">
		<buginformation>
			<summary> Miss space and closing quote in AccessController#checkSystemOrSuperUser</summary>
			<description> Miss space and closing quote in AccessController#checkSystemOrSuperUser


  private void checkSystemOrSuperUser() throws IOException {
    // No need to check if we&amp;amp;apos;re not going to throw
    if (!authorizationEnabled) {
      return;
    }
    User activeUser = getActiveUser();
    if (!Superusers.isSuperUser(activeUser)) {
    //***, miss closing &amp;amp;apos; and space in the AccessDeniedException string
      throw new AccessDeniedException("User &amp;amp;apos;" + (activeUser != null ?
        activeUser.getShortName() : "null") + "is not system or super user.");
    }
  }

</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0, 1.3.0, 0.98.19, 1.1.5, 1.2.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.security.access.AccessController.java</file>
		</fixedFiles>
	</bug>
	<bug id="15621" opendate="2016-04-08 21:52:28" fixdate="2016-04-12 19:53:20" resolution="Fixed">
		<buginformation>
			<summary>Suppress Hbase SnapshotHFile cleaner error  messages when a snaphot is going on</summary>
			<description>Run into the following exception when a snapshot is going on.
partial file of region-manifest and data.manifest could be read and parsed by the cleaner which results in InvalidProtocolBufferException, which needs to be ignored for in-progress snapshot.


2016-04-01 00:31:50,200 ERROR org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner: Exception while checking if: *** was valid, keeping it just in case.
com.google.protobuf.InvalidProtocolBufferException: While parsing a protocol message, the input ended unexpectedly in the middle of a field.  This could mean either than the input has been truncated or that an embedded message misreported its own length.
        at com.google.protobuf.InvalidProtocolBufferException.truncatedMessage(InvalidProtocolBufferException.java:70)
        at com.google.protobuf.CodedInputStream.refillBuffer(CodedInputStream.java:746)
        at com.google.protobuf.CodedInputStream.readRawByte(CodedInputStream.java:769)
        at com.google.protobuf.CodedInputStream.readRawVarint64(CodedInputStream.java:462)
        at com.google.protobuf.CodedInputStream.readUInt64(CodedInputStream.java:188)
        at org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest$StoreFile.&amp;lt;init&amp;gt;(SnapshotProtos.java:1331)
        at org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest$StoreFile.&amp;lt;init&amp;gt;(SnapshotProtos.java:1263)
        at org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest$StoreFile$1.parsePartialFrom(SnapshotProtos.java:1364)
        at org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest$StoreFile$1.parsePartialFrom(SnapshotProtos.java:1359)
        at com.google.protobuf.CodedInputStream.readMessage(CodedInputStream.java:309)
        at org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest$FamilyFiles.&amp;lt;init&amp;gt;(SnapshotProtos.java:2161)
        at org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest$FamilyFiles.&amp;lt;init&amp;gt;(SnapshotProtos.java:2103)
        at org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest$FamilyFiles$1.parsePartialFrom(SnapshotProtos.java:2197)
        at org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest$FamilyFiles$1.parsePartialFrom(SnapshotProtos.java:2192)
        at com.google.protobuf.CodedInputStream.readMessage(CodedInputStream.java:309)
        at org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest.&amp;lt;init&amp;gt;(SnapshotProtos.java:1165)
        at org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest.&amp;lt;init&amp;gt;(SnapshotProtos.java:1094)
        at org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest$1.parsePartialFrom(SnapshotProtos.java:1201)
        at org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotRegionManifest$1.parsePartialFrom(SnapshotProtos.java:1196)
        at com.google.protobuf.CodedInputStream.readMessage(CodedInputStream.java:309)
        at org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotDataManifest.&amp;lt;init&amp;gt;(SnapshotProtos.java:3858)
        at org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotDataManifest.&amp;lt;init&amp;gt;(SnapshotProtos.java:3792)
        at org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotDataManifest$1.parsePartialFrom(SnapshotProtos.java:3894)
        at org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotDataManifest$1.parsePartialFrom(SnapshotProtos.java:3889)
        at com.google.protobuf.AbstractParser.parsePartialFrom(AbstractParser.java:200)
        at com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:217)
        at com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:223)
        at com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:49)
        at org.apache.hadoop.hbase.protobuf.generated.SnapshotProtos$SnapshotDataManifest.parseFrom(SnapshotProtos.java:4094)
        at org.apache.hadoop.hbase.snapshot.SnapshotManifest.readDataManifest(SnapshotManifest.java:433)
        at org.apache.hadoop.hbase.snapshot.SnapshotManifest.load(SnapshotManifest.java:273)
        at org.apache.hadoop.hbase.snapshot.SnapshotManifest.open(SnapshotManifest.java:119)
        at org.apache.hadoop.hbase.snapshot.SnapshotReferenceUtil.visitTableStoreFiles(SnapshotReferenceUtil.java:125)
        at org.apache.hadoop.hbase.snapshot.SnapshotReferenceUtil.getHFileNames(SnapshotReferenceUtil.java:346)
        at org.apache.hadoop.hbase.snapshot.SnapshotReferenceUtil.getHFileNames(SnapshotReferenceUtil.java:329)
        at org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner$1.filesUnderSnapshot(SnapshotHFileCleaner.java:80)
        at org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache.refreshCache(SnapshotFileCache.java:259)
        at org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache.contains(SnapshotFileCache.java:179)
        at org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner.isFileDeletable(SnapshotHFileCleaner.java:60)
        at org.apache.hadoop.hbase.master.cleaner.BaseFileCleanerDelegate$1.apply(BaseFileCleanerDelegate.java:38)
        at org.apache.hadoop.hbase.master.cleaner.BaseFileCleanerDelegate$1.apply(BaseFileCleanerDelegate.java:35)
        at com.google.common.collect.Iterators$8.computeNext(Iterators.java:688)
        at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)
        at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)
        at com.google.common.collect.Iterators$8.computeNext(Iterators.java:686)
        at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)
        at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)
        at com.google.common.collect.Iterators$6.hasNext(Iterators.java:582)


</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0, 1.3.0, 0.98.19, 1.1.5, 1.2.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.snapshot.SnapshotManifest.java</file>
			<file type="M">org.apache.hadoop.hbase.snapshot.SnapshotManifestV2.java</file>
			<file type="M">org.apache.hadoop.hbase.master.snapshot.TestSnapshotHFileCleaner.java</file>
			<file type="M">org.apache.hadoop.hbase.snapshot.TestSnapshotManifest.java</file>
			<file type="M">org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner.java</file>
			<file type="M">org.apache.hadoop.hbase.snapshot.SnapshotTestingUtils.java</file>
		</fixedFiles>
	</bug>
	<bug id="15636" opendate="2016-04-12 16:28:21" fixdate="2016-04-12 23:57:15" resolution="Fixed">
		<buginformation>
			<summary>hard coded wait time out value in HBaseTestingUtility#waitUntilAllRegionsAssigned might cause test failure</summary>
			<description>HBaseTestingUtility#waitUntilAllRegionsAssigned(final TableName tableName) hard coded 60 seconds wait for region assignment in a table.  This could cause flaky tests, as the caller could create table with longs of region which takes longs time; or in CM, RS unavailable could slow down assignment; or in a slow machine, IT might take long to assign regions.  
In HBaseAdmin.java, we use a configurable value to wait for the table DDLs: this.syncWaitTimeout = this.conf.getInt("hbase.client.sync.wait.timeout.msec", 10 * 60000); // 10min - we should use the config for the HBaseTestingUtility#waitUntilAllRegionsAssigned() too.
Of course, the caller could use the "public void waitUntilAllRegionsAssigned(final TableName tableName, final long timeout)"; but it requires test change (currently, no test directly calls this signature). 

  
/**
   * Wait until all regions for a table in hbase:meta have a non-empty
   * info:server, up to 60 seconds. This means all regions have been deployed,
   * master has been informed and updated hbase:meta with the regions deployed
   * server.
   * @param tableName the table name
   * @throws IOException
   */
  public void waitUntilAllRegionsAssigned(final TableName tableName) throws IOException {
    waitUntilAllRegionsAssigned(tableName, 60000);
  }

</description>
			<version>1.1.4</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.1.5, 1.2.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
		</fixedFiles>
	</bug>
	<bug id="15637" opendate="2016-04-12 21:43:35" fixdate="2016-04-13 19:38:59" resolution="Fixed">
		<buginformation>
			<summary>TSHA Thrift-2 server should allow limiting call queue size</summary>
			<description>Right now seems like thrift-2 hsha server always create unbounded queue, which could lead to OOM)</description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.3.0, 0.98.19</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.thrift2.ThriftServer.java</file>
		</fixedFiles>
	</bug>
	<bug id="15504" opendate="2016-03-21 18:50:59" fixdate="2016-04-14 01:17:52" resolution="Fixed">
		<buginformation>
			<summary>Fix Balancer in 1.3 not moving regions off overloaded regionserver</summary>
			<description>We pushed 1.3 to a couple of clusters. In some cases the regions were assigned VERY un-evenly and the regions would not move after that.
We ended up with one rs getting thousands of regions and most servers getting 0. Running balancer would do nothing. The balancer would say that it couldn&amp;amp;apos;t find a solution with less than the current cost.</description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.java</file>
		</fixedFiles>
	</bug>
	<bug id="15622" opendate="2016-04-08 22:04:37" fixdate="2016-04-15 15:43:45" resolution="Fixed">
		<buginformation>
			<summary>Superusers does not consider the keytab credentials</summary>
			<description>After HBASE-13755 the superuser we add by default (the process running hbase) does not take in consideration the keytab credential.
We have an env with the process user being hbase and the keytab being hbasefoo.
from Superusers TRACE I see, the hbase being picked up

TRACE Superusers: Current user name is hbase


from the RS audit I see the hbasefoo making requests

"allowed":true,"serviceName":"HBASE-1","username":"hbasefoo...


looking at the code in HRegionServer we do 


public HRegionServer(Configuration conf, CoordinatedStateManager csm)
      throws IOException {
   ...
    this.userProvider = UserProvider.instantiate(conf);
    Superusers.initialize(conf);
   ..
   // login the server principal (if using secure Hadoop)
    login(userProvider, hostName);
  ..


Before HBASE-13755 we were initializing the super user in the ACL coprocessor, so after the login. but now we do that before the login.
I&amp;amp;apos;m not sure if we can just move the Superuser.initialize() after the login Mikhail Antonov?</description>
			<version>0.98.16.1</version>
			<fixedVersion>2.0.0, 1.3.0, 0.98.19, 1.1.5, 1.2.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
		</fixedFiles>
	</bug>
	<bug id="15650" opendate="2016-04-14 04:54:20" fixdate="2016-04-16 03:13:49" resolution="Fixed">
		<buginformation>
			<summary>Remove TimeRangeTracker as point of contention when many threads reading a StoreFile</summary>
			<description>HBASE-12148 is about "Remove TimeRangeTracker as point of contention when many threads writing a Store". It is also a point of contention when reading.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0, 1.3.0, 0.98.19, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.TimeRange.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StripeStoreFlusher.java</file>
			<file type="M">org.apache.hadoop.hbase.HConstants.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestTimeRangeTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.mob.DefaultMobStoreFlusher.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestQueryMatcher.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFileReader.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
			<file type="M">org.apache.hadoop.hbase.KeyValueUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.client.Query.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFileWriter.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.ExplicitColumnTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TimeRangeTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.ScanQueryMatcher.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Segment.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MemStoreSnapshot.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.ImmutableSegment.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MockStoreFile.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.DefaultMemStore.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MutableSegment.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.AbstractMemStore.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.compactions.Compactor.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat2.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">16175</link>
			<link type="Reference" description="is related to">12148</link>
			<link type="Reference" description="is related to">16074</link>
		</links>
	</bug>
	<bug id="15287" opendate="2016-02-17 22:01:45" fixdate="2016-04-17 16:30:17" resolution="Fixed">
		<buginformation>
			<summary>mapreduce.RowCounter returns incorrect result with binary row key inputs</summary>
			<description>org.apache.hadoop.hbase.mapreduce.RowCounter takes optional start/end key as inputs (-range option). It would work only when the string representation of value is identical to the string. When row key is binary,  the string representation of the value would look like this: "\x00\x01", which would be incorrect interpreted as 8 char string in the current implementation:
https://github.com/apache/hbase/blob/master/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/RowCounter.java
To fix that, we need change how the value is converted from command line inputs:
Change 
      scan.setStartRow(Bytes.toBytes(startKey));
to
      scan.setStartRow(Bytes.toBytesBinary(startKey));
Do the same conversion to end key as well.
The issue was discovered when the utility was used to calcualte row distribution on regions from table with binary row keys. The hbase:meta contains the start key of each region in format of above example. </description>
			<version>1.1.1</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TestCellCounter.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.SimpleTotalOrderPartitioner.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.GroupingTableMapper.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.CopyTable.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.GroupingTableMap.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TestRowCounter.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.RowCounter.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TestCopyTable.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.CellCounter.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TableInputFormat.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.Export.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TestImportExport.java</file>
		</fixedFiles>
	</bug>
	<bug id="15668" opendate="2016-04-18 12:28:20" fixdate="2016-04-18 16:54:59" resolution="Fixed">
		<buginformation>
			<summary>HFileReplicator$Copier fails to replicate other hfiles in the request when a hfile in not found in FS anywhere</summary>
			<description>When a hfile is not found either in its source or archive directory then HFileReplicator$Copier will ignore that file and return instead we should ignore and continue with other hfiles replication in that request.</description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.HFileReplicator.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">13153</link>
		</links>
	</bug>
	<bug id="15664" opendate="2016-04-17 11:19:08" fixdate="2016-04-18 19:15:49" resolution="Fixed">
		<buginformation>
			<summary>Use Long.MAX_VALUE instead of HConstants.FOREVER in CompactionPolicy</summary>
			<description>The TTL per CF is in seconds, we will convert it to milliseconds when construct HStore. And if it is HConstants.FOREVER, we will set it to Long.MAX_VALUE.
HStore.java

  public static long determineTTLFromFamily(final HColumnDescriptor family) {
    // HCD.getTimeToLive returns ttl in seconds.  Convert to milliseconds.
    long ttl = family.getTimeToLive();
    if (ttl == HConstants.FOREVER) {
      // Default is unlimited ttl.
      ttl = Long.MAX_VALUE;
    } else if (ttl == -1) {
      ttl = Long.MAX_VALUE;
    } else {
      // Second -&amp;gt; ms adjust for user data
      ttl *= 1000;
    }
    return ttl;
  }

</description>
			<version>0.98.19</version>
			<fixedVersion>2.0.0, 1.3.0, 0.98.19, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.compactions.RatioBasedCompactionPolicy.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.compactions.DateTieredCompactionPolicy.java</file>
		</fixedFiles>
	</bug>
	<bug id="15672" opendate="2016-04-18 22:05:59" fixdate="2016-04-20 00:11:39" resolution="Fixed">
		<buginformation>
			<summary>hadoop.hbase.security.visibility.TestVisibilityLabelsWithDeletes fails</summary>
			<description>016-04-18 15:02:50,632 WARN  [member: '10.22.11.177,55156,1461016964801' subprocedure-pool5-thread-1] flush.RegionServerFlushTableProcedureManager$FlushTableSubprocedurePool(275): Got Exception in FlushSubprocedurePool
java.util.concurrent.ExecutionException: java.lang.IllegalArgumentException: Timestamp cannot be negative. minStamp:-9223372036854775808, maxStamp:128
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:188)
	at org.apache.hadoop.hbase.procedure.flush.RegionServerFlushTableProcedureManager$FlushTableSubprocedurePool.waitForOutstandingTasks(RegionServerFlushTableProcedureManager.java:251)
	at org.apache.hadoop.hbase.procedure.flush.FlushTableSubprocedure.flushRegions(FlushTableSubprocedure.java:102)
	at org.apache.hadoop.hbase.procedure.flush.FlushTableSubprocedure.acquireBarrier(FlushTableSubprocedure.java:113)
	at org.apache.hadoop.hbase.procedure.Subprocedure.call(Subprocedure.java:166)
	at org.apache.hadoop.hbase.procedure.Subprocedure.call(Subprocedure.java:1)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: Timestamp cannot be negative. minStamp:-9223372036854775808, maxStamp:128
	at org.apache.hadoop.hbase.io.TimeRange.&amp;lt;init&amp;gt;(TimeRange.java:81)
	at org.apache.hadoop.hbase.regionserver.TimeRangeTracker.toTimeRange(TimeRangeTracker.java:204)
	at org.apache.hadoop.hbase.regionserver.ImmutableSegment.&amp;lt;init&amp;gt;(ImmutableSegment.java:44)
	at org.apache.hadoop.hbase.regionserver.SegmentFactory.createImmutableSegment(SegmentFactory.java:57)
	at org.apache.hadoop.hbase.regionserver.DefaultMemStore.snapshot(DefaultMemStore.java:93)
	at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.prepare(HStore.java:2151)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalPrepareFlushCache(HRegion.java:2324)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2192)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2163)
	at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:2054)
	at org.apache.hadoop.hbase.regionserver.HRegion.flush(HRegion.java:1980)
	at org.apache.hadoop.hbase.procedure.flush.FlushTableSubprocedure$RegionFlushTask.call(FlushTableSubprocedure.java:68)
	at org.apache.hadoop.hbase.procedure.flush.FlushTableSubprocedure$RegionFlushTask.call(FlushTableSubprocedure.java:1)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)</description>
			<version>0.98.4</version>
			<fixedVersion>2.0.0, 1.3.0, 0.98.19, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.security.visibility.VisibilityController.java</file>
		</fixedFiles>
	</bug>
	<bug id="15360" opendate="2016-02-29 21:12:32" fixdate="2016-04-24 10:42:30" resolution="Fixed">
		<buginformation>
			<summary>Fix flaky TestSimpleRpcScheduler</summary>
			<description>There were several flaky tests added there as part of HBASE-15306 and likely HBASE-15136.</description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">15306</link>
			<link type="Regression" description="is broken by">15136</link>
		</links>
	</bug>
	<bug id="15699" opendate="2016-04-23 14:12:04" fixdate="2016-04-25 05:28:17" resolution="Fixed">
		<buginformation>
			<summary>Can not sync AsyncFSWAL if no edit is appended</summary>
			<description>The problem is the txid that we assign to SyncFuture. In AsyncFSWAL, we will assign a zero txid if no edit is append, and it just equals to SyncFuture.NOT_DONE, so the sync request will never finish...</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestFSHLog.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.SyncFuture.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.java</file>
			<file type="M">org.apache.hadoop.hbase.wal.AsyncFSWALProvider.java</file>
		</fixedFiles>
	</bug>
	<bug id="15634" opendate="2016-04-12 04:18:04" fixdate="2016-04-26 16:27:00" resolution="Fixed">
		<buginformation>
			<summary>TestDateTieredCompactionPolicy#negativeForMajor is flaky</summary>
			<description>https://builds.apache.org/job/PreCommit-HBASE-Build/1365/artifact/patchprocess/patch-unit-hbase-server.txt :


negativeForMajor(org.apache.hadoop.hbase.regionserver.TestDateTieredCompactionPolicy)  Time elapsed: 0.48 sec  &amp;lt;&amp;lt;&amp;lt; FAILURE!
java.lang.AssertionError: expected:&amp;lt;true&amp;gt; but was:&amp;lt;false&amp;gt;
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:144)
	at org.apache.hadoop.hbase.regionserver.TestDateTieredCompactionPolicy.compactEquals(TestDateTieredCompactionPolicy.java:94)
	at org.apache.hadoop.hbase.regionserver.TestDateTieredCompactionPolicy.negativeForMajor(TestDateTieredCompactionPolicy.java:301)


Similar test failure occurred in master JDK 8 build as well (https://builds.apache.org/job/HBase-TRUNK_matrix/839/jdk=latest1.8,label=yahoo-not-h2/testReport/org.apache.hadoop.hbase.regionserver/TestDateTieredCompactionPolicy/negativeForMajor/).
Since TestDateTieredCompactionPolicy is a small test, its failure prevented large tests from running.</description>
			<version>1.4.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 0.98.20</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestDateTieredCompactionPolicy.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.compactions.DateTieredCompactionPolicy.java</file>
		</fixedFiles>
	</bug>
	<bug id="15645" opendate="2016-04-13 15:04:21" fixdate="2016-04-27 17:08:40" resolution="Fixed">
		<buginformation>
			<summary>hbase.rpc.timeout is not used in operations of HTable</summary>
			<description>While fixing HBASE-15593, I find that we use operationTimeout as the timeout of Get operation rpc call (hbase.client.scanner.timeout.period is used in scan rpc), not the hbase.rpc.timeout.
This can be verified by add one line in TestHCM.setUpBeforeClass():


TEST_UTIL.getConfiguration().setLong(HConstants.HBASE_RPC_TIMEOUT_KEY, 3000);


and then run testOperationTimeout(), the test passes but it should have failed because we should get rpc timeout first after 3 seconds then client should retry and timeout again and again until operationTimeout or max retries reached.
If I port this test to 0.98, it will fail as expected.</description>
			<version>1.0.3</version>
			<fixedVersion>2.0.0, 1.3.0, 1.0.4, 1.4.0, 1.1.5, 1.2.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.Table.java</file>
			<file type="M">org.apache.hadoop.hbase.HConstants.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.client.RemoteHTable.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.RegionAsTable.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTableWrapper.java</file>
			<file type="M">org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.client.RpcRetryingCallerFactory.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestHCM.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
		</fixedFiles>
		<links>
			<link type="Regression" description="breaks">16420</link>
		</links>
	</bug>
	<bug id="15707" opendate="2016-04-25 23:26:14" fixdate="2016-04-27 20:51:13" resolution="Fixed">
		<buginformation>
			<summary>ImportTSV bulk output does not support tags with hfile.format.version=3</summary>
			<description>Running the following command:


hbase hbase org.apache.hadoop.hbase.mapreduce.ImportTsv \ 
-Dhfile.format.version=3 \ 
-Dmapreduce.map.combine.minspills=1 \ 
-Dimporttsv.separator=, \ 
-Dimporttsv.skip.bad.lines=false \ 
-Dimporttsv.columns="HBASE_ROW_KEY,cf1:a,HBASE_CELL_TTL" \ 
-Dimporttsv.bulk.output=/tmp/testttl/output/1 \ 
testttl \ 
/tmp/testttl/input 


The content of input is like:


row1,data1,00000060 
row2,data2,00000660 
row3,data3,00000060 
row4,data4,00000660


When running hfile tool with the output hfile, there is no ttl tag.</description>
			<version>1.0.5</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 0.98.20</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TestHFileOutputFormat2.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2.java</file>
		</fixedFiles>
	</bug>
	<bug id="15697" opendate="2016-04-22 21:52:32" fixdate="2016-04-28 08:56:17" resolution="Fixed">
		<buginformation>
			<summary>Excessive TestHRegion running time on branch-1</summary>
			<description>On my dev box TestHRegion takes about 90 seconds to complete in master and about 60 seconds in 0.98, but about 370 seconds in branch-1. Furthermore TestHRegion in branch-1 blew past my open files ulimit. I had to raise it from default in order for the unit to complete at all.
I am going to bisect the recent history of branch-1 in search of a culprit and report back.
master
Running org.apache.hadoop.hbase.regionserver.TestHRegion
Tests run: 102, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 87.299 sec - in org.apache.hadoop.hbase.regionserver.TestHRegion
Running org.apache.hadoop.hbase.regionserver.TestHRegion
Tests run: 102, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 91.529 sec - in org.apache.hadoop.hbase.regionserver.TestHRegion
Running org.apache.hadoop.hbase.regionserver.TestHRegion
Tests run: 102, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 89.23 sec - in org.apache.hadoop.hbase.regionserver.TestHRegion

branch-1
Running org.apache.hadoop.hbase.regionserver.TestHRegion
Tests run: 102, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 368.868 sec - in org.apache.hadoop.hbase.regionserver.TestHRegion
Running org.apache.hadoop.hbase.regionserver.TestHRegion
Tests run: 102, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 366.203 sec - in org.apache.hadoop.hbase.regionserver.TestHRegion
Running org.apache.hadoop.hbase.regionserver.TestHRegion
Tests run: 102, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 345.806 sec - in org.apache.hadoop.hbase.regionserver.TestHRegion

0.98
Running org.apache.hadoop.hbase.regionserver.TestHRegion
Tests run: 90, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 61.038 sec - in org.apache.hadoop.hbase.regionserver.TestHRegion
Running org.apache.hadoop.hbase.regionserver.TestHRegion
Tests run: 90, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 56.382 sec - in org.apache.hadoop.hbase.regionserver.TestHRegion
Running org.apache.hadoop.hbase.regionserver.TestHRegion
Tests run: 90, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 63.509 sec - in org.apache.hadoop.hbase.regionserver.TestHRegion
</description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">14970</link>
		</links>
	</bug>
	<bug id="15676" opendate="2016-04-19 03:54:10" fixdate="2016-04-28 14:04:11" resolution="Fixed">
		<buginformation>
			<summary>FuzzyRowFilter fails and matches all the rows in the table if the mask consists of all 0s</summary>
			<description>While using FuzzyRowFilter we noticed that if the mask array consists of all 0s (fixed) the FuzzyRowFilter matches all the rows in the table. We noticed this on HBase 1.1, 1.2 and higher.
After some digging we suspect that this is because of isPreprocessedMask() check which is used in preprocessMask() which was added here: https://issues.apache.org/jira/browse/HBASE-13761
If the mask consists of all 0s then the isPreprocessedMask() returns true and the preprocessing which responsible for changing 0s to -1 doesn&amp;amp;apos;t happen and hence all rows are matched in scan.
This scenario can be tested in TestFuzzyRowFilterEndToEnd#testHBASE14782() If we change the 
byte[] fuzzyKey = Bytes.toBytesBinary("\\x00\\x00x044");
byte[] mask = new byte[] 
{1,0,0,0}
;
to 
byte[] fuzzyKey = Bytes.toBytesBinary("\\x9B\\x00x044e");
byte[] mask = new byte[] 
{0,0,0,0,0}
;
We expect one match but this will match all the rows in the table. </description>
			<version>0.98.13</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.1.5, 1.2.2, 0.98.20</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.filter.FuzzyRowFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.TestFuzzyRowFilterEndToEnd.java</file>
		</fixedFiles>
	</bug>
	<bug id="15703" opendate="2016-04-25 18:27:13" fixdate="2016-05-02 22:40:46" resolution="Fixed">
		<buginformation>
			<summary>Deadline scheduler needs to return to the client info about skipped calls, not just drop them</summary>
			<description>In AdaptiveLifoCodelCallQueue we drop the calls when we think we&amp;amp;apos;re overloaded, we should instead return CallDroppedException to the cleent or something.</description>
			<version>1.3.0</version>
			<fixedVersion>1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.CallQueueTooBigException.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.AdaptiveLifoCoDelCallQueue.java</file>
			<file type="M">org.apache.hadoop.hbase.client.PreemptiveFastFailInterceptor.java</file>
			<file type="M">org.apache.hadoop.hbase.exceptions.ClientExceptionsUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.CallRunner.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">15136</link>
		</links>
	</bug>
	<bug id="15741" opendate="2016-04-30 01:13:48" fixdate="2016-05-04 19:48:00" resolution="Fixed">
		<buginformation>
			<summary>Provide backward compatibility for HBase coprocessor service names</summary>
			<description>Attempting to run a map reduce job with a 1.3 client on a secure cluster running 1.2 is failing when making the coprocessor rpc to obtain a delegation token:

Exception in thread "main" org.apache.hadoop.hbase.exceptions.UnknownProtocolException: org.apache.hadoop.hbase.exceptions.UnknownProtocolException: No registered coprocessor service found for name hbase.pb.AuthenticationService in region hbase:meta,,1
        at org.apache.hadoop.hbase.regionserver.HRegion.execService(HRegion.java:7741)
        at org.apache.hadoop.hbase.regionserver.RSRpcServices.execServiceOnRegion(RSRpcServices.java:1988)
        at org.apache.hadoop.hbase.regionserver.RSRpcServices.execService(RSRpcServices.java:1970)
        at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:33652)
        at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2170)
        at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:109)
        at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:137)
        at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:112)
        at java.lang.Thread.run(Thread.java:745)

        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
        at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
        at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:95)
        at org.apache.hadoop.hbase.protobuf.ProtobufUtil.getRemoteException(ProtobufUtil.java:332)
        at org.apache.hadoop.hbase.protobuf.ProtobufUtil.execService(ProtobufUtil.java:1631)
        at org.apache.hadoop.hbase.ipc.RegionCoprocessorRpcChannel$1.call(RegionCoprocessorRpcChannel.java:104)
        at org.apache.hadoop.hbase.ipc.RegionCoprocessorRpcChannel$1.call(RegionCoprocessorRpcChannel.java:94)
        at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:137)
        at org.apache.hadoop.hbase.ipc.RegionCoprocessorRpcChannel.callExecService(RegionCoprocessorRpcChannel.java:108)
        at org.apache.hadoop.hbase.ipc.CoprocessorRpcChannel.callBlockingMethod(CoprocessorRpcChannel.java:73)
        at org.apache.hadoop.hbase.protobuf.generated.AuthenticationProtos$AuthenticationService$BlockingStub.getAuthenticationToken(AuthenticationProtos.java:4512)
        at org.apache.hadoop.hbase.security.token.TokenUtil.obtainToken(TokenUtil.java:86)
        at org.apache.hadoop.hbase.security.token.TokenUtil$1.run(TokenUtil.java:111)
        at org.apache.hadoop.hbase.security.token.TokenUtil$1.run(TokenUtil.java:108)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
        at org.apache.hadoop.hbase.security.User$SecureHadoopUser.runAs(User.java:340)
        at org.apache.hadoop.hbase.security.token.TokenUtil.obtainToken(TokenUtil.java:108)
        at org.apache.hadoop.hbase.security.token.TokenUtil.addTokenForJob(TokenUtil.java:329)
        at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initCredentials(TableMapReduceUtil.java:490)
        at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(TableMapReduceUtil.java:209)
        at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(TableMapReduceUtil.java:162)
        at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(TableMapReduceUtil.java:285)
        at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(TableMapReduceUtil.java:86)
        at org.apache.hadoop.hbase.mapreduce.CellCounter.createSubmittableJob(CellCounter.java:193)
        at org.apache.hadoop.hbase.mapreduce.CellCounter.main(CellCounter.java:290)
Caused by: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(org.apache.hadoop.hbase.exceptions.UnknownProtocolException): org.apache.hadoop.hbase.exceptions.UnknownProtocolException: No registered coprocessor service found for name hbase.pb.AuthenticationService in region hbase:meta,,1
        at org.apache.hadoop.hbase.regionserver.HRegion.execService(HRegion.java:7741)
        at org.apache.hadoop.hbase.regionserver.RSRpcServices.execServiceOnRegion(RSRpcServices.java:1988)
        at org.apache.hadoop.hbase.regionserver.RSRpcServices.execService(RSRpcServices.java:1970)
        at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:33652)
        at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2170)
        at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:109)
        at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:137)
        at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:112)
        at java.lang.Thread.run(Thread.java:745)

        at org.apache.hadoop.hbase.ipc.RpcClientImpl.call(RpcClientImpl.java:1270)
        at org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(AbstractRpcClient.java:226)
        at org.apache.hadoop.hbase.ipc.AbstractRpcClient$BlockingRpcChannelImplementation.callBlockingMethod(AbstractRpcClient.java:331)
        at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.execService(ClientProtos.java:35420)
        at org.apache.hadoop.hbase.protobuf.ProtobufUtil.execService(ProtobufUtil.java:1628)
        ... 22 more


This is talking to a 1.2 server.  Running with a 1.2 client works.  I believe this is due to HBASE-14077, where we added package names to the protobuf files.
This is causing 1.2 and 1.3 to disagree on the name of the AuthenticationService:

1.2 = AuthenticationService
1.3 = hbase.pb.AuthenticationService

I think this is effectively a break in client-server wire compatibility between 1.2 and 1.3, since this is calling a built-in coprocessor required for security.</description>
			<version>1.3.0</version>
			<fixedVersion>1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="M">org.apache.hadoop.hbase.coprocessor.protobuf.generated.DummyRegionServerEndpointProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.MasterCoprocessorRpcChannel.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.RegionServerCoprocessorRpcChannel.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.RegionCoprocessorRpcChannel.java</file>
		</fixedFiles>
	</bug>
	<bug id="15669" opendate="2016-04-18 13:09:38" fixdate="2016-05-06 12:03:04" resolution="Fixed">
		<buginformation>
			<summary>HFile size is not considered correctly in a replication request</summary>
			<description>In a single replication request from source cluster a RS can send either at most replication.source.size.capacity size of data or replication.source.nb.capacity entries. 
The size is calculated by considering the cells size in each entry which will get calculated wrongly in case of bulk loaded data replication, in this case we need to consider the size of hfiles not cell.</description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.WALProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.TestReplicationSink.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManager.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.ReplicationSource.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">13153</link>
		</links>
	</bug>
	<bug id="15781" opendate="2016-05-05 22:01:44" fixdate="2016-05-06 17:10:03" resolution="Fixed">
		<buginformation>
			<summary>Remove unused TableEventHandler and TotesHRegionInfo</summary>
			<description>Remove unused classes TableEventHandler and TotesHRegionInfo</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="D">org.apache.hadoop.hbase.master.handler.TotesHRegionInfo.java</file>
			<file type="D">org.apache.hadoop.hbase.master.handler.TableEventHandler.java</file>
		</fixedFiles>
	</bug>
	<bug id="15773" opendate="2016-05-05 17:51:04" fixdate="2016-05-06 18:27:09" resolution="Fixed">
		<buginformation>
			<summary>CellCounter improvements</summary>
			<description>Looking at the CellCounter map reduce, it seems like it can be improved in a few areas:

it does not currently support setting scan batching.  This is important when we&amp;amp;apos;re fetching all versions for columns.  Actually, it would be nice to support all of the scan configuration currently provided in TableInputFormat.
generating job counters containing row keys and column qualifiers is guaranteed to blow up on anything but the smallest table.  This is not usable and doesn&amp;amp;apos;t make any sense when the same counts are in the job output.  The row and qualifier specific counters should be dropped.

</description>
			<version>1.2.0</version>
			<fixedVersion>1.3.0</fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TableInputFormat.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.CellCounter.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">13707</link>
		</links>
	</bug>
	<bug id="13707" opendate="2015-05-18 20:28:18" fixdate="2016-05-06 19:27:01" resolution="Duplicate">
		<buginformation>
			<summary>CellCounter uses to many counters</summary>
			<description>CellCounters creates a counter per row... So it quickly becomes to many.
We should provide an option to drop the statistic per rows and count only cells overall for the table.</description>
			<version>1.0.1</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TableInputFormat.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.CellCounter.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">15773</link>
		</links>
	</bug>
	<bug id="15742" opendate="2016-04-30 14:43:51" fixdate="2016-05-11 03:08:31" resolution="Fixed">
		<buginformation>
			<summary>Reduce allocation of objects in metrics</summary>
			<description>We use JMX and o.a.h.metrics2 to do some metrics on regions, tables, region servers and cluster. We use MetricsInfo to show the information of metrics, and we use Interns to cache MetricsInfo objects because it won&amp;amp;apos;t be changed.
However, in Interns there are some static values to limit the max cached objects. We can only cache 2010 metrics, but we have dozens of metrics for one region and we have some RS-level metrics in each RS and all metrics for all regions will be saved in master. So each server will have thousands of metrics, and we can not cache most of them. When we collect metrics by JMX, we will create many objects which can be avoid. It increases the pressure of GC and JMX has some caching logic so the objects can not be removed immediately which increases the pressure more.
Interns is in Hadoop project, and I think the implementation is not suitable for HBase. Because we can not know how many MetricsInfo we have, it depends on the number of regions. And we can not set it unlimited because we should remove the objects whose region is split, moved, or dropped. I think we can use Guava&amp;amp;apos;s cache with expireAfterAccess which is very simple and convenient.
So we can add a new Interns class in HBase project first, and put it to upstream later.
Moreover, in MutableHistogram#snapshot we create same Strings each time, we can create them only in the first time.</description>
			<version>0.98.19</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.1.5, 1.2.2, 0.98.20</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.MetricsMasterSourceImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.master.balancer.MetricsStochasticBalancerSourceImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsTableAggregateSourceImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegionAggregateSourceImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsTableSourceImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegionSourceImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.master.MetricsMasterProcSourceImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegionServerSourceImpl.java</file>
			<file type="M">org.apache.hadoop.metrics2.lib.DynamicMetricsRegistry.java</file>
			<file type="M">org.apache.hadoop.metrics2.lib.MutableHistogram.java</file>
			<file type="M">org.apache.hadoop.metrics2.lib.MutableRangeHistogram.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.MetricsHBaseServerSourceImpl.java</file>
		</fixedFiles>
	</bug>
	<bug id="13783" opendate="2015-05-27 02:56:16" fixdate="2016-05-13 22:54:22" resolution="Duplicate">
		<buginformation>
			<summary>Improve error message "Could not seek StoreFileScanner" to indicate that issue could be a bad disk</summary>
			<description>Feedback from customers.
Following error could mean that a disk has gone bad. We have seen many users confused by this error. 
java.io.IOException: Could not seek StoreFileScanner[HFileScanner for reader reader=hdfs://XXXX/843914879034b56117dfa6b7f3c8383d/content/b6f5e9961d2d4578aea3917c0637bb7c</description>
			<version>0.94.21</version>
			<fixedVersion></fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.hfile.ChecksumUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.TestChecksum.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">11625</link>
		</links>
	</bug>
	<bug id="15811" opendate="2016-05-10 18:36:37" fixdate="2016-05-14 01:06:13" resolution="Fixed">
		<buginformation>
			<summary>Batch Get after batch Put does not fetch all Cells</summary>
			<description>A big batch put followed by a batch get does not always return all Cells put. See attached test program by Robert Farr that reproduces the issue. It seems to be an issue to do with a cluster of more than one machine. Running against a single machine does not have the problem (though the single machine may have many regions). Robert was unable to make his program fail with a single machine only.
I reproduced what Robert was seeing running his program. I was also unable to make a single machine fail. In a batch of 1000 puts, I see one to three Gets fail. I noticed too that if I wait a second after a fail and then re-get, the Get succeeds.</description>
			<version>0.98.19</version>
			<fixedVersion>1.3.0, 1.2.2, 1.1.6</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.AsyncProcess.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestAsyncProcess.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">15922</link>
		</links>
	</bug>
	<bug id="15615" opendate="2016-04-08 05:40:05" fixdate="2016-05-16 03:54:26" resolution="Fixed">
		<buginformation>
			<summary>Wrong sleep time when RegionServerCallable need retry</summary>
			<description>In RpcRetryingCallerImpl, it get pause time by expectedSleep = callable.sleep(pause, tries + 1); And in RegionServerCallable, it get pasue time by sleep = ConnectionUtils.getPauseTime(pause, tries + 1). So tries will be bumped up twice. And the pasue time is 3 * hbase.client.pause when tries is 0.
RETRY_BACKOFF = 
{1, 2, 3, 5, 10, 20, 40, 100, 100, 100, 100, 200, 200}</description>
			<version>0.98.19</version>
			<fixedVersion>1.3.0, 1.2.2, 0.98.20, 1.1.6</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.TestHCM.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestConnectionUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.client.AbstractRegionServerCallable.java</file>
			<file type="M">org.apache.hadoop.hbase.client.RegionAdminServiceCallable.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ConnectionUtils.java</file>
		</fixedFiles>
	</bug>
	<bug id="15828" opendate="2016-05-14 00:32:29" fixdate="2016-05-16 04:12:26" resolution="Fixed">
		<buginformation>
			<summary>fix extant findbug</summary>
			<description></description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.Future.java</file>
		</fixedFiles>
	</bug>
	<bug id="15848" opendate="2016-05-17 19:42:01" fixdate="2016-05-17 21:09:56" resolution="Fixed">
		<buginformation>
			<summary>Fix possible null point dereference in RSGroupBasedLoadBalancer#getMisplacedRegions()</summary>
			<description>Possible null pointer dereference of local variable &amp;amp;apos;info&amp;amp;apos; in the function RSGroupBasedLoadBalancer#getMisplacedRegions():



      if (assignedServer != null &amp;amp;&amp;amp;
          (info == null || !info.containsServer(assignedServer.getHostPort()))) {
        LOG.debug("Found misplaced region: " + region.getRegionNameAsString() +
            " on server: " + assignedServer +
            " found in group: " +
            RSGroupInfoManager.getRSGroupOfServer(assignedServer.getHostPort()) +
            " outside of group: " + info.getName());
        misplacedRegions.add(region);
      }

</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.rsgroup.RSGroupBasedLoadBalancer.java</file>
		</fixedFiles>
	</bug>
	<bug id="15593" opendate="2016-04-05 12:34:40" fixdate="2016-05-18 12:56:08" resolution="Fixed">
		<buginformation>
			<summary>Time limit of scanning should be offered by client</summary>
			<description>In RSRpcServices.scan, we will set a time limit equaling to Math.min(scannerLeaseTimeoutPeriod, rpcTimeout) / 2, and will response heartbeat message if we reach this limit. However, two timeout settings (hbase.client.scanner.timeout.period and hbase.rpc.timeout) are read from RS&amp;amp;apos;s configure, which may be different from client&amp;amp;apos;s. If client&amp;amp;apos;s setting is much less than server&amp;amp;apos;s, there may still be timeout at client side.</description>
			<version>1.1.4</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.RpcClientImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.AsyncRpcChannelImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.RPCProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.CallRunner.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.RpcServer.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.RpcServerInterface.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestScannerHeartbeatMessages.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">13090</link>
			<link type="Reference" description="is related to">16492</link>
		</links>
	</bug>
	<bug id="15850" opendate="2016-05-18 07:30:33" fixdate="2016-05-18 20:23:41" resolution="Fixed">
		<buginformation>
			<summary>Localize the configuration change in testCheckTableLocks to reduce flakiness of TestHBaseFsck test suite </summary>
			<description>TestHBaseFsck#testCheckTableLocks changes the "hbase.table.lock.expire.ms" config from 10 minutes default value to 1 ms.  This change impacts other tests in the TestHBaseFsck test suite, especially in branch-1.1.  


conf.setLong(TableLockManager.TABLE_LOCK_EXPIRE_TIMEOUT, 1);


The proposed change is to make the configuration change local for testing purpose so that other tests would not be impacted.</description>
			<version>1.1.5</version>
			<fixedVersion>2.0.0, 1.3.0, 1.2.2, 1.1.6</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.TestHBaseFsckOneRS.java</file>
		</fixedFiles>
		<links>
			<link type="Blocker" description="blocks">15852</link>
		</links>
	</bug>
	<bug id="15617" opendate="2016-04-08 16:55:56" fixdate="2016-05-19 02:21:41" resolution="Fixed">
		<buginformation>
			<summary>Canary in regionserver mode might not enumerate all regionservers</summary>
			<description>When running in regionserver mode the Canary is expected to probe for service health one time per regionserver during a probe interval. 
Each time the canary chore fires, we create a RegionServerMonitor, which uses filterRegionServerByName (via getAllRegionServerByName) to enumerate over all table descriptors, find the locations for each table, then assemble the list of regionservers to probe from this result. The list may not contain all live regionservers, if there is a regionserver up but for some reason not serving any regions. To ensure we have the complete list of live regionservers I think it would be better to use Admin#getClusterStatus and enumerate the live server list returned in the result.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.2.2, 0.98.20</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.tool.Canary.java</file>
		</fixedFiles>
	</bug>
	<bug id="15465" opendate="2016-03-15 03:08:39" fixdate="2016-05-20 03:48:05" resolution="Fixed">
		<buginformation>
			<summary>userPermission returned by getUserPermission() for the selected namespace does not have namespace set</summary>
			<description>The request sent is with type = Namespace, but the response returned contains Global permissions (that is, the field of namespace is not set)
It is in hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java, from line 2380, and I made some comments into it


/**
   * A utility used to get permissions for selected namespace.
   * &amp;lt;p&amp;gt;
   * It&amp;amp;apos;s also called by the shell, in case you want to find references.
   *
   * @param protocol the AccessControlService protocol proxy
   * @param namespace name of the namespace
   * @throws ServiceException
   */
  public static List&amp;lt;UserPermission&amp;gt; getUserPermissions(
      AccessControlService.BlockingInterface protocol,
      byte[] namespace) throws ServiceException {
    AccessControlProtos.GetUserPermissionsRequest.Builder builder =
      AccessControlProtos.GetUserPermissionsRequest.newBuilder();
    if (namespace != null) {
      builder.setNamespaceName(ByteStringer.wrap(namespace)); 
    }
    builder.setType(AccessControlProtos.Permission.Type.Namespace);  //builder is set with type = Namespace
    AccessControlProtos.GetUserPermissionsRequest request = builder.build();  //I printed the request, its type is Namespace, which is correct.
    AccessControlProtos.GetUserPermissionsResponse response =  
       protocol.getUserPermissions(null, request);
/* I printed the response, it contains Global permissions, as below, not a Namespace permission.

user_permission {
  user: "a1"
  permission {
    type: Global
    global_permission {
      action: READ
      action: WRITE
      action: ADMIN
      action: EXEC
      action: CREATE
    }
  }
}

AccessControlProtos.GetUserPermissionsRequest has a member called type_ to store the type, but AccessControlProtos.GetUserPermissionsResponse does not.
*/
     
    List&amp;lt;UserPermission&amp;gt; perms = new ArrayList&amp;lt;UserPermission&amp;gt;(response.getUserPermissionCount());
    for (AccessControlProtos.UserPermission perm: response.getUserPermissionList()) {
      perms.add(ProtobufUtil.toUserPermission(perm));  // (1)
    }
    return perms;
  }


it could be more reasonable to return user permissions with namespace set in getUserPermission() for selected namespace ?</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.2.2, 0.98.20</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.security.access.AccessControlLists.java</file>
			<file type="M">org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">10879</link>
			<link type="Reference" description="relates to">14818</link>
		</links>
	</bug>
	<bug id="15856" opendate="2016-05-18 21:54:50" fixdate="2016-05-20 19:36:22" resolution="Fixed">
		<buginformation>
			<summary>Cached Connection instances can wind up with addresses never resolved</summary>
			<description>During periods where DNS is not working properly, we can wind up caching connections to master or regionservers where the initial hostname resolution and the resolution is never re-attempted.  This means that clients will forever get UnknownHostException for any calls.
When constructing a BlockingRpcChannelImplementation, we instantiate the InetSocketAddress to use for the connection.  This instance is then used in the rpc client connection, where we check isUnresolved() and throw an UnknownHostException if that returns true.  However, at this point the rpc channel is already cached in the HConnectionImplementation map of stubs.  So at this point it will never be resolved.
Setting the config for hbase.resolve.hostnames.on.failure masks this issue, since the stub key used is modified to contain the address.  However, even in that case, if DNS fails, an rpc channel instance with unresolved ISA will still be cached in the stubs under the hostname only key.</description>
			<version>0.98.8</version>
			<fixedVersion>2.0.0, 1.3.0, 1.2.2, 0.98.20, 1.1.6</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.zookeeper.MetaTableLocator.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.AbstractRpcClient.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestMasterNoCluster.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestClientTimeouts.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">13960</link>
		</links>
	</bug>
	<bug id="14818" opendate="2015-11-16 17:08:13" fixdate="2016-05-22 03:46:44" resolution="Fixed">
		<buginformation>
			<summary>user_permission does not list namespace permissions</summary>
			<description>The user_permission command does not list namespace permissions:
For example: if I create a new namespace or use an existing namespace and grant a user privileges to that namespace, the command user_permission does not list it. The permission is visible in the acl table.
Example:
hbase(main):005:0&amp;gt;  create_namespace &amp;amp;apos;ns3&amp;amp;apos;
0 row(s) in 0.1640 seconds
hbase(main):007:0&amp;gt; grant &amp;amp;apos;test_user&amp;amp;apos;,&amp;amp;apos;RWXAC&amp;amp;apos;,&amp;amp;apos;@ns3&amp;amp;apos;
0 row(s) in 0.5680 seconds
hbase(main):008:0&amp;gt; user_permission &amp;amp;apos;.*&amp;amp;apos;
User                               Namespace,Table,Family,Qualifier:Permission                                                        
 sh82993                           finance,finance:emp,,: [Permission: actions=READ,WRITE,EXEC,CREATE,ADMIN] 
 @hbaseglobaldba                   hbase,hbase:acl,,: [Permission: actions=EXEC,CREATE,ADMIN] 
 @hbaseglobaloper                  hbase,hbase:acl,,: [Permission: actions=EXEC,ADMIN] 
 hdfs                              hbase,hbase:acl,,: [Permission: actions=READ,WRITE,CREATE,ADMIN,EXEC] 
 sh82993                           ns1,ns1:tbl1,,: [Permission: actions=READ,WRITE,EXEC,CREATE,ADMIN] 
 ns1admin                          ns1,ns1:tbl2,,: [Permission: actions=EXEC,CREATE,ADMIN] 
 @hbaseappltest_ns1funct           ns1,ns1:tbl2,,: [Permission: actions=READ,WRITE,EXEC] 
 ns1funct                          ns1,ns1:tbl2,,: [Permission: actions=READ,WRITE,EXEC,CREATE,ADMIN] 
 hbase                             ns2,ns2:tbl1,,: [Permission: actions=READ,WRITE,EXEC,CREATE,ADMIN] 
9 row(s) in 1.8090 seconds
As you can see user test_user does not appear in the output, but we can see the permission in the ACL table. 
hbase(main):001:0&amp;gt;  scan &amp;amp;apos;hbase:acl&amp;amp;apos;
ROW                                COLUMN+CELL                                                                                        
 @finance                          column=l:sh82993, timestamp=1444405519510, value=RWXCA                                             
 @gcbcppdn                         column=l:hdfs, timestamp=1446141119602, value=RWCXA                                                
 @hbase                            column=l:hdfs, timestamp=1446141485136, value=RWCAX                                                
 @ns1                              column=l:@hbaseappltest_ns1admin, timestamp=1447437007467, value=RWXCA                             
 @ns1                              column=l:@hbaseappltest_ns1funct, timestamp=1447427366835, value=RWX                               
 @ns2                              column=l:@hbaseappltest_ns2admin, timestamp=1446674470456, value=XCA                               
 @ns2                              column=l:test_user, timestamp=1447692840030, value=RWAC                                            
 @ns3                              column=l:test_user, timestamp=1447692860434, value=RWXAC                                           
 finance:emp                       column=l:sh82993, timestamp=1444407723316, value=RWXCA                                             
 hbase:acl                         column=l:@hbaseglobaldba, timestamp=1446590375370, value=XCA                                       
 hbase:acl                         column=l:@hbaseglobaloper, timestamp=1446590387965, value=XA                                       
 hbase:acl                         column=l:hdfs, timestamp=1446141737213, value=RWCAX                                                
 ns1:tbl1                          column=l:sh82993, timestamp=1446674153058, value=RWXCA                                             
 ns1:tbl2                          column=l:@hbaseappltest_ns1funct, timestamp=1447183824580, value=RWX                               
 ns1:tbl2                          column=l:ns1admin, timestamp=1447183766370, value=XCA                                              
 ns1:tbl2                          column=l:ns1funct, timestamp=1447184077545, value=RWXCA                                            
 ns2:tbl1                          column=l:hbase, timestamp=1447182228314, value=RWXCA                                               
11 row(s) in 0.4990 seconds
It would be nice to be able to see namespace permissions via the user_permission &amp;amp;apos;.*&amp;amp;apos; command as scanning the acl table is not the recommended way to view object permissions. Especially if one is looking to access base via a shell and collect ACL information.
Steven</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.2.2, 0.98.20</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.security.access.AccessControlClient.java</file>
			<file type="M">org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">15465</link>
		</links>
	</bug>
	<bug id="15876" opendate="2016-05-22 16:30:39" fixdate="2016-05-23 17:25:59" resolution="Fixed">
		<buginformation>
			<summary>Remove doBulkLoad(Path hfofDir, final HTable table) though it has not been through a full deprecation cycle</summary>
			<description>HBASE-15875 purges the properly deprecated HTable. The method doBulkLoad(Path hfofDir, final HTable table), while it has a deprecated param, the method itself did not get a deprecation label; it is a public method in a public class marked stable. This issue is about getting consensus that it is ok to remove this method used by offline tooling that will break until updated on upgrade to 2.0 w/o a proper deprecation cycle (I think it will be ok to do this  the benefit of our being able to remove HTable is worth this minor inconvenience). We&amp;amp;apos;ll do some ugly patching of this oversight by adding a late deprecation and flagging the removal of this offline method as an incompatible change in 2.0. We&amp;amp;apos;ll add the deprecation in a subissue.
It is a problem removing
  doBulkLoad(Path hfofDir, final HTable table) 
... since this is a public/stable Class.
There is the alternate:
  public void doBulkLoad(Path hfofDir, final Admin admin, Table table,
      RegionLocator regionLocator) throws TableNotFoundException, IOException  {
The former calls the latter.
The latter went in here:


commit ac95cc1fbb951bb9db96f2738f621d1d7cd45739
Author: tedyu &amp;lt;yuzhihong@gmail.com&amp;gt;
Date:   Fri Jan 2 19:48:06 2015 -0800

    HBASE-12783 Create efficient RegionLocator implementation (Solomon Duskis)


This was added in time for release 1.1.0.
So, this method has not gone through a full major version of deprecation.
It will break when someone moves to 2.0. But it is offline method. Not the end of the world.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mob.compactions.PartitionedMobCompactor.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles.java</file>
		</fixedFiles>
	</bug>
	<bug id="15880" opendate="2016-05-23 19:04:41" fixdate="2016-05-23 19:53:59" resolution="Fixed">
		<buginformation>
			<summary>RpcClientImpl#tracedWriteRequest incorrectly closes HTrace span</summary>
			<description>In this method we continue the span and then close it, which causes the current span (the one created by client app around HTabl#get() or similar API call) to be closed incorrectly.


 TraceScope ts = Trace.continueSpan(span);
      try {
        writeRequest(call, priority, span);
      } finally {
        ts.close();
      }

</description>
			<version>1.1.5</version>
			<fixedVersion>1.3.0, 1.2.2, 1.1.6</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.RpcClientImpl.java</file>
		</fixedFiles>
	</bug>
	<bug id="15884" opendate="2016-05-24 09:15:48" fixdate="2016-05-26 14:26:21" resolution="Fixed">
		<buginformation>
			<summary>NPE in StoreFileScanner#skipKVsNewerThanReadpoint during reverse scan</summary>
			<description>Here is a part of skipKVsNewerThanReadpoint method:

      hfs.next();
      setCurrentCell(hfs.getKeyValue());
      if (this.stopSkippingKVsIfNextRow
          &amp;amp;&amp;amp; getComparator().compareRows(cur.getRowArray(), cur.getRowOffset(),
              cur.getRowLength(), startKV.getRowArray(), startKV.getRowOffset(),
              startKV.getRowLength()) &amp;gt; 0) {



If hfs has no more KVs, cur will be set to Null and on on the next step will throw NPE. </description>
			<version>1.2.1</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
		</fixedFiles>
	</bug>
	<bug id="11625" opendate="2014-07-31 06:22:54" fixdate="2016-05-28 10:01:52" resolution="Fixed">
		<buginformation>
			<summary>Reading datablock throws "Invalid HFile block magic" and can not switch to hdfs checksum </summary>
			<description>when using hbase checksum,call readBlockDataInternal() in hfileblock.java, it could happen file corruption but it only can switch to hdfs checksum inputstream till validateBlockChecksum(). If the datablock&amp;amp;apos;s header corrupted when b = new HFileBlock(),it throws the exception "Invalid HFile block magic" and the rpc call fail</description>
			<version>0.94.21</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.2.2, 1.1.6</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.hfile.ChecksumUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.TestChecksum.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">13783</link>
			<link type="Regression" description="breaks">15908</link>
		</links>
	</bug>
	<bug id="15610" opendate="2016-04-07 10:31:24" fixdate="2016-05-29 14:52:41" resolution="Fixed">
		<buginformation>
			<summary>Remove deprecated HConnection for 2.0 thus removing all PB references for 2.0</summary>
			<description>This is sub-task for HBASE-15174.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegionServerBulkLoad.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.ReplicationSinkManager.java</file>
			<file type="M">org.apache.hadoop.hbase.client.MasterCallable.java</file>
			<file type="M">org.apache.hadoop.hbase.TestMetaTableAccessorNoCluster.java</file>
			<file type="M">org.apache.hadoop.hbase.backup.example.HFileArchiveManager.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ClusterConnection.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestRestartCluster.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.WALEditsReplaySink.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
			<file type="M">org.apache.hadoop.hbase.master.RegionStateStore.java</file>
			<file type="M">org.apache.hadoop.hbase.client.RegionAdminServiceCallable.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestRpcControllerFactory.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
			<file type="M">org.apache.hadoop.hbase.rsgroup.TestRSGroupsBase.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ConnectionUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.util.hbck.ReplicationChecker.java</file>
			<file type="M">org.apache.hadoop.hbase.zookeeper.MetaTableLocator.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestConnectionCache.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ConnectionFactory.java</file>
			<file type="M">org.apache.hadoop.hbase.util.MultiThreadedAction.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
			<file type="M">org.apache.hadoop.hbase.rsgroup.TestRSGroups.java</file>
			<file type="M">org.apache.hadoop.hbase.util.MultiThreadedWriter.java</file>
			<file type="M">org.apache.hadoop.hbase.util.BaseTestHBaseFsck.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestAdmin1.java</file>
			<file type="M">org.apache.hadoop.hbase.util.MultiThreadedUpdater.java</file>
			<file type="M">org.apache.hadoop.hbase.util.HBaseFsckRepair.java</file>
			<file type="M">org.apache.hadoop.hbase.wal.WALSplitter.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestHBaseFsckTwoRS.java</file>
			<file type="M">org.apache.hadoop.hbase.client.AsyncProcess.java</file>
			<file type="M">org.apache.hadoop.hbase.client.Connection.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.TestReplicationSinkManager.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint.java</file>
			<file type="M">org.apache.hadoop.hbase.util.HBaseFsck.java</file>
			<file type="M">org.apache.hadoop.hbase.util.ConnectionCache.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestShortCircuitConnection.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestReplicasClient.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTableInterface.java</file>
			<file type="M">org.apache.hadoop.hbase.IntegrationTestRegionReplicaPerf.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ZooKeeperKeepAliveConnection.java</file>
			<file type="M">org.apache.hadoop.hbase.util.MultiThreadedReader.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestClientNoCluster.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestFromClientSide3.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
			<file type="M">org.apache.hadoop.hbase.util.HMerge.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFilesSplitRecovery.java</file>
			<file type="D">org.apache.hadoop.hbase.client.HConnection.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionTestingUtility.java</file>
			<file type="M">org.apache.hadoop.hbase.util.MultiHConnection.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestMasterNoCluster.java</file>
			<file type="M">org.apache.hadoop.hbase.test.IntegrationTestBigLinkedListWithVisibility.java</file>
			<file type="M">org.apache.hadoop.hbase.LocalHBaseCluster.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestReplicaWithCluster.java</file>
			<file type="M">org.apache.hadoop.hbase.client.CoprocessorHConnection.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestHCM.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">14763</link>
			<link type="Incorporates" description="is part of">13784</link>
			<link type="dependent" description="is depended upon by">15174</link>
		</links>
	</bug>
	<bug id="13960" opendate="2015-06-24 09:50:43" fixdate="2016-05-31 13:05:12" resolution="Duplicate">
		<buginformation>
			<summary>HConnection stuck with UnknownHostException </summary>
			<description>when put/get from hbase, if we meet a temporary dns failure causes resolve RS&amp;amp;apos;s host, the error will never recovered. put/get will failed with UnknownHostException forever. 
I checked the code, and the reason maybe:
1. when RegionServerCallable or MultiServerCallable prepare(), it gets a  ClientService.BlockingInterface stub from Hconnection
2. In HConnectionImplementation::getClient, it caches the stub with a BlockingRpcChannelImplementation
3. In BlockingRpcChannelImplementation(), 
     this.isa = new InetSocketAddress(sn.getHostname(), sn.getPort()); If we meet a  temporary dns failure then the "address" in isa will be null.
4. then we launch the real rpc call, the following stack is:
Caused by: java.net.UnknownHostException: unknown host: xxx.host2
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.&amp;lt;init&amp;gt;(RpcClient.java:385)
	at org.apache.hadoop.hbase.ipc.RpcClient.createConnection(RpcClient.java:351)
	at org.apache.hadoop.hbase.ipc.RpcClient.getConnection(RpcClient.java:1523)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1435)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1654)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1712)
Besides, i noticed there is a protection in RpcClient:
if (remoteId.getAddress().isUnresolved()) 
{
        throw new UnknownHostException("unknown host: " + remoteId.getAddress().getHostName());
      }
shouldn&amp;amp;apos;t we do something when this situation occurred? </description>
			<version>0.98.8</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.zookeeper.MetaTableLocator.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.AbstractRpcClient.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestMasterNoCluster.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestClientTimeouts.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">15856</link>
		</links>
	</bug>
	<bug id="15922" opendate="2016-05-31 12:52:13" fixdate="2016-05-31 13:13:08" resolution="Duplicate">
		<buginformation>
			<summary>Fix waitForMaximumCurrentTasks logic in AsyncProcess</summary>
			<description>In current implementation of AsyncProcess#waitForMaximumCurrentTasks, we have below codes:


while ((currentInProgress = this.tasksInProgress.get()) &amp;gt; max) {
      ...
      try {
        synchronized (this.tasksInProgress) {
          if (tasksInProgress.get() != oldInProgress) break;
          this.tasksInProgress.wait(100);
        }
      } catch (InterruptedException e) {
        throw new InterruptedIOException("#" + id + ", interrupted." +
            " currentNumberOfTask=" + currentInProgress);
      }
}


Which will cause end of while loop if there&amp;amp;apos;s any task done inside one loop making taskInProgress.get() no longer equals to oldInProgress
This is a regression issue caused by HBASE-11403 and only exists in branch-1/master branch, we could easily see the difference comparing to latest 0.98 code.</description>
			<version>1.1.4</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.AsyncProcess.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestAsyncProcess.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">15811</link>
		</links>
	</bug>
	<bug id="15932" opendate="2016-06-01 14:16:43" fixdate="2016-06-02 02:38:43" resolution="Fixed">
		<buginformation>
			<summary>Shell test fails due to uninitialized constant</summary>
			<description>In master branch, shell tests fail due to IN_MEMORY_COMPACTION not being found:


Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 32.299 sec &amp;lt;&amp;lt;&amp;lt; FAILURE! - in org.apache.hadoop.hbase.client.rsgroup.TestShellRSGroups
testRunShellTests(org.apache.hadoop.hbase.client.rsgroup.TestShellRSGroups)  Time elapsed: 0.069 sec  &amp;lt;&amp;lt;&amp;lt; ERROR!
org.jruby.embed.EvalFailedException: (NameError) uninitialized constant Java::OrgApacheHadoopHbase::HConstants::IN_MEMORY_COMPACTION
	at org.jruby.embed.internal.EmbedEvalUnitImpl.run(EmbedEvalUnitImpl.java:136)
	at org.jruby.embed.ScriptingContainer.runUnit(ScriptingContainer.java:1263)
	at org.jruby.embed.ScriptingContainer.runScriptlet(ScriptingContainer.java:1308)
	at org.apache.hadoop.hbase.client.rsgroup.TestShellRSGroups.testRunShellTests(TestShellRSGroups.java:101)
Caused by: org.jruby.exceptions.RaiseException: (NameError) uninitialized constant Java::OrgApacheHadoopHbase::HConstants::IN_MEMORY_COMPACTION
	at org.jruby.RubyModule.const_missing(org/jruby/RubyModule.java:2647)
	at Module.const_missing(file:/home/jenkins/yetus-m2/hbase-master-1/org/jruby/jruby-complete/1.6.8/jruby-complete-1.6.8.jar!/META-INF/jruby.home/lib/ruby/gems/1.8/gems/rake-0.8.7/lib/rake.rb:2503)
	at Module.HBaseConstants(/home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/component/hbase-shell/src/main/ruby/hbase.rb:42)
	at (Anonymous).(root)(/home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/component/hbase-shell/src/main/ruby/hbase.rb:34)
	at org.jruby.RubyKernel.require(org/jruby/RubyKernel.java:1062)
	at Kernel.require(/home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/component/hbase-shell/src/main/ruby/hbase.rb:36)

</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.HColumnDescriptor.java</file>
		</fixedFiles>
	</bug>
	<bug id="15955" opendate="2016-06-03 18:35:51" fixdate="2016-06-03 22:58:56" resolution="Fixed">
		<buginformation>
			<summary>Disable action in CatalogJanitor#setEnabled should wait for active cleanup scan to finish</summary>
			<description>When user calls Admin.enableCatalogJanitor(false) to disable the catalog janitor, it expects that the janitor would stop working once the API returns.  It is not true, the janitor could have an active scan going on and clean up unused region.  The &amp;amp;apos;false&amp;amp;apos; state would be enforced during the next background runs.  
To avoid confusing, if &amp;amp;apos;CatalogJanitor.enabled&amp;amp;apos; is true and we want to set to false in CatalogJanitor#setEnabled, the function should wait for the on-going active scan to complete.</description>
			<version>1.0.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.2.2, 1.1.6</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.CatalogJanitor.java</file>
		</fixedFiles>
	</bug>
	<bug id="15889" opendate="2016-05-25 15:33:16" fixdate="2016-06-06 17:51:42" resolution="Fixed">
		<buginformation>
			<summary>String case conversions are locale-sensitive, used without locale</summary>
			<description>Static code analysis is flagging cases of String.toLowerCase and String.toUpperCase being used without Locale. From the API reference:

Note: This method is locale sensitive, and may produce unexpected results if used for strings that are intended to be interpreted locale independently. Examples are programming language identifiers, protocol keys, and HTML tags. For instance, "TITLE".toLowerCase() in a Turkish locale returns "t\u0131tle", where &amp;amp;apos;\u0131&amp;amp;apos; is the LATIN SMALL LETTER DOTLESS I character. To obtain correct results for locale insensitive strings, use toLowerCase(Locale.ROOT).
Many uses of these functions do appear to be looking up classes, etc. and not dealing with stored data, so I&amp;amp;apos;d think there aren&amp;amp;apos;t significant compatibility problems here and specifying the locale is indeed the safer way to go.</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.4.0, 0.98.20</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.Import.java</file>
			<file type="M">org.apache.hadoop.hbase.util.ServerCommandLine.java</file>
			<file type="M">org.apache.hadoop.hbase.util.LoadTestTool.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.AsyncRpcChannelImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.RpcExecutor.java</file>
			<file type="M">org.apache.hadoop.hbase.security.HBaseSaslRpcServer.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestRegionServerHostname.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseClusterManager.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFiles.java</file>
			<file type="M">org.apache.hadoop.hbase.ServerName.java</file>
			<file type="M">org.apache.hadoop.hbase.StripeCompactionsPerformanceEvaluation.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.HThreadedSelectorServerArgs.java</file>
			<file type="M">org.apache.hadoop.hbase.zookeeper.MetaTableLocator.java</file>
			<file type="M">org.apache.hadoop.hbase.HColumnDescriptor.java</file>
			<file type="M">org.apache.hadoop.hbase.RESTApiClusterManager.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.ThriftUtilities.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.RpcClientImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScanBase.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.DataBlockEncodingTool.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.MetricsHBaseServerSourceFactoryImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.test.MetricsAssertHelperImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.util.HBaseFsck.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.MultiTableInputFormatTestBase.java</file>
			<file type="M">org.apache.hadoop.hbase.util.FSUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.util.CompressionTest.java</file>
			<file type="M">org.apache.hadoop.hbase.io.crypto.KeyStoreKeyProvider.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.filter.GzipFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.BaseRowProcessor.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.SubstringComparator.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TableInputFormat.java</file>
			<file type="M">org.apache.hadoop.hbase.util.RegionMover.java</file>
			<file type="M">org.apache.hadoop.hbase.util.DirectMemoryUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.PerformanceEvaluation.java</file>
			<file type="M">org.apache.hadoop.hbase.classification.tools.StabilityOptions.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.util.PoolMap.java</file>
			<file type="M">org.apache.hadoop.hbase.TimedOutTestsListener.java</file>
			<file type="M">org.apache.hadoop.hbase.TestIPv6NIOServerSocketChannel.java</file>
		</fixedFiles>
	</bug>
	<bug id="15698" opendate="2016-04-23 01:21:33" fixdate="2016-06-07 06:14:18" resolution="Fixed">
		<buginformation>
			<summary>Increment TimeRange not serialized to server</summary>
			<description>Before HBase-1.2, the Increment TimeRange set on the client was serialized over to the server. As of HBase 1.2, this appears to no longer be true, as my preIncrement coprocessor always gets HConstants.LATEST_TIMESTAMP as the value of increment.getTimeRange().getMax() regardless of what the client has specified.</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.2.2, 0.98.20, 1.1.6</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
		</fixedFiles>
	</bug>
	<bug id="15957" opendate="2016-06-03 18:51:23" fixdate="2016-06-07 18:46:47" resolution="Fixed">
		<buginformation>
			<summary>RpcClientImpl.close never ends in some circumstances</summary>
			<description>This bug is related to HBASE-14241 and HBASE-13851. 
Fix for HBASE-13851 introduced the check for non alive connections and if connection is not alive, it close it:

        if (!conn.isAlive()) {
          if (connsToClose == null) {
            connsToClose = new HashSet&amp;lt;Connection&amp;gt;();
          }
          connsToClose.add(conn);
        }
....
    if (connsToClose != null) {
      for (Connection conn : connsToClose) {
        if (conn.markClosed(new InterruptedIOException("RpcClient is closing"))) {
          conn.close();
        }
      }
    }



That worked fine until fix for HBASE-14241 introduced handling for interrupt in writer thread:

          try {
            cts = callsToWrite.take();
          } catch (InterruptedException e) {
            markClosed(new InterruptedIOException());
          }


So, if writer thread is running, but connection thread is not started yet, interrupt will cause calling of markClosed which will set shouldCloseConnection flag for the parent connection. And the next time during the handling of non alive connections markClosed will return false and close will not be called. As the result connection will not be removed from the connections pool and RpcClientImpl.close never finish. </description>
			<version>1.1.2</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.2.2, 1.1.6</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.IntegrationTestRpcClient.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.RpcClientImpl.java</file>
		</fixedFiles>
	</bug>
	<bug id="15952" opendate="2016-06-03 13:27:44" fixdate="2016-06-09 13:22:17" resolution="Fixed">
		<buginformation>
			<summary>Bulk load data replication is not working when RS user does not have permission on hfile-refs node</summary>
			<description>In our recent testing in secure cluster we found that when a RS user does not have permission on hfile-refs znode then RS was failing to replicate the bulk loaded data as the hfile-refs znode is created by hbase client and RS user may not have permission to it.</description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.replication.TestReplicationStateBasic.java</file>
			<file type="M">org.apache.hadoop.hbase.master.cleaner.TestReplicationHFileCleaner.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.ReplicationQueuesZKImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.ReplicationQueues.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.ReplicationPeersZKImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.ReplicationQueuesHBaseImpl.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">13153</link>
		</links>
	</bug>
	<bug id="15946" opendate="2016-06-02 19:06:04" fixdate="2016-06-10 17:47:41" resolution="Fixed">
		<buginformation>
			<summary>Eliminate possible security concerns in RS web UI&amp;apos;s store file metrics</summary>
			<description>More from static code analysis: it warns about the invoking of a separate command ("hbase hfile -s -f ...") as a possible security issue in hbase-server/src/main/resources/hbase-webapps/regionserver/storeFile.jsp.
It looks to me like one cannot inject arbitrary shell script or even arbitrary arguments: ProcessBuilder makes that fairly safe and only allows the user to specify the argument that comes after -f. However that does potentially allow them to have the daemon&amp;amp;apos;s user access files they shouldn&amp;amp;apos;t be able to touch, albeit only for reading.
To more explicitly eliminate any threats here, we should add some validation that the file is at least within HBase&amp;amp;apos;s root directory and use the Java API directly instead of invoking a separate executable.</description>
			<version>1.2.1</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.2.2, 0.98.21</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFilePrettyPrinter.java</file>
		</fixedFiles>
	</bug>
	<bug id="15746" opendate="2016-05-02 17:29:24" fixdate="2016-06-14 23:05:53" resolution="Fixed">
		<buginformation>
			<summary>Remove extra RegionCoprocessor preClose() in RSRpcServices#closeRegion</summary>
			<description>The preClose() region coprocessor call gets called 3 times via rpc.
The first one is when we receive the RPC
https://github.com/apache/hbase/blob/master/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java#L1329
The second time is when ask the RS to close the region
https://github.com/apache/hbase/blob/master/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java#L2852
The third time is when the doClose() on the region is executed.
https://github.com/apache/hbase/blob/master/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java#L1419
I&amp;amp;apos;m pretty sure the first one can be removed since, there is no code between that and the second call. and they are a copy-paste.
The second one explicitly says that is to enforce ACLs before starting the operation, which leads me to the fact that the 3rd one in the region gets executed too late in the process. but the region.close() may be called by someone other than the RS, so we should probably leave the preClose() in there (e.g. OpenRegionHandler on failure cleanup). 
any idea?</description>
			<version>0.98.19</version>
			<fixedVersion>2.0.0, 1.3.0, 1.0.4, 1.4.0, 1.2.2, 0.98.21</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">8075</link>
		</links>
	</bug>
	<bug id="16017" opendate="2016-06-13 21:36:34" fixdate="2016-06-15 16:19:18" resolution="Fixed">
		<buginformation>
			<summary>HBase TableOutputFormat has connection leak in getRecordWriter</summary>
			<description>Currently getRecordWriter will not release the connection until jvm terminate, which is not a right assumption given that the function may be invoked many times in the same jvm lifecycle. Inside of mapreduce, the issue has already fixed. 
</description>
			<version>1.1.6</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapred.TableOutputFormat.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">16117</link>
		</links>
	</bug>
	<bug id="15908" opendate="2016-05-28 04:45:26" fixdate="2016-06-16 18:55:58" resolution="Fixed">
		<buginformation>
			<summary>Checksum verification is broken due to incorrect passing of ByteBuffers in DataChecksum</summary>
			<description>It looks like HBASE-11625 (cc stack, Appy) has broken checksum verification? I&amp;amp;apos;m seeing the following on my cluster (1.3.0, Hadoop 2.7).
Caused by: org.apache.hadoop.hbase.io.hfile.CorruptHFileException: Problem reading HFile Trailer from file &amp;lt;file path&amp;gt;
	at org.apache.hadoop.hbase.io.hfile.HFile.pickReaderVersion(HFile.java:497)
	at org.apache.hadoop.hbase.io.hfile.HFile.createReader(HFile.java:525)
	at org.apache.hadoop.hbase.regionserver.StoreFile$Reader.&amp;lt;init&amp;gt;(StoreFile.java:1135)
	at org.apache.hadoop.hbase.regionserver.StoreFileInfo.open(StoreFileInfo.java:259)
	at org.apache.hadoop.hbase.regionserver.StoreFile.open(StoreFile.java:427)
	at org.apache.hadoop.hbase.regionserver.StoreFile.createReader(StoreFile.java:528)
	at org.apache.hadoop.hbase.regionserver.StoreFile.createReader(StoreFile.java:518)
	at org.apache.hadoop.hbase.regionserver.HStore.createStoreFileAndReader(HStore.java:652)
	at org.apache.hadoop.hbase.regionserver.HStore.access$000(HStore.java:117)
	at org.apache.hadoop.hbase.regionserver.HStore$1.call(HStore.java:519)
	at org.apache.hadoop.hbase.regionserver.HStore$1.call(HStore.java:516)
	... 6 more
Caused by: java.lang.IllegalArgumentException: input ByteBuffers must be direct buffers
	at org.apache.hadoop.util.NativeCrc32.nativeComputeChunkedSums(Native Method)
	at org.apache.hadoop.util.NativeCrc32.verifyChunkedSums(NativeCrc32.java:59)
	at org.apache.hadoop.util.DataChecksum.verifyChunkedSums(DataChecksum.java:301)
	at org.apache.hadoop.hbase.io.hfile.ChecksumUtil.validateChecksum(ChecksumUtil.java:120)
	at org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderImpl.validateChecksum(HFileBlock.java:1785)
	at org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderImpl.readBlockDataInternal(HFileBlock.java:1728)
	at org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderImpl.readBlockData(HFileBlock.java:1558)
	at org.apache.hadoop.hbase.io.hfile.HFileBlock$AbstractFSReader$1.nextBlock(HFileBlock.java:1397)
	at org.apache.hadoop.hbase.io.hfile.HFileBlock$AbstractFSReader$1.nextBlockWithBlockType(HFileBlock.java:1405)
	at org.apache.hadoop.hbase.io.hfile.HFileReaderV2.&amp;lt;init&amp;gt;(HFileReaderV2.java:151)
	at org.apache.hadoop.hbase.io.hfile.HFileReaderV3.&amp;lt;init&amp;gt;(HFileReaderV3.java:78)
	at org.apache.hadoop.hbase.io.hfile.HFile.pickReaderVersion(HFile.java:487)
	... 16 more
Prior this change we won&amp;amp;apos;t use use native crc32 checksum verification as in Hadoop&amp;amp;apos;s DataChecksum#verifyChunkedSums we would go this codepath
if (data.hasArray() &amp;amp;&amp;amp; checksums.hasArray()) 
{
  &amp;lt;check native checksum, but using byte[] instead of byte buffers&amp;gt;
}

So we were fine. However, now we&amp;amp;apos;re dropping below and try to use the slightly different variant of native crc32 (if one is available)  taking ByteBuffer instead of byte[], which expects DirectByteBuffer, not Heap BB. 
I think easiest fix working on all Hadoops would be to remove asReadonly() conversion here:
!validateChecksum(offset, onDiskBlockByteBuffer.asReadOnlyBuffer(), hdrSize)) {
I don&amp;amp;apos;t see why do we need it. Let me test.</description>
			<version>1.3.0</version>
			<fixedVersion>1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
		</fixedFiles>
		<links>
			<link type="Regression" description="is broken by">11625</link>
		</links>
	</bug>
	<bug id="16047" opendate="2016-06-16 19:21:14" fixdate="2016-06-16 21:15:57" resolution="Fixed">
		<buginformation>
			<summary>TestFastFail is broken again</summary>
			<description>As found by Appy here - http://hbase.x10host.com/flaky-tests/
Has been failing since https://builds.apache.org/job/HBase-Flaky-Tests/1294/#showFailuresLink,</description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.TestFastFail.java</file>
		</fixedFiles>
	</bug>
	<bug id="15467" opendate="2016-03-15 18:03:49" fixdate="2016-06-18 00:38:05" resolution="Fixed">
		<buginformation>
			<summary>Remove 1.x/2.0 TableDescriptor incompatibility</summary>
			<description>I&amp;amp;apos;m experimenting with Master on "2.0" and RSs on 1.x and the first problem that I get is on createTable where the Master is trying to write the HTD as TableDescriptor instead of TableSchema and the RS is not able to read it.
Since TableDescriptor does nothing for now. I&amp;amp;apos;d say we can remove it. </description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="M">org.apache.hadoop.hbase.master.procedure.MasterProcedureTestingUtility.java</file>
			<file type="M">org.apache.hadoop.hbase.HTableDescriptor.java</file>
			<file type="M">org.apache.hadoop.hbase.util.Merge.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.CompactionTool.java</file>
			<file type="M">org.apache.hadoop.hbase.master.procedure.TestTableDescriptorModificationFromClient.java</file>
			<file type="M">org.apache.hadoop.hbase.TableDescriptors.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
			<file type="D">org.apache.hadoop.hbase.TableDescriptor.java</file>
			<file type="M">org.apache.hadoop.hbase.snapshot.SnapshotManifest.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestMergeTool.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TableStateManager.java</file>
			<file type="M">org.apache.hadoop.hbase.snapshot.SnapshotTestingUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.master.MasterFileSystem.java</file>
			<file type="M">org.apache.hadoop.hbase.master.procedure.CloneSnapshotProcedure.java</file>
			<file type="M">org.apache.hadoop.hbase.util.HBaseFsck.java</file>
			<file type="D">org.apache.hadoop.hbase.TestTableDescriptor.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.master.procedure.CreateTableProcedure.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestFSTableDescriptors.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestDefaultMemStore.java</file>
			<file type="M">org.apache.hadoop.hbase.TestHColumnDescriptorDefaultVersions.java</file>
			<file type="M">org.apache.hadoop.hbase.master.procedure.TruncateTableProcedure.java</file>
			<file type="M">org.apache.hadoop.hbase.util.HMerge.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestRegionMergeTransactionOnCluster.java</file>
			<file type="M">org.apache.hadoop.hbase.util.FSTableDescriptors.java</file>
		</fixedFiles>
	</bug>
	<bug id="16058" opendate="2016-06-17 17:37:14" fixdate="2016-06-18 02:04:08" resolution="Fixed">
		<buginformation>
			<summary>TestHRegion fails on 1.4 builds</summary>
			<description>Results :
Failed tests: 
org.apache.hadoop.hbase.regionserver.TestHRegion.testFlushSizeAccounting(org.apache.hadoop.hbase.regionserver.TestHRegion)
  Run 1: TestHRegion.testFlushSizeAccounting:465 expected:&amp;lt;384&amp;gt; but was:&amp;lt;368&amp;gt;
  Run 2: TestHRegion.testFlushSizeAccounting:465 expected:&amp;lt;384&amp;gt; but was:&amp;lt;368&amp;gt;
  Run 3: TestHRegion.testFlushSizeAccounting:465 expected:&amp;lt;384&amp;gt; but was:&amp;lt;368&amp;gt;
org.apache.hadoop.hbase.regionserver.TestHRegion.testMemstoreSizeAccountingWithFailedPostBatchMutate(org.apache.hadoop.hbase.regionserver.TestHRegion)
  Run 1: TestHRegion.testMemstoreSizeAccountingWithFailedPostBatchMutate:434 memstoreSize should be incremented expected:&amp;lt;448&amp;gt; but was:&amp;lt;432&amp;gt;
  Run 2: TestHRegion.testMemstoreSizeAccountingWithFailedPostBatchMutate:434 memstoreSize should be incremented expected:&amp;lt;448&amp;gt; but was:&amp;lt;432&amp;gt;
  Run 3: TestHRegion.testMemstoreSizeAccountingWithFailedPostBatchMutate:434 memstoreSize should be incremented expected:&amp;lt;448&amp;gt; but was:&amp;lt;432&amp;gt;
Tests run: 2567, Failures: 2, Errors: 0, Skipped: 56</description>
			<version>1.4.0</version>
			<fixedVersion>2.0.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">15950</link>
		</links>
	</bug>
	<bug id="16066" opendate="2016-06-19 09:04:19" fixdate="2016-06-19 09:27:49" resolution="Fixed">
		<buginformation>
			<summary>Resolve RpC_REPEATED_CONDITIONAL_TEST findbugs warnings in HMaster</summary>
			<description>As titled, find this issue in findbugs report of HBASE-16032:

Code	Warning
RpC	Repeated conditional test in org.apache.hadoop.hbase.master.HMaster.normalizeRegions()
Bug type RpC_REPEATED_CONDITIONAL_TEST (click for details) 
In class org.apache.hadoop.hbase.master.HMaster
In method org.apache.hadoop.hbase.master.HMaster.normalizeRegions()
At HMaster.java:[line 1388]
At HMaster.java:[line 1388]


And we could find below lines in HMaster line 1388:


        if (table.isSystemTable() || (tblDesc != null &amp;amp;&amp;amp;
            tblDesc != null &amp;amp;&amp;amp;
            !tblDesc.isNormalizationEnabled())) {


where there&amp;amp;apos;s a duplicated check, introduced by HBASE-15467</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
		</fixedFiles>
	</bug>
	<bug id="14485" opendate="2015-09-24 22:19:04" fixdate="2016-06-20 19:31:35" resolution="Fixed">
		<buginformation>
			<summary>ConnectionImplementation leaks on construction failure</summary>
			<description>If an exception is thrown in the constructor of ConnectionImplementation we will have a leak zkRegistry, rpcClient, ...
an example was clusterId parse error, causing zk (registry) leaks

org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:238)
	... 22 more
Caused by: java.lang.ExceptionInInitializerError
	at org.apache.hadoop.hbase.ClusterId.parseFrom(ClusterId.java:64)
	at org.apache.hadoop.hbase.zookeeper.ZKClusterId.readClusterIdZNode(ZKClusterId.java:75)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry.java:86)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.retrieveClusterId(ConnectionManager.java:850)

</description>
			<version>1.0.1.1</version>
			<fixedVersion>2.0.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
			<file type="M">org.apache.hadoop.hbase.client.RegistryFactory.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestAsyncProcess.java</file>
		</fixedFiles>
	</bug>
	<bug id="16032" opendate="2016-06-15 14:50:56" fixdate="2016-06-21 18:36:49" resolution="Fixed">
		<buginformation>
			<summary>Possible memory leak in StoreScanner</summary>
			<description>We observed frequent fullGC of RS in our production environment, and after analyzing the heapdump, we found large memory occupancy by HStore#changedReaderObservers, the map is surprisingly containing 7500w objects...
After some debugging, I located some possible memory leak in StoreScanner constructor:


  public StoreScanner(Store store, ScanInfo scanInfo, Scan scan, final NavigableSet&amp;lt;byte[]&amp;gt; columns,
      long readPt)
  throws IOException {
    this(store, scan, scanInfo, columns, readPt, scan.getCacheBlocks());
    if (columns != null &amp;amp;&amp;amp; scan.isRaw()) {
      throw new DoNotRetryIOException("Cannot specify any column for a raw scan");
    }
    matcher = new ScanQueryMatcher(scan, scanInfo, columns,
        ScanType.USER_SCAN, Long.MAX_VALUE, HConstants.LATEST_TIMESTAMP,
        oldestUnexpiredTS, now, store.getCoprocessorHost());

    this.store.addChangedReaderObserver(this);

    // Pass columns to try to filter out unnecessary StoreFiles.
    List&amp;lt;KeyValueScanner&amp;gt; scanners = getScannersNoCompaction();
    ...
    seekScanners(scanners, matcher.getStartKey(), explicitColumnQuery
        &amp;amp;&amp;amp; lazySeekEnabledGlobally, parallelSeekEnabled);
    ...
    resetKVHeap(scanners, store.getComparator());
  }


If there&amp;amp;apos;s any Exception thrown after this.store.addChangedReaderObserver(this), the returned scanner might be null and there&amp;amp;apos;s no chance to remove the scanner from changedReaderObservers, like in HRegion#get


    RegionScanner scanner = null;
    try {
      scanner = getScanner(scan);
      scanner.next(results);
    } finally {
      if (scanner != null)
        scanner.close();
    }


What&amp;amp;apos;s more, all exception thrown in the HRegion#getScanner path will cause scanner==null then memory leak, so we also need to handle this part.</description>
			<version>0.98.20</version>
			<fixedVersion>2.0.0, 1.3.0, 1.2.2, 1.1.6, 0.98.21</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">16012</link>
		</links>
	</bug>
	<bug id="16062" opendate="2016-06-17 23:52:39" fixdate="2016-06-22 04:13:38" resolution="Fixed">
		<buginformation>
			<summary>Improper error handling in WAL Reader/Writer creation</summary>
			<description>If creation of WAL reader/ writer fails for some reason RS may leak hanging socket in CLOSE_WAIT state. </description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.2.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.wal.FSHLogProvider.java</file>
			<file type="M">org.apache.hadoop.hbase.wal.WALFactory.java</file>
		</fixedFiles>
	</bug>
	<bug id="16012" opendate="2016-06-13 10:39:04" fixdate="2016-06-22 09:15:57" resolution="Fixed">
		<buginformation>
			<summary>Major compaction can&amp;apos;t work due to obsolete scanner read point in RegionServer</summary>
			<description>When new RegionScanner, it will add a scanner read point in scannerReadPoints. But if we got a exception after add read point, the read point will keep in regions server and the delete after this mvcc number will never be compacted.
Our hbase version is base 0.94. If it throws other exception when initialize RegionScanner, the master branch has this bug, too.
ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: Failed openScanner java.io.IOException: Could not seek StoreFileScanner
  at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seek(StoreFileScanner.java:160)
  at org.apache.hadoop.hbase.regionserver.StoreScanner.seekScanners(StoreScanner.java:268)
  at org.apache.hadoop.hbase.regionserver.StoreScanner.&amp;lt;init&amp;gt;(StoreScanner.java:168)
  at org.apache.hadoop.hbase.regionserver.Store.getScanner(Store.java:2232)
  at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.&amp;lt;init&amp;gt;(HRegion.java:4026)
  at org.apache.hadoop.hbase.regionserver.HRegion.instantiateRegionScanner(HRegion.java:1895)
  at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1879)
  at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1854)
  at org.apache.hadoop.hbase.regionserver.HRegionServer.internalOpenScanner(HRegionServer.java:3032)
  at org.apache.hadoop.hbase.regionserver.HRegionServer.openScanner(HRegionServer.java:2995)
  at sun.reflect.GeneratedMethodAccessor67.invoke(Unknown Source)
  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
  at java.lang.reflect.Method.invoke(Method.java:597)
  at org.apache.hadoop.hbase.ipc.SecureRpcEngine$Server.call(SecureRpcEngine.java:338)
  at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1595)
Caused by: org.apache.hadoop.hbase.ipc.CallerDisconnectedException: Aborting call openScanner, since caller disconnected
  at org.apache.hadoop.hbase.ipc.HBaseServer$Call.throwExceptionIfCallerDisconnected(HBaseServer.java:475)
  at org.apache.hadoop.hbase.io.hfile.HFileBlock$AbstractFSReader.readAtOffset(HFileBlock.java:1443)
  at org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderV2.readBlockDataInternal(HFileBlock.java:1902)
  at org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderV2.readBlockData(HFileBlock.java:1766)
  at org.apache.hadoop.hbase.io.hfile.HFileReaderV2.readBlock(HFileReaderV2.java:345)
  at org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexReader.loadDataBlockWithScanInfo(HFileBlockIndex.java:254)
  at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.seekTo(HFileReaderV2.java:499)
  at org.apache.hadoop.hbase.io.hfile.HFileReaderV2$AbstractScannerV2.seekTo(HFileReaderV2.java:520)
  at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekAtOrAfter(StoreFileScanner.java:235)
  at org.apache.hadoop.hbase.regionserver.StoreFileScanner.seek(StoreFileScanner.java:148)
  ... 14 more</description>
			<version>0.94.27</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.2.2, 1.1.6, 0.98.21</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">16032</link>
		</links>
	</bug>
	<bug id="16103" opendate="2016-06-24 08:18:29" fixdate="2016-06-24 19:23:56" resolution="Fixed">
		<buginformation>
			<summary>Procedure v2 - TestCloneSnapshotProcedure relies on execution order</summary>
			<description>https://builds.apache.org/view/All/job/HBase-Trunk_matrix/jdk=latest1.8,label=yahoo-not-h2/1100/ 
the TestCloneSnapshotProcedure is written in a way that relies on the execution order and does not tolerate failure of a previous test.
getSnapshot() has a cached snapshot. if we haven&amp;amp;apos;t created yet we will create it.
(from how the code is written is a bit unclear that where we are taking the snapshot, so in the patch I moved out the call to make it more readable)
In this case we started with testCloneSnapshotToSameTable and it failed because the table was waiting for flushes and compaction and it took a long time.

org.apache.hadoop.hbase.snapshot.SnapshotTestingUtils.waitForTableToBeOnline(SnapshotTestingUtils.java:737)
  at org.apache.hadoop.hbase.snapshot.SnapshotTestingUtils.loadData(SnapshotTestingUtils.java:799)
  at org.apache.hadoop.hbase.snapshot.SnapshotTestingUtils.loadData(SnapshotTestingUtils.java:770)
  at org.apache.hadoop.hbase.master.procedure.TestCloneSnapshotProcedure.getSnapshot(TestCloneSnapshotProcedure.java:114)
  at org.apache.hadoop.hbase.master.procedure.TestCloneSnapshotProcedure.testCloneSnapshotToSameTable(TestCloneSnapshotProcedure.java:176)


when we got to testRollbackAndDoubleExecution which stop and start the executor to simulate crashes the snapshot. we ask the executor to stop and then we asked to take a snapshot, but of course the executor is not running so we are stuck there. 
Similarly if we run TestCloneSnapshotProcedure#testRollbackAndDoubleExecution alone, this will always fail because of the above. the snapshot cannot be taken because we stopped the executor. the test here was written relying on the execution order. easy fix is to take the snapshot before stopping the executor for the clone failure simulation as it is supposed to be.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.procedure.TestCloneSnapshotProcedure.java</file>
		</fixedFiles>
	</bug>
	<bug id="15976" opendate="2016-06-07 03:15:14" fixdate="2016-06-29 09:59:10" resolution="Fixed">
		<buginformation>
			<summary>RegionServerMetricsWrapperRunnable will be failure  when disable blockcache.</summary>
			<description>When i disable blockcache, the code "cacheStats = blockCache.getStats();" will occur NPE in org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.RegionServerMetricsWrapperRunnable.
It lead to many regionserver&amp;amp;apos;s metrics&amp;amp;apos; value always equal 0.</description>
			<version>0.98.15</version>
			<fixedVersion>2.0.0, 1.3.0, 1.0.4, 1.4.0, 1.2.2, 1.1.6, 0.98.21</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.MetricsRegionServerWrapperImpl.java</file>
		</fixedFiles>
	</bug>
	<bug id="14763" opendate="2015-11-04 23:10:11" fixdate="2016-06-30 01:17:09" resolution="Duplicate">
		<buginformation>
			<summary>Remove usages of deprecated HConnection </summary>
			<description>HConnection was deprecated in 1.0.0.  There are two interfaces that are supposed to be used instead  Connection for client programs and ClusterConnection for internal hbaes and special tools (LoadIncremental, HBCK, etc).
</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegionServerBulkLoad.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.ReplicationSinkManager.java</file>
			<file type="M">org.apache.hadoop.hbase.client.MasterCallable.java</file>
			<file type="M">org.apache.hadoop.hbase.TestMetaTableAccessorNoCluster.java</file>
			<file type="M">org.apache.hadoop.hbase.backup.example.HFileArchiveManager.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ClusterConnection.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestRestartCluster.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.WALEditsReplaySink.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
			<file type="M">org.apache.hadoop.hbase.master.RegionStateStore.java</file>
			<file type="M">org.apache.hadoop.hbase.client.RegionAdminServiceCallable.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestRpcControllerFactory.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
			<file type="M">org.apache.hadoop.hbase.rsgroup.TestRSGroupsBase.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ConnectionUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.util.hbck.ReplicationChecker.java</file>
			<file type="M">org.apache.hadoop.hbase.zookeeper.MetaTableLocator.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestConnectionCache.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ConnectionFactory.java</file>
			<file type="M">org.apache.hadoop.hbase.util.MultiThreadedAction.java</file>
			<file type="M">org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
			<file type="M">org.apache.hadoop.hbase.rsgroup.TestRSGroups.java</file>
			<file type="M">org.apache.hadoop.hbase.util.MultiThreadedWriter.java</file>
			<file type="M">org.apache.hadoop.hbase.util.BaseTestHBaseFsck.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestAdmin1.java</file>
			<file type="M">org.apache.hadoop.hbase.util.MultiThreadedUpdater.java</file>
			<file type="M">org.apache.hadoop.hbase.util.HBaseFsckRepair.java</file>
			<file type="M">org.apache.hadoop.hbase.wal.WALSplitter.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestHBaseFsckTwoRS.java</file>
			<file type="M">org.apache.hadoop.hbase.client.AsyncProcess.java</file>
			<file type="M">org.apache.hadoop.hbase.client.Connection.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.TestReplicationSinkManager.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint.java</file>
			<file type="M">org.apache.hadoop.hbase.util.HBaseFsck.java</file>
			<file type="M">org.apache.hadoop.hbase.util.ConnectionCache.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestShortCircuitConnection.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestReplicasClient.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTableInterface.java</file>
			<file type="M">org.apache.hadoop.hbase.IntegrationTestRegionReplicaPerf.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ZooKeeperKeepAliveConnection.java</file>
			<file type="M">org.apache.hadoop.hbase.util.MultiThreadedReader.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestClientNoCluster.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestFromClientSide3.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
			<file type="M">org.apache.hadoop.hbase.util.HMerge.java</file>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TestLoadIncrementalHFilesSplitRecovery.java</file>
			<file type="D">org.apache.hadoop.hbase.client.HConnection.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionTestingUtility.java</file>
			<file type="M">org.apache.hadoop.hbase.util.MultiHConnection.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestMasterNoCluster.java</file>
			<file type="M">org.apache.hadoop.hbase.test.IntegrationTestBigLinkedListWithVisibility.java</file>
			<file type="M">org.apache.hadoop.hbase.LocalHBaseCluster.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestReplicaWithCluster.java</file>
			<file type="M">org.apache.hadoop.hbase.client.CoprocessorHConnection.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestHCM.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">15610</link>
		</links>
	</bug>
	<bug id="16125" opendate="2016-06-27 19:24:20" fixdate="2016-07-01 17:04:32" resolution="Fixed">
		<buginformation>
			<summary>RegionMover uses hardcoded, Unix-style tmp folder - breaks Windows</summary>
			<description>The issue exists in all branches.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.RegionMover.java</file>
		</fixedFiles>
	</bug>
	<bug id="16135" opendate="2016-06-28 10:19:27" fixdate="2016-07-04 12:42:18" resolution="Fixed">
		<buginformation>
			<summary>PeerClusterZnode under rs of removed peer may never be deleted</summary>
			<description>One of our cluster run out of space recently, and we found that the .oldlogs directory had almost the same size as the data directory.
Finally we found the problem is that, we removed a peer abort 3 months ago, but there are still some replication queue znode under some rs nodes. This prevents the deletion of .oldlogs.</description>
			<version>0.98.20</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.1.6, 0.98.21, 1.2.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManager.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.ReplicationQueuesZKImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManagerZkImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.TestTableBasedReplicationSourceManagerImpl.java</file>
		</fixedFiles>
		<links>
			<link type="Supercedes" description="supercedes">14476</link>
		</links>
	</bug>
	<bug id="16091" opendate="2016-06-23 09:38:51" fixdate="2016-07-05 18:14:14" resolution="Fixed">
		<buginformation>
			<summary>Canary takes lot more time when there are delete markers in the table</summary>
			<description>We have a table which has lot of delete markers and we running Canary test on a regular interval sometimes tests are timing out because to reading first row would skip all these delete markers. Since purpose of Canary is to find health of the region, i think keeping raw=true would not defeat the purpose but provide good perf improvement. 
Following are the example of one such scan where 
without changing code it took 62.3 sec for onre region scan
2016-06-23 08:49:11,670 INFO  [pool-2-thread-1] tool.Canary - read from region  &amp;lt;tablename&amp;gt;.&amp;lt;region&amp;gt; column family 0 in 62338ms
whereas after setting raw=true, it reduced to 58ms
2016-06-23 08:45:20,259 INFO  [pool-2-thread-1] tests.Canary - read from region &amp;lt;tablename&amp;gt;.&amp;lt;region&amp;gt; column family 0 in 58ms
Taking this over multiple tables , with multiple region would be a good performance gain.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0, 1.4.0, 0.98.21</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.tool.Canary.java</file>
			<file type="M">org.apache.hadoop.hbase.tool.TestCanaryTool.java</file>
			<file type="M">org.apache.hadoop.hbase.HConstants.java</file>
		</fixedFiles>
	</bug>
	<bug id="16074" opendate="2016-06-20 21:48:24" fixdate="2016-07-10 15:23:42" resolution="Fixed">
		<buginformation>
			<summary>ITBLL fails, reports lost big or tiny families</summary>
			<description>Underlying MR jobs succeed but I&amp;amp;apos;m seeing the following in the logs (mid-size distributed test cluster):
ERROR test.IntegrationTestBigLinkedList$Verify: Found nodes which lost big or tiny families, count=164
I do not know exactly yet whether it&amp;amp;apos;s a bug, a test issue or env setup issue, but need figure it out. Opening this to raise awareness and see if someone saw that recently.
</description>
			<version>0.98.20</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.TimeRange.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StripeStoreFlusher.java</file>
			<file type="M">org.apache.hadoop.hbase.HConstants.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestTimeRangeTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.mob.DefaultMobStoreFlusher.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestQueryMatcher.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFileReader.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
			<file type="M">org.apache.hadoop.hbase.KeyValueUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.client.Query.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFileWriter.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.ExplicitColumnTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TimeRangeTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.ScanQueryMatcher.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.Store.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">15650</link>
			<link type="Reference" description="relates to">16175</link>
		</links>
	</bug>
	<bug id="16160" opendate="2016-07-01 02:57:19" fixdate="2016-07-11 17:50:31" resolution="Fixed">
		<buginformation>
			<summary>Get the UnsupportedOperationException when using delegation token with encryption</summary>
			<description>Using delegation token with encryption, when do the Put operation, will get the following exception:
[RpcServer.FifoWFPBQ.priority.handler=5,queue=1,port=48345] ipc.CallRunner(161): RpcServer.FifoWFPBQ.priority.handler=5,queue=1,port=48345: caught: java.lang.UnsupportedOperationException
        at java.nio.ByteBuffer.array(ByteBuffer.java:959)
        at org.apache.hadoop.hbase.ipc.BufferChain.getBytes(BufferChain.java:66)
        at org.apache.hadoop.hbase.ipc.RpcServer$Call.wrapWithSasl(RpcServer.java:547)
        at org.apache.hadoop.hbase.ipc.RpcServer$Call.setResponse(RpcServer.java:467)
        at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:140)
        at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:189)
        at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:169)</description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 0.98.21</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.BufferChain.java</file>
			<file type="M">org.apache.hadoop.hbase.security.token.TestGenerateDelegationToken.java</file>
		</fixedFiles>
	</bug>
	<bug id="16081" opendate="2016-06-22 01:47:30" fixdate="2016-07-12 01:16:05" resolution="Fixed">
		<buginformation>
			<summary>Replication remove_peer gets stuck and blocks WAL rolling</summary>
			<description>We use a blocking take from CompletionService in HBaseInterClusterReplicationEndpoint. When we remove a peer, we try to shut down all threads gracefully. But, under certain race condition, the underlying executor gets shutdown and the CompletionService#take will block forever, which means the remove_peer call will never gracefully finish.
Since ReplicationSourceManager#removePeer and ReplicationSourceManager#recordLog lock on the same object, we are not able to roll WALs in such a situation and will end up with gigantic WALs.</description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.HBaseInterClusterReplicationEndpoint.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.ReplicationEndpoint.java</file>
		</fixedFiles>
	</bug>
	<bug id="16207" opendate="2016-07-11 17:15:16" fixdate="2016-07-12 13:29:16" resolution="Fixed">
		<buginformation>
			<summary>can&amp;apos;t restore snapshot without "Admin" permission</summary>
			<description>MasterRpcServices.restoreSnapshot() tries to verify if the NS exists before starting the restore, but instead of calling ensureNamespaceExists() it calls master.getNamespace() which requires ADMIN permission to get the NS descriptor. 


public RestoreSnapshotResponse restoreSnapshot(RpcController controller,
...
  // Ensure namespace exists. Will throw exception if non-known NS.
  master.getNamespace(dstTable.getNamespaceAsString());


unfortunately i&amp;amp;apos;m not aware of any unit-test that cover this kind of situations. we cover single ACLs from the TestAccessController but we don&amp;amp;apos;t exercise rpc calls and verify if there is more than one check on the ACLs like in this case</description>
			<version>1.1.5</version>
			<fixedVersion>2.0.0, 1.3.0, 1.1.6, 0.98.21, 1.2.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.MasterRpcServices.java</file>
		</fixedFiles>
	</bug>
	<bug id="16144" opendate="2016-06-29 06:55:38" fixdate="2016-07-18 02:02:34" resolution="Fixed">
		<buginformation>
			<summary>Replication queue&amp;apos;s lock will live forever if RS acquiring the lock has died prematurely</summary>
			<description>In default, we will use multi operation when we claimQueues from ZK. But if we set hbase.zookeeper.useMulti=false, we will add a lock first, then copy nodes, finally clean old queue and the lock. 
However, if the RS acquiring the lock crash before claimQueues done, the lock will always be there and other RS can never claim the queue.</description>
			<version>0.98.20</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.1.6, 1.2.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.replication.ReplicationFactory.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.TestMultiSlaveReplication.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.ReplicationQueuesZKImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="D">org.apache.hadoop.hbase.master.cleaner.ReplicationZKLockCleanerChore.java</file>
		</fixedFiles>
	</bug>
	<bug id="16076" opendate="2016-06-21 04:56:55" fixdate="2016-07-18 02:29:46" resolution="Fixed">
		<buginformation>
			<summary>Cannot configure split policy in HBase shell</summary>
			<description>The reference guide explains how to configure split policy in HBase shell(link).

Configuring the Split Policy On a Table Using HBase Shell
hbase&amp;gt; create &amp;amp;apos;test&amp;amp;apos;, {METHOD =&amp;gt; &amp;amp;apos;table_att&amp;amp;apos;, CONFIG =&amp;gt; {&amp;amp;apos;SPLIT_POLICY&amp;amp;apos; =&amp;gt; &amp;amp;apos;org.apache.hadoop.hbase.regionserver.ConstantSizeRegionSplitPolicy&amp;amp;apos;}},
{NAME =&amp;gt; &amp;amp;apos;cf1&amp;amp;apos;}


But if run that command, shell complains &amp;amp;apos;An argument ignored (unknown or overridden): CONFIG&amp;amp;apos;, and the table description has no split policy.

hbase(main):067:0* create &amp;amp;apos;test&amp;amp;apos;, {METHOD =&amp;gt; &amp;amp;apos;table_att&amp;amp;apos;, CONFIG =&amp;gt; {&amp;amp;apos;SPLIT_POLICY&amp;amp;apos; =&amp;gt; &amp;amp;apos;org.apache.hadoop.hbase.regionserver.ConstantSizeRegionSplitPolicy&amp;amp;apos;}}, {NAME =&amp;gt; &amp;amp;apos;cf1&amp;amp;apos;}
An argument ignored (unknown or overridden): CONFIG
Created table test
Took 1.2180 seconds

hbase(main):068:0&amp;gt; describe &amp;amp;apos;test&amp;amp;apos;
Table test is ENABLED
test
COLUMN FAMILIES DESCRIPTION
{NAME =&amp;gt; &amp;amp;apos;cf1&amp;amp;apos;, DATA_BLOCK_ENCODING =&amp;gt; &amp;amp;apos;NONE&amp;amp;apos;, BLOOMFILTER =&amp;gt; &amp;amp;apos;ROW&amp;amp;apos;, REPLICATION_SCOPE =&amp;gt; &amp;amp;apos;0&amp;amp;apos;, COMPRESSION =&amp;gt; &amp;amp;apos;NONE&amp;amp;apos;, VERSIONS =&amp;gt; &amp;amp;apos;1&amp;amp;apos;, TTL =&amp;gt; &amp;amp;apos;FOREVER&amp;amp;apos;, MIN_VERSIONS =&amp;gt; &amp;amp;apos;0&amp;amp;apos;, IN_MEMORY_COMPACTION =&amp;gt; &amp;amp;apos;false&amp;amp;apos;, KEEP_DELETED_CELLS =&amp;gt; &amp;amp;apos;FALSE&amp;amp;apos;, BLOCKSIZE =&amp;gt; &amp;amp;apos;65536&amp;amp;apos;, IN_MEMORY =&amp;gt; &amp;amp;apos;
false&amp;amp;apos;, BLOCKCACHE =&amp;gt; &amp;amp;apos;true&amp;amp;apos;}
1 row(s)
Took 0.0200 seconds

</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFileBlockIndex.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">12701</link>
		</links>
	</bug>
	<bug id="16110" opendate="2016-06-24 21:55:46" fixdate="2016-07-18 12:02:24" resolution="Fixed">
		<buginformation>
			<summary>AsyncFS WAL doesn&amp;apos;t work with Hadoop 2.8+</summary>
			<description>The async wal implementation doesn&amp;amp;apos;t work with Hadoop 2.8+. Fails compilation and will fail running.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutputHelper.java</file>
			<file type="M">org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutput.java</file>
			<file type="M">org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutputSaslHelper.java</file>
		</fixedFiles>
		<links>
			<link type="Regression" description="is broken by">8803</link>
			<link type="Regression" description="is broken by">9111</link>
			<link type="Regression" description="is broken by">8100</link>
		</links>
	</bug>
	<bug id="16238" opendate="2016-07-16 08:50:55" fixdate="2016-07-18 21:39:32" resolution="Fixed">
		<buginformation>
			<summary>It&amp;apos;s useless to catch SESSIONEXPIRED exception and retry in RecoverableZooKeeper</summary>
			<description>After HBASE-5549, SESSIONEXPIRED exception was caught and retried with other zookeeper exceptions like ConnectionLoss. But it is useless to retry when a session expired happens, since the retry will never be successful. Though there is a config called "zookeeper.recovery.retry" to control retry times, in our cases, we set this config to a very big number like "99999". When a session expired happens, the regionserver should kill itself, but because of the retrying, threads of regionserver stuck at trying to reconnect to zookeeper, and never properly shut down.


public Stat exists(String path, boolean watch)
  throws KeeperException, InterruptedException {
    TraceScope traceScope = null;
    try {
      traceScope = Trace.startSpan("RecoverableZookeeper.exists");
      RetryCounter retryCounter = retryCounterFactory.create();
      while (true) {
        try {
          return checkZk().exists(path, watch);
        } catch (KeeperException e) {
          switch (e.code()) {
            case CONNECTIONLOSS:
            case SESSIONEXPIRED: //we shouldn&amp;amp;apos;t catch this
            case OPERATIONTIMEOUT:
              retryOrThrow(retryCounter, e, "exists");
              break;

            default:
              throw e;
          }
        }
        retryCounter.sleepUntilNextRetry();
      }
    } finally {
      if (traceScope != null) traceScope.close();
    }
  }

</description>
			<version>0.98.20</version>
			<fixedVersion>1.3.0, 1.2.2, 1.1.6</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.java</file>
		</fixedFiles>
	</bug>
	<bug id="16244" opendate="2016-07-19 04:05:42" fixdate="2016-07-19 21:49:47" resolution="Fixed">
		<buginformation>
			<summary>LocalHBaseCluster start timeout should be configurable</summary>
			<description>Scenario:

Ambari metrics service uses HBase in standalone mode
On restart of AMS HBase, the Master gives up in 30 seconds due to a hardcoded timeout in JVMClusterUtil


2016-07-18 19:24:44,199 ERROR [main] master.HMasterCommandLine: Master exiting
java.lang.RuntimeException: Master not active after 30 seconds
        at org.apache.hadoop.hbase.util.JVMClusterUtil.startup(JVMClusterUtil.java:194)
        at org.apache.hadoop.hbase.LocalHBaseCluster.startup(LocalHBaseCluster.java:445)
        at org.apache.hadoop.hbase.master.HMasterCommandLine.startMaster(HMasterCommandLine.java:227)
        at org.apache.hadoop.hbase.master.HMasterCommandLine.run(HMasterCommandLine.java:139)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
        at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:126)
        at org.apache.hadoop.hbase.master.HMaster.main(HMaster.java:2526)



On restart the current Master waits to become active and this leads to the timeout being triggered, waiting for a slightly longer time evades this issue.
The timeout it seems was meant for unit tests

Attached patch allows the timeout to be configured via hbase-site as well as sets it to 5 minutes for clusters started through HMasterCommandLine.</description>
			<version>1.0.1.1</version>
			<fixedVersion>2.0.0, 1.4.0, 0.98.21</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.JVMClusterUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMasterCommandLine.java</file>
		</fixedFiles>
	</bug>
	<bug id="16221" opendate="2016-07-13 00:55:26" fixdate="2016-07-23 00:59:53" resolution="Fixed">
		<buginformation>
			<summary>Thrift server drops connection on long scans</summary>
			<description>Thrift servers use connection cache and we drop connections after hbase.thrift.connection.max-idletime milliseconds from the last time a connection object was accessed. However, we never update this last accessed time on scan path. 
By default, this will cause scanners to fail after 10 minutes, if the underlying connection object is not being used along other operation paths (like put).</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.thrift2.ThriftHBaseServiceHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.util.ConnectionCache.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift2.TestThriftHBaseServiceHandler.java</file>
		</fixedFiles>
	</bug>
	<bug id="16281" opendate="2016-07-25 03:44:53" fixdate="2016-07-26 03:21:59" resolution="Fixed">
		<buginformation>
			<summary>TestMasterReplication is flaky</summary>
			<description>In TestMasterReplication we put some mutations and wait until we can read the data from slave cluster. However the waiting time is too short. Replication service in slave cluster may not be initialized and ready to handle replication RPC requests in several seconds. 
We should wait for more time.

2016-07-25 11:47:03,156 WARN  [Time-limited test-EventThread.replicationSource,1.replicationSource.10.235.114.28%2C56313%2C1469418386448,1] regionserver.HBaseInterClusterReplicationEndpoint(310): Can&amp;amp;apos;t replicate because of a local or network error: 
java.io.IOException: java.io.IOException: Replication services are not initialized yet
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2263)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:118)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:189)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:169)
Caused by: com.google.protobuf.ServiceException: Replication services are not initialized yet
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.replicateWALEntry(RSRpcServices.java:1935)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$2.callBlockingMethod(AdminProtos.java:22751)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2212)
	... 3 more</description>
			<version>0.98.20</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.1.6, 0.98.21, 1.2.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.replication.TestMasterReplication.java</file>
		</fixedFiles>
	</bug>
	<bug id="16293" opendate="2016-07-27 18:50:15" fixdate="2016-07-28 17:47:55" resolution="Fixed">
		<buginformation>
			<summary>TestSnapshotFromMaster#testSnapshotHFileArchiving flakey</summary>
			<description>Got the following stack trace for this failure, not sure if it is related with HBASE-9072
-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running org.apache.hadoop.hbase.master.cleaner.TestSnapshotFromMaster
Tests run: 4, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 336.042 sec &amp;lt;&amp;lt;&amp;lt; FAILURE! - in org.apache.hadoop.hbase.master.cleaner.TestSnapshotFromMaster
testSnapshotHFileArchiving(org.apache.hadoop.hbase.master.cleaner.TestSnapshotFromMaster)  Time elapsed: 303.771 sec  &amp;lt;&amp;lt;&amp;lt; ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 300000 milliseconds
	at java.lang.Object.wait(Native Method)
	at org.apache.hadoop.hbase.client.AsyncProcess.waitForMaximumCurrentTasks(AsyncProcess.java:1810)
	at org.apache.hadoop.hbase.client.AsyncProcess.waitForMaximumCurrentTasks(AsyncProcess.java:1784)
	at org.apache.hadoop.hbase.client.AsyncProcess.waitForAllPreviousOpsAndReset(AsyncProcess.java:1860)
	at org.apache.hadoop.hbase.client.BufferedMutatorImpl.backgroundFlushCommits(BufferedMutatorImpl.java:241)
	at org.apache.hadoop.hbase.client.BufferedMutatorImpl.flush(BufferedMutatorImpl.java:191)
	at org.apache.hadoop.hbase.client.HTable.flushCommits(HTable.java:979)
	at org.apache.hadoop.hbase.client.HTable.put(HTable.java:576)
	at org.apache.hadoop.hbase.HBaseTestingUtility.loadTable(HBaseTestingUtility.java:2002)
	at org.apache.hadoop.hbase.HBaseTestingUtility.loadTable(HBaseTestingUtility.java:1979)
	at org.apache.hadoop.hbase.HBaseTestingUtility.loadTable(HBaseTestingUtility.java:1967)
	at org.apache.hadoop.hbase.HBaseTestingUtility.loadTable(HBaseTestingUtility.java:1945)
	at org.apache.hadoop.hbase.master.cleaner.TestSnapshotFromMaster.testSnapshotHFileArchiving(TestSnapshotFromMaster.java:297)
Results :
Tests in error: 
  TestSnapshotFromMaster.testSnapshotHFileArchiving:297-&amp;gt;Object.wait:-2  TestTimedOut
Tests run: 4, Failures: 0, Errors: 1, Skipped: 0
</description>
			<version>1.4.0</version>
			<fixedVersion>2.0.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.cleaner.TestSnapshotFromMaster.java</file>
		</fixedFiles>
	</bug>
	<bug id="16096" opendate="2016-06-23 21:02:36" fixdate="2016-07-28 18:32:55" resolution="Fixed">
		<buginformation>
			<summary>Replication keeps accumulating znodes</summary>
			<description>If there is an error while creating the replication source on adding the peer, the source if not added to the in memory list of sources but the replication peer is. 
However, in such a scenario, when you remove the peer, it is deleted from zookeeper successfully but for removing the in memory list of peers, we wait for the corresponding sources to get deleted (which as we said don&amp;amp;apos;t exist because of error creating the source). 
The problem here is the ordering of operations for adding/removing source and peer. 
Modifying the code to always remove queues from the underlying storage, even if there exists no sources also requires a small refactoring of TableBasedReplicationQueuesImpl to not abort on removeQueues() of an empty queue</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManager.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.java</file>
		</fixedFiles>
		<links>
			<link type="dependent" description="is depended upon by">15867</link>
		</links>
	</bug>
	<bug id="16234" opendate="2016-07-15 04:58:51" fixdate="2016-08-01 03:24:07" resolution="Fixed">
		<buginformation>
			<summary>Expect and handle nulls when assigning replicas</summary>
			<description>Observed this on a cluster:


FATAL org.apache.hadoop.hbase.master.HMaster: Unhandled exception. Starting shutdown. 
java.lang.NullPointerException 
at org.apache.hadoop.hbase.master.AssignmentManager.replicaRegionsNotRecordedInMeta(AssignmentManager.java:2799) 
at org.apache.hadoop.hbase.master.AssignmentManager.assignAllUserRegions(AssignmentManager.java:2778) 
at org.apache.hadoop.hbase.master.AssignmentManager.processDeadServersAndRegionsInTransition(AssignmentManager.java:638) 
at org.apache.hadoop.hbase.master.AssignmentManager.joinCluster(AssignmentManager.java:485) 
at org.apache.hadoop.hbase.master.HMaster.finishActiveMasterInitialization(HMaster.java:723) 
at org.apache.hadoop.hbase.master.HMaster.access$500(HMaster.java:169) 
at org.apache.hadoop.hbase.master.HMaster$1.run(HMaster.java:1481) 
at java.lang.Thread.run(Thread.java:745) 


It looks like FSTableDescriptors#get() can be expected to return null in some cases, but AssignmentManager.replicaRegionsNotRecordedInMeta() does not currently have any handling for such a possibility.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.AssignmentManager.java</file>
		</fixedFiles>
	</bug>
	<bug id="16301" opendate="2016-07-28 19:32:39" fixdate="2016-08-03 18:35:46" resolution="Fixed">
		<buginformation>
			<summary>Trigger flush without waiting when compaction is disabled on a table</summary>
			<description>When compaction is disabled on a table, flush needs to wait MemStoreFlusher#blockingWaitTime (default value is 90 seconds) before it goes ahead to flush. It has side effect that client may be blocked due to RegionTooBusyException. Please see the mail sent to dev list.
http://mail-archives.apache.org/mod_mbox/hbase-dev/201607.mbox/%3C2D66B8CA-7C6F-40EA-A861-2DE5482EC7B2@cloudera.com%3E
I guess that the right behavior is to do flush without waiting if compaction is disabled on a table. Attached a patch. </description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.MemStoreFlusher.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestCompactSplitThread.java</file>
		</fixedFiles>
	</bug>
	<bug id="16359" opendate="2016-08-04 22:38:48" fixdate="2016-08-05 16:16:47" resolution="Fixed">
		<buginformation>
			<summary>NullPointerException in RSRpcServices.openRegion()</summary>
			<description>I was investigating why some region failed to move out of transition within timeout 120000ms and found the following in region server log:


2016-08-04 09:19:52,616 INFO  [B.priority.fifo.QRpcServer.handler=12,queue=0,port=16020] regionserver.RSRpcServices: Open hbck_table_772674,,1470302211047.                                da859880bb51bc0fd25979798a96c444.
2016-08-04 09:19:52,620 ERROR [B.priority.fifo.QRpcServer.handler=12,queue=0,port=16020] ipc.RpcServer: Unexpected throwable object
java.lang.NullPointerException
  at org.apache.hadoop.hbase.regionserver.RSRpcServices.openRegion(RSRpcServices.java:1530)
  at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$2.callBlockingMethod(AdminProtos.java:22737)
  at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2127)
  at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:107)
  at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:133)


Here is related code - NPE was thrown from the last line:


        htd = htds.get(region.getTable());
        if (htd == null) {
          htd = regionServer.tableDescriptors.get(region.getTable());
          htds.put(region.getTable(), htd);
        }
...
          if (region.isMetaRegion()) {
            regionServer.service.submit(new OpenMetaHandler(
              regionServer, regionServer, region, htd, masterSystemTime, coordination, ord));
          } else {
            regionServer.updateRegionFavoredNodesMapping(region.getEncodedName(),
              regionOpenInfo.getFavoredNodesList());
            if (htd.getPriority() &amp;gt;= HConstants.ADMIN_QOS || region.getTable().isSystemTable()) {


region.getTable() shouldn&amp;amp;apos;t be null since it is called via htds.get(region.getTable()) unconditionally.
It seems htd was null.</description>
			<version>1.1.2</version>
			<fixedVersion>2.0.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
		</fixedFiles>
	</bug>
	<bug id="16362" opendate="2016-08-05 05:55:40" fixdate="2016-08-06 14:48:52" resolution="Fixed">
		<buginformation>
			<summary>Mob compaction does not set cacheBlocks to false when creating StoreScanner</summary>
			<description>In the constructor of StoreScanner which it uses, scan.getCacheBlocks is used directly. It is default to true, and in PartitionedMobCompactor.createScanner, we do not set it to false.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreScanner.java</file>
		</fixedFiles>
	</bug>
	<bug id="15866" opendate="2016-05-19 19:22:33" fixdate="2016-08-07 00:19:35" resolution="Fixed">
		<buginformation>
			<summary>Split hbase.rpc.timeout into *.read.timeout and *.write.timeout</summary>
			<description>We have a single tunable for the RPC timeout interval - hbase.rpc.timeout. This is fine for the general case but there are use cases where it would be advantageous to set two separate timeouts for reads (gets, scans, perhaps with significant server side filtering - although the new scanner heartbeat feature mitigates where available) and mutations (fail fast under tight SLA, resubmit or take mitigating action). 
I propose we refer to a configuration setting "hbase.rpc.read.timeout" when handling read operations and "hbase.rpc.write.timeout" when handling write operations. If those values are not set in the configuration, fall back to the value of "hbase.rpc.timeout" or its default. 
So for example in HTable instead of one global timeout for each RPC (rpcTimeout), there would be a readRpcTimeout and writeRpcTimeout also set up in HTable#finishSetup. Then wherever we set up RPC with RpcRetryingCallerFactory#newCaller(int rpcTimeout) we pass in the read or write timeout depending on what the op is.
In general I don&amp;amp;apos;t like the idea of adding configuration parameters to our already heavyweight set, but I think the inability to control timeouts separately for reads and writes is an operational deficit.
See also PHOENIX-2916.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.Table.java</file>
			<file type="M">org.apache.hadoop.hbase.client.AsyncProcess.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.RegionAsTable.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestAsyncProcess.java</file>
			<file type="M">org.apache.hadoop.hbase.rest.client.RemoteHTable.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTableMultiplexer.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
			<file type="M">org.apache.hadoop.hbase.client.BufferedMutatorImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HConnectionTestingUtility.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTableWrapper.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestHCM.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HTable.java</file>
			<file type="M">org.apache.hadoop.hbase.HConstants.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">2916</link>
		</links>
	</bug>
	<bug id="12770" opendate="2014-12-29 14:25:32" fixdate="2016-08-08 08:37:24" resolution="Fixed">
		<buginformation>
			<summary>Don&amp;apos;t transfer all the queued hlogs of a dead server to the same alive server</summary>
			<description>When a region server is down(or the cluster restart), all the hlog queues will be transferred by the same alive region server. In a shared cluster, we might create several peers replicating data to different peer clusters. There might be lots of hlogs queued for these peers caused by several reasons, such as some peers might be disabled, or errors from peer cluster might prevent the replication, or the replication sources may fail to read some hlog because of hdfs problem. Then, if the server is down or restarted, another alive server will take all the replication jobs of the dead server, this might bring a big pressure to resources(network/disk read) of the alive server and also is not fast enough to replicate the queued hlogs. And if the alive server is down, all the replication jobs including that takes from other dead servers will once again be totally transferred to another alive server, this might cause a server have a large number of queued hlogs(in our shared cluster, we find one server might have thousands of queued hlogs for replication). As an optional way, is it reasonable that the alive server only transfer one peer&amp;amp;apos;s hlogs from the dead server one time? Then, other alive region servers might have the opportunity to transfer the hlogs of rest peers. This may also help the queued hlogs be processed more fast. Any discussion is welcome.</description>
			<version>1.4.0</version>
			<fixedVersion>2.0.0, 1.4.0</fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.replication.TestReplicationStateBasic.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManagerZkImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.TableBasedReplicationQueuesImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.ReplicationQueuesZKImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.ReplicationQueues.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManager.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.TestReplicationStateHBaseImpl.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">16581</link>
		</links>
	</bug>
	<bug id="16367" opendate="2016-08-06 09:20:28" fixdate="2016-08-08 17:42:13" resolution="Fixed">
		<buginformation>
			<summary>Race between master and region server initialization may lead to premature server abort</summary>
			<description>I was troubleshooting a case where hbase (1.1.2) master always dies shortly after start - see attached master log snippet.
It turned out that master initialization thread was racing with HRegionServer#preRegistrationInitialization() (initializeZooKeeper, actually) since HMaster extends HRegionServer.
Through additional logging in master:


    this.oldLogDir = createInitialFileSystemLayout();
    HFileSystem.addLocationsOrderInterceptor(conf);
    LOG.info("creating splitLogManager");


I found that execution didn&amp;amp;apos;t reach the last log line before region server declared cluster Id being null.</description>
			<version>1.1.2</version>
			<fixedVersion>2.0.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
		</fixedFiles>
	</bug>
	<bug id="16310" opendate="2016-08-01 07:45:06" fixdate="2016-08-10 08:25:36" resolution="Fixed">
		<buginformation>
			<summary>Revisit the logic of filterRowKey for Filters</summary>
			<description>Based on HBASE-16926 it was observed that filterRowKey() API behaviour for FilterList and a standalone filter should be made consistent. This JIRA is to track down the changes and ensure 1.3+ on wards we have consistent behaviour.</description>
			<version>1.0.3</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.filter.FilterWrapper.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.PrefixFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.InclusiveStopFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.WhileMatchFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.FilterBase.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.MultiRowRangeFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.ColumnCountGetFilter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.Filter.java</file>
			<file type="M">org.apache.hadoop.hbase.filter.PageFilter.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">16296</link>
		</links>
	</bug>
	<bug id="16368" opendate="2016-08-06 09:32:55" fixdate="2016-08-10 10:47:33" resolution="Fixed">
		<buginformation>
			<summary>test*WhenRegionMove in TestPartialResultsFromClientSide is flaky</summary>
			<description>This test fail when Hadoop QA run preCommit:
https://builds.apache.org/job/PreCommit-HBASE-Build/2971/testReport/org.apache.hadoop.hbase/TestPartialResultsFromClientSide/testReversedCompleteResultWhenRegionMove/.
And I found it is in Flaky Tests Dashboard: http://hbase.x10host.com/flaky-tests/. I run it in my local machine and it may fail, too.
Test results show that the region location didn&amp;amp;apos;t update when scanner callable get a NotServingRegionException or RegionMovedException.


org.apache.hadoop.hbase.client.RetriesExhaustedException: Failed after attempts=36, exceptions:
Sat Aug 06 05:55:52 UTC 2016, null, java.net.SocketTimeoutException: callTimeout=2000, callDuration=2157: org.apache.hadoop.hbase.NotServingRegionException: testReversedCompleteResultWhenRegionMove,,1470462949504.5069bd63bf6eda5108acec4fcc087b0e. is closing
	at org.apache.hadoop.hbase.regionserver.HRegion.startRegionOperation(HRegion.java:8233)
	at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:2634)
	at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:2629)
	at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:2623)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.scan(RSRpcServices.java:2490)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:34950)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2264)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:118)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:189)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:169)
 row &amp;amp;apos;&amp;amp;apos; on table &amp;amp;apos;testReversedCompleteResultWhenRegionMove&amp;amp;apos; at region=testReversedCompleteResultWhenRegionMove,,1470462949504.5069bd63bf6eda5108acec4fcc087b0e., hostname=asf907.gq1.ygridcore.net,38914,1470462943053, seqNum=2

	at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.throwEnrichedException(RpcRetryingCallerWithReadReplicas.java:281)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:213)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:61)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:212)
	at org.apache.hadoop.hbase.client.ReversedClientScanner.nextScanner(ReversedClientScanner.java:118)
	at org.apache.hadoop.hbase.client.ClientScanner.initializeScannerInConstruction(ClientScanner.java:166)
	at org.apache.hadoop.hbase.client.ClientScanner.&amp;lt;init&amp;gt;(ClientScanner.java:161)
	at org.apache.hadoop.hbase.client.ReversedClientScanner.&amp;lt;init&amp;gt;(ReversedClientScanner.java:56)
	at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:785)
	at org.apache.hadoop.hbase.TestPartialResultsFromClientSide.testReversedCompleteResultWhenRegionMove(TestPartialResultsFromClientSide.java:986)




org.apache.hadoop.hbase.client.RetriesExhaustedException: Failed after attempts=36, exceptions:
Sat Aug 06 16:27:22 CST 2016, null, java.net.SocketTimeoutException: callTimeout=2000, callDuration=3035: Region moved to: hostname=localhost port=58351 startCode=1470472007714. As of locationSeqNum=6. row &amp;amp;apos;testRow0&amp;amp;apos; on table &amp;amp;apos;testPartialResultWhenRegionMove&amp;amp;apos; at region=testPartialResultWhenRegionMove,,1470472035048.977faf05c1d6d9990b5559b17aa18913., hostname=localhost,40425,1470472007646, seqNum=2

	at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.throwEnrichedException(RpcRetryingCallerWithReadReplicas.java:281)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:213)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:61)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:212)
	at org.apache.hadoop.hbase.client.ClientScanner.call(ClientScanner.java:326)
	at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:301)
	at org.apache.hadoop.hbase.client.ClientScanner.possiblyNextScanner(ClientScanner.java:247)
	at org.apache.hadoop.hbase.client.ClientScanner.loadCache(ClientScanner.java:541)
	at org.apache.hadoop.hbase.client.ClientScanner.next(ClientScanner.java:370)
	at org.apache.hadoop.hbase.TestPartialResultsFromClientSide.testPartialResultWhenRegionMove(TestPartialResultsFromClientSide.java:884)
Caused by: java.net.SocketTimeoutException: callTimeout=2000, callDuration=3035: Region moved to: hostname=localhost port=58351 startCode=1470472007714. As of locationSeqNum=6. row &amp;amp;apos;testRow0&amp;amp;apos; on table &amp;amp;apos;testPartialResultWhenRegionMove&amp;amp;apos; at region=testPartialResultWhenRegionMove,,1470472035048.977faf05c1d6d9990b5559b17aa18913., hostname=localhost,40425,1470472007646, seqNum=2
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:171)
	at org.apache.hadoop.hbase.client.ResultBoundedCompletionService$QueueingFuture.run(ResultBoundedCompletionService.java:65)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.hbase.exceptions.RegionMovedException: Region moved to: hostname=localhost port=58351 startCode=1470472007714. As of locationSeqNum=6.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:95)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.getRemoteException(ProtobufUtil.java:332)
	at org.apache.hadoop.hbase.client.ScannerCallable.openScanner(ScannerCallable.java:406)
	at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:210)
	at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:64)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:212)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:367)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:341)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:137)
	at org.apache.hadoop.hbase.client.ResultBoundedCompletionService$QueueingFuture.run(ResultBoundedCompletionService.java:65)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

</description>
			<version>1.1.5</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.1.6, 1.2.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.TestPartialResultsFromClientSide.java</file>
		</fixedFiles>
	</bug>
	<bug id="16403" opendate="2016-08-12 02:38:01" fixdate="2016-08-12 14:19:02" resolution="Duplicate">
		<buginformation>
			<summary>Upgrade guava version to the lastest one(19.0)</summary>
			<description>HBase client use the guava version 12.0.1, while elasticsearch sdk use the version 18+. It makes conflict, cause the constructor of StopWatch class is not public now.
We have to choose the es rest api to resolve the conflict.  Why not try to upgrade our dependency versions?
thx.</description>
			<version>1.1.4</version>
			<fixedVersion></fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.zookeeper.MetaTableLocator.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">14963</link>
		</links>
	</bug>
	<bug id="15635" opendate="2016-04-12 05:55:18" fixdate="2016-08-17 18:04:03" resolution="Fixed">
		<buginformation>
			<summary>Mean age of Blocks in cache (seconds) on webUI should be greater than zero</summary>
			<description></description>
			<version>0.98.17</version>
			<fixedVersion>2.0.0, 1.0.4, 1.4.0, 1.1.6, 1.3.1, 1.2.3, 0.98.22</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.hfile.BlockCacheUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.CacheStats.java</file>
		</fixedFiles>
	</bug>
	<bug id="16429" opendate="2016-08-17 03:35:09" fixdate="2016-08-18 03:21:34" resolution="Fixed">
		<buginformation>
			<summary>FSHLog: deadlock if rollWriter called when ring buffer filled with appends</summary>
			<description>Recently we experienced an online problem that all handlers are stuck. Checking the jstack we could see all handler threads waiting for RingBuffer.next, while the single ring buffer consumer dead waiting for safePointReleasedLatch to count down:

Normal handler thread:
"B.defaultRpcServer.handler=126,queue=9,port=16020" daemon prio=10 tid=0x00007efd4b44f800 nid=0x15f29 runnable [0x00007efd3db7b000]
   java.lang.Thread.State: TIMED_WAITING (parking)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:349)
        at com.lmax.disruptor.MultiProducerSequencer.next(MultiProducerSequencer.java:136)
        at com.lmax.disruptor.MultiProducerSequencer.next(MultiProducerSequencer.java:105)
        at com.lmax.disruptor.RingBuffer.next(RingBuffer.java:246)
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog.append(FSHLog.java:1222)
        at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutation(HRegion.java:3188)
        at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2879)
        at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2819)
        at org.apache.hadoop.hbase.regionserver.RSRpcServices.doBatchOp(RSRpcServices.java:736)
        at org.apache.hadoop.hbase.regionserver.RSRpcServices.doNonAtomicRegionMutation(RSRpcServices.java:698)
        at org.apache.hadoop.hbase.regionserver.RSRpcServices.multi(RSRpcServices.java:2095)
        at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:32213)
        at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:774)
        at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:102)
        at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:133)
        at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
        at java.lang.Thread.run(Thread.java:756)

RingBufferEventHandler thread waiting for safePointReleasedLatch:
"regionserver/hadoop0369.et2.tbsite.net/11.251.152.226:16020.append-pool2-t1" prio=10 tid=0x00007efd320d0000 nid=0x1777b waiting on condition [0x00007efd2d2fa000]
   java.lang.Thread.State: WAITING (parking)
        at sun.misc.Unsafe.park(Native Method)
        - parking to wait for  &amp;lt;0x00007f01b48d9178&amp;gt; (a java.util.concurrent.CountDownLatch$Sync)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:834)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:994)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1303)
        at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:236)
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog$SafePointZigZagLatch.safePointAttained(FSHLog.java:1866)
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.attainSafePoint(FSHLog.java:2066)
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:2029)
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:1909)
        at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:128)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:756)


FSHLog#replaceWriter will call SafePointZigZagLatch#releaseSafePoint to count down safePointReleasedLatch, but replaceWriter got stuck when trying to publish a sync onto ring buffer:

"regionserver/hadoop0369.et2.tbsite.net/11.251.152.226:16020.logRoller" daemon prio=10 tid=0x00007efd320c8800 nid=0x16123 runnable [0x00007efd311f6000]
   java.lang.Thread.State: TIMED_WAITING (parking)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:349)
        at com.lmax.disruptor.MultiProducerSequencer.next(MultiProducerSequencer.java:136)
        at com.lmax.disruptor.MultiProducerSequencer.next(MultiProducerSequencer.java:105)
        at com.lmax.disruptor.RingBuffer.next(RingBuffer.java:246)
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog.publishSyncOnRingBuffer(FSHLog.java:1481)
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog.publishSyncOnRingBuffer(FSHLog.java:1477)
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog.replaceWriter(FSHLog.java:957)
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog.rollWriter(FSHLog.java:726)
        at org.apache.hadoop.hbase.regionserver.LogRoller.run(LogRoller.java:148)
        at java.lang.Thread.run(Thread.java:756)


Thus deadlock happens.
A brief process of how deadlock forms:

ring buffer filled with appends
-&amp;gt; rollWriter happens
-&amp;gt; the only consumer of ring buffer waiting for safePointReleasedLatch
-&amp;gt; rollWriter cannot publish sync since ring buffer is full
-&amp;gt; rollWriter won&amp;amp;apos;t release safePointReleasedLatch


This JIRA targeting at resolve this issue, and will add a UT to cover the case</description>
			<version>1.1.2</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.1.6, 1.2.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
		</fixedFiles>
	</bug>
	<bug id="16430" opendate="2016-08-17 03:40:05" fixdate="2016-08-19 17:43:39" resolution="Fixed">
		<buginformation>
			<summary>Fix RegionServer Group&amp;apos;s bug when moving multiple tables</summary>
			<description>It will be good when move one table at the same time. 
However,will appear abnormal when move two or more tables at once.
For example,move tableA and tableB from Group foo to Group bar:


hbase(main):001:0&amp;gt; get_rsgroup &amp;amp;apos;foo&amp;amp;apos;
GROUP INFORMATION                                                                                                                                                                            
Servers:                                                                                                                                                                                     
hbase-rs1:60020                                                                                                                                                                     
Tables:                                                                                                                                                                                      
tableA                                                                                                                                                                                       
tableB                                                                                                                                                                                       
5 row(s) in 0.2800 seconds

hbase(main):002:0&amp;gt; get_rsgroup &amp;amp;apos;bar&amp;amp;apos;
GROUP INFORMATION                                                                                                                                                                            
Servers:                                                                                                                                                                                     
hbase-rs2:60020                                                                                                                                                                     
Tables:                                                                                                                                                                                      
3 row(s) in 0.0050 seconds

hbase(main):003:0&amp;gt; move_rsgroup_tables &amp;amp;apos;bar&amp;amp;apos;,[&amp;amp;apos;tableA&amp;amp;apos;,&amp;amp;apos;tableB&amp;amp;apos;]

hbase(main):004:0&amp;gt; get_rsgroup &amp;amp;apos;foo&amp;amp;apos;
GROUP INFORMATION                                                                                                                                                                            
Servers:                                                                                                                                                                                     
hbase-rs1:60020                                                                                                                                                                     
Tables:                                                                                                                                                                                      
tableB                                                                                                                                                                                       
4 row(s) in 0.0120 seconds

hbase(main):005:0&amp;gt; get_rsgroup &amp;amp;apos;bar&amp;amp;apos;
GROUP INFORMATION                                                                                                                                                                            
Servers:                                                                                                                                                                                     
hbase-rs2:60020                                                                                                                                                                    
Tables:                                                                                                                                                                                      
tableA                                                                                                                                                                                       
tableB                                                                                                                                                                                       
5 row(s) in 0.0130 seconds


Now, you will be find tableB belongs to Group foo and Group bar.
Implementation of the moveTables as follows
RSGroupInfoManagerImpl.java

@Override
  public synchronized void moveTables(
      Set&amp;lt;TableName&amp;gt; tableNames, String groupName) throws IOException {
    if (groupName != null &amp;amp;&amp;amp; !rsGroupMap.containsKey(groupName)) {
      throw new DoNotRetryIOException("Group "+groupName+" does not exist or is a special group");
    }

    Map&amp;lt;String,RSGroupInfo&amp;gt; newGroupMap = Maps.newHashMap(rsGroupMap);
    for(TableName tableName: tableNames) {
      if (tableMap.containsKey(tableName)) {
        RSGroupInfo src = new RSGroupInfo(rsGroupMap.get(tableMap.get(tableName)));
        src.removeTable(tableName);
        newGroupMap.put(src.getName(), src);
      }
      if(groupName != null) {
        RSGroupInfo dst = new RSGroupInfo(newGroupMap.get(groupName));
        dst.addTable(tableName);
        newGroupMap.put(dst.getName(), dst);
      }
    }
    flushConfig(newGroupMap);
  }


Should use newGroupMap instead of rsGroupMap:


RSGroupInfo src = new RSGroupInfo(rsGroupMap.get(tableMap.get(tableName)));


==&amp;gt;


RSGroupInfo src = new RSGroupInfo(newGroupMap.get(tableMap.get(tableName)));

</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.rsgroup.RSGroupInfoManagerImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.rsgroup.TestRSGroupsBase.java</file>
		</fixedFiles>
	</bug>
	<bug id="16446" opendate="2016-08-18 11:17:57" fixdate="2016-08-23 10:01:23" resolution="Fixed">
		<buginformation>
			<summary>append_peer_tableCFs failed when there already have this table&amp;apos;s partial cfs in the peer</summary>
			<description>

hbase(main):011:0&amp;gt; list_peers
 PEER_ID CLUSTER_KEY STATE TABLE_CFS PROTOCOL BANDWIDTH
 20 hbase://c3tst-pressure98 ENABLED default.test_replication:A NATIVE 0
1 row(s) in 0.0080 seconds

hbase(main):012:0&amp;gt; append_peer_tableCFs &amp;amp;apos;20&amp;amp;apos;, {"test_replication" =&amp;gt; []}
0 row(s) in 0.0060 seconds

hbase(main):013:0&amp;gt; list_peers
 PEER_ID CLUSTER_KEY STATE TABLE_CFS PROTOCOL BANDWIDTH
 20 hbase://c3tst-pressure98 ENABLED default.test_replication:A NATIVE 0
1 row(s) in 0.0030 seconds


"test_replication" =&amp;gt; [] means replication all cf of this table,so the result is not right. It should not just contain cf A after append_peer_tableCFs.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.replication.ReplicationAdmin.java</file>
			<file type="M">org.apache.hadoop.hbase.client.replication.TestReplicationAdmin.java</file>
		</fixedFiles>
	</bug>
	<bug id="16360" opendate="2016-08-04 23:31:04" fixdate="2016-08-23 21:45:22" resolution="Fixed">
		<buginformation>
			<summary>TableMapReduceUtil addHBaseDependencyJars has the wrong class name for PrefixTreeCodec</summary>
			<description>HBASE-15152 included the prefix tree module as dependency to TableMapReduceUtil. but the hardcoded string of the class name is wrong. 


Class.forName("org.apache.hadoop.hbase.code.prefixtree.PrefixTreeCodec");


should be ".codec." instead of ".code."


Class.forName("org.apache.hadoop.hbase.codec.prefixtree.PrefixTreeCodec");

</description>
			<version>0.98.21</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.2.2, 1.1.6, 0.98.22</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
		</fixedFiles>
	</bug>
	<bug id="16464" opendate="2016-08-22 07:56:11" fixdate="2016-08-24 06:08:35" resolution="Fixed">
		<buginformation>
			<summary>archive folder grows bigger and bigger due to corrupt snapshot under tmp dir</summary>
			<description>We met the problem on our real production cluster,  we need to cleanup some data on hbase,  we notice the archive folder is much larger than others,  so we delete all snapshots of all tables,  but the archive folder still grows bigger and bigger. 
After check the hmaster log, we notice the exception below:


2016-08-22 15:34:33,089 ERROR [f04,16000,1471240833208_ChoreService_1] snapshot.SnapshotHFileCleaner: Exception while checking if files were valid, keeping them just in case.
org.apache.hadoop.hbase.snapshot.CorruptedSnapshotException: Couldn&amp;amp;apos;t read snapshot info from:hdfs://f04/hbase/.hbase-snapshot/.tmp/frog_stastic_2016-08-17/.snapshotinfo
        at org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils.readSnapshotInfo(SnapshotDescriptionUtils.java:295)
        at org.apache.hadoop.hbase.snapshot.SnapshotReferenceUtil.getHFileNames(SnapshotReferenceUtil.java:328)
        at org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner$1.filesUnderSnapshot(SnapshotHFileCleaner.java:85)
        at org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache.getSnapshotsInProgress(SnapshotFileCache.java:303)
        at org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache.getUnreferencedFiles(SnapshotFileCache.java:194)
        at org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner.getDeletableFiles(SnapshotHFileCleaner.java:62)
        at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteFiles(CleanerChore.java:233)
        at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteEntries(CleanerChore.java:157)
        at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteDirectory(CleanerChore.java:180)
        at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteEntries(CleanerChore.java:149)
        at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteDirectory(CleanerChore.java:180)
        at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteEntries(CleanerChore.java:149)
        at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteDirectory(CleanerChore.java:180)
        at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteEntries(CleanerChore.java:149)
        at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteDirectory(CleanerChore.java:180)
        at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteEntries(CleanerChore.java:149)
        at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteDirectory(CleanerChore.java:180)
        at org.apache.hadoop.hbase.master.cleaner.CleanerChore.checkAndDeleteEntries(CleanerChore.java:149)
        at org.apache.hadoop.hbase.master.cleaner.CleanerChore.chore(CleanerChore.java:124)
        at org.apache.hadoop.hbase.ScheduledChore.run(ScheduledChore.java:185)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.FileNotFoundException: File does not exist: /hbase/.hbase-snapshot/.tmp/frog_stastic_2016-08-17/.snapshotinfo
        at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)
        at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1828)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1799)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1712)
        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:587)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:365)
        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)


It means when SnapshotHFileCleaner begin to cleanup the archive folder, it reads the the snapshot dir to check if any links to hfiles exist, but when read the file /.hbase-snapshot/.tmp/frog_stastic_2016-08-17/.snapshotinfo, corrupt exception thrown out (not sure why the file not found),  and cleanup will be failed.
When i check the /.hbase-snapshot/.tmp/frog_stastic_2016-08-17, i can see there is only one file exist /hbase/.hbase-snapshot/.tmp/frog_stastic_2016-08-17/region-manifest.8e3179c388e10770eba7d35e30f2777f,  /hbase/.hbase-snapshot/.tmp/frog_stastic_2016-08-17/.snapshotinfo missed. 
I think we should catch up the exception and delete the file to ensure cleanup will go on.
</description>
			<version>1.1.1</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.1.6, 1.2.3, 0.98.22</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache.java</file>
			<file type="M">org.apache.hadoop.hbase.snapshot.SnapshotManifestV2.java</file>
			<file type="M">org.apache.hadoop.hbase.master.snapshot.TestSnapshotHFileCleaner.java</file>
			<file type="M">org.apache.hadoop.hbase.master.snapshot.TakeSnapshotHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.snapshot.SnapshotTestingUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils.java</file>
		</fixedFiles>
	</bug>
	<bug id="16456" opendate="2016-08-19 16:34:13" fixdate="2016-08-24 09:30:59" resolution="Fixed">
		<buginformation>
			<summary>Fix findbugs warnings in hbase-rsgroup module</summary>
			<description>https://builds.apache.org/job/PreCommit-HBASE-Build/3161/artifact/patchprocess/branch-findbugs-hbase-rsgroup-warnings.html :
Multithreaded correctness Warnings
Code	Warning
SC	new org.apache.hadoop.hbase.rsgroup.RSGroupInfoManagerImpl(MasterServices) invokes org.apache.hadoop.hbase.rsgroup.RSGroupInfoManagerImpl$RSGroupStartupWorker.start()
SWL	org.apache.hadoop.hbase.rsgroup.RSGroupAdminServer.moveServers(Set, String) calls Thread.sleep() with a lock held
Performance Warnings
Code	Warning
WMI	org.apache.hadoop.hbase.rsgroup.RSGroupBasedLoadBalancer.correctAssignments(Map) makes inefficient use of keySet iterator instead of entrySet iterator
WMI	org.apache.hadoop.hbase.rsgroup.RSGroupBasedLoadBalancer.getMisplacedRegions(Map) makes inefficient use of keySet iterator instead of entrySet iterator
Dodgy code Warnings
Code	Warning
REC	Exception is caught when Exception is not thrown in org.apache.hadoop.hbase.rsgroup.RSGroupInfoManagerImpl$RSGroupStartupWorker.waitForGroupTableOnline()
ST	Write to static field org.apache.hadoop.hbase.rsgroup.RSGroupAdminEndpoint.groupInfoManager from instance method org.apache.hadoop.hbase.rsgroup.RSGroupAdminEndpoint.start(CoprocessorEnvironment)</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.rsgroup.RSGroupInfoManagerImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.rsgroup.RSGroupBasedLoadBalancer.java</file>
			<file type="M">org.apache.hadoop.hbase.rsgroup.RSGroupAdminEndpoint.java</file>
			<file type="M">org.apache.hadoop.hbase.rsgroup.RSGroupAdminServer.java</file>
		</fixedFiles>
	</bug>
	<bug id="16471" opendate="2016-08-23 04:09:51" fixdate="2016-08-24 13:42:21" resolution="Fixed">
		<buginformation>
			<summary>Region Server metrics context will be wrong when machine hostname contain "master" word</summary>
			<description>While initializing RSRpcServices server name is formed as,


    String name = rs.getProcessName() + "/" + initialIsa.toString();


So name will be like "regionserver/host_Name/host_IP:port".
During MetricsHBaseServer intializing, we create server context name using String contains() which will be wrong when machine hostname contain "master" words.
In MetricsHBaseServerSourceFactory, 


  protected static String createContextName(String serverName) {
    if (serverName.contains("HMaster") || serverName.contains("master")) {
      return "Master";
    } else if (serverName.contains("HRegion") || serverName.contains("regionserver")) {
      return "RegionServer";
    }
    return "IPC";
  }


For example, "regionserver/node-master1-xyz/host-IP:16020"</description>
			<version>0.98.21</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.1.6, 1.2.3, 0.98.22</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.MetricsHBaseServerSourceFactory.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.TestRpcMetrics.java</file>
		</fixedFiles>
	</bug>
	<bug id="16270" opendate="2016-07-21 21:13:49" fixdate="2016-08-24 13:54:53" resolution="Fixed">
		<buginformation>
			<summary>Handle duplicate clearing of snapshot in region replicas</summary>
			<description>We have an HBase (1.1.2) production cluster with 58 region servers and a staging cluster with 6 region servers.
For both clusters, we enabled region replicas with the following settings:
hbase.regionserver.storefile.refresh.period = 0
hbase.region.replica.replication.enabled = true
hbase.region.replica.replication.memstore.enabled = true
hbase.master.hfilecleaner.ttl = 3600000
hbase.master.loadbalancer.class = org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer
hbase.meta.replica.count = 3
hbase.regionserver.meta.storefile.refresh.period = 30000
hbase.region.replica.wait.for.primary.flush = true
hbase.region.replica.storefile.refresh.memstore.multiplier = 4
We then altered our HBase tables to have REGION_REPLICATION =&amp;gt; 2
Both clusters got into a state where a few region servers were spewing the following error below in the HBase logs.  In one instance the error occurred over 70K times.  At this time, these region servers would see 10x write traffic (the hadoop.HBase.RegionServer.Server.writeRequestCount metric) and in some instances would crash.
At the same time, we would see secondary regions move and then go into the "reads are disabled" state for extended periods.  
It appears there is a race condition where the DefaultMemStore::clearSnapshot method might be called more than once in succession. The first call would set snapshotId to -1, but the second call would throw an exception.  It seems the second call should just return if the snapshotId is already -1, rather than throwing an exception.
Thu Jul 21 08:38:50 UTC 2016, RpcRetryingCaller
{globalStartTime=1469090201543, pause=100, retries=35}
, org.apache.hadoop.hbase.regionserver.UnexpectedStateException: org.apache.hadoop.hbase.regionserver.UnexpectedStateException: Current snapshot id is -1,passed 1469085004304
        at org.apache.hadoop.hbase.regionserver.DefaultMemStore.clearSnapshot(DefaultMemStore.java:187)
        at org.apache.hadoop.hbase.regionserver.HStore.updateStorefiles(HStore.java:1054)
        at org.apache.hadoop.hbase.regionserver.HStore.access$500(HStore.java:128)
        at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.replayFlush(HStore.java:2270)
        at org.apache.hadoop.hbase.regionserver.HRegion.replayFlushInStores(HRegion.java:4487)
        at org.apache.hadoop.hbase.regionserver.HRegion.replayWALFlushCommitMarker(HRegion.java:4388)
        at org.apache.hadoop.hbase.regionserver.HRegion.replayWALFlushMarker(HRegion.java:4191)
        at org.apache.hadoop.hbase.regionserver.RSRpcServices.doReplayBatchOp(RSRpcServices.java:776)
        at org.apache.hadoop.hbase.regionserver.RSRpcServices.replay(RSRpcServices.java:1655)
        at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$2.callBlockingMethod(AdminProtos.java:22255)
        at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2114)
        at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:101)
        at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)
        at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)
        at java.lang.Thread.run(Thread.java:745)</description>
			<version>1.1.2</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.1.6, 1.2.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.AbstractMemStore.java</file>
		</fixedFiles>
	</bug>
	<bug id="16304" opendate="2016-07-29 09:33:23" fixdate="2016-08-24 20:02:28" resolution="Fixed">
		<buginformation>
			<summary>HRegion#RegionScannerImpl#handleFileNotFoundException may lead to deadlock when trying to obtain write lock on updatesLock</summary>
			<description>here is my jvm stack:


2016-07-29 16:36:56
Full thread dump Java HotSpot(TM) 64-Bit Server VM (24.72-b04 mixed mode):

"Timer for &amp;amp;apos;HBase&amp;amp;apos; metrics system" daemon prio=10 tid=0x00007f205cf38000 nid=0xafa5 in Object.wait() [0x00007f203b353000]
   java.lang.Thread.State: TIMED_WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	at java.util.TimerThread.mainLoop(Timer.java:552)
	- locked &amp;lt;0x000000063503c790&amp;gt; (a java.util.TaskQueue)
	at java.util.TimerThread.run(Timer.java:505)

"Attach Listener" daemon prio=10 tid=0x00007f205d017800 nid=0x1300 waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

"IPC Parameter Sending Thread #2" daemon prio=10 tid=0x00007f205c7c4000 nid=0x4f1a waiting on condition [0x00007f20362e1000]
   java.lang.Thread.State: TIMED_WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f996718&amp;gt; (a java.util.concurrent.SynchronousQueue$TransferStack)
	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)
	at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
	at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:359)
	at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:942)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

"RS_LOG_REPLAY_OPS-hadoop-datanode-0042:16020-1" prio=10 tid=0x00007f2054ec8000 nid=0x832d waiting on condition [0x00007f2039a18000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066ffb5950&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

"RS_LOG_REPLAY_OPS-hadoop-datanode-0042:16020-0" prio=10 tid=0x00007f20542ca800 nid=0x5a5d waiting on condition [0x00007f2033bba000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066ffb5950&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

"hadoop-datanode-0042.corp.cootek.com,16020,1469690065288_ChoreService_2" daemon prio=10 tid=0x00007f205d0d4000 nid=0x72af waiting on condition [0x00007f203b151000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066fd70dd8&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1079)
	at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:807)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

"RS_CLOSE_REGION-hadoop-datanode-0042:16020-2" prio=10 tid=0x0000000002232000 nid=0xab85 waiting on condition [0x00007f2033ab9000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x00000006708113f8&amp;gt; (a java.util.concurrent.locks.ReentrantReadWriteLock$NonfairSync)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:834)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(AbstractQueuedSynchronizer.java:867)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:1197)
	at java.util.concurrent.locks.ReentrantReadWriteLock$WriteLock.lock(ReentrantReadWriteLock.java:945)
	at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:1423)
	at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1369)
	- locked &amp;lt;0x00000006707c3560&amp;gt; (a java.lang.Object)
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:138)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:129)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

"RS_CLOSE_REGION-hadoop-datanode-0042:16020-1" prio=10 tid=0x00007f204cfa3000 nid=0xab84 waiting on condition [0x00007f2033ebd000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066ffb5c20&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

"RS_CLOSE_REGION-hadoop-datanode-0042:16020-0" prio=10 tid=0x00007f204c30f800 nid=0xab31 waiting on condition [0x00007f203b555000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066ffb5c20&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

"group-cache-0" daemon prio=10 tid=0x00007f205c904000 nid=0xa858 waiting on condition [0x00007f20339b8000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066fa930b0&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1079)
	at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:807)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

"ReplicationExecutor-0" daemon prio=10 tid=0x00007f204c600000 nid=0x9596 waiting on condition [0x00007f20356d5000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066ffb5ed8&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

"RS_OPEN_REGION-hadoop-datanode-0042:16020-1" prio=10 tid=0x00007f205404c800 nid=0x8f88 waiting on condition [0x00007f2039f3f000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066fc65d60&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

"RS_OPEN_REGION-hadoop-datanode-0042:16020-2" prio=10 tid=0x00000000017dc800 nid=0x8f87 waiting on condition [0x00007f203a040000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066fc65d60&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

"RS_OPEN_REGION-hadoop-datanode-0042:16020-0" prio=10 tid=0x00007f204c5fe000 nid=0x8f86 waiting on condition [0x00007f203a141000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066fc65d60&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

"org.apache.hadoop.hdfs.PeerCache@7c1775ad" daemon prio=10 tid=0x00007f204cfdd000 nid=0x8f85 waiting on condition [0x00007f203a242000]
   java.lang.Thread.State: TIMED_WAITING (sleeping)
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.PeerCache.run(PeerCache.java:244)
	at org.apache.hadoop.hdfs.PeerCache.access$000(PeerCache.java:41)
	at org.apache.hadoop.hdfs.PeerCache$1.run(PeerCache.java:119)
	at java.lang.Thread.run(Thread.java:745)

"hadoop-datanode-0042:16020Replication Statistics #0" daemon prio=10 tid=0x0000000001bc2800 nid=0x8f52 waiting on condition [0x00007f203a444000]
   java.lang.Thread.State: TIMED_WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066fef1b58&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082)
	at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1090)
	at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:807)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

"HBase-Metrics2-1" daemon prio=10 tid=0x00000000018b0000 nid=0x8f4c waiting on condition [0x00007f203aa4a000]
   java.lang.Thread.State: TIMED_WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066fd70da8&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082)
	at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1090)
	at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:807)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

"sync.4" prio=10 tid=0x00007f204c10c800 nid=0x8f4b waiting on condition [0x00007f203ab4b000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066fb98ee8&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$SyncRunner.run(FSHLog.java:1212)
	at java.lang.Thread.run(Thread.java:745)

"sync.3" prio=10 tid=0x00007f204c4df800 nid=0x8f4a waiting on condition [0x00007f203ac4c000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f9ab398&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$SyncRunner.run(FSHLog.java:1212)
	at java.lang.Thread.run(Thread.java:745)

"sync.2" prio=10 tid=0x00007f204c4dd800 nid=0x8f49 waiting on condition [0x00007f203ad4d000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066fef7240&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$SyncRunner.run(FSHLog.java:1212)
	at java.lang.Thread.run(Thread.java:745)

"sync.1" prio=10 tid=0x00007f204c4dc800 nid=0x8f48 waiting on condition [0x00007f203ae4e000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066ff089b8&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$SyncRunner.run(FSHLog.java:1212)
	at java.lang.Thread.run(Thread.java:745)

"sync.0" prio=10 tid=0x00007f204c503000 nid=0x8f47 waiting on condition [0x00007f203af4f000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066fef71f8&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$SyncRunner.run(FSHLog.java:1212)
	at java.lang.Thread.run(Thread.java:745)

"regionserver/hadoop-datanode-0042.corp.cootek.com/192.168.0.168:16020.append-pool1-t1" prio=10 tid=0x0000000001ba0800 nid=0x8f46 waiting on condition [0x00007f203b050000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066ff08200&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at com.lmax.disruptor.BlockingWaitStrategy.waitFor(BlockingWaitStrategy.java:45)
	at com.lmax.disruptor.ProcessingSequenceBarrier.waitFor(ProcessingSequenceBarrier.java:55)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

"LeaseRenewer:hadoop@hadoop2-namenode:9000" daemon prio=10 tid=0x0000000001b6c000 nid=0x8f42 waiting on condition [0x00007f203b252000]
   java.lang.Thread.State: TIMED_WAITING (sleeping)
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:438)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)

"JvmPauseMonitor" daemon prio=10 tid=0x0000000001cf5800 nid=0x8f3a waiting on condition [0x00007f203b959000]
   java.lang.Thread.State: TIMED_WAITING (sleeping)
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hbase.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:159)
	at java.lang.Thread.run(Thread.java:745)

"regionserver/hadoop-datanode-0042.corp.cootek.com/192.168.0.168:16020" prio=10 tid=0x00007f205d045800 nid=0x8f37 waiting on condition [0x00007f203be5a000]
   java.lang.Thread.State: TIMED_WAITING (sleeping)
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.sleep(HRegionServer.java:1301)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.waitOnAllRegionsToClose(HRegionServer.java:1287)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:1057)
	at java.lang.Thread.run(Thread.java:745)

"ReplicationRpcServer.handler=2,queue=0,port=16020" daemon prio=10 tid=0x00007f205cfe1000 nid=0x8f33 waiting on condition [0x00007f203c25e000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f996eb0&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"ReplicationRpcServer.handler=1,queue=0,port=16020" daemon prio=10 tid=0x00007f205cfdf000 nid=0x8f32 waiting on condition [0x00007f203c35f000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f996eb0&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"ReplicationRpcServer.handler=0,queue=0,port=16020" daemon prio=10 tid=0x00007f205cfdd000 nid=0x8f31 waiting on condition [0x00007f203c460000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f996eb0&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"PriorityRpcServer.handler=19,queue=1,port=16020" daemon prio=10 tid=0x00007f205cfdb000 nid=0x8f30 waiting on condition [0x00007f203c561000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f997620&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"PriorityRpcServer.handler=18,queue=0,port=16020" daemon prio=10 tid=0x00007f205cfd8800 nid=0x8f2f waiting on condition [0x00007f203c662000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f9977a0&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"PriorityRpcServer.handler=17,queue=1,port=16020" daemon prio=10 tid=0x00007f205cfd6800 nid=0x8f2e waiting on condition [0x00007f203c763000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f997620&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"PriorityRpcServer.handler=16,queue=0,port=16020" daemon prio=10 tid=0x00007f205cfd4800 nid=0x8f2d waiting on condition [0x00007f203c864000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f9977a0&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"PriorityRpcServer.handler=15,queue=1,port=16020" daemon prio=10 tid=0x00007f205cfd2800 nid=0x8f2c waiting on condition [0x00007f203c965000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f997620&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"PriorityRpcServer.handler=14,queue=0,port=16020" daemon prio=10 tid=0x00007f205cfd0800 nid=0x8f2b waiting on condition [0x00007f203ca66000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f9977a0&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"PriorityRpcServer.handler=13,queue=1,port=16020" daemon prio=10 tid=0x00007f205cfce000 nid=0x8f2a waiting on condition [0x00007f203cb67000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f997620&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"PriorityRpcServer.handler=12,queue=0,port=16020" daemon prio=10 tid=0x00007f205cfcc000 nid=0x8f29 waiting on condition [0x00007f203cc68000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f9977a0&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"PriorityRpcServer.handler=11,queue=1,port=16020" daemon prio=10 tid=0x00007f205cfca000 nid=0x8f28 waiting on condition [0x00007f203cd69000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f997620&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"PriorityRpcServer.handler=10,queue=0,port=16020" daemon prio=10 tid=0x00007f205cfc8000 nid=0x8f27 waiting on condition [0x00007f203ce6a000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f9977a0&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"PriorityRpcServer.handler=9,queue=1,port=16020" daemon prio=10 tid=0x00007f205cfc5800 nid=0x8f26 waiting on condition [0x00007f203cf6b000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f997620&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"PriorityRpcServer.handler=8,queue=0,port=16020" daemon prio=10 tid=0x00007f205cfc3800 nid=0x8f25 waiting on condition [0x00007f203d06c000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f9977a0&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"PriorityRpcServer.handler=7,queue=1,port=16020" daemon prio=10 tid=0x00007f205cfc1800 nid=0x8f24 waiting on condition [0x00007f203d16d000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f997620&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"PriorityRpcServer.handler=6,queue=0,port=16020" daemon prio=10 tid=0x00007f205cfbf800 nid=0x8f23 waiting on condition [0x00007f203d26e000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f9977a0&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"PriorityRpcServer.handler=5,queue=1,port=16020" daemon prio=10 tid=0x00007f205cfbd000 nid=0x8f22 waiting on condition [0x00007f203d36f000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f997620&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"PriorityRpcServer.handler=4,queue=0,port=16020" daemon prio=10 tid=0x00007f205cfbb000 nid=0x8f21 waiting on condition [0x00007f203d470000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f9977a0&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"PriorityRpcServer.handler=3,queue=1,port=16020" daemon prio=10 tid=0x00007f205cfb9000 nid=0x8f20 waiting on condition [0x00007f203d571000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f997620&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"PriorityRpcServer.handler=2,queue=0,port=16020" daemon prio=10 tid=0x00007f205cfb7000 nid=0x8f1f waiting on condition [0x00007f203d672000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f9977a0&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"PriorityRpcServer.handler=1,queue=1,port=16020" daemon prio=10 tid=0x00007f205cfb4800 nid=0x8f1e waiting on condition [0x00007f203d773000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f997620&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"PriorityRpcServer.handler=0,queue=0,port=16020" daemon prio=10 tid=0x00007f205cfb2800 nid=0x8f1d waiting on condition [0x00007f203d874000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f9977a0&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"B.defaultRpcServer.handler=29,queue=2,port=16020" daemon prio=10 tid=0x00007f205cfb0800 nid=0x8f1c waiting on condition [0x00007f203d975000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f998ae8&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.take(BoundedPriorityBlockingQueue.java:214)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"B.defaultRpcServer.handler=28,queue=1,port=16020" daemon prio=10 tid=0x00007f205cfae800 nid=0x8f1b waiting on condition [0x00007f203da76000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f998070&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.take(BoundedPriorityBlockingQueue.java:214)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"B.defaultRpcServer.handler=27,queue=0,port=16020" daemon prio=10 tid=0x00007f205cfac800 nid=0x8f1a waiting on condition [0x00007f203db77000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f9910c8&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.take(BoundedPriorityBlockingQueue.java:214)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"B.defaultRpcServer.handler=26,queue=2,port=16020" daemon prio=10 tid=0x00007f205cfaa000 nid=0x8f19 waiting on condition [0x00007f203dc78000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f998ae8&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.take(BoundedPriorityBlockingQueue.java:214)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"B.defaultRpcServer.handler=25,queue=1,port=16020" daemon prio=10 tid=0x00007f205cfa8000 nid=0x8f18 waiting on condition [0x00007f203dd79000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f998070&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.take(BoundedPriorityBlockingQueue.java:214)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"B.defaultRpcServer.handler=24,queue=0,port=16020" daemon prio=10 tid=0x00007f205cfa6000 nid=0x8f17 waiting for monitor entry [0x00007f203de79000]
   java.lang.Thread.State: BLOCKED (on object monitor)
	at org.apache.hadoop.hbase.regionserver.HRegion.refreshStoreFiles(HRegion.java:4887)
	- waiting to lock &amp;lt;0x00000006707c3500&amp;gt; (a org.apache.hadoop.hbase.regionserver.HRegion$WriteState)
	at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.handleFileNotFound(HRegion.java:6104)
	at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.populateResult(HRegion.java:5736)
	at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.nextInternal(HRegion.java:5875)
	at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.nextRaw(HRegion.java:5653)
	at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.next(HRegion.java:5630)
	- locked &amp;lt;0x00000007130162c8&amp;gt; (a org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl)
	at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.next(HRegion.java:5616)
	at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:6810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getIncrementCurrentValue(HRegion.java:7673)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyIncrementsToColumnFamily(HRegion.java:7583)
	at org.apache.hadoop.hbase.regionserver.HRegion.doIncrement(HRegion.java:7480)
	at org.apache.hadoop.hbase.regionserver.HRegion.increment(HRegion.java:7440)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.increment(RSRpcServices.java:551)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2227)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:33646)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2178)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:112)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"B.defaultRpcServer.handler=23,queue=2,port=16020" daemon prio=10 tid=0x00007f205cfa4000 nid=0x8f16 waiting on condition [0x00007f203df7b000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f998ae8&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.take(BoundedPriorityBlockingQueue.java:214)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"B.defaultRpcServer.handler=22,queue=1,port=16020" daemon prio=10 tid=0x00007f205cfa2000 nid=0x8f15 waiting on condition [0x00007f203e07c000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f998070&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.take(BoundedPriorityBlockingQueue.java:214)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"B.defaultRpcServer.handler=21,queue=0,port=16020" daemon prio=10 tid=0x00007f205cfa0000 nid=0x8f14 waiting on condition [0x00007f203e17d000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f9910c8&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.take(BoundedPriorityBlockingQueue.java:214)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"B.defaultRpcServer.handler=20,queue=2,port=16020" daemon prio=10 tid=0x00007f205cf9d800 nid=0x8f13 waiting on condition [0x00007f203e27e000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f998ae8&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.take(BoundedPriorityBlockingQueue.java:214)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"B.defaultRpcServer.handler=19,queue=1,port=16020" daemon prio=10 tid=0x00007f205cf9b800 nid=0x8f12 waiting on condition [0x00007f203e37f000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f998070&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.take(BoundedPriorityBlockingQueue.java:214)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"B.defaultRpcServer.handler=18,queue=0,port=16020" daemon prio=10 tid=0x00007f205cf99800 nid=0x8f11 waiting on condition [0x00007f203e480000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f9910c8&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.take(BoundedPriorityBlockingQueue.java:214)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"B.defaultRpcServer.handler=17,queue=2,port=16020" daemon prio=10 tid=0x00007f205cf97800 nid=0x8f10 waiting on condition [0x00007f203e581000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f998ae8&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.take(BoundedPriorityBlockingQueue.java:214)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"B.defaultRpcServer.handler=16,queue=1,port=16020" daemon prio=10 tid=0x00007f205cf95800 nid=0x8f0f waiting on condition [0x00007f203e682000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f998070&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.take(BoundedPriorityBlockingQueue.java:214)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"B.defaultRpcServer.handler=15,queue=0,port=16020" daemon prio=10 tid=0x00007f205cf93000 nid=0x8f0e waiting on condition [0x00007f203e783000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f9910c8&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.take(BoundedPriorityBlockingQueue.java:214)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"B.defaultRpcServer.handler=14,queue=2,port=16020" daemon prio=10 tid=0x00007f205cf91000 nid=0x8f0d waiting on condition [0x00007f203e884000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f998ae8&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.take(BoundedPriorityBlockingQueue.java:214)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"B.defaultRpcServer.handler=13,queue=1,port=16020" daemon prio=10 tid=0x00007f205cf8f000 nid=0x8f0c waiting on condition [0x00007f203e985000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f998070&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.take(BoundedPriorityBlockingQueue.java:214)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"B.defaultRpcServer.handler=12,queue=0,port=16020" daemon prio=10 tid=0x00007f205cf8d000 nid=0x8f0b waiting on condition [0x00007f203ea85000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x00000006708113c8&amp;gt; (a java.util.concurrent.locks.ReentrantReadWriteLock$NonfairSync)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:834)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(AbstractQueuedSynchronizer.java:867)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:1197)
	at java.util.concurrent.locks.ReentrantReadWriteLock$WriteLock.lock(ReentrantReadWriteLock.java:945)
	at org.apache.hadoop.hbase.regionserver.HRegion.dropMemstoreContentsForSeqId(HRegion.java:4568)
	at org.apache.hadoop.hbase.regionserver.HRegion.refreshStoreFiles(HRegion.java:4919)
	- locked &amp;lt;0x00000006707c3500&amp;gt; (a org.apache.hadoop.hbase.regionserver.HRegion$WriteState)
	at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.handleFileNotFound(HRegion.java:6104)
	at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.populateResult(HRegion.java:5736)
	at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.nextInternal(HRegion.java:5875)
	at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.nextRaw(HRegion.java:5653)
	at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.next(HRegion.java:5630)
	- locked &amp;lt;0x0000000713017648&amp;gt; (a org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl)
	at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.next(HRegion.java:5616)
	at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:6810)
	at org.apache.hadoop.hbase.regionserver.HRegion.getIncrementCurrentValue(HRegion.java:7673)
	at org.apache.hadoop.hbase.regionserver.HRegion.applyIncrementsToColumnFamily(HRegion.java:7583)
	at org.apache.hadoop.hbase.regionserver.HRegion.doIncrement(HRegion.java:7480)
	at org.apache.hadoop.hbase.regionserver.HRegion.increment(HRegion.java:7440)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.increment(RSRpcServices.java:551)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.mutate(RSRpcServices.java:2227)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:33646)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2178)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:112)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:133)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"B.defaultRpcServer.handler=11,queue=2,port=16020" daemon prio=10 tid=0x00007f205cf8a800 nid=0x8f0a waiting on condition [0x00007f203eb87000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f998ae8&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.take(BoundedPriorityBlockingQueue.java:214)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"B.defaultRpcServer.handler=10,queue=1,port=16020" daemon prio=10 tid=0x00007f205cf88800 nid=0x8f09 waiting on condition [0x00007f203ec88000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f998070&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.take(BoundedPriorityBlockingQueue.java:214)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"B.defaultRpcServer.handler=9,queue=0,port=16020" daemon prio=10 tid=0x00007f205cf86800 nid=0x8f08 waiting on condition [0x00007f203ed89000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f9910c8&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.take(BoundedPriorityBlockingQueue.java:214)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"B.defaultRpcServer.handler=8,queue=2,port=16020" daemon prio=10 tid=0x00007f205cf84800 nid=0x8f07 waiting on condition [0x00007f203ee8a000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f998ae8&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.take(BoundedPriorityBlockingQueue.java:214)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"B.defaultRpcServer.handler=7,queue=1,port=16020" daemon prio=10 tid=0x00007f205cf82000 nid=0x8f06 waiting on condition [0x00007f203ef8b000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f998070&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.take(BoundedPriorityBlockingQueue.java:214)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"B.defaultRpcServer.handler=6,queue=0,port=16020" daemon prio=10 tid=0x00007f205cf80000 nid=0x8f05 waiting on condition [0x00007f203f08c000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f9910c8&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.take(BoundedPriorityBlockingQueue.java:214)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"B.defaultRpcServer.handler=5,queue=2,port=16020" daemon prio=10 tid=0x00007f205cf7e000 nid=0x8f04 waiting on condition [0x00007f203f18d000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f998ae8&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.take(BoundedPriorityBlockingQueue.java:214)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"B.defaultRpcServer.handler=4,queue=1,port=16020" daemon prio=10 tid=0x00007f205cf7b800 nid=0x8f03 waiting on condition [0x00007f203f28e000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f998070&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.take(BoundedPriorityBlockingQueue.java:214)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"B.defaultRpcServer.handler=3,queue=0,port=16020" daemon prio=10 tid=0x00007f205cf79800 nid=0x8f02 waiting on condition [0x00007f203f38f000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f9910c8&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.take(BoundedPriorityBlockingQueue.java:214)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"B.defaultRpcServer.handler=2,queue=2,port=16020" daemon prio=10 tid=0x00007f205cf78000 nid=0x8f01 waiting on condition [0x00007f203f490000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f998ae8&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.take(BoundedPriorityBlockingQueue.java:214)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"B.defaultRpcServer.handler=1,queue=1,port=16020" daemon prio=10 tid=0x00007f205cf77000 nid=0x8f00 waiting on condition [0x00007f203f591000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f998070&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.take(BoundedPriorityBlockingQueue.java:214)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"B.defaultRpcServer.handler=0,queue=0,port=16020" daemon prio=10 tid=0x00007f205cf5a800 nid=0x8eff waiting on condition [0x00007f203f692000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;0x000000066f9910c8&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at org.apache.hadoop.hbase.util.BoundedPriorityBlockingQueue.take(BoundedPriorityBlockingQueue.java:214)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:129)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)
	at java.lang.Thread.run(Thread.java:745)

"RpcServer.listener,port=16020" daemon prio=10 tid=0x00007f205cf56800 nid=0x8efe runnable [0x00007f203f793000]
   java.lang.Thread.State: RUNNABLE
	at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
	at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
	at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:79)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:87)
	- locked &amp;lt;0x000000066f9a4490&amp;gt; (a sun.nio.ch.Util$2)
	- locked &amp;lt;0x000000066f9a44a8&amp;gt; (a java.util.Collections$UnmodifiableSet)
	- locked &amp;lt;0x000000066f99c370&amp;gt; (a sun.nio.ch.EPollSelectorImpl)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:98)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:102)
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener.run(RpcServer.java:728)

"RpcServer.responder" daemon prio=10 tid=0x00007f205cf4d800 nid=0x8efd runnable [0x00007f203f894000]
   java.lang.Thread.State: RUNNABLE
	at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
	at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
	at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:79)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:87)
	- locked &amp;lt;0x000000066f9905f8&amp;gt; (a sun.nio.ch.Util$2)
	- locked &amp;lt;0x000000066f990610&amp;gt; (a java.util.Collections$UnmodifiableSet)
	- locked &amp;lt;0x000000066f9a60e8&amp;gt; (a sun.nio.ch.EPollSelectorImpl)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:98)
	at org.apache.hadoop.hbase.ipc.RpcServer$Responder.doRunLoop(RpcServer.java:967)
	at org.apache.hadoop.hbase.ipc.RpcServer$Responder.run(RpcServer.java:914)

"RpcServer.reader=9,bindAddress=hadoop-datanode-0042.corp.cootek.com,port=16020" daemon prio=10 tid=0x00007f205cbaf800 nid=0x8ef8 runnable [0x00007f20402ca000]
   java.lang.Thread.State: RUNNABLE
	at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
	at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
	at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:79)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:87)
	- locked &amp;lt;0x000000066f9919f8&amp;gt; (a sun.nio.ch.Util$2)
	- locked &amp;lt;0x000000066f991a10&amp;gt; (a java.util.Collections$UnmodifiableSet)
	- locked &amp;lt;0x000000066f9a51b0&amp;gt; (a sun.nio.ch.EPollSelectorImpl)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:98)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:102)
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.doRunLoop(RpcServer.java:622)
	- locked &amp;lt;0x000000066f991a28&amp;gt; (a org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader)
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.run(RpcServer.java:609)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

"RpcServer.reader=8,bindAddress=hadoop-datanode-0042.corp.cootek.com,port=16020" daemon prio=10 tid=0x00007f205ca84000 nid=0x8ef7 runnable [0x00007f20403cb000]
   java.lang.Thread.State: RUNNABLE
	at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
	at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
	at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:79)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:87)
	- locked &amp;lt;0x000000066f9a6c40&amp;gt; (a sun.nio.ch.Util$2)
	- locked &amp;lt;0x000000066f9a6c58&amp;gt; (a java.util.Collections$UnmodifiableSet)
	- locked &amp;lt;0x000000066f9a6520&amp;gt; (a sun.nio.ch.EPollSelectorImpl)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:98)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:102)
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.doRunLoop(RpcServer.java:622)
	- locked &amp;lt;0x000000066f9a6c70&amp;gt; (a org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader)
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.run(RpcServer.java:609)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

"RpcServer.reader=7,bindAddress=hadoop-datanode-0042.corp.cootek.com,port=16020" daemon prio=10 tid=0x00007f205ca81800 nid=0x8ef6 runnable [0x00007f20404cc000]
   java.lang.Thread.State: RUNNABLE
	at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
	at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
	at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:79)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:87)
	- locked &amp;lt;0x000000066f9a79f0&amp;gt; (a sun.nio.ch.Util$2)
	- locked &amp;lt;0x000000066f9a7a08&amp;gt; (a java.util.Collections$UnmodifiableSet)
	- locked &amp;lt;0x000000066f9a4718&amp;gt; (a sun.nio.ch.EPollSelectorImpl)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:98)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:102)
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.doRunLoop(RpcServer.java:622)
	- locked &amp;lt;0x000000066f9a7a20&amp;gt; (a org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader)
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.run(RpcServer.java:609)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

"RpcServer.reader=6,bindAddress=hadoop-datanode-0042.corp.cootek.com,port=16020" daemon prio=10 tid=0x00007f205ca7f800 nid=0x8ef5 runnable [0x00007f20405cd000]
   java.lang.Thread.State: RUNNABLE
	at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
	at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
	at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:79)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:87)
	- locked &amp;lt;0x000000066f9afd68&amp;gt; (a sun.nio.ch.Util$2)
	- locked &amp;lt;0x000000066f9afd80&amp;gt; (a java.util.Collections$UnmodifiableSet)
	- locked &amp;lt;0x000000066f9a82c0&amp;gt; (a sun.nio.ch.EPollSelectorImpl)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:98)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:102)
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.doRunLoop(RpcServer.java:622)
	- locked &amp;lt;0x000000066f9afd98&amp;gt; (a org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader)
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.run(RpcServer.java:609)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

"RpcServer.reader=5,bindAddress=hadoop-datanode-0042.corp.cootek.com,port=16020" daemon prio=10 tid=0x00007f205ca7d800 nid=0x8ef4 runnable [0x00007f20406ce000]
   java.lang.Thread.State: RUNNABLE
	at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
	at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
	at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:79)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:87)
	- locked &amp;lt;0x000000066f998998&amp;gt; (a sun.nio.ch.Util$2)
	- locked &amp;lt;0x000000066f9989b0&amp;gt; (a java.util.Collections$UnmodifiableSet)
	- locked &amp;lt;0x000000066f99c568&amp;gt; (a sun.nio.ch.EPollSelectorImpl)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:98)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:102)
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.doRunLoop(RpcServer.java:622)
	- locked &amp;lt;0x000000066f9989c8&amp;gt; (a org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader)
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.run(RpcServer.java:609)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

"RpcServer.reader=4,bindAddress=hadoop-datanode-0042.corp.cootek.com,port=16020" daemon prio=10 tid=0x00007f205ca7c000 nid=0x8ef3 runnable [0x00007f20407cf000]
   java.lang.Thread.State: RUNNABLE
	at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
	at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
	at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:79)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:87)
	- locked &amp;lt;0x000000066f9a4598&amp;gt; (a sun.nio.ch.Util$2)
	- locked &amp;lt;0x000000066f9a45b0&amp;gt; (a java.util.Collections$UnmodifiableSet)
	- locked &amp;lt;0x000000066f9a39c8&amp;gt; (a sun.nio.ch.EPollSelectorImpl)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:98)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:102)
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.doRunLoop(RpcServer.java:622)
	- locked &amp;lt;0x000000066f9a45c8&amp;gt; (a org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader)
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.run(RpcServer.java:609)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

"RpcServer.reader=3,bindAddress=hadoop-datanode-0042.corp.cootek.com,port=16020" daemon prio=10 tid=0x00007f205ca7a800 nid=0x8ef2 runnable [0x00007f20408d0000]
   java.lang.Thread.State: RUNNABLE
	at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
	at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
	at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:79)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:87)
	- locked &amp;lt;0x000000066f99c970&amp;gt; (a sun.nio.ch.Util$2)
	- locked &amp;lt;0x000000066f99c988&amp;gt; (a java.util.Collections$UnmodifiableSet)
	- locked &amp;lt;0x000000066f9a2008&amp;gt; (a sun.nio.ch.EPollSelectorImpl)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:98)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:102)
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.doRunLoop(RpcServer.java:622)
	- locked &amp;lt;0x000000066f99c9a0&amp;gt; (a org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader)
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.run(RpcServer.java:609)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

"RpcServer.reader=2,bindAddress=hadoop-datanode-0042.corp.cootek.com,port=16020" daemon prio=10 tid=0x00007f205ca78800 nid=0x8ef1 runnable [0x00007f20409d1000]
   java.lang.Thread.State: RUNNABLE
	at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
	at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
	at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:79)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:87)
	- locked &amp;lt;0x000000066f9989e0&amp;gt; (a sun.nio.ch.Util$2)
	- locked &amp;lt;0x000000066f9989f8&amp;gt; (a java.util.Collections$UnmodifiableSet)
	- locked &amp;lt;0x000000066f99c640&amp;gt; (a sun.nio.ch.EPollSelectorImpl)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:98)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:102)
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.doRunLoop(RpcServer.java:622)
	- locked &amp;lt;0x000000066f998a10&amp;gt; (a org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader)
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.run(RpcServer.java:609)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

"RpcServer.reader=1,bindAddress=hadoop-datanode-0042.corp.cootek.com,port=16020" daemon prio=10 tid=0x00007f205ca93000 nid=0x8ef0 runnable [0x00007f2040ad2000]
   java.lang.Thread.State: RUNNABLE
	at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
	at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
	at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:79)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:87)
	- locked &amp;lt;0x000000066f9a94a8&amp;gt; (a sun.nio.ch.Util$2)
	- locked &amp;lt;0x000000066f9a94c0&amp;gt; (a java.util.Collections$UnmodifiableSet)
	- locked &amp;lt;0x000000066f9a8d58&amp;gt; (a sun.nio.ch.EPollSelectorImpl)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:98)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:102)
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.doRunLoop(RpcServer.java:622)
	- locked &amp;lt;0x000000066f998a88&amp;gt; (a org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader)
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.run(RpcServer.java:609)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

"RpcServer.reader=0,bindAddress=hadoop-datanode-0042.corp.cootek.com,port=16020" daemon prio=10 tid=0x00007f205ca47000 nid=0x8eef runnable [0x00007f2040de0000]
   java.lang.Thread.State: RUNNABLE
	at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
	at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
	at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:79)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:87)
	- locked &amp;lt;0x000000066f998a28&amp;gt; (a sun.nio.ch.Util$2)
	- locked &amp;lt;0x000000066f998a40&amp;gt; (a java.util.Collections$UnmodifiableSet)
	- locked &amp;lt;0x000000066f99c6d0&amp;gt; (a sun.nio.ch.EPollSelectorImpl)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:98)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:102)
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.doRunLoop(RpcServer.java:622)
	- locked &amp;lt;0x000000066f998a58&amp;gt; (a org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader)
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.run(RpcServer.java:609)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

"Service Thread" daemon prio=10 tid=0x00007f205c2dc800 nid=0x8ee9 runnable [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

"C2 CompilerThread1" daemon prio=10 tid=0x00007f205c2da000 nid=0x8ee8 waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

"C2 CompilerThread0" daemon prio=10 tid=0x00007f205c2d7800 nid=0x8ee7 waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

"Signal Dispatcher" daemon prio=10 tid=0x00007f205c2d5000 nid=0x8ee6 runnable [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

"Surrogate Locker Thread (Concurrent GC)" daemon prio=10 tid=0x00007f205c2d3000 nid=0x8ee5 waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

"Finalizer" daemon prio=10 tid=0x00007f205c2b2800 nid=0x8ee4 in Object.wait() [0x00007f20423b2000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:135)
	- locked &amp;lt;0x000000066f99d7d8&amp;gt; (a java.lang.ref.ReferenceQueue$Lock)
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:151)
	at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:209)

"Reference Handler" daemon prio=10 tid=0x00007f205c2b0800 nid=0x8ee3 in Object.wait() [0x00007f20424b3000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:503)
	at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:133)
	- locked &amp;lt;0x000000066f998a70&amp;gt; (a java.lang.ref.Reference$Lock)

"main" prio=10 tid=0x00007f205c00e000 nid=0x8ec3 in Object.wait() [0x00007f2065144000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	- waiting on &amp;lt;0x000000066f9927d0&amp;gt; (a java.lang.Thread)
	at java.lang.Thread.join(Thread.java:1281)
	- locked &amp;lt;0x000000066f9927d0&amp;gt; (a java.lang.Thread)
	at java.lang.Thread.join(Thread.java:1355)
	at org.apache.hadoop.hbase.util.HasThread.join(HasThread.java:89)
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.start(HRegionServerCommandLine.java:66)
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.run(HRegionServerCommandLine.java:87)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:126)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.main(HRegionServer.java:2665)

"VM Thread" prio=10 tid=0x00007f205c2ac000 nid=0x8ee2 runnable 

"Gang worker#0 (Parallel GC Threads)" prio=10 tid=0x00007f205c01f000 nid=0x8ec4 runnable 

"Gang worker#1 (Parallel GC Threads)" prio=10 tid=0x00007f205c021000 nid=0x8ec5 runnable 

"Gang worker#2 (Parallel GC Threads)" prio=10 tid=0x00007f205c022800 nid=0x8ec6 runnable 

"Gang worker#3 (Parallel GC Threads)" prio=10 tid=0x00007f205c024800 nid=0x8ec7 runnable 

"Gang worker#4 (Parallel GC Threads)" prio=10 tid=0x00007f205c026800 nid=0x8ec8 runnable 

"Gang worker#5 (Parallel GC Threads)" prio=10 tid=0x00007f205c028800 nid=0x8ec9 runnable 

"Gang worker#6 (Parallel GC Threads)" prio=10 tid=0x00007f205c02a000 nid=0x8eca runnable 

"Gang worker#7 (Parallel GC Threads)" prio=10 tid=0x00007f205c02c000 nid=0x8ecb runnable 

"Gang worker#8 (Parallel GC Threads)" prio=10 tid=0x00007f205c02e000 nid=0x8ecc runnable 

"Gang worker#9 (Parallel GC Threads)" prio=10 tid=0x00007f205c02f800 nid=0x8ecd runnable 

"Gang worker#10 (Parallel GC Threads)" prio=10 tid=0x00007f205c031800 nid=0x8ece runnable 

"Gang worker#11 (Parallel GC Threads)" prio=10 tid=0x00007f205c033800 nid=0x8ecf runnable 

"Gang worker#12 (Parallel GC Threads)" prio=10 tid=0x00007f205c035800 nid=0x8ed0 runnable 

"Gang worker#13 (Parallel GC Threads)" prio=10 tid=0x00007f205c037000 nid=0x8ed1 runnable 

"Gang worker#14 (Parallel GC Threads)" prio=10 tid=0x00007f205c039000 nid=0x8ed2 runnable 

"Gang worker#15 (Parallel GC Threads)" prio=10 tid=0x00007f205c03b000 nid=0x8ed3 runnable 

"Gang worker#16 (Parallel GC Threads)" prio=10 tid=0x00007f205c03c800 nid=0x8ed4 runnable 

"Gang worker#17 (Parallel GC Threads)" prio=10 tid=0x00007f205c03e800 nid=0x8ed5 runnable 

"Gang worker#18 (Parallel GC Threads)" prio=10 tid=0x00007f205c040800 nid=0x8ed6 runnable 

"Gang worker#19 (Parallel GC Threads)" prio=10 tid=0x00007f205c042000 nid=0x8ed7 runnable 

"Gang worker#20 (Parallel GC Threads)" prio=10 tid=0x00007f205c044000 nid=0x8ed8 runnable 

"Gang worker#21 (Parallel GC Threads)" prio=10 tid=0x00007f205c046000 nid=0x8ed9 runnable 

"Gang worker#22 (Parallel GC Threads)" prio=10 tid=0x00007f205c048000 nid=0x8eda runnable 

"Concurrent Mark-Sweep GC Thread" prio=10 tid=0x00007f205c267000 nid=0x8ee1 runnable 
"Gang worker#0 (Parallel CMS Threads)" prio=10 tid=0x00007f205c25b000 nid=0x8edb runnable 

"Gang worker#1 (Parallel CMS Threads)" prio=10 tid=0x00007f205c25d000 nid=0x8edc runnable 

"Gang worker#2 (Parallel CMS Threads)" prio=10 tid=0x00007f205c25e800 nid=0x8edd runnable 

"Gang worker#3 (Parallel CMS Threads)" prio=10 tid=0x00007f205c260800 nid=0x8ede runnable 

"Gang worker#4 (Parallel CMS Threads)" prio=10 tid=0x00007f205c262800 nid=0x8edf runnable 

"Gang worker#5 (Parallel CMS Threads)" prio=10 tid=0x00007f205c264000 nid=0x8ee0 runnable 

"VM Periodic Task Thread" prio=10 tid=0x00007f205c2df800 nid=0x8eea waiting on condition 

JNI global references: 221

</description>
			<version>1.2.2</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.2.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
		</fixedFiles>
	</bug>
	<bug id="16528" opendate="2016-08-30 02:29:50" fixdate="2016-08-31 17:09:57" resolution="Fixed">
		<buginformation>
			<summary>Procedure-V2: ServerCrashProcedure misses owner information</summary>
			<description>ServerCrashProcedure constructor does not set up owner information.  If someone wants to access the owner of ServerCrashProcedure, it would get NPE (eg. in case someone accidentally tries to abort a ServerCrashProcedure, the coprocessor to check owner of the procedure would throw NPE)</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.2.4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.TestDeadServer.java</file>
			<file type="M">org.apache.hadoop.hbase.master.procedure.TestServerCrashProcedure.java</file>
			<file type="M">org.apache.hadoop.hbase.master.procedure.ServerCrashProcedure.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ServerManager.java</file>
			<file type="M">org.apache.hadoop.hbase.master.procedure.TestMasterProcedureEvents.java</file>
		</fixedFiles>
		<links>
			<link type="dependent" description="depends upon">16522</link>
		</links>
	</bug>
	<bug id="15278" opendate="2016-02-17 00:32:25" fixdate="2016-09-01 02:36:01" resolution="Fixed">
		<buginformation>
			<summary>AsyncRPCClient hangs if Connection closes before RPC call response </summary>
			<description>The test for HBASE-15212 discovered an issue with Async RPC Client. 
In that test, we are closing the connection if an RPC call writes a call larger than max allowed size, the server closes the connection. However the async client does not seem to handle connection closes with outstanding RPC calls. The client just hangs. 
Marking this blocker against 2.0 since it is default there. </description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.RpcServer.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.AbstractTestIPC.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.AsyncServerResponseHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.AsyncRpcChannel.java</file>
		</fixedFiles>
	</bug>
	<bug id="16527" opendate="2016-08-30 02:09:13" fixdate="2016-09-01 19:39:37" resolution="Fixed">
		<buginformation>
			<summary>IOExceptions from DFS client still can cause CatalogJanitor to delete referenced files</summary>
			<description>that was fixed partially in HBASE-13331, but issue still exists , now a little bit deeper in the code.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 0.98.22, 1.1.7, 1.2.4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.CatalogJanitor.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionFileSystem.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">13331</link>
		</links>
	</bug>
	<bug id="16375" opendate="2016-08-08 17:39:47" fixdate="2016-09-01 23:27:03" resolution="Fixed">
		<buginformation>
			<summary>Mapreduce mini cluster using HBaseTestingUtility not setting correct resourcemanager and jobhistory webapp address of MapReduceTestingShim  </summary>
			<description>Starting mapreduce mini cluster using HBaseTestingUtility is not setting "yarn.resourcemanager.webapp.address" and "mapreduce.jobhistory.webapp.address" which are required for getting the submitted yarn apps using mapreduce webapp. These properties are not being copied from jobConf of MapReduceTestingShim resulting in default values.

HBaseTestingUtility.java
    // Allow the user to override FS URI for this map-reduce cluster to use.
    mrCluster = new MiniMRCluster(servers,
      FS_URI != null ? FS_URI : FileSystem.get(conf).getUri().toString(), 1,
      null, null, new JobConf(this.conf));
    JobConf jobConf = MapreduceTestingShim.getJobConf(mrCluster);
    if (jobConf == null) 
Unknown macro: {
      jobConf = mrCluster.createJobConf();
    } 
    jobConf.set("mapreduce.cluster.local.dir",
      conf.get("mapreduce.cluster.local.dir")); //Hadoop MiniMR overwrites this while it should not
    LOG.info("Mini mapreduce cluster started");
    // In hadoop2, YARN/MR2 starts a mini cluster with its own conf instance and updates settings.
    // Our HBase MR jobs need several of these settings in order to properly run.  So we copy the
    // necessary config properties here.  YARN-129 required adding a few properties.
    conf.set("mapreduce.jobtracker.address", jobConf.get("mapreduce.jobtracker.address"));
    // this for mrv2 support; mr1 ignores this
    conf.set("mapreduce.framework.name", "yarn");
    conf.setBoolean("yarn.is.minicluster", true);
    String rmAddress = jobConf.get("yarn.resourcemanager.address");
    if (rmAddress != null) 
Unknown macro: {
      conf.set("yarn.resourcemanager.address", rmAddress);
    } 
    String historyAddress = jobConf.get("mapreduce.jobhistory.address");
    if (historyAddress != null) 
Unknown macro: {
      conf.set("mapreduce.jobhistory.address", historyAddress);
    } 
    String schedulerAddress =
      jobConf.get("yarn.resourcemanager.scheduler.address");
    if (schedulerAddress != null) 
Unknown macro: {
      conf.set("yarn.resourcemanager.scheduler.address", schedulerAddress);
    } 
As a immediate fix for phoenix e2e test to succeed, need the below lines to be added as well

    String rmWebappAddress = jobConf.get("yarn.resourcemanager.webapp.address");
    if (rmWebappAddress != null) 
Unknown macro: {
      conf.set("yarn.resourcemanager.webapp.address", rmWebappAddress);
    } 
    String historyWebappAddress = jobConf.get("mapreduce.jobhistory.webapp.address");
    if (historyWebappAddress != null) 
Unknown macro: {
      conf.set("mapreduce.jobhistory.webapp.address", historyWebappAddress);
    } 
Eventually, we should also see if we can copy over all the jobConf properties to HBaseTestingUtility conf object.</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.3.0, 0.98.22, 1.1.7, 1.2.4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.HBaseTestingUtility.java</file>
			<file type="M">org.apache.hadoop.hbase.TestHBaseTestingUtility.java</file>
		</fixedFiles>
	</bug>
	<bug id="16552" opendate="2016-09-02 14:23:55" fixdate="2016-09-03 00:03:40" resolution="Fixed">
		<buginformation>
			<summary>MiniHBaseCluster#getServerWith() does not ignore stopped RSs</summary>
			<description>MiniHBaseCluster#getServerWith() does not ignore stopped RSs </description>
			<version>0.98.21</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 0.98.22, 1.1.7, 1.2.4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.MiniHBaseCluster.java</file>
		</fixedFiles>
	</bug>
	<bug id="16460" opendate="2016-08-20 02:59:01" fixdate="2016-09-06 00:30:31" resolution="Fixed">
		<buginformation>
			<summary>Can&amp;apos;t rebuild the BucketAllocator&amp;apos;s data structures when BucketCache uses FileIOEngine</summary>
			<description>When bucket cache use FileIOEngine, it will rebuild the bucket allocator&amp;amp;apos;s data structures from a persisted map. So it should first read the map from persistence file then use the map to new a BucketAllocator. But now the code has wrong sequence in retrieveFromFile() method of BucketCache.java.


      BucketAllocator allocator = new BucketAllocator(cacheCapacity, bucketSizes, backingMap, realCacheSize);
      backingMap = (ConcurrentHashMap&amp;lt;BlockCacheKey, BucketEntry&amp;gt;) ois.readObject();

</description>
			<version>0.98.22</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.1.7, 1.2.4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.hfile.bucket.BucketCache.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.CacheTestUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocator.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.bucket.TestBucketCache.java</file>
		</fixedFiles>
	</bug>
	<bug id="16572" opendate="2016-09-07 14:16:49" fixdate="2016-09-07 19:50:53" resolution="Fixed">
		<buginformation>
			<summary>Sync method in RecoverableZooKeeper failed to pass callback function in</summary>
			<description>

public void sync(String path, AsyncCallback.VoidCallback cb, Object ctx) throws KeeperException {
    checkZk().sync(path, null, null); //callback function cb is not passed in
  }


It is obvious that the callback method is not passed in.  Since sync operation in Zookeeper is a &amp;amp;apos;async&amp;amp;apos; operation, we need a callback method to notify the caller that the &amp;amp;apos;sync&amp;amp;apos; operation is finished.</description>
			<version>1.1.4</version>
			<fixedVersion>2.0.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
		</fixedFiles>
	</bug>
	<bug id="16581" opendate="2016-09-08 04:11:56" fixdate="2016-09-08 17:04:56" resolution="Duplicate">
		<buginformation>
			<summary>Optimize Replication queue transfers after server fail over</summary>
			<description>Currently if a region server fails, the replication queue of this server will be picked up by another region server.  The problem is this queue can possibly be huge and contains queues from other multiple or cascading server failures.
We had such a case in production.  From zk_dump:


...
/hbase/replication/rs/r01data10-va-pub.xxx.ext,60020,1472680007498/1-r01data10-va-pub.xxx.ext,60020,1455993417125-r01data07-va-pub.xxx.ext,60020,1472680008225-r01data08-va-pub.xxx.ext,60020,1472680007318/r01data10-va-pub.xxx.ext%2C60020%2C1455993417125.1467603735059: 18748267

/hbase/replication/rs/r01data10-va-pub.xxx.ext,60020,1472680007498/1-r01data10-va-pub.xxx.ext,60020,1455993417125-r01data07-va-pub.xxx.ext,60020,1472680008225-r01data08-va-pub.xxx.ext,60020,1472680007318/r01data10-va-pub.xxx.ext%2C60020%2C1455993417125.1471723778060: 

/hbase/replication/rs/r01data10-va-pub.xxx.ext,60020,1472680007498/1-r01data10-va-pub.xxx.ext,60020,1455993417125-r01data07-va-pub.xxx.ext,60020,1472680008225-r01data08-va-pub.xxx.ext,60020,1472680007318/r01data10-va-pub.xxx.ext%2C60020%2C1455993417125.1468258960080: 

/hbase/replication/rs/r01data10-va-pub.xxx.ext,60020,1472680007498/1-r01data10-va-pub.xxx.ext,60020,1455993417125-r01data07-va-pub.xxx.ext,60020,1472680008225-r01data08-va-pub.xxx.ext,60020,1472680007318/r01data10-va-pub.xxx.ext%2C60020%2C1455993417125.1468204958990: 

/hbase/replication/rs/r01data10-va-pub.xxx.ext,60020,1472680007498/1-r01data10-va-pub.xxx.ext,60020,1455993417125-r01data07-va-pub.xxx.ext,60020,1472680008225-r01data08-va-pub.xxx.ext,60020,1472680007318/r01data10-va-pub.xxx.ext%2C60020%2C1455993417125.1469701010649: 

/hbase/replication/rs/r01data10-va-pub.xxx.ext,60020,1472680007498/1-r01data10-va-pub.xxx.ext,60020,1455993417125-r01data07-va-pub.xxx.ext,60020,1472680008225-r01data08-va-pub.xxx.ext,60020,1472680007318/r01data10-va-pub.xxx.ext%2C60020%2C1455993417125.1470409989238: 

/hbase/replication/rs/r01data10-va-pub.xxx.ext,60020,1472680007498/1-r01data10-va-pub.xxx.ext,60020,1455993417125-r01data07-va-pub.xxx.ext,60020,1472680008225-r01data08-va-pub.xxx.ext,60020,1472680007318/r01data10-va-pub.xxx.ext%2C60020%2C1455993417125.1471838985073: 

/hbase/replication/rs/r01data10-va-pub.xxx.ext,60020,1472680007498/1-r01data10-va-pub.xxx.ext,60020,1455993417125-r01data07-va-pub.xxx.ext,60020,1472680008225-r01data08-va-pub.xxx.ext,60020,1472680007318/r01data10-va-pub.xxx.ext%2C60020%2C1455993417125.1467142915090: 57804890

/hbase/replication/rs/r01data10-va-pub.xxx.ext,60020,1472680007498/1-r01data10-va-pub.xxx.ext,60020,1455993417125-r01data07-va-pub.xxx.ext,60020,1472680008225-r01data08-va-pub.xxx.ext,60020,1472680007318/r01data10-va-pub.xxx.ext%2C60020%2C1455993417125.1472181000614: 

/hbase/replication/rs/r01data10-va-pub.xxx.ext,60020,1472680007498/1-r01data10-va-pub.xxx.ext,60020,1455993417125-r01data07-va-pub.xxx.ext,60020,1472680008225-r01data08-va-pub.xxx.ext,60020,1472680007318/r01data10-va-pub.xxx.ext%2C60020%2C1455993417125.1471464567365: 

/hbase/replication/rs/r01data10-va-pub.xxx.ext,60020,1472680007498/1-r01data10-va-pub.xxx.ext,60020,1455993417125-r01data07-va-pub.xxx.ext,60020,1472680008225-r01data08-va-pub.xxx.ext,60020,1472680007318/r01data10-va-pub.xxx.ext%2C60020%2C1455993417125.1469486466965: 

/hbase/replication/rs/r01data10-va-pub.xxx.ext,60020,1472680007498/1-r01data10-va-pub.xxx.ext,60020,1455993417125-r01data07-va-pub.xxx.ext,60020,1472680008225-r01data08-va-pub.xxx.ext,60020,1472680007318/r01data10-va-pub.xxx.ext%2C60020%2C1455993417125.1467787339841: 47812951
...


There were hundreds of wals hanging under this queue, coming from diferent region servers, which took a long time to replicate.
We should have a better strategy which lets live region servers each grep part of this nested queue, and replicate in parallel.  </description>
			<version>1.4.0</version>
			<fixedVersion></fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.replication.TestReplicationStateBasic.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManagerZkImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.TableBasedReplicationQueuesImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.ReplicationQueuesZKImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.ReplicationQueues.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.TestReplicationSourceManager.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.TestReplicationStateHBaseImpl.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">12770</link>
		</links>
	</bug>
	<bug id="16309" opendate="2016-08-01 07:05:33" fixdate="2016-09-09 06:23:01" resolution="Fixed">
		<buginformation>
			<summary>TestDefaultCompactSelection.testCompactionRatio is flaky</summary>
			<description>The aged major compaction condition is not stable.
</description>
			<version>1.4.0</version>
			<fixedVersion>2.0.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestDefaultCompactSelection.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.compactions.RatioBasedCompactionPolicy.java</file>
		</fixedFiles>
	</bug>
	<bug id="16614" opendate="2016-09-12 08:30:30" fixdate="2016-09-12 14:06:30" resolution="Fixed">
		<buginformation>
			<summary>Use daemon thread for netty event loop</summary>
			<description>As always use daemon thread in rpc implementation.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.NettyRpcClient.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.DefaultNettyEventLoopConfig.java</file>
		</fixedFiles>
	</bug>
	<bug id="16609" opendate="2016-09-11 01:36:59" fixdate="2016-09-12 15:53:53" resolution="Fixed">
		<buginformation>
			<summary>Fake cells EmptyByteBufferedCell  created in read path not implementing SettableSequenceId </summary>
			<description>I backport offheap in 2.0 to hbase-1.1.2, and when testingI encounter a similar problem HBASE-15379 ,Here is the stack trace:

java.io.IOException: java.lang.UnsupportedOperationException: Cell is not of type org.apache.hadoop.hbase.SettableSequenceId
        at org.apache.hadoop.hbase.CellUtil.setSequenceId(CellUtil.java:915)
        at org.apache.hadoop.hbase.regionserver.StoreFileScanner.setCurrentCell(StoreFileScanner.java:203)
        at org.apache.hadoop.hbase.regionserver.StoreFileScanner.requestSeek(StoreFileScanner.java:338)
        at org.apache.hadoop.hbase.regionserver.KeyValueHeap.generalizedSeek(KeyValueHeap.java:321)
        at org.apache.hadoop.hbase.regionserver.KeyValueHeap.requestSeek(KeyValueHeap.java:279)
        at org.apache.hadoop.hbase.regionserver.StoreScanner.reseek(StoreScanner.java:821)
        at org.apache.hadoop.hbase.regionserver.StoreScanner.seekAsDirection(StoreScanner.java:809)
        at org.apache.hadoop.hbase.regionserver.StoreScanner.next(StoreScanner.java:636)
        at org.apache.hadoop.hbase.regionserver.KeyValueHeap.next(KeyValueHeap.java:153)
        at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.populateResult(HRegion.java:5611)
        at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.nextInternal(HRegion.java:5750)
        at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.nextRaw(HRegion.java:5551)
        at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.next(HRegion.java:5528)
        at org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.next(HRegion.java:5515)
        at org.apache.hadoop.hbase.regionserver.RSRpcServices.get(RSRpcServices.java:2125)
        at org.apache.hadoop.hbase.regionserver.RSRpcServices.get(RSRpcServices.java:2068)
        at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:32201
)
        at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:790)
        at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:102)
        at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:133)
        at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)


this will occur in read path when offheap is used. mostly due to ByteBuffer backed Cells dont implement interface SettableSequenceId. </description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.CellUtil.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">11425</link>
		</links>
	</bug>
	<bug id="16615" opendate="2016-09-12 12:14:29" fixdate="2016-09-13 10:39:00" resolution="Fixed">
		<buginformation>
			<summary>Fix flaky TestScannerHeartbeatMessages</summary>
			<description></description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestScannerHeartbeatMessages.java</file>
		</fixedFiles>
	</bug>
	<bug id="15297" opendate="2016-02-20 04:07:36" fixdate="2016-09-13 13:05:52" resolution="Fixed">
		<buginformation>
			<summary>error message is wrong when a wrong namspace is specified in grant in hbase shell</summary>
			<description>In HBase shell, specify a non-existing namespace in "grant" command, such as


hbase(main):001:0&amp;gt; grant &amp;amp;apos;a1&amp;amp;apos;, &amp;amp;apos;R&amp;amp;apos;, &amp;amp;apos;@aaa&amp;amp;apos;    &amp;lt;--- there is no namespace called "aaa"


The error message issued is not correct


ERROR: Unknown namespace a1!


a1 is the user name, not the namespace.
The following error message would be better


ERROR: Unknown namespace aaa!


or


Can&amp;amp;apos;t find a namespace: aaa

</description>
			<version>1.2.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
			<file type="M">org.apache.hadoop.hbase.client.Admin.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">14254</link>
		</links>
	</bug>
	<bug id="16612" opendate="2016-09-12 06:53:33" fixdate="2016-09-13 19:45:29" resolution="Fixed">
		<buginformation>
			<summary>Use array to cache Types for KeyValue.Type.codeToType</summary>
			<description>We don&amp;amp;apos;t rely on enum ordinals in KeyValye.Type. We have own code in it. In codeToType, we use a loop to find the Type which is not a good idea. We can just use an arryay[256] to cache all types.</description>
			<version>0.98.22</version>
			<fixedVersion>2.0.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.KeyValue.java</file>
		</fixedFiles>
	</bug>
	<bug id="16624" opendate="2016-09-13 05:58:48" fixdate="2016-09-15 18:06:03" resolution="Fixed">
		<buginformation>
			<summary>MVCC DeSerialization bug in the HFileScannerImpl</summary>
			<description>My colleague Nitin Aggarwal found a bug in the deserialization of mvcc from HFile, As a part of the optimization of deserialization of VLong, we read a int at once but we forgot to convert it to unsigned one. 
This would cause issues because once we cross the integer threshold in sequenceId and a compaction happens we would write MAX_MEMSTORE_TS in the trailer as 0 (because we will be reading negative values from the file that got flushed with sequenceId &amp;gt; Integer.MAX_VALUE). And once we have MAX_MEMSTORE_TS as 0, and there are sequenceId values present alongside with KeyValues the regionserver will now start failing to read the compacted file and thus corruption. 
Interestingly this would happen only on the tables that don&amp;amp;apos;t have  DataBlockEncoding enabled and unfortunately in our case that turned out to be META and a another small table.
Fix is small (~20 chars) and attached</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFileReaderImpl.java</file>
		</fixedFiles>
	</bug>
	<bug id="16165" opendate="2016-07-01 09:53:54" fixdate="2016-09-18 02:34:13" resolution="Fixed">
		<buginformation>
			<summary>Decrease RpcServer.callQueueSize before writeResponse causes OOM</summary>
			<description>In RpcServer, we use callQueueSizeInBytes to avoid queuing too many calls which causes OOM. But in CallRunner.run, we decrease it before send the response back. And even after calling sendResponseIfReady, the call object could stay in our heap for a long time if we can not write out the response(That&amp;amp;apos;s why we need a Responder thread...). This makes it possible that the actual size of all call object in heap is larger than maxQueueSizeInBytes and causes OOM.</description>
			<version>0.98.22</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.1.7, 0.98.23, 1.2.4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.RpcServer.java</file>
		</fixedFiles>
	</bug>
	<bug id="16551" opendate="2016-09-02 05:58:52" fixdate="2016-09-20 17:36:46" resolution="Fixed">
		<buginformation>
			<summary>Cleanup SplitLogManager and CatalogJanitor</summary>
			<description>couple of cleanups around SplitLogManager and CatalogJanitor:
replace all copy-pasted cast in SplitLogManager with one call to an helper method
remove Server, MasterServices, Stoppable since we call the class in only one place and is called as master, master, master
reuse MockNoopMasterServices instead of creating the Server/MasterServices classes</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.MasterWalManager.java</file>
			<file type="M">org.apache.hadoop.hbase.coordination.ZKSplitLogManagerCoordination.java</file>
			<file type="M">org.apache.hadoop.hbase.master.CatalogJanitor.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestSplitLogManager.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="M">org.apache.hadoop.hbase.coordination.SplitLogManagerCoordination.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
			<file type="M">org.apache.hadoop.hbase.master.SplitLogManager.java</file>
		</fixedFiles>
	</bug>
	<bug id="16654" opendate="2016-09-19 12:22:27" fixdate="2016-09-21 14:38:57" resolution="Fixed">
		<buginformation>
			<summary>Better handle channelInactive and close for netty rpc client</summary>
			<description>We should pass the event to the next handler in the pipeline as channelInactive and close are usually used as the cleanup method of a ChannelHandler.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.NettyRpcConnection.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.BufferCallBeforeInitHandler.java</file>
			<file type="D">org.apache.hadoop.hbase.security.AsyncHBaseSaslRpcClient.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.java</file>
			<file type="D">org.apache.hadoop.hbase.security.AsyncHBaseSaslRpcClientHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.security.SaslWrapHandler.java</file>
			<file type="M">org.apache.hadoop.hbase.security.SaslUnwrapHandler.java</file>
		</fixedFiles>
	</bug>
	<bug id="16294" opendate="2016-07-27 21:02:50" fixdate="2016-09-21 21:45:21" resolution="Fixed">
		<buginformation>
			<summary>hbck reporting "No HDFS region dir found" for replicas</summary>
			<description>simple test, create a table with replicas and then run hbck. 
we don&amp;amp;apos;t filter out the replicas for the loadHdfsRegioninfo()

$ hbase shell
hbase(main):001:0&amp;gt; create &amp;amp;apos;myTable&amp;amp;apos;, &amp;amp;apos;myCF&amp;amp;apos;, {REGION_REPLICATION =&amp;gt; &amp;amp;apos;3&amp;amp;apos;}

$ hbase hbck
2016-07-27 13:47:38,090 WARN  [hbasefsck-pool1-t2] util.HBaseFsck: No HDFS region dir found: { meta =&amp;gt; myTable,,1469652448440_0002.9dea3506e09e00910158dc91fa21e550., hdfs =&amp;gt; null, deployed =&amp;gt; u1604srv,42895,1469652420413;myTable,,1469652448440_0002.9dea3506e09e00910158dc91fa21e550., replicaId =&amp;gt; 2 } meta={ENCODED =&amp;gt; 9dea3506e09e00910158dc91fa21e550, NAME =&amp;gt; &amp;amp;apos;myTable,,1469652448440_0002.9dea3506e09e00910158dc91fa21e550.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;&amp;amp;apos;, REPLICA_ID =&amp;gt; 2}
2016-07-27 13:47:38,092 WARN  [hbasefsck-pool1-t1] util.HBaseFsck: No HDFS region dir found: { meta =&amp;gt; myTable,,1469652448440_0001.a03250bca30781ff7002a91c281b4e92., hdfs =&amp;gt; null, deployed =&amp;gt; u1604srv,42895,1469652420413;myTable,,1469652448440_0001.a03250bca30781ff7002a91c281b4e92., replicaId =&amp;gt; 1 } meta={ENCODED =&amp;gt; a03250bca30781ff7002a91c281b4e92, NAME =&amp;gt; &amp;amp;apos;myTable,,1469652448440_0001.a03250bca30781ff7002a91c281b4e92.&amp;amp;apos;, STARTKEY =&amp;gt; &amp;amp;apos;&amp;amp;apos;, ENDKEY =&amp;gt; &amp;amp;apos;&amp;amp;apos;, REPLICA_ID =&amp;gt; 1}

</description>
			<version>1.0.3</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.1.7, 1.2.4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.HBaseFsck.java</file>
		</fixedFiles>
	</bug>
	<bug id="16669" opendate="2016-09-21 19:26:18" fixdate="2016-09-22 03:45:53" resolution="Fixed">
		<buginformation>
			<summary>fix flaky TestAdmin#testmergeRegions</summary>
			<description>Recent test runs show that this test is failing with these error messages:


java.lang.AssertionError: expected:&amp;lt;2&amp;gt; but was:&amp;lt;3&amp;gt;
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.junit.Assert.assertEquals(Assert.java:631)
	at org.apache.hadoop.hbase.client.TestAdmin1.testMergeRegions(TestAdmin1.java:1385)


or 


java.lang.AssertionError: expected:&amp;lt;1&amp;gt; but was:&amp;lt;2&amp;gt;
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.junit.Assert.assertEquals(Assert.java:631)
	at org.apache.hadoop.hbase.client.TestAdmin1.testMergeRegions(TestAdmin1.java:1394)


looking at the code this indicates that merge operation did not complete or didn&amp;amp;apos;t work.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.TestAdmin1.java</file>
		</fixedFiles>
	</bug>
	<bug id="16676" opendate="2016-09-22 00:05:54" fixdate="2016-09-22 22:04:51" resolution="Duplicate">
		<buginformation>
			<summary>All RPC requests serviced by PriorityRpcServer in some deploys after HBASE-13375</summary>
			<description>I have been trying to track down why 1.2.x won&amp;amp;apos;t sometimes pass a 1 billion row ITBLL run while 0.98.22 and 1.1.6 will always, and a defeat of RPC prioritization could explain it. We get stuck during the loading phase and the loader job eventually fails. 
All testing is done in an insecure environment under the same UNIX user (clusterdock) so effectively all ops are issued by the superuser.
Doing unrelated work - or so I thought! - I was looking at object allocations by YCSB workload by thread and when looking at the RegionServer RPC threads noticed that for 0.98.22 and 1.1.6, as expected, the vast majority of allocations are from threads named "B.defaultRpcServer.handler*". In 1.2.0 and up, instead the vast majority are from threads named "PriorityRpcServer.handler*" with very little from threads named "B.defaultRpcServer.handler*".  A git bisect to find the change that causes this leads to HBASE-13375, and so of course this makes sense out of what I am seeing, but is this really what we want? What about production environments (insecure and degenerate secure) where all ops are effectively issued by the superuser? We run one of these at Salesforce.</description>
			<version>1.2.0</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.AnnotationReadingPriorityFunction.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestPriorityRpc.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">15315</link>
			<link type="Reference" description="is related to">13375</link>
			<link type="Reference" description="is related to">15315</link>
		</links>
	</bug>
	<bug id="16697" opendate="2016-09-23 15:53:19" fixdate="2016-09-23 23:01:13" resolution="Fixed">
		<buginformation>
			<summary>bump TestRegionServerMetrics to LargeTests</summary>
			<description>TestRegionServerMetrics keeps failing because it exceed the MediumTests time limit. bump it to Large</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestRegionServerMetrics.java</file>
		</fixedFiles>
	</bug>
	<bug id="16645" opendate="2016-09-16 17:02:01" fixdate="2016-09-25 13:43:18" resolution="Fixed">
		<buginformation>
			<summary>Wrong range of Cells is caused by CellFlatMap#tailMap, headMap, and SubMap</summary>
			<description>Two reasons are shown below:
1) CellFlatMap#find doesnt consider desc order array
2) CellFlatMap#getValidIndex return the wrong upper bound</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.CellSet.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestCellFlatSet.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.CellFlatMap.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">14921</link>
		</links>
	</bug>
	<bug id="16704" opendate="2016-09-25 02:05:07" fixdate="2016-09-26 17:03:26" resolution="Fixed">
		<buginformation>
			<summary>Scan will be broken while working with DBE and KeyValueCodecWithTags</summary>
			<description>scan will always broken if we set LIMIT more than 1 with rs  hbase.client.rpc.codec set to org.apache.hadoop.hbase.codec.KeyValueCodecWithTags.
How to reproduce:
1. 1 master + 1 rs, codec use KeyValueCodecWithTags.
2.  create a table table_1024B_30g1 cf and with only 1 qualifier, then load some data with ycsb.  Use Diff DataBlockEncoding
3. scan &amp;amp;apos;table_1024B_30g&amp;amp;apos;, 
{LIMIT =&amp;gt; 2, STARTROW =&amp;gt; &amp;amp;apos;user5499&amp;amp;apos;}
, STARTROW  is set any valid start row.
4. scan failed.
this should be bug in KeyValueCodecWithTags, after some investigations, I found some the key not serialized correctly.
</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.encoding.TestBufferedDataBlockEncoder.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFileReaderImpl.java</file>
			<file type="M">org.apache.hadoop.hbase.CellUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.io.encoding.BufferedDataBlockEncoder.java</file>
		</fixedFiles>
		<links>
			<link type="Regression" description="is broken by">13754</link>
		</links>
	</bug>
	<bug id="16649" opendate="2016-09-18 15:22:15" fixdate="2016-09-26 20:51:42" resolution="Fixed">
		<buginformation>
			<summary>Truncate table with splits preserved can cause both data loss and truncated data appeared again</summary>
			<description>Since truncate table with splits preserved will delete hfiles and use the previous regioninfo. It can cause odd behaviors

Case 1: Data appeared after truncate
reproduce procedure
1. create a table, let&amp;amp;apos;s say &amp;amp;apos;test&amp;amp;apos;
2. write data to &amp;amp;apos;test&amp;amp;apos;, make sure memstore of &amp;amp;apos;test&amp;amp;apos; is not empty
3. truncate &amp;amp;apos;test&amp;amp;apos; with splits preserved
4. kill the regionserver hosting the region(s) of &amp;amp;apos;test&amp;amp;apos;
5. start the regionserver, now it is the time to witness the miracle! the truncated data appeared in table &amp;amp;apos;test&amp;amp;apos;


Case 2: Data loss
reproduce procedure:
1. create a table, let&amp;amp;apos;s say &amp;amp;apos;test&amp;amp;apos;
2. write some data to &amp;amp;apos;test&amp;amp;apos;, no matter how many
3. truncate &amp;amp;apos;test&amp;amp;apos; with splits preserved
4. restart the regionserver to reset the seqid
5. write some data, but less than 2 since we don&amp;amp;apos;t want the seqid to run over the one in 2
6. kill the regionserver hosting the region(s) of &amp;amp;apos;test&amp;amp;apos;
7. restart the regionserver. Congratulations! the data writen in 4 is now all lost

Why?
for case 1
Since preserve splits in truncate table procedure will not change the regioninfo, when log replay happens, the &amp;amp;apos;unflushed&amp;amp;apos; data will restore back to the region
for case 2
since the flushedSequenceIdByRegion are stored in Master in a map with the region&amp;amp;apos;s encodedName. Although the table is truncated, the region&amp;amp;apos;s name is not changed since we chose to preserve the splits. So after truncate the table, the region&amp;amp;apos;s sequenceid is reset in the regionserver, but not reset in master. When flush comes and report to master, master will reject the update of sequenceid since the new one is smaller than the old one. The same happens in log replay, all the edits writen in 4 will be skipped since they have a smaller seqid</description>
			<version>1.1.3</version>
			<fixedVersion>2.0.0, 1.3.0, 1.1.7, 0.98.23, 1.2.4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.procedure.TruncateTableProcedure.java</file>
			<file type="M">org.apache.hadoop.hbase.master.procedure.TestTruncateTableProcedure.java</file>
			<file type="M">org.apache.hadoop.hbase.master.CatalogJanitor.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestCatalogJanitor.java</file>
			<file type="M">org.apache.hadoop.hbase.master.procedure.DeleteTableProcedure.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ServerManager.java</file>
		</fixedFiles>
	</bug>
	<bug id="16660" opendate="2016-09-20 13:00:25" fixdate="2016-09-27 18:17:27" resolution="Fixed">
		<buginformation>
			<summary>ArrayIndexOutOfBounds during the majorCompactionCheck in DateTieredCompaction</summary>
			<description>We get an ArrayIndexOutOfBoundsException during the major compaction check as follows

2016-09-19 05:04:18,287 ERROR [20.compactionChecker] regionserver.HRegionServer$CompactionChecker - Caught exception
java.lang.ArrayIndexOutOfBoundsException: -2
        at org.apache.hadoop.hbase.regionserver.compactions.DateTieredCompactionPolicy.shouldPerformMajorCompaction(DateTieredCompactionPolicy.java:159)
        at org.apache.hadoop.hbase.regionserver.HStore.isMajorCompaction(HStore.java:1412)
        at org.apache.hadoop.hbase.regionserver.HRegionServer$CompactionChecker.chore(HRegionServer.java:1532)
        at org.apache.hadoop.hbase.Chore.run(Chore.java:80)
        at java.lang.Thread.run(Thread.java:745)


This happens due to the following lines in org.apache.hadoop.hbase.regionserver.compactions.DateTieredCompactionPolicy.selectMajorCompaction

int lowerWindowIndex = Collections.binarySearch(boundaries,
        minTimestamp == null ? Long.MAX_VALUE : file.getMinimumTimestamp());
      int upperWindowIndex = Collections.binarySearch(boundaries,
        file.getMaximumTimestamp() == null ? Long.MAX_VALUE : file.getMaximumTimestamp());


These return negative values if the element is not found and in the case the values are equal we get the exception.</description>
			<version>0.98.20</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 0.98.23</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestDateTieredCompactionPolicy.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.compactions.DateTieredCompactionPolicy.java</file>
		</fixedFiles>
	</bug>
	<bug id="16711" opendate="2016-09-26 23:06:13" fixdate="2016-09-28 20:12:57" resolution="Fixed">
		<buginformation>
			<summary>Fix hadoop-3.0 profile compile</summary>
			<description>The -Dhadoop.profile=3.0 build is failing currently due to code deprecated in hadoop2 and removed in hadoop3.
</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			<file type="M">org.apache.hadoop.hbase.http.HttpServer.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestBulkLoad.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.IncrementCoalescer.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">6581</link>
		</links>
	</bug>
	<bug id="16723" opendate="2016-09-28 10:52:38" fixdate="2016-09-29 13:53:05" resolution="Fixed">
		<buginformation>
			<summary>RMI registry is not destroyed after stopping JMX Connector Server</summary>
			<description>We are creating RMI registry in JMXListener.startConnectorServer() ,


    // Create the RMI registry
    LocateRegistry.createRegistry(rmiRegistryPort);


This registry is never deregistered, should be destoyed after stopping JMX Connector server.</description>
			<version>0.98.22</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.2.4, 0.98.24</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.JMXListener.java</file>
		</fixedFiles>
		<links>
			<link type="Dependent" description="Dependent">16663</link>
		</links>
	</bug>
	<bug id="16739" opendate="2016-09-30 18:07:48" fixdate="2016-10-03 13:47:30" resolution="Fixed">
		<buginformation>
			<summary>Timed out exception message should include encoded region name</summary>
			<description>Saw the following in region server log repeatedly:


2016-09-26 10:13:33,219 WARN org.apache.hadoop.hbase.regionserver.HRegion: Failed getting lock in batch put, row=1
java.io.IOException: Timed out waiting for lock for row: 1
  at org.apache.hadoop.hbase.regionserver.HRegion.getRowLockInternal(HRegion.java:5151)
  at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutation(HRegion.java:3046)
  at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2902)
  at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2844)
  at org.apache.hadoop.hbase.regionserver.RSRpcServices.doBatchOp(RSRpcServices.java:692)
  at org.apache.hadoop.hbase.regionserver.RSRpcServices.doNonAtomicRegionMutation(RSRpcServices.java:654)
  at org.apache.hadoop.hbase.regionserver.RSRpcServices.multi(RSRpcServices.java:2040)


Region name was not logged - making troubleshooting a bit difficult.</description>
			<version>1.4.0</version>
			<fixedVersion>2.0.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
		</fixedFiles>
	</bug>
	<bug id="16644" opendate="2016-09-16 09:12:18" fixdate="2016-10-05 04:32:32" resolution="Fixed">
		<buginformation>
			<summary>Errors when reading legit HFile Trailer of old (v2.0) format file</summary>
			<description>There seems to be a regression in branch 1.3 where we can&amp;amp;apos;t read HFile trailer(getting "CorruptHFileException: Problem reading HFile Trailer") on some HFiles that could be successfully read on 1.2.
I&amp;amp;apos;ve seen this error manifesting in two ways so far.

Caused by: org.apache.hadoop.hbase.io.hfile.CorruptHFileException: Problem reading HFile Trailer from file  &amp;lt;file name&amp;gt;
	at org.apache.hadoop.hbase.io.hfile.HFile.pickReaderVersion(HFile.java:497)
	at org.apache.hadoop.hbase.io.hfile.HFile.createReader(HFile.java:525)
	at org.apache.hadoop.hbase.regionserver.StoreFile$Reader.&amp;lt;init&amp;gt;(StoreFile.java:1164)
	at org.apache.hadoop.hbase.regionserver.StoreFileInfo.open(StoreFileInfo.java:259)
	at org.apache.hadoop.hbase.regionserver.StoreFile.open(StoreFile.java:427)
	at org.apache.hadoop.hbase.regionserver.StoreFile.createReader(StoreFile.java:528)
	at org.apache.hadoop.hbase.regionserver.StoreFile.createReader(StoreFile.java:518)
	at org.apache.hadoop.hbase.regionserver.HStore.createStoreFileAndReader(HStore.java:652)
	at org.apache.hadoop.hbase.regionserver.HStore.access$000(HStore.java:117)
	at org.apache.hadoop.hbase.regionserver.HStore$1.call(HStore.java:519)
	at org.apache.hadoop.hbase.regionserver.HStore$1.call(HStore.java:516)
	... 6 more
Caused by: java.io.IOException: Invalid HFile block magic: \x00\x00\x04\x00\x00\x00\x00\x00
	at org.apache.hadoop.hbase.io.hfile.BlockType.parse(BlockType.java:155)
	at org.apache.hadoop.hbase.io.hfile.BlockType.read(BlockType.java:167)
	at org.apache.hadoop.hbase.io.hfile.HFileBlock.&amp;lt;init&amp;gt;(HFileBlock.java:344)
	at org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderImpl.readBlockDataInternal(HFileBlock.java:1735)
	at org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderImpl.readBlockData(HFileBlock.java:1558)
	at org.apache.hadoop.hbase.io.hfile.HFileBlock$AbstractFSReader$1.nextBlock(HFileBlock.java:1397)
	at org.apache.hadoop.hbase.io.hfile.HFileBlock$AbstractFSReader$1.nextBlockWithBlockType(HFileBlock.java:1405)
	at org.apache.hadoop.hbase.io.hfile.HFileReaderV2.&amp;lt;init&amp;gt;(HFileReaderV2.java:156)
	at org.apache.hadoop.hbase.io.hfile.HFile.pickReaderVersion(HFile.java:485)


and second


Caused by: org.apache.hadoop.hbase.io.hfile.CorruptHFileException: Problem reading HFile Trailer from file &amp;lt;file path&amp;gt;
	at org.apache.hadoop.hbase.io.hfile.HFile.pickReaderVersion(HFile.java:497)
	at org.apache.hadoop.hbase.io.hfile.HFile.createReader(HFile.java:525)
	at org.apache.hadoop.hbase.regionserver.StoreFile$Reader.&amp;lt;init&amp;gt;(StoreFile.java:1164)
	at org.apache.hadoop.hbase.io.HalfStoreFileReader.&amp;lt;init&amp;gt;(HalfStoreFileReader.java:104)
	at org.apache.hadoop.hbase.regionserver.StoreFileInfo.open(StoreFileInfo.java:256)
	at org.apache.hadoop.hbase.regionserver.StoreFile.open(StoreFile.java:427)
	at org.apache.hadoop.hbase.regionserver.StoreFile.createReader(StoreFile.java:528)
	at org.apache.hadoop.hbase.regionserver.StoreFile.createReader(StoreFile.java:518)
	at org.apache.hadoop.hbase.regionserver.HStore.createStoreFileAndReader(HStore.java:652)
	at org.apache.hadoop.hbase.regionserver.HStore.access$000(HStore.java:117)
	at org.apache.hadoop.hbase.regionserver.HStore$1.call(HStore.java:519)
	at org.apache.hadoop.hbase.regionserver.HStore$1.call(HStore.java:516)
	... 6 more
Caused by: java.io.IOException: Premature EOF from inputStream (read returned -1, was trying to read 10083 necessary bytes and 24 extra bytes, successfully read 1072
	at org.apache.hadoop.hbase.io.hfile.HFileBlock.readWithExtra(HFileBlock.java:737)
	at org.apache.hadoop.hbase.io.hfile.HFileBlock$AbstractFSReader.readAtOffset(HFileBlock.java:1459)
	at org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderImpl.readBlockDataInternal(HFileBlock.java:1712)
	at org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderImpl.readBlockData(HFileBlock.java:1558)
	at org.apache.hadoop.hbase.io.hfile.HFileBlock$AbstractFSReader$1.nextBlock(HFileBlock.java:1397)
	at org.apache.hadoop.hbase.io.hfile.HFileBlock$AbstractFSReader$1.nextBlockWithBlockType(HFileBlock.java:1405)
	at org.apache.hadoop.hbase.io.hfile.HFileReaderV2.&amp;lt;init&amp;gt;(HFileReaderV2.java:156)
	at org.apache.hadoop.hbase.io.hfile.HFile.pickReaderVersion(HFile.java:485)


In my case this problem was reproducible by running `hbase hfile -m  -f` command. There seem to be two changes in behavior introduced by HBASE-15477 (cc stack).
One is that HFileBlock#getOnDiskSizeWithHeader always assumes that checksum verification is true (this behavior results in onDiskSizeWithHeader being calculated differently in 1.2 and 1.3 for some cases).
Second is that in HFileBlock constructor we always attempt to retrive checksum-related fields from the header even if no checksum verification is going on.
Attached is the patch which when applied allows 1.3 to read again the same HFiles.</description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFileBlock.java</file>
		</fixedFiles>
	</bug>
	<bug id="16117" opendate="2016-06-26 23:50:51" fixdate="2016-10-08 00:33:35" resolution="Fixed">
		<buginformation>
			<summary>Fix Connection leak in mapred.TableOutputFormat </summary>
			<description>Spark seems to instantiate multiple instances of output formats within a single process.  When mapred.TableOutputFormat (not mapreduce.TableOutputFormat) is used, this may cause connection leaks that slowly exhaust the cluster&amp;amp;apos;s zk connections.  
This patch fixes that.</description>
			<version>1.1.6</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.TestClientTimeouts.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ConnectionImplementation.java</file>
			<file type="M">org.apache.hadoop.hbase.client.Registry.java</file>
			<file type="M">org.apache.hadoop.hbase.mapred.TableOutputFormat.java</file>
			<file type="M">org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ZooKeeperRegistry.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">16017</link>
			<link type="Reference" description="is related to">16774</link>
		</links>
	</bug>
	<bug id="16767" opendate="2016-10-05 00:29:40" fixdate="2016-10-08 00:50:13" resolution="Fixed">
		<buginformation>
			<summary>Mob compaction needs to clean up files in /hbase/mobdir/.tmp and /hbase/mobdir/.tmp/.bulkload when running into IO exceptions </summary>
			<description>For the following lines, when it runs into IOException, it does not clean up the files under /hbase/mobdir/.tmp and /hbase/mobdir/.tmp/.bulkload. 
It could be due to creating of new mob file or new reference file under .bulkload directory fails. Or when mob files from ./tmp to the mob region directory fails.
https://github.com/apache/hbase/blob/master/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/compactions/PartitionedMobCompactor.java#L433
https://github.com/apache/hbase/blob/master/hbase-server/src/main/java/org/apache/hadoop/hbase/mob/compactions/PartitionedMobCompactor.java#L433</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mob.compactions.TestPartitionedMobCompactor.java</file>
			<file type="M">org.apache.hadoop.hbase.mob.compactions.PartitionedMobCompactor.java</file>
		</fixedFiles>
	</bug>
	<bug id="16699" opendate="2016-09-23 21:02:48" fixdate="2016-10-10 21:34:14" resolution="Fixed">
		<buginformation>
			<summary>Overflows in AverageIntervalRateLimiter&amp;apos;s refill() and getWaitInterval()</summary>
			<description>It seems that there are more overflow in other places, and a concurrent issue.
I will post a patch within one or 2 days after I figure out adding new unittest cases.
Please see the following two lines. Once it overflows, it will cause wrong behavior. For unconfigured RateLimiters, we should have simpler logic to byPass the check. 
https://github.com/apache/hbase/blob/master/hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/AverageIntervalRateLimiter.java#L37
https://github.com/apache/hbase/blob/master/hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/AverageIntervalRateLimiter.java#L51</description>
			<version>1.4.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.2.4, 1.1.8</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.quotas.OperationQuota.java</file>
			<file type="M">org.apache.hadoop.hbase.quotas.RateLimiter.java</file>
			<file type="M">org.apache.hadoop.hbase.quotas.TimeBasedLimiter.java</file>
			<file type="M">org.apache.hadoop.hbase.quotas.QuotaLimiter.java</file>
			<file type="M">org.apache.hadoop.hbase.quotas.TestRateLimiter.java</file>
			<file type="M">org.apache.hadoop.hbase.quotas.AverageIntervalRateLimiter.java</file>
			<file type="M">org.apache.hadoop.hbase.quotas.DefaultOperationQuota.java</file>
			<file type="M">org.apache.hadoop.hbase.quotas.NoopOperationQuota.java</file>
			<file type="M">org.apache.hadoop.hbase.quotas.NoopQuotaLimiter.java</file>
		</fixedFiles>
	</bug>
	<bug id="16788" opendate="2016-10-06 23:14:38" fixdate="2016-10-10 23:15:48" resolution="Fixed">
		<buginformation>
			<summary>Race in compacted file deletion between HStore close() and closeAndArchiveCompactedFiles()</summary>
			<description>HBASE-13082 changed the way that compacted files are archived from being done inline on compaction completion to an async cleanup by the CompactedHFilesDischarger chore.  It looks like the changes to HStore to support this introduced a race condition in the compacted HFile archiving.
In the following sequence, we can wind up with two separate threads trying to archive the same HFiles, causing a regionserver abort:

compaction completes normally and the compacted files are added to compactedfiles in HStore&amp;amp;apos;s DefaultStoreFileManager
threadA: CompactedHFilesDischargeHandler runs in a RS executor service, calling closeAndArchiveCompactedFiles()
	
obtains HStore readlock
gets a copy of compactedfiles
releases readlock


threadB: calls HStore.close() as part of region close
	
obtains HStore writelock
calls DefaultStoreFileManager.clearCompactedfiles(), getting a copy of same compactedfiles


threadA: calls HStore.removeCompactedfiles(compactedfiles)
	
archives files in 
{compactedfiles}
 in HRegionFileSystem.removeStoreFiles()
call HStore.clearCompactedFiles()
waits on write lock


threadB: continues with close()
	
calls removeCompactedfiles(compactedfiles)
calls HRegionFIleSystem.removeStoreFiles() -&amp;gt; HFileArchiver.archiveStoreFiles()
receives FileNotFoundException because the files have already been archived by threadA
throws IOException


RS aborts

I think the combination of fetching the compactedfiles list and removing the files needs to be covered by locking.  Options I see are:

Modify HStore.closeAndArchiveCompactedFiles(): use writelock instead of readlock and move the call to removeCompactedfiles() inside the lock.  This means the read operations will be blocked while the files are being archived, which is bad.
Synchronize closeAndArchiveCompactedFiles() and modify close() to call it instead of calling removeCompactedfiles() directly
Add a separate lock for compacted files removal and use in closeAndArchiveCompactedFiles() and close()

</description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
		</fixedFiles>
	</bug>
	<bug id="15109" opendate="2016-01-14 15:32:04" fixdate="2016-10-11 22:44:32" resolution="Fixed">
		<buginformation>
			<summary>HM/RS failed to start when "fs.hdfs.impl.disable.cache" is set to true</summary>
			<description>HMaster failed to start during installing ShutdownHook when "fs.hdfs.impl.disable.cache" is set to true.

2016-10-10 10:33:28,367 FATAL [master/HOST-10-18-106-146/10.18.106.146:16000] master.HMaster: Unhandled: Failed suppression of fs shutdown hook: org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer@19a003b4
java.lang.RuntimeException: Failed suppression of fs shutdown hook: org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer@19a003b4
        at org.apache.hadoop.hbase.regionserver.ShutdownHook.suppressHdfsShutdownHook(ShutdownHook.java:204)
        at org.apache.hadoop.hbase.regionserver.ShutdownHook.install(ShutdownHook.java:84)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:950)
        at java.lang.Thread.run(Thread.java:745)


And RegionServer is in blocking state until a master is available,

"regionserver/HOST-10-18-106-146/10.18.106.146:16020" #17 prio=5 os_prio=0 tid=0x0000000000e4e800 nid=0xdc38 in Object.wait() [0x00007f329dac6000]
   java.lang.Thread.State: TIMED_WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hbase.zookeeper.ZooKeeperNodeTracker.blockUntilAvailable(ZooKeeperNodeTracker.java:159)
        - locked &amp;lt;0x00000000ae25c0c8&amp;gt; (a org.apache.hadoop.hbase.zookeeper.MasterAddressTracker)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.blockAndCheckIfStopped(HRegionServer.java:870)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.initializeZooKeeper(HRegionServer.java:809)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.preRegistrationInitialization(HRegionServer.java:783)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:943)
        at java.lang.Thread.run(Thread.java:745)


During installation, first time it will try to suppress the HDFS shutdownhook by removing the hdfsclientfinalizer from HDFS. Since fs.hdfs.impl.disable.cache is enabled, so removal will be unsuccessful from HDFS  (FS is not cached) and RuntimeException will be thrown with "Failed suppression of fs shutdown hook" message.
In ShutdownHook,


if (!fsShutdownHooks.containsKey(hdfsClientFinalizer) &amp;amp;&amp;amp;
!ShutdownHookManager.deleteShutdownHook(hdfsClientFinalizer)) {
throw new RuntimeException("Failed suppression of fs shutdown hook: " +
hdfsClientFinalizer);
}


</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.ShutdownHook.java</file>
		</fixedFiles>
	</bug>
	<bug id="16801" opendate="2016-10-10 19:37:34" fixdate="2016-10-12 17:07:52" resolution="Fixed">
		<buginformation>
			<summary>The Append/Increment may return the data from future</summary>
			<description>OperationContext maintains the mvcc as a static member, so any Appends and Increments read point will be changed by others. That is, a retrying Append/Increment may see the future data.
This is a master only issue.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.ServerNonceManager.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestServerNonceManager.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">9899</link>
		</links>
	</bug>
	<bug id="16731" opendate="2016-09-29 10:06:59" fixdate="2016-10-12 19:14:22" resolution="Fixed">
		<buginformation>
			<summary>Inconsistent results from the Get/Scan if we use the empty FilterList</summary>
			<description>RSRpcServices#get() converts the Get to Scan without scan#setLoadColumnFamiliesOnDemand. It causes that the result retrieved from Get and Scan will be different if we use the empty filter. Scan doesn&amp;amp;apos;t return any data but Get does.
see HBASE-16729 
Any comments? Thanks.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.TestScan.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.generated.ClientProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
			<file type="M">org.apache.hadoop.hbase.client.Scan.java</file>
			<file type="M">org.apache.hadoop.hbase.client.Query.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.ProtobufUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.RSRpcServices.java</file>
			<file type="M">org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.java</file>
			<file type="M">org.apache.hadoop.hbase.protobuf.TestProtobufUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.client.Get.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">5416</link>
			<link type="Reference" description="is related to">16729</link>
		</links>
	</bug>
	<bug id="16716" opendate="2016-09-27 06:39:22" fixdate="2016-10-13 02:42:50" resolution="Fixed">
		<buginformation>
			<summary>OfflineMetaRepair leaves empty directory inside /hbase/WALs which remains forever</summary>
			<description>OfflineMetaRepair rebuild Meta table, while creating meta region it creates it&amp;amp;apos;s own WAL (inside /hbase/WALs/hbck-meta-recovery-&amp;lt;randomNumber&amp;gt;) which wll be closed and archived after rebuilding Meta. 

hbase org.apache.hadoop.hbase.util.hbck.OfflineMetaRepair
    &amp;gt;&amp;gt; /hbase/WALs/hbck-meta-recovery-&amp;lt;randomNumber&amp;gt;


It doesn&amp;amp;apos;t clear the empty dir, empty directory should be removed after success.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.hbck.TestOfflineMetaRebuildBase.java</file>
			<file type="M">org.apache.hadoop.hbase.util.HBaseFsck.java</file>
		</fixedFiles>
	</bug>
	<bug id="16724" opendate="2016-09-28 11:55:55" fixdate="2016-10-13 11:54:46" resolution="Fixed">
		<buginformation>
			<summary>Snapshot owner can&amp;apos;t clone</summary>
			<description>Currently only Global admin has the access of cloning a snapshot.
In AccessController,


  @Override
  public void preCloneSnapshot(final ObserverContext&amp;lt;MasterCoprocessorEnvironment&amp;gt; ctx,
      final SnapshotDescription snapshot, final HTableDescriptor hTableDescriptor)
      throws IOException {
    requirePermission(getActiveUser(ctx), "cloneSnapshot " + snapshot.getName(), Action.ADMIN);
  }


Snapshot owner should be able to  clone it, need to add a check like,


SnapshotDescriptionUtils.isSnapshotOwner(snapshot, user)

</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.security.access.AccessController.java</file>
			<file type="M">org.apache.hadoop.hbase.security.access.TestAccessController.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">11869</link>
		</links>
	</bug>
	<bug id="16810" opendate="2016-10-11 18:51:02" fixdate="2016-10-13 17:50:38" resolution="Fixed">
		<buginformation>
			<summary>HBase Balancer throws ArrayIndexOutOfBoundsException when regionservers are in /hbase/draining znode and unloaded</summary>
			<description>1. Add a regionserver znode under /hbase/draining znode.
2. Use RegionMover to unload all regions from the regionserver.
3. Run balancer.


16/09/21 14:17:33 ERROR ipc.RpcServer: Unexpected throwable object
java.lang.ArrayIndexOutOfBoundsException: 75
      at org.apache.hadoop.hbase.master.balancer.BaseLoadBalancer$Cluster.getLocalityOfRegion(BaseLoadBalancer.java:867)
      at org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer$LocalityCostFunction.cost(StochasticLoadBalancer.java:1186)
      at org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.computeCost(StochasticLoadBalancer.java:521)
      at org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.balanceCluster(StochasticLoadBalancer.java:309)
      at org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.balanceCluster(StochasticLoadBalancer.java:264)
      at org.apache.hadoop.hbase.master.HMaster.balance(HMaster.java:1339)
      at org.apache.hadoop.hbase.master.MasterRpcServices.balance(MasterRpcServices.java:442)
      at org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MasterService$2.callBlockingMethod(MasterProtos.java:58555)
      at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2268)
      at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:123)
      at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:188)
      at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:168)

</description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.balancer.BalancerTestBase.java</file>
			<file type="M">org.apache.hadoop.hbase.master.balancer.TestStochasticLoadBalancer.java</file>
			<file type="M">org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.java</file>
		</fixedFiles>
	</bug>
	<bug id="16853" opendate="2016-10-16 10:11:59" fixdate="2016-10-17 03:00:06" resolution="Fixed">
		<buginformation>
			<summary>Regions are assigned to Region Servers in /hbase/draining after HBase Master failover</summary>
			<description>Problem
If there are Region Servers registered as "draining", they will continue to have "draining" znodes after a HMaster failover; however, the balancer will assign regions to them.
How to reproduce (on hbase master):

Add regionserver to /hbase/draining: bin/hbase-jruby bin/draining_servers.rb add server1:16205
Unload the regionserver:  bin/hbase-jruby bin/region_mover.rb unload server1:16205
Kill the Active HMaster and failover to the Backup HMaster
Run the balancer: hbase shell &amp;lt;&amp;lt;&amp;lt; "balancer"
Notice regions get assigned on new Active Master to Region Servers in /hbase/draining

Root Cause
The Backup HMaster initializes the DrainingServerTracker before the Region Servers are registered as "online" with the ServerManager.  As a result, the ServerManager.drainingServers isn&amp;amp;apos;t populated with existing Region Servers in draining when we have an HMaster failover.
E.g., 

We have a region server in draining: server1,16205,1000
The RegionServerTracker starts up and adds a ZK watcher on the Znode for this RegionServer: /hbase/rs/server1,16205,1000
The DrainingServerTracker starts and processes each Znode under /hbase/draining, but the Region Server isn&amp;amp;apos;t registered as "online" so it isn&amp;amp;apos;t added to the ServerManager.drainingServers list.
The Region Server is added to the DrainingServerTracker.drainingServers list.
The Region Server&amp;amp;apos;s Znode watcher is triggered and the ZK watcher is restarted.
The Region Server is registered with ServerManager as "online".

END STATE: The Region Server has a Znode in /hbase/draining, but it is registered as "online" and the Balancer will start assigning regions to it.


$ bin/hbase-jruby bin/draining_servers.rb list
[1] server1,16205,1000

$ grep server1,16205,1000 logs/master-server1.log
2016-10-14 16:02:47,713 DEBUG [server1:16001.activeMasterManager] zookeeper.ZKUtil: master:16001-0x157c56adc810014, quorum=localhost:2181, baseZNode=/hbase Set watcher on existing znode=/hbase/rs/server1,16205,1000

[2] 2016-10-14 16:02:47,722 DEBUG [server1:16001.activeMasterManager] zookeeper.RegionServerTracker: Added tracking of RS /hbase/rs/server1,16205,1000

2016-10-14 16:02:47,730 DEBUG [server1:16001.activeMasterManager] zookeeper.ZKUtil: master:16001-0x157c56adc810014, quorum=localhost:2181, baseZNode=/hbase Set watcher on existing znode=/hbase/draining/server1,16205,1000

[3] 2016-10-14 16:02:47,731 WARN  [server1:16001.activeMasterManager] master.ServerManager: Server server1,16205,1000 is not currently online. Ignoring request to add it to draining list.

[4] 2016-10-14 16:02:47,731 INFO  [server1:16001.activeMasterManager] zookeeper.DrainingServerTracker: Draining RS node created, adding to list [server1,16205,1000]

2016-10-14 16:02:47,971 DEBUG [main-EventThread] zookeeper.ZKUtil: master:16001-0x157c56adc810014, quorum=localhost:2181, baseZNode=/hbase Set watcher on existing znode=/hbase/rs/dev6918.prn2.facebook.com,16205,1476486047114

[5] 2016-10-14 16:02:47,976 DEBUG [main-EventThread] zookeeper.RegionServerTracker: Added tracking of RS /hbase/rs/server1,16205,1000

[6] 2016-10-14 16:02:52,084 INFO  [RpcServer.FifoWFPBQ.default.handler=29,queue=2,port=16001] master.ServerManager: Registering server=server1,16205,1000

</description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 0.98.24</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.zookeeper.DrainingServerTracker.java</file>
			<file type="M">org.apache.hadoop.hbase.master.ServerManager.java</file>
			<file type="M">org.apache.hadoop.hbase.master.TestAssignmentListener.java</file>
		</fixedFiles>
	</bug>
	<bug id="16856" opendate="2016-10-17 06:22:14" fixdate="2016-10-17 14:24:16" resolution="Fixed">
		<buginformation>
			<summary>Exception message in SyncRunner.run() should print currentSequence</summary>
			<description>A very small bug, a typo in exception message:


if (syncFutureSequence &amp;gt; currentSequence) {
              throw new IllegalStateException("currentSequence=" + syncFutureSequence
                  + ", syncFutureSequence=" + syncFutureSequence);
            }


It should print currentSequence and syncFutureSequence, but print two syncFutureSequence</description>
			<version>1.1.7</version>
			<fixedVersion>2.0.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
		</fixedFiles>
	</bug>
	<bug id="16855" opendate="2016-10-17 04:44:44" fixdate="2016-10-17 16:36:00" resolution="Fixed">
		<buginformation>
			<summary>Avoid NPE in MetricsConnections construction</summary>
			<description>a) The batch pool may not be assigned a value in the ConnectionImpls construction.
b) The meta pool always be null in the ConnectionImpls construction.
For reasons outlined above, the NPE may happen in MetricsConnections construction

  final ThreadPoolExecutor batchPool = (ThreadPoolExecutor) conn.getCurrentBatchPool();
  final ThreadPoolExecutor metaPool = (ThreadPoolExecutor) conn.getCurrentMetaLookupPool();

  this.registry.register(name(this.getClass(), "executorPoolActiveThreads", scope),
    new RatioGauge() {
     @Override
     protected Ratio getRatio() {
      return Ratio.of(batchPool.getActiveCount(), batchPool.getMaximumPoolSize());
     }
    });
  this.registry.register(name(this.getClass(), "metaPoolActiveThreads", scope),
    new RatioGauge() {
     @Override
     protected Ratio getRatio() {
      return Ratio.of(metaPool.getActiveCount(), metaPool.getMaximumPoolSize());
     }
    });

</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.TestMetricsConnection.java</file>
			<file type="M">org.apache.hadoop.hbase.client.MetricsConnection.java</file>
		</fixedFiles>
	</bug>
	<bug id="16721" opendate="2016-09-28 00:33:17" fixdate="2016-10-17 21:32:06" resolution="Fixed">
		<buginformation>
			<summary>Concurrency issue in WAL unflushed seqId tracking</summary>
			<description>I&amp;amp;apos;m inspecting an interesting case where in a production cluster, some regionservers ends up accumulating hundreds of WAL files, even with force flushes going on due to max logs. This happened multiple times on the cluster, but not on other clusters. The cluster has periodic memstore flusher disabled, however, this still does not explain why the force flush of regions due to max limit is not working. I think the periodic memstore flusher just masks the underlying problem, which is why we do not see this in other clusters. 
The problem starts like this: 


2016-09-21 17:49:18,272 INFO  [regionserver//10.2.0.55:16020.logRoller] wal.FSHLog: Too many wals: logs=33, maxlogs=32; forcing flush of 1 regions(s): d4cf39dc40ea79f5da4d0cf66d03cb1f
2016-09-21 17:49:18,273 WARN  [regionserver//10.2.0.55:16020.logRoller] regionserver.LogRoller: Failed to schedule flush of d4cf39dc40ea79f5da4d0cf66d03cb1f, region=null, requester=null


then, it continues until the RS is restarted: 


2016-09-23 17:43:49,356 INFO  [regionserver//10.2.0.55:16020.logRoller] wal.FSHLog: Too many wals: logs=721, maxlogs=32; forcing flush of 1 regions(s): d4cf39dc40ea79f5da4d0cf66d03cb1f
2016-09-23 17:43:49,357 WARN  [regionserver//10.2.0.55:16020.logRoller] regionserver.LogRoller: Failed to schedule flush of d4cf39dc40ea79f5da4d0cf66d03cb1f, region=null, requester=null


The problem is that region d4cf39dc40ea79f5da4d0cf66d03cb1f is already split some time ago, and was able to flush its data and split without any problems. However, the FSHLog still thinks that there is some unflushed data for this region. 
</description>
			<version>1.0.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.2.4, 1.1.8</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.wal.WAL.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestFSHLog.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.AbstractTestFSWAL.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">16820</link>
		</links>
	</bug>
	<bug id="16283" opendate="2016-07-26 02:44:44" fixdate="2016-10-17 22:42:41" resolution="Fixed">
		<buginformation>
			<summary>Batch Append/Increment will always fail if set ReturnResults to false</summary>
			<description>If set Append/Increment&amp;amp;apos;s ReturnResult attribute to false, and batch the appends/increments to server. The batch operation will always return false.
The reason is that, since return result is set to false, append/increment will return null instead of Result object. But in ResponseConverter#getResults, there is some check code 


if (requestRegionActionCount != responseRegionActionResultCount) {
      throw new IllegalStateException("Request mutation count=" + requestRegionActionCount +
          " does not match response mutation result count=" + responseRegionActionResultCount);
    }


That means if the result count is not meet with request mutation count, it will fail the request.
The solution is simple, instead of returning a null result, returning a empty result if ReturnResult set to false.</description>
			<version>1.1.5</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.TestDurability.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestIncrementsFromClientSide.java</file>
			<file type="M">org.apache.hadoop.hbase.client.TestFromClientSide.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestAtomicOperation.java</file>
		</fixedFiles>
	</bug>
	<bug id="16866" opendate="2016-10-18 01:16:31" fixdate="2016-10-18 18:11:12" resolution="Fixed">
		<buginformation>
			<summary>Avoid NPE in AsyncRequestFutureImpl#updateStats</summary>
			<description>If region disables the stats, it wont response any ClientProtos.RegionLoadStats to client. So the NPE will happen in AsyncRequestFutureImpl#updateStats.
We should use relevant log instead of NPE because the data manipulation shouldnt be broken by statistics.

 protected void updateStats(ServerName server, Map&amp;lt;byte[], MultiResponse.RegionResult&amp;gt; results) {
   
   ClientProtos.RegionLoadStats stat = regionStats.getValue().getStat();
   RegionLoadStats regionLoadstats = ProtobufUtil.createRegionLoadStats(stat);
   
 }

</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.AsyncRequestFutureImpl.java</file>
		</fixedFiles>
	</bug>
	<bug id="16578" opendate="2016-09-07 21:09:26" fixdate="2016-10-19 06:23:47" resolution="Fixed">
		<buginformation>
			<summary>Mob data loss after mob compaction and normal compaction</summary>
			<description>StoreFileScanners on MOB cells rely on the scannerOrder to find the latest cells after mob compaction. The value of scannerOrder is assigned by the order of maxSeqId of StoreFile, and this maxSeqId is valued only after the reader of the StoreFile is created.
In Compactor.compact, the compacted store files are cloned and their readers are not created. And in StoreFileScanner.getScannersForStoreFiles the StoreFiles are sorted before the readers are created and at that time the maxSeqId for each file is -1 (the default value). This will lead  to a chaos in scanners in the following normal compaction. Some older cells might be chosen during the normal compaction.
We need to create readers either before the sorting in the method StoreFileScanner.getScannersForStoreFiles, or create readers just after the store files are cloned in Compactor.compact.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mob.compactions.TestMobCompactor.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFile.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.compactions.Compactor.java</file>
		</fixedFiles>
	</bug>
	<bug id="16752" opendate="2016-10-03 19:56:50" fixdate="2016-10-19 23:04:06" resolution="Fixed">
		<buginformation>
			<summary>Upgrading from 1.2 to 1.3 can lead to replication failures due to difference in RPC size limit</summary>
			<description>In HBase 1.2, we don&amp;amp;apos;t limit size of a single RPC but in 1.3 we limit it by default to 256 MB.  This means that during upgrade scenarios (or when source is 1.2 peer is already on 1.3), it&amp;amp;apos;s possible to encounter a situation where we try to send an rpc with size greater than 256 MB because we never unroll a WALEdit while sending replication traffic.
RpcServer throws the underlying exception locally, but closes the connection with returning the underlying error to the client, and client only sees a "Broken pipe" error.
I am not sure what is the proper fix here (or if one is needed) to make sure this does not happen, but we should return the underlying exception to the RpcClient, because without it, it can be difficult to diagnose the problem, especially for someone new to HBase.</description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.RpcServer.java</file>
			<file type="M">org.apache.hadoop.hbase.exceptions.RequestTooBigException.java</file>
			<file type="M">org.apache.hadoop.hbase.exceptions.ClientExceptionsUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.AbstractTestIPC.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">15212</link>
			<link type="Reference" description="is related to">17200</link>
		</links>
	</bug>
	<bug id="16889" opendate="2016-10-20 17:23:54" fixdate="2016-10-21 01:35:14" resolution="Fixed">
		<buginformation>
			<summary>Proc-V2: verifyTables in the IntegrationTestDDLMasterFailover test after each table DDL is incorrect </summary>
			<description>In the IntegrationTestDDLMasterFailover test, verifyTables is called after each table DDL.  It iterates 3 lists of tables in ConcurrentHashMap (enabledTables, disabledTables, deletedTables) and tries to do some verification.  This is incorrect, eg. a table in enabledTables map could be picked up by DeleteTableAction and is disabled, while the verification tries to check whether table is enabled.  This leads to false assertion.  
The same for verifyNamespaces().  
The proposed fix is to verify maps only at the end of tests (while no active DDL operation is going on).  During test run, we only verify the target table before putting into map.</description>
			<version>1.1.7</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.2.4, 1.1.8</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.IntegrationTestDDLMasterFailover.java</file>
		</fixedFiles>
	</bug>
	<bug id="16910" opendate="2016-10-21 08:19:01" fixdate="2016-10-21 17:26:22" resolution="Fixed">
		<buginformation>
			<summary>Avoid NPE when starting StochasticLoadBalancer</summary>
			<description>When master start, it initialize StochasticLoadBalancer.


this.balancer.setClusterStatus(getClusterStatus());
this.balancer.setMasterServices(this);


It first setClusterStatus(), then setMasterService(). But in setClusterStatus method, it use master service which is not initialized. So it will throw NPE.


int tablesCount = isByTable ? services.getTableDescriptors().getAll().size() : 1;


It happens when set isByTable is ture.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.rsgroup.RSGroupBasedLoadBalancer.java</file>
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			<file type="M">org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer.java</file>
		</fixedFiles>
	</bug>
	<bug id="16754" opendate="2016-10-04 00:03:46" fixdate="2016-10-21 19:25:09" resolution="Fixed">
		<buginformation>
			<summary>Regions failing compaction due to referencing non-existent store file</summary>
			<description>Running a mixed read write workload on a recent build off branch-1.3, we are seeing compactions occasionally fail with errors like the following (actual filenames replaced with placeholders):

16/09/27 16:57:28 ERROR regionserver.CompactSplitThread: Compaction selection failed Store = XXX, pri = 116
java.io.FileNotFoundException: File does not exist: hdfs://.../hbase/data/ns/table/region/cf/XXfilenameXX
        at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
        at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
        at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
        at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1317)
        at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)  
        at org.apache.hadoop.hbase.regionserver.StoreFileInfo.getReferencedFileStatus(StoreFileInfo.java:342)
        at org.apache.hadoop.hbase.regionserver.StoreFileInfo.getFileStatus(StoreFileInfo.java:355)  
        at org.apache.hadoop.hbase.regionserver.StoreFileInfo.getModificationTime(StoreFileInfo.java:360)
        at org.apache.hadoop.hbase.regionserver.StoreFile.getModificationTimeStamp(StoreFile.java:321)  
        at org.apache.hadoop.hbase.regionserver.StoreUtils.getLowestTimestamp(StoreUtils.java:63)
        at org.apache.hadoop.hbase.regionserver.compactions.RatioBasedCompactionPolicy.shouldPerformMajorCompaction(RatioBasedCompactionPolicy.java:63)
        at org.apache.hadoop.hbase.regionserver.compactions.SortedCompactionPolicy.selectCompaction(SortedCompactionPolicy.java:82)  
        at org.apache.hadoop.hbase.regionserver.DefaultStoreEngine$DefaultCompactionContext.select(DefaultStoreEngine.java:107)  
        at org.apache.hadoop.hbase.regionserver.HStore.requestCompaction(HStore.java:1644)
        at org.apache.hadoop.hbase.regionserver.CompactSplitThread.selectCompaction(CompactSplitThread.java:373)
        at org.apache.hadoop.hbase.regionserver.CompactSplitThread.access$100(CompactSplitThread.java:59)
        at org.apache.hadoop.hbase.regionserver.CompactSplitThread$CompactionRunner.doCompaction(CompactSplitThread.java:498)
        at org.apache.hadoop.hbase.regionserver.CompactSplitThread$CompactionRunner.run(CompactSplitThread.java:568)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
16/09/27 17:01:31 ERROR regionserver.CompactSplitThread: Compaction selection failed Store = XXX, pri = 115
java.io.FileNotFoundException: File does not exist: hdfs://.../hbase/data/ns/table/region/cf/XXfilenameXX
        at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
        at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
        at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
        at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1317)
        at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)  
        at org.apache.hadoop.hbase.regionserver.StoreFileInfo.getReferencedFileStatus(StoreFileInfo.java:342)
        at org.apache.hadoop.hbase.regionserver.StoreFileInfo.getFileStatus(StoreFileInfo.java:355)  
        at org.apache.hadoop.hbase.regionserver.StoreFileInfo.getModificationTime(StoreFileInfo.java:360)
        at org.apache.hadoop.hbase.regionserver.StoreFile.getModificationTimeStamp(StoreFile.java:321)  
        at org.apache.hadoop.hbase.regionserver.StoreUtils.getLowestTimestamp(StoreUtils.java:63)
        at org.apache.hadoop.hbase.regionserver.compactions.RatioBasedCompactionPolicy.shouldPerformMajorCompaction(RatioBasedCompactionPolicy.java:63)
        at org.apache.hadoop.hbase.regionserver.compactions.SortedCompactionPolicy.selectCompaction(SortedCompactionPolicy.java:82)  
        at org.apache.hadoop.hbase.regionserver.DefaultStoreEngine$DefaultCompactionContext.select(DefaultStoreEngine.java:107)  
        at org.apache.hadoop.hbase.regionserver.HStore.requestCompaction(HStore.java:1644)
        at org.apache.hadoop.hbase.regionserver.CompactSplitThread.selectCompaction(CompactSplitThread.java:373)
        at org.apache.hadoop.hbase.regionserver.CompactSplitThread.access$100(CompactSplitThread.java:59)
        at org.apache.hadoop.hbase.regionserver.CompactSplitThread$CompactionRunner.doCompaction(CompactSplitThread.java:498)
        at org.apache.hadoop.hbase.regionserver.CompactSplitThread$CompactionRunner.run(CompactSplitThread.java:568)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)


It looks like we somehow deleted the underlying store file from HDFS (probably after it was compacted away), after the path was loaded into the list of store files for the region.
For two cases of this that I looked into, in both cases the region in question was previously hosted by a regionserver that stalled, then aborted after its zk session expired.  In both cases it looked like a compaction was also in progress.  So it&amp;amp;apos;s possible that the compacted files are being deleted from HDFS by the stalled regionserver before it aborts, but after the region has been opened by a new regionserver.  That&amp;amp;apos;s speculation though and needs to be substantiated.</description>
			<version>1.2.3</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.2.4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.RegionReplicaReplicationEndpoint.java</file>
			<file type="M">org.apache.hadoop.hbase.wal.TestWALSplit.java</file>
			<file type="M">org.apache.hadoop.hbase.wal.WALSplitter.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.WALEdit.java</file>
		</fixedFiles>
	</bug>
	<bug id="16815" opendate="2016-10-12 11:27:39" fixdate="2016-10-22 00:09:38" resolution="Fixed">
		<buginformation>
			<summary>Low scan ratio in RPC queue tuning triggers divide by zero exception</summary>
			<description>Trying the following settings:

&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hbase.ipc.server.callqueue.handler.factor&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;0.5&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hbase.ipc.server.callqueue.read.ratio&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;0.5&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hbase.ipc.server.callqueue.scan.ratio&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;0.1&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;


With 30 default handlers, this means 15 queues. Further, it means 8 write queues and 7 read queues. 10% of that is 0.7 which is then floor&amp;amp;apos;ed to 0. The debug log confirms it, as the tertiary check omits the scan details when they are zero:

2016-10-12 12:50:27,305 INFO  [main] ipc.SimpleRpcScheduler: Using fifo as user call queue, count=15
2016-10-12 12:50:27,311 DEBUG [main] ipc.RWQueueRpcExecutor: FifoRWQ.default writeQueues=7 writeHandlers=15 readQueues=8 readHandlers=14


But the code in RWQueueRpcExecutor calls RpcExecutor.startHandler() nevertheless and that does this:


    for (int i = 0; i &amp;lt; numHandlers; i++) {
      final int index = qindex + (i % qsize);
      String name = "RpcServer." + threadPrefix + ".handler=" + handlers.size() + ",queue=" +
          index + ",port=" + port;


The modulo triggers then 

2016-10-12 11:41:22,810 ERROR [main] master.HMasterCommandLine: Master exiting
java.lang.RuntimeException: Failed construction of Master: class org.apache.hadoop.hbase.master.HMasterCommandLine$LocalHMaster
        at org.apache.hadoop.hbase.util.JVMClusterUtil.createMasterThread(JVMClusterUtil.java:145)
        at org.apache.hadoop.hbase.LocalHBaseCluster.addMaster(LocalHBaseCluster.java:220)
        at org.apache.hadoop.hbase.LocalHBaseCluster.(LocalHBaseCluster.java:155)
        at org.apache.hadoop.hbase.master.HMasterCommandLine.startMaster(HMasterCommandLine.java:222)
        at org.apache.hadoop.hbase.master.HMasterCommandLine.run(HMasterCommandLine.java:137)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
        at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:126)
        at org.apache.hadoop.hbase.master.HMaster.main(HMaster.java:2524)
Caused by: java.lang.ArithmeticException: / by zero
        at org.apache.hadoop.hbase.ipc.RpcExecutor.startHandlers(RpcExecutor.java:125)
        at org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor.startHandlers(RWQueueRpcExecutor.java:178)
        at org.apache.hadoop.hbase.ipc.RpcExecutor.start(RpcExecutor.java:78)
        at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.start(SimpleRpcScheduler.java:272)
        at org.apache.hadoop.hbase.ipc.RpcServer.start(RpcServer.java:2212)
        at org.apache.hadoop.hbase.regionserver.RSRpcServices.start(RSRpcServices.java:1143)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.(HRegionServer.java:615)
        at org.apache.hadoop.hbase.master.HMaster.(HMaster.java:396)
        at org.apache.hadoop.hbase.master.HMasterCommandLine$LocalHMaster.(HMasterCommandLine.java:312)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
        at org.apache.hadoop.hbase.util.JVMClusterUtil.createMasterThread(JVMClusterUtil.java:140)
        ... 7 more


That causes the server to not even start. I would suggest we either skip the startHandler() call altogether, or make it zero aware.
Another possible option is to reserve at least one scan handler/queue when the scan ratio is greater than zero, but only of there is more than one read handler/queue to begin with. Otherwise the scan handler/queue should be zero and share the one read handler/queue.
Makes sense?</description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.4.0, 1.2.4, 1.1.8</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.RWQueueRpcExecutor.java</file>
		</fixedFiles>
	</bug>
	<bug id="16870" opendate="2016-10-18 11:18:35" fixdate="2016-10-22 06:30:23" resolution="Fixed">
		<buginformation>
			<summary>Add the metrics of replication sources which were transformed from other dead rs to ReplicationLoad</summary>
			<description>

  private void buildReplicationLoad() {
    // get source
    List&amp;lt;ReplicationSourceInterface&amp;gt; sources = this.replicationManager.getSources();
    List&amp;lt;MetricsSource&amp;gt; sourceMetricsList = new ArrayList&amp;lt;MetricsSource&amp;gt;();

    for (ReplicationSourceInterface source : sources) {
      if (source instanceof ReplicationSource) {
        sourceMetricsList.add(((ReplicationSource) source).getSourceMetrics());
      }
    }

    // get sink
    MetricsSink sinkMetrics = this.replicationSink.getSinkMetrics();
    this.replicationLoad.buildReplicationLoad(sourceMetricsList, sinkMetrics);
  }


The buildReplicationLoad method in o.a.h.h.r.r.Replication didn&amp;amp;apos;t consider the replication source which were transformed from other died rs.</description>
			<version>1.1.7</version>
			<fixedVersion>2.0.0, 1.4.0, 1.2.4, 0.98.24, 1.1.8</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.replication.TestReplicationSmallTests.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.ReplicationLoad.java</file>
			<file type="D">org.apache.hadoop.hbase.replication.TestReplicationStatus.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.MetricsSource.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.ReplicationSourceManager.java</file>
			<file type="M">org.apache.hadoop.hbase.replication.regionserver.Replication.java</file>
		</fixedFiles>
	</bug>
	<bug id="15684" opendate="2016-04-21 06:20:53" fixdate="2016-10-22 09:44:26" resolution="Fixed">
		<buginformation>
			<summary>Fix the broken log file size accounting</summary>
			<description>

long oldFileLen = 0L;
      doReplaceWriter(oldPath, newPath, nextWriter);


Should be


long oldFileLen =  doReplaceWriter(oldPath, newPath, nextWriter);

</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.AbstractTestLogRolling.java</file>
			<file type="M">org.apache.hadoop.hbase.wal.AbstractFSWALProvider.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.java</file>
		</fixedFiles>
	</bug>
	<bug id="16880" opendate="2016-10-19 06:23:39" fixdate="2016-10-25 05:23:47" resolution="Fixed">
		<buginformation>
			<summary>Correct the javadoc/behaviour of the APIs in ByteBufferUtils</summary>
			<description>There are some issues either with the javadoc or the actual behaviour of some APIs in BBUtils.
For eg,
BBUtil#copyFromBufferToBuffer() says


  /**
   * Copy one buffer&amp;amp;apos;s whole data to another. Write starts at the current position of &amp;amp;apos;out&amp;amp;apos; buffer.
   * Note : This will advance the position marker of {@code out} but not change the position maker
   * for {@code in}. The position and limit of the {@code in} buffer to be set properly by caller.
   * @param in source buffer
   * @param out destination buffer


But this is true in case of UNSAFE.


    if (UNSAFE_AVAIL) {
      int length = in.remaining();
      UnsafeAccess.copy(in, in.position(), out, out.position(), length);
      out.position(out.position() + length);
    } else {
      out.put(in);
    }


But in other case where we move the else - the &amp;amp;apos;in&amp;amp;apos; is also advanced. So we need to either correct the behaviour or change the doc and see all the used places. This JIRA can be used to correct all the APIs in this util class.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.TestByteBufferUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.util.ByteBufferUtils.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.BufferChain.java</file>
			<file type="M">org.apache.hadoop.hbase.ipc.RpcServer.java</file>
		</fixedFiles>
	</bug>
	<bug id="16743" opendate="2016-09-30 23:55:51" fixdate="2016-10-28 23:50:31" resolution="Fixed">
		<buginformation>
			<summary>TestSimpleRpcScheduler#testCoDelScheduling is broke</summary>
			<description>The testCoDelScheduling test is broke. Here are some notes on it. I have disabled it in the HBASE-15638 shading patch.


I don&amp;amp;apos;t get this test. When I time this test, the minDelay is &amp;gt; 2 * codel delay from the get go. So we are always overloaded. The test below would seem to complete the queuing of all the CallRunners inside the codel check interval. I don&amp;amp;apos;t think we are skipping codel checking. Second, I think this test has been  broken since HBASE-16089 Add on FastPath for CoDel went in. The thread name we were looking for was the name BEFORE we updated: i.e. "RpcServer.CodelBQ.default.handler". But same patch changed the name of the codel  fastpath thread to: new FastPathBalancedQueueRpcExecutor("CodelFPBQ.default", handlerCount, numCallQueues...

Codel is hard to test. This test is going to be flakey given it all timer-based. Disabling for now till chat


FYI Mikhail Antonov</description>
			<version>1.3.0</version>
			<fixedVersion>1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler.java</file>
		</fixedFiles>
	</bug>
	<bug id="16971" opendate="2016-10-31 03:08:02" fixdate="2016-10-31 16:51:13" resolution="Fixed">
		<buginformation>
			<summary>The passed durability of Append/Increment isn&amp;apos;t used in wal sync</summary>
			<description>We should pass the effectiveDurability to the doWALAppend() metohd.
HRegion.java

private Result doDelta(...) {
        Durability effectiveDurability = getEffectiveDurability(mutation.getDurability());
        Map&amp;lt;Store, List&amp;lt;Cell&amp;gt;&amp;gt; forMemStore =
            new HashMap&amp;lt;Store, List&amp;lt;Cell&amp;gt;&amp;gt;(mutation.getFamilyCellMap().size());
        // Reckon Cells to apply to WAL --  in returned walEdit -- and what to add to memstore and
        // what to return back to the client (in &amp;amp;apos;forMemStore&amp;amp;apos; and &amp;amp;apos;results&amp;amp;apos; respectively).
        WALEdit walEdit = reckonDeltas(op, mutation, effectiveDurability, forMemStore, results);
        // Actually write to WAL now if a walEdit to apply.
        if (walEdit != null &amp;amp;&amp;amp; !walEdit.isEmpty()) {
          writeEntry = doWALAppend(walEdit, durability, nonceGroup, nonce);
        } else {
}

</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">15158</link>
		</links>
	</bug>
	<bug id="16966" opendate="2016-10-28 23:50:03" fixdate="2016-10-31 21:41:39" resolution="Fixed">
		<buginformation>
			<summary>Re-enable TestSimpleRpcScheduler#testCoDelScheduling  in master branch</summary>
			<description>see HBASE-16743. Creating separate jira so we don&amp;amp;apos;t forget. This test been flaky for a while. Need to make sure it&amp;amp;apos;s fixed.
it&amp;amp;apos;s already enabled on branch-1 and branch-1.3 (rather, never was disabled)</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler.java</file>
		</fixedFiles>
	</bug>
	<bug id="16980" opendate="2016-11-01 01:14:44" fixdate="2016-11-02 02:23:30" resolution="Fixed">
		<buginformation>
			<summary>TestRowProcessorEndpoint failing consistently</summary>
			<description>Found while evaluating 1.2.4 RC1

  TestRowProcessorEndpoint.testMultipleRows:246 expected:&amp;lt;3&amp;gt; but was:&amp;lt;2&amp;gt;
  TestRowProcessorEndpoint.testReadModifyWrite:184 expected:&amp;lt;101&amp;gt; but was:&amp;lt;91&amp;gt;

</description>
			<version>1.2.4</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.2.5, 0.98.24, 1.1.8</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.coprocessor.TestRowProcessorEndpoint.java</file>
		</fixedFiles>
	</bug>
	<bug id="16931" opendate="2016-10-24 04:05:14" fixdate="2016-11-02 03:41:00" resolution="Fixed">
		<buginformation>
			<summary>Setting cell&amp;apos;s seqId to zero in compaction flow might cause RS down.</summary>
			<description>Compactor#performCompaction
      do {
        hasMore = scanner.next(cells, scannerContext);
        // output to writer:
        for (Cell c : cells) {
          if (cleanSeqId &amp;amp;&amp;amp; c.getSequenceId() &amp;lt;= smallestReadPoint) 
{
            CellUtil.setSequenceId(c, 0);
          }
          writer.append(c);
        }
        cells.clear();
      } while (hasMore);
scanner.next will choose at most "hbase.hstore.compaction.kv.max" kvs, the last cell still reference by StoreScanner.prevCell, so if cleanSeqId is called when the scanner.next call StoreScanner.checkScanOrder may throw exception and cause regionserver down.</description>
			<version>1.1.7</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.2.4, 1.1.8</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.compactions.Compactor.java</file>
		</fixedFiles>
	</bug>
	<bug id="16960" opendate="2016-10-28 03:38:40" fixdate="2016-11-04 15:24:19" resolution="Fixed">
		<buginformation>
			<summary>RegionServer hang when aborting</summary>
			<description>We see regionserver hang when aborting several times and cause all regions on this regionserver out of service and then all affected applications stop works.</description>
			<version>1.1.7</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.2.4, 1.1.8</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.SyncFuture.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.FSHLog.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestWALLockup.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">14317</link>
		</links>
	</bug>
	<bug id="17032" opendate="2016-11-05 00:17:10" fixdate="2016-11-07 05:46:38" resolution="Fixed">
		<buginformation>
			<summary>CallQueueTooBigException and CallDroppedException should not be triggering PFFE</summary>
			<description>Back in HBASE-15137 we made it so that CQTBE causes preemptive fast fail exception on the client. 
It seems those 2 load control mechanists don&amp;amp;apos;t exactly align here. Server throws CallQueueTooBigException, CallDroppedException (from deadline scheduler) when it feels overloaded. Client should accept that behavior and retry. When servers sheds the load, and client also bails out, the load shedding  bubbles up too high and high level impact on the client applications seems worse with PFFE turned on then without.</description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.3.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.TestFastFail.java</file>
			<file type="M">org.apache.hadoop.hbase.client.PreemptiveFastFailInterceptor.java</file>
		</fixedFiles>
	</bug>
	<bug id="16992" opendate="2016-11-02 10:16:01" fixdate="2016-11-07 17:57:12" resolution="Fixed">
		<buginformation>
			<summary>The usage of mutation from CP is weird.</summary>
			<description>HRegion#doMiniBatchMutate

Mutation cpMutation = cpMutations[j];
Map&amp;lt;byte[], List&amp;lt;Cell&amp;gt;&amp;gt; cpFamilyMap = cpMutation.getFamilyCellMap();
checkAndPrepareMutation(cpMutation, replay, cpFamilyMap, now);
 // Acquire row locks. If not, the whole batch will fail.
acquiredRowLocks.add(getRowLockInternal(cpMutation.getRow(), true));
if (cpMutation.getDurability() == Durability.SKIP_WAL) {
  recordMutationWithoutWal(cpFamilyMap);
}
// Returned mutations from coprocessor correspond to the Mutation at index i. We can
 // directly add the cells from those mutations to the familyMaps of this mutation.
mergeFamilyMaps(familyMaps[i], cpFamilyMap); // will get added to the memstore later


1. Does the returned mutation from coprocessor have the same row as the corresponded mutation? If so, the acquiredRowLocks() can be saved. If not, the corresponded mutation may maintain the cells with different row due to mergeFamilyMaps().
2. Is returned mutation&amp;amp;apos;s durability useful? If so, we should deal with the different durabilities before mergeFamilyMaps(). If not, the recordMutationWithoutWal can be saved. 
3. If both the returned mutation and corresponded mutation have Durability.SKIP_WAL, the recordMutationWithoutWal() may record the duplicate cells due to mergeFamilyMaps().
Any comment? Thanks.</description>
			<version>1.3.0</version>
			<fixedVersion>2.0.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHRegion.java</file>
			<file type="M">org.apache.hadoop.hbase.regionserver.MiniBatchOperationInProgress.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">15600</link>
		</links>
	</bug>
	<bug id="17042" opendate="2016-11-07 22:50:59" fixdate="2016-11-08 02:08:59" resolution="Fixed">
		<buginformation>
			<summary>Remove &amp;apos;public&amp;apos; keyword from MasterObserver interface</summary>
			<description>Very minor, when I added some new observers, I put &amp;amp;apos;public&amp;amp;apos; is in some new observers in the MasterObserver interface.  The fix is trivial.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.0, 1.3.0, 1.4.0, 1.2.5, 1.1.8</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.coprocessor.MasterObserver.java</file>
		</fixedFiles>
	</bug>
	<bug id="16938" opendate="2016-10-25 01:55:08" fixdate="2016-11-10 22:16:36" resolution="Fixed">
		<buginformation>
			<summary>TableCFsUpdater maybe failed due to no write permission on peerNode</summary>
			<description>After HBASE-11393, replication table-cfs use a PB object. So it need copy the old string config to new PB object when upgrade cluster. In our use case, we have different kerberos for different cluster, etc. online serve cluster and offline processing cluster. And we use a unify global admin kerberos for all clusters. The peer node is created by client. So only global admin has the write  permission for it. When upgrade cluster, HMaster doesn&amp;amp;apos;t has the write permission on peer node, it maybe failed to copy old table-cfs string to new PB Object. I thought it need a tool for client to do this copy job.</description>
			<version>1.4.0</version>
			<fixedVersion>2.0.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.replication.master.TableCFsUpdater.java</file>
		</fixedFiles>
	</bug>
	<bug id="17020" opendate="2016-11-04 11:06:29" fixdate="2016-11-11 02:46:25" resolution="Fixed">
		<buginformation>
			<summary>keylen in midkey() dont computed correctly</summary>
			<description>in CellBasedKeyBlockIndexReader.midkey():


          ByteBuff b = midLeafBlock.getBufferWithoutHeader();
          int numDataBlocks = b.getIntAfterPosition(0);
          int keyRelOffset = b.getIntAfterPosition(Bytes.SIZEOF_INT * (midKeyEntry + 1));
          int keyLen = b.getIntAfterPosition(Bytes.SIZEOF_INT * (midKeyEntry + 2)) - keyRelOffset;


the local varible keyLen get this should be total length of: SECONDARY_INDEX_ENTRY_OVERHEAD  + firstKey.length;
the code is:


    void add(byte[] firstKey, long blockOffset, int onDiskDataSize,
        long curTotalNumSubEntries) {
      // Record the offset for the secondary index
      secondaryIndexOffsetMarks.add(curTotalNonRootEntrySize);
      curTotalNonRootEntrySize += SECONDARY_INDEX_ENTRY_OVERHEAD
          + firstKey.length;


when the midkey last entry of a leaf-level index block, this may throw:

2016-10-01 12:27:55,186 ERROR [MemStoreFlusher.0] regionserver.MemStoreFlusher: Cache flusher failed for entry [flush region pora_6_item_feature,0061:,1473838922457.12617bc4ebbfd171018bf96ac9bdd2a7.]
java.lang.ArrayIndexOutOfBoundsException
        at org.apache.hadoop.hbase.util.ByteBufferUtils.copyFromBufferToArray(ByteBufferUtils.java:936)
        at org.apache.hadoop.hbase.nio.SingleByteBuff.toBytes(SingleByteBuff.java:303)
        at org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$CellBasedKeyBlockIndexReader.midkey(HFileBlockIndex.java:419)
        at org.apache.hadoop.hbase.io.hfile.HFileReaderImpl.midkey(HFileReaderImpl.java:1519)
        at org.apache.hadoop.hbase.regionserver.StoreFile$Reader.midkey(StoreFile.java:1520)
        at org.apache.hadoop.hbase.regionserver.StoreFile.getFileSplitPoint(StoreFile.java:706)
        at org.apache.hadoop.hbase.regionserver.DefaultStoreFileManager.getSplitPoint(DefaultStoreFileManager.java:126)
        at org.apache.hadoop.hbase.regionserver.HStore.getSplitPoint(HStore.java:1983)
        at org.apache.hadoop.hbase.regionserver.ConstantFamilySizeRegionSplitPolicy.getSplitPoint(ConstantFamilySizeRegionSplitPolicy.java:77)
        at org.apache.hadoop.hbase.regionserver.HRegion.checkSplit(HRegion.java:7756)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:513)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:471)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.access$800(MemStoreFlusher.java:75)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushHandler.run(MemStoreFlusher.java:259)
        at java.lang.Thread.run(Thread.java:756)
</description>
			<version>0.98.23</version>
			<fixedVersion>2.0.0, 1.4.0, 1.2.5, 0.98.24, 1.1.8</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFileBlockIndex.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.RandomKeyValueUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.TestHFileBlockIndex.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">17113</link>
			<link type="Reference" description="is related to">17070</link>
		</links>
	</bug>
	<bug id="17039" opendate="2016-11-07 04:11:53" fixdate="2016-11-11 02:54:29" resolution="Fixed">
		<buginformation>
			<summary>SimpleLoadBalancer schedules large amount of invalid region moves</summary>
			<description>After increasing one of our clusters to 1600 nodes, we observed a large amount of invalid region moves(more than 30k moves) fired by the balance chore. Thus we simulated the problem and printed out the balance plan, only to find out many servers that had two regions for a certain table(we use by table strategy), sent out both regions to other two servers that have zero region. 
In the SimpleLoadBalancer&amp;amp;apos;s balanceCluster function,
the code block that determines the underLoadedServers might have a problem:


      if (load &amp;gt;= min &amp;amp;&amp;amp; load &amp;gt; 0) {
        continue; // look for other servers which haven&amp;amp;apos;t reached min
      }
      int regionsToPut = min - load;
      if (regionsToPut == 0)
      {
        regionsToPut = 1;
      }


if min is zero, some server that has load of zero, which equals to min would be marked as underloaded, which would cause the phenomenon mentioned above.
Since we increased the cluster&amp;amp;apos;s size to 1600+, many tables that only have 1000 regions, now would encounter such issue.
By fixing it up, the balance plan went back to normal.</description>
			<version>1.1.7</version>
			<fixedVersion>2.0.0, 1.4.0, 1.2.5, 1.1.8</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.master.balancer.SimpleLoadBalancer.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="is related to">17059</link>
		</links>
	</bug>
	<bug id="16345" opendate="2016-08-03 08:33:55" fixdate="2016-11-14 21:40:10" resolution="Fixed">
		<buginformation>
			<summary>RpcRetryingCallerWithReadReplicas#call() should catch some RegionServer Exceptions</summary>
			<description>Update for the description. Debugged more at this front based on the comments from Enis. 
The cause is that for the primary replica, if its retry is exhausted too fast, f.get() [1] returns ExecutionException. This Exception needs to be ignored and continue with the replicas.
The other issue is that after adding calls for the replicas, if the first completed task gets ExecutionException (due to the retry exhausted), it throws the exception to the client[2].
In this case, it needs to loop through these tasks, waiting for the success one. If no one succeeds, throw exception.
Similar for the scan as well
[1] https://github.com/apache/hbase/blob/master/hbase-client/src/main/java/org/apache/hadoop/hbase/client/RpcRetryingCallerWithReadReplicas.java#L197
[2] https://github.com/apache/hbase/blob/master/hbase-client/src/main/java/org/apache/hadoop/hbase/client/RpcRetryingCallerWithReadReplicas.java#L219
</description>
			<version>1.0.3</version>
			<fixedVersion>2.0.0, 1.4.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.client.TestReplicaWithCluster.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ResultBoundedCompletionService.java</file>
			<file type="M">org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.java</file>
			<file type="M">org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.java</file>
		</fixedFiles>
	</bug>
	<bug id="17113" opendate="2016-11-16 15:04:57" fixdate="2016-11-16 15:23:49" resolution="Duplicate">
		<buginformation>
			<summary>finding middle key in HFileV2 is always wrong and can cause IndexOutOfBoundsException </summary>
			<description>When we want  to split a region, we need to  get the middle rowkey from the biggest store file. 
Here is the code from HFileBlockIndex.midkey() which help us find a approximation middle key.


// Caching, using pread, assuming this is not a compaction.
        HFileBlock midLeafBlock = cachingBlockReader.readBlock(
            midLeafBlockOffset, midLeafBlockOnDiskSize, true, true, false, true,
            BlockType.LEAF_INDEX, null);

        ByteBuffer b = midLeafBlock.getBufferWithoutHeader();
        int numDataBlocks = b.getInt();
        int keyRelOffset = b.getInt(Bytes.SIZEOF_INT * (midKeyEntry + 1));
        int keyLen = b.getInt(Bytes.SIZEOF_INT * (midKeyEntry + 2)) -
            keyRelOffset - SECONDARY_INDEX_ENTRY_OVERHEAD;
        int keyOffset = Bytes.SIZEOF_INT * (numDataBlocks + 2) + keyRelOffset
            + SECONDARY_INDEX_ENTRY_OVERHEAD;
        targetMidKey = ByteBufferUtils.toBytes(b, keyOffset, keyLen);


and in each entry of Non-root block index contains three object:
1. Offset of the block referenced by this entry in the file (long)
2 .Ondisk size of the referenced block (int)
3. RowKey. 
But when we caculating the keyLen from the entry, we forget to take away the 12 byte overhead(1,2 above, SECONDARY_INDEX_ENTRY_OVERHEAD in the code). So the keyLen is always 12 bytes bigger than the real rowkey length.
Every time we read the rowkey form the entry, we read 12 bytes from the next entry. 
No exception will throw unless the middle key is in the last entry of the Non-root block index. which will cause a IndexOutOfBoundsException. That is exactly what HBASE-16097 is suffering from.


2016-11-16 05:27:31,991 ERROR [MemStoreFlusher.1] regionserver.MemStoreFlusher: Cache flusher failed for entry [flush region hitsdb,\x14\x03\x83\x1AX\x1A\x9A \x00\x00\x07\x00\x00\x07\x00\x00\x09\x00\x00\x09\x00\x01\x9F\x00F\xE3\x00\x00\x0A\x00\x01~\x00\x00\x08\x00\x5C\x09\x00\x03\x11\x00\xEF\x99,1478311873096.79d3f7f285396b6896f3229e2bcac7af.]
java.lang.IndexOutOfBoundsException
        at java.nio.Buffer.checkIndex(Buffer.java:532)
        at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:139)
        at org.apache.hadoop.hbase.util.ByteBufferUtils.toBytes(ByteBufferUtils.java:490)
        at org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexReader.midkey(HFileBlockIndex.java:349)
        at org.apache.hadoop.hbase.io.hfile.HFileReaderV2.midkey(HFileReaderV2.java:529)
        at org.apache.hadoop.hbase.regionserver.StoreFile$Reader.midkey(StoreFile.java:1527)
        at org.apache.hadoop.hbase.regionserver.StoreFile.getFileSplitPoint(StoreFile.java:684)
        at org.apache.hadoop.hbase.regionserver.DefaultStoreFileManager.getSplitPoint(DefaultStoreFileManager.java:126)
        at org.apache.hadoop.hbase.regionserver.HStore.getSplitPoint(HStore.java:1976)
        at org.apache.hadoop.hbase.regionserver.RegionSplitPolicy.getSplitPoint(RegionSplitPolicy.java:82)
        at org.apache.hadoop.hbase.regionserver.HRegion.checkSplit(HRegion.java:7614)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:521)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:471)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.access$800(MemStoreFlusher.java:75)
        at org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushHandler.run(MemStoreFlusher.java:259)
        at java.lang.Thread.run(Thread.java:756)



It is a quite serious bug. It may exsits from HFileV2 was invented. But no one has found out! Since this bug ONLY happens when finding a middlekey, and since we compare a rowkey from the left side, adding 12 bytes more to the right side is totally OK, no one cares!
It even won&amp;amp;apos;t throw IndexOutOfBoundsException before HBASE-12297. since Arrays.copyOfRange is used, which will check the limit to ensue the length won&amp;amp;apos;t running past the end of the array.
 But now, ByteBufferUtils.toBytes is used and IndexOutOfBoundsException will been thrown. 
It happens in our production environment. Because of this bug, the region can&amp;amp;apos;t be split can grow bigger and bigger.</description>
			<version>0.94.17</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.io.hfile.HFileBlockIndex.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.RandomKeyValueUtil.java</file>
			<file type="M">org.apache.hadoop.hbase.io.hfile.TestHFileBlockIndex.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">17020</link>
			<link type="Reference" description="relates to">16097</link>
		</links>
	</bug>
	<bug id="2535" opendate="2010-05-12 03:13:41" fixdate="2016-11-16 19:58:14" resolution="Duplicate">
		<buginformation>
			<summary>split hostname format should be consistent with tasktracker for locality</summary>
			<description>I was running a mapreduce job (via Hive) against HBase, and noticed that I wasn&amp;amp;apos;t getting any locality (the input split location and the task tracker machine in the job tracker UI were always different, and "Rack-local map tasks" in the job counters was 0).
I tracked this down to a discrepancy in the way hostnames were being compared.
The task tracker detail had a Host like
/f/s/1.2.3.4/h.s.f.com.
(with trailing dot)
But the Input Split Location had
/f/s/1.2.3.4/h.s.f.com
(without trailing dot)</description>
			<version>0.20.4</version>
			<fixedVersion></fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TableInputFormatBase.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">7693</link>
		</links>
	</bug>
	<bug id="3307" opendate="2010-12-03 17:58:18" fixdate="2016-11-16 19:59:30" resolution="Duplicate">
		<buginformation>
			<summary>Add checkAndPut to the Thrift API</summary>
			<description>It would be very useful to have the checkAndPut method available via the Thrift API. This would both allow for easier atomic updates as well as cut down on at least one Thrift roundtrip for quite a few common tasks. </description>
			<version>0.89.20100924</version>
			<fixedVersion></fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.thrift.ThriftUtilities.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.TestThriftServer.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.generated.Hbase.java</file>
			<file type="M">org.apache.hadoop.hbase.thrift.ThriftServerRunner.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">10960</link>
		</links>
	</bug>
	<bug id="3778" opendate="2011-04-13 20:58:19" fixdate="2016-11-16 20:56:52" resolution="Duplicate">
		<buginformation>
			<summary>HBaseAdmin.create doesn&amp;apos;t create empty boundary keys</summary>
			<description>In my ycsb stuff, I have code that looks like this:


    String startKey = "user1020000000";
    String endKey = "user940000000";
    admin.createTable(descriptor, startKey.getBytes(), endKey.getBytes(), regions);


The result, however, is a table where the first and last region has defined first and last keys rather than empty keys.
The patch I am about to attach fixes this, I think.  I have some worries about other uses of Bytes.split, however, and would like some eyes on this patch.  Perhaps we need a new dialect of split.</description>
			<version>0.90.2</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.util.RegionSplitter.java</file>
			<file type="M">org.apache.hadoop.hbase.util.Bytes.java</file>
			<file type="M">org.apache.hadoop.hbase.util.TestRegionSplitter.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">4627</link>
		</links>
	</bug>
	<bug id="9913" opendate="2013-11-07 08:11:20" fixdate="2016-11-16 22:05:33" resolution="Duplicate">
		<buginformation>
			<summary>weblogic deployment project implementation under the mapreduce hbase reported a NullPointerException</summary>
			<description>java.lang.NullPointerException
	at java.io.File.&amp;lt;init&amp;gt;(File.java:222)
	at java.util.zip.ZipFile.&amp;lt;init&amp;gt;(ZipFile.java:75)
	at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.updateMap(TableMapReduceUtil.java:617)
	at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.findOrCreateJar(TableMapReduceUtil.java:597)
	at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.addDependencyJars(TableMapReduceUtil.java:557)
	at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.addDependencyJars(TableMapReduceUtil.java:518)
	at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(TableMapReduceUtil.java:144)
	at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(TableMapReduceUtil.java:221)
	at org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(TableMapReduceUtil.java:87)
	at com.easymap.ezserver6.map.source.hbase.convert.HBaseMapMerge.beginMerge(HBaseMapMerge.java:163)
	at com.easymap.ezserver6.app.servlet.EzMapToHbaseService.doPost(EzMapToHbaseService.java:32)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:727)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at weblogic.servlet.internal.StubSecurityHelper$ServletServiceAction.run(StubSecurityHelper.java:227)
	at weblogic.servlet.internal.StubSecurityHelper.invokeServlet(StubSecurityHelper.java:125)
	at weblogic.servlet.internal.ServletStubImpl.execute(ServletStubImpl.java:292)
	at weblogic.servlet.internal.ServletStubImpl.execute(ServletStubImpl.java:175)
	at weblogic.servlet.internal.WebAppServletContext$ServletInvocationAction.run(WebAppServletContext.java:3594)
	at weblogic.security.acl.internal.AuthenticatedSubject.doAs(AuthenticatedSubject.java:321)
	at weblogic.security.service.SecurityManager.runAs(SecurityManager.java:121)
	at weblogic.servlet.internal.WebAppServletContext.securedExecute(WebAppServletContext.java:2202)
	at weblogic.servlet.internal.WebAppServletContext.execute(WebAppServletContext.java:2108)
	at weblogic.servlet.internal.ServletRequestImpl.run(ServletRequestImpl.java:1432)
	at weblogic.work.ExecuteThread.execute(ExecuteThread.java:201)
	at weblogic.work.ExecuteThread.run(ExecuteThread.java:173)
&amp;gt; 
my project deploy under weblogic11,and when i run hbase mapreduceit throws a NullPointerException.i found the method TableMapReduceUtil.findContainingJar() returns null,so i debug it, url.getProtocol() return "zip",but the file is a jar file,so the if condition:
 if ("jar".equals(url.getProtocol()))  cann&amp;amp;apos;t run. so i add a if condition to judge "zip" type</description>
			<version>0.94.10</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">12491</link>
		</links>
	</bug>
	<bug id="17058" opendate="2016-11-10 02:45:27" fixdate="2016-11-17 20:33:45" resolution="Fixed">
		<buginformation>
			<summary>Lower epsilon used for jitter verification from HBASE-15324</summary>
			<description>The current epsilon used is 1E-6 and its too big it might overflow the desiredMaxFileSize. A trivial fix is to lower the epsilon to 2^-52 or even 2^-53. An option to consider too is just to shift the jitter to always decrement hbase.hregion.max.filesize (MAX_FILESIZE) instead of increase the size of the region and having to deal with the round off.</description>
			<version>1.1.7</version>
			<fixedVersion>2.0.0, 1.4.0, 1.3.1, 1.2.5, 1.1.8</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.apache.hadoop.hbase.regionserver.ConstantSizeRegionSplitPolicy.java</file>
		</fixedFiles>
		<links>
			<link type="Reference" description="relates to">15324</link>
		</links>
	</bug>
</bugrepository>