Possible race condition while updating DataSource Metadata [Kafka Indexing Service].
We have Kafka indexing service running currently with no replication and task count equivalent to number of kafka partitions. One of the tasks failed with this exception -
com.metamx.common.ISE: Transaction failure publishing segments, aborting
        at io.druid.indexing.kafka.KafkaIndexTask.run(KafkaIndexTask.java:524) ~[druid-kafka-indexing-service-0.9.3-1476736930-8d59341-1004.jar:0.9.3-1476736930-8d59341-1004]
        at io.druid.indexing.overlord.ThreadPoolTaskRunner$ThreadPoolTaskRunnerCallable.call(ThreadPoolTaskRunner.java:436) [druid-indexing-service-0.9.3-1476736930-8d59341-1004.jar:0.9.3-1476736930-8d59341-1004]
        at io.druid.indexing.overlord.ThreadPoolTaskRunner$ThreadPoolTaskRunnerCallable.call(ThreadPoolTaskRunner.java:408) [druid-indexing-service-0.9.3-1476736930-8d59341-1004.jar:0.9.3-1476736930-8d59341-1004]
        at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_60]
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_60]
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_60]
        at java.lang.Thread.run(Thread.java:745) [?:1.8.0_60]
2016-10-19T08:23:19,572 INFO [task-runner-0-priority-0] io.druid.indexing.overlord.TaskRunnerUtils - Task [index_kafka_v2_metrics_cluster_966f1c1b7a001cf_menkjigj] status changed to [FAILED].
2016-10-19T08:23:19,575 INFO [task-runner-0-priority-0] io.druid.indexing.worker.executor.ExecutorLifecycle - Task completed with status: {
  "id" : "index_kafka_v2_metrics_cluster_966f1c1b7a001cf_menkjigj",
  "status" : "FAILED",
  "duration" : 11637165
}

Earlier in the task log I see this -
2016-10-19T08:23:19,300 INFO [task-runner-0-priority-0] io.druid.indexing.common.actions.RemoteTaskActionClient - Submitting action for task[index_kafka_v2_metrics_cluster_966f1c1b7a001cf_menkjigj] to overlord[/druid/indexer/v1/action]: SegmentInsertAction{segments=[DataSegment{size=357264367, shardSpec=NumberedShardSpec{partitionNum=36, partitions=0}, metrics=[], dimensions=[], version='2016-10-19T05:00:01.567Z', loadSpec={type=hdfs, path=}, interval=2016-10-19T05:00:00.000Z/2016-10-19T06:00:00.000Z, dataSource='v2_metrics_cluster', binaryVersion='9'}, DataSegment{size=328688502, shardSpec=NumberedShardSpec{partitionNum=5, partitions=0}, metrics=[], dimensions=[], version='2016-10-19T07:00:00.975Z', loadSpec={type=hdfs, path=}, interval=2016-10-19T07:00:00.000Z/2016-10-19T08:00:00.000Z, dataSource='v2_metrics_cluster', binaryVersion='9'}, DataSegment{size=55419587, shardSpec=NumberedShardSpec{partitionNum=3, partitions=0}, metrics=[], dimensions=[], version='2016-10-19T08:00:00.443Z', loadSpec={type=hdfs, path=}, interval=2016-10-19T08:00:00.000Z/2016-10-19T09:00:00.000Z, dataSource='v2_metrics_cluster', binaryVersion='9'}, DataSegment{size=396175234, shardSpec=NumberedShardSpec{partitionNum=1, partitions=0}, metrics=[], dimensions=[], version='2016-10-19T06:00:00.545Z', loadSpec={type=hdfs, path=}, interval=2016-10-19T06:00:00.000Z/2016-10-19T07:00:00.000Z, dataSource='v2_metrics_cluster', binaryVersion='9'}], startMetadata=KafkaDataSourceMetadata{kafkaPartitions=KafkaPartitions{topic='mx-cluster-production-metrics', partitionOffsetMap={8=158229668}}}, endMetadata=KafkaDataSourceMetadata{kafkaPartitions=KafkaPartitions{topic='mx-cluster-production-metrics', partitionOffsetMap={8=202436580}}}}
2016-10-19T08:23:19,318 INFO [task-runner-0-priority-0] com.metamx.http.client.pool.ChannelResourceFactory - Generating:
2016-10-19T08:23:19,411 INFO [task-runner-0-priority-0] io.druid.segment.realtime.appenderator.FiniteAppenderatorDriver - Transaction failure while publishing segments, checking if someone else beat us to it.
2016-10-19T08:23:19,414 INFO [task-runner-0-priority-0] io.druid.indexing.common.actions.RemoteTaskActionClient - Performing action for task[index_kafka_v2_metrics_cluster_966f1c1b7a001cf_menkjigj]: SegmentListUsedAction{dataSource='v2_metrics_cluster', intervals=[2016-10-19T05:00:00.000Z/2016-10-19T09:00:00.000Z]}
2016-10-19T08:23:19,419 INFO [task-runner-0-priority-0] io.druid.indexing.common.actions.RemoteTaskActionClient - Submitting action for task[index_kafka_v2_metrics_cluster_966f1c1b7a001cf_menkjigj] to overlord[/druid/indexer/v1/action]: SegmentListUsedAction{dataSource='v2_metrics_cluster', intervals=[2016-10-19T05:00:00.000Z/2016-10-19T09:00:00.000Z]}
2016-10-19T08:23:19,422 INFO [task-runner-0-priority-0] com.metamx.http.client.pool.ChannelResourceFactory - Generating:
2016-10-19T08:23:19,513 WARN [task-runner-0-priority-0] io.druid.segment.realtime.appenderator.FiniteAppenderatorDriver - Our segments don't exist, giving up.
2016-10-19T08:23:19,524 INFO [task-runner-0-priority-0] io.druid.segment.realtime.appenderator.AppenderatorImpl - Shutting down...

Meanwhile this was in the overlord log -
2016-10-19T08:23:19,303 INFO [qtp370356001-171] io.druid.indexing.common.actions.LocalTaskActionClient - Performing action for task[index_kafka_v2_metrics_cluster_a47237b6077ddb0_opnaifmo]: SegmentInsertAction{segments=[DataSegment{size=396764861, shardSpec=NumberedShardSpec{partitionNum=12, partitions=0}, metrics=[], dimensions=[], version='2016-10-19T06:00:00.545Z', loadSpec={type=hdfs, path=}, interval=2016-10-19T06:00:00.000Z/2016-10-19T07:00:00.000Z, dataSource='v2_metrics_cluster', binaryVersion='9'}, DataSegment{size=327245790, shardSpec=NumberedShardSpec{partitionNum=7, partitions=0}, metrics=[], dimensions=[], version='2016-10-19T07:00:00.975Z', loadSpec={type=hdfs, path=}, interval=2016-10-19T07:00:00.000Z/2016-10-19T08:00:00.000Z, dataSource='v2_metrics_cluster', binaryVersion='9'}, DataSegment{size=55834521, shardSpec=NumberedShardSpec{partitionNum=20, partitions=0}, metrics=[], dimensions=[], version='2016-10-19T08:00:00.443Z', loadSpec={type=hdfs, path=}, interval=2016-10-19T08:00:00.000Z/2016-10-19T09:00:00.000Z, dataSource='v2_metrics_cluster', binaryVersion='9'}, DataSegment{size=357963459, shardSpec=NumberedShardSpec{partitionNum=33, partitions=0}, metrics=[], dimensions=[], version='2016-10-19T05:00:01.567Z', loadSpec={type=hdfs, path=}, interval=2016-10-19T05:00:00.000Z/2016-10-19T06:00:00.000Z, dataSource='v2_metrics_cluster', binaryVersion='9'}], startMetadata=KafkaDataSourceMetadata{kafkaPartitions=KafkaPartitions{topic='mx-cluster-production-metrics', partitionOffsetMap={0=176009748}}}, endMetadata=KafkaDataSourceMetadata{kafkaPartitions=KafkaPartitions{topic='mx-cluster-production-metrics', partitionOffsetMap={0=220414028}}}}
2016-10-19T08:23:19,321 INFO [qtp370356001-152] io.druid.indexing.common.actions.LocalTaskActionClient - Performing action for task[index_kafka_v2_metrics_cluster_966f1c1b7a001cf_menkjigj]: SegmentInsertAction{segments=[DataSegment{size=357264367, shardSpec=NumberedShardSpec{partitionNum=36, partitions=0}, metrics=[], dimensions=[], version='2016-10-19T05:00:01.567Z', loadSpec={type=hdfs, path=}, interval=2016-10-19T05:00:00.000Z/2016-10-19T06:00:00.000Z, dataSource='v2_metrics_cluster', binaryVersion='9'}, DataSegment{size=328688502, shardSpec=NumberedShardSpec{partitionNum=5, partitions=0}, metrics=[], dimensions=[], version='2016-10-19T07:00:00.975Z', loadSpec={type=hdfs, path=}, interval=2016-10-19T07:00:00.000Z/2016-10-19T08:00:00.000Z, dataSource='v2_metrics_cluster', binaryVersion='9'}, DataSegment{size=55419587, shardSpec=NumberedShardSpec{partitionNum=3, partitions=0}, metrics=[], dimensions=[], version='2016-10-19T08:00:00.443Z', loadSpec={type=hdfs, path=}, interval=2016-10-19T08:00:00.000Z/2016-10-19T09:00:00.000Z, dataSource='v2_metrics_cluster', binaryVersion='9'}, DataSegment{size=396175234, shardSpec=NumberedShardSpec{partitionNum=1, partitions=0}, metrics=[], dimensions=[], version='2016-10-19T06:00:00.545Z', loadSpec={type=hdfs, path=}, interval=2016-10-19T06:00:00.000Z/2016-10-19T07:00:00.000Z, dataSource='v2_metrics_cluster', binaryVersion='9'}], startMetadata=KafkaDataSourceMetadata{kafkaPartitions=KafkaPartitions{topic='mx-cluster-production-metrics', partitionOffsetMap={8=158229668}}}, endMetadata=KafkaDataSourceMetadata{kafkaPartitions=KafkaPartitions{topic='mx-cluster-production-metrics', partitionOffsetMap={8=202436580}}}}
2016-10-19T08:23:19,327 INFO [qtp370356001-171] io.druid.metadata.IndexerSQLMetadataStorageCoordinator - Updated metadata from[KafkaDataSourceMetadata{kafkaPartitions=KafkaPartitions{topic='mx-cluster-production-metrics', partitionOffsetMap={0=176009748, 1=220256750, 2=175667526, 3=202804552, 4=158505772, 5=158445369, 6=158347444, 7=202503474, 8=158229668, 9=158129698, 10=158076757, 11=157993918, 12=157748351, 13=201366328, 14=157333088, 15=157251399, 16=157198909, 17=157139279, 18=157074283, 19=156992007, 20=156273109, 21=155401237, 22=155088780, 23=154850255, 24=154639521, 25=154498798, 26=154345135, 27=154142700, 28=154004983, 29=153935016}}}] to[KafkaDataSourceMetadata{kafkaPartitions=KafkaPartitions{topic='mx-cluster-production-metrics', partitionOffsetMap={0=220414028, 1=220256750, 2=175667526, 3=202804552, 4=158505772, 5=158445369, 6=158347444, 7=202503474, 8=158229668, 9=158129698, 10=158076757, 11=157993918, 12=157748351, 13=201366328, 14=157333088, 15=157251399, 16=157198909, 17=157139279, 18=157074283, 19=156992007, 20=156273109, 21=155401237, 22=155088780, 23=154850255, 24=154639521, 25=154498798, 26=154345135, 27=154142700, 28=154004983, 29=153935016}}}].
2016-10-19T08:23:19,342 INFO [qtp370356001-171] io.druid.metadata.IndexerSQLMetadataStorageCoordinator - Published segment [v2_metrics_cluster_2016-10-19T06:00:00.000Z_2016-10-19T07:00:00.000Z_2016-10-19T06:00:00.545Z_12] to DB
2016-10-19T08:23:19,357 INFO [qtp370356001-171] io.druid.metadata.IndexerSQLMetadataStorageCoordinator - Published segment [v2_metrics_cluster_2016-10-19T07:00:00.000Z_2016-10-19T08:00:00.000Z_2016-10-19T07:00:00.975Z_7] to DB
2016-10-19T08:23:19,372 INFO [qtp370356001-171] io.druid.metadata.IndexerSQLMetadataStorageCoordinator - Published segment [v2_metrics_cluster_2016-10-19T08:00:00.000Z_2016-10-19T09:00:00.000Z_2016-10-19T08:00:00.443Z_20] to DB
2016-10-19T08:23:19,387 INFO [qtp370356001-171] io.druid.metadata.IndexerSQLMetadataStorageCoordinator - Published segment [v2_metrics_cluster_2016-10-19T05:00:00.000Z_2016-10-19T06:00:00.000Z_2016-10-19T05:00:01.567Z_33] to DB
2016-10-19T08:23:19,392 INFO [qtp370356001-152] io.druid.metadata.IndexerSQLMetadataStorageCoordinator - Not updating metadata, compare-and-swap failure.
2016-10-19T08:23:19,426 INFO [qtp370356001-112] io.druid.indexing.common.actions.LocalTaskActionClient - Performing action for task[index_kafka_v2_metrics_cluster_966f1c1b7a001cf_menkjigj]: SegmentListUsedAction{dataSource='v2_metrics_cluster', intervals=[2016-10-19T05:00:00.000Z/2016-10-19T09:00:00.000Z]}
2016-10-19T08:23:21,085 INFO [Curator-PathChildrenCache-0] io.druid.indexing.overlord.RemoteTaskRunner - Worker[] wrote FAILED status for task [index_kafka_v2_metrics_cluster_966f1c1b7a001cf_menkjigj] on [TaskLocation{host='', port=}]
2016-10-19T08:23:21,085 INFO [Curator-PathChildrenCache-0] io.druid.indexing.overlord.RemoteTaskRunner - Worker[] completed task[index_kafka_v2_metrics_cluster_966f1c1b7a001cf_menkjigj] with status[FAILED]
2016-10-19T08:23:21,085 INFO [Curator-PathChildrenCache-0] io.druid.indexing.overlord.TaskQueue - Received FAILED status for task: index_kafka_v2_metrics_cluster_966f1c1b7a001cf_menkjigj

From the logs it seems like that two threads qtp370356001-171 and qtp370356001-152 wanted to update the datasource metadata. Initially, both threads read the commit_metadata_payload from DB and then qtp370356001-171 updated the metadata successfully whereas qtp370356001-152 failed as the old commit metadata it read earlier is not as same as commit metadata in DB now. All this happens in updateDataSourceMetadataWithHandle method of IndexerSQLMetadataStorageCoordinator.java class.
One way to solve this issue is to synchronize access to updateDataSourceMetadataWithHandle method but better way would be to retry in case of such failures. However, retryTransaction does not retry in case of RuntimeException which would be thrown in this case here - https://github.com/druid-io/druid/blob/master/server/src/main/java/io/druid/metadata/IndexerSQLMetadataStorageCoordinator.java#L342
      