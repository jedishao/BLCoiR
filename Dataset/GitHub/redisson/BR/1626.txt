Deadlock with RedissonLock used by JCache.
We've ran into a number of issues with using the Redisson implementation of JCache via bucket4j in production for rate limiting.

Actual behavior

JCache.put(K key, V value) calls RedissonLock.lock() with no lease time, resulting in RedissonLock's creating a 'watchdog' thread that continuously renews the lease on the lock in Redis. We are using the default 'lockWatchdogTimeout' of 30 seconds so this thread runs every 10 seconds. What we've seen is in rare cases this watchdog thread never gets canceled, meaning it continues renewing the lease indefinitely until the instance containing the thread is restarted. This causes deadlock of all other threads trying to grab the lock and can ultimately bring down an application as threads build up.

Threads using RedissonLock will wait forever for a lock to be released. There is no timeout when waiting for the lock.

    public void lockInterruptibly(long leaseTime, TimeUnit unit) throws InterruptedException {
            ...
            while (true) {
                ttl = tryAcquire(leaseTime, unit, threadId);
                // lock acquired
                if (ttl == null) {
                    break;
                }

                // waiting for message
                if (ttl >= 0) {
                    getEntry(threadId).getLatch().tryAcquire(ttl, TimeUnit.MILLISECONDS);
                } else {
                    getEntry(threadId).getLatch().acquire();
                }
            }
The 'unlock' method in RedissonLock can fail for a number of reasons -- e.g., timing out trying to unlock with Redis after 3 seconds (this happened in our case). When the unlock fails the watchdog thread is not canceled. This means the instance would have to be restarted to release the lock.
public RFuture<Void> unlockAsync(final long threadId) {
  final RPromise<Void> result = newPromise();
        RFuture<Boolean> future = unlockInnerAsync(threadId);

        future.addListener(new FutureListener<Boolean>() {
            @Override
            public void operationComplete(Future<Boolean> future) throws Exception {
                if (!future.isSuccess()) {
                    result.tryFailure(future.cause());
                    return;
                }

                Boolean opStatus = future.getNow();
                if (opStatus == null) {
                    IllegalMonitorStateException cause = new IllegalMonitorStateException("attempt to unlock lock, not locked by current thread by node id: "
                            + id + " thread-id: " + threadId);
                    result.tryFailure(cause);
                    return;
                }
                if (opStatus) {
                    cancelExpirationRenewal();
                }
                result.trySuccess(null);
            }
        });

        return result;
Expected behavior

A 'watchdog' thread should not exist. This is prone to issues where it never gets destroyed and a lock is held forever. A lease time should be used to ensure the lock is never held forever and somehow it should be verified that the lock is still held by the caller when making updates with it (an atomic check at update time) in case the first thread doesn't execute its update within the lease time and another thread grabs the lock.

Threads should not wait forever for the lock. There should be some configurable timeout.

A timeout on 'unlock' should be retried, but the lease time in 1 should handle any failure to unlock. If for some reason the 'watchdog' thread is kept, the unlock needs to ensure it is canceled if it fails.

Steps to reproduce or test case

Issues verified via redisson code review.

Can reproduce by forcing a timeout in redis on the 'unlock' call made by RedissonLock, leaving the 'watchdog' thread around to keep holding the lock and observing that all other threads wait forever for the lock.

Redis version

Redis 3.2.4 via AWS ElastiCache

Redisson version

Redisson 3.5.4 but the same issues appear to be present in 3.8.0 as well

Redisson configuration

        final Config redissonConfig = new Config();
        redissonConfig.setCodec( new SerializationCodec() );
        redissonConfig.setUseLinuxNativeEpoll( false );
        redissonConfig.useReplicatedServers()
                      .addNodeAddress( redisNodes );
Stacktraces

Timeout on 'unlock':
time 01:16:21.500

javax.cache.processor.EntryProcessorException: org.redisson.client.RedisTimeoutException: Redis server response timeout (3000 ms) occured for command: (EVAL) with params:
[if (redis.call('exists', KEYS[1]) == 0) then redis.call('publish', KEYS[2], ARGV[1]); return 1; end;..., 2, {buckets}:SiBJapgTpcxaB*******Sw:key,
redisson_lock__channel:{buckets}:SiBJapgTpcxa*******Sw:key, 0, 30000, a6688b3a-07dc-4347-bd8c-060a3a86b32f:174] channel: [id: *****, L:/**********:******* - R:******.cache.amazonaws.com/*********:******]
	at org.redisson.jcache.JCache.invoke(JCache.java:2210) ~[redisson-3.5.4.jar!/:?]
	at io.github.bucket4j.grid.jcache.JCacheProxy.execute(JCacheProxy.java:39) ~[bucket4j-jcache-2.1.0.jar!/:?]
	at io.github.bucket4j.grid.GridBucket.execute(GridBucket.java:108) ~[bucket4j-core-2.1.0.jar!/:?]
	at io.github.bucket4j.grid.GridBucket.tryConsumeAndReturnRemainingTokensImpl(GridBucket.java:67) ~[bucket4j-core-2.1.0.jar!/:?]
	at io.github.bucket4j.AbstractBucket.tryConsumeAndReturnRemaining(AbstractBucket.java:113) ~[bucket4j-core-2.1.0.jar!/:?]
	...
Caused by: org.redisson.client.RedisTimeoutException: Redis server response timeout (3000 ms) occured for command: (EVAL) with params:
[if (redis.call('exists', KEYS[1]) == 0) then redis.call('publish', KEYS[2], ARGV[1]); return 1; end;..., 2, {buckets}:SiBJapgTpcxaB************:key,
redisson_lock__channel:{buckets}:SiBJapgTpcx***********qSw:key, 0, 30000, a6688b3a-07dc-4347-bd8c-060a3a86b32f:174] channel: [id:********8, L:/*****:*******- R:***********.cache.amazonaws.com/*****:****]
	at org.redisson.command.CommandAsyncService$11.run(CommandAsyncService.java:698) ~[redisson-3.5.4.jar!/:?]
	at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:663) ~[netty-common-4.1.15.Final.jar!/:4.1.15.Final]
	at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:738) ~[netty-common-4.1.15.Final.jar!/:4.1.15.Final]
	at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:466) ~[netty-common-4.1.15.Final.jar!/:4.1.15.Final]
	... 1 more
Subsequent 'watchdog' thread timing out, actually saving us in this case because when the 'watchdog' thread fails it doesn't reschedule itself and the lock got released:
time 01:16:31.300

Can't update lock {buckets}:SiBJapgTpcxaBHBLc5ZqSw:key expiration
org.redisson.client.RedisTimeoutException: Redis server response timeout (3000 ms) occured for command: (EVAL) with params:
[if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then redis.call('pexpire', KEYS[1], ARGV[1]); retu..., 1, {buckets}:SiBJapgTpcxaB*******qSw:key, 30000,
 a6688b3a-07dc-4347-bd8c-060a3a86b32f:174] channel: [id: ******, L:/*********:******* - R:***********.cache.amazonaws.com/*******:*****]
	at org.redisson.command.CommandAsyncService$11.run(CommandAsyncService.java:698) [redisson-3.5.4.jar!/:?]
	at io.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:663) [netty-common-4.1.15.Final.jar!/:4.1.15.Final]
	at io.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:738) [netty-common-4.1.15.Final.jar!/:4.1.15.Final]
	at io.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:466) [netty-common-4.1.15.Final.jar!/:4.1.15.Final]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
