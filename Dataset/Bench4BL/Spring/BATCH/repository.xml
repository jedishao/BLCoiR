<?xml version = "1.0" encoding = "UTF-8" ?>
<bugrepository name="BATCH">
	<bug id="244" opendate="2007-12-02 19:42:17" fixdate="2007-12-04 04:17:39" resolution="Fixed">
		<buginformation>
			<summary>Repeated processing of items does not work if exception is in first chunk</summary>
			<description>If an exception occurs during the processing of a chunk an ExceptionHandler in the StepOperations can be used to signal the framework to rollback the current chunk. It is assumed that the default behaviour of the DefaultStepExecutor used in all the examples has the ability to process all items again that could be handled successfully in the previous execution of the chunk. The item which caused the processing of the chunk to fail should be skipped. Unfortunately this does not work out of the box. An attached example which is based on tradeJob.xml should show this.</description>
			<version>1.0-m3</version>
			<fixedVersion>1.0-m3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.io.file.support.ResourceLineReader.java</file>
			<file type="M">org.springframework.batch.sample.item.processor.TradeProcessor.java</file>
			<file type="M">org.springframework.batch.io.file.support.ResourceLineReaderTests.java</file>
			<file type="M">org.springframework.batch.io.driving.IbatisDrivingQueryInputSource.java</file>
		</fixedFiles>
	</bug>
	<bug id="252" opendate="2007-12-09 19:47:25" fixdate="2007-12-10 07:00:22" resolution="Fixed">
		<buginformation>
			<summary>HibernateFailureJob does not fail as expected</summary>
			<description>HibernateFailureJob testcase expects the job to end with exception, but does not check it really does. In fact the job doesn&amp;amp;apos;t fail and the assert in catch block is never executed (although it would have passed if it was).</description>
			<version>1.0-m3</version>
			<fixedVersion>1.0.0.m4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.sample.HibernateFailureJobFunctionalTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="250" opendate="2007-12-07 23:20:57" fixdate="2007-12-11 21:51:28" resolution="Fixed">
		<buginformation>
			<summary>Wrong DB Schema for DB2 for z/OS</summary>
			<description>The batch tables defnied in the schema definition for DB2 do not work out of the box with the framework DAOs when they are created on DB2 for z/OS. There&amp;amp;apos;s a problem with the SCHEDULE_DATE column.</description>
			<version>1.0-m3</version>
			<fixedVersion>1.0.0.m4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.execution.repository.dao.SqlJobDao.java</file>
		</fixedFiles>
	</bug>
	<bug id="212" opendate="2007-11-20 18:53:05" fixdate="2007-12-18 04:48:04" resolution="Fixed">
		<buginformation>
			<summary>Merge InputSource with ItemProvider</summary>
			<description>Merge InputSource with ItemProvider - there is no real need for two interfaces, and ItemProvider is probably fine to keep.  The only complication is recovery - it needs to be delegated to a new marker interface (maybe replacing Recoverable).</description>
			<version>1.0-m3</version>
			<fixedVersion>1.0.0.m4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.retry.policy.ItemReaderRetryPolicy.java</file>
			<file type="M">org.springframework.batch.execution.launch.SimpleJobTests.java</file>
			<file type="M">org.springframework.batch.sample.tasklet.ExceptionRestartableTaskletTests.java</file>
			<file type="M">org.springframework.batch.sample.item.provider.StagingItemReaderTests.java</file>
			<file type="M">org.springframework.batch.retry.callback.ItemReaderRetryCallbackTests.java</file>
			<file type="M">org.springframework.batch.execution.tasklet.RestartableItemOrientedTaskletTests.java</file>
			<file type="M">org.springframework.batch.execution.tasklet.ItemOrientedTaskletTests.java</file>
			<file type="M">org.springframework.batch.retry.callback.ItemReaderRetryCallback.java</file>
			<file type="M">org.springframework.batch.execution.step.simple.DefaultStepExecutorTests.java</file>
			<file type="M">org.springframework.batch.execution.tasklet.ItemOrientedTasklet.java</file>
			<file type="M">org.springframework.batch.item.processor.PropertyExtractingDelegatingItemProcessor.java</file>
			<file type="D">org.springframework.batch.retry.policy.ItemProviderRetryPolicyTests.java</file>
			<file type="D">org.springframework.batch.item.ItemProvider.java</file>
			<file type="M">org.springframework.batch.sample.domain.PersonService.java</file>
			<file type="M">org.springframework.batch.sample.tasklet.ExceptionRestartableTasklet.java</file>
			<file type="M">org.springframework.batch.sample.tasklet.SimpleTradeTaskletTests.java</file>
			<file type="M">org.springframework.batch.io.file.support.ResourceLineReader.java</file>
			<file type="M">org.springframework.batch.io.driving.FooInputSource.java</file>
			<file type="D">org.springframework.batch.io.sql.AbstractJdbcInputSourceIntegrationTests.java</file>
			<file type="M">org.springframework.batch.retry.jms.ExternalRetryTests.java</file>
			<file type="D">org.springframework.batch.io.file.support.DefaultFlatFileInputSource.java</file>
			<file type="D">org.springframework.batch.io.driving.SingleColumnJdbcDrivingQueryInputSourceIntegrationTests.java</file>
			<file type="D">org.springframework.batch.io.file.support.SimpleFlatFileInputSource.java</file>
			<file type="D">org.springframework.batch.io.driving.IbatisInputSourceIntegrationTests.java</file>
			<file type="M">org.springframework.batch.support.AbstractDelegatorTests.java</file>
			<file type="M">org.springframework.batch.sample.FixedLengthImportJobFunctionalTests.java</file>
			<file type="D">org.springframework.batch.retry.callback.ItemProviderRetryCallbackTests.java</file>
			<file type="D">org.springframework.batch.retry.callback.ItemProviderRetryCallback.java</file>
			<file type="M">org.springframework.batch.repeat.RepeatCallback.java</file>
			<file type="D">org.springframework.batch.item.provider.TransactionAwareListItemProviderTests.java</file>
			<file type="M">org.springframework.batch.item.ItemProviderTests.java</file>
			<file type="D">org.springframework.batch.io.cursor.HibernateCursorInputSource.java</file>
			<file type="M">org.springframework.batch.io.driving.support.IbatisKeyGenerator.java</file>
			<file type="D">org.springframework.batch.item.provider.InputSourceItemProviderTests.java</file>
			<file type="D">org.springframework.batch.retry.ListItemProviderRecoverer.java</file>
			<file type="D">org.springframework.batch.io.file.support.StaxEventReaderInputSourceTests.java</file>
			<file type="D">org.springframework.batch.item.provider.InputSourceItemProvider.java</file>
			<file type="D">org.springframework.batch.item.provider.AggregateItemProviderTests.java</file>
			<file type="M">org.springframework.batch.item.FailedItemIdentifier.java</file>
			<file type="D">org.springframework.batch.item.provider.JmsItemProviderTests.java</file>
			<file type="D">org.springframework.batch.execution.tasklet.ItemProviderProcessTasklet.java</file>
			<file type="D">org.springframework.batch.item.processor.DelegatingItemProcessor.java</file>
			<file type="D">org.springframework.batch.io.file.support.DefaultFlatFileInputSourceTests.java</file>
			<file type="D">org.springframework.batch.io.driving.IbatisDrivingQueryInputSource.java</file>
			<file type="D">org.springframework.batch.io.support.AbstractDataSourceInputSourceIntegrationTests.java</file>
			<file type="M">org.springframework.retry.jms.SynchronousTests.java</file>
			<file type="D">org.springframework.batch.io.InputSource.java</file>
			<file type="D">org.springframework.batch.io.driving.DrivingQueryInputSourceTests.java</file>
			<file type="D">org.springframework.batch.item.provider.JmsItemProvider.java</file>
			<file type="D">org.springframework.batch.io.file.support.StaxEventReaderInputSource.java</file>
			<file type="M">org.springframework.batch.sample.tasklet.SimpleTradeTasklet.java</file>
			<file type="D">org.springframework.batch.support.AbstractDelegator.java</file>
			<file type="D">org.springframework.batch.sample.item.provider.OrderItemProvider.java</file>
			<file type="M">org.springframework.batch.io.support.AbstractTransactionalIoSourceTests.java</file>
			<file type="D">org.springframework.batch.sample.item.provider.StagingItemProvider.java</file>
			<file type="M">org.springframework.batch.repeat.support.ChunkedRepeatTests.java</file>
			<file type="D">org.springframework.batch.item.provider.DelegatingItemProvider.java</file>
			<file type="D">org.springframework.batch.sample.item.provider.OrderItemProviderTests.java</file>
			<file type="D">org.springframework.batch.execution.tasklet.RestartableItemProviderTasklet.java</file>
			<file type="D">org.springframework.batch.io.oxm.AbstractStaxEventReaderInputSourceTests.java</file>
			<file type="D">org.springframework.batch.repeat.callback.ItemProviderRepeatCallback.java</file>
			<file type="D">org.springframework.batch.item.provider.DelegatingItemProviderIntegrationTests.java</file>
			<file type="D">org.springframework.batch.item.provider.AggregateItemProvider.java</file>
			<file type="M">org.springframework.batch.io.oxm.CastorUnmarshallingTests.java</file>
			<file type="M">org.springframework.batch.repeat.support.AsynchronousRepeatTests.java</file>
			<file type="D">org.springframework.batch.sample.item.provider.StagingItemProviderTests.java</file>
			<file type="D">org.springframework.batch.io.cursor.JdbcCursorInputSourceIntegrationTests.java</file>
			<file type="M">org.springframework.batch.retry.jms.SynchronousTests.java</file>
			<file type="D">org.springframework.batch.execution.tasklet.RestartableItemProviderTaskletTests.java</file>
			<file type="M">org.springframework.batch.io.driving.support.MultipleColumnJdbcKeyGenerator.java</file>
			<file type="D">org.springframework.batch.io.driving.DrivingQueryInputSource.java</file>
			<file type="M">org.springframework.batch.item.processor.DelegatingItemProcessorIntegrationTests.java</file>
			<file type="D">org.springframework.batch.execution.tasklet.ItemProviderProcessTaskletTests.java</file>
			<file type="D">org.springframework.batch.io.cursor.HibernateCursorInputSourceIntegrationTests.java</file>
			<file type="M">org.springframework.batch.io.oxm.XStreamUnmarshallingTests.java</file>
			<file type="M">org.springframework.batch.repeat.support.AbstractTradeBatchTests.java</file>
			<file type="D">org.springframework.batch.item.provider.ValidatingItemProvider.java</file>
			<file type="D">org.springframework.batch.io.file.support.SimpleFlatFileInputSourceTests.java</file>
			<file type="D">org.springframework.batch.item.provider.AbstractItemProvider.java</file>
			<file type="D">org.springframework.batch.io.cursor.JdbcCursorInputSource.java</file>
			<file type="M">org.springframework.batch.jms.ExternalRetryInBatchTests.java</file>
			<file type="M">org.springframework.batch.io.support.AbstractTransactionalIoSource.java</file>
			<file type="D">org.springframework.batch.repeat.callback.ItemProviderRepeatCallbackTests.java</file>
			<file type="D">org.springframework.batch.item.provider.ValidatingItemProviderTests.java</file>
			<file type="M">org.springframework.batch.repeat.support.SimpleRepeatTemplateTests.java</file>
			<file type="D">org.springframework.batch.io.driving.MultipleColumnJdbcDrivingQueryInputSourceIntegrationTests.java</file>
			<file type="D">org.springframework.batch.retry.policy.ItemProviderRetryPolicy.java</file>
			<file type="D">org.springframework.batch.item.provider.ListItemProviderTests.java</file>
			<file type="D">org.springframework.batch.item.provider.ListItemProvider.java</file>
			<file type="D">org.springframework.batch.io.cursor.HibernateCursorInputSourceStatefulIntegrationTests.java</file>
		</fixedFiles>
		<links>
			<link type="Depends" description="depends on">222</link>
			<link type="Depends" description="is depended on by">230</link>
		</links>
	</bug>
	<bug id="170" opendate="2007-10-15 09:14:22" fixdate="2007-12-19 00:01:56" resolution="Fixed">
		<buginformation>
			<summary>Concurrent modification of StepExecution when running an asynchrounous step operation</summary>
			<description>Use of a hibernateJobDao eventually results in a StaleObjectStateException when running an asynchrounous step operation:
  &amp;lt;bean id="myStepExecutor" class="org.springframework.batch.execution.step.simple.SimpleStepExecutor" scope="prototype"&amp;gt;
    &amp;lt;property name="transactionManager" ref="txManager" /&amp;gt;
    &amp;lt;property name="repository" ref="simpleJobRepository" /&amp;gt;  
    &amp;lt;property name="stepOperations"&amp;gt;
      &amp;lt;bean class="org.springframework.batch.repeat.support.TaskExecutorRepeatTemplate"&amp;gt;
        &amp;lt;property name="taskExecutor" ref="threadPoolTaskExecutor"/&amp;gt;        
      &amp;lt;/bean&amp;gt;
    &amp;lt;/property&amp;gt;    
  &amp;lt;/bean&amp;gt;
See:
http://forum.springframework.org/showthread.php?t=44884</description>
			<version>1.0-m3</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.domain.StepContribution.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.SqlStepDao.java</file>
			<file type="D">org.springframework.batch.execution.repository.dao.MockJdbcTemplate.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.SqlStepDaoPrefixTests.java</file>
			<file type="M">org.springframework.batch.core.domain.EntityTests.java</file>
			<file type="M">org.springframework.batch.core.domain.Entity.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.AbstractStepDaoTests.java</file>
			<file type="M">org.springframework.batch.execution.step.simple.SimpleStepExecutor.java</file>
			<file type="M">org.springframework.batch.execution.repository.SimpleJobRepository.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.SqlStepDaoTests.java</file>
			<file type="M">org.springframework.batch.core.domain.StepExecution.java</file>
			<file type="M">org.springframework.batch.sample.item.provider.StagingItemReader.java</file>
			<file type="M">org.springframework.batch.core.domain.StepExecutionTests.java</file>
			<file type="M">org.springframework.batch.execution.repository.SimpleJobRepositoryTests.java</file>
			<file type="M">org.springframework.batch.core.domain.JobInstance.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.SqlJobDaoQueryTests.java</file>
			<file type="M">org.springframework.batch.execution.step.simple.DefaultStepExecutorTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="261" opendate="2007-12-18 21:35:24" fixdate="2007-12-19 07:19:22" resolution="Fixed">
		<buginformation>
			<summary>FixedLengthTokenizer by default maps zero padded numeric fields as octal.</summary>
			<description>A common formatting for numeric fields in simple flat batch input files is to pad the numeric data with leading zeros. e.g. the value 9 in a field of width 7 would be represented "0000009".  Using just the DefaultFlatFileInputSource and the FixedLengthTokenizer from Spring batch 1.0-m3 to parse the input record causes the following error, as, by default, the conversion is done using Long.decode and this assumes that leading zeros imply octal. This issue was raised with Lucas Ward at the  Spring Experience  2007 who said he considered this effect on batch input data  to be a bug, and requested that we raise this issue on the JIRA.
Exception in thread "main" org.springframework.batch.io.exception.FlatFileParsingException: Parsing error
	at org.springframework.batch.io.file.support.SimpleFlatFileInputSource.read(SimpleFlatFileInputSource.java:198)
&amp;lt;snip&amp;gt;
Caused by: org.springframework.beans.PropertyBatchUpdateException; nested PropertyAccessExceptions (1) are:
PropertyAccessException 1: org.springframework.beans.TypeMismatchException: Failed to convert property value of type [java.lang.String] to required type [java.lang.Long] for property &amp;amp;apos;recordSequenceNumber&amp;amp;apos;; nested exception is java.lang.NumberFormatException: For input string: "0000009"
Here is a cut down version of the relevant beans in the XML config. A simple POJO was created to receive the data with the type of RecordSequenceNumber being Long.
	&amp;lt;bean id="InterchangeTokenizer"
		class="org.springframework.batch.io.file.support.transform.FixedLengthTokenizer"&amp;gt;
		&amp;lt;property name="names"
			value="RecordSequenceNumber" /&amp;gt;
		&amp;lt;property name="columns"
			value="4-11" /&amp;gt;
	&amp;lt;/bean&amp;gt;
	&amp;lt;bean id="inputSource"
		class="org.springframework.batch.io.file.support.DefaultFlatFileInputSource"&amp;gt;
		&amp;lt;property name="resource" value="file:input.txt" /&amp;gt;
		&amp;lt;property name="fieldSetMapper" ref="InterchangeMapper" /&amp;gt;
		&amp;lt;property name="tokenizer" ref="InterchangeTokenizer" /&amp;gt;
	&amp;lt;/bean&amp;gt;
	&amp;lt;bean id="InterchangeMapper"
		class="org.springframework.batch.io.file.support.mapping.BeanWrapperFieldSetMapper"&amp;gt;
		&amp;lt;property name="targetType"
			value="com.aciworldwide.backoffice.interchange.InterchangeIncomingTransaction" /&amp;gt;
	&amp;lt;/bean&amp;gt;
It would be better if the default for processing this type of field was to assume BASE-10, or, perhaps, alternatively if there was a way of specifiying the numeric base of the fields on the tokenizer.</description>
			<version>1.0-m3</version>
			<fixedVersion>1.0.0.m4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.io.file.FieldSetTests.java</file>
		</fixedFiles>
		<links>
			<link type="Depends" description="depends on">154</link>
		</links>
	</bug>
	<bug id="243" opendate="2007-11-30 00:12:40" fixdate="2007-12-20 22:21:56" resolution="Fixed">
		<buginformation>
			<summary>Register Job twice if beanName property is used to define a job name</summary>
			<description>When the "jobConfiguration" bean is defined:
      	&amp;lt;bean id="jobConfiguration" parent="simpleJob"&amp;gt;
		&amp;lt;property name="beanName" value="ibSplit"/&amp;gt;
		&amp;lt;property name="steps"&amp;gt;
                .... ... ...
      the framework (org.springframework.batch.execution.configuration.MapJobConfigurationRegistry) registers the job with the "beanName" value, and then re-registers it with the bean&amp;amp;apos;s "id" value due to the BeanAwareness:
    springframework/batch/core/configuration/JobConfiguration.java:
    /** 

The callback from 
{@link BeanNameAware}
 comes after the setters, so it
will always overwrite the name with the bean id.

@see org.springframework.beans.factory.BeanNameAware#setBeanName(java.lang.String)
     */
    public void setBeanName(String name) 
{
        this.name = name;
    }
 

    Hence I commented &amp;lt;!-- &amp;lt;property name="beanName" value="ibSplit"/&amp;gt; --&amp;gt; and changed the "id" to the actual jobname. I guess the way it works right now is the intended behavior, but that is not how it worked before according to the code I picked up.
</description>
			<version>1.0-m3</version>
			<fixedVersion>1.0.0.m4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.execution.configuration.JobConfigurationRegistryBeanPostProcessorTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="262" opendate="2007-12-20 23:26:37" fixdate="2007-12-21 19:42:02" resolution="Fixed">
		<buginformation>
			<summary>Hibernate Job  blocks on flush</summary>
			<description>Hibernate Job  blocks on flush (using real database).  The driving query input source is putting a range lock on the Customer objects.</description>
			<version>1.0-m3</version>
			<fixedVersion>1.0.0.m4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.sample.AbstractCustomerCreditIncreaseTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="285" opendate="2008-01-14 07:44:54" fixdate="2008-01-15 20:34:46" resolution="Fixed">
		<buginformation>
			<summary>Problem with DelimitedLineTokenizer and whitespace after quote</summary>
			<description>The DelimitedLineTokenizer doesn&amp;amp;apos;t seem to gracefully handle lines that end with a quoted value that also has extra whitespaces after the closing quote. ie:
(whitespace replaced by _)
a,b,"c"_
returns c" as the string value at index 2.
a,b,"c"__
returns "c" as the string value at index 2.
I&amp;amp;apos;ll attach a patch that adds both test cases to the DelimitedLineTokenizerTests class.</description>
			<version>1.0.0.m4</version>
			<fixedVersion>1.0.0.m4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.io.file.transform.DelimitedLineTokenizer.java</file>
			<file type="M">org.springframework.batch.io.file.transform.DelimitedLineTokenizerTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="293" opendate="2008-01-15 07:08:00" fixdate="2008-01-16 00:18:27" resolution="Fixed">
		<buginformation>
			<summary>ResourceLineReader eats newlines within a record&amp;apos;s field</summary>
			<description>Considering the lines:
1,2,"3
4"
5,6,7
The expected return value of two consecutive calls to the read() method of ResourceLineReader are (without &amp;lt; and &amp;gt;):
call 1:
&amp;lt;1,2,"3
4"&amp;gt;
call 2:
&amp;lt;5,6,7&amp;gt;
But currently, call 1 returns 
&amp;lt;1,2,"34"
&amp;gt;
(notice that the newline is misplaced...)</description>
			<version>1.0.0.m4</version>
			<fixedVersion>1.0.0.m4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.io.file.separator.ResourceLineReader.java</file>
			<file type="M">org.springframework.batch.io.file.ResourceLineReaderTests.java</file>
			<file type="M">org.springframework.batch.io.file.separator.RecordSeparatorPolicy.java</file>
		</fixedFiles>
	</bug>
	<bug id="296" opendate="2008-01-16 00:56:15" fixdate="2008-01-16 23:12:25" resolution="Fixed">
		<buginformation>
			<summary>rollback of first chunk fails</summary>
			<description>The attached test (a modification of the current one) shows that a roll back that occurs in the first chunk, of a step, does not properly reset the input source to the first record. But, instead, continues with the next record after the rollback is executed.
I believe the solution is to call the inputreader.mark() as part of the open() method in DefaultFlatFileInputSource.java</description>
			<version>1.0-m3</version>
			<fixedVersion>1.0-m3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.io.file.DefaultFlatFileItemReaderTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="281" opendate="2008-01-12 22:10:48" fixdate="2008-01-20 23:41:31" resolution="Fixed">
		<buginformation>
			<summary>Null fields cause problems in Oracle and Derby</summary>
			<description>Null fields cause problems in Oracle and Derby.  See forum (http://forum.springframework.org/showthread.php?t=46821) for more information.</description>
			<version>1.0-m3</version>
			<fixedVersion>1.0.0.m4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.execution.repository.dao.AbstractJobDaoTests.java</file>
			<file type="M">org.springframework.batch.execution.runtime.ScheduledJobIdentifier.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.JdbcJobDao.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.JdbcJobDaoTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="305" opendate="2008-01-22 06:32:20" fixdate="2008-01-23 20:41:50" resolution="Fixed">
		<buginformation>
			<summary>ItemProvider still referenced in comments / variable naming in ItemOrientedTasklet</summary>
			<description>In ItemOrientedTasklet, parameter and member field are called itemProvider but method name and type are ItemReader - this is inconsistent. Additionally, ItemReader is still referred to as ItemProvider inconsistently throughout comments.</description>
			<version>1.0-m3</version>
			<fixedVersion>1.0.0.m4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.reader.ItemReaderAdapter.java</file>
			<file type="M">org.springframework.batch.item.reader.DelegatingItemReaderIntegrationTests.java</file>
			<file type="M">org.springframework.batch.item.reader.ValidatingItemReader.java</file>
			<file type="M">org.springframework.batch.execution.tasklet.ItemOrientedTaskletTests.java</file>
			<file type="M">org.springframework.batch.item.processor.CompositeItemProcessor.java</file>
			<file type="M">org.springframework.batch.execution.tasklet.ItemOrientedTasklet.java</file>
		</fixedFiles>
	</bug>
	<bug id="312" opendate="2008-01-23 20:25:45" fixdate="2008-01-23 22:50:54" resolution="Fixed">
		<buginformation>
			<summary>Fix JMX demo now that JobIdentifier has been replaced with JobParameters</summary>
			<description>Fix JMX demo now that JobIdentifier has been replaced with JobParameters</description>
			<version>1.0-m3</version>
			<fixedVersion>1.0.0.m4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.execution.bootstrap.support.ExportedJobLauncher.java</file>
		</fixedFiles>
	</bug>
	<bug id="192" opendate="2007-11-07 01:16:40" fixdate="2008-01-24 02:58:21" resolution="Fixed">
		<buginformation>
			<summary>ScheduledJobIdentifier.scheduleDate can cause issues because it is java.util.Date</summary>
			<description>ScheduledJobIdentifier.scheduleDate is a java.util.Date, rather than a java.sql.Date.  This makes sense from a domain perspective, since tying our domains objects to java.sql.* wouldn&amp;amp;apos;t be good.  However, older versions of DB2 may have issues converting from from util.Date to sql.Date.  So far I have only seen this in the sql daos, but I still need to do more testing with Hibernate.  I was able to create a work around by creating a custom factory that would create the schedule date as a java.sql.Date, since it extends util.Date, however, it might be worth while to just translate to sql.Date in the sql daos, to avoid any issues.
If it is decided that we should stay completely in java.util.Date, and out of java.sql.*, then Timestamps would also need to be modfied in the *Execution classes as well, and would definitely require some translation in sql, and some testing with Hibernate to see how it would handle the conversion.</description>
			<version>1.0-m2</version>
			<fixedVersion>1.0.0.m4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.execution.repository.dao.AbstractJobDaoTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="322" opendate="2008-01-28 09:48:29" fixdate="2008-01-28 21:05:40" resolution="Fixed">
		<buginformation>
			<summary>Keyword  KEY is not allowed in the script mysql</summary>
			<description>when you run spring batch with mysql, i have a sqlexception. 
after analyse, i think that the keyword key in table BATCH_JOB_INSTANCE_PROPERTIES is not authorized in mysql. To fix this bug you must modify the name of this field, and modify the org.springframework.batch.execution.repository.dao.JdbcJobDao
my stack trace
00:32:36,290  INFO main FootballJobFunctionalTests:210 - Loading context for locations: jobs/footballJob.xml
java.sql.SQLException: Syntax error or access violation: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &amp;amp;apos;VARCHAR(100) NOT NULL , 
	STRING_VAL VARCHAR(250) , 
	DATE_VAL TIMESTAMP ,
	LONG&amp;amp;apos; at line 4
	at org.gjt.mm.mysql.MysqlIO.sendCommand(MysqlIO.java:508)
	at org.gjt.mm.mysql.MysqlIO.sqlQueryDirect(MysqlIO.java:561)
	at org.gjt.mm.mysql.MysqlIO.sqlQuery(MysqlIO.java:646)
	at org.gjt.mm.mysql.Connection.execSQL(Connection.java:973)
	at org.gjt.mm.mysql.Connection.execSQL(Connection.java:897)
	at org.gjt.mm.mysql.Statement.execute(Statement.java:598)
	at org.gjt.mm.mysql.jdbc2.Statement.execute(Statement.java:116)
	at org.springframework.jdbc.core.JdbcTemplate$1ExecuteStatementCallback.doInStatement(JdbcTemplate.java:397)
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:371)
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:404)
	at test.jdbc.datasource.InitializingDataSourceFactoryBean$1.doInTransaction(InitializingDataSourceFactoryBean.java:119)
	at org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:128)
	at test.jdbc.datasource.InitializingDataSourceFactoryBean.doExecuteScript(InitializingDataSourceFactoryBean.java:103)
	at test.jdbc.datasource.InitializingDataSourceFactoryBean.createInstance(InitializingDataSourceFactoryBean.java:91)
	at org.springframework.beans.factory.config.AbstractFactoryBean.afterPropertiesSet(AbstractFactoryBean.java:120)
	at test.jdbc.datasource.InitializingDataSourceFactoryBean.afterPropertiesSet(InitializingDataSourceFactoryBean.java:76)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1390)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1359)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:540)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory$1.run(AbstractAutowireCapableBeanFactory.java:485)
	at java.security.AccessController.doPrivileged(Native Method)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:455)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:251)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:169)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:248)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:170)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:407)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:735)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:369)
	at org.springframework.context.support.ClassPathXmlApplicationContext.&amp;lt;init&amp;gt;(ClassPathXmlApplicationContext.java:122)
	at org.springframework.context.support.ClassPathXmlApplicationContext.&amp;lt;init&amp;gt;(ClassPathXmlApplicationContext.java:66)
	at org.springframework.batch.sample.AbstractBatchLauncherTests.createApplicationContext(AbstractBatchLauncherTests.java:53)
	at org.springframework.test.AbstractSingleSpringContextTests.loadContextLocations(AbstractSingleSpringContextTests.java:212)
	at org.springframework.test.AbstractSingleSpringContextTests.loadContext(AbstractSingleSpringContextTests.java:187)
	at org.springframework.test.AbstractSpringContextTests.getContext(AbstractSpringContextTests.java:140)
	at org.springframework.test.AbstractSingleSpringContextTests.setUp(AbstractSingleSpringContextTests.java:100)
	at junit.framework.TestCase.runBare(TestCase.java:125)
	at org.springframework.test.ConditionalTestCase.runBare(ConditionalTestCase.java:76)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:128)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:460)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:673)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:386)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:196)
java.sql.SQLException: Syntax error or access violation: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &amp;amp;apos;VARCHAR(100) NOT NULL , 
	STRING_VAL VARCHAR(250) , 
	DATE_VAL TIMESTAMP ,
	LONG&amp;amp;apos; at line 4
	at org.gjt.mm.mysql.MysqlIO.sendCommand(MysqlIO.java:508)
	at org.gjt.mm.mysql.MysqlIO.sqlQueryDirect(MysqlIO.java:561)
	at org.gjt.mm.mysql.MysqlIO.sqlQuery(MysqlIO.java:646)
	at org.gjt.mm.mysql.Connection.execSQL(Connection.java:973)
	at org.gjt.mm.mysql.Connection.execSQL(Connection.java:897)
	at org.gjt.mm.mysql.Statement.execute(Statement.java:598)
	at org.gjt.mm.mysql.jdbc2.Statement.execute(Statement.java:116)
	at org.springframework.jdbc.core.JdbcTemplate$1ExecuteStatementCallback.doInStatement(JdbcTemplate.java:397)
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:371)
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:404)
	at test.jdbc.datasource.InitializingDataSourceFactoryBean$1.doInTransaction(InitializingDataSourceFactoryBean.java:119)
	at org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:128)
	at test.jdbc.datasource.InitializingDataSourceFactoryBean.doExecuteScript(InitializingDataSourceFactoryBean.java:103)
	at test.jdbc.datasource.InitializingDataSourceFactoryBean.createInstance(InitializingDataSourceFactoryBean.java:91)
	at org.springframework.beans.factory.config.AbstractFactoryBean.afterPropertiesSet(AbstractFactoryBean.java:120)
	at test.jdbc.datasource.InitializingDataSourceFactoryBean.afterPropertiesSet(InitializingDataSourceFactoryBean.java:76)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1390)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1359)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:540)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory$1.run(AbstractAutowireCapableBeanFactory.java:485)
	at java.security.AccessController.doPrivileged(Native Method)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:455)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:251)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:169)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:248)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:170)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:407)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:735)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:369)
	at org.springframework.context.support.ClassPathXmlApplicationContext.&amp;lt;init&amp;gt;(ClassPathXmlApplicationContext.java:122)
	at org.springframework.context.support.ClassPathXmlApplicationContext.&amp;lt;init&amp;gt;(ClassPathXmlApplicationContext.java:66)
	at org.springframework.batch.sample.AbstractBatchLauncherTests.createApplicationContext(AbstractBatchLauncherTests.java:53)
	at org.springframework.test.AbstractSingleSpringContextTests.loadContextLocations(AbstractSingleSpringContextTests.java:212)
	at org.springframework.test.AbstractSingleSpringContextTests.loadContext(AbstractSingleSpringContextTests.java:187)
	at org.springframework.test.AbstractSpringContextTests.getContext(AbstractSpringContextTests.java:140)
	at org.springframework.test.AbstractSingleSpringContextTests.setUp(AbstractSingleSpringContextTests.java:100)
	at junit.framework.TestCase.runBare(TestCase.java:125)
	at org.springframework.test.ConditionalTestCase.runBare(ConditionalTestCase.java:76)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:128)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:460)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:673)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:386)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:196)
java.sql.SQLException: Syntax error or access violation: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &amp;amp;apos;VARCHAR(100) NOT NULL , 
	STRING_VAL VARCHAR(250) , 
	DATE_VAL TIMESTAMP ,
	LONG&amp;amp;apos; at line 4
	at org.gjt.mm.mysql.MysqlIO.sendCommand(MysqlIO.java:508)
	at org.gjt.mm.mysql.MysqlIO.sqlQueryDirect(MysqlIO.java:561)
	at org.gjt.mm.mysql.MysqlIO.sqlQuery(MysqlIO.java:646)
	at org.gjt.mm.mysql.Connection.execSQL(Connection.java:973)
	at org.gjt.mm.mysql.Connection.execSQL(Connection.java:897)
	at org.gjt.mm.mysql.Statement.execute(Statement.java:598)
	at org.gjt.mm.mysql.jdbc2.Statement.execute(Statement.java:116)
	at org.springframework.jdbc.core.JdbcTemplate$1ExecuteStatementCallback.doInStatement(JdbcTemplate.java:397)
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:371)
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:404)
	at test.jdbc.datasource.InitializingDataSourceFactoryBean$1.doInTransaction(InitializingDataSourceFactoryBean.java:119)
	at org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:128)
	at test.jdbc.datasource.InitializingDataSourceFactoryBean.doExecuteScript(InitializingDataSourceFactoryBean.java:103)
	at test.jdbc.datasource.InitializingDataSourceFactoryBean.createInstance(InitializingDataSourceFactoryBean.java:91)
	at org.springframework.beans.factory.config.AbstractFactoryBean.afterPropertiesSet(AbstractFactoryBean.java:120)
	at test.jdbc.datasource.InitializingDataSourceFactoryBean.afterPropertiesSet(InitializingDataSourceFactoryBean.java:76)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1390)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1359)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:540)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory$1.run(AbstractAutowireCapableBeanFactory.java:485)
	at java.security.AccessController.doPrivileged(Native Method)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:455)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:251)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:169)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:248)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:170)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:407)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:735)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:369)
	at org.springframework.context.support.ClassPathXmlApplicationContext.&amp;lt;init&amp;gt;(ClassPathXmlApplicationContext.java:122)
	at org.springframework.context.support.ClassPathXmlApplicationContext.&amp;lt;init&amp;gt;(ClassPathXmlApplicationContext.java:66)
	at org.springframework.batch.sample.AbstractBatchLauncherTests.createApplicationContext(AbstractBatchLauncherTests.java:53)
	at org.springframework.test.AbstractSingleSpringContextTests.loadContextLocations(AbstractSingleSpringContextTests.java:212)
	at org.springframework.test.AbstractSingleSpringContextTests.loadContext(AbstractSingleSpringContextTests.java:187)
	at org.springframework.test.AbstractSpringContextTests.getContext(AbstractSpringContextTests.java:140)
	at org.springframework.test.AbstractSingleSpringContextTests.setUp(AbstractSingleSpringContextTests.java:100)
	at junit.framework.TestCase.runBare(TestCase.java:125)
	at org.springframework.test.ConditionalTestCase.runBare(ConditionalTestCase.java:76)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:128)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:460)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:673)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:386)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:196)
java.sql.SQLException: Syntax error or access violation: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &amp;amp;apos;VARCHAR(100) NOT NULL , 
	STRING_VAL VARCHAR(250) , 
	DATE_VAL TIMESTAMP ,
	LONG&amp;amp;apos; at line 4
	at org.gjt.mm.mysql.MysqlIO.sendCommand(MysqlIO.java:508)
	at org.gjt.mm.mysql.MysqlIO.sqlQueryDirect(MysqlIO.java:561)
	at org.gjt.mm.mysql.MysqlIO.sqlQuery(MysqlIO.java:646)
	at org.gjt.mm.mysql.Connection.execSQL(Connection.java:973)
	at org.gjt.mm.mysql.Connection.execSQL(Connection.java:897)
	at org.gjt.mm.mysql.Statement.execute(Statement.java:598)
	at org.gjt.mm.mysql.jdbc2.Statement.execute(Statement.java:116)
	at org.springframework.jdbc.core.JdbcTemplate$1ExecuteStatementCallback.doInStatement(JdbcTemplate.java:397)
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:371)
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:404)
	at test.jdbc.datasource.InitializingDataSourceFactoryBean$1.doInTransaction(InitializingDataSourceFactoryBean.java:119)
	at org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:128)
	at test.jdbc.datasource.InitializingDataSourceFactoryBean.doExecuteScript(InitializingDataSourceFactoryBean.java:103)
	at test.jdbc.datasource.InitializingDataSourceFactoryBean.createInstance(InitializingDataSourceFactoryBean.java:91)
	at org.springframework.beans.factory.config.AbstractFactoryBean.afterPropertiesSet(AbstractFactoryBean.java:120)
	at test.jdbc.datasource.InitializingDataSourceFactoryBean.afterPropertiesSet(InitializingDataSourceFactoryBean.java:76)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1390)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1359)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:540)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory$1.run(AbstractAutowireCapableBeanFactory.java:485)
	at java.security.AccessController.doPrivileged(Native Method)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:455)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:251)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:169)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:248)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:170)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:407)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:735)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:369)
	at org.springframework.context.support.ClassPathXmlApplicationContext.&amp;lt;init&amp;gt;(ClassPathXmlApplicationContext.java:122)
	at org.springframework.context.support.ClassPathXmlApplicationContext.&amp;lt;init&amp;gt;(ClassPathXmlApplicationContext.java:66)
	at org.springframework.batch.sample.AbstractBatchLauncherTests.createApplicationContext(AbstractBatchLauncherTests.java:53)
	at org.springframework.test.AbstractSingleSpringContextTests.loadContextLocations(AbstractSingleSpringContextTests.java:212)
	at org.springframework.test.AbstractSingleSpringContextTests.loadContext(AbstractSingleSpringContextTests.java:187)
	at org.springframework.test.AbstractSpringContextTests.getContext(AbstractSpringContextTests.java:140)
	at org.springframework.test.AbstractSingleSpringContextTests.setUp(AbstractSingleSpringContextTests.java:100)
	at junit.framework.TestCase.runBare(TestCase.java:125)
	at org.springframework.test.ConditionalTestCase.runBare(ConditionalTestCase.java:76)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:128)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:460)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:673)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:386)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:196)</description>
			<version>1.0.0.m4</version>
			<fixedVersion>1.0.0.m4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.execution.repository.dao.JdbcJobDao.java</file>
		</fixedFiles>
	</bug>
	<bug id="304" opendate="2008-01-22 00:35:00" fixdate="2008-01-30 02:50:39" resolution="Fixed">
		<buginformation>
			<summary>BatchCommandLineLauncher simplified and rename</summary>
			<description>BatchCommandLineLauncher simplified and renamed.  There are simply too many ways to skin this cat, and we don&amp;amp;apos;t want to try and cover everyone&amp;amp;apos;s preferences in one main method.  Rename as SimpleCommandLineJobDispatcher (or something?), and make it work in the simple case that there is one application context (in XML) and a named Job (possibly one of many), with two optional runtime parameters (a key and a schedule date).  The JobLauncher is identified by type.</description>
			<version>1.0-m3</version>
			<fixedVersion>1.0.0.m4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.runtime.JobParametersFactory.java</file>
			<file type="M">org.springframework.batch.core.domain.JobParameters.java</file>
			<file type="M">org.springframework.batch.execution.bootstrap.support.DefaultJobParametersFactory.java</file>
			<file type="M">org.springframework.batch.execution.bootstrap.support.CommandLineJobRunner.java</file>
			<file type="M">org.springframework.batch.execution.bootstrap.support.DefaultJobParametersFactoryTests.java</file>
			<file type="M">org.springframework.batch.execution.bootstrap.support.CommandLineJobRunnerTests.java</file>
			<file type="M">org.springframework.batch.execution.bootstrap.support.ScheduledJobParametersFactoryTests.java</file>
			<file type="M">org.springframework.batch.execution.bootstrap.support.ExitCodeMapper.java</file>
			<file type="M">org.springframework.batch.execution.bootstrap.support.ScheduledJobParametersFactory.java</file>
			<file type="M">org.springframework.batch.core.domain.NoSuchJobException.java</file>
			<file type="M">org.springframework.batch.execution.resource.DefaultJobInstanceLabelGeneratorTests.java</file>
			<file type="M">org.springframework.batch.execution.bootstrap.support.JobParametersPropertyEditorTests.java</file>
			<file type="M">org.springframework.batch.core.domain.JobParametersBuilderTests.java</file>
			<file type="M">org.springframework.batch.execution.bootstrap.support.JobParametersPropertyEditor.java</file>
			<file type="M">org.springframework.batch.core.domain.JobInstance.java</file>
			<file type="M">org.springframework.batch.core.domain.JobInstanceTests.java</file>
			<file type="M">org.springframework.batch.execution.repository.SimpleJobRepository.java</file>
			<file type="M">org.springframework.batch.execution.launch.JobLauncher.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.AbstractJobDaoTests.java</file>
			<file type="M">org.springframework.batch.execution.launch.SimpleJobLauncher.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.JdbcJobDao.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.MapJobDao.java</file>
			<file type="M">org.springframework.batch.core.domain.JobParametersBuilder.java</file>
			<file type="M">org.springframework.batch.execution.resource.DefaultJobInstanceLabelGenerator.java</file>
			<file type="D">org.springframework.batch.execution.bootstrap.support.ScheduledJobInstancePropertiesFactoryTests.java</file>
			<file type="M">org.springframework.batch.core.repository.JobRepository.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.JobDao.java</file>
			<file type="D">org.springframework.batch.core.runtime.SimpleJobIdentifierTests.java</file>
			<file type="M">org.springframework.batch.execution.bootstrap.support.ExportedJobLauncher.java</file>
			<file type="D">org.springframework.batch.execution.resource.DefaultJobIdentifierLabelGeneratorTests.java</file>
			<file type="D">org.springframework.batch.execution.runtime.ScheduledJobIdentifier.java</file>
			<file type="D">org.springframework.batch.execution.runtime.ScheduledJobIdentifierTests.java</file>
			<file type="D">org.springframework.batch.execution.resource.JobIdentifierLabelGenerator.java</file>
			<file type="D">org.springframework.batch.core.domain.JobIdentifier.java</file>
			<file type="D">org.springframework.batch.execution.runtime.DefaultJobIdentifierTests.java</file>
			<file type="D">org.springframework.batch.core.runtime.SimpleJobIdentifier.java</file>
			<file type="D">org.springframework.batch.execution.launch.JobExecutorFacade.java</file>
			<file type="M">org.springframework.batch.sample.dao.JdbcJobRepositoryTests.java</file>
			<file type="D">org.springframework.batch.execution.runtime.DefaultJobIdentifier.java</file>
			<file type="D">org.springframework.batch.execution.resource.DefaultJobIdentifierLabelGenerator.java</file>
			<file type="D">org.springframework.batch.execution.launch.SimpleJobExecutorFacade.java</file>
			<file type="M">org.springframework.batch.core.domain.BatchStatus.java</file>
			<file type="M">org.springframework.batch.core.domain.BatchStatusTests.java</file>
			<file type="D">org.springframework.batch.core.runtime.JobIdentifierFactory.java</file>
			<file type="M">org.springframework.batch.execution.step.simple.SimpleStepExecutorFactoryTests.java</file>
			<file type="M">org.springframework.batch.execution.bootstrap.support.SimpleCommandLineJobRunnerTests.java</file>
			<file type="M">org.springframework.batch.execution.launch.SimpleJobLauncherTests.java</file>
			<file type="D">org.springframework.batch.execution.runtime.DefaultJobIdentifierFactory.java</file>
			<file type="D">org.springframework.batch.execution.runtime.ScheduledJobIdentifierFactoryTests.java</file>
			<file type="M">org.springframework.batch.execution.repository.SimpleJobRepositoryTests.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.MapJobDaoTests.java</file>
			<file type="M">org.springframework.batch.sample.GracefulShutdownFunctionalTest.java</file>
			<file type="D">org.springframework.batch.execution.bootstrap.support.JobIdentifierPropertyEditor.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.AbstractStepDaoTests.java</file>
			<file type="M">org.springframework.batch.core.domain.JobExecutionTests.java</file>
			<file type="M">org.springframework.batch.sample.RestartFunctionalTests.java</file>
			<file type="M">org.springframework.batch.core.domain.StepExecutionTests.java</file>
			<file type="M">org.springframework.batch.execution.step.simple.JobRepositorySupport.java</file>
			<file type="M">org.springframework.batch.execution.launch.SimpleJobTests.java</file>
			<file type="D">org.springframework.batch.core.domain.JobInstanceProperties.java</file>
			<file type="M">org.springframework.batch.sample.item.processor.StagingItemProcessorTests.java</file>
			<file type="D">org.springframework.batch.core.runtime.SimpleJobIdentifierFactoryTests.java</file>
			<file type="M">org.springframework.batch.execution.bootstrap.support.StubJobLauncher.java</file>
			<file type="D">org.springframework.batch.execution.runtime.ScheduledJobIdentifierFactory.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.JdbcJobDaoQueryTests.java</file>
			<file type="D">org.springframework.batch.core.domain.JobInstancePropertiesBuilder.java</file>
			<file type="M">org.springframework.batch.sample.AbstractBatchLauncherTests.java</file>
			<file type="M">org.springframework.batch.sample.AbstractCustomerCreditIncreaseTests.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.MapStepDaoTests.java</file>
			<file type="M">org.springframework.batch.execution.job.DefaultJobExecutorTests.java</file>
			<file type="M">org.springframework.batch.sample.item.reader.StagingItemReaderTests.java</file>
			<file type="D">org.springframework.batch.core.runtime.SimpleJobIdentifierFactory.java</file>
			<file type="M">org.springframework.batch.execution.step.simple.DefaultStepExecutorTests.java</file>
			<file type="D">org.springframework.batch.core.domain.JobInstancePropertiesTests.java</file>
			<file type="D">org.springframework.batch.execution.runtime.DefaultJobIdentifierFactoryTests.java</file>
			<file type="M">org.springframework.batch.execution.bootstrap.support.SimpleCommandLineJobRunner.java</file>
			<file type="M">org.springframework.batch.sample.HibernateFailureJobFunctionalTests.java</file>
			<file type="M">org.springframework.batch.execution.step.simple.StepExecutorInterruptionTests.java</file>
			<file type="D">org.springframework.batch.core.domain.JobInstancePropertiesBuilderTests.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.JdbcStepDaoPrefixTests.java</file>
			<file type="D">org.springframework.batch.execution.bootstrap.support.JobIdentifierPropertyEditorTests.java</file>
			<file type="D">org.springframework.batch.execution.bootstrap.support.ScheduledJobInstancePropertiesFactory.java</file>
			<file type="M">org.springframework.batch.execution.resource.BatchResourceFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.domain.StepInstanceTests.java</file>
			<file type="M">org.springframework.batch.sample.AbstractValidatingBatchLauncherTests.java</file>
			<file type="D">org.springframework.batch.execution.bootstrap.support.SimpleCommandLineJobDispatcherTests.java</file>
			<file type="D">org.springframework.batch.execution.bootstrap.support.SimpleCommandLineJobDispatcher.java</file>
			<file type="D">org.springframework.batch.execution.bootstrap.support.BatchCommandLineLauncherTests.java</file>
			<file type="D">org.springframework.batch.execution.bootstrap.support.BatchCommandLineLauncher.java</file>
		</fixedFiles>
	</bug>
	<bug id="343" opendate="2008-02-05 22:31:50" fixdate="2008-02-06 00:21:34" resolution="Fixed">
		<buginformation>
			<summary>close() is called twice on ItemReaders/ItemWriters</summary>
			<description>ItemReaders and ItemWriters implement both DisposableBean and ItemStream, which results in calling the close() method twice (e.g. in case of HibernateCursorItemReader the second calls result in error as hibernate session is already closed)</description>
			<version>1.0.0.m4</version>
			<fixedVersion>1.0.0.m5</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.io.cursor.JdbcCursorItemReader.java</file>
			<file type="M">org.springframework.batch.io.support.AbstractDataSourceItemReaderIntegrationTests.java</file>
			<file type="M">org.springframework.batch.io.file.FlatFileItemWriter.java</file>
			<file type="M">org.springframework.batch.io.driving.FooInputSource.java</file>
			<file type="M">org.springframework.batch.io.cursor.HibernateCursorItemReader.java</file>
			<file type="M">org.springframework.batch.io.xml.StaxEventItemWriter.java</file>
			<file type="M">org.springframework.batch.io.file.separator.ResourceLineReader.java</file>
			<file type="M">org.springframework.batch.sample.item.reader.StagingItemReader.java</file>
			<file type="M">org.springframework.batch.io.cursor.HibernateCursorItemReaderIntegrationTests.java</file>
			<file type="M">org.springframework.batch.io.xml.StaxEventItemReaderTests.java</file>
			<file type="M">org.springframework.batch.io.xml.StaxEventWriterItemWriterTests.java</file>
			<file type="M">org.springframework.batch.io.xml.StaxEventItemReader.java</file>
			<file type="M">org.springframework.batch.io.driving.DrivingQueryItemReader.java</file>
		</fixedFiles>
	</bug>
	<bug id="347" opendate="2008-02-08 06:57:24" fixdate="2008-02-10 02:30:07" resolution="Fixed">
		<buginformation>
			<summary>aop / template interceptor class names ambiguous</summary>
			<description>RepeatInterceptor vs. RepeatOperationsInterceptor
RetryInterceptor vs. RetryOperationsInterceptor
Each of these pairs is badly named. Perhaps the aop ones might be renamed "Advisor" so as not to be as confusing?
i.e.
RepeatOperationsAdvisor
RetryOperationsAdvisor</description>
			<version>1.0.0.m4</version>
			<fixedVersion>1.0.0.m5</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="D">org.springframework.batch.retry.interceptor.RetryListenerSupportTests.java</file>
			<file type="M">org.springframework.batch.repeat.support.RepeatTemplate.java</file>
			<file type="M">org.springframework.batch.execution.step.tasklet.TaskletStep.java</file>
			<file type="M">org.springframework.batch.retry.support.RetryTemplate.java</file>
			<file type="M">org.springframework.batch.io.support.HibernateAwareItemWriter.java</file>
			<file type="D">org.springframework.batch.retry.interceptor.RetryInterceptorSupportTests.java</file>
			<file type="D">org.springframework.batch.repeat.interceptor.ApplicationEventPublisherRepeatInterceptor.java</file>
			<file type="M">org.springframework.batch.retry.aop.RetryOperationsInterceptor.java</file>
			<file type="D">org.springframework.batch.repeat.interceptor.ApplicationEventPublisherRepeatInterceptorTests.java</file>
			<file type="M">org.springframework.batch.io.support.HibernateAwareItemWriterTests.java</file>
			<file type="D">org.springframework.batch.retry.interceptor.RetryInterceptorSupport.java</file>
			<file type="M">org.springframework.batch.execution.step.simple.RepeatOperationsStepTests.java</file>
			<file type="D">org.springframework.batch.retry.RetryInterceptor.java</file>
			<file type="M">org.springframework.batch.execution.step.simple.SimpleStepExecutorTests.java</file>
			<file type="M">org.springframework.batch.execution.step.tasklet.TaskletStepTests.java</file>
			<file type="D">org.springframework.batch.repeat.RepeatInterceptor.java</file>
			<file type="D">org.springframework.batch.retry.interceptor.RetryInterceptorTests.java</file>
			<file type="M">org.springframework.batch.sample.dao.HibernateCreditWriter.java</file>
			<file type="D">org.springframework.batch.repeat.interceptor.RepeatInterceptorTests.java</file>
			<file type="D">org.springframework.batch.repeat.interceptor.RepeatInterceptorAdapter.java</file>
			<file type="M">org.springframework.batch.repeat.aop.RepeatOperationsInterceptor.java</file>
		</fixedFiles>
	</bug>
	<bug id="350" opendate="2008-02-10 09:44:22" fixdate="2008-02-10 22:29:44" resolution="Fixed">
		<buginformation>
			<summary>Remove close() method from non ItemStreams</summary>
			<description>The following classes have a default close method implementation which does not belong and should be removed:
org.springframework.batch.execution.launch.EmptyItemWriter
org.springframework.batch.item.writer.ItemWriterAdapter
org.springframework.batch.item.reader.ItemReaderAdapter
Here&amp;amp;apos;s an interesting question  how do you deal with something that needs to be both an ItemStream and a RepeatInterceptor?
Take org.springframework.batch.io.support.HibernateAwareItemWriter for instance  suppose you want this to be transaction managed as an ItemStream, how would you do that?</description>
			<version>1.0.0.m4</version>
			<fixedVersion>1.0.0.m5</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.execution.launch.EmptyItemWriter.java</file>
		</fixedFiles>
	</bug>
	<bug id="268" opendate="2008-01-03 01:33:50" fixdate="2008-02-11 03:22:53" resolution="Fixed">
		<buginformation>
			<summary>retry configuration for ItemOrientedTasklet</summary>
			<description>ItemOrientedTasklet no longer has a setter for RetryOperations which allowed to configure retry behaviour. Now only RetryPolicy can be set, but tasklet wraps it by ItemReaderRetryPolicy which rethrows exceptions by default, so exception always causes immediate rollback no matter what RetryPolicy was injected into the tasklet.</description>
			<version>1.0-m3</version>
			<fixedVersion>1.0.0.m5</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.stream.ItemStreamAdapter.java</file>
			<file type="M">org.springframework.batch.repeat.policy.DefaultResultCompletionPolicy.java</file>
			<file type="M">org.springframework.batch.repeat.policy.CompletionPolicySupport.java</file>
			<file type="M">org.springframework.batch.execution.step.simple.SimpleStepExecutor.java</file>
			<file type="M">org.springframework.batch.retry.jms.ExternalRetryTests.java</file>
			<file type="M">org.springframework.batch.item.reader.DelegatingItemReader.java</file>
			<file type="M">org.springframework.batch.repeat.policy.CompositeCompletionPolicy.java</file>
			<file type="M">org.springframework.batch.jms.ExternalRetryInBatchTests.java</file>
			<file type="M">org.springframework.batch.io.file.DefaultFlatFileItemReader.java</file>
			<file type="M">org.springframework.batch.io.exception.WriteFailureException.java</file>
			<file type="M">org.springframework.batch.repeat.callback.NestedRepeatCallback.java</file>
			<file type="D">org.springframework.batch.item.AbstractItemReaderRecoverer.java</file>
			<file type="M">org.springframework.batch.io.exception.ReadFailureException.java</file>
			<file type="M">org.springframework.batch.execution.step.simple.AbstractStep.java</file>
		</fixedFiles>
		<links>
			<link type="Depends" description="depends on">334</link>
			<link type="Related" description="is related to">334</link>
		</links>
	</bug>
	<bug id="362" opendate="2008-02-14 02:21:19" fixdate="2008-02-14 22:17:22" resolution="Fixed">
		<buginformation>
			<summary>Rename ExecutionAttributes to ExecutionContext</summary>
			<description>Rename ExecutionAttributes to ExecutionContext.  Arjen in particular thought that "context" was much more descriptive (he even suggested "state", but we all voted him down on that).</description>
			<version>1.0.0.m4</version>
			<fixedVersion>1.0.0.m5</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.reader.DelegatingItemReaderTests.java</file>
			<file type="M">org.springframework.batch.item.writer.ItemWriterItemProcessorTests.java</file>
			<file type="M">org.springframework.batch.io.file.FlatFileItemReader.java</file>
			<file type="M">org.springframework.batch.io.driving.support.SingleColumnJdbcKeyGenerator.java</file>
			<file type="M">org.springframework.batch.core.domain.StepContribution.java</file>
			<file type="M">org.springframework.batch.item.reader.DelegatingItemReader.java</file>
			<file type="D">org.springframework.batch.item.ExecutionAttributesProvider.java</file>
			<file type="M">org.springframework.batch.io.cursor.HibernateCursorItemReader.java</file>
			<file type="M">org.springframework.batch.io.driving.support.MultipleColumnJdbcKeyGenerator.java</file>
			<file type="M">org.springframework.batch.execution.bootstrap.support.SimpleExportedJobLauncherTests.java</file>
			<file type="M">org.springframework.batch.core.domain.StepSupport.java</file>
			<file type="M">org.springframework.batch.sample.item.reader.StagingItemReader.java</file>
			<file type="M">org.springframework.batch.execution.step.simple.SimpleStepExecutorTests.java</file>
			<file type="M">org.springframework.batch.execution.repository.SimpleJobRepositoryTests.java</file>
			<file type="M">org.springframework.batch.io.driving.FooInputSource.java</file>
			<file type="M">org.springframework.batch.io.driving.support.IbatisKeyGenerator.java</file>
			<file type="M">org.springframework.batch.item.stream.StreamManager.java</file>
			<file type="M">org.springframework.batch.execution.scope.SimpleStepContext.java</file>
			<file type="M">org.springframework.batch.io.cursor.JdbcCursorItemReader.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.AbstractStepDaoTests.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.JdbcStepInstanceDao.java</file>
			<file type="M">org.springframework.batch.item.stream.SimpleStreamManager.java</file>
			<file type="M">org.springframework.batch.io.driving.DrivingQueryItemReaderTests.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.StepInstanceDao.java</file>
			<file type="M">org.springframework.batch.core.domain.StepExecutionTests.java</file>
			<file type="D">org.springframework.batch.io.driving.support.ColumnMapExecutionAttributesRowMapperTests.java</file>
			<file type="M">org.springframework.batch.io.driving.support.MultipleColumnJdbcKeyGeneratorIntegrationTests.java</file>
			<file type="M">org.springframework.batch.execution.scope.StepContext.java</file>
			<file type="M">org.springframework.batch.io.file.FlatFileItemWriterTests.java</file>
			<file type="M">org.springframework.batch.io.xml.StaxEventWriterItemWriterTests.java</file>
			<file type="M">org.springframework.batch.core.domain.StepSupportTests.java</file>
			<file type="M">org.springframework.batch.io.support.AbstractDataSourceItemReaderIntegrationTests.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.JdbcStepExecutionDao.java</file>
			<file type="M">org.springframework.batch.sample.tasklet.InfiniteLoopTasklet.java</file>
			<file type="M">org.springframework.batch.item.stream.ItemStreamAdapter.java</file>
			<file type="M">org.springframework.batch.io.driving.KeyGenerator.java</file>
			<file type="M">org.springframework.batch.execution.repository.SimpleJobRepository.java</file>
			<file type="M">org.springframework.batch.core.domain.StepExecution.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.MapStepDao.java</file>
			<file type="M">org.springframework.batch.item.stream.SimpleStreamManagerTests.java</file>
			<file type="M">org.springframework.batch.io.xml.StaxEventItemReader.java</file>
			<file type="M">org.springframework.batch.core.domain.StepContributionTests.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.MapStepDaoTests.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.StepExecutionDao.java</file>
			<file type="D">org.springframework.batch.item.ExecutionAttributesTests.java</file>
			<file type="M">org.springframework.batch.core.domain.Step.java</file>
			<file type="D">org.springframework.batch.io.driving.support.ColumnMapExecutionAttributesRowMapper.java</file>
			<file type="M">org.springframework.batch.io.xml.StaxEventItemWriter.java</file>
			<file type="M">org.springframework.batch.execution.step.simple.ChunkedStep.java</file>
			<file type="M">org.springframework.batch.core.repository.JobRepository.java</file>
			<file type="M">org.springframework.batch.execution.step.simple.SimpleStepExecutor.java</file>
			<file type="M">org.springframework.batch.io.file.FlatFileItemWriter.java</file>
			<file type="M">org.springframework.batch.execution.bootstrap.support.SimpleExportedJobLauncher.java</file>
			<file type="D">org.springframework.batch.io.driving.support.ExecutionAttributesRowMapper.java</file>
			<file type="D">org.springframework.batch.item.ExecutionAttributes.java</file>
			<file type="M">org.springframework.batch.io.file.FlatFileItemReaderAdvancedTests.java</file>
			<file type="M">org.springframework.batch.execution.repository.MockStepDao.java</file>
			<file type="M">org.springframework.batch.execution.step.simple.SimpleStepConfigurationTests.java</file>
			<file type="M">org.springframework.batch.io.driving.DrivingQueryItemReader.java</file>
			<file type="M">org.springframework.batch.sample.item.reader.GeneratingItemReader.java</file>
			<file type="M">org.springframework.batch.io.driving.support.SingleColumnJdbcKeyGeneratorIntegrationTests.java</file>
			<file type="M">org.springframework.batch.io.xml.StaxEventItemReaderTests.java</file>
			<file type="M">org.springframework.batch.io.sql.AbstractJdbcItemReaderIntegrationTests.java</file>
			<file type="M">org.springframework.batch.sample.tasklet.SimpleTradeWriter.java</file>
			<file type="M">org.springframework.batch.execution.scope.SimpleStepContextTests.java</file>
			<file type="M">org.springframework.batch.item.ItemStream.java</file>
		</fixedFiles>
	</bug>
	<bug id="367" opendate="2008-02-14 23:34:16" fixdate="2008-02-17 20:40:17" resolution="Fixed">
		<buginformation>
			<summary>When the samples run, all the execution attributes are of type STRING - this must be wrong.</summary>
			<description>When the samples run, all the execution attributes are of type STRING - this must be wrong.  Surely most of them are longs?</description>
			<version>1.0.0.m4</version>
			<fixedVersion>1.0.0.m5</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.stream.SimpleStreamManagerTests.java</file>
			<file type="M">org.springframework.batch.item.stream.SimpleStreamManager.java</file>
		</fixedFiles>
	</bug>
	<bug id="366" opendate="2008-02-14 19:57:43" fixdate="2008-02-19 19:26:59" resolution="Fixed">
		<buginformation>
			<summary>Do we still need StepInstance?</summary>
			<description>StepInstance has lost weight over time to the point where I think it&amp;amp;apos;s mere existence needs to be questioned. 
Currently the only information StepInstance essentially provides is the step name. The execution count and last execution can be seen as convenience values that can be retrieved by different means - classes asking the step instance for these values (SimpleJob and StepExecutor/ChunkedStep) already have reference to the repository.
Technically it seems easy to add &amp;amp;apos;stepName&amp;amp;apos; property to StepExecution and live with the pair Step+StepExecution (with already existing link StepExecution -&amp;gt; JobExecution -&amp;gt; JobInstance) rather than triple Step+StepInstance+StepExecution.
Alternatively it might be StepInstance is missing properties that would logically belong to it and justify its existence, but I can&amp;amp;apos;t think of any candidates.</description>
			<version>1.0.0.m5</version>
			<fixedVersion>1.0.0.m5</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.execution.repository.dao.AbstractJobDaoTests.java</file>
			<file type="M">org.springframework.batch.execution.step.simple.SimpleStepTests.java</file>
			<file type="M">org.springframework.batch.execution.bootstrap.support.SimpleExportedJobLauncherTests.java</file>
			<file type="M">org.springframework.batch.execution.repository.SimpleJobRepositoryTests.java</file>
			<file type="M">org.springframework.batch.execution.step.simple.SimpleStepExecutorTests.java</file>
			<file type="M">org.springframework.batch.execution.step.tasklet.TaskletStepTests.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.JobExecutionDao.java</file>
			<file type="M">org.springframework.batch.execution.job.simple.SimpleJobTests.java</file>
			<file type="M">org.springframework.batch.execution.step.simple.RepeatOperationsStepTests.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.AbstractStepDaoTests.java</file>
			<file type="M">org.springframework.batch.core.domain.JobExecutionTests.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.JdbcStepDaoPrefixTests.java</file>
			<file type="D">org.springframework.batch.execution.repository.dao.StepInstanceDao.java</file>
			<file type="M">org.springframework.batch.core.domain.StepExecutionTests.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.MapJobDao.java</file>
			<file type="M">org.springframework.batch.core.domain.JobExecution.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.JdbcStepExecutionDao.java</file>
			<file type="M">org.springframework.batch.execution.resource.BatchResourceFactoryBean.java</file>
			<file type="M">org.springframework.batch.execution.repository.SimpleJobRepository.java</file>
			<file type="M">org.springframework.batch.execution.launch.SimpleJobTests.java</file>
			<file type="M">org.springframework.batch.core.domain.StepExecution.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.MapStepDao.java</file>
			<file type="M">org.springframework.batch.core.domain.JobInstanceTests.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.MapStepDaoTests.java</file>
			<file type="M">org.springframework.batch.execution.step.simple.ChunkedStep.java</file>
			<file type="D">org.springframework.batch.execution.repository.dao.JdbcStepInstanceDao.java</file>
			<file type="M">org.springframework.batch.sample.item.reader.StagingItemReaderTests.java</file>
			<file type="D">org.springframework.batch.core.domain.StepInstanceTests.java</file>
			<file type="M">org.springframework.batch.core.domain.JobInstance.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.StepExecutionDao.java</file>
			<file type="M">org.springframework.batch.core.repository.JobRepository.java</file>
			<file type="M">org.springframework.batch.execution.step.simple.SimpleStepExecutor.java</file>
			<file type="M">org.springframework.batch.execution.step.simple.StepExecutorInterruptionTests.java</file>
			<file type="D">org.springframework.batch.core.domain.StepInstance.java</file>
			<file type="M">org.springframework.batch.execution.repository.MockStepDao.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.JdbcStepDaoTests.java</file>
			<file type="M">org.springframework.batch.execution.step.simple.JobRepositorySupport.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.JdbcJobExecutionDao.java</file>
			<file type="M">org.springframework.batch.sample.item.writer.StagingItemProcessorTests.java</file>
			<file type="M">org.springframework.batch.execution.resource.BatchResourceFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.execution.job.simple.SimpleJob.java</file>
			<file type="M">org.springframework.batch.core.domain.JobSupportTests.java</file>
		</fixedFiles>
		<links>
			<link type="Depends" description="depends on">364</link>
		</links>
	</bug>
	<bug id="373" opendate="2008-02-19 20:32:07" fixdate="2008-02-19 22:33:14" resolution="Fixed">
		<buginformation>
			<summary>jobExecution.getJobInstance().getJob() return null when re-run</summary>
			<description>It is found that, if a job is re-run (by passing same JobParameters), the JobExecution created is referring to a JobInstance which refers to null for its Job.
i.e.
JobExecution x = jobLauncher.run(job, jobParam);
x.getJobInstance().getJob();  // returns null
It seems that for re-run job, the Job passed in the JobLauncher is not set to the JobInstance restored from DB.
As I am trying to intercept the Job&amp;amp;apos;s execute() by AOP, the only method I can get know of which job being executed is by jobExecution.getJobInstance().getJob()
</description>
			<version>1.0.0.m4</version>
			<fixedVersion>1.0.0.m5</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.execution.repository.SimpleJobRepository.java</file>
		</fixedFiles>
	</bug>
	<bug id="376" opendate="2008-02-21 03:46:20" fixdate="2008-02-21 20:57:53" resolution="Fixed">
		<buginformation>
			<summary>Problem with DelimitedLineTokenizer and empty quoted value</summary>
			<description>The DelimitedLineTokenizer throws a StringIndexOutOfBoundsException when a line contains an empty quoted field.
example line: "a", "b", "", "d"
I will attach a patch with test for this scenario.</description>
			<version>1.0.0.m4</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.io.file.transform.DelimitedLineTokenizer.java</file>
			<file type="M">org.springframework.batch.io.file.transform.DelimitedLineTokenizerTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="371" opendate="2008-02-19 04:44:17" fixdate="2008-02-25 01:00:47" resolution="Fixed">
		<buginformation>
			<summary>FlatFileItemWriter no longer uses LineAggregator</summary>
			<description>It seems that the FlatFileItemWriter no longer takes a LineAggregator to determine how lines should be written. This seems to be an oversight?
It could be argued that the ItemTransformer that&amp;amp;apos;s injectable could be used instead, except that it only gets invoked when the item type is not String. Additionally, it is asymmetrical with the ItemReader&amp;amp;apos;s LineTokenizer. Also, there is no packaged ItemTransformer equivalent to the LineAggregators.
Anyway, as of the moment, it seems the LineAggregators are not used or injectable anywhere, so they should either be made injectable and invoked appropriately again, OR equivalent ItemTransformers should be provided and the LineTokenizers should also be replaced, and the transformer should be invoked even if the item is a String...</description>
			<version>1.0.0.m4</version>
			<fixedVersion>1.0.0.m5</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="D">org.springframework.batch.item.stream.ItemStreamAdapter.java</file>
			<file type="M">org.springframework.batch.item.stream.SimpleStreamManagerTests.java</file>
			<file type="M">org.springframework.batch.io.file.mapping.PassThroughFieldSetMapperTests.java</file>
			<file type="D">org.springframework.batch.item.writer.ItemWriterAdapterIntegrationTests.java</file>
			<file type="M">org.springframework.batch.io.file.separator.ResourceLineReader.java</file>
			<file type="M">org.springframework.batch.item.reader.ItemReaderAdapter.java</file>
			<file type="M">org.springframework.batch.io.file.mapping.PassThroughFieldSetMapper.java</file>
			<file type="M">org.springframework.batch.repeat.interceptor.RepeatListenerTests.java</file>
			<file type="M">org.springframework.batch.retry.interceptor.RetryListenerTests.java</file>
			<file type="M">org.springframework.batch.io.support.AbstractTransactionalIoSource.java</file>
			<file type="M">org.springframework.batch.item.reader.AbstractItemStreamItemReader.java</file>
			<file type="D">org.springframework.batch.io.file.mapping.FieldSetUnmapper.java</file>
			<file type="D">org.springframework.batch.io.file.transform.FieldSetUnmapperItemTransformer.java</file>
			<file type="M">org.springframework.batch.io.file.FlatFileItemWriter.java</file>
			<file type="D">org.springframework.batch.retry.interceptor.RetryListenerAdapter.java</file>
			<file type="D">org.springframework.batch.repeat.interceptor.RepeatListenerAdapter.java</file>
			<file type="D">org.springframework.batch.retry.interceptor.RetryListenerAdapterTests.java</file>
			<file type="M">org.springframework.batch.io.file.FlatFileItemWriterTests.java</file>
			<file type="M">org.springframework.batch.item.writer.DelegatingItemWriter.java</file>
			<file type="M">org.springframework.batch.sample.MultilineJobFunctionalTests.java</file>
			<file type="M">org.springframework.batch.io.file.transform.LineAggregatorItemTransformerTests.java</file>
			<file type="M">org.springframework.batch.io.file.transform.LineAggregatorItemTransformer.java</file>
			<file type="M">org.springframework.batch.io.file.transform.RecursiveCollectionItemTransformer.java</file>
			<file type="D">org.springframework.batch.io.file.transform.LineAggregatorStub.java</file>
			<file type="M">org.springframework.batch.sample.dao.FlatFileOrderWriterTests.java</file>
			<file type="D">org.springframework.batch.sample.LineAggregatorStub.java</file>
			<file type="M">org.springframework.batch.io.file.transform.FixedLengthLineAggregatorTests.java</file>
			<file type="M">org.springframework.batch.io.file.transform.DelimitedLineAggregatorTests.java</file>
			<file type="M">org.springframework.batch.io.file.transform.LineAggregator.java</file>
			<file type="M">org.springframework.batch.sample.dao.OrderTransformer.java</file>
			<file type="M">org.springframework.batch.io.file.transform.FixedLengthLineAggregator.java</file>
			<file type="M">org.springframework.batch.io.file.transform.DelimitedLineAggregator.java</file>
			<file type="M">org.springframework.batch.execution.configuration.JobBeanDefinitionParser.java</file>
		</fixedFiles>
	</bug>
	<bug id="349" opendate="2008-02-10 09:25:24" fixdate="2008-02-25 03:10:43" resolution="Fixed">
		<buginformation>
			<summary>ItemStreamAdapter isn&amp;apos;t an Adapter</summary>
			<description>Perhaps this should be called ItemStreamSupport? Thanks.</description>
			<version>1.0.0.m4</version>
			<fixedVersion>1.0.0.m5</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="D">org.springframework.batch.item.stream.ItemStreamAdapter.java</file>
			<file type="M">org.springframework.batch.item.stream.SimpleStreamManagerTests.java</file>
			<file type="M">org.springframework.batch.io.file.mapping.PassThroughFieldSetMapperTests.java</file>
			<file type="D">org.springframework.batch.item.writer.ItemWriterAdapterIntegrationTests.java</file>
			<file type="M">org.springframework.batch.io.file.separator.ResourceLineReader.java</file>
			<file type="M">org.springframework.batch.item.reader.ItemReaderAdapter.java</file>
			<file type="M">org.springframework.batch.io.file.mapping.PassThroughFieldSetMapper.java</file>
			<file type="M">org.springframework.batch.repeat.interceptor.RepeatListenerTests.java</file>
			<file type="M">org.springframework.batch.retry.interceptor.RetryListenerTests.java</file>
			<file type="M">org.springframework.batch.io.support.AbstractTransactionalIoSource.java</file>
			<file type="M">org.springframework.batch.item.reader.AbstractItemStreamItemReader.java</file>
			<file type="D">org.springframework.batch.io.file.mapping.FieldSetUnmapper.java</file>
			<file type="D">org.springframework.batch.io.file.transform.FieldSetUnmapperItemTransformer.java</file>
			<file type="M">org.springframework.batch.io.file.FlatFileItemWriter.java</file>
			<file type="D">org.springframework.batch.retry.interceptor.RetryListenerAdapter.java</file>
			<file type="D">org.springframework.batch.repeat.interceptor.RepeatListenerAdapter.java</file>
			<file type="D">org.springframework.batch.retry.interceptor.RetryListenerAdapterTests.java</file>
			<file type="M">org.springframework.batch.io.file.FlatFileItemWriterTests.java</file>
			<file type="M">org.springframework.batch.execution.step.ItemOrientedStepTests.java</file>
			<file type="M">org.springframework.batch.execution.step.TaskletStepTests.java</file>
			<file type="M">org.springframework.batch.execution.step.support.RepeatOperationsStepTests.java</file>
			<file type="M">org.springframework.batch.item.writer.DelegatingItemWriter.java</file>
			<file type="M">org.springframework.batch.execution.step.ChunkedStepTests.java</file>
			<file type="M">org.springframework.batch.item.writer.AbstractItemStreamItemWriter.java</file>
		</fixedFiles>
	</bug>
	<bug id="364" opendate="2008-02-14 02:48:01" fixdate="2008-02-25 17:44:09" resolution="Fixed">
		<buginformation>
			<summary>StepScope responsibilities can be assumed by Step (not ApplicationContext)</summary>
			<description>StepScope responsibilities can be assumed by Step (not ApplicationContext).  The aim (to clarify issues raised below), is to make scope="step" strongly advised but not mandatory for item readers and writers in simple steps.  Application programmers are very welcome to use scope="step" where they need access to the context through StepContextAware, since this is consistent with other custom scope usages.  They are also advised to use scope="step" wherever there is a possibility of more than one thread executing the same step - as in the case of a JMX launcher (see samples) or a web service that runs jobs.  Step scope is not necessary for single JVM, single Job processes, but it would be recommended to use it anyway, in case the job is ever run in a mult-threaded container.</description>
			<version>1.0.0.m4</version>
			<fixedVersion>1.0.0.m5</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.domain.StepExecution.java</file>
			<file type="M">org.springframework.batch.core.domain.Entity.java</file>
			<file type="M">org.springframework.batch.execution.step.simple.SimpleStepExecutor.java</file>
			<file type="M">org.springframework.batch.execution.step.simple.ItemChunker.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.MapStepDao.java</file>
			<file type="M">org.springframework.batch.execution.repository.MockStepDao.java</file>
			<file type="M">org.springframework.batch.core.domain.Chunker.java</file>
			<file type="M">org.springframework.batch.core.domain.StepExecutionTests.java</file>
			<file type="M">org.springframework.batch.execution.repository.SimpleJobRepositoryTests.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.JdbcStepExecutionDao.java</file>
			<file type="M">org.springframework.batch.execution.scope.SimpleStepContext.java</file>
			<file type="M">org.springframework.batch.item.reader.AggregateItemReader.java</file>
			<file type="M">org.springframework.batch.item.stream.SimpleStreamManagerTests.java</file>
			<file type="M">org.springframework.batch.item.stream.StreamManager.java</file>
			<file type="M">org.springframework.batch.item.stream.SimpleStreamManager.java</file>
			<file type="M">org.springframework.batch.item.reader.DelegatingItemReader.java</file>
			<file type="M">org.springframework.batch.sample.item.reader.OrderItemReader.java</file>
			<file type="M">org.springframework.batch.execution.step.simple.ChunkedStep.java</file>
			<file type="M">org.springframework.batch.execution.step.simple.SimpleStepExecutorTests.java</file>
			<file type="M">org.springframework.batch.execution.scope.StepContext.java</file>
			<file type="M">org.springframework.batch.sample.tasklet.ExceptionThrowingItemReaderProxy.java</file>
			<file type="M">org.springframework.batch.sample.tasklet.ExceptionThrowingItemReaderProxyTests.java</file>
			<file type="M">org.springframework.batch.execution.scope.SimpleStepContextTests.java</file>
			<file type="M">org.springframework.batch.repeat.context.SynchronizedAttributeAccessorTests.java</file>
			<file type="M">org.springframework.batch.io.file.FlatFileItemReader.java</file>
			<file type="M">org.springframework.batch.repeat.support.AbstractTradeBatchTests.java</file>
			<file type="M">org.springframework.batch.io.file.FlatFileItemReaderAdvancedTests.java</file>
			<file type="M">org.springframework.batch.sample.AbstractBatchLauncherTests.java</file>
			<file type="M">org.springframework.batch.io.xml.StaxEventItemReader.java</file>
			<file type="M">org.springframework.batch.sample.item.reader.StagingItemReader.java</file>
			<file type="M">org.springframework.batch.core.repository.JobRepository.java</file>
			<file type="M">org.springframework.batch.sample.item.reader.StagingItemReaderTests.java</file>
			<file type="D">org.springframework.batch.execution.step.simple.ChunkedStepTests.java</file>
			<file type="M">org.springframework.batch.sample.FixedLengthImportJobFunctionalTests.java</file>
			<file type="M">org.springframework.batch.io.xml.StaxEventItemReaderTests.java</file>
			<file type="M">org.springframework.batch.io.file.FlatFileItemReaderBasicTests.java</file>
			<file type="M">org.springframework.batch.io.xml.StaxEventItemWriter.java</file>
			<file type="M">org.springframework.batch.io.xml.StaxEventWriterItemWriterTests.java</file>
		</fixedFiles>
		<links>
			<link type="Depends" description="is depended on by">366</link>
		</links>
	</bug>
	<bug id="380" opendate="2008-02-21 19:51:06" fixdate="2008-02-26 02:26:25" resolution="Fixed">
		<buginformation>
			<summary>Step Scope problem in TaskletStep</summary>
			<description>snippet of app context config:
    &amp;lt;!-- stuffs that copied from simple-container-definition.xml --&amp;gt;
    &amp;lt;bean id="job" parent="simpleJob"&amp;gt;
        &amp;lt;property name="steps"&amp;gt;
            &amp;lt;list&amp;gt;
                &amp;lt;bean id="step1" parent="taskletStep"&amp;gt;
                    &amp;lt;property name="tasklet"&amp;gt;
                        &amp;lt;bean id="tradeTasklet"
                                class="foo.sample.TradeMatchTasklet"
                                scope="step"&amp;gt;
                            &amp;lt;aop:scoped-proxy /&amp;gt;
                            &amp;lt;property name="status" value="9"/&amp;gt;
                        &amp;lt;/bean&amp;gt;
                    &amp;lt;/property&amp;gt;
                &amp;lt;/bean&amp;gt;
            &amp;lt;/list&amp;gt;
        &amp;lt;/property&amp;gt;
    &amp;lt;/bean&amp;gt;
My Unit test:
@RunWith(SpringJUnit4ClassRunner.class)
@TransactionConfiguration
@Transactional
@ContextConfiguration(locations=
{"/mysample/sample1-job.xml"}
)
public class TradeMatchBatchTests {
    @Resource
    JobLauncher jobLauncher;
    @Resource
    private Job job;
    @Resource
    MapJobRegistry jobConfigurationRegistry;
    @Test
    public void testLaunchJob() throws Exception 
{
        Map&amp;lt;String, String&amp;gt; strParam = new HashMap&amp;lt;String, String&amp;gt;();
        strParam.put("KEY", "1");
        JobParameters jobParam = new JobParameters(strParam, new HashMap(), new HashMap());

        JobExecution x = jobLauncher.run(job, jobParam);
    }
}
Once it is run, following exception is thrown:
2008-02-21 19:26:01,645 INFO [org.springframework.batch.execution.launch.SimpleJobLauncher] - &amp;lt;Job: [SimpleJob: [name=job]] failed with the following parameters: [
{KEY=1}
{}{}]&amp;gt;
org.springframework.batch.io.exception.BatchCriticalException: org.springframework.beans.factory.BeanCreationException: Error creating bean with name &amp;amp;apos;scopedTarget.tradeTasklet&amp;amp;apos;: Scope &amp;amp;apos;step&amp;amp;apos; is not active for the current thread; consider defining a scoped proxy for this bean if you intend to refer to it from a singleton; nested exception is java.lang.IllegalStateException: No context holder available for step scope
	at org.springframework.batch.execution.step.tasklet.TaskletStep.execute(TaskletStep.java:134)
	at org.springframework.batch.execution.job.simple.SimpleJob.execute(SimpleJob.java:88)
	at org.springframework.batch.execution.launch.SimpleJobLauncher$1.run(SimpleJobLauncher.java:85)
	at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:49)
	at org.springframework.batch.execution.launch.SimpleJobLauncher.run(SimpleJobLauncher.java:80)
	at foo.sample.TradeMatchBatchTests.testLaunchJob(TradeMatchBatchTests.java:117)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.springframework.test.context.junit4.SpringTestMethod.invoke(SpringTestMethod.java:198)
	at org.springframework.test.context.junit4.SpringMethodRoadie.runTestMethod(SpringMethodRoadie.java:274)
	at org.springframework.test.context.junit4.SpringMethodRoadie$2.run(SpringMethodRoadie.java:207)
	at org.springframework.test.context.junit4.SpringMethodRoadie.runBeforesThenTestThenAfters(SpringMethodRoadie.java:254)
	at org.springframework.test.context.junit4.SpringMethodRoadie.runWithRepetitions(SpringMethodRoadie.java:234)
	at org.springframework.test.context.junit4.SpringMethodRoadie.runTest(SpringMethodRoadie.java:204)
	at org.springframework.test.context.junit4.SpringMethodRoadie.run(SpringMethodRoadie.java:146)
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.invokeTestMethod(SpringJUnit4ClassRunner.java:151)
	at org.junit.internal.runners.JUnit4ClassRunner.runMethods(JUnit4ClassRunner.java:51)
	at org.junit.internal.runners.JUnit4ClassRunner$1.run(JUnit4ClassRunner.java:44)
	at org.junit.internal.runners.ClassRoadie.runUnprotected(ClassRoadie.java:27)
	at org.junit.internal.runners.ClassRoadie.runProtected(ClassRoadie.java:37)
	at org.junit.internal.runners.JUnit4ClassRunner.run(JUnit4ClassRunner.java:42)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:38)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:460)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:673)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:386)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:196)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name &amp;amp;apos;scopedTarget.tradeTasklet&amp;amp;apos;: Scope &amp;amp;apos;step&amp;amp;apos; is not active for the current thread; consider defining a scoped proxy for this bean if you intend to refer to it from a singleton; nested exception is java.lang.IllegalStateException: No context holder available for step scope
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:299)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:170)
	at org.springframework.aop.target.SimpleBeanTargetSource.getTarget(SimpleBeanTargetSource.java:33)
	at org.springframework.aop.framework.Cglib2AopProxy$DynamicAdvisedInterceptor.getTarget(Cglib2AopProxy.java:662)
	at org.springframework.aop.framework.Cglib2AopProxy$DynamicAdvisedInterceptor.intercept(Cglib2AopProxy.java:612)
	at foo.sample.TradeMatchTasklet$$EnhancerByCGLIB$$f5e84820.execute(&amp;lt;generated&amp;gt;)
	at org.springframework.batch.execution.step.tasklet.TaskletStep$1.doInIteration(TaskletStep.java:124)
	at org.springframework.batch.repeat.support.RepeatTemplate.getNextResult(RepeatTemplate.java:324)
	at org.springframework.batch.repeat.support.RepeatTemplate.executeInternal(RepeatTemplate.java:201)
	at org.springframework.batch.repeat.support.RepeatTemplate.iterate(RepeatTemplate.java:131)
	at org.springframework.batch.execution.step.tasklet.TaskletStep.execute(TaskletStep.java:122)
	... 28 more
Caused by: java.lang.IllegalStateException: No context holder available for step scope
	at org.springframework.batch.execution.scope.StepScope.getContext(StepScope.java:127)
	at org.springframework.batch.execution.scope.StepScope.get(StepScope.java:68)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:285)
	... 38 more</description>
			<version>1.0.0.m4</version>
			<fixedVersion>1.0.0.m5</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.domain.JobExecutionTests.java</file>
			<file type="M">org.springframework.batch.execution.step.TaskletStepTests.java</file>
			<file type="M">org.springframework.batch.execution.step.TaskletStep.java</file>
		</fixedFiles>
	</bug>
	<bug id="368" opendate="2008-02-15 01:40:30" fixdate="2008-02-27 03:06:36" resolution="Fixed">
		<buginformation>
			<summary>StepExecution attributes can overflow and cause spurious OptimisticLockingException</summary>
			<description>StepExecution attributes can overflow in the attrs table and in the step execution table (the "compressed" version).  I hacked the DDL to extend the columns, but we have to catch the exceptions and deal with them better - the job cannot be re-run if the meta-data are corrupt (it should get status UNKNOWN).</description>
			<version>1.0.0.m4</version>
			<fixedVersion>1.0.0.m5</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.execution.repository.dao.JdbcStepExecutionDao.java</file>
			<file type="M">org.springframework.batch.execution.job.AbstractJob.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.AbstractStepDaoTests.java</file>
			<file type="M">org.springframework.batch.core.repository.JobRepository.java</file>
			<file type="M">org.springframework.batch.execution.step.TaskletStep.java</file>
			<file type="M">org.springframework.batch.execution.repository.SimpleJobRepository.java</file>
			<file type="M">org.springframework.batch.execution.step.support.JobRepositorySupport.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.MapStepDao.java</file>
			<file type="M">org.springframework.batch.execution.step.TaskletStepTests.java</file>
			<file type="M">org.springframework.batch.execution.step.ItemOrientedStep.java</file>
			<file type="M">org.springframework.batch.execution.repository.MockStepDao.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.StepExecutionDao.java</file>
			<file type="M">org.springframework.batch.execution.step.ItemOrientedStepTests.java</file>
			<file type="M">org.springframework.batch.execution.repository.SimpleJobRepositoryTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="400" opendate="2008-02-28 03:11:39" fixdate="2008-02-28 18:23:48" resolution="Fixed">
		<buginformation>
			<summary>Batch support schemas does not include RI and primary keys </summary>
			<description>It looks like BATCH_JOB_PARAMS and BATCH_STEP_EXECUTION_ATTRS do not include primary keys. (It also appears that these two tables are not yet used anywhere). Also, the schema does include referential integrity between tables. 
It becomes difficult to get an approval from DBA&amp;amp;apos;s to approve such table structure...
Of course, RI can be manually added as an easy workaround, but still... </description>
			<version>1.0.0.m4</version>
			<fixedVersion>1.0.0.m5</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.sample.dao.JdbcJobRepositoryTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="385" opendate="2008-02-25 18:13:35" fixdate="2008-02-28 23:28:07" resolution="Fixed">
		<buginformation>
			<summary>Merge user attributes in StepContext with ExecutionContext</summary>
			<description>Developers find StepContext easy to locate and use, and mistakenly assume that its attributes ight be persisted (like the ExecutionContext).  It&amp;amp;apos;s an easy mistake to make, so maybe user defined attributes in StepContext should use an ExecutionContext, or maybe a separate API in StepContext could provide the same feature.</description>
			<version>1.0.0.m4</version>
			<fixedVersion>1.0.0.m5</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.writer.DelegatingItemWriter.java</file>
			<file type="M">org.springframework.batch.item.reader.DelegatingItemReader.java</file>
			<file type="M">org.springframework.batch.sample.item.reader.GeneratingItemReader.java</file>
			<file type="M">org.springframework.batch.item.reader.DelegatingItemReaderTests.java</file>
			<file type="M">org.springframework.batch.repeat.support.AbstractTradeBatchTests.java</file>
			<file type="M">org.springframework.batch.sample.item.writer.TradeWriter.java</file>
			<file type="D">org.springframework.batch.execution.scope.SimpleStepContext.java</file>
			<file type="D">org.springframework.batch.execution.scope.StepContextAwareStepScopeTests.java</file>
			<file type="D">org.springframework.batch.execution.scope.StepScope.java</file>
			<file type="D">org.springframework.batch.execution.scope.JobParametersAware.java</file>
			<file type="D">org.springframework.batch.execution.scope.StepScopeTests.java</file>
			<file type="D">org.springframework.batch.execution.scope.SimpleStepContextTests.java</file>
			<file type="M">org.springframework.batch.execution.listener.CompositeItemWriteListener.java</file>
			<file type="M">org.springframework.batch.execution.job.SimpleJob.java</file>
			<file type="D">org.springframework.batch.execution.scope.StepContext.java</file>
			<file type="M">org.springframework.batch.execution.step.TaskletStepTests.java</file>
			<file type="D">org.springframework.batch.execution.scope.StepContextAware.java</file>
			<file type="M">org.springframework.batch.execution.job.SimpleJobTests.java</file>
			<file type="D">org.springframework.batch.execution.scope.StepSynchronizationManager.java</file>
			<file type="D">org.springframework.batch.execution.scope.JobParametersAwareStepScopeTests.java</file>
			<file type="M">org.springframework.batch.execution.resource.StepExecutionProxyResourceTests.java</file>
			<file type="M">org.springframework.batch.sample.item.writer.StagingItemWriter.java</file>
			<file type="M">org.springframework.batch.execution.step.ItemOrientedStepTests.java</file>
			<file type="D">org.springframework.batch.execution.resource.BatchResourceFactoryBean.java</file>
			<file type="M">org.springframework.batch.execution.step.ItemOrientedStep.java</file>
			<file type="M">org.springframework.batch.sample.item.reader.StagingItemReader.java</file>
			<file type="M">org.springframework.batch.sample.item.reader.StagingItemReaderTests.java</file>
			<file type="D">org.springframework.batch.execution.resource.BatchResourceFactoryBeanTests.java</file>
			<file type="D">org.springframework.batch.sample.item.writer.StagingItemProcessorTests.java</file>
			<file type="M">org.springframework.batch.execution.step.TaskletStep.java</file>
			<file type="M">org.springframework.batch.execution.step.support.ListenerMulticaster.java</file>
			<file type="M">org.springframework.batch.item.ExecutionContext.java</file>
		</fixedFiles>
	</bug>
	<bug id="398" opendate="2008-02-27 22:03:01" fixdate="2008-02-29 19:57:50" resolution="Fixed">
		<buginformation>
			<summary>That old stateful / stateless thing again....</summary>
			<description>Step used to have StepExecutorFactory to create stack-confined stateful StepExecutor instances.  Now that StepExecutor is merged with Step it needs to have its own factory.  Or else we go back to the StepExecutor/Factory design.  So Job has a list of StepFactory instead of a list of Steps, and creates a Step for use inside its execute() method.  The simplest possible factory would be a prototype bean lookup, otherwise the factory has to have all the public setters of the Step implementation (maybe now that things are settling down that isn&amp;amp;apos;t so bad).</description>
			<version>1.0.0.m5</version>
			<fixedVersion>1.0.0.m5</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.execution.configuration.MapJobRegistry.java</file>
			<file type="M">org.springframework.batch.execution.configuration.JobRegistryBeanPostProcessor.java</file>
			<file type="M">org.springframework.batch.execution.bootstrap.support.SimpleExportedJobLauncherTests.java</file>
			<file type="M">org.springframework.batch.sample.TaskExecutorLauncher.java</file>
			<file type="M">org.springframework.batch.core.repository.JobRegistry.java</file>
			<file type="M">org.springframework.batch.execution.configuration.MapJobRegistryTests.java</file>
			<file type="M">org.springframework.batch.sample.tasklet.InfiniteLoopTasklet.java</file>
			<file type="M">org.springframework.batch.core.repository.ListableJobRegistry.java</file>
			<file type="M">org.springframework.batch.execution.configuration.JobRegistryBeanPostProcessorTests.java</file>
			<file type="M">org.springframework.batch.sample.DefaultJobLoader.java</file>
			<file type="M">org.springframework.batch.sample.FootballJobFunctionalTests.java</file>
			<file type="M">org.springframework.batch.sample.RetrySampleFunctionalTests.java</file>
			<file type="M">org.springframework.batch.sample.HibernateJobFunctionalTests.java</file>
			<file type="M">org.springframework.batch.sample.DelegatingJobFunctionalTests.java</file>
			<file type="M">org.springframework.batch.sample.CompositeProcessorSampleFunctionalTests.java</file>
			<file type="M">org.springframework.batch.sample.HibernateFailureJobFunctionalTests.java</file>
			<file type="M">org.springframework.batch.core.repository.JobLocator.java</file>
			<file type="M">org.springframework.batch.sample.BeanWrapperMapperSampleJobFunctionalTests.java</file>
			<file type="M">org.springframework.batch.sample.XmlStaxJobFunctionalTests.java</file>
			<file type="M">org.springframework.batch.sample.RollbackJobFunctionalTests.java</file>
			<file type="M">org.springframework.batch.sample.AbstractBatchLauncherTests.java</file>
			<file type="M">org.springframework.batch.sample.RestartFunctionalTests.java</file>
			<file type="M">org.springframework.batch.sample.FixedLengthImportJobFunctionalTests.java</file>
			<file type="M">org.springframework.batch.sample.IbatisJobFunctionalTests.java</file>
			<file type="M">org.springframework.batch.sample.TradeJobFunctionalTests.java</file>
			<file type="M">org.springframework.batch.sample.GracefulShutdownFunctionalTests.java</file>
			<file type="M">org.springframework.batch.sample.MultilineOrderJobFunctionalTests.java</file>
			<file type="M">org.springframework.batch.sample.SimpleJobFunctionalTests.java</file>
			<file type="M">org.springframework.batch.sample.ParallelJobFunctionalTests.java</file>
			<file type="M">org.springframework.batch.sample.MultilineJobFunctionalTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="402" opendate="2008-03-01 01:27:50" fixdate="2008-03-03 03:19:04" resolution="Fixed">
		<buginformation>
			<summary>Does startLimit need to be on Job and Step?</summary>
			<description>Does startLimit need to be on Job and Step?  I would be happy if it was only in one or the other (prefer Job, but others might have different opinions).</description>
			<version>1.0.0.m5</version>
			<fixedVersion>1.0.0.m5</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.domain.JobInstance.java</file>
			<file type="M">org.springframework.batch.core.domain.JobInstanceTests.java</file>
			<file type="M">org.springframework.batch.core.domain.Job.java</file>
			<file type="M">org.springframework.batch.execution.repository.SimpleJobRepositoryTests.java</file>
			<file type="M">org.springframework.batch.execution.job.AbstractJob.java</file>
			<file type="M">org.springframework.batch.execution.repository.SimpleJobRepository.java</file>
		</fixedFiles>
	</bug>
	<bug id="408" opendate="2008-03-03 17:03:43" fixdate="2008-03-03 19:55:06" resolution="Fixed">
		<buginformation>
			<summary>Parallel job sample is prone to OptimisticLockingException</summary>
			<description>Parallel job sample is prone to OptimisticLockingException when using commons DBCP and Oracle (and probably other RDBMS, but not HSQL or Derby).  The "toy" databases that we currently test with do not really support multi-threaded access.  When you upgrade there are issues with optimistic locking exceptions.  The exceptions are meaningful - they tell you that the step execution in the database is not accurately reflecting the current status of the job.</description>
			<version>1.0.0.m5</version>
			<fixedVersion>1.0.0.m5</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.execution.step.ItemOrientedStep.java</file>
		</fixedFiles>
	</bug>
	<bug id="393" opendate="2008-02-27 01:23:09" fixdate="2008-03-03 20:18:34" resolution="Fixed">
		<buginformation>
			<summary>DefaultFieldSet should not always trim whitespace from the value returned</summary>
			<description>DefaultFieldSet should not always trim whitespace from the value returned.  (I think it&amp;amp;apos;s valid for trimming to occur on the "name" of a field.)  It&amp;amp;apos;s a valid use-case for people to want the raw data that was read with whitespace included.  (It also can slightly slow performance during the reading of a file when trimming is done).
Please allow users to decide which field(s) they would like trimming to occur on.</description>
			<version>1.0.0.m4</version>
			<fixedVersion>1.0.0.m5</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.io.file.mapping.FieldSet.java</file>
			<file type="M">org.springframework.batch.io.file.FieldSetTests.java</file>
			<file type="M">org.springframework.batch.io.file.mapping.DefaultFieldSet.java</file>
		</fixedFiles>
	</bug>
	<bug id="406" opendate="2008-03-03 01:24:58" fixdate="2008-03-03 21:48:28" resolution="Fixed">
		<buginformation>
			<summary>jobInstance properties lastExecution and executionCount are useless</summary>
			<description></description>
			<version>1.0.0.m5</version>
			<fixedVersion>1.0.0.rc1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.execution.repository.SimpleJobRepository.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.JdbcJobDaoQueryTests.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.AbstractJobDaoTests.java</file>
			<file type="M">org.springframework.batch.core.domain.JobInstanceTests.java</file>
			<file type="M">org.springframework.batch.execution.resource.StepExecutionProxyResourceTests.java</file>
			<file type="M">org.springframework.batch.execution.step.ItemOrientedStepTests.java</file>
			<file type="M">org.springframework.batch.execution.job.SimpleJob.java</file>
			<file type="M">org.springframework.batch.execution.repository.SimpleJobRepositoryTests.java</file>
			<file type="M">org.springframework.batch.core.domain.JobInstance.java</file>
		</fixedFiles>
	</bug>
	<bug id="413" opendate="2008-03-04 04:55:02" fixdate="2008-03-04 05:36:10" resolution="Fixed">
		<buginformation>
			<summary>Unhandled IndexOutOfBounds in DrivingQueryItemReader</summary>
			<description>In the getCurrentKey() method of org.springframework.batch.io.driving.DrivingQueryItemReader, if currentIndex is 0, you will get an ArrayIndexOutOfBoundsException. This occurred when my KeyGenerator query returned 0 results for a particular batch job.
Is this supposed to be handled gracefully or is it an error?  Is it a condition that my query must return at least 1 result?</description>
			<version>1.0.0.m4</version>
			<fixedVersion>1.0.0.rc1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.io.driving.DrivingQueryItemReader.java</file>
			<file type="M">org.springframework.batch.io.driving.DrivingQueryItemReaderTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="412" opendate="2008-03-04 02:44:44" fixdate="2008-03-04 22:35:34" resolution="Fixed">
		<buginformation>
			<summary>consistent ItemStream key prefixes</summary>
			<description>ItemStream key names seem to follow the convention to use the short class name as key prefix - this should be consolidated (some use full class name, others hard-coded strings with out of date class name values)</description>
			<version>1.0.0.m5</version>
			<fixedVersion>1.0.0.rc1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.io.cursor.JdbcCursorItemReader.java</file>
			<file type="M">org.springframework.batch.io.file.FlatFileItemReader.java</file>
			<file type="M">org.springframework.batch.io.driving.support.SingleColumnJdbcKeyGenerator.java</file>
			<file type="M">org.springframework.batch.io.file.FlatFileItemWriter.java</file>
			<file type="M">org.springframework.batch.io.file.FlatFileItemReaderAdvancedTests.java</file>
			<file type="M">org.springframework.batch.io.xml.StaxEventItemWriterTests.java</file>
			<file type="M">org.springframework.batch.io.file.FlatFileItemWriterTests.java</file>
			<file type="M">org.springframework.batch.io.cursor.HibernateCursorItemReader.java</file>
			<file type="M">org.springframework.batch.io.driving.support.MultipleColumnJdbcKeyGenerator.java</file>
			<file type="M">org.springframework.batch.io.xml.StaxEventItemReaderTests.java</file>
			<file type="M">org.springframework.batch.io.driving.support.SingleColumnJdbcKeyGeneratorIntegrationTests.java</file>
			<file type="M">org.springframework.batch.io.xml.StaxEventItemWriter.java</file>
			<file type="M">org.springframework.batch.io.xml.StaxEventItemReader.java</file>
			<file type="M">org.springframework.batch.io.driving.support.IbatisKeyGenerator.java</file>
		</fixedFiles>
		<links>
			<link type="Depends" description="is depended on by">168</link>
		</links>
	</bug>
	<bug id="427" opendate="2008-03-05 16:52:37" fixdate="2008-03-05 18:25:39" resolution="Fixed">
		<buginformation>
			<summary>Another example of dual extends and implements</summary>
			<description>Using eUML to reverse engineer the models and finding more examples of cleanup that needs to occur in the ItemWriter hierarchy - a very small fix.  In this case CompositeItemWriter is both extending AbstractItemWriter and implementing ItemWriter.  Remove ItemWriter from implements list.</description>
			<version>1.0.0.rc1</version>
			<fixedVersion>1.0.0.rc1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.writer.CompositeItemWriter.java</file>
			<file type="M">org.springframework.batch.io.support.HibernateAwareItemWriter.java</file>
		</fixedFiles>
	</bug>
	<bug id="409" opendate="2008-03-03 23:10:59" fixdate="2008-03-06 05:08:52" resolution="Fixed">
		<buginformation>
			<summary>StatefulRetryStepFactoryBean needs to co-ordinate exception handler with retry policy</summary>
			<description>StatefulRetryStepFactoryBean needs to co-ordinate exception handler with retry policy.</description>
			<version>1.0.0.m5</version>
			<fixedVersion>1.0.0.rc1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.execution.step.support.StatefulRetryStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.execution.step.support.DefaultStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.execution.step.support.StatefulRetryStepFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.retry.RetryPolicy.java</file>
		</fixedFiles>
	</bug>
	<bug id="423" opendate="2008-03-05 11:16:08" fixdate="2008-03-07 18:16:36" resolution="Fixed">
		<buginformation>
			<summary>SimpleExitStatusExceptionClassifier never returns a value that will result in ExitMapper.JVM_EXITCODE_JOB_ERROR</summary>
			<description>SimpleExitStatusExceptionClassifier does not ever return ExitCodeMapper.NO_SUCH_JOB or JOB_NOT_PROVIDED, therefore JVM_EXITCODE_JOB_ERROR (2) is never returned to the command line.
The SimpleExitStatusExceptionClassifier should either return these values appropriately, or JVM_EXITCODE_JOB_ERROR and the two ExitCodeMapper values NO_SUCH_JOB and JOB_NOT_PROVIDED should be removed from the SimpleJvmExitCodeMapper.</description>
			<version>1.0.0.m5</version>
			<fixedVersion>1.0.0.rc1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.execution.step.support.SimpleExitStatusExceptionClassifier.java</file>
			<file type="M">org.springframework.batch.execution.step.support.SimpleExitStatusExceptionClassifierTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="439" opendate="2008-03-07 18:56:09" fixdate="2008-03-07 19:20:05" resolution="Fixed">
		<buginformation>
			<summary>Restart not working properly with Oracle</summary>
			<description>Restart not working properly with Oracle.  This is a weird one.  Some people seem to have the problem and others not (see forum thread, dating from pre-m3: http://forum.springframework.org/showthread.php?t=46821).</description>
			<version>1.0.0.m5</version>
			<fixedVersion>1.0.0.rc1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.execution.repository.dao.JdbcJobInstanceDao.java</file>
		</fixedFiles>
	</bug>
	<bug id="438" opendate="2008-03-06 23:08:03" fixdate="2008-03-08 06:41:48" resolution="Fixed">
		<buginformation>
			<summary>ExitStatus constants cleanup</summary>
			<description>ExitStatus constants need to be reviewed and cleaned up - some of them are not used anymore (outside tests)</description>
			<version>1.0.0.m5</version>
			<fixedVersion>1.0.0.rc1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.repeat.ExitStatusTests.java</file>
			<file type="M">org.springframework.batch.execution.job.SimpleJobTests.java</file>
			<file type="M">org.springframework.batch.repeat.ExitStatus.java</file>
		</fixedFiles>
		<links>
			<link type="Related" description="is related to">434</link>
		</links>
	</bug>
	<bug id="329" opendate="2008-01-29 20:38:14" fixdate="2008-03-08 06:59:50" resolution="Fixed">
		<buginformation>
			<summary>Make "VERSION" meaningful?</summary>
			<description>The version field in Entity and the corresponding VERSION field in the database schema doesn&amp;amp;apos;t seem to have any meaning right now. Where are these values supposed to come from? I can&amp;amp;apos;t seem to track it down in the code. 
It would make sense for job instance to have the version number of the job config as defined by the user, and likewise for step / step config
I can&amp;amp;apos;t imagine what version would mean for the execution metadata... if it has the same meaning then it&amp;amp;apos;s redundant.
Or am I misunderstanding what the version field is supposed to mean?</description>
			<version>1.0.0.m4</version>
			<fixedVersion>1.0.0.rc1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.execution.repository.dao.MapJobExecutionDaoTests.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.MapStepExecutionDaoTests.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.MapStepExecutionDao.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.MapJobInstanceDao.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.MapJobExecutionDao.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.JdbcJobInstanceDao.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.AbstractJobDaoTests.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.MapJobInstanceDaoTests.java</file>
			<file type="M">org.springframework.batch.execution.repository.dao.JdbcJobExecutionDao.java</file>
		</fixedFiles>
	</bug>
	<bug id="335" opendate="2008-02-04 00:31:26" fixdate="2008-03-10 07:40:28" resolution="Fixed">
		<buginformation>
			<summary>MultipleColumnJdbcKeyGenerator, various</summary>
			<description>In class: org.springframework.batch.io.driving.support.MultipleColumnJdbcKeyGenerator
1) Method setRestartQuery is a duplicate method of setRestartSql
2) The restart data key mapper (field keyMapper of type StreamContextRowMapper) should probably not be settable ...
3) ... it should probably be renamed from keyMapper to something to the effect of restartKeyMapper...
4) ... accordingly, a separate injectable keyMapper should be added (symmetrically with the SingleColumn version)  it&amp;amp;apos;s useless for me to map my results to restart data, I need to map it to a business domain object</description>
			<version>1.0.0.m4</version>
			<fixedVersion>1.0.0.rc1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="D">org.springframework.batch.item.database.KeyGenerator.java</file>
			<file type="M">org.springframework.batch.item.database.SingleColumnJdbcDrivingQueryItemReaderIntegrationTests.java</file>
			<file type="D">org.springframework.batch.item.database.support.IbatisKeyGenerator.java</file>
			<file type="M">org.springframework.batch.item.database.DrivingQueryItemReaderTests.java</file>
			<file type="M">org.springframework.batch.item.database.IbatisDrivingQueryItemReader.java</file>
			<file type="M">org.springframework.batch.item.database.support.SingleColumnJdbcKeyGeneratorIntegrationTests.java</file>
			<file type="M">org.springframework.batch.item.database.support.MultipleColumnJdbcKeyGeneratorIntegrationTests.java</file>
			<file type="M">org.springframework.batch.item.database.support.ExecutionContextRowMapper.java</file>
			<file type="M">org.springframework.batch.item.database.IbatisItemReaderIntegrationTests.java</file>
			<file type="M">org.springframework.batch.item.database.MultipleColumnJdbcDrivingQueryItemReaderIntegrationTests.java</file>
			<file type="M">org.springframework.batch.item.database.DrivingQueryItemReader.java</file>
			<file type="D">org.springframework.batch.item.database.support.SingleColumnJdbcKeyGenerator.java</file>
			<file type="M">org.springframework.batch.item.database.support.ColumnMapExecutionContextRowMapper.java</file>
			<file type="D">org.springframework.batch.item.database.support.MultipleColumnJdbcKeyGenerator.java</file>
		</fixedFiles>
	</bug>
	<bug id="383" opendate="2008-02-24 21:46:45" fixdate="2008-03-11 02:32:07" resolution="Fixed">
		<buginformation>
			<summary>Remove Java 5 features from samples</summary>
			<description>Remove Java 5 features from samples: it is OK for the main jars to require Java 5 for compilation, as long as they can be shipped with 1.4 compatibility.  But the samples probably need to be 1.4 compatible at the source level (e.g. no StringBuilder, Integer.valueOf, etc.).  Once it is fixed an additional build plan in Bamboo would help</description>
			<version>1.0.0.m5</version>
			<fixedVersion>1.0.0.rc1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.support.DefaultJobParametersConverter.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemWriterTests.java</file>
			<file type="M">org.springframework.batch.item.file.transform.RecursiveCollectionItemTransformer.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReaderAdvancedTests.java</file>
			<file type="M">org.springframework.batch.core.JobParametersTests.java</file>
			<file type="M">org.springframework.batch.item.database.support.SingleColumnJdbcKeyCollector.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemWriter.java</file>
			<file type="M">org.springframework.batch.io.oxm.AbstractStaxEventReaderItemReaderTests.java</file>
			<file type="M">org.springframework.batch.core.launch.support.ScheduledJobParametersFactory.java</file>
			<file type="M">org.springframework.batch.core.support.DefaultJobParametersConverterTests.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReaderBasicTests.java</file>
			<file type="M">org.springframework.batch.config.DatasourceTests.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemReaderTests.java</file>
			<file type="M">org.springframework.batch.repeat.jms.SynchronousTests.java</file>
			<file type="M">org.springframework.batch.support.PropertiesConverter.java</file>
			<file type="M">org.springframework.batch.core.launch.SimpleJobLauncherTests.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemReader.java</file>
			<file type="M">org.springframework.batch.item.database.HibernateCursorItemReader.java</file>
			<file type="M">org.springframework.batch.repeat.jms.AsynchronousTests.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemWriter.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReader.java</file>
			<file type="M">org.springframework.retry.jms.SynchronousTests.java</file>
			<file type="M">org.springframework.batch.item.database.JdbcCursorItemReader.java</file>
			<file type="M">org.springframework.batch.sample.mapping.OrderItemFieldSetMapperTests.java</file>
			<file type="M">org.springframework.batch.repeat.exception.LogOrRethrowExceptionHandler.java</file>
			<file type="M">org.springframework.batch.retry.jms.SynchronousTests.java</file>
			<file type="M">org.springframework.batch.core.step.ItemOrientedStepTests.java</file>
			<file type="M">org.springframework.batch.core.step.TaskletStepTests.java</file>
			<file type="M">org.springframework.batch.io.oxm.AbstractStaxEventWriterItemWriterTests.java</file>
			<file type="M">org.springframework.batch.core.launch.support.ScheduledJobParametersFactoryTests.java</file>
			<file type="M">org.springframework.batch.core.launch.support.SimpleExportedJobLauncherTests.java</file>
			<file type="M">org.springframework.batch.core.job.AbstractJobTests.java</file>
			<file type="M">org.springframework.batch.jms.ExternalRetryInBatchTests.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemWriterTests.java</file>
			<file type="M">org.springframework.batch.item.database.support.IbatisKeyCollector.java</file>
			<file type="M">org.springframework.batch.repeat.exception.LogOrRethrowExceptionHandlerTests.java</file>
			<file type="M">org.springframework.batch.repeat.interceptor.RepeatOperationsInterceptor.java</file>
			<file type="M">org.springframework.batch.retry.jms.ExternalRetryTests.java</file>
			<file type="M">org.springframework.batch.sample.item.writer.CustomerCreditIncreaseWriter.java</file>
			<file type="M">org.springframework.batch.sample.advice.JobExecutionNotificationPublisherTests.java</file>
			<file type="M">org.springframework.batch.sample.dao.OrderTransformerTests.java</file>
			<file type="M">org.springframework.batch.sample.dao.JdbcGameDaoIntegrationTests.java</file>
			<file type="M">org.springframework.batch.sample.dao.JdbcPlayerSummaryDao.java</file>
			<file type="M">org.springframework.batch.sample.FixedLengthImportJobFunctionalTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="443" opendate="2008-03-11 05:19:11" fixdate="2008-03-11 05:22:31" resolution="Fixed">
		<buginformation>
			<summary>ItemOrientedStep might not either commit or rollback transaction</summary>
			<description>ItemOrientedStep might not either commit or rollback transaction.  There is a catch (CommitFailedException) that leads to a simple rethrow and no attempt to rollback.</description>
			<version>1.0.0.m5</version>
			<fixedVersion>1.0.0.rc1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.ItemOrientedStepTests.java</file>
			<file type="M">org.springframework.batch.core.step.ItemOrientedStep.java</file>
			<file type="M">org.springframework.batch.core.step.LimitCheckingItemSkipPolicy.java</file>
		</fixedFiles>
	</bug>
	<bug id="449" opendate="2008-03-12 20:55:06" fixdate="2008-03-12 22:22:22" resolution="Fixed">
		<buginformation>
			<summary>skip synchronization between reader and writer</summary>
			<description>ItemSkipPolicyItemHandler always calls skip on both reader and writer. If reader threw the exception it is one item ahead of the writer, so calling skip makes reader skip the item that caused the error, but writer will skip the previous item.</description>
			<version>1.0.0.m5</version>
			<fixedVersion>1.0.0.rc1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.SkipLimitStepFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.step.SimpleItemHandler.java</file>
			<file type="M">org.springframework.batch.core.step.ItemSkipPolicyItemHandler.java</file>
		</fixedFiles>
	</bug>
	<bug id="448" opendate="2008-03-12 02:06:24" fixdate="2008-03-13 01:23:21" resolution="Fixed">
		<buginformation>
			<summary>StaxEventItemWriter creates invalid xml for zero row documents</summary>
			<description>Copied from http://forum.springframework.org/showthread.php?t=51054 :
The seems to be a minor bug in org.springframework.batch.io.xml.StaxEventItemWrit er which causes it to generate invalid xml for output files that have zero rows e.g.
&amp;lt;?xml version=&amp;amp;apos;1.0&amp;amp;apos; encoding=&amp;amp;apos;UTF-8&amp;amp;apos;?&amp;gt;&amp;lt;modules&amp;lt;/modules&amp;gt;
rather than
&amp;lt;?xml version=&amp;amp;apos;1.0&amp;amp;apos; encoding=&amp;amp;apos;UTF-8&amp;amp;apos;?&amp;gt;&amp;lt;modules&amp;gt;&amp;lt;/modules&amp;gt;
It looks like it is due to the frig in endDocument() which writes the end tag manually.
I have subclassed it in my project and overridden the endDocument() and added another event to the writer (writer.add(factory.createCharacters(""))), to get round this problem. This extra &amp;amp;apos;useless&amp;amp;apos; event seems to result in the startElement event being rendered correctly.</description>
			<version>1.0.0.m5</version>
			<fixedVersion>1.0.0.rc1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemWriter.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemWriterTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="457" opendate="2008-03-13 07:45:54" fixdate="2008-03-13 20:54:41" resolution="Fixed">
		<buginformation>
			<summary>Error handling broken in SimpleJob</summary>
			<description>SimpleJob.execute() uses rethrow() to rethrow all Throwables caught during execution.  rethrow checks to see if something is a RuntimeException and wraps it if it is not.
the issue is that anything that is an Error (OutOfMemory, StackOverflow, etc.) is caught and wrapped as an UnexpectedJobExecutionException.  errors are inadvertently reclassified as exceptions.
honestly, i think that it&amp;amp;apos;s a little dodgy to be catching errors anyway, but if you must, rethrow needs to be corrected.</description>
			<version>1.0.0.m5</version>
			<fixedVersion>1.0.0.rc1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.repeat.exception.LogOrRethrowExceptionHandlerTests.java</file>
			<file type="M">org.springframework.batch.repeat.exception.RethrowOnThresholdExceptionHandlerTests.java</file>
			<file type="M">org.springframework.batch.repeat.exception.DefaultExceptionHandlerTests.java</file>
			<file type="M">org.springframework.batch.repeat.support.RepeatTemplate.java</file>
			<file type="M">org.springframework.batch.core.step.TaskletStep.java</file>
			<file type="M">org.springframework.batch.core.job.SimpleJob.java</file>
			<file type="M">org.springframework.batch.core.step.ItemOrientedStep.java</file>
			<file type="M">org.springframework.batch.repeat.exception.DefaultExceptionHandler.java</file>
			<file type="M">org.springframework.batch.core.step.ItemOrientedStepTests.java</file>
			<file type="M">org.springframework.batch.core.job.SimpleJobTests.java</file>
			<file type="M">org.springframework.batch.core.step.TaskletStepTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="454" opendate="2008-03-13 04:33:30" fixdate="2008-03-13 22:19:56" resolution="Fixed">
		<buginformation>
			<summary>broken step&amp;apos;s isAllowedStartIfComplete property</summary>
			<description>When restarting job should restore execution context only for the step that crashed. If a step completed successfully but has isAllowedStartIfComplete=true, it needs to be started with empty execution context.</description>
			<version>1.0.0.m5</version>
			<fixedVersion>1.0.0.rc1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.job.SimpleJobTests.java</file>
			<file type="M">org.springframework.batch.core.job.SimpleJob.java</file>
		</fixedFiles>
	</bug>
	<bug id="459" opendate="2008-03-14 01:34:45" fixdate="2008-03-14 03:23:21" resolution="Fixed">
		<buginformation>
			<summary>unused StepExecution methods</summary>
			<description>item count and commit count have setters and incrementer methods that are unused (the values are adjusted using apply(StepContribution).</description>
			<version>1.0.0.m5</version>
			<fixedVersion>1.0.0.rc1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.StepExecution.java</file>
			<file type="M">org.springframework.batch.core.StepExecutionTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="468" opendate="2008-03-14 05:54:09" fixdate="2008-03-14 20:47:59" resolution="Fixed">
		<buginformation>
			<summary>ExitStatusExceptionClassifier, ExitCodeMapper and simple versions thereof (and others?) incorrectly moved into step.item package</summary>
			<description>Interfaces mentioned in summary and their implementations should be under the step package - they are just as relevant to TaskletSteps or ChunkedSteps as they are to ItemOrientedSteps
I&amp;amp;apos;m also confused as to what the StepExecutionSynchronizer, et al. and StepInterruptionPolicy et al. are doing there. These seem like general step concerns, not item-related step concerns.</description>
			<version>1.0.0.rc1</version>
			<fixedVersion>1.0.0.rc1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="D">org.springframework.batch.core.step.item.NeverSkipItemSkipPolicy.java</file>
			<file type="M">org.springframework.batch.core.step.item.ItemSkipPolicyItemHandler.java</file>
			<file type="D">org.springframework.batch.core.step.item.SimpleExitStatusExceptionClassifierTests.java</file>
			<file type="D">org.springframework.batch.core.step.item.ExitStatusExceptionClassifier.java</file>
			<file type="M">org.springframework.batch.core.launch.support.SimpleJvmExitCodeMapper.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.AbstractStepDaoTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.ItemOrientedStep.java</file>
			<file type="D">org.springframework.batch.core.step.item.StepExecutionSynchronizer.java</file>
			<file type="D">org.springframework.batch.core.step.item.SkipLimitExceededException.java</file>
			<file type="D">org.springframework.batch.core.step.item.SimpleExitStatusExceptionClassifier.java</file>
			<file type="M">org.springframework.batch.core.launch.support.ExitCodeMapper.java</file>
			<file type="M">org.springframework.batch.core.step.item.ItemOrientedStepTests.java</file>
			<file type="M">org.springframework.batch.core.StepContributionTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.StepExecutorInterruptionTests.java</file>
			<file type="M">org.springframework.batch.core.StepContribution.java</file>
			<file type="D">org.springframework.batch.core.step.item.BackportConcurrentStepExecutionSynchronizer.java</file>
			<file type="D">org.springframework.batch.core.step.item.LimitCheckingItemSkipPolicy.java</file>
			<file type="M">org.springframework.batch.core.job.SimpleJobTests.java</file>
			<file type="M">org.springframework.batch.core.launch.support.CommandLineJobRunner.java</file>
			<file type="D">org.springframework.batch.core.step.item.StepInterruptionPolicy.java</file>
			<file type="M">org.springframework.batch.core.launch.support.SimpleJvmExitCodeMapperTests.java</file>
			<file type="D">org.springframework.batch.core.step.item.ThreadStepInterruptionPolicy.java</file>
			<file type="D">org.springframework.batch.core.step.item.JdkConcurrentStepExecutionSynchronizer.java</file>
			<file type="M">org.springframework.batch.sample.step.support.NoopStepInterruptionPolicy.java</file>
			<file type="D">org.springframework.batch.core.step.item.ThreadStepInterruptionPolicyTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.SkipLimitStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.step.item.SkipLimitReadFailurePolicyTests.java</file>
			<file type="D">org.springframework.batch.core.ItemSkipPolicy.java</file>
			<file type="D">org.springframework.batch.core.step.item.AlwaysSkipItemSkipPolicy.java</file>
			<file type="D">org.springframework.batch.core.step.item.StepExecutionSyncronizerFactory.java</file>
		</fixedFiles>
	</bug>
	<bug id="465" opendate="2008-03-14 05:33:50" fixdate="2008-03-14 20:55:13" resolution="Fixed">
		<buginformation>
			<summary>The term "exit code" is overloaded</summary>
			<description>In the ExitStatus class exit code refers to the string representing the exit status e.g. FAILED
In the CommandLineJobRunner exit code refers to what will be returned to the OS
One of these should be changed to remove confusion, e.g.
 return exitCodeMapper.getExitCode(jobExecution.getExitStatus().getExitCode());  
At first glance can you tell what the heck this does? 
</description>
			<version>1.0.0.rc1</version>
			<fixedVersion>1.0.0.rc1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="D">org.springframework.batch.core.step.item.NeverSkipItemSkipPolicy.java</file>
			<file type="M">org.springframework.batch.core.step.item.ItemSkipPolicyItemHandler.java</file>
			<file type="D">org.springframework.batch.core.step.item.SimpleExitStatusExceptionClassifierTests.java</file>
			<file type="D">org.springframework.batch.core.step.item.ExitStatusExceptionClassifier.java</file>
			<file type="M">org.springframework.batch.core.launch.support.SimpleJvmExitCodeMapper.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.AbstractStepDaoTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.ItemOrientedStep.java</file>
			<file type="D">org.springframework.batch.core.step.item.StepExecutionSynchronizer.java</file>
			<file type="D">org.springframework.batch.core.step.item.SkipLimitExceededException.java</file>
			<file type="D">org.springframework.batch.core.step.item.SimpleExitStatusExceptionClassifier.java</file>
			<file type="M">org.springframework.batch.core.launch.support.ExitCodeMapper.java</file>
			<file type="M">org.springframework.batch.core.step.item.ItemOrientedStepTests.java</file>
			<file type="M">org.springframework.batch.core.StepContributionTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.StepExecutorInterruptionTests.java</file>
			<file type="M">org.springframework.batch.core.StepContribution.java</file>
			<file type="D">org.springframework.batch.core.step.item.BackportConcurrentStepExecutionSynchronizer.java</file>
			<file type="D">org.springframework.batch.core.step.item.LimitCheckingItemSkipPolicy.java</file>
			<file type="M">org.springframework.batch.core.job.SimpleJobTests.java</file>
			<file type="M">org.springframework.batch.core.launch.support.CommandLineJobRunner.java</file>
			<file type="D">org.springframework.batch.core.step.item.StepInterruptionPolicy.java</file>
			<file type="M">org.springframework.batch.core.launch.support.SimpleJvmExitCodeMapperTests.java</file>
			<file type="D">org.springframework.batch.core.step.item.ThreadStepInterruptionPolicy.java</file>
			<file type="D">org.springframework.batch.core.step.item.JdkConcurrentStepExecutionSynchronizer.java</file>
			<file type="M">org.springframework.batch.sample.step.support.NoopStepInterruptionPolicy.java</file>
			<file type="D">org.springframework.batch.core.step.item.ThreadStepInterruptionPolicyTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.SkipLimitStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.step.item.SkipLimitReadFailurePolicyTests.java</file>
			<file type="D">org.springframework.batch.core.ItemSkipPolicy.java</file>
			<file type="D">org.springframework.batch.core.step.item.AlwaysSkipItemSkipPolicy.java</file>
			<file type="D">org.springframework.batch.core.step.item.StepExecutionSyncronizerFactory.java</file>
		</fixedFiles>
	</bug>
	<bug id="461" opendate="2008-03-14 02:40:26" fixdate="2008-03-16 22:21:52" resolution="Fixed">
		<buginformation>
			<summary>skip counting</summary>
			<description>both StepExecution#apply(StepContribution) and StepContribution.getSkipCount() add the other&amp;amp;apos;s skip count to the total number of skipped items, so the eventual result reminds of Fibonacci.</description>
			<version>1.0.0.m5</version>
			<fixedVersion>1.0.0.rc1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.StepExecution.java</file>
			<file type="M">org.springframework.batch.core.step.item.ItemOrientedStep.java</file>
			<file type="M">org.springframework.batch.core.step.item.SkipLimitStepFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.ItemOrientedStepTests.java</file>
			<file type="M">org.springframework.batch.core.StepContributionTests.java</file>
			<file type="M">org.springframework.batch.core.StepContribution.java</file>
			<file type="M">org.springframework.batch.core.step.item.ItemSkipPolicyItemHandler.java</file>
		</fixedFiles>
	</bug>
	<bug id="483" opendate="2008-03-18 06:59:49" fixdate="2008-03-18 07:13:33" resolution="Fixed">
		<buginformation>
			<summary>ExecutionContext does not handle null values correctly</summary>
			<description>ExecutionContext still does not handle null values correctly:
	public void put(String key, Object value) 
{
		Assert.isInstanceOf(Serializable.class, value, "Value: [ " + value + "must be serializable.");
		dirty = true;
		map.put(key, value);
	}

since null won&amp;amp;apos;t pass this test, it will throw an error.</description>
			<version>1.0.0.rc1</version>
			<fixedVersion>1.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.ExecutionContext.java</file>
			<file type="M">org.springframework.batch.item.ExecutionContextTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="444" opendate="2008-03-11 10:33:16" fixdate="2008-03-18 21:21:01" resolution="Fixed">
		<buginformation>
			<summary>Remove null check from ExecutionContext#putString</summary>
			<description>The ExecutionContext putString() method does an null check and throws an IllegalArgumentException if the value is null. (Assert.notNull) but this can cause issues if someone stores a string like: executionContext.putString("key", new String()).  If the job fails and comes back from restart, it will pull a null value from the database, and the execution context will throw an exception.  The underlying map doesn&amp;amp;apos;t really care if it&amp;amp;apos;s null, and it seems like we shouldn&amp;amp;apos;t enforce new semantics.
Here&amp;amp;apos;s a like to the forum thread it was raised in:
http://forum.springframework.org/showthread.php?p=169118&amp;amp;posted=1#post169118
The JdbcCursorItemReader should also be modified to not put an empty string in, which only happens because we&amp;amp;apos;re putting in a comma delimited list of strings representing row numbers that have been skipped.  If it&amp;amp;apos;s empty nothing should be written.</description>
			<version>1.0.0.m5</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.ExecutionContext.java</file>
		</fixedFiles>
	</bug>
	<bug id="489" opendate="2008-03-19 00:32:57" fixdate="2008-03-19 01:44:13" resolution="Fixed">
		<buginformation>
			<summary>undocumented JobExecutionException</summary>
			<description>The root of job-centric exception hierarchy has empty javadoc</description>
			<version>1.0.0.rc1</version>
			<fixedVersion>1.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.JobExecutionException.java</file>
		</fixedFiles>
	</bug>
	<bug id="490" opendate="2008-03-19 01:11:03" fixdate="2008-03-19 02:06:17" resolution="Fixed">
		<buginformation>
			<summary>SkipLimitStepFactoryBean ignores the skippableExceptionClasses property</summary>
			<description>The value of this property should be passed to the underlying ExceptionHandler, but gets overwritten in this suspicious code fragment:
SimpleLimitExceptionHandler exceptionHandler = new SimpleLimitExceptionHandler();
exceptionHandler.setLimit(skipLimit);
exceptionHandler.setExceptionClasses(skippableExceptionClasses);
setExceptionHandler(new SimpleLimitExceptionHandler(skipLimit));</description>
			<version>1.0.0.rc1</version>
			<fixedVersion>1.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.SkipLimitStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.step.item.SkipLimitStepFactoryBeanTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="492" opendate="2008-03-19 02:12:39" fixdate="2008-03-19 02:56:02" resolution="Fixed">
		<buginformation>
			<summary>CommandLineJobRunner should close the spring context</summary>
			<description>In CommandLineJobRunner.start (), you create a new Spring context but don&amp;amp;apos;t close it at the end.
That means that if any spring bean is expecting some close method to be called (for flushing generated file for example), it won&amp;amp;apos;t work.
Grard COLLIN</description>
			<version>1.0.0.rc1</version>
			<fixedVersion>1.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.launch.support.CommandLineJobRunnerTests.java</file>
			<file type="M">org.springframework.batch.core.launch.support.CommandLineJobRunner.java</file>
		</fixedFiles>
	</bug>
	<bug id="495" opendate="2008-03-20 01:35:39" fixdate="2008-03-24 21:03:47" resolution="Fixed">
		<buginformation>
			<summary>readers must not clear buffers on mark()</summary>
			<description>Historically readers implemented TransactionSynchronization and the logic from afterCommit() was largely moved into current mark(). However, the contract of mark() differs significantly - it is not a point where the reader can safely forget the past events and clear its buffers. This relates to skipped item buffers in general and specifically to buffered XMLEvents in StaxEventItemReader.
The basic issue is that mark() is called also before re-processing rolled back chunk.</description>
			<version>1.0.0.rc1</version>
			<fixedVersion>1.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.ItemReader.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReader.java</file>
			<file type="M">org.springframework.batch.core.step.item.ItemOrientedStep.java</file>
		</fixedFiles>
	</bug>
	<bug id="491" opendate="2008-03-19 02:05:25" fixdate="2008-03-24 23:01:21" resolution="Fixed">
		<buginformation>
			<summary>checked exception handling</summary>
			<description>Specifying exception types for stepOperations&amp;amp;apos; exception handler doesn&amp;amp;apos;t work properly for checked exceptions. This is because chunkOperations&amp;amp;apos; exception handler is called first and wraps the checked exception into runtime RepeatException.</description>
			<version>1.0.0.rc1</version>
			<fixedVersion>1.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.repeat.support.RepeatTemplate.java</file>
			<file type="M">org.springframework.batch.repeat.interceptor.RepeatOperationsInterceptorTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.SkipLimitStepFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.repeat.exception.LogOrRethrowExceptionHandler.java</file>
			<file type="M">org.springframework.batch.repeat.exception.DefaultExceptionHandler.java</file>
			<file type="M">org.springframework.batch.repeat.exception.RethrowOnThresholdExceptionHandler.java</file>
			<file type="M">org.springframework.batch.core.step.item.SimpleRetryExceptionHandlerTests.java</file>
			<file type="M">org.springframework.batch.sample.exception.handler.FootballExceptionHandler.java</file>
			<file type="M">org.springframework.batch.repeat.exception.ExceptionHandler.java</file>
			<file type="M">org.springframework.batch.repeat.exception.RethrowOnThresholdExceptionHandlerTests.java</file>
			<file type="M">org.springframework.batch.repeat.exception.DefaultExceptionHandlerTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.SimpleRetryExceptionHandler.java</file>
			<file type="M">org.springframework.batch.repeat.exception.LogOrRethrowExceptionHandlerTests.java</file>
			<file type="M">org.springframework.batch.repeat.exception.SimpleLimitExceptionHandler.java</file>
			<file type="M">org.springframework.batch.repeat.exception.SimpleLimitExceptionHandlerTests.java</file>
			<file type="M">org.springframework.batch.repeat.exception.CompositeExceptionHandler.java</file>
			<file type="M">org.springframework.batch.repeat.exception.CompositeExceptionHandlerTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="478" opendate="2008-03-17 08:56:57" fixdate="2008-03-24 23:09:07" resolution="Fixed">
		<buginformation>
			<summary>Incorrect message logged in SimpleJobLauncher when TaskExecutor is set</summary>
			<description>Regardless of whether a (custom) TaskExecutor is specified, SimpleJobLauncher always logs the following message in afterPropertiesSet(): "No TaskExecutor has been set, defaulting to synchronous executor". See attached patch for a fix. Note that this patch requires that afterPropertiesSet() is called or else a NPE will be thrown.</description>
			<version>1.0.0.rc1</version>
			<fixedVersion>1.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.launch.SimpleJobLauncherTests.java</file>
			<file type="M">org.springframework.batch.core.repository.support.JobRepositoryFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.launch.support.SimpleJobLauncher.java</file>
		</fixedFiles>
	</bug>
	<bug id="507" opendate="2008-03-25 01:11:39" fixdate="2008-03-25 02:40:59" resolution="Fixed">
		<buginformation>
			<summary>FlatFileItemWriter OutputSource not initialised on FlatFileItemReader.open()</summary>
			<description>FlatFileItemWriter.OutputSource contains a number of member variables that are only initialised via the FlatFileItemWriter.set methods - for example setShouldDeleteIfExists.
If a writer is closed and then re-opened (ie same FlatFileItemWriter object is reused in same vm), a new OutputSource object is created, but it is not reinitialised so these attributes are defaulted - eg shouldDeleteIfExists defaults to true.
Apologies if this is a product of the way I am using the FlatFileItemWriter.  I am new to Spring and SpringBatch and don&amp;amp;apos;t properly understand the lifecycle of the beans. I might be misusing the FlatFileItemWriter - perhaps it should not be possible to close and then re-open one of these?
I have been using code below based on one of the sample jobs which seems to reuse the same writer on the second run of the jobs. My aim was to reproduce a second potential bug, whereby FlatFileItemWriter won&amp;amp;apos;t restart if it already exists but  no record of it exists in StepExecutionContext (eg if first run of job failed before this step commits for first time), however this bug is preventing me from doing this  - I am dependant on shouldDeleteIfExists being false, however I am finding that it is false on first run (set via my job.xml), but true on second run.
public class FlatFileItemWriterRestartTests extends AbstractBatchLauncherTests {
    public void testLaunchJob() throws Exception {
        final JobParameters jobParameters = new JobParameters();
        logger.info("Starting test");
        JobExecution jobExecution = null;
        try 
{
            jobExecution = launcher.run(getJob(), jobParameters);
        }
        catch (InfrastructureException expected) 
{
            logger.info("Caught Exception");
            logger.info(expected);
            assertTrue("Not planned exception: "+expected.getMessage(), expected.getMessage().toLowerCase().indexOf("planned")&amp;gt;=0);
        }

        // At this point existing FlatFileItemWriter is reused, 
        // but new OutputState  
        // is created, with default shouldDeleteIfExists=true 
        jobExecution = launcher.run(getJob(), jobParameters); 
        assertEquals(BatchStatus.COMPLETED, jobExecution.getStatus());
        logger.info("Completed");
    }
}
For reference I mentioned this on:
http://forum.springframework.org/showthread.php?t=51190</description>
			<version>1.0.0.rc1</version>
			<fixedVersion>1.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.FlatFileItemWriterTests.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemWriter.java</file>
		</fixedFiles>
	</bug>
	<bug id="513" opendate="2008-03-25 13:16:36" fixdate="2008-03-25 18:41:43" resolution="Fixed">
		<buginformation>
			<summary>CompositeItemReadListener, CompositeItemWriteListener using ChunkListeners?</summary>
			<description>The setListeners method in both composite listeners takes type ChunkListener[].... since we use 1.4.2, the list they get added to isn&amp;amp;apos;t parameterized so this would only get caught at runtime when they are cast back  this seems very broken to me.
I think this should be ItemReadListener[] and ItemWriteListener[], respectively?</description>
			<version>1.0.0.rc1</version>
			<fixedVersion>1.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.listener.CompositeItemWriteListener.java</file>
			<file type="M">org.springframework.batch.core.listener.CompositeItemWriteListenerTests.java</file>
			<file type="M">org.springframework.batch.core.listener.CompositeItemReadListener.java</file>
			<file type="M">org.springframework.batch.core.listener.CompositeItemReadListenerTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="510" opendate="2008-03-25 03:12:03" fixdate="2008-03-25 21:48:57" resolution="Fixed">
		<buginformation>
			<summary>FlatFileItemWriter.restarted logic fails if step fails before first chunk commit.</summary>
			<description>Forum ref  http://forum.springframework.org/showthread.php?p=171215
Scenario:

I have a Step that reads in items, and outputs via FFIW with shouldDeleteIfExists=false;
Step runs through a few items and output file buffer is flushed to disk
Job fails before first chunk commit (I am ending the job in a debugger).

On restart:

Output file accessed via FFIW will exist on the file system.
No record of it exists in the STEP_EXECUTION_CONTEXT table.

Restart the job (has to be in a new vm becasue of #batch-507) and it will fail with:
org.springframework.batch.item.exception.StreamException: Resource already exists: file [D:\temp\output1.csv]
at org.springframework.batch.io.file.FlatFileItemWriter$OutputState.initializeBufferedWriter(FlatFileItemWriter.java:378)
I think this is because outputState.restoreFrom is not getting called because STEP_EXECUTION_CONTEXT table has no data for this step (see code extract below).
        /**

Initialize the Output Template.
*
@see ResourceLifecycle#open()
*/
public void open(ExecutionContext executionContext) {
    OutputState outputState = getOutputState();
    if (executionContext.containsKey(getKey(RESTART_DATA_NAME))) 
{
        outputState.restoreFrom(executionContext);
    }
}

This means FFIW.restarted is false, and then initializeBufferedWriter fails in
....
    if (!restarted) {
	if (file.exists()) {
	    if (shouldDeleteIfExists) 
{
		file.delete();
	    }
 else 
{
		throw new ItemStreamException("Resource already exists: " + resource);
	    }
	}
.... </description>
			<version>1.0.0.rc1</version>
			<fixedVersion>1.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.ItemOrientedStep.java</file>
			<file type="M">org.springframework.batch.core.step.item.ItemOrientedStepTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="517" opendate="2008-03-26 20:59:53" fixdate="2008-03-26 22:05:41" resolution="Fixed">
		<buginformation>
			<summary>item writers need to handle empty flush gracefully</summary>
			<description>In case "item_count mod commit_interval == 0" there will be an empty extra chunk that only calls the item reader that will return null to indicate all items have been read. This results in flushing item writer without calling write(item) previously - an "empty" flush, that needs to be handled gracefully (e.g. BatchSqlUpdateItemWriter throws a confusing exception).
In principle the execution logic should be smart enough not to do silly things such as empty flushing, but it&amp;amp;apos;s unrealistic to fix for 1.0. Making sure writers handle empty flushing gracefully should be good enough for now.</description>
			<version>1.0.0.rc1</version>
			<fixedVersion>1.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.BatchSqlUpdateItemWriter.java</file>
			<file type="M">org.springframework.batch.item.database.BatchSqlUpdateItemWriterTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="511" opendate="2008-03-25 08:07:55" fixdate="2008-03-26 22:32:48" resolution="Fixed">
		<buginformation>
			<summary>read failures cause rollback</summary>
			<description>when using &amp;amp;apos;skipping&amp;amp;apos;, the item handler rethrows any read exception to delegate to the exception handler
protected Object read(StepContribution contribution) throws Exception {
		try 
{
			return getItemReader().read();
		}
		catch (Exception e) {
			if (itemSkipPolicy.shouldSkip(e, contribution.getStepSkipCount())) {
				contribution.incrementSkipCount();
				if (getItemReader() instanceof Skippable) 
{
					((Skippable) getItemReader()).skip();
				}
			}
			===&amp;gt;&amp;gt; throw e; &amp;lt;&amp;lt;===
		}
	}
the exception handler picks up the exception at the step level
...
SimpleLimitExceptionHandler exceptionHandler = new SimpleLimitExceptionHandler();
			exceptionHandler.setLimit(skipLimit);
			exceptionHandler.setExceptionClasses(skippableExceptionClasses);
			exceptionHandler.setFatalExceptionClasses(fatalExceptionClasses);
			setExceptionHandler(exceptionHandler);
			getStepOperations().setExceptionHandler(getExceptionHandler());
...
so, whenever you encounter an exception in the read, it rolls back all successful writes instead of just skipping the item and continuing.</description>
			<version>1.0.0.rc1</version>
			<fixedVersion>1.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.StepExecution.java</file>
			<file type="M">org.springframework.batch.core.step.item.ItemOrientedStep.java</file>
			<file type="M">org.springframework.batch.core.step.item.ItemSkipPolicyItemHandler.java</file>
			<file type="M">org.springframework.batch.core.step.item.ItemSkipPolicyItemHandlerTests.java</file>
			<file type="M">org.springframework.batch.core.StepContribution.java</file>
			<file type="M">org.springframework.batch.core.step.item.SkipLimitStepFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.SkipLimitStepFactoryBean.java</file>
		</fixedFiles>
	</bug>
	<bug id="523" opendate="2008-03-27 20:48:34" fixdate="2008-03-27 21:13:33" resolution="Fixed">
		<buginformation>
			<summary>FlatFileItemReader calls mark??</summary>
			<description>Line 151: 		mark();
Seems like this is a bug  it would break the mark/reset logic of the enclosing Step.</description>
			<version>1.0.0.rc1</version>
			<fixedVersion>1.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReader.java</file>
		</fixedFiles>
	</bug>
	<bug id="498" opendate="2008-03-20 10:16:31" fixdate="2008-03-28 02:11:50" resolution="Fixed">
		<buginformation>
			<summary>Skip method should get ExecutionContext as an argument</summary>
			<description>Skippable readers and writers are, most of the time, going to keep some sort of statistic about how much or what was skipped. It makes sense for these collaborators to have the ExecutionContext directly supplied as an argument the skip method rather than making each Skippable have to also implement StepListener to become context aware.
Since this is a change to a public API, requesting consideration for 1.0.0 release. Please vote / comment ASAP. Thanks.</description>
			<version>1.0.0.rc1</version>
			<fixedVersion>1.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.retry.policy.ItemWriterRetryPolicy.java</file>
			<file type="M">org.springframework.batch.retry.callback.ItemWriterRetryCallbackTests.java</file>
			<file type="M">org.springframework.batch.retry.callback.ItemWriterRetryCallback.java</file>
			<file type="M">org.springframework.batch.core.step.item.ItemSkipPolicyItemHandlerTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.ItemSkipPolicyItemHandler.java</file>
			<file type="M">org.springframework.batch.core.step.item.ItemOrientedStep.java</file>
			<file type="M">org.springframework.batch.core.step.item.BatchListenerFactoryHelper.java</file>
			<file type="M">org.springframework.batch.core.listener.CompositeStepExecutionListenerTests.java</file>
			<file type="M">org.springframework.batch.item.FailedItemIdentifier.java</file>
			<file type="M">org.springframework.batch.retry.callback.ItemReaderRetryCallback.java</file>
			<file type="M">org.springframework.batch.core.step.item.RepeatOperationsStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.retry.policy.ItemReaderRetryPolicyTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.SkipLimitStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.step.item.ItemOrientedStepTests.java</file>
			<file type="M">org.springframework.batch.core.job.SimpleJob.java</file>
			<file type="M">org.springframework.batch.retry.policy.ItemReaderRetryPolicy.java</file>
			<file type="M">org.springframework.batch.core.listener.MulticasterBatchListener.java</file>
			<file type="M">org.springframework.batch.core.job.SimpleJobTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.SimpleStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.listener.CompositeJobExecutionListenerTests.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReader.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReaderAdvancedTests.java</file>
			<file type="M">org.springframework.batch.item.support.DelegatingItemWriter.java</file>
			<file type="M">org.springframework.batch.item.database.JdbcCursorItemReader.java</file>
			<file type="M">org.springframework.batch.item.support.DelegatingItemReaderTests.java</file>
			<file type="M">org.springframework.batch.item.database.AbstractDataSourceItemReaderIntegrationTests.java</file>
			<file type="M">org.springframework.batch.item.database.DrivingQueryItemReader.java</file>
			<file type="M">org.springframework.batch.item.support.DelegatingItemReader.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemReaderTests.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemReader.java</file>
			<file type="M">org.springframework.batch.item.database.HibernateCursorItemReader.java</file>
			<file type="D">org.springframework.batch.item.Skippable.java</file>
			<file type="M">org.springframework.batch.sample.domain.CustomerCredit.java</file>
			<file type="M">org.springframework.batch.core.step.item.SimpleItemHandler.java</file>
			<file type="M">org.springframework.batch.core.step.item.SkipLimitStepFactoryBeanTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="533" opendate="2008-03-30 22:25:53" fixdate="2008-03-30 23:54:00" resolution="Fixed">
		<buginformation>
			<summary>prefix in the JobRepositoryFactoryBean does not apply to the sequences</summary>
			<description>...
dao.setJobIncrementer(incrementerFactory.getIncrementer(databaseType, "BATCH_JOB_SEQ"));
...
dao.setJobExecutionIncrementer(incrementerFactory.getIncrementer(databaseType, "BATCH_JOB_EXECUTION_SEQ"));
...
dao.setStepExecutionIncrementer(incrementerFactory.getIncrementer(databaseType, "BATCH_STEP_EXECUTION_SEQ"));
....
As you can see, the prefix is not applied to any of the sequences.</description>
			<version>1.0.0</version>
			<fixedVersion>1.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.repository.support.JobRepositoryFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.repository.support.JobRepositoryFactoryBeanTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="198" opendate="2007-11-12 17:58:21" fixdate="2008-03-31 20:48:28" resolution="Fixed">
		<buginformation>
			<summary>Make backoff policy tests less sensitive to virtualisation</summary>
			<description>Make backoff policy tests less sensitive to virtualisation - they keep failing because they run too slowly.</description>
			<version>1.0-m3</version>
			<fixedVersion>1.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.retry.backoff.StatelessBackOffPolicy.java</file>
			<file type="M">org.springframework.batch.retry.backoff.ExponentialBackOffPolicyTests.java</file>
			<file type="M">org.springframework.batch.retry.backoff.FixedBackOffPolicyTests.java</file>
			<file type="M">org.springframework.batch.retry.backoff.FixedBackOffPolicy.java</file>
			<file type="M">org.springframework.batch.retry.backoff.ExponentialBackOffPolicy.java</file>
		</fixedFiles>
	</bug>
	<bug id="529" opendate="2008-03-29 00:02:27" fixdate="2008-03-31 22:08:59" resolution="Fixed">
		<buginformation>
			<summary>StepExecutionListener.afterStep() should only be called on success</summary>
			<description>StepExecutionListener.afterStep() should only be called on success.  The interface javadocs don&amp;amp;apos;t say this, but I think it makes more sense for this callback to come only on a successful completion (since there is an onError() callback for the failure case).</description>
			<version>1.0.0</version>
			<fixedVersion>1.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.ItemOrientedStep.java</file>
			<file type="M">org.springframework.batch.core.step.item.ItemOrientedStepTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="532" opendate="2008-03-29 20:28:20" fixdate="2008-03-31 22:10:09" resolution="Fixed">
		<buginformation>
			<summary>StepExecutionListener can influence exit status but not status of step execution</summary>
			<description>StepExecutionListener can influence exit status but not status of step execution.  The exit status can be downgraded from COMPLETE to FAILED by returning FAILED from the afterStep() callback.  But the BatchStatus in the stepExecution is unchanged, so it looks as if the step was successful.  It&amp;amp;apos;s a hard decision to decide how to fix this.  I suggest that StepExecutionListener should be allowed to throw an exception to signal a failure, and treat that as a normal way for steps to fail, instead of trying to map exit codes to statuses.</description>
			<version>1.0.0</version>
			<fixedVersion>1.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.StepExecutionListener.java</file>
			<file type="M">org.springframework.batch.core.step.tasklet.TaskletStepTests.java</file>
			<file type="M">org.springframework.batch.core.step.tasklet.TaskletStep.java</file>
			<file type="M">org.springframework.batch.core.step.item.ItemOrientedStep.java</file>
			<file type="M">org.springframework.batch.core.step.item.ItemOrientedStepTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="97" opendate="2007-08-16 17:41:50" fixdate="2008-04-01 00:18:07" resolution="Fixed">
		<buginformation>
			<summary>Fix integration tests on Bamboo server</summary>
			<description>Fix integration tests on Bamboo server.  Because it is VMWare it runs slower than a normal machine (according to Ben) so the asynchronous tests keep failing in random places.  Disabled them for short term.</description>
			<version>1.0-m2</version>
			<fixedVersion>1.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.ItemOrientedStepTests.java</file>
			<file type="M">org.springframework.batch.retry.backoff.ExponentialBackOffPolicyTests.java</file>
			<file type="M">org.springframework.batch.retry.backoff.FixedBackOffPolicyTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="538" opendate="2008-04-01 05:42:29" fixdate="2008-04-01 06:16:21" resolution="Fixed">
		<buginformation>
			<summary>HibernateCursorItemReader close() doesn&amp;apos;t close statefull sessions correctly</summary>
			<description>	public void close(ExecutionContext executionContext) {
		initialized = false;
		if (cursor != null) 
{
			cursor.close();
		}
		currentProcessedRow = 0;
		if (useStatelessSession) {
			if (statelessSession != null) 
{
				statelessSession.close();
			}
		}
		else {
			if (statelessSession != null) {				statelessSession.close();			}
		}
	}
The close method above won&amp;amp;apos;t close correctly because if useStatelessSession is false, the statelessSession will always been false as well.</description>
			<version>1.0.0</version>
			<fixedVersion>1.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.HibernateCursorItemReaderStatefulIntegrationTests.java</file>
			<file type="M">org.springframework.batch.item.database.HibernateCursorItemReader.java</file>
		</fixedFiles>
	</bug>
	<bug id="537" opendate="2008-04-01 01:41:14" fixdate="2008-04-01 07:07:57" resolution="Fixed">
		<buginformation>
			<summary>Bad ItemKeyGenerator strategy can lead to infinite loop in retry</summary>
			<description>Bad ItemKeyGenerator strategy can lead to infinite loop in retry. http://forum.springframework.org/showthread.php?t=51766 is a good example.  Part of the problem here is that the skip limit is ignored when retry is in place (that&amp;amp;apos;s a bug as well).</description>
			<version>1.0.0</version>
			<fixedVersion>1.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.retry.policy.ItemWriterRetryPolicy.java</file>
			<file type="M">org.springframework.batch.core.step.item.SkipLimitStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.step.item.SimpleRetryExceptionHandlerTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.StatefulRetryStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.step.item.StatefulRetryStepFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.SimpleRetryExceptionHandler.java</file>
			<file type="M">org.springframework.batch.retry.policy.RetryContextCache.java</file>
			<file type="M">org.springframework.batch.retry.policy.MapRetryContextCache.java</file>
			<file type="M">org.springframework.batch.retry.policy.ItemWriterRetryPolicyTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="542" opendate="2008-04-01 18:38:01" fixdate="2008-04-01 19:19:15" resolution="Fixed">
		<buginformation>
			<summary>StatefulRetryStepFactoryBean still uses a local variable that refers to item provider</summary>
			<description>Local variable itemProviderRetryPolicy should be itemWriterRetryPolicy. No biggie.</description>
			<version>1.0.0</version>
			<fixedVersion>1.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.StatefulRetryStepFactoryBean.java</file>
		</fixedFiles>
	</bug>
	<bug id="545" opendate="2008-04-02 00:26:20" fixdate="2008-04-02 01:45:34" resolution="Fixed">
		<buginformation>
			<summary>RetryTemplate swallows Throwables that are not Exception or Error</summary>
			<description>The following code is missing an else clause that would rethrow unclassified throwable as RetryException perhaps:
private static void unwrapAndThrow(Throwable ex) throws Exception {
		if (ex instanceof Exception) 
{
			throw (Exception) ex;
		}
		else if (ex instanceof Error) 
{
			throw (Error) ex;
		}
}</description>
			<version>1.0.0</version>
			<fixedVersion>1.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.retry.support.RetryTemplate.java</file>
			<file type="M">org.springframework.batch.retry.support.RetryTemplateTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="549" opendate="2008-04-02 02:29:41" fixdate="2008-04-02 02:52:12" resolution="Fixed">
		<buginformation>
			<summary>JdbcCursorItemReader will not handle more than one restart</summary>
			<description>The JdbcCursorItemReader won&amp;amp;apos;t handle restarting more than once, since the BufferedResultSetReader returns only the records it&amp;amp;apos;s processed.  An extra unit test for this scenario should be added to the abstract integration tests as well.</description>
			<version>1.0.0</version>
			<fixedVersion>1.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.JdbcCursorItemReaderIntegrationTests.java</file>
			<file type="M">org.springframework.batch.item.database.JdbcCursorItemReader.java</file>
			<file type="M">org.springframework.batch.item.database.AbstractDataSourceItemReaderIntegrationTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="552" opendate="2008-04-02 22:12:18" fixdate="2008-04-02 23:21:48" resolution="Fixed">
		<buginformation>
			<summary>Fix samples-14 CI build (MBeanServer not automatically created in Java 1.4)</summary>
			<description>Fix samples-14 CI build (MBeanServer not automatically created in Java 1.4)</description>
			<version>1.0.0</version>
			<fixedVersion>1.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.sample.launch.RemoteLauncherTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="560" opendate="2008-04-04 23:37:49" fixdate="2008-04-06 18:19:37" resolution="Fixed">
		<buginformation>
			<summary>StepExecutionResourceProxy can not be used with FlatFileItemWriter</summary>
			<description>StepExecutionResourceProxy can work with FlatFileItemReader, but FlatFileItemWriter. It seems FlatFileItemWriter try to get the real file during its afterPropertiesSet(), which means before StepExecutionResourceProxy.beforeStep() get called. Hence, the "The delegate resource has not been initialised..." exception always get thrown by StepExecutionResourceProxy.</description>
			<version>1.0.0</version>
			<fixedVersion>1.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.FlatFileItemWriterTests.java</file>
			<file type="M">org.springframework.batch.item.util.FileUtilsTests.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemWriter.java</file>
			<file type="M">org.springframework.batch.item.util.FileUtils.java</file>
		</fixedFiles>
	</bug>
	<bug id="561" opendate="2008-04-06 14:45:56" fixdate="2008-04-06 19:09:25" resolution="Fixed">
		<buginformation>
			<summary>ItemReaderAdapter still implements unnecessary close method</summary>
			<description>Summary says it all</description>
			<version>1.0.0</version>
			<fixedVersion>1.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.adapter.ItemReaderAdapter.java</file>
		</fixedFiles>
	</bug>
	<bug id="558" opendate="2008-04-04 14:38:45" fixdate="2008-04-06 19:19:50" resolution="Fixed">
		<buginformation>
			<summary>TaskletAdapter still maps to CONTINUABLE by default</summary>
			<description>Summary says it all.</description>
			<version>1.0.0</version>
			<fixedVersion>1.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.tasklet.TaskletAdapter.java</file>
			<file type="M">org.springframework.batch.core.step.tasklet.TaskletAdapterTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="564" opendate="2008-04-06 20:39:26" fixdate="2008-04-06 20:40:34" resolution="Fixed">
		<buginformation>
			<summary>CompositeSkipListener has method from StepExecutionListener</summary>
			<description>CompositeSkipListener has method from StepExecutionListener - clearly should be removed as it will never be called.</description>
			<version>1.0.0</version>
			<fixedVersion>1.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.listener.CompositeSkipListener.java</file>
		</fixedFiles>
	</bug>
	<bug id="565" opendate="2008-04-06 21:02:30" fixdate="2008-04-06 21:37:37" resolution="Fixed">
		<buginformation>
			<summary>StatefulRetryStepFactoryBean ignores skip configuration</summary>
			<description>StatefulRetryStepFactoryBean ignores skip limit and exceptions</description>
			<version>1.0.0</version>
			<fixedVersion>1.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.SkipLimitStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.step.item.StatefulRetryStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.step.item.SimpleStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.step.item.StatefulRetryStepFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.SkipLimitStepFactoryBeanTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="531" opendate="2008-03-29 03:06:34" fixdate="2008-04-08 14:44:20" resolution="Fixed">
		<buginformation>
			<summary>Off by one error in itemCount of StepExecution</summary>
			<description>The StepExecution always has one more item at the end than it should.  Here&amp;amp;apos;s a unit test (insert in ItemOrientedStepTests):
	public void testStepToCompletion() throws Exception 
{

		RepeatTemplate template = new RepeatTemplate();

		// process all items:
		template.setCompletionPolicy(new DefaultResultCompletionPolicy());
		itemOrientedStep.setStepOperations(template);
		
		JobExecution jobExecutionContext = new JobExecution(jobInstance);
		StepExecution stepExecution = new StepExecution(itemOrientedStep, jobExecutionContext);

		itemOrientedStep.execute(stepExecution);
		assertEquals(3, processed.size());
		assertEquals(3, stepExecution.getItemCount().intValue());
	}
</description>
			<version>1.0.0</version>
			<fixedVersion>1.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.ItemOrientedStep.java</file>
			<file type="M">org.springframework.batch.core.step.item.ItemOrientedStepTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.SimpleItemHandler.java</file>
		</fixedFiles>
	</bug>
	<bug id="553" opendate="2008-04-03 03:02:17" fixdate="2008-04-08 14:56:08" resolution="Fixed">
		<buginformation>
			<summary>There is no way to set the ChunkOperations ExceptionHandler in any factory bean</summary>
			<description>The SimpleStepFactoryBean has a setter for the ExceptionHandler, but it isn&amp;amp;apos;t used anywhere.</description>
			<version>1.0.0</version>
			<fixedVersion>1.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.SimpleStepFactoryBean.java</file>
		</fixedFiles>
	</bug>
	<bug id="579" opendate="2008-04-11 08:18:21" fixdate="2008-04-11 08:18:54" resolution="Fixed">
		<buginformation>
			<summary>Remove redundant IOException from throws declaration in FlatFileIteReader</summary>
			<description>Remove redundant IOException from throws declaration in FlatFileIteReader</description>
			<version>1.0.0</version>
			<fixedVersion>1.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReader.java</file>
		</fixedFiles>
	</bug>
	<bug id="590" opendate="2008-04-15 22:54:08" fixdate="2008-04-15 23:44:19" resolution="Fixed">
		<buginformation>
			<summary>broken rollback/buffering in JdbcCursorItemReader</summary>
			<description>The reader keeps moving  the result set cursor while returning items from the buffer (after rollback). This means after next commit the buffer is cleared and some items from the chunk following the rollbacked chunk are skipped e.g.
read -&amp;gt; 1
commit
read -&amp;gt; 2
rollback
read -&amp;gt;2
commit
read -&amp;gt; 4 // 3 was skipped during re-reading 2</description>
			<version>1.0.0</version>
			<fixedVersion>1.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.JdbcCursorItemReader.java</file>
			<file type="M">org.springframework.batch.item.CommonItemReaderTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="589" opendate="2008-04-15 07:32:21" fixdate="2008-04-16 00:14:41" resolution="Fixed">
		<buginformation>
			<summary>StepExecutionResourceProxy&amp;apos;s toString() leads to NPE</summary>
			<description>Since it is possible to call toString before the delegate is set, toString will throw a NPE.
For example, when setResource() is invoked on FlatFileItemReader
public void setResource(Resource resource) throws IOException {
		this.resource = resource;
		path = resource.toString();
		if (path.length() &amp;gt; 50) 
{
			path = path.substring(0, 20) + "..." + path.substring(path.length());
		}
	}
you end up with a NPE when you try to get the path.
</description>
			<version>1.0.1</version>
			<fixedVersion>1.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.resource.StepExecutionResourceProxyTests.java</file>
			<file type="M">org.springframework.batch.core.resource.StepExecutionResourceProxy.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReader.java</file>
		</fixedFiles>
	</bug>
	<bug id="577" opendate="2008-04-10 23:13:40" fixdate="2008-04-16 20:30:17" resolution="Fixed">
		<buginformation>
			<summary>JdbcCursorItemReader doesn&amp;apos;t work with Derby</summary>
			<description>Using embedded Derby driver:
java.sql.SQLException: The &amp;amp;apos;getRow()&amp;amp;apos; method is only allowed on scroll cursors.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedResultSet.checkScrollCursor(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedResultSet.getRow(Unknown Source)
	at org.apache.commons.dbcp.DelegatingResultSet.getRow(DelegatingResultSet.java:331)
	at org.springframework.batch.item.database.JdbcCursorItemReader$BufferredResultSetReader.read(JdbcCursorItemReader.java:475)
</description>
			<version>1.0.0</version>
			<fixedVersion>1.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.JdbcCursorItemReader.java</file>
		</fixedFiles>
	</bug>
	<bug id="593" opendate="2008-04-20 17:21:03" fixdate="2008-04-20 19:07:49" resolution="Fixed">
		<buginformation>
			<summary>Calling update before read on DrivingQueryItemReader causes ArrayIndexOutOfBoundsError</summary>
			<description>When calling the update method on the DrivingQueryItemReader to save the state to the execution context, an attempt is made to get the current key by doing a get(currentIndex - 1) on the keys list.  Unfortunately, since the read() method has not yet been called, the currentIndex is still at 0, and an ArrayIndexOutOfBoundsError is thrown.</description>
			<version>1.0.0</version>
			<fixedVersion>1.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.CommonItemStreamItemReaderTests.java</file>
			<file type="M">org.springframework.batch.item.database.DrivingQueryItemReader.java</file>
		</fixedFiles>
	</bug>
	<bug id="595" opendate="2008-04-21 19:59:14" fixdate="2008-04-21 22:27:55" resolution="Fixed">
		<buginformation>
			<summary>Incorrect JDBC type for job parameters of long type</summary>
			<description>The JDBC type for long parameters is Types.INTEGER in JdbcJobInstanceDao.insertParameter. This makes the values become truncated to int before they are inserted into the table. The type should probably be Types.BIGINT.</description>
			<version>1.0.0</version>
			<fixedVersion>1.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcJobInstanceDao.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.AbstractJobInstanceDaoTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="604" opendate="2008-04-25 07:00:26" fixdate="2008-04-25 11:15:27" resolution="Fixed">
		<buginformation>
			<summary>JdbcStepExecutionDao isn&amp;apos;t deserializing objects correctly.</summary>
			<description>I&amp;amp;apos;m not sure how this issue has been there so long.  I checked back and it&amp;amp;apos;s been doing the following since I originally wrote it:
executionContext.put(key, rs.getObject("OBJECT_VAL"));
Which will never work, since getObject will just return a Byte[].  Perhaps it&amp;amp;apos;s a reflection of usage that no one has caught this?</description>
			<version>1.0.0</version>
			<fixedVersion>1.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcStepExecutionDaoTests.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.AbstractStepExecutionDaoTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.StatefulRetryStepFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcStepExecutionDao.java</file>
		</fixedFiles>
	</bug>
	<bug id="571" opendate="2008-04-09 18:53:30" fixdate="2008-04-27 23:11:13" resolution="Fixed">
		<buginformation>
			<summary>Remove reference to Step from StepExecution and reference to Job from JobInstance</summary>
			<description>Remove reference to Step from StepExecution.  It is only used to get the name of the step, and it doesn&amp;amp;apos;t really belong in an Entity (makes it questionably Serializable for example).</description>
			<version>1.0.0</version>
			<fixedVersion>1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.SimpleStepFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.JobExecutionTests.java</file>
			<file type="M">org.springframework.batch.core.step.AbstractStepTests.java</file>
			<file type="M">org.springframework.batch.core.repository.support.SimpleJobRepositoryIntegrationTests.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcJobInstanceDao.java</file>
			<file type="M">org.springframework.batch.core.step.item.ItemOrientedStepTests.java</file>
			<file type="M">org.springframework.batch.sample.item.writer.StagingItemWriterTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.ItemSkipPolicyItemHandlerTests.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.AbstractJobInstanceDaoTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.SkipLimitStepFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.JobInstance.java</file>
			<file type="M">org.springframework.batch.core.resource.StepExecutionPreparedStatementSetterTests.java</file>
			<file type="M">org.springframework.batch.core.job.SimpleJobTests.java</file>
			<file type="M">org.springframework.batch.core.step.tasklet.TaskletStepTests.java</file>
			<file type="M">org.springframework.batch.sample.item.reader.StagingItemReaderTests.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.AbstractJobExecutionDaoTests.java</file>
			<file type="M">org.springframework.batch.core.repository.support.SimpleJobRepositoryTests.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.MapJobInstanceDao.java</file>
			<file type="M">org.springframework.batch.core.resource.StepExecutionResourceProxyTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.RepeatOperationsStepFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcJobDaoQueryTests.java</file>
			<file type="M">org.springframework.batch.core.StepExecutionTests.java</file>
			<file type="M">org.springframework.batch.core.resource.JdbcCursorItemReaderPreparedStatementIntegrationTests.java</file>
			<file type="M">org.springframework.batch.core.JobInstanceTests.java</file>
			<file type="M">org.springframework.batch.core.listener.CompositeJobExecutionListenerTests.java</file>
			<file type="M">org.springframework.batch.core.listener.CompositeStepExecutionListenerTests.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.AbstractStepDaoTests.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.AbstractStepExecutionDaoTests.java</file>
			<file type="M">org.springframework.batch.core.StepExecution.java</file>
			<file type="M">org.springframework.batch.core.step.item.StepExecutorInterruptionTests.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcStepExecutionDao.java</file>
			<file type="M">org.springframework.batch.core.step.ThreadStepInterruptionPolicyTests.java</file>
			<file type="M">org.springframework.batch.core.JobExecution.java</file>
			<file type="M">org.springframework.batch.core.step.item.StatefulRetryStepFactoryBeanTests.java</file>
		</fixedFiles>
		<links>
			<link type="Depends" description="is depended on by">603</link>
			<link type="Depends" description="is depended on by">29</link>
		</links>
	</bug>
	<bug id="610" opendate="2008-05-02 01:58:52" fixdate="2008-05-02 02:21:32" resolution="Fixed">
		<buginformation>
			<summary>JdbcCursorItemReader cannot be reopened once closed.</summary>
			<description>The JdbcCursorItemReader cannot be reopned because it does a check to ensure the previous resultset is null before opening.  However, the close method only closes the resultset and doesn&amp;amp;apos;t set it to null.</description>
			<version>1.0.0</version>
			<fixedVersion>1.0.1, 1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.FooInputSource.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemReader.java</file>
			<file type="M">org.springframework.batch.item.CommonItemStreamItemReaderTests.java</file>
			<file type="M">org.springframework.batch.item.database.JdbcCursorItemReader.java</file>
		</fixedFiles>
	</bug>
	<bug id="608" opendate="2008-04-30 18:54:10" fixdate="2008-05-04 19:48:17" resolution="Fixed">
		<buginformation>
			<summary>JobExecutionListener.onInterrupt() is never called by spring batch framework</summary>
			<description>The onInterrupt() callback method of JobExecutionListener should be called by SimpleJob once JobInterruptedException is caught</description>
			<version>1.0.0</version>
			<fixedVersion>1.0.1, 1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.job.SimpleJobTests.java</file>
			<file type="M">org.springframework.batch.core.job.SimpleJob.java</file>
		</fixedFiles>
	</bug>
	<bug id="613" opendate="2008-05-05 21:02:34" fixdate="2008-05-06 19:04:19" resolution="Fixed">
		<buginformation>
			<summary>StaxEventItemReader can run out of memory</summary>
			<description>StaxEventItemReader buffers XMLEvents, which causes out of memory error if the XML document has a large part that contains no items. This should be resolved by buffering items instead of XMLEvents.</description>
			<version>1.0.0</version>
			<fixedVersion>1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemReader.java</file>
			<file type="M">org.springframework.batch.item.CommonItemReaderTests.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemReaderTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="603" opendate="2008-04-25 01:22:56" fixdate="2008-05-09 08:25:41" resolution="Fixed">
		<buginformation>
			<summary>JobExecution fields could be modified in another Thread and are not volatile</summary>
			<description>JobExecution fields could be modified in another Thread and are not volatile.</description>
			<version>1.0.0</version>
			<fixedVersion>1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.StepExecution.java</file>
			<file type="M">org.springframework.batch.core.JobExecutionTests.java</file>
			<file type="M">org.springframework.batch.core.StepExecutionTests.java</file>
			<file type="M">org.springframework.batch.core.JobExecution.java</file>
			<file type="M">org.springframework.batch.core.JobInstance.java</file>
			<file type="M">org.springframework.batch.core.StepContributionTests.java</file>
			<file type="M">org.springframework.batch.core.StepContribution.java</file>
		</fixedFiles>
		<links>
			<link type="Depends" description="depends on">571</link>
		</links>
	</bug>
	<bug id="616" opendate="2008-05-09 02:04:52" fixdate="2008-05-11 19:49:19" resolution="Fixed">
		<buginformation>
			<summary>Possible overflow in exit description if a stream.open() throws exception</summary>
			<description>Possible overflow in exit description if a stream.open() throws exception.  Since we only truncate the exitStatus.description on update, if an exception is thrown before the initial insert would normally happen (ItemOrientedStep.doExecute) then the description could overflow the database column.  Fix would be to truncate on insert as well.</description>
			<version>1.0.1</version>
			<fixedVersion>1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcStepExecutionDaoTests.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.AbstractStepExecutionDaoTests.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcStepExecutionDao.java</file>
		</fixedFiles>
	</bug>
	<bug id="625" opendate="2008-05-14 22:29:29" fixdate="2008-05-15 01:57:49" resolution="Fixed">
		<buginformation>
			<summary>SkipListener#onSkipInWrite(..) called multiple times for the same item and not called without rollback</summary>
			<description>SkipListener#onSkipInWrite(..) is called every time the problematic item is encountered i.e. multiple times in case of rollbacks. It should instead be called once per skipped item (i.e. the listener should be called when the write error was encountered and the item was marked for future skipping).</description>
			<version>1.0.1</version>
			<fixedVersion>1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.SkipListener.java</file>
			<file type="M">org.springframework.batch.core.step.item.ItemSkipPolicyItemHandlerTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.ItemSkipPolicyItemHandler.java</file>
		</fixedFiles>
	</bug>
	<bug id="650" opendate="2008-06-03 03:45:22" fixdate="2008-06-04 00:48:36" resolution="Fixed">
		<buginformation>
			<summary>Use FORWARD_ONLY as scroll mode in HibernateCursorItemReader</summary>
			<description>When using a HibernateCursorItemReader with the thin Oracle Database Driver hughe amounts of date lead to a Memory Exception. The current implementation doesn&amp;amp;apos;t set the cursor that is opened to FORWARD_ONLY. FORWARD_ONLY disables the caching in the driver, otherwise every row that is fetched is stored in the drivers caching mechanism.
A possible fix for this issue is: 
if (useStatelessSession) {
  statelessSession = sessionFactory.openStatelessSession();
  cursor = statelessSession.createQuery(queryString).scroll(FORWARD_ONLY);
} else {
  statefulSession = sessionFactory.openSession();
  cursor = statefulSession.createQuery(queryString).scroll(FORWARD_ONLY);
} </description>
			<version>1.0.0</version>
			<fixedVersion>1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.sample.AbstractCustomerCreditIncreaseTests.java</file>
			<file type="M">org.springframework.batch.sample.domain.CustomerCredit.java</file>
			<file type="M">org.springframework.batch.item.CommonItemReaderTests.java</file>
			<file type="M">org.springframework.batch.sample.item.writer.BatchSqlCustomerCreditIncreaseWriter.java</file>
			<file type="M">org.springframework.batch.sample.item.writer.CustomerCreditIncreaseProcessorTests.java</file>
			<file type="M">org.springframework.batch.sample.item.writer.CustomerCreditIncreaseWriter.java</file>
			<file type="M">org.springframework.batch.item.database.HibernateCursorItemReader.java</file>
		</fixedFiles>
	</bug>
	<bug id="651" opendate="2008-06-04 00:56:27" fixdate="2008-06-04 19:59:39" resolution="Fixed">
		<buginformation>
			<summary>buffered readers don&amp;apos;t handle volatile commit interval</summary>
			<description>If commit interval is decreased after rollback buffered readers simply clear the item buffer on mark() - this happens when used e.g. with batchUpdateWriter which causes commits on each item after rollback.
All buffered readers should be consolidated not to duplicate the item buffering logic (common superclass is probably the way to go until BATCH-592 can be implemented).</description>
			<version>1.0.1</version>
			<fixedVersion>1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.JdbcCursorItemReader.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemReader.java</file>
			<file type="M">org.springframework.batch.item.MultiResourceItemReader.java</file>
			<file type="M">org.springframework.batch.item.CommonItemReaderTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="638" opendate="2008-05-21 04:14:53" fixdate="2008-06-09 19:13:02" resolution="Fixed">
		<buginformation>
			<summary>ItemSkipPolicyItemHandler does not count items</summary>
			<description>In 1.0.1 release, the resolution of  "http://jira.springframework.org/browse/BATCH-531" issue causes another issue.
The item count has move to SimpleItemHandler. The write method calls contribution.incrementItemCount().
The problem is in ItemSkipPolicyItemHandler, subclass of SimpleItemHandler. This class doesn&amp;amp;apos;t call incrementItemCount.
In my application, using 1.0.0 release item count ends with one number more than total items, and in 1.0.1, ends always with 0 (zero).</description>
			<version>1.0.1</version>
			<fixedVersion>1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.ItemSkipPolicyItemHandlerTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.SkipLimitStepFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.SimpleItemHandler.java</file>
		</fixedFiles>
	</bug>
	<bug id="623" opendate="2008-05-14 01:09:57" fixdate="2008-06-09 19:21:37" resolution="Fixed">
		<buginformation>
			<summary>StatefulRetryStepFactoryBean causes item count to be lost in database</summary>
			<description>StatefulRetryStepFactoryBean causes item count to be lost in database</description>
			<version>1.0.1</version>
			<fixedVersion>1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.StatefulRetryStepFactoryBeanTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="660" opendate="2008-06-10 19:03:51" fixdate="2008-06-10 19:54:32" resolution="Fixed">
		<buginformation>
			<summary> SimpleStepFactoryBean#setExceptionHandler() not working</summary>
			<description>Copied from http://forum.springframework.org/showthread.php?t=55706
It appears that while SkipLimitFactoryBean and StatefulRetryFactoryBean propogate the ExceptionHandler set in setExceptionHandler(), SimpleStepFactoryBean does not. The resulting ItemOrientedStep does not have anything other than DefaultExceptionHandler.
I believe that a call to ItemOrientedStep#setExceptionHandler() within SimpleStepFactoryBean#applyConfiguration() will fix the issue.</description>
			<version>1.0.1</version>
			<fixedVersion>1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.SimpleStepFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.SimpleStepFactoryBean.java</file>
		</fixedFiles>
	</bug>
	<bug id="548" opendate="2008-04-02 02:29:39" fixdate="2008-06-10 22:31:13" resolution="Fixed">
		<buginformation>
			<summary>skipping items can lead to an invalidated mark in the ResourceItemReader</summary>
			<description>since spring batch does not apply skipped items to the commit interval so a large chunk of skippable items can cause the underlying BufferedItemReader to invalidate its mark.  Then, if reset is invoked, the reader will throw an IOException.</description>
			<version>1.0.0</version>
			<fixedVersion>1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReaderBasicTests.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReader.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReaderAdvancedTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="663" opendate="2008-06-10 23:30:09" fixdate="2008-06-11 00:08:29" resolution="Fixed">
		<buginformation>
			<summary>MultiResourceItemReader doesn&amp;apos;t restart correctly after multi-resource rollback</summary>
			<description>MultiResourceItemReader needs to track the last marked resource and delegates position within that resource to restart correctly after multi-resource rollback. After rollback it also needs to handle possible shortening of the commit interval.</description>
			<version>1.1.0</version>
			<fixedVersion>1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.MultiResourceItemReader.java</file>
			<file type="M">org.springframework.batch.item.CommonItemStreamItemReaderTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="661" opendate="2008-06-10 19:26:14" fixdate="2008-06-11 19:21:30" resolution="Fixed">
		<buginformation>
			<summary>broken job interruption logic</summary>
			<description>Currenlty jobExecution#stop() is implemented by setting the "terminateOnly" flag on all step executions created so far. Therefore in case stop() is called e.g. in StepListener#afterStep(..) it has no effect on the following steps. Also the terminateOnly flag is checked only in ItemOrientedStep so a job consisting of arbitrary number of TaskletSteps can&amp;amp;apos;t be stopped unless the Tasklet implementations support interruption.</description>
			<version>1.0.1</version>
			<fixedVersion>1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.job.SimpleJobTests.java</file>
			<file type="M">org.springframework.batch.core.job.SimpleJob.java</file>
		</fixedFiles>
		<links>
			<link type="Related" description="is related to">401</link>
		</links>
	</bug>
	<bug id="665" opendate="2008-06-11 01:14:30" fixdate="2008-06-11 19:36:39" resolution="Fixed">
		<buginformation>
			<summary>ChunkListeners are registered on stepOperations in RepeatOperationsStepFactoryBean - should be chunkOperations</summary>
			<description>In RepeatOperationsStepFactoryBean.applyConfiguration(), the chunk listeners are registered on the stepOperations, which means they are executed when the step starts and when it ends, which seems to be wrong : as name and javadoc mentions it, ChunkListeners are executed around a chunk, i.e. inside the transaction boundaries.
The other step factory bean SimpleStepFactoryBean correctly registers the chunk listeners on the chunkOperations.</description>
			<version>1.0.1</version>
			<fixedVersion>1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.RepeatOperationsStepFactoryBean.java</file>
		</fixedFiles>
		<links>
			<link type="Related" description="is related to">666</link>
		</links>
	</bug>
	<bug id="654" opendate="2008-06-05 02:31:58" fixdate="2008-06-17 20:47:51" resolution="Fixed">
		<buginformation>
			<summary>Ensure best efforts are made to commit StepExecution when commit fails</summary>
			<description>When the commit operation fails in an ItemOrientedStep, the writing of the Spring Batch metadata fails (trying to write the rollback information). 
When trying to commit the transaction, SB has already set the information it&amp;amp;apos;s about to persist in the StepExecutionContext. Then, in another transaction, SB wants to store that a rollback ocurred. Nevertheless, SB hasn&amp;amp;apos;t read the current persisted state from the database, so it still has the Version it read when trying to commit. That&amp;amp;apos;s why we think it fails.
Furthermore, even if it succeeded, the persisted information wouldn&amp;amp;apos;t be accurate, because, as I&amp;amp;apos;ve pointed out, the StepExecutionContext hasn&amp;amp;apos;t been reset.</description>
			<version>1.0.1</version>
			<fixedVersion>1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.ItemOrientedStep.java</file>
			<file type="M">org.springframework.batch.core.step.AbstractStep.java</file>
			<file type="M">org.springframework.batch.core.job.SimpleJobTests.java</file>
			<file type="M">org.springframework.batch.core.repository.support.SimpleJobRepository.java</file>
			<file type="M">org.springframework.batch.item.ExecutionContext.java</file>
			<file type="M">org.springframework.batch.item.ExecutionContextTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.ItemOrientedStepTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="687" opendate="2008-06-24 22:41:57" fixdate="2008-06-24 22:57:34" resolution="Fixed">
		<buginformation>
			<summary>BatchUpdateItemWriter should fail if any of the statements does not update any rows (at least by default).</summary>
			<description>BatchUpdateItemWriter should fail if any of the statements does not update any rows (at least by default).</description>
			<version>1.0.1</version>
			<fixedVersion>1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.BatchSqlUpdateItemWriter.java</file>
			<file type="M">org.springframework.batch.item.database.BatchSqlUpdateItemWriterTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="698" opendate="2008-06-30 22:49:52" fixdate="2008-07-01 00:52:13" resolution="Fixed">
		<buginformation>
			<summary>StaxEventItemWriter test failures</summary>
			<description>cca one half of the StaxItemWriterTests keep failing (reproduced on two machines, Windows &amp;amp; Linux).</description>
			<version>1.1.0</version>
			<fixedVersion>1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemWriter.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemWriterTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="706" opendate="2008-07-02 02:49:28" fixdate="2008-07-02 03:46:24" resolution="Fixed">
		<buginformation>
			<summary>Commit exception is lost if update fails as well</summary>
			<description>http://forum.springframework.org/showthread.php?t=56783</description>
			<version>1.1.0</version>
			<fixedVersion>1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.StepExecution.java</file>
			<file type="M">org.springframework.batch.core.StepExecutionTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.ItemOrientedStepTests.java</file>
			<file type="M">org.springframework.batch.core.step.AbstractStepTests.java</file>
			<file type="M">org.springframework.batch.core.step.AbstractStep.java</file>
		</fixedFiles>
	</bug>
	<bug id="703" opendate="2008-07-01 23:32:21" fixdate="2008-07-02 18:19:27" resolution="Fixed">
		<buginformation>
			<summary>JdbcJobInstanceDao doesn&amp;apos;t locate JOB_INSTANCE on Oracle where JOB_KEY is empty</summary>
			<description>Oracle has this "feature" where an empty string is stored as NULL.  This causes the JdbcJobInstanceDao to fail to look up existing JOB_INSTANCE where the key is empty since the JOB_KEY is stored as NULL in the database and must be queried using JOB_KEY IS NULL.  The end result is that there will be a new JOB_INSTANCE created even though a matching one already exists.
The JdbcJobRepositoryTests expose this issue.</description>
			<version>1.0.1</version>
			<fixedVersion>1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcJobInstanceDao.java</file>
		</fixedFiles>
	</bug>
	<bug id="705" opendate="2008-07-02 02:03:22" fixdate="2008-07-02 18:24:57" resolution="Fixed">
		<buginformation>
			<summary>TradeJobFunctionalTests might fail since verification queries don&amp;apos;t have ORDER clause</summary>
			<description>TradeJobFunctionalTests might randomly fail since verification queries don&amp;amp;apos;t have ORDER clause.  When the data stored is verified it might fail if rows are retrieved in a random order that is different from the order the rows where added.</description>
			<version>1.0.1</version>
			<fixedVersion>1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.sample.TradeJobFunctionalTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="713" opendate="2008-07-03 05:09:53" fixdate="2008-07-03 05:51:09" resolution="Fixed">
		<buginformation>
			<summary>FlatFileItemWriter initialization causes file deletion</summary>
			<description>FlatFileItemWriter will inadvertently delete it&amp;amp;apos;s output file multiple times if open is not called first.  The following unit test fails on my machine:
	public void testWriteBeforeOpen() throws Exception
{
		
		writer.write("test1");
		writer.flush();
		writer.open(executionContext);
		writer.write("test2");
		writer.flush();
		assertEquals("test1", readLine());
		assertEquals("test2", readLine());
	}

The issue is that the write method initializes the buffer:
public void write(String line) throws IOException {
			if (!initialized) 
{
				initializeBufferedWriter();
			}

			outputBufferedWriter.write(line);
			outputBufferedWriter.flush();
			linesWritten++;
		}
Note: the above is from OutputState#write
However, the open method never checks to see if it&amp;amp;apos;s already been initialized:
	public void open(ExecutionContext executionContext) throws ItemStreamException {
		OutputState outputState = getOutputState();
		if (executionContext.containsKey(getKey(RESTART_DATA_NAME))) 
{
			outputState.restoreFrom(executionContext);
		}
		try 
{
			outputState.initializeBufferedWriter();
		}
		catch (IOException ioe) 
{
			throw new ItemStreamException("Failed to initialize writer", ioe);
		}
		if (outputState.lastMarkedByteOffsetPosition == 0) {
			for (Iterator iterator = headerLines.iterator(); iterator.hasNext() 
{
				String line = (String) iterator.next();
				lineBuffer.add(line + lineSeparator);
			}
		}
	}
Thus, the FileUtils will call delete on the file.
</description>
			<version>1.0.1</version>
			<fixedVersion>1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.WriterNotOpenException.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemWriterTests.java</file>
			<file type="M">org.springframework.batch.item.file.transform.FixedLengthTokenizerTests.java</file>
			<file type="M">org.springframework.batch.item.file.transform.DelimitedLineTokenizerTests.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemWriter.java</file>
		</fixedFiles>
	</bug>
	<bug id="715" opendate="2008-07-05 01:17:15" fixdate="2008-07-07 18:48:02" resolution="Fixed">
		<buginformation>
			<summary>Default value of saveState flag should be true</summary>
			<description>Default value of saveState flag should be true - restartable should be the default.  Assigning to Robert because he did the original abstraction so he might know why the default isn&amp;amp;apos;t already true.</description>
			<version>1.1.0</version>
			<fixedVersion>1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemWriter.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemWriter.java</file>
			<file type="M">org.springframework.batch.item.support.AbstractBufferedItemReaderItemStream.java</file>
		</fixedFiles>
	</bug>
	<bug id="722" opendate="2008-07-12 22:35:55" fixdate="2008-07-12 22:47:35" resolution="Fixed">
		<buginformation>
			<summary>No framework logic should depend on the value of ExitStatus</summary>
			<description>No framework logic should depend on the value of ExitStatus - BatchStatus is fixed by the framework, but users can set the ExitStatus codes to what they like.</description>
			<version>1.1.0</version>
			<fixedVersion>1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.retry.support.RetryTemplate.java</file>
			<file type="M">org.springframework.batch.integration.job.StepExecutionMessageHandlerTests.java</file>
			<file type="M">org.springframework.batch.integration.job.StepExecutionMessageHandler.java</file>
			<file type="M">org.springframework.batch.core.job.SimpleJobTests.java</file>
			<file type="M">org.springframework.batch.integration.chunk.ChunkMessageChannelItemWriter.java</file>
			<file type="M">org.springframework.batch.core.job.SimpleJob.java</file>
		</fixedFiles>
	</bug>
	<bug id="723" opendate="2008-07-13 13:54:08" fixdate="2008-07-13 18:35:16" resolution="Fixed">
		<buginformation>
			<summary>tablePrefix property is not injected into JbdcExecutionContextDao</summary>
			<description>When using an alternate table prefix in the batch repository schema and
setting this property on the JobRepositoryFactoryBean, the setting is properly injected into the three primary daos
(  JdbcJobInstanceDao, JdbcJobExecutionDao, JdbcStepExecutionDao ).
However the setting is not injected into the JdbcExecutionContextDao, resulting in an inconsistent table naming prefix strategy in the batch schema.
It appears to me that the JdbcJobExecutionDao and JdbcStepExecutionDao each create an instance of the JdbcExecutionContextDao, referred to as "ecDao", and should inject the tablePrefix.  
They already set some properties of the "ecDao" in their afterPropertiesSet() .. but seems they neglect to inject the tablePrefix as well.
Should be a simple one line fix in each dao?
</description>
			<version>1.1.0</version>
			<fixedVersion>1.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcJobExecutionDao.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.AbstractJdbcBatchMetadataDao.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcStepExecutionDao.java</file>
		</fixedFiles>
		<links>
			<link type="Related" description="is related to">724</link>
		</links>
	</bug>
	<bug id="732" opendate="2008-07-17 02:18:02" fixdate="2008-07-17 04:05:29" resolution="Fixed">
		<buginformation>
			<summary>FlatFileItemReader doesn&amp;apos;t take "firstLineIsHeader" flag into account when restarting</summary>
			<description>FlatFileItemReader doesn&amp;amp;apos;t take "firstLineIsHeader" flag into account when restarting so the restart begins with the last successfully processed item rather than the one following it.  This is only an issue if the flat file contains a header line.</description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0.M1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReader.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReaderAdvancedTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="737" opendate="2008-07-18 03:56:37" fixdate="2008-07-20 19:25:45" resolution="Fixed">
		<buginformation>
			<summary>JdbcCursorItemReader will spin through entire resultset if numberOfProcessRows=0</summary>
			<description>If a step using jdbccursoritemreader to read fails in the processing-step (itemwriter), number of processed rows (0) will be persisted in ExecutionContext. When re-running the step, 0 will be read as the number of processed rows, and the code will call moveCursorToRow with 0 as param.
The way the private method moveCursorToRow is implemented now, it will always call next() and increment count once, before checking if count==rows. At this point count=1 and row=0, this resultset will be traveresed until next()=false.
Checked the history of the file, and it seems this behavior has been there since before the private method was introduced.
The code below should solve this problem:
	/**

Moves the cursor in the resultset to the position specified by the in param by
traversing the resultset
@param row
	 */
	private void moveCursorToRow(int row){
		try 
Unknown macro: {			for (int skipped = 0; skipped &amp;lt; row &amp;amp;&amp;amp; rs.next(); skipped++) {
				//Do nothing
			}		} 
		catch (SQLException se) 
{
			throw getExceptionTranslator().translate("Attempted to move ResultSet to last committed row", sql, se);
		}
 
	}

</description>
			<version>1.0.1</version>
			<fixedVersion>1.1.1, 2.0.0.M1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.JdbcCursorItemReader.java</file>
			<file type="M">org.springframework.batch.item.database.AbstractDataSourceItemReaderIntegrationTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="741" opendate="2008-07-21 19:03:40" fixdate="2008-07-21 22:23:09" resolution="Fixed">
		<buginformation>
			<summary>DefaultFieldSet should clone the tokens before exposing them in getValues()</summary>
			<description>DefaultFieldSet should clone the tokens before exposing them in getValues()</description>
			<version>1.1.0</version>
			<fixedVersion>1.1.1, 2.0.0.M1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.mapping.DefaultFieldSet.java</file>
		</fixedFiles>
	</bug>
	<bug id="744" opendate="2008-07-24 17:59:56" fixdate="2008-07-24 18:36:02" resolution="Fixed">
		<buginformation>
			<summary>restart.count is always 0 in FlatFileItemWriter</summary>
			<description></description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0.M1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.FlatFileItemWriterTests.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemWriter.java</file>
		</fixedFiles>
	</bug>
	<bug id="693" opendate="2008-06-27 03:19:16" fixdate="2008-07-27 19:06:09" resolution="Fixed">
		<buginformation>
			<summary>Refactor samples along domain contours</summary>
			<description>It has always bugged me that the samples have technical packaging.  It is really hard to isolate the individual domains (e.g. football).</description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0.M1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="D">org.springframework.batch.sample.domain.trade.HibernateCreditDao.java</file>
			<file type="D">org.springframework.batch.sample.domain.trade.CustomerCreditUpdateWriter.java</file>
			<file type="D">org.springframework.batch.sample.domain.order.valang.FutureDateFunctionTests.java</file>
			<file type="D">org.springframework.batch.sample.domain.trade.IbatisCustomerCreditDao.java</file>
			<file type="D">org.springframework.batch.sample.domain.order.valang.TotalOrderItemsFunctionTests.java</file>
			<file type="D">org.springframework.batch.sample.domain.trade.CustomerDebitRowMapper.java</file>
			<file type="D">org.springframework.batch.sample.domain.trade.CustomerUpdateProcessorTests.java</file>
			<file type="M">org.springframework.batch.sample.domain.order.OrderItemReaderTests.java</file>
			<file type="D">org.springframework.batch.sample.domain.order.valang.ValidateDiscountsFunctionTests.java</file>
			<file type="D">org.springframework.batch.sample.domain.trade.FlatFileCustomerCreditDaoTests.java</file>
			<file type="M">org.springframework.batch.sample.RetrySampleFunctionalTests.java</file>
			<file type="D">org.springframework.batch.sample.domain.trade.TradeFieldSetMapper.java</file>
			<file type="D">org.springframework.batch.sample.domain.order.OrderItemFieldSetMapper.java</file>
			<file type="D">org.springframework.batch.sample.domain.order.ShippingFieldSetMapper.java</file>
			<file type="D">org.springframework.batch.sample.domain.trade.CustomerCreditIncreaseProcessorTests.java</file>
			<file type="M">org.springframework.batch.sample.domain.order.BillingFieldSetMapperTests.java</file>
			<file type="D">org.springframework.batch.sample.domain.order.CustomerFieldSetMapper.java</file>
			<file type="D">org.springframework.batch.sample.domain.order.valang.ValidateDiscountsFunction.java</file>
			<file type="D">org.springframework.batch.sample.domain.order.xml.Customer.java</file>
			<file type="D">org.springframework.batch.sample.domain.trade.TradeRowMapper.java</file>
			<file type="D">org.springframework.batch.sample.domain.football.PlayerSummaryRowMapper.java</file>
			<file type="D">org.springframework.batch.sample.domain.order.valang.ValidateShippingPricesFunction.java</file>
			<file type="D">org.springframework.batch.sample.domain.order.OrderItemReader.java</file>
			<file type="D">org.springframework.batch.sample.domain.order.AddressFieldSetMapper.java</file>
			<file type="D">org.springframework.batch.sample.domain.football.JdbcGameDao.java</file>
			<file type="D">org.springframework.batch.sample.domain.order.valang.ValidatePricesFunction.java</file>
			<file type="D">org.springframework.batch.sample.domain.trade.JdbcTradeWriterTests.java</file>
			<file type="D">org.springframework.batch.sample.domain.football.JdbcPlayerSummaryDao.java</file>
			<file type="D">org.springframework.batch.sample.domain.trade.CustomerCreditRowMapper.java</file>
			<file type="D">org.springframework.batch.sample.domain.trade.GeneratingItemReaderTests.java</file>
			<file type="M">org.springframework.batch.sample.domain.order.OrderItemFieldSetMapperTests.java</file>
			<file type="D">org.springframework.batch.sample.domain.trade.FlatFileCustomerCreditDao.java</file>
			<file type="D">org.springframework.batch.sample.domain.trade.JdbcCustomerDebitDaoTests.java</file>
			<file type="D">org.springframework.batch.sample.domain.football.JdbcPlayerSummaryDaoIntegrationTests.java</file>
			<file type="D">org.springframework.batch.sample.domain.person.PersonWriter.java</file>
			<file type="D">org.springframework.batch.sample.domain.trade.CustomerCreditUpdatePreparedStatementSetterTests.java</file>
			<file type="D">org.springframework.batch.sample.domain.trade.CustomerCreditRowMapperTests.java</file>
			<file type="D">org.springframework.batch.sample.domain.trade.TradeProcessorTests.java</file>
			<file type="D">org.springframework.batch.sample.domain.trade.TradeFieldSetMapperTests.java</file>
			<file type="D">org.springframework.batch.sample.domain.order.xml.Shipper.java</file>
			<file type="D">org.springframework.batch.sample.domain.order.xml.Order.java</file>
			<file type="D">org.springframework.batch.sample.domain.trade.CustomerCreditIncreaseWriter.java</file>
			<file type="D">org.springframework.batch.sample.domain.football.PlayerSummaryMapper.java</file>
			<file type="D">org.springframework.batch.sample.domain.football.FootballExceptionHandler.java</file>
			<file type="D">org.springframework.batch.sample.domain.trade.CustomerCreditUpdateProcessorTests.java</file>
			<file type="D">org.springframework.batch.sample.domain.football.PlayerFieldSetMapper.java</file>
			<file type="D">org.springframework.batch.sample.domain.order.OrderTransformer.java</file>
			<file type="D">org.springframework.batch.sample.domain.football.JdbcPlayerDaoIntegrationTests.java</file>
			<file type="M">org.springframework.batch.sample.domain.order.FlatFileOrderWriterTests.java</file>
			<file type="M">org.springframework.batch.sample.domain.order.AddressFieldSetMapperTests.java</file>
			<file type="M">org.springframework.batch.sample.AbstractCustomerCreditIncreaseTests.java</file>
			<file type="M">org.springframework.batch.sample.FixedLengthImportJobFunctionalTests.java</file>
			<file type="D">org.springframework.batch.sample.domain.order.valang.ValidateQuantitiesFunctionTests.java</file>
			<file type="D">org.springframework.batch.sample.domain.order.valang.ValidateHandlingPricesFunctionTests.java</file>
			<file type="D">org.springframework.batch.sample.domain.order.valang.ValidateQuantitiesFunction.java</file>
			<file type="D">org.springframework.batch.sample.domain.trade.TradeWriter.java</file>
			<file type="D">org.springframework.batch.sample.domain.order.valang.ValidateIdsFunctionTests.java</file>
			<file type="D">org.springframework.batch.sample.domain.trade.GeneratingTradeItemReader.java</file>
			<file type="D">org.springframework.batch.sample.domain.football.PlayerItemWriter.java</file>
			<file type="D">org.springframework.batch.sample.domain.order.valang.FutureDateFunction.java</file>
			<file type="D">org.springframework.batch.sample.domain.trade.JdbcCustomerDebitDao.java</file>
			<file type="D">org.springframework.batch.sample.domain.order.valang.TotalOrderItemsFunction.java</file>
			<file type="D">org.springframework.batch.sample.domain.trade.JdbcTradeDao.java</file>
			<file type="D">org.springframework.batch.sample.domain.order.HeaderFieldSetMapper.java</file>
			<file type="D">org.springframework.batch.sample.domain.order.valang.ValidatePricesFunctionTests.java</file>
			<file type="M">org.springframework.batch.sample.HibernateFailureJobFunctionalTests.java</file>
			<file type="D">org.springframework.batch.sample.domain.football.JdbcPlayerDao.java</file>
			<file type="D">org.springframework.batch.sample.domain.trade.CustomerUpdateWriter.java</file>
			<file type="D">org.springframework.batch.sample.domain.order.valang.ValidateHandlingPricesFunction.java</file>
			<file type="D">org.springframework.batch.sample.domain.football.GameFieldSetMapper.java</file>
			<file type="D">org.springframework.batch.sample.domain.trade.TradeRowMapperTests.java</file>
			<file type="M">org.springframework.batch.sample.domain.order.HeaderFieldSetMapperTests.java</file>
			<file type="D">org.springframework.batch.sample.domain.trade.CustomerCreditUpdatePreparedStatementSetter.java</file>
			<file type="D">org.springframework.batch.sample.domain.order.valang.ValidateIdsFunction.java</file>
			<file type="D">org.springframework.batch.sample.domain.order.valang.ValidateTotalPricesFunctionTests.java</file>
			<file type="M">org.springframework.batch.sample.domain.order.CustomerFieldSetMapperTests.java</file>
			<file type="M">org.springframework.batch.sample.domain.order.OrderTransformerTests.java</file>
			<file type="D">org.springframework.batch.sample.domain.order.valang.ValidateShippingPricesFunctionTests.java</file>
			<file type="D">org.springframework.batch.sample.domain.football.JdbcGameDaoIntegrationTests.java</file>
			<file type="D">org.springframework.batch.sample.domain.order.BillingFieldSetMapper.java</file>
			<file type="M">org.springframework.batch.sample.domain.order.ShippingFieldSetMapperTests.java</file>
			<file type="D">org.springframework.batch.sample.domain.order.valang.ValidateTotalPricesFunction.java</file>
			<file type="D">org.springframework.batch.sample.domain.order.xml.LineItem.java</file>
			<file type="D">org.springframework.batch.sample.dao.JdbcJobRepositoryTests.java</file>
			<file type="D">org.springframework.batch.sample.dao.JdbcTradeWriterTests.java</file>
			<file type="D">org.springframework.batch.sample.dao.JdbcPlayerDaoIntegrationTests.java</file>
			<file type="D">org.springframework.batch.sample.dao.JdbcGameDaoIntegrationTests.java</file>
			<file type="D">org.springframework.batch.sample.dao.FlatFileCustomerCreditDaoTests.java</file>
			<file type="D">org.springframework.batch.sample.dao.JdbcCustomerDebitDaoTests.java</file>
			<file type="D">org.springframework.batch.sample.dao.JdbcPlayerSummaryDaoIntegrationTests.java</file>
			<file type="D">org.springframework.batch.sample.tasklet.ExceptionThrowingItemReaderProxyTests.java</file>
			<file type="D">org.springframework.batch.sample.mapping.AbstractFieldSetMapperTests.java</file>
			<file type="D">org.springframework.batch.sample.item.writer.StagingItemWriterTests.java</file>
			<file type="D">org.springframework.batch.sample.tasklet.JobSupport.java</file>
			<file type="M">org.springframework.batch.sample.quartz.JobLauncherDetailsTests.java</file>
			<file type="D">org.springframework.batch.sample.tasklet.SimpleSystemProcessExitCodeMapperTests.java</file>
			<file type="D">org.springframework.batch.sample.tasklet.StepSupport.java</file>
			<file type="D">org.springframework.batch.sample.item.reader.StagingItemReaderTests.java</file>
			<file type="D">org.springframework.batch.sample.tasklet.ConfigurableSystemProcessExitCodeMapperTests.java</file>
			<file type="D">org.springframework.batch.sample.item.writer.RetrySampleItemWriterTests.java</file>
			<file type="D">org.springframework.batch.sample.tasklet.SystemCommandTaskletIntegrationTests.java</file>
			<file type="D">org.springframework.batch.sample.advice.JobExecutionNotificationPublisherTests.java</file>
			<file type="D">org.springframework.batch.sample.mapping.AbstractRowMapperTests.java</file>
			<file type="D">org.springframework.batch.sample.item.writer.TradeProcessorTests.java</file>
			<file type="D">org.springframework.batch.sample.item.writer.CustomerCreditUpdatePreparedStatementSetterTests.java</file>
			<file type="D">org.springframework.batch.sample.mapping.TradeFieldSetMapperTests.java</file>
			<file type="D">org.springframework.batch.sample.mapping.TradeRowMapperTests.java</file>
			<file type="D">org.springframework.batch.sample.item.writer.CustomerCreditUpdateProcessorTests.java</file>
			<file type="D">org.springframework.batch.sample.item.reader.GeneratingItemReaderTests.java</file>
			<file type="D">org.springframework.batch.sample.mapping.CustomerCreditRowMapperTests.java</file>
			<file type="D">org.springframework.batch.sample.item.writer.CustomerUpdateProcessorTests.java</file>
			<file type="D">org.springframework.batch.sample.item.writer.CustomerCreditIncreaseProcessorTests.java</file>
			<file type="D">org.springframework.batch.sample.mapping.ShippingFieldSetMapperTests.java</file>
			<file type="D">org.springframework.batch.sample.dao.OrderTransformerTests.java</file>
			<file type="D">org.springframework.batch.sample.mapping.HeaderFieldSetMapperTests.java</file>
			<file type="D">org.springframework.batch.sample.mapping.AddressFieldSetMapperTests.java</file>
			<file type="D">org.springframework.batch.sample.mapping.OrderItemFieldSetMapperTests.java</file>
			<file type="D">org.springframework.batch.sample.item.reader.OrderItemReaderTests.java</file>
			<file type="D">org.springframework.batch.sample.dao.FlatFileOrderWriterTests.java</file>
			<file type="D">org.springframework.batch.sample.mapping.CustomerFieldSetMapperTests.java</file>
			<file type="D">org.springframework.batch.sample.mapping.BillingFieldSetMapperTests.java</file>
			<file type="D">org.springframework.batch.sample.trade.CustomerUpdateWriter.java</file>
			<file type="D">org.springframework.batch.sample.trade.IbatisCustomerCreditDao.java</file>
			<file type="D">org.springframework.batch.sample.order.xml.Customer.java</file>
			<file type="D">org.springframework.batch.sample.trade.CustomerCreditRowMapper.java</file>
			<file type="D">org.springframework.batch.sample.order.Customer.java</file>
			<file type="D">org.springframework.batch.sample.order.xml.Order.java</file>
			<file type="D">org.springframework.batch.sample.football.PlayerDao.java</file>
			<file type="D">org.springframework.batch.sample.order.Address.java</file>
			<file type="D">org.springframework.batch.sample.trade.FlatFileCustomerCreditDao.java</file>
			<file type="D">org.springframework.batch.sample.person.PersonService.java</file>
			<file type="D">org.springframework.batch.sample.order.xml.Shipper.java</file>
			<file type="D">org.springframework.batch.sample.order.Order.java</file>
			<file type="D">org.springframework.batch.sample.person.PersonWriter.java</file>
			<file type="D">org.springframework.batch.sample.order.xml.LineItem.java</file>
			<file type="D">org.springframework.batch.sample.trade.TradeWriter.java</file>
			<file type="D">org.springframework.batch.sample.football.JdbcPlayerSummaryDao.java</file>
			<file type="D">org.springframework.batch.sample.trade.GeneratingTradeItemReader.java</file>
			<file type="D">org.springframework.batch.sample.order.ShippingInfo.java</file>
			<file type="D">org.springframework.batch.sample.order.valang.TotalOrderItemsFunction.java</file>
			<file type="D">org.springframework.batch.sample.football.PlayerSummary.java</file>
			<file type="D">org.springframework.batch.sample.football.Game.java</file>
			<file type="D">org.springframework.batch.sample.retry.RetrySampleItemWriter.java</file>
			<file type="D">org.springframework.batch.sample.order.CustomerFieldSetMapper.java</file>
			<file type="D">org.springframework.batch.sample.trade.TradeFieldSetMapper.java</file>
			<file type="D">org.springframework.batch.sample.football.GameFieldSetMapper.java</file>
			<file type="D">org.springframework.batch.sample.order.valang.FutureDateFunction.java</file>
			<file type="D">org.springframework.batch.sample.trade.Trade.java</file>
			<file type="D">org.springframework.batch.sample.football.PlayerSummaryMapper.java</file>
			<file type="D">org.springframework.batch.sample.order.valang.ValidatePricesFunction.java</file>
			<file type="D">org.springframework.batch.sample.order.HeaderFieldSetMapper.java</file>
			<file type="M">org.springframework.batch.sample.TradeJobFunctionalTests.java</file>
			<file type="D">org.springframework.batch.sample.trade.HibernateCreditDao.java</file>
			<file type="D">org.springframework.batch.sample.order.valang.TotalOrderItemsFunctionTests.java</file>
			<file type="D">org.springframework.batch.sample.order.OrderItemReader.java</file>
			<file type="D">org.springframework.batch.sample.football.FootballExceptionHandler.java</file>
			<file type="D">org.springframework.batch.sample.order.valang.ValidatePricesFunctionTests.java</file>
			<file type="D">org.springframework.batch.sample.person.Person.java</file>
			<file type="D">org.springframework.batch.sample.trade.CustomerDebitDao.java</file>
			<file type="M">org.springframework.batch.sample.CompositeItemWriterSampleFunctionalTests.java</file>
			<file type="D">org.springframework.batch.sample.football.JdbcPlayerDao.java</file>
			<file type="D">org.springframework.batch.sample.order.valang.ValidateHandlingPricesFunction.java</file>
			<file type="D">org.springframework.batch.sample.order.OrderDao.java</file>
			<file type="D">org.springframework.batch.sample.order.valang.ValidateShippingPricesFunction.java</file>
			<file type="D">org.springframework.batch.sample.order.valang.FutureDateFunctionTests.java</file>
			<file type="D">org.springframework.batch.sample.football.Player.java</file>
			<file type="D">org.springframework.batch.sample.trade.CustomerCreditDao.java</file>
			<file type="D">org.springframework.batch.sample.order.BillingInfo.java</file>
			<file type="D">org.springframework.batch.sample.trade.CustomerCreditUpdatePreparedStatementSetter.java</file>
			<file type="D">org.springframework.batch.sample.trade.TradeRowMapper.java</file>
			<file type="D">org.springframework.batch.sample.order.valang.ValidateTotalPricesFunction.java</file>
			<file type="D">org.springframework.batch.sample.order.valang.ValidateDiscountsFunction.java</file>
			<file type="D">org.springframework.batch.sample.trade.CustomerCredit.java</file>
			<file type="D">org.springframework.batch.sample.football.PlayerSummaryRowMapper.java</file>
			<file type="D">org.springframework.batch.sample.order.ShippingFieldSetMapper.java</file>
			<file type="D">org.springframework.batch.sample.order.valang.ValidateQuantitiesFunction.java</file>
			<file type="D">org.springframework.batch.sample.trade.JdbcTradeDao.java</file>
			<file type="D">org.springframework.batch.sample.order.valang.ValidateIdsFunction.java</file>
			<file type="D">org.springframework.batch.sample.trade.CustomerDebit.java</file>
			<file type="D">org.springframework.batch.sample.person.Child.java</file>
			<file type="D">org.springframework.batch.sample.order.OrderItemFieldSetMapper.java</file>
			<file type="D">org.springframework.batch.sample.trade.CustomerCreditIncreaseWriter.java</file>
			<file type="D">org.springframework.batch.sample.order.valang.ValidateQuantitiesFunctionTests.java</file>
			<file type="D">org.springframework.batch.sample.football.PlayerFieldSetMapper.java</file>
			<file type="D">org.springframework.batch.sample.order.valang.ValidateDiscountsFunctionTests.java</file>
			<file type="D">org.springframework.batch.sample.order.LineItem.java</file>
			<file type="D">org.springframework.batch.sample.order.OrderTransformer.java</file>
			<file type="D">org.springframework.batch.sample.order.valang.ValidateIdsFunctionTests.java</file>
			<file type="D">org.springframework.batch.sample.trade.TradeDao.java</file>
			<file type="D">org.springframework.batch.sample.football.PlayerItemWriter.java</file>
			<file type="D">org.springframework.batch.sample.football.JdbcGameDao.java</file>
			<file type="D">org.springframework.batch.sample.trade.CustomerDebitRowMapper.java</file>
			<file type="D">org.springframework.batch.sample.order.AddressFieldSetMapper.java</file>
			<file type="M">org.springframework.batch.sample.DelegatingJobFunctionalTests.java</file>
			<file type="D">org.springframework.batch.sample.order.BillingFieldSetMapper.java</file>
			<file type="D">org.springframework.batch.sample.order.valang.ValidateHandlingPricesFunctionTests.java</file>
			<file type="D">org.springframework.batch.sample.order.valang.ValidateShippingPricesFunctionTests.java</file>
			<file type="D">org.springframework.batch.sample.trade.CustomerCreditUpdateWriter.java</file>
			<file type="D">org.springframework.batch.sample.order.valang.ValidateTotalPricesFunctionTests.java</file>
			<file type="D">org.springframework.batch.sample.trade.JdbcCustomerDebitDao.java</file>
			<file type="D">org.springframework.batch.sample.advice.JobExecutionNotificationPublisher.java</file>
			<file type="D">org.springframework.batch.sample.advice.StepExecutionApplicationEventAdvice.java</file>
			<file type="D">org.springframework.batch.sample.advice.SimpleMessageApplicationEvent.java</file>
			<file type="D">org.springframework.batch.sample.common.ExceptionThrowingItemReaderProxy.java</file>
			<file type="M">org.springframework.batch.sample.SkipSampleFunctionalTests.java</file>
			<file type="D">org.springframework.batch.sample.common.DummyItemWriter.java</file>
			<file type="D">org.springframework.batch.sample.advice.LogAdvice.java</file>
			<file type="D">org.springframework.batch.sample.common.ItemTrackingItemWriter.java</file>
			<file type="D">org.springframework.batch.sample.advice.ProcessorLogAdvice.java</file>
			<file type="D">org.springframework.batch.sample.advice.MethodExecutionLogAdvice.java</file>
			<file type="D">org.springframework.batch.sample.advice.TradeWriterLogAdvice.java</file>
			<file type="D">org.springframework.batch.sample.order.Child.java</file>
			<file type="D">org.springframework.batch.sample.domain.PersonService.java</file>
			<file type="D">org.springframework.batch.sample.dao.FlatFileCustomerCreditDao.java</file>
			<file type="D">org.springframework.batch.sample.dao.IbatisCustomerCreditDao.java</file>
			<file type="D">org.springframework.batch.sample.domain.Person.java</file>
			<file type="D">org.springframework.batch.sample.item.writer.RetrySampleItemWriter.java</file>
			<file type="D">org.springframework.batch.sample.dao.CustomerCreditDao.java</file>
			<file type="D">org.springframework.batch.sample.dao.JdbcCustomerDebitDao.java</file>
			<file type="D">org.springframework.batch.sample.item.writer.PersonWriter.java</file>
			<file type="D">org.springframework.batch.sample.dao.JdbcTradeDao.java</file>
			<file type="D">org.springframework.batch.sample.dao.HibernateCreditDao.java</file>
			<file type="D">org.springframework.batch.sample.dao.TradeDao.java</file>
			<file type="D">org.springframework.batch.sample.dao.CustomerDebitDao.java</file>
			<file type="D">org.springframework.batch.sample.validation.valang.custom.ValidateDiscountsFunction.java</file>
			<file type="D">org.springframework.batch.sample.domain.Address.java</file>
			<file type="D">org.springframework.batch.sample.validation.valang.custom.ValidateTotalPricesFunction.java</file>
			<file type="D">org.springframework.batch.sample.dao.OrderTransformer.java</file>
			<file type="M">org.springframework.batch.sample.RestartFunctionalTests.java</file>
			<file type="D">org.springframework.batch.sample.validation.valang.custom.ValidatePricesFunction.java</file>
			<file type="D">org.springframework.batch.sample.domain.ShippingInfo.java</file>
			<file type="D">org.springframework.batch.sample.validation.valang.custom.ValidateShippingPricesFunctionTests.java</file>
			<file type="D">org.springframework.batch.sample.validation.valang.custom.ValidateHandlingPricesFunction.java</file>
			<file type="M">org.springframework.batch.sample.MultilineOrderJobFunctionalTests.java</file>
			<file type="D">org.springframework.batch.sample.domain.xml.Shipper.java</file>
			<file type="D">org.springframework.batch.sample.domain.xml.LineItem.java</file>
			<file type="D">org.springframework.batch.sample.mapping.ShippingFieldSetMapper.java</file>
			<file type="D">org.springframework.batch.sample.item.reader.OrderItemReader.java</file>
			<file type="D">org.springframework.batch.sample.validation.valang.custom.ValidateTotalPricesFunctionTests.java</file>
			<file type="D">org.springframework.batch.sample.validation.valang.custom.ValidateShippingPricesFunction.java</file>
			<file type="M">org.springframework.batch.sample.ParallelJobFunctionalTests.java</file>
			<file type="M">org.springframework.batch.sample.IbatisJobFunctionalTests.java</file>
			<file type="D">org.springframework.batch.sample.mapping.BillingFieldSetMapper.java</file>
			<file type="M">org.springframework.batch.sample.TaskletJobFunctionalTests.java</file>
			<file type="D">org.springframework.batch.sample.validation.valang.custom.ValidateIdsFunction.java</file>
			<file type="M">org.springframework.batch.sample.GracefulShutdownFunctionalTests.java</file>
			<file type="D">org.springframework.batch.sample.mapping.OrderItemFieldSetMapper.java</file>
			<file type="M">org.springframework.batch.sample.JobExecutionContextSampleFunctionalTests.java</file>
			<file type="D">org.springframework.batch.sample.validation.valang.custom.ValidatePricesFunctionTests.java</file>
			<file type="D">org.springframework.batch.sample.validation.valang.custom.ValidateDiscountsFunctionTests.java</file>
			<file type="M">org.springframework.batch.sample.FootballJobFunctionalTests.java</file>
			<file type="D">org.springframework.batch.sample.domain.Order.java</file>
			<file type="D">org.springframework.batch.sample.validation.valang.custom.TotalOrderItemsFunction.java</file>
			<file type="D">org.springframework.batch.sample.domain.xml.Customer.java</file>
			<file type="D">org.springframework.batch.sample.domain.LineItem.java</file>
			<file type="M">org.springframework.batch.sample.MultilineJobFunctionalTests.java</file>
			<file type="M">org.springframework.batch.sample.HibernateJobFunctionalTests.java</file>
			<file type="D">org.springframework.batch.sample.mapping.AddressFieldSetMapper.java</file>
			<file type="D">org.springframework.batch.sample.validation.valang.custom.TotalOrderItemsFunctionTests.java</file>
			<file type="D">org.springframework.batch.sample.domain.BillingInfo.java</file>
			<file type="D">org.springframework.batch.sample.domain.Child.java</file>
			<file type="D">org.springframework.batch.sample.validation.valang.custom.ValidateQuantitiesFunctionTests.java</file>
			<file type="D">org.springframework.batch.sample.validation.valang.custom.FutureDateFunctionTests.java</file>
			<file type="D">org.springframework.batch.sample.validation.valang.custom.ValidateIdsFunctionTests.java</file>
			<file type="M">org.springframework.batch.sample.MultiResourceJobFunctionalTests.java</file>
			<file type="D">org.springframework.batch.sample.mapping.HeaderFieldSetMapper.java</file>
			<file type="D">org.springframework.batch.sample.validation.valang.custom.ValidateHandlingPricesFunctionTests.java</file>
			<file type="D">org.springframework.batch.sample.domain.Customer.java</file>
			<file type="D">org.springframework.batch.sample.domain.xml.Order.java</file>
			<file type="D">org.springframework.batch.sample.mapping.CustomerFieldSetMapper.java</file>
			<file type="D">org.springframework.batch.sample.dao.OrderDao.java</file>
			<file type="D">org.springframework.batch.sample.validation.valang.custom.ValidateQuantitiesFunction.java</file>
			<file type="D">org.springframework.batch.sample.validation.valang.custom.FutureDateFunction.java</file>
			<file type="M">org.springframework.batch.sample.BeanWrapperMapperSampleJobFunctionalTests.java</file>
			<file type="M">org.springframework.batch.sample.BatchSqlUpdateJobFunctionalTests.java</file>
			<file type="D">org.springframework.batch.sample.mapping.TradeFieldSetMapper.java</file>
			<file type="D">org.springframework.batch.sample.domain.CustomerCredit.java</file>
			<file type="D">org.springframework.batch.sample.mapping.CustomerDebitRowMapper.java</file>
			<file type="D">org.springframework.batch.sample.item.writer.CustomerCreditIncreaseWriter.java</file>
			<file type="D">org.springframework.batch.sample.domain.CustomerDebit.java</file>
			<file type="D">org.springframework.batch.sample.domain.PlayerSummary.java</file>
			<file type="D">org.springframework.batch.sample.item.reader.ExceptionThrowingItemReaderProxy.java</file>
			<file type="D">org.springframework.batch.sample.domain.Game.java</file>
			<file type="D">org.springframework.batch.sample.domain.Trade.java</file>
			<file type="D">org.springframework.batch.sample.item.reader.GeneratingTradeItemReader.java</file>
			<file type="D">org.springframework.batch.sample.item.writer.CustomerUpdateWriter.java</file>
			<file type="D">org.springframework.batch.sample.item.writer.CustomerCreditUpdatePreparedStatementSetter.java</file>
			<file type="D">org.springframework.batch.sample.domain.Player.java</file>
			<file type="D">org.springframework.batch.sample.item.writer.TradeWriter.java</file>
			<file type="D">org.springframework.batch.sample.item.writer.ItemTrackingItemWriter.java</file>
			<file type="D">org.springframework.batch.sample.mapping.CustomerCreditRowMapper.java</file>
			<file type="D">org.springframework.batch.sample.item.writer.CustomerCreditUpdateWriter.java</file>
			<file type="D">org.springframework.batch.sample.mapping.TradeRowMapper.java</file>
			<file type="D">org.springframework.batch.sample.mapping.GameFieldSetMapper.java</file>
			<file type="D">org.springframework.batch.sample.dao.JdbcPlayerDao.java</file>
			<file type="D">org.springframework.batch.sample.item.writer.PlayerItemWriter.java</file>
			<file type="D">org.springframework.batch.sample.mapping.PlayerFieldSetMapper.java</file>
			<file type="D">org.springframework.batch.sample.dao.JdbcPlayerSummaryDao.java</file>
			<file type="D">org.springframework.batch.sample.dao.PlayerDao.java</file>
			<file type="D">org.springframework.batch.sample.dao.JdbcGameDao.java</file>
			<file type="D">org.springframework.batch.sample.mapping.PlayerSummaryRowMapper.java</file>
			<file type="D">org.springframework.batch.sample.item.reader.GeneratingItemReader.java</file>
			<file type="D">org.springframework.batch.sample.mapping.PlayerSummaryMapper.java</file>
			<file type="D">org.springframework.batch.sample.FieldSetResultSetExtractor.java</file>
			<file type="D">org.springframework.batch.sample.tasklet.SystemCommandException.java</file>
			<file type="D">org.springframework.batch.sample.item.writer.StagingItemWriter.java</file>
			<file type="D">org.springframework.batch.sample.exception.handler.FootballExceptionHandler.java</file>
			<file type="D">org.springframework.batch.sample.item.writer.DummyItemWriter.java</file>
			<file type="D">org.springframework.batch.sample.item.reader.StagingItemReader.java</file>
			<file type="D">org.springframework.batch.sample.tasklet.ConfigurableSystemProcessExitCodeMapper.java</file>
			<file type="D">org.springframework.batch.sample.tasklet.SystemProcessExitCodeMapper.java</file>
			<file type="D">org.springframework.batch.sample.tasklet.SimpleSystemProcessExitCodeMapper.java</file>
			<file type="D">org.springframework.batch.sample.tasklet.SystemCommandTasklet.java</file>
		</fixedFiles>
	</bug>
	<bug id="751" opendate="2008-07-29 01:10:32" fixdate="2008-07-29 19:07:03" resolution="Fixed">
		<buginformation>
			<summary>ensure StepExecution is saved before trying to save ExecutionContext</summary>
			<description>http://forum.springframework.org/showthread.php?t=57647</description>
			<version>1.1.0</version>
			<fixedVersion>1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.JobRepositorySupport.java</file>
			<file type="M">org.springframework.batch.core.step.AbstractStepTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="752" opendate="2008-07-30 00:19:46" fixdate="2008-07-30 00:58:59" resolution="Fixed">
		<buginformation>
			<summary>FlatFileItemReader restart broken for non-default RecordSeparatorPolicy (record &gt; 1 line)</summary>
			<description>Simple fix is to remove the overriden jumpToItem(int) method and use the default provided by superclass</description>
			<version>1.1.0</version>
			<fixedVersion>1.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReader.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReaderAdvancedTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="766" opendate="2008-08-07 00:02:32" fixdate="2008-08-10 20:43:17" resolution="Fixed">
		<buginformation>
			<summary>Insufficient error handling in case of a missing resource for a org.springframework.batch.item.xml.StaxEventItemWriter</summary>
			<description>Using an ItemOrientedStep with the following combination of ItemReader and ItemWriter
                   ... &amp;lt;!-- other tags --&amp;gt;
	&amp;lt;bean id="testFileItemReader"
		class="org.springframework.batch.item.xml.StaxEventItemReader"&amp;gt;
		&amp;lt;property name="fragmentRootElementName" value="record" /&amp;gt;
		&amp;lt;property name="resource" value="classpath:doesntexist.xml" /&amp;gt;
		&amp;lt;property name="fragmentDeserializer"&amp;gt;
			&amp;lt;bean
				class="org.springframework.batch.item.xml.oxm.UnmarshallingEventReaderDeserializer"&amp;gt;
				&amp;lt;constructor-arg ref="jaxb2Marshaller" /&amp;gt;
			&amp;lt;/bean&amp;gt;
		&amp;lt;/property&amp;gt;
	&amp;lt;/bean&amp;gt;
	&amp;lt;bean id="jaxb2Marshaller"
		class="org.springframework.oxm.jaxb.Jaxb2Marshaller"&amp;gt;
		&amp;lt;property name="contextPath"
			value="$
{context.path}
" /&amp;gt;
		&amp;lt;property name="schema" value="classpath:$
{input.schema}
" /&amp;gt;
	&amp;lt;/bean&amp;gt;
	&amp;lt;bean class="org.springframework.batch.item.xml.StaxEventItemWriter"
		id="testFileItemWriter"&amp;gt;
		&amp;lt;property name="resource"
			value="file:$
{output.resource}
" /&amp;gt;
		&amp;lt;property name="serializer" ref="marshallingSerializer" /&amp;gt;
		&amp;lt;property name="rootTagName" value="records" /&amp;gt;
		&amp;lt;property name="overwriteOutput" value="true" /&amp;gt;
	&amp;lt;/bean&amp;gt;
	&amp;lt;bean
		class="org.springframework.batch.item.xml.oxm.MarshallingEventWriterSerializer"
		id="marshallingSerializer"&amp;gt;
		&amp;lt;constructor-arg ref="jaxb2Marshaller" /&amp;gt;
	&amp;lt;/bean&amp;gt;
will lead to a NullPointerException in the execution of the ItemWriter if the resource configured for the ItemReader doesn&amp;amp;apos;t exist (for example due to an unintentional typo). 
This behavior makes it rather difficult to analyze the error and find the true cause. There should be a more sophisticated error handling if the StaxEventItemReader can&amp;amp;apos;t find its resource.
Log entry:
ERROR AbstractStep                   - Encountered an error executing the step: class org.springframework.batch.core.UnexpectedJobExecutionException: Failed to initialize the step
ERROR AbstractStep                   - Exception while closing step execution resources
java.lang.NullPointerException
	at org.springframework.batch.item.xml.StaxEventItemWriter.flush(StaxEventItemWriter.java:463)
	at org.springframework.batch.item.xml.StaxEventItemWriter.close(StaxEventItemWriter.java:373)
	at org.springframework.batch.item.support.CompositeItemStream.close(CompositeItemStream.java:90)
	at org.springframework.batch.core.step.item.ItemOrientedStep.close(ItemOrientedStep.java:435)
	at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:226)
	at org.springframework.batch.core.job.SimpleJob.execute(SimpleJob.java:100)
	at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:86)
	at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:49)
	at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:81)
	at com.tsystems.favbg.batch.job.TestJobTest.testLaunchJob(TestJobTest.java:83)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at junit.framework.TestCase.runTest(TestCase.java:164)
	at junit.framework.TestCase.runBare(TestCase.java:130)
	at org.springframework.test.ConditionalTestCase.runBare(ConditionalTestCase.java:76)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:120)
	at junit.framework.TestSuite.runTest(TestSuite.java:230)
	at junit.framework.TestSuite.run(TestSuite.java:225)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:460)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:673)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:386)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:196)</description>
			<version>1.1.1</version>
			<fixedVersion>1.1.2, 2.0.0.M1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemWriter.java</file>
			<file type="M">org.springframework.batch.item.util.FileUtilsTests.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemWriterTests.java</file>
			<file type="M">org.springframework.batch.item.util.FileUtils.java</file>
		</fixedFiles>
	</bug>
	<bug id="757" opendate="2008-08-04 01:45:54" fixdate="2008-08-11 18:44:21" resolution="Fixed">
		<buginformation>
			<summary>remove DelegatingItemWriter</summary>
			<description></description>
			<version>1.1.1</version>
			<fixedVersion>2.0.0.M1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="D">org.springframework.batch.item.support.DelegatingItemWriter.java</file>
			<file type="D">org.springframework.batch.item.support.DelegatingItemWriterTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.BatchListenerFactoryHelper.java</file>
		</fixedFiles>
	</bug>
	<bug id="765" opendate="2008-08-06 08:43:29" fixdate="2008-08-12 20:26:56" resolution="Fixed">
		<buginformation>
			<summary>StepExecution should be saved on every commit</summary>
			<description>StepExecution is saved when step starts and updated when step ends, but it is not being updated after chunk is commited. This means the statistics such as item_count are reflected in the database only once the step has finished executing.</description>
			<version>1.1.1</version>
			<fixedVersion>1.1.2, 2.0.0.M1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.StepHandlerStepTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.StepHandlerStep.java</file>
			<file type="M">org.springframework.batch.core.step.item.ItemOrientedStep.java</file>
			<file type="M">org.springframework.batch.core.step.item.ItemOrientedStepTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="782" opendate="2008-08-13 21:48:54" fixdate="2008-08-14 01:33:49" resolution="Fixed">
		<buginformation>
			<summary>Synchronization issue in ItemOrientedStep if exception is throw in chunk processing</summary>
			<description>I have read source code of 1.0.x and 1.1.x and both share similar problem
In ItemOrientedStep:
Code:
protected ExitStatus doExecute(final StepExecution stepExecution) throws Exception {
    // blablabla
    return stepOperations.iterate(new RepeatCallback() {
        public ExitStatus doInIteration(RepeatContext context) throws Exception {
            // balblabla
            try {
                // Process chunk .... (1)
                try 
{
                    synchronizer.lock(stepExecution);
                }
                catch (InterruptedException e) 
{
                    stepExecution.setStatus(BatchStatus.STOPPED);
                    Thread.currentThread().interrupt();
                }
                // step execution persistence
            }
            catch (Error e) 
{
                processRollback(stepExecution, contribution, fatalException, transaction);
                throw e;
            }
            catch (Exception e) {                processRollback(stepExecution, contribution, fatalException, transaction);                throw e;            }
            finally 
{
                synchronizer.release(stepExecution);
            }
            //blblabla
            return exitStatus;
        }
    });
}
In case of any exception occured in (1) or during synchronizer.lock(), the internal semaphore in synchronizer is NOT acquired. However, the outer final block releases synchronizer, and hence, releasing the semaphore.
From JDK API of 1.5, it stated that Semaphore can be released by another thread which is not the original acquirer of semaphore.
So, in case of parallel processing, I may goes into some case:
Thread 1 acquired the semaphore and doing those step execution persistence stuff.
Thread 2 have exception in processChunk, and hence releasing the semaphore.
Thread 3, originally waiting for semaphore, is now acquired the semaphore because Thread 2 releases it, and hence, it goes to the peresistence block of code.
In such case, Thread 1 and 3 goes into the should-be-protected block of code for step execution persistence.
In my environment, I throwed an exception in my writer, and it caused this exception:
[ERROR] SimpleAsyncTaskExecutor-1 [step.AbstractStep] Encountered an error executing the step
org.springframework.batch.core.step.AbstractStep$FatalException: Fatal error detected during save of step execution context
// stack trace deleted
Caused by: org.springframework.dao.OptimisticLockingFailureException: Attempt to update step execution id=609 with wrong version (5), where current version is 4
// stack trace deleted
It is caused by concurrent access and persistence of step execution because of the above mentioned issue.  
Upon happening, in DB, the step execution will be updated with UNKNOWN status, and hence, preventing it from re-run.
A quick fix is to set a flag after synchronizer lock, and only release if flag is set.  However it does not cater for interruption exception during synchronizer locking.</description>
			<version>1.0.1</version>
			<fixedVersion>1.1.2, 2.0.0.M2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.StepExecutorInterruptionTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.StepHandlerStep.java</file>
		</fixedFiles>
	</bug>
	<bug id="734" opendate="2008-07-17 06:17:47" fixdate="2008-08-14 02:42:17" resolution="Fixed">
		<buginformation>
			<summary>ItemReaders and ItemWriters using Resource(s) should check for file during ItemStream#open</summary>
			<description>During bean initialization MultiResourceItemReader checks [in afterPropertiesSet()] that it actually has resources to read. If not, it throws an exception. There are use cases where the resources might not be created at bean initialization time (see http://forum.springframework.org/showthread.php?t=57502 for details).
Lucas Ward suggests that this check might better be made during ItemStream#open().</description>
			<version>1.1.0</version>
			<fixedVersion>1.1.2, 2.0.0.M1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReader.java</file>
			<file type="M">org.springframework.batch.item.file.MultiResourceItemReaderXmlTests.java</file>
			<file type="M">org.springframework.batch.item.file.MultiResourceItemReader.java</file>
			<file type="M">org.springframework.batch.item.file.MultiResourceItemReaderFlatFileTests.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemWriter.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemWriter.java</file>
			<file type="M">org.springframework.batch.item.file.MultiResourceItemReaderIntegrationTests.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemReader.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemReaderTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="807" opendate="2008-09-02 22:27:19" fixdate="2008-09-02 22:30:02" resolution="Fixed">
		<buginformation>
			<summary>Serialization bug in JobExecution</summary>
			<description>Serialization bug in JobExecution.  When deserialized, the transient field stepExecutions is assumed to be not null in createStepExecution().  I think it maybe comes from an old version where StepExecution had a reference to a Step - and was therefore not really Serializable.</description>
			<version>2.0.0.M2</version>
			<fixedVersion>2.0.0.M2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.JobExecution.java</file>
			<file type="M">org.springframework.batch.core.JobExecutionTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="795" opendate="2008-08-27 19:22:21" fixdate="2008-09-03 20:04:34" resolution="Fixed">
		<buginformation>
			<summary>JdbcJobExecutionDao output sorting</summary>
			<description>There is minor bug in JdbcJobExecutionDao.findJobExecutions(JobInstance jobInstance). JobExecutionDao&amp;amp;apos;s javadoc says that executions returned from this method are sorted bacwards by start time, but there is no ORDER BY clause in sql query so executions are sorted the wrong way. I didn&amp;amp;apos;t see ORDER BY anywhere in the file so maybe other methods should be checked too.</description>
			<version>2.0.0.M1</version>
			<fixedVersion>2.0.0.M2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcJobExecutionDao.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.MapJobExecutionDao.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.AbstractJobExecutionDaoTests.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.JobExecutionDao.java</file>
		</fixedFiles>
	</bug>
	<bug id="776" opendate="2008-08-09 01:03:39" fixdate="2008-09-04 22:20:50" resolution="Fixed">
		<buginformation>
			<summary>StaxEventItemWriter headers should not have to be the same type as the T that the writer is parameterised with</summary>
			<description>StaxEventItemWriter headers should not have to be the same type as the T that the writer is parameterised with.  They could be anything that the Marshaller understands. </description>
			<version>2.0.0.M1</version>
			<fixedVersion>2.0.0.M2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemWriter.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemWriterTests.java</file>
			<file type="M">org.springframework.batch.item.xml.TransactionalStaxEventItemWriterTests.java</file>
		</fixedFiles>
		<links>
			<link type="Depends" description="depends on">821</link>
			<link type="Related" description="is related to">821</link>
		</links>
	</bug>
	<bug id="814" opendate="2008-09-03 20:40:53" fixdate="2008-09-05 04:28:59" resolution="Fixed">
		<buginformation>
			<summary>JobRepository should not require Step or Job (only their names)</summary>
			<description>It&amp;amp;apos;s a matter of encapsulation.  The repository responsibility should not intersect with the configuration concerns of Step and Job (or their execution concerns).  THis change is necessary for efficient partitioning of a step (where the name might be overridden for partitions).</description>
			<version>2.0.0.M2</version>
			<fixedVersion>2.0.0.M2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.JobRepositorySupport.java</file>
			<file type="M">org.springframework.batch.core.job.JobSupport.java</file>
			<file type="M">org.springframework.batch.core.repository.support.MapJobRepositoryFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.repository.support.SimpleJobRepositoryIntegrationTests.java</file>
			<file type="M">org.springframework.batch.integration.job.StepExecutionMessageHandlerTests.java</file>
			<file type="M">org.springframework.batch.sample.GracefulShutdownFunctionalTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.SimpleStepFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.AbstractStepExecutionDaoTests.java</file>
			<file type="M">org.springframework.batch.core.repository.support.JobRepositoryFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.step.tasklet.ChunkOrientedStepIntegrationTests.java</file>
			<file type="M">org.springframework.batch.core.launch.support.SimpleJobOperator.java</file>
			<file type="M">org.springframework.batch.integration.file.FileToMessagesJobFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.launch.SimpleJobLauncherTests.java</file>
			<file type="M">org.springframework.batch.core.job.SimpleJobTests.java</file>
			<file type="M">org.springframework.batch.integration.chunk.ChunkMessageItemWriterIntegrationTests.java</file>
			<file type="M">org.springframework.batch.core.step.tasklet.TasketStepTests.java</file>
			<file type="M">org.springframework.batch.sample.DatabaseShutdownFunctionalTests.java</file>
			<file type="M">org.springframework.batch.core.repository.support.SimpleJobRepository.java</file>
			<file type="M">org.springframework.batch.core.step.tasklet.StepExecutorInterruptionTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.StatefulRetryStepFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.repository.support.JobRepositoryFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.repository.JobRepository.java</file>
			<file type="M">org.springframework.batch.integration.JobRepositorySupport.java</file>
			<file type="M">org.springframework.batch.core.launch.support.SimpleJobLauncher.java</file>
			<file type="M">org.springframework.batch.sample.support.JdbcJobRepositoryTests.java</file>
			<file type="M">org.springframework.batch.core.explore.support.SimpleJobExplorer.java</file>
			<file type="M">org.springframework.batch.core.exlore.support.SimpleJobExplorerTests.java</file>
			<file type="M">org.springframework.batch.core.launch.support.SimpleJobOperatorTests.java</file>
			<file type="M">org.springframework.batch.core.explore.JobExplorer.java</file>
			<file type="M">org.springframework.batch.core.repository.support.SimpleJobRepositoryTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.support.ClassPathXmlApplicationContextFactoryTests.java</file>
			<file type="M">org.springframework.batch.core.launch.support.JobRegistryBackgroundJobRunner.java</file>
			<file type="M">org.springframework.batch.core.configuration.support.ClassPathXmlJobRegistry.java</file>
			<file type="M">org.springframework.batch.core.job.SimpleJob.java</file>
			<file type="M">org.springframework.batch.core.configuration.support.ClassPathXmlApplicationContextFactory.java</file>
			<file type="M">org.springframework.batch.integration.job.StepExecutionMessageHandler.java</file>
		</fixedFiles>
	</bug>
	<bug id="831" opendate="2008-09-11 00:57:38" fixdate="2008-09-11 02:29:25" resolution="Fixed">
		<buginformation>
			<summary>id counter in MapJobInstanceDao should be declared static</summary>
			<description>http://forum.springframework.org/showthread.php?t=60053</description>
			<version>1.1.2</version>
			<fixedVersion>1.1.3, 2.0.0.M2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.repository.dao.MapJobInstanceDao.java</file>
		</fixedFiles>
	</bug>
	<bug id="835" opendate="2008-09-11 20:04:08" fixdate="2008-09-12 07:55:52" resolution="Fixed">
		<buginformation>
			<summary>sql error "column ambiguously defined" in JdbcJobInstanceDao</summary>
			<description>I&amp;amp;apos;m getting BadSqlGrammarException "column ambiguously defined" on oracle while executing query in JdbcJobInstanceDao.getJobInstance(). The problem is in following query: 
SELECT JOB_INSTANCE_ID, JOB_NAME, JOB_KEY, VERSION from %PREFIX%JOB_INSTANCE ji, %PREFIX%JOB_EXECUTION je where JOB_EXECUTION_ID = ? and ji.JOB_INSTANCE_ID = je.JOB_INSTANCE_ID
Poor oracle doesn&amp;amp;apos;t know from which table to get JOB_INSTANCE_ID and VERSION.
Simple addition of "ji." to these two columns works fine.</description>
			<version>2.0.0.M2</version>
			<fixedVersion>2.0.0.M2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcJobInstanceDao.java</file>
		</fixedFiles>
	</bug>
	<bug id="843" opendate="2008-09-19 02:16:53" fixdate="2008-09-21 20:08:06" resolution="Fixed">
		<buginformation>
			<summary>FlatFileItemWriter handling of failure in LineAggregator</summary>
			<description>FFIW should first map all items to strings and only then write them. Currently failure in line aggregator can cause rollback when some lines from the current chunk are already written.</description>
			<version>2.0.0.M1</version>
			<fixedVersion>2.0.0.M2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.FlatFileItemWriterTests.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemWriter.java</file>
		</fixedFiles>
	</bug>
	<bug id="813" opendate="2008-09-03 19:47:02" fixdate="2008-09-21 23:25:53" resolution="Fixed">
		<buginformation>
			<summary>SingleColumnJdbcKeyGeneratorIntegrationTests fails in Eclipse</summary>
			<description>SingleColumnJdbcKeyGeneratorIntegrationTests fails in Eclipse.  Looks like an ordering issue - some other test isn&amp;amp;apos;t cleaning up a thread local?
java.lang.IllegalStateException: Already value [org.springframework.jdbc.datasource.ConnectionHolder@90ebfe] for key [org.springframework.jdbc.datasource.DriverManagerDataSource@13043d2] bound to thread [main]
	at org.springframework.transaction.support.TransactionSynchronizationManager.bindResource(TransactionSynchronizationManager.java:182)
	at org.springframework.jdbc.datasource.DataSourceTransactionManager.doBegin(DataSourceTransactionManager.java:232)
	at org.springframework.transaction.support.AbstractPlatformTransactionManager.getTransaction(AbstractPlatformTransactionManager.java:377)
	at org.springframework.test.context.transaction.TransactionalTestExecutionListener$TransactionContext.startTransaction(TransactionalTestExecutionListener.java:496)
	at org.springframework.test.context.transaction.TransactionalTestExecutionListener.startNewTransaction(TransactionalTestExecutionListener.java:256)
	at org.springframework.test.context.transaction.TransactionalTestExecutionListener.beforeTestMethod(TransactionalTestExecutionListener.java:149)
	at org.springframework.test.context.TestContextManager.beforeTestMethod(TestContextManager.java:292)
...</description>
			<version>2.0.0.M2</version>
			<fixedVersion>2.0.0.M2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="D">org.springframework.batch.item.ExecutionContextTests.java</file>
			<file type="M">org.springframework.batch.item.database.DrivingQueryItemReaderTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="838" opendate="2008-09-15 01:48:40" fixdate="2008-09-23 23:15:49" resolution="Fixed">
		<buginformation>
			<summary>TimeoutTerminationPolicy does not terminate when eof is encountered</summary>
			<description>The isCompleted methods of TimeoutTerminationPolicy (both the one implemented in the class and the one inherited from CompletionPolicySupport) does not seem to take end-of-file into account., They returns false until the timeout-time is up, even if the exitCode of the ExitStatus parameter changes to "COMPLETED"  when an eof is reached (looking at the constants in ExitStatus I should have guessed that the status should be "FINISHED"....). The result is lots of extra reads that all gets end-of-file.</description>
			<version>1.1.2</version>
			<fixedVersion>1.1.3, 2.0.0.M2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.repeat.policy.TimeoutTerminationPolicy.java</file>
			<file type="M">org.springframework.batch.repeat.policy.TimeoutCompletionPolicyTests.java</file>
			<file type="M">org.springframework.batch.repeat.policy.CompletionPolicySupport.java</file>
		</fixedFiles>
	</bug>
	<bug id="761" opendate="2008-08-05 05:10:14" fixdate="2008-09-24 21:02:24" resolution="Fixed">
		<buginformation>
			<summary>StaxEventItemWriter writes extra end document tag with Woodstox 3.2.6</summary>
			<description>Woodstox 3.2.6 (current stable)&amp;amp;apos;s StaxEventWriter implementation automatically writes end tags and end document tags that it detects as still open on close.  When StaxEventItemWriter wraps Woodstox with a NoStartEndDocumentStreamWriter for the chunk writer (eventWriter), and another Woodstox instance for the document writer (delegateEventWriter), the result is two end document tags being written.  This is because even though the NoStartEndDocumentStreamWriter prevents the end document event from being written to the chunk writer, it writes the end document tag on close() anyway, on top of the one being written by StaxEventItemWriter.endDocument(delegateEventWriter) itself.
Here&amp;amp;apos;s the relevant stack trace:
Thread [main] (Suspended)	
	com.ctc.wstx.sw.SimpleNsStreamWriter(com.ctc.wstx.sw.BaseStreamWriter).finishDocument() line: 1672	
	com.ctc.wstx.sw.SimpleNsStreamWriter(com.ctc.wstx.sw.BaseStreamWriter).close() line: 288	
	com.ctc.wstx.evt.WstxEventWriter.close() line: 237	
	org.springframework.batch.item.xml.stax.NoStartEndDocumentStreamWriter(org.springframework.batch.item.xml.stax.AbstractEventWriterWrapper).close() line: 32	
	org.springframework.batch.item.xml.StaxEventItemWriter.close(org.springframework.batch.item.ExecutionContext) line: 376	
This was captured with Spring 1.1.0, but I diff&amp;amp;apos;ed StaxEventItemWriter and NoStartEndDocumentStreamWriter for 1.1.0 vs. 1.1.1 in FishEye, and am not seeing anything that would change the behavior.</description>
			<version>1.1.0</version>
			<fixedVersion>1.1.2, 2.0.0.M1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemWriter.java</file>
		</fixedFiles>
	</bug>
	<bug id="830" opendate="2008-09-10 17:08:52" fixdate="2008-09-25 01:11:52" resolution="Fixed">
		<buginformation>
			<summary>DelegatingItemReader should be removed</summary>
			<description>There have been a small logic mistake if I understand it right in adding generics to DelegatingItemReader. It&amp;amp;apos;s read method returns type T and the delegate must be of type T too. So there is no clean way to read eg. FieldSet from delegate and return some domain object, which is the purpose of this reader, isn&amp;amp;apos;t it?</description>
			<version>2.0.0.M2</version>
			<fixedVersion>2.0.0.M2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.sample.support.ExceptionThrowingItemReaderProxy.java</file>
			<file type="D">org.springframework.batch.item.support.DelegatingItemReader.java</file>
			<file type="M">org.springframework.batch.sample.common.ExceptionThrowingItemReaderProxyTests.java</file>
			<file type="D">org.springframework.batch.item.support.DelegatingItemReaderTests.java</file>
			<file type="M">org.springframework.batch.item.support.CompositeItemProcessorTests.java</file>
			<file type="M">org.springframework.batch.item.support.CompositeItemProcessor.java</file>
			<file type="D">org.springframework.batch.item.validator.ValidatingItemReader.java</file>
			<file type="D">org.springframework.batch.item.validator.ValidatingItemReaderTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="847" opendate="2008-09-22 06:18:39" fixdate="2008-09-29 23:05:58" resolution="Fixed">
		<buginformation>
			<summary>FaultTolerantChunkOrientedTasklet loses chunks when non-skippable exceptions thrown in read phase</summary>
			<description>FaultTolerantChunkOrientedTasklet loses chunks when non-skippable exceptions are thrown during the read phase.  This is true for exceptions thrown in Readers or in ItemListeners.  The RepeatTemplate doesn&amp;amp;apos;t see this as a fatal exception so it keeps going.  The chunk that was processed is lost and the reader picks up at the next record or page from where the failure occurred.
If there is an error in the SQL statement used for a JdbcPagingItemReader then the end result looks like there was nothing to process.
Having the read throw a fatal exception for any non-skippable exception would solve this specific issue.  Not sure of that would cause some other side effects.
</description>
			<version>1.1.2</version>
			<fixedVersion>1.1.3, 2.0.0.M2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.SkipLimitStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantChunkOrientedTasklet.java</file>
			<file type="M">org.springframework.batch.core.step.item.SimpleRetryExceptionHandler.java</file>
			<file type="M">org.springframework.batch.core.step.item.SkipLimitStepFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.StatefulRetryStepFactoryBeanTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="682" opendate="2008-06-22 20:35:12" fixdate="2008-09-30 21:53:39" resolution="Fixed">
		<buginformation>
			<summary>Use SoftReference and/or expiry to store entries in RetryContextCache implementation(s)</summary>
			<description>Use SoftReference and/or expiry to store entries in RetryContextCache implementation(s).  If the map-based cache is used in a multi-VM environment, stale cache entries can easily be accumulated inadvertently because the successful processing of a previously failed item happened on a different node than the original failure.  A good start would be to use SoftReferences in the map-based implementation.  Expiry and more complicated features would be best left to mature cache technologies, and custom implementations of the RetryContextCache interface.</description>
			<version>1.0.1</version>
			<fixedVersion>2.0.0.M2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.retry.policy.MapRetryContextCache.java</file>
		</fixedFiles>
	</bug>
	<bug id="778" opendate="2008-08-11 04:43:17" fixdate="2008-09-30 23:17:14" resolution="Fixed">
		<buginformation>
			<summary>MapJobRepositoryFactoryBean shouldn&amp;apos;t require transactionManager</summary>
			<description>If you&amp;amp;apos;re using:
&amp;lt;bean id="jobRepository"
		class="org.springframework.batch.core.repository.support.MapJobRepositoryFactoryBean" /&amp;gt;
This exception occurs:
java.lang.IllegalArgumentException: TransactionManager must not be null
This is because MapJobRepositoryFactoryBean extends AbstractJobRepositoryFactoryBean (same as JobRepositoryFactoryBean) and this
abstract class require a TransactionManager set. (in afterPropertiesSet method)
I believe the TransactionManager  should be requiered only for JobRepositoryFactoryBean, because only in this we have database operations involved.</description>
			<version>1.1.0</version>
			<fixedVersion>2.0.0.M1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.repository.dao.MapJobInstanceDao.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.MapJobExecutionDao.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.MapExecutionContextDao.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.MapStepExecutionDao.java</file>
			<file type="M">org.springframework.batch.core.repository.support.AbstractJobRepositoryFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.repository.support.MapJobRepositoryFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.repository.support.JobRepositoryFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.repository.support.MapJobRepositoryFactoryBeanTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="865" opendate="2008-10-03 12:55:15" fixdate="2008-10-03 13:20:09" resolution="Fixed">
		<buginformation>
			<summary>CompositeItemProcessor should handle null properly</summary>
			<description>Now that returning null from an ItemProcessor indicates filtering on an item, CompositeItemProcessor should return null if any processor in the chain returns null.</description>
			<version>2.0.0.M1</version>
			<fixedVersion>2.0.0.M2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.support.CompositeItemProcessorTests.java</file>
			<file type="M">org.springframework.batch.item.support.CompositeItemProcessor.java</file>
		</fixedFiles>
	</bug>
	<bug id="833" opendate="2008-09-11 11:06:10" fixdate="2008-10-05 19:24:39" resolution="Fixed">
		<buginformation>
			<summary>TransactionAttributes swallows Exceptions</summary>
			<description>If the TransactionAttributes determines that a Transaction shouldn&amp;amp;apos;t be rolled back, the exception is effectively swallowed:
try 
{
						exitStatus = tasklet.execute(contribution, attributes);
					}
					catch (Error e) {
						if (transactionAttribute.rollbackOn(e)) 
{
							throw e;
						}
						else {
							logger.error("Ecountered error that should not cause rollback: ", e);
						}
					}
					catch (Exception e) {
						if (transactionAttribute.rollbackOn(e)) {							throw e;						}
						else 
{
							logger.error("Ecountered error that should not cause rollback: ", e);
						}
					}
So, for example, if the TransactionAttributes are set to not rollback a SkipLimitExceededException, it won&amp;amp;apos;t be rolledback, effectively preventing it from going up to the StepOperations and causing the step to fail.  Of course, someone shouldn&amp;amp;apos;t think to do that, but it&amp;amp;apos;s just one example.  If someone sets any exception to be on the fatal list, but messes up and puts an exception in the attribute list to cause rollback, the step won&amp;amp;apos;t fail.
I propose that the rollback decision on transaction attribute be used solely to determine whether the transaction is committing, but that the exception should still be propagated up to the StepOperations to determine whether or not it should cause failure.</description>
			<version>1.1.2</version>
			<fixedVersion>1.1.3, 2.0.0.M2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.tasklet.TaskletStep.java</file>
		</fixedFiles>
	</bug>
	<bug id="832" opendate="2008-09-11 07:24:21" fixdate="2008-10-06 18:57:09" resolution="Fixed">
		<buginformation>
			<summary>DefaultTransactionAttribute is inappropriate for TaskletStep</summary>
			<description>The DefaultTransactionAttributes use in TaskletStep should not be used.  The problem is how it determines what should be rolledback:
	public boolean rollbackOn(Throwable ex) 
{
		return (ex instanceof RuntimeException || ex instanceof Error);
	}

This means that any checked exceptions will not cause a rollback.  This was fine in 1.1 given how way it was structured, it wouldn&amp;amp;apos;t be possible to get a checked exception, since it would have been wrapped first.  However, the Tasklet interface declares that it throws exception, so anyone using the TaskletStep for the same reasons they would have done so in 1.1 will get into an infinite loop if they throw a checked exception from their Tasklet.</description>
			<version>2.0.0.M1</version>
			<fixedVersion>1.1.3, 2.0.0.M2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.SkipLimitStepFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.SkipLimitStepFactoryBeanNonBufferingTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.SimpleStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.step.tasklet.TaskletStep.java</file>
		</fixedFiles>
	</bug>
	<bug id="870" opendate="2008-10-08 18:10:56" fixdate="2008-10-08 18:58:21" resolution="Fixed">
		<buginformation>
			<summary>Cannot add description to empty ExitStatus</summary>
			<description>Cannot add description to empty ExitStatus.  One result is that the stack trace is missing from JobExecution when an exception is thrown in a step.</description>
			<version>1.1.1</version>
			<fixedVersion>1.1.3, 2.0.0.M2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.repeat.ExitStatus.java</file>
			<file type="M">org.springframework.batch.repeat.ExitStatusTests.java</file>
			<file type="M">org.springframework.batch.core.step.AbstractStepTests.java</file>
			<file type="M">org.springframework.batch.core.step.AbstractStep.java</file>
		</fixedFiles>
	</bug>
	<bug id="866" opendate="2008-10-05 05:33:38" fixdate="2008-10-08 23:38:56" resolution="Fixed">
		<buginformation>
			<summary>Reference manual has invalid references to org.springframework.batch.io.file package</summary>
			<description>The org.springframework.batch.io.file package doesn&amp;amp;apos;t exists - should reference org.springframework.batch.item.file instead</description>
			<version>1.1.2</version>
			<fixedVersion>1.1.3, 2.0.0.M2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.mapping.PassThroughFieldSetMapper.java</file>
			<file type="M">org.springframework.batch.item.file.mapping.DefaultFieldSet.java</file>
		</fixedFiles>
	</bug>
	<bug id="857" opendate="2008-10-01 00:07:43" fixdate="2008-10-14 19:37:59" resolution="Fixed">
		<buginformation>
			<summary>map daos need to be truly transactional for correct restart</summary>
			<description>Map daos keep references to mutable entities therefore they aren&amp;amp;apos;t truly transactional, regardless of using transactional maps. This leads to incorrect restart since the values stored in ExecutionContext don&amp;amp;apos;t reflect the rollback that preceded step failure.
The solution should be to clone the values before storing them, together with using the transactional collection wrappers.</description>
			<version>1.1.2</version>
			<fixedVersion>1.1.3, 2.0.0.M3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.repository.dao.MapExecutionContextDaoTests.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.MapStepExecutionDaoTests.java</file>
			<file type="M">org.springframework.batch.core.job.SimpleJobTests.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.MapExecutionContextDao.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.MapJobExecutionDaoTests.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.MapStepExecutionDao.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.MapJobExecutionDao.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.MapJobInstanceDao.java</file>
			<file type="M">org.springframework.batch.core.repository.support.AbstractJobRepositoryFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.repository.support.MapJobRepositoryFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.repository.support.JobRepositoryFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.repository.support.JobRepositoryFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.repository.support.MapJobRepositoryFactoryBeanTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="853" opendate="2008-09-25 02:31:08" fixdate="2008-10-16 20:23:19" resolution="Fixed">
		<buginformation>
			<summary>broken transactional item processing</summary>
			<description>Results of processing are buffered between transactions, which means in case of write failure causing rollback items don&amp;amp;apos;t get re-processed. In case processing is transactional this is obviously wrong behavior. We either need to fix this or document clearly as limitation.</description>
			<version>2.0.0.M1</version>
			<fixedVersion>2.0.0.M3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBeanNonBufferingTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantChunkOrientedTaskletTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantChunkOrientedTasklet.java</file>
		</fixedFiles>
	</bug>
	<bug id="887" opendate="2008-10-23 13:49:36" fixdate="2008-10-23 19:25:30" resolution="Fixed">
		<buginformation>
			<summary>onSkipInProcess called multiple times for same item using FaultTolerantChunkOrientedTasklet</summary>
			<description>If there are skips during the writing of the chunk then the items in the chunk are processed twice again and the onSkipInProcess gets called for each time the chunk is processed.
The basic sequence of events:

read chunk


process chunk - some items cause process skip and the items are removed from chunk and placed in skip list
onSkipInProcess called for skipped items
write chunk - exception thrown for one item


process chunk without the process skips
onSkipInProcess called again for skipped items
write individual chunks - exception thrown for same item  and the item is removed from the chunk
onSkipInWrite called


process chunk without the process or write skips
write chunk without the process or write skips
onSkipInProcess called again for skipped items

Seems that we should remove the skips from the skip list after the first onSkipInProcess is completed or supress the call once it has been made for the skip list.</description>
			<version>2.0.0.M2</version>
			<fixedVersion>2.0.0.M3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantChunkOrientedTaskletTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantChunkOrientedTasklet.java</file>
		</fixedFiles>
	</bug>
	<bug id="892" opendate="2008-10-28 22:15:48" fixdate="2008-10-29 21:39:21" resolution="Fixed">
		<buginformation>
			<summary>Thread visibility issues in repeat template</summary>
			<description>ResultHolder implementation in TaskExecutorRepeatTemplate probably needs some volatile keywords (http://forum.springframework.org/showthread.php?t=61715).</description>
			<version>1.1.2</version>
			<fixedVersion>1.1.3, 2.0.0.M3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.repeat.support.TaskExecutorRepeatTemplate.java</file>
		</fixedFiles>
	</bug>
	<bug id="897" opendate="2008-10-30 03:53:45" fixdate="2008-11-03 22:23:59" resolution="Fixed">
		<buginformation>
			<summary>Version is not rehydrated from database in JobInstance or JobExecution</summary>
			<description>Version is not rehydrated from database in JobInstance or JobExecution</description>
			<version>2.0.0.M3</version>
			<fixedVersion>2.0.0.M3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.repository.dao.MapJobExecutionDao.java</file>
			<file type="M">org.springframework.batch.sample.DatabaseShutdownFunctionalTests.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcStepExecutionDao.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.AbstractJobDaoTests.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcJobExecutionDao.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.AbstractJobExecutionDaoTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="912" opendate="2008-11-08 02:25:39" fixdate="2008-11-08 04:09:09" resolution="Fixed">
		<buginformation>
			<summary>Thread safety issue in JobRegistryBackgroundJobRunner</summary>
			<description>I noticed that the errors variable in JobRegistryBackgroundJobRunner is modified by one thread and accessed by another without synchronization. As the ArrayList isn&amp;amp;apos;t thread safe, I think this might cause visibility issues in the code that checks if errors has occurred during initialization of the application context. As with all visibility issues it is hard to prove this, but I believe that at least in theory this may be a problem.
A way to fix this would be by replacing
private static List&amp;lt;Exception&amp;gt; errors = new ArrayList&amp;lt;Exception&amp;gt;();
with
private static List&amp;lt;Exception&amp;gt; errors = Collections.synchronizedCollection(new ArrayList&amp;lt;Exception&amp;gt;());
Not sure if making the list volatile will work...as I&amp;amp;apos;m not all that confident on what the implications are of making a collection variable volatile. Don&amp;amp;apos;t think there will much of a performance hit this particular case anyway.</description>
			<version>2.0.0.M2</version>
			<fixedVersion>2.0.0.M3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.launch.support.JobRegistryBackgroundJobRunner.java</file>
		</fixedFiles>
	</bug>
	<bug id="921" opendate="2008-11-11 21:38:32" fixdate="2008-11-12 00:40:56" resolution="Fixed">
		<buginformation>
			<summary>ExecutionContext keys are not unique enough in partition components</summary>
			<description>ExecutionContext keys are not unique enough.  I thought we used to prepend the class name or something?</description>
			<version>2.0.0.M3</version>
			<fixedVersion>2.0.0.M3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.partition.support.SimpleStepExecutionSplitter.java</file>
		</fixedFiles>
	</bug>
	<bug id="926" opendate="2008-11-13 00:54:53" fixdate="2008-11-17 20:09:58" resolution="Fixed">
		<buginformation>
			<summary>vague skip limit for concurrent chunks</summary>
			<description>When chunks execute concurrently each chunk works with its own local copy of skipCount (from StepContribution). Given skipLimit=1 and 10 chunks execute concurrenlty we can end up with successful job execution and 10 skips. As the number of concurrent chunks increases the skipLimit becomes more a limit per chunk rather than job.</description>
			<version>1.1.3</version>
			<fixedVersion>1.1.4, 2.0.0.M3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBean.java</file>
		</fixedFiles>
	</bug>
	<bug id="931" opendate="2008-11-19 02:48:02" fixdate="2008-11-20 20:29:22" resolution="Fixed">
		<buginformation>
			<summary>Write failures don&amp;apos;t fail immediately.</summary>
			<description>When using the FaultTolerantStepFactoryBean, without configuring any exception lists, an exception thrown in the writer will cause failure.  However, it appears to be trying to determine which item failed before actually failing, which is somewhat confusing.</description>
			<version>2.0.0.M2</version>
			<fixedVersion>2.0.0.M3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantChunkOrientedTaskletTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.AbstractFaultTolerantChunkOrientedTasklet.java</file>
		</fixedFiles>
		<links>
			<link type="Related" description="is related to">936</link>
		</links>
	</bug>
	<bug id="939" opendate="2008-11-23 18:04:06" fixdate="2008-11-23 18:04:24" resolution="Fixed">
		<buginformation>
			<summary>Make step scope work with aop-auto-proxy</summary>
			<description></description>
			<version>2.0.0.M3</version>
			<fixedVersion>2.0.0.M3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.scope.TestCollaborator.java</file>
			<file type="M">org.springframework.batch.core.scope.util.PlaceholderTargetSource.java</file>
			<file type="M">org.springframework.batch.core.scope.StepContext.java</file>
			<file type="M">org.springframework.batch.core.scope.TestStep.java</file>
			<file type="M">org.springframework.batch.core.scope.util.PlaceholderProxyFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.scope.StepScope.java</file>
		</fixedFiles>
	</bug>
	<bug id="946" opendate="2008-11-27 03:57:48" fixdate="2008-11-28 00:06:21" resolution="Fixed">
		<buginformation>
			<summary>NullPointerException in MapStepExecutionDao.getStepExecutions</summary>
			<description> MapStepExecutionDao throws a NullPointerException for jobs whitout steps. For example
Job job1 = new Job() {
	public void execute(JobExecution arg0) 
{
		System.err.println("execute!");
	}
..
}
I get the following exception while running a job:
java.lang.NullPointerException
	at org.springframework.batch.core.repository.dao.MapStepExecutionDao.getStepExecutions(MapStepExecutionDao.java:101)
	at org.springframework.batch.core.explore.support.SimpleJobExplorer.getJobExecutionDependencies(SimpleJobExplorer.java:127)
	at org.springframework.batch.core.explore.support.SimpleJobExplorer.findJobExecutions(SimpleJobExplorer.java:73)
	at StartupTest.testMe(StartupTest.java:72)
The solution is:
	public List&amp;lt;StepExecution&amp;gt; getStepExecutions(JobExecution jobExecution) {
 		Map&amp;lt;String, StepExecution&amp;gt; executions = executionsByJobExecutionId.get(jobExecution.getId());
+		if (executions == null) 
{
+			return null;
+		}
 		List&amp;lt;StepExecution&amp;gt; result = new ArrayList&amp;lt;StepExecution&amp;gt;(executions.values());</description>
			<version>2.0.0.M3</version>
			<fixedVersion>2.0.0.M4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.repository.dao.AbstractStepExecutionDaoTests.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.MapStepExecutionDao.java</file>
		</fixedFiles>
	</bug>
	<bug id="948" opendate="2008-12-01 00:37:23" fixdate="2008-12-01 03:19:36" resolution="Fixed">
		<buginformation>
			<summary>MapJobInstanceDao.getLastJobInstances ignores jobName parameter</summary>
			<description>MapJobInstanceDao.getLastJobInstances ignores jobName parameter and returns  JobInstances for all jobs. 
</description>
			<version>2.0.0.M3</version>
			<fixedVersion>2.0.0.M4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.repository.dao.MapJobInstanceDao.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.AbstractJobInstanceDaoTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="951" opendate="2008-12-02 03:36:00" fixdate="2008-12-04 07:48:17" resolution="Fixed">
		<buginformation>
			<summary>MapJobInstanceDao.getLastJobInstances doesn&amp;apos;t return the last job instance </summary>
			<description>Wrong order of job instances in MapJobInstanceDao.getLastJobInstances. MapJobInstanceDao.getLastJobInstances returns always  &amp;amp;apos;old&amp;amp;apos; job instances.</description>
			<version>2.0.0.M3</version>
			<fixedVersion>2.0.0.M4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.repository.dao.MapJobInstanceDao.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.AbstractJobInstanceDaoTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="954" opendate="2008-12-04 23:55:20" fixdate="2008-12-07 22:52:01" resolution="Fixed">
		<buginformation>
			<summary>Failure on job stop</summary>
			<description>Try to stop a job with SimpleJobOperator through JMX.
A OptimisticLockingFailureException is thrown because the jobExecution version doesn&amp;amp;apos;t match with persisted one.
Bug origin :
When the JobExecution status is synchronized, the version is not updated.</description>
			<version>2.0.0.M3</version>
			<fixedVersion>2.0.0.M4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcJobExecutionDaoTests.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.MapJobExecutionDao.java</file>
			<file type="M">org.springframework.batch.core.launch.support.SimpleJobOperator.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcJobExecutionDao.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.JobExecutionDao.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.AbstractJobExecutionDaoTests.java</file>
			<file type="M">org.springframework.batch.core.job.SimpleJobTests.java</file>
			<file type="M">org.springframework.batch.core.partition.support.PartitionStepTests.java</file>
		</fixedFiles>
		<links>
			<link type="Related" description="is related to">961</link>
		</links>
	</bug>
	<bug id="950" opendate="2008-12-02 02:06:33" fixdate="2008-12-08 01:34:53" resolution="Fixed">
		<buginformation>
			<summary>Exception during rollback hides root cause</summary>
			<description>If an exception is thrown while processing a rollback the root exception fails to be logged.
In ItemOrientedStep it catches Exception then calls processRollback but if processRollback throws an exception the original cause is never even logged, making it very difficult to track down the root cause of the exception. Perhaps changing the code from:
catch (Exception e) {
	processRollback(stepExecution, contribution, fatalException, transaction);
	throw e;
}
to:
catch (Exception e) {
    try 
{
    	processRollback(stepExecution, contribution, fatalException, transaction);
    	throw e;
    }
    catch (Exception rollbackException) 
{
        logger.error("Exception thrown during processRollback will be propegated, exception that caused the rollback follows", e);
        throw rollbackException;
    }
}
An example stack trace for this problem is:
org.springframework.batch.core.step.AbstractStep$FatalException: Failed while processing rollback
        at org.springframework.batch.core.step.item.ItemOrientedStep.processRollback(ItemOrientedStep.java:428)
        at org.springframework.batch.core.step.item.ItemOrientedStep.access$1000(ItemOrientedStep.java:68)
        at org.springframework.batch.core.step.item.ItemOrientedStep$1.doInIteration(ItemOrientedStep.java:347)
        at org.springframework.batch.repeat.support.RepeatTemplate.getNextResult(RepeatTemplate.java:346)
        at org.springframework.batch.repeat.support.RepeatTemplate.executeInternal(RepeatTemplate.java:212)
        at org.springframework.batch.repeat.support.RepeatTemplate.iterate(RepeatTemplate.java:143)
        at org.springframework.batch.core.step.item.ItemOrientedStep.doExecute(ItemOrientedStep.java:231)
        at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:172)
        at org.springframework.batch.core.job.SimpleJob.execute(SimpleJob.java:100)
        at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:86)
        at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:49)
        at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:81)
        at org.jasig.portal.stats.quartz.JobLauncherDetails.executeInternal(JobLauncherDetails.java:71)
        at org.springframework.scheduling.quartz.QuartzJobBean.execute(QuartzJobBean.java:86)
        at org.quartz.core.JobRunShell.run(JobRunShell.java:203)
        at org.quartz.simpl.SimpleThreadPool$WorkerThread.run(SimpleThreadPool.java:520)
Caused by: org.springframework.transaction.TransactionSystemException: Could not roll back JDBC transaction; nested exception is java.sql.SQLException: Protocol violation
        at org.springframework.jdbc.datasource.DataSourceTransactionManager.doRollback(DataSourceTransactionManager.java:279)
        at org.springframework.transaction.support.AbstractPlatformTransactionManager.processRollback(AbstractPlatformTransactionManager.java:800)
        at org.springframework.transaction.support.AbstractPlatformTransactionManager.rollback(AbstractPlatformTransactionManager.java:777)
        at org.springframework.batch.core.step.item.ItemOrientedStep.processRollback(ItemOrientedStep.java:419)
        ... 15 more
Caused by: java.sql.SQLException: Protocol violation
        at oracle.jdbc.driver.SQLStateMapping.newSQLException(SQLStateMapping.java:70)
        at oracle.jdbc.driver.DatabaseError.newSQLException(DatabaseError.java:110)
        at oracle.jdbc.driver.DatabaseError.throwSqlException(DatabaseError.java:171)
        at oracle.jdbc.driver.DatabaseError.throwSqlException(DatabaseError.java:227)
        at oracle.jdbc.driver.DatabaseError.throwSqlException(DatabaseError.java:439)
        at oracle.jdbc.driver.T4C7Ocommoncall.receive(T4C7Ocommoncall.java:130)
        at oracle.jdbc.driver.T4CConnection.doRollback(T4CConnection.java:613)
        at oracle.jdbc.driver.PhysicalConnection.rollback(PhysicalConnection.java:3389)
        at org.apache.commons.dbcp.DelegatingConnection.rollback(DelegatingConnection.java:328)
        at org.apache.commons.dbcp.PoolingDataSource$PoolGuardConnectionWrapper.rollback(PoolingDataSource.java:312)
        at org.springframework.jdbc.datasource.DataSourceTransactionManager.doRollback(DataSourceTransactionManager.java:276)
        ... 18 more</description>
			<version>1.1.3</version>
			<fixedVersion>1.1.4, 2.0.0.M4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.tasklet.TaskletStep.java</file>
		</fixedFiles>
		<links>
			<link type="Related" description="is related to">962</link>
		</links>
	</bug>
	<bug id="963" opendate="2008-12-08 20:31:29" fixdate="2008-12-09 22:11:50" resolution="Fixed">
		<buginformation>
			<summary>ExecutionContext modifications in ItemStream.close(ExecutionContext) are not persisted</summary>
			<description>There is an issue with semantics - the close(..) method is typically used to release resources after step completion but can also be used to store values in execution context. In the first case  failure in close(..) shouldn&amp;amp;apos;t cause step failure, in the latter it should.
The easy way to go would be to document the behavior, or maybe we can simply remove the ExecutionContext method argument?</description>
			<version>2.0.0.M3</version>
			<fixedVersion>2.0.0.M4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.integration.chunk.ChunkMessageChannelItemWriter.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReaderCommonTests.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemWriterTests.java</file>
			<file type="M">org.springframework.batch.item.file.MultiResourceItemReaderXmlTests.java</file>
			<file type="M">org.springframework.batch.item.database.AbstractPagingItemReaderParameterTests.java</file>
			<file type="M">org.springframework.batch.core.partition.ExampleItemReader.java</file>
			<file type="M">org.springframework.batch.item.xml.TransactionalStaxEventItemWriterTests.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemWriter.java</file>
			<file type="M">org.springframework.batch.item.CommonItemStreamItemReaderTests.java</file>
			<file type="M">org.springframework.batch.item.file.MultiResourceItemWriter.java</file>
			<file type="M">spring-batch-infrastructure.src.test.java.MultiResourceItemWriterXmlTests.java</file>
			<file type="M">org.springframework.batch.sample.iosample.internal.MultiLineTradeItemWriter.java</file>
			<file type="M">org.springframework.batch.item.database.HibernateCursorItemReaderCommonTests.java</file>
			<file type="M">org.springframework.batch.item.ItemStreamSupport.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemReaderCommonTests.java</file>
			<file type="M">org.springframework.batch.io.oxm.AbstractStaxEventWriterItemWriterTests.java</file>
			<file type="M">org.springframework.batch.item.support.AbstractItemCountingItemStreamItemReader.java</file>
			<file type="M">org.springframework.batch.item.database.DrivingQueryItemReader.java</file>
			<file type="M">org.springframework.batch.item.database.HibernateCursorItemReaderStatefulIntegrationTests.java</file>
			<file type="M">org.springframework.batch.io.oxm.AbstractStaxEventReaderItemReaderTests.java</file>
			<file type="M">org.springframework.batch.item.database.AbstractDataSourceItemReaderIntegrationTests.java</file>
			<file type="M">org.springframework.batch.item.database.IbatisItemReaderCommonTests.java</file>
			<file type="M">org.springframework.batch.item.database.IbatisPagingItemReaderCommonTests.java</file>
			<file type="M">org.springframework.batch.sample.iosample.internal.MultiLineTradeItemReader.java</file>
			<file type="M">org.springframework.batch.item.database.JpaPagingItemReaderCommonTests.java</file>
			<file type="M">org.springframework.batch.item.database.JdbcCursorItemReader.java</file>
			<file type="M">org.springframework.batch.item.file.MultiResourceItemReader.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemWriterTests.java</file>
			<file type="M">org.springframework.batch.core.step.tasklet.TaskletStepTests.java</file>
			<file type="M">org.springframework.batch.item.database.FooInputSource.java</file>
			<file type="M">org.springframework.batch.item.file.MultiResourceItemReaderIntegrationTests.java</file>
			<file type="M">org.springframework.batch.sample.domain.trade.internal.FlatFileCustomerCreditDaoTests.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemReaderTests.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReaderTests.java</file>
			<file type="M">org.springframework.batch.sample.common.CustomItemReaderTests.java</file>
			<file type="M">org.springframework.batch.item.support.CompositeItemStreamTests.java</file>
			<file type="M">org.springframework.batch.item.ItemStream.java</file>
			<file type="M">org.springframework.batch.sample.domain.trade.internal.FlatFileCustomerCreditDao.java</file>
			<file type="M">org.springframework.batch.item.database.SingleColumnJdbcDrivingQueryItemReaderCommonTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.TestReader.java</file>
			<file type="M">org.springframework.batch.item.file.MultiResourceItemWriterFlatFileTests.java</file>
			<file type="M">org.springframework.batch.item.database.JdbcPagingItemReaderCommonTests.java</file>
			<file type="M">org.springframework.batch.item.database.JdbcCursorItemReaderCommonTests.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemWriter.java</file>
			<file type="M">org.springframework.batch.core.step.tasklet.TaskletStep.java</file>
			<file type="M">org.springframework.batch.item.support.CompositeItemStream.java</file>
			<file type="M">org.springframework.batch.item.file.MultiResourceItemReaderFlatFileTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.TaskletStepExceptionTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="969" opendate="2008-12-14 19:02:19" fixdate="2008-12-14 20:40:24" resolution="Fixed">
		<buginformation>
			<summary>FlatFileItemWriters interference in CompositeItemWriter</summary>
			<description>http://forum.springframework.org/showthread.php?t=64607
Two FFIW end up writing to the same resource when injected into CompositeItemWriter. No clue how that&amp;amp;apos;s possible yet, but I was able to recreate the problem.</description>
			<version>2.0.0.M3</version>
			<fixedVersion>2.0.0.M4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.support.transaction.TransactionAwareBufferedWriter.java</file>
			<file type="M">org.springframework.batch.support.transaction.TransactionAwareBufferedWriterTests.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemWriter.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemWriter.java</file>
			<file type="M">org.springframework.batch.item.util.ExecutionContextUserSupport.java</file>
			<file type="M">org.springframework.batch.sample.CompositeItemWriterSampleFunctionalTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="979" opendate="2008-12-29 18:40:54" fixdate="2009-01-12 21:07:35" resolution="Fixed">
		<buginformation>
			<summary>Insert Apache license header in Java sources (where missing)</summary>
			<description>Insert Apache license header in Java sources (where missing).  I think 1.0 started off with all headers correct.  Looks like we have slipped...</description>
			<version>2.0.0.M3</version>
			<fixedVersion>2.0.0.M4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.repository.support.MapJobRepositoryFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.step.tasklet.SystemCommandException.java</file>
			<file type="M">org.springframework.batch.core.repository.support.AbstractJobRepositoryFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.launch.support.ExitCodeMapper.java</file>
			<file type="M">org.springframework.batch.item.support.CompositeItemProcessor.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.JobInstanceDao.java</file>
			<file type="M">org.springframework.batch.integration.launch.JobLaunchingMessageHandler.java</file>
			<file type="M">org.springframework.batch.core.configuration.support.OsgiBundleXmlApplicationContextFactory.java</file>
			<file type="M">org.springframework.batch.sample.domain.trade.CompositeCustomerUpdateLineTokenizer.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.JobExecutionDao.java</file>
			<file type="M">org.springframework.batch.core.configuration.support.ClassPathXmlApplicationContextFactory.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemWriter.java</file>
			<file type="M">org.springframework.batch.item.file.transform.RangeArrayPropertyEditor.java</file>
			<file type="M">org.springframework.batch.sample.domain.trade.CustomerUpdateWriter.java</file>
			<file type="M">org.springframework.batch.core.partition.support.Partitioner.java</file>
			<file type="M">org.springframework.batch.sample.domain.football.Player.java</file>
			<file type="M">org.springframework.batch.sample.support.RetrySampleItemWriter.java</file>
			<file type="M">org.springframework.batch.item.file.SimpleResourceSuffixCreator.java</file>
			<file type="M">org.springframework.batch.integration.file.MessageToJobParametersStrategy.java</file>
			<file type="M">org.springframework.batch.core.annotation.OnProcessError.java</file>
			<file type="M">org.springframework.batch.sample.common.InfiniteLoopReader.java</file>
			<file type="M">org.springframework.batch.core.step.item.SimpleChunkProcessor.java</file>
			<file type="M">org.springframework.batch.core.annotation.AfterStep.java</file>
			<file type="M">org.springframework.batch.repeat.support.ResultHolder.java</file>
			<file type="M">org.springframework.batch.item.xml.stax.AbstractEventReaderWrapper.java</file>
			<file type="M">org.springframework.batch.item.util.FileUtils.java</file>
			<file type="M">org.springframework.batch.item.ItemProcessor.java</file>
			<file type="M">org.springframework.batch.core.partition.support.StepExecutionAggregator.java</file>
			<file type="M">org.springframework.batch.sample.domain.trade.CustomerOperation.java</file>
			<file type="M">org.springframework.batch.sample.domain.trade.internal.CommonsLoggingInvalidCustomerLogger.java</file>
			<file type="M">org.springframework.batch.core.partition.StepExecutionSplitter.java</file>
			<file type="M">org.springframework.batch.core.step.tasklet.SystemProcessExitCodeMapper.java</file>
			<file type="M">org.springframework.batch.core.job.flow.support.state.DecisionState.java</file>
			<file type="M">org.springframework.batch.core.partition.support.PartitionStep.java</file>
			<file type="M">org.springframework.batch.repeat.RepeatStatus.java</file>
			<file type="M">org.springframework.batch.sample.domain.trade.internal.CustomerCreditItemWriter.java</file>
			<file type="M">org.springframework.batch.sample.domain.trade.CustomerUpdateFieldSetMapper.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileFooterCallback.java</file>
			<file type="M">org.springframework.batch.core.scope.util.StepContextFactory.java</file>
			<file type="M">org.springframework.batch.sample.domain.trade.CustomerUpdate.java</file>
			<file type="M">org.springframework.batch.item.file.mapping.DefaultLineMapper.java</file>
			<file type="M">org.springframework.batch.item.xml.stax.AbstractEventWriterWrapper.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.MapJobExecutionDao.java</file>
			<file type="M">org.springframework.batch.core.annotation.BeforeJob.java</file>
			<file type="M">org.springframework.batch.core.step.item.Chunk.java</file>
			<file type="M">org.springframework.batch.test.AbstractSimpleJobTests.java</file>
			<file type="M">org.springframework.batch.core.partition.support.SimpleStepExecutionSplitter.java</file>
			<file type="M">org.springframework.batch.item.database.KeyCollector.java</file>
			<file type="M">org.springframework.batch.test.StepRunner.java</file>
			<file type="M">org.springframework.batch.sample.domain.trade.InvalidCustomerLogger.java</file>
			<file type="M">org.springframework.batch.item.database.support.ColumnMapItemPreparedStatementSetter.java</file>
			<file type="M">org.springframework.batch.sample.support.SummaryFooterCallback.java</file>
			<file type="M">org.springframework.batch.sample.domain.trade.internal.CustomerCreditRowMapper.java</file>
			<file type="M">org.springframework.batch.sample.domain.football.Game.java</file>
			<file type="M">org.springframework.batch.core.scope.context.StepScopeManager.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxWriterCallback.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReader.java</file>
			<file type="M">org.springframework.batch.test.AssertFile.java</file>
			<file type="M">org.springframework.batch.core.step.item.SkipWrapper.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileHeaderCallback.java</file>
			<file type="M">org.springframework.batch.sample.domain.football.internal.PlayerFieldSetMapper.java</file>
			<file type="M">org.springframework.batch.core.step.item.ChunkOrientedTasklet.java</file>
			<file type="M">org.springframework.batch.core.annotation.AfterWrite.java</file>
			<file type="M">org.springframework.batch.sample.common.StagingItemWriter.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.MapJobInstanceDao.java</file>
			<file type="M">org.springframework.batch.item.file.mapping.PassThroughLineMapper.java</file>
			<file type="M">org.springframework.batch.item.file.ResourceAwareItemReaderItemStream.java</file>
			<file type="M">org.springframework.batch.core.partition.PartitionHandler.java</file>
			<file type="M">org.springframework.batch.core.JobParametersBuilder.java</file>
			<file type="M">org.springframework.batch.sample.domain.trade.internal.CustomerCreditIncreaseProcessor.java</file>
			<file type="M">org.springframework.batch.core.scope.context.ChunkContext.java</file>
			<file type="M">org.springframework.batch.integration.chunk.AsynchronousFailureException.java</file>
			<file type="M">org.springframework.batch.item.file.ResourceAwareItemWriterItemStream.java</file>
			<file type="M">org.springframework.batch.integration.chunk.ChunkResponse.java</file>
			<file type="M">org.springframework.batch.core.configuration.support.ClassPathXmlJobRegistry.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcJobExecutionDao.java</file>
			<file type="M">org.springframework.batch.core.step.tasklet.ConfigurableSystemProcessExitCodeMapper.java</file>
			<file type="M">org.springframework.batch.core.step.tasklet.SystemCommandTasklet.java</file>
			<file type="M">org.springframework.batch.support.DatabaseType.java</file>
			<file type="M">org.springframework.batch.item.xml.stax.NoStartEndDocumentStreamWriter.java</file>
			<file type="M">org.springframework.batch.core.annotation.OnSkipInRead.java</file>
			<file type="M">org.springframework.batch.sample.domain.trade.CustomerDao.java</file>
			<file type="M">org.springframework.batch.core.step.skip.NonSkippableReadException.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.MapExecutionContextDao.java</file>
			<file type="M">org.springframework.batch.core.explore.support.AbstractJobExplorerFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.partition.support.TaskExecutorPartitionHandler.java</file>
			<file type="M">org.springframework.batch.core.explore.support.MapJobExplorerFactoryBean.java</file>
			<file type="M">org.springframework.batch.sample.domain.trade.internal.GeneratingTradeItemReader.java</file>
			<file type="M">org.springframework.batch.sample.launch.DefaultJobLoader.java</file>
			<file type="M">org.springframework.batch.item.file.ResourceSuffixCreator.java</file>
			<file type="M">org.springframework.batch.core.annotation.OnSkipInWrite.java</file>
			<file type="M">org.springframework.batch.sample.domain.trade.internal.JdbcCustomerDao.java</file>
			<file type="M">org.springframework.batch.item.file.MultiResourceItemWriter.java</file>
			<file type="M">org.springframework.batch.sample.domain.football.internal.JdbcPlayerSummaryDao.java</file>
			<file type="M">org.springframework.batch.core.annotation.BeforeWrite.java</file>
			<file type="M">org.springframework.batch.core.step.item.ChunkProcessor.java</file>
			<file type="M">org.springframework.batch.core.configuration.support.JobFactoryRegistrationListener.java</file>
			<file type="M">org.springframework.batch.core.annotation.AfterJob.java</file>
			<file type="M">org.springframework.batch.item.support.PassthroughItemProcessor.java</file>
			<file type="M">org.springframework.batch.core.job.flow.support.state.EndState.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemReader.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantChunkProvider.java</file>
			<file type="M">org.springframework.batch.core.job.flow.support.state.StepState.java</file>
			<file type="M">org.springframework.batch.item.xml.stax.DefaultFragmentEventReader.java</file>
			<file type="M">org.springframework.batch.sample.common.StagingItemReader.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.item.file.MultiResourceItemReader.java</file>
			<file type="M">org.springframework.batch.sample.domain.football.PlayerDao.java</file>
			<file type="M">org.springframework.batch.integration.chunk.ChunkHandler.java</file>
			<file type="M">org.springframework.batch.sample.domain.trade.CustomerUpdateProcessor.java</file>
			<file type="M">org.springframework.batch.core.JobParameters.java</file>
			<file type="M">org.springframework.batch.core.step.item.SimpleChunkProvider.java</file>
			<file type="M">org.springframework.batch.core.scope.util.ContextFactory.java</file>
			<file type="M">org.springframework.batch.core.step.item.BatchRetryTemplate.java</file>
			<file type="M">org.springframework.batch.test.AbstractJobTests.java</file>
			<file type="M">org.springframework.batch.integration.chunk.ChunkMessageChannelItemWriter.java</file>
			<file type="M">org.springframework.batch.item.database.support.IbatisKeyCollector.java</file>
			<file type="M">org.springframework.batch.item.file.transform.Range.java</file>
			<file type="M">org.springframework.batch.sample.domain.football.internal.FootballExceptionHandler.java</file>
			<file type="M">org.springframework.batch.sample.domain.trade.internal.HibernateAwareCustomerCreditItemWriter.java</file>
			<file type="M">org.springframework.batch.core.step.item.ChunkProvider.java</file>
			<file type="M">org.springframework.batch.item.support.CompositeItemWriter.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcJobInstanceDao.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.ExecutionContextDao.java</file>
			<file type="M">org.springframework.batch.sample.jmx.SimpleMessageApplicationEvent.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.AbstractJdbcBatchMetadataDao.java</file>
			<file type="M">org.springframework.batch.item.file.mapping.LineMapper.java</file>
			<file type="M">org.springframework.batch.sample.common.StagingItemListener.java</file>
			<file type="M">org.springframework.batch.item.file.transform.PassThroughLineAggregator.java</file>
			<file type="M">org.springframework.batch.core.partition.support.SimplePartitioner.java</file>
			<file type="M">org.springframework.batch.item.file.LineCallbackHandler.java</file>
			<file type="M">org.springframework.batch.sample.domain.football.internal.JdbcPlayerDao.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.StepExecutionDao.java</file>
			<file type="M">org.springframework.batch.item.support.AbstractItemCountingItemStreamItemReader.java</file>
			<file type="M">org.springframework.batch.core.annotation.AfterProcess.java</file>
			<file type="M">org.springframework.batch.core.StartLimitExceededException.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcStepExecutionDao.java</file>
			<file type="M">org.springframework.batch.sample.domain.football.PlayerSummary.java</file>
			<file type="M">org.springframework.batch.core.scope.util.PlaceholderProxyFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.annotation.OnWriteError.java</file>
			<file type="M">org.springframework.batch.item.validator.ValidatingItemProcessor.java</file>
			<file type="M">org.springframework.batch.sample.domain.football.internal.PlayerItemWriter.java</file>
			<file type="M">org.springframework.batch.core.configuration.support.ApplicationContextFactory.java</file>
			<file type="M">org.springframework.batch.integration.chunk.ChunkRequest.java</file>
			<file type="M">org.springframework.batch.item.file.transform.RecursiveCollectionLineAggregator.java</file>
			<file type="M">org.springframework.batch.item.adapter.DynamicMethodInvocationException.java</file>
			<file type="M">org.springframework.batch.core.JobParameter.java</file>
			<file type="M">org.springframework.batch.core.annotation.OnSkipInProcess.java</file>
			<file type="M">org.springframework.batch.core.annotation.BeforeStep.java</file>
			<file type="M">org.springframework.batch.sample.domain.football.internal.JdbcGameDao.java</file>
			<file type="M">org.springframework.batch.sample.domain.football.internal.GameFieldSetMapper.java</file>
			<file type="M">org.springframework.batch.sample.support.HeaderCopyCallback.java</file>
			<file type="M">org.springframework.batch.core.step.tasklet.SimpleSystemProcessExitCodeMapper.java</file>
			<file type="M">org.springframework.batch.integration.chunk.ChunkProcessorChunkHandler.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantChunkProcessor.java</file>
			<file type="M">org.springframework.batch.item.xml.stax.FragmentEventReader.java</file>
		</fixedFiles>
	</bug>
	<bug id="994" opendate="2009-01-12 23:38:19" fixdate="2009-01-13 02:34:03" resolution="Fixed">
		<buginformation>
			<summary>BackOffPolicy is not applied for exceptions that cause rollback</summary>
			<description>Retryable exceptions that should cause rollback get re-thrown before BackOffPolicy applies.
http://forum.springframework.org/showthread.php?t=65811</description>
			<version>2.0.0.M3</version>
			<fixedVersion>2.0.0.M4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.retry.support.RetryTemplate.java</file>
			<file type="M">org.springframework.batch.retry.support.RetryTemplateTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="952" opendate="2008-12-02 21:00:50" fixdate="2009-01-14 22:26:41" resolution="Fixed">
		<buginformation>
			<summary>StagingItemReader is not restartable</summary>
			<description>StagingItemReader is not restartable because it updates the process indicator in the read() method, which is only ever called once per item (used to be once per item per transaction in 1.x).  I&amp;amp;apos;m not sure the best way to fix this.  The reader knows the id of the record to be updated, but that information is lost further downstream in the processing pipeline.  Maybe it&amp;amp;apos;s time to get serious about ChunkContext or @ChunkAttribute (see BATCH-920)?
It would be a good time to replace the innards of StagingItemReader anyway - it can delegate most of its stateful behaviour to an off the shelf JDBC ItemReader.</description>
			<version>2.0.0.M3</version>
			<fixedVersion>2.0.0.M4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.sample.common.StagingItemReaderTests.java</file>
			<file type="M">org.springframework.batch.sample.common.StagingItemReader.java</file>
		</fixedFiles>
	</bug>
	<bug id="995" opendate="2009-01-13 00:24:29" fixdate="2009-01-15 20:29:03" resolution="Fixed">
		<buginformation>
			<summary>unclear retry configuration in FaultTolerantStepFactoryBean</summary>
			<description>if (retryPolicy == null) {
	SimpleRetryPolicy simpleRetryPolicy = new SimpleRetryPolicy(retryLimit);
	if (!retryableExceptionClasses.isEmpty()) 
{ // otherwise we
		// retry all exceptions
		simpleRetryPolicy.setRetryableExceptionClasses(retryableExceptionClasses);
	}
	simpleRetryPolicy.setFatalExceptionClasses(fatalExceptionClasses);
	ExceptionClassifierRetryPolicy classifierRetryPolicy = new ExceptionClassifierRetryPolicy();
	HashMap&amp;lt;Class&amp;lt;? extends Throwable&amp;gt;, RetryPolicy&amp;gt; exceptionTypeMap = new HashMap&amp;lt;Class&amp;lt;? extends Throwable&amp;gt;, RetryPolicy&amp;gt;();
	for (Class&amp;lt;? extends Throwable&amp;gt; cls : retryableExceptionClasses) 
{
		exceptionTypeMap.put(cls, simpleRetryPolicy);
	}
	classifierRetryPolicy.setPolicyMap(exceptionTypeMap);
	retryPolicy = classifierRetryPolicy;
}
SimpleRetryPolicy is for some reason wrapped in ExceptionClassifierRetryPolicy. This not only seems unnecessary, but also ignores the fatalExceptionClasses (unless they subclass the retryableExceptionClasses).
The most interesting thing however is that using simpleRetryPolicy directly severely breaks the FaultTolerantStepFactoryBeanTests.</description>
			<version>2.0.0.M3</version>
			<fixedVersion>2.0.0.M4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBean.java</file>
		</fixedFiles>
		<links>
			<link type="Related" description="is related to">996</link>
		</links>
	</bug>
	<bug id="1002" opendate="2009-01-20 14:41:57" fixdate="2009-01-21 22:40:23" resolution="Fixed">
		<buginformation>
			<summary>Default behavior for a Job should be failure if a step fails</summary>
			<description>Currently, the when the "next" attribute is used on a step in a job configuration with the namespace, such as the following:
	&amp;lt;step name="step1" next="step2"/&amp;gt;
	&amp;lt;step name="step2" /&amp;gt;
the interpretation is as follows:
	&amp;lt;step name="step1"&amp;gt;
		&amp;lt;next on="*" to="step2"/&amp;gt;
	&amp;lt;/step&amp;gt;
	&amp;lt;step name="step2" /&amp;gt;
However, this behavior may be confusing for users because "step2" will still execute even if "step1" fails.  Therefore, the correct default behavior should be:
	&amp;lt;step name="step1"&amp;gt;
		&amp;lt;end on="FAILED" status="FAILED"/&amp;gt;
		&amp;lt;next on="*" to="step2"/&amp;gt;
	&amp;lt;/step&amp;gt;
	&amp;lt;step name="step2" /&amp;gt;
</description>
			<version>2.0.0.M3</version>
			<fixedVersion>2.0.0.M4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.NextAttributeJobParserTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1005" opendate="2009-01-21 07:06:30" fixdate="2009-01-22 08:39:16" resolution="Fixed">
		<buginformation>
			<summary>startLimit and allowStartIfComplete cannot be set in the namespace</summary>
			<description>startLimit and allowStartIfComplete are properties on AbstractStep and SimpleStepFactoryBean.  However, there is currently no way to set them using the batch namespace.</description>
			<version>2.0.0.M3</version>
			<fixedVersion>2.0.0.M4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParserTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParser.java</file>
		</fixedFiles>
	</bug>
	<bug id="1001" opendate="2009-01-20 07:05:19" fixdate="2009-01-23 01:50:10" resolution="Fixed">
		<buginformation>
			<summary>Make jobs restartable by default</summary>
			<description>A Job should be restartable by default.  However, the Spring Batch schema, spring-batch-2.0.xsd, and the AbstractJob class list the "restartable" attribute has being false by default.
A patch has been created and attached to make these changes.</description>
			<version>2.0.0.M3</version>
			<fixedVersion>2.0.0.M4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.job.AbstractJob.java</file>
		</fixedFiles>
	</bug>
	<bug id="1021" opendate="2009-01-26 00:42:06" fixdate="2009-01-26 01:13:07" resolution="Fixed">
		<buginformation>
			<summary>AssertFile.assertFileEquals(File,File) parameters in the wrong order</summary>
			<description>In the AssertFile class in spring-batch-test, the method:
assertFileEquals(File actual, File expected)
should be:
assertFileEquals(File expected, File actual)
Patches are attached to fix this.</description>
			<version>2.0.0.M3</version>
			<fixedVersion>2.0.0.M4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.test.AssertFileTests.java</file>
			<file type="M">org.springframework.batch.sample.iosample.MultiLineFunctionalTests.java</file>
			<file type="M">org.springframework.batch.sample.iosample.MultiRecordTypeFunctionalTests.java</file>
			<file type="M">org.springframework.batch.test.AssertFile.java</file>
		</fixedFiles>
	</bug>
	<bug id="1004" opendate="2009-01-21 06:22:42" fixdate="2009-01-26 12:38:11" resolution="Fixed">
		<buginformation>
			<summary>Using namespace to define a step does not store step name</summary>
			<description>When the namespace is used to define a step within a job definition, the parser does not store the step&amp;amp;apos;s "name" attribute on the step.  Instead, the name stored in the step execution is a generated name, for example "(inner bean)#3".
&amp;lt;job id="skipJob"&amp;gt;
    &amp;lt;step name="step1"&amp;gt;
        &amp;lt;tasklet ... /&amp;gt;
StepExecution: id=0, name=(inner bean)#3, ...</description>
			<version>2.0.0.M3</version>
			<fixedVersion>2.0.0.M4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.sample.SkipSampleFunctionalTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParserTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1022" opendate="2009-01-26 06:39:01" fixdate="2009-01-26 17:42:20" resolution="Fixed">
		<buginformation>
			<summary>Chunk is not serializable but is wrapped by a Serializable ChunkRequest</summary>
			<description>The Chunk class is not serializable. This is particularly useful when sending chunks via JMS.</description>
			<version>2.0.0.M3</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.StepContributionTests.java</file>
			<file type="M">org.springframework.batch.core.StepContribution.java</file>
			<file type="M">org.springframework.batch.integration.chunk.ChunkRequest.java</file>
			<file type="M">org.springframework.batch.integration.chunk.ChunkProcessorChunkHandler.java</file>
		</fixedFiles>
	</bug>
	<bug id="1031" opendate="2009-01-27 00:41:12" fixdate="2009-01-27 00:56:33" resolution="Fixed">
		<buginformation>
			<summary>FlatFileItemReader should identify missing resource in warning</summary>
			<description>Current warning says: "Input resource does not exist," but does not identify the resource, forcing debugging to correct.  Patch adds the resource.toString() to the message.</description>
			<version>2.0.0.M3</version>
			<fixedVersion>2.0.0.M4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemReader.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReader.java</file>
		</fixedFiles>
	</bug>
	<bug id="960" opendate="2008-12-07 05:49:37" fixdate="2009-01-27 06:58:22" resolution="Fixed">
		<buginformation>
			<summary>Redundant test cases in samples?</summary>
			<description>Redundant test cases in samples?  There are some test cases in the (mis-named?) iosample package that only test classes in src/test/java.  Is this just a mistake?</description>
			<version>2.0.0.M3</version>
			<fixedVersion>2.0.0.M4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="D">org.springframework.batch.sample.iosample.internal.DelegatingTradeLineAggregatorTests.java</file>
			<file type="D">org.springframework.batch.sample.iosample.internal.MultiLineTradeItemWriterTests.java</file>
			<file type="D">org.springframework.batch.sample.iosample.internal.MultiLineTradeItemReaderTests.java</file>
			<file type="D">org.springframework.batch.sample.iosample.internal.PrefixMatchingCompositeFieldSetMapperTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="959" opendate="2008-12-07 05:47:11" fixdate="2009-01-27 07:45:13" resolution="Fixed">
		<buginformation>
			<summary>Get rid of compiler warnings in samples</summary>
			<description>Get rid of compiler warnings in samples.  I think they are all just caused by sloppy use of raw types.</description>
			<version>2.0.0.M3</version>
			<fixedVersion>2.0.0.M4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.sample.iosample.internal.MultiLineTradeItemWriterTests.java</file>
			<file type="M">org.springframework.batch.sample.iosample.internal.PrefixMatchingCompositeFieldSetMapper.java</file>
			<file type="M">org.springframework.batch.sample.iosample.internal.PrefixMatchingCompositeFieldSetMapperTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1007" opendate="2009-01-21 08:00:02" fixdate="2009-01-28 06:17:23" resolution="Fixed">
		<buginformation>
			<summary>JobRepository default is inconsistent between job and step</summary>
			<description>The way that the job repository property is defaulted in job and step is inconsistent.  With Step, it&amp;amp;apos;s done the right way, by defaulting in the namespace, with good documentation.  However, job is done in the parser:
		String repositoryAttribute = element.getAttribute("repository");
		if (!StringUtils.hasText(repositoryAttribute)) 
{
			repositoryAttribute = "jobRepository";
		}
		builder.addPropertyReference("jobRepository", repositoryAttribute);
There are many others like this in job.</description>
			<version>2.0.0.M3</version>
			<fixedVersion>2.0.0.M4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.JobParser.java</file>
		</fixedFiles>
	</bug>
	<bug id="996" opendate="2009-01-13 23:36:25" fixdate="2009-01-29 00:01:25" resolution="Fixed">
		<buginformation>
			<summary>use default retryLimit  == 1 (not 0) in *StepFactoryBean</summary>
			<description>Per SimpleRetryPolicy&amp;amp;apos;s javadoc the retryLimit includes the initial try as well, therefore it only makes sense to use value &amp;gt;=1.</description>
			<version>1.1.3</version>
			<fixedVersion>1.1.Maintenance, 2.0.0.M4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.retry.policy.SimpleRetryPolicy.java</file>
			<file type="M">org.springframework.batch.retry.policy.SimpleRetryPolicyTests.java</file>
		</fixedFiles>
		<links>
			<link type="Related" description="is related to">995</link>
		</links>
	</bug>
	<bug id="1030" opendate="2009-01-26 22:18:20" fixdate="2009-01-31 19:54:14" resolution="Fixed">
		<buginformation>
			<summary>FlowJob replays failed steps on restart, even if the failure did not fail the job</summary>
			<description>	@Test
	public void testFailedStepRestarted() throws Exception {
		SimpleFlow flow = new SimpleFlow("job");
		Collection&amp;lt;StateTransition&amp;gt; transitions = new ArrayList&amp;lt;StateTransition&amp;gt;();
		transitions.add(StateTransition.createStateTransition(new StepState(new StepSupport("step1") {
			@Override
			public void execute(StepExecution stepExecution) throws JobInterruptedException,
					UnexpectedJobExecutionException 
{
				stepExecution.setStatus(BatchStatus.FAILED);
				stepExecution.setExitStatus(ExitStatus.FAILED);
				jobRepository.update(stepExecution);
			}
		}), "step2"));
		transitions.add(StateTransition.createEndStateTransition(new StepState(new StubStep("step2") {
			@Override
			public void execute(StepExecution stepExecution) throws JobInterruptedException,
					UnexpectedJobExecutionException {
				if (fail) 
{
					stepExecution.setStatus(BatchStatus.FAILED);
					stepExecution.setExitStatus(ExitStatus.FAILED);
					jobRepository.update(stepExecution);
				}
 else 
{
					super.execute(stepExecution);
				}
			}
		})));
		flow.setStateTransitions(transitions);
		job.setFlow(flow);
		job.afterPropertiesSet();
		fail = true;
		job.execute(jobExecution);
		assertEquals(ExitStatus.FAILED, jobExecution.getExitStatus());
		assertEquals(2, jobExecution.getStepExecutions().size());
		jobRepository.update(jobExecution);
		jobExecution = jobRepository.createJobExecution("job", new JobParameters());
		fail = false;
		job.execute(jobExecution);
		assertEquals(ExitStatus.COMPLETED, jobExecution.getExitStatus());
		assertEquals(1, jobExecution.getStepExecutions().size());
	}</description>
			<version>2.0.0.M3</version>
			<fixedVersion>2.0.0.RC1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.job.flow.FlowJobTests.java</file>
			<file type="M">org.springframework.batch.core.job.AbstractJob.java</file>
			<file type="M">org.springframework.batch.core.BatchStatus.java</file>
			<file type="M">org.springframework.batch.core.job.flow.FlowJob.java</file>
		</fixedFiles>
	</bug>
	<bug id="1058" opendate="2009-02-02 16:01:27" fixdate="2009-02-02 17:40:28" resolution="Fixed">
		<buginformation>
			<summary>PlaceholderTargetSource doesn&amp;apos;t always replace all placeholders</summary>
			<description>When multiple Spring EL binding patterns are used, some keys may be missed when replacing text is shorter than the key length.
For exapmle,
&amp;lt;beans:property name="file" value="file:sample_#
{jobParameters[year]}#{jobParameters[month]}#{jobParameters[day]}.xls"/&amp;gt;

When "#{jobParameters[year]}
" gets replaced with "2009", the following code fragment misses the second key "#{jobParameters[month]"
as "next + 1" points to where "#
{jobParameters[month]}
" has already started.
while (first &amp;gt;= 0) 
{

	...
	first = result.indexOf(PLACEHOLDER_PREFIX, next + 1);
	next = result.indexOf(PLACEHOLDER_SUFFIX, first + 1);

}</description>
			<version>2.0.0.M4</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.scope.util.PlaceholderTargetSourceTests.java</file>
			<file type="M">org.springframework.batch.core.scope.util.PlaceholderTargetSource.java</file>
		</fixedFiles>
	</bug>
	<bug id="1059" opendate="2009-02-03 02:53:21" fixdate="2009-02-03 19:12:15" resolution="Fixed">
		<buginformation>
			<summary>BATCH_JOB_INSTANCE.JOB_KEY ignores Date milliseconds</summary>
			<description>When a Date is used as a Job Parameter it is stored correctly (including milliseconds) in BATCH_JOB_PARAMS but the JOB_KEY in BATCH_JOB_INSTANCE does not include milliseconds when generating the key. The problem is in JdbcJobInstanceDao.createJobKey, it just blindly toString&amp;amp;apos;s all the parameters and Date&amp;amp;apos;s toString hides some data.
Instead of blindly calling toString on all parameters a better approach may be to use type-specific String formatting, this would also be slightly more efficient as it avoids adding all parameters to a single Map then iterating that and removes an extra string concatenation operation.
    private String createJobKey(JobParameters jobParameters) {
        StringBuffer stringBuffer = new StringBuffer();
        final Map stringParameters = jobParameters.getStringParameters();
        for (Iterator it = stringParameters.entrySet().iterator(); it.hasNext() 
{
            Entry entry = (Entry) it.next();
            stringBuffer.append(entry.getKey());
            stringBuffer.append("=");
            
            stringBuffer.append(entry.getValue());
            stringBuffer.append(";");
        }

        final Map longParameters = jobParameters.getLongParameters();
        for (Iterator it = longParameters.entrySet().iterator(); it.hasNext() {            Entry entry = (Entry) it.next();            stringBuffer.append(entry.getKey());            stringBuffer.append("=");                        stringBuffer.append(entry.getValue());            stringBuffer.append(";");        }

        final Map doubleParameters = jobParameters.getDoubleParameters();
        for (Iterator it = doubleParameters.entrySet().iterator(); it.hasNext() 
{
            Entry entry = (Entry) it.next();
            stringBuffer.append(entry.getKey());
            stringBuffer.append("=");
            
            stringBuffer.append(entry.getValue());
            stringBuffer.append(";");
        }

        final Map dateParameters = jobParameters.getDateParameters();
        for (Iterator it = dateParameters.entrySet().iterator(); it.hasNext() {
            Entry entry = (Entry) it.next();
            stringBuffer.append(entry.getKey());
            stringBuffer.append("=");
            final Date date = (Date)entry.getValue();
            final String formattedDate;
            synchronized (DATE_PARAMETER_FORMAT) 
{
                //Logic cloned from java.util.Date
                DATE_PARAMETER_FORMAT.setTimeZone(TimeZone.getDefault());
                formattedDate = DATE_PARAMETER_FORMAT.format(date);
            }
            stringBuffer.append(formattedDate);
            stringBuffer.append(";");
        }
        return stringBuffer.toString();
    }</description>
			<version>1.1.4</version>
			<fixedVersion>2.0.0.RC1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.JobParameterTests.java</file>
			<file type="M">org.springframework.batch.core.JobParameter.java</file>
		</fixedFiles>
	</bug>
	<bug id="1061" opendate="2009-02-05 09:50:40" fixdate="2009-02-05 13:05:47" resolution="Fixed">
		<buginformation>
			<summary>FlowJob.getLastStepExecution() puts arguments into isLater() in the wrong order</summary>
			<description>FlowJob.getLastStepExecution() puts arguments into isLater() in the wrong order:
		for (StepExecution stepExecution : execution.getStepExecutions()) {
			if (stepExecution.getStepName().equals(result.getName())
					&amp;amp;&amp;amp; stepExecution.getExitStatus().getExitCode().equals(result.getStatus())) 
{
				value = stepExecution;
			}
			if (isLater(backup, stepExecution)) 
{
				backup = stepExecution;
			}
</description>
			<version>2.0.0.M4</version>
			<fixedVersion>2.0.0.RC1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.job.flow.FlowJob.java</file>
		</fixedFiles>
	</bug>
	<bug id="1053" opendate="2009-01-31 18:19:37" fixdate="2009-02-11 02:17:04" resolution="Fixed">
		<buginformation>
			<summary>Add getStep(String) to Job interface</summary>
			<description>I find AbstractJobTests very useful, but the implementation is awkward, and there are other situations where I can imagine asking the Job for a specific Step.  However getSteps() should remain an implementation detail for the SimpleJob.  I think it is debatable whether getStep(String) belongs on the interface in fact, so let&amp;amp;apos;s have a thin and a chat about it first, but at least it could go on AbstractJob.</description>
			<version>2.0.0.M4</version>
			<fixedVersion>2.0.0.RC1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="D">org.springframework.batch.core.job.flow.support.State.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.SplitParser.java</file>
			<file type="M">org.springframework.batch.core.job.flow.support.StateSupport.java</file>
			<file type="M">org.springframework.batch.core.job.flow.FlowJob.java</file>
			<file type="M">org.springframework.batch.core.job.flow.support.SimpleFlowTests.java</file>
			<file type="M">org.springframework.batch.core.job.flow.support.SimpleFlow.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.DecisionParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.InlineStepParser.java</file>
			<file type="M">org.springframework.batch.core.job.flow.Flow.java</file>
			<file type="M">org.springframework.batch.core.job.AbstractJob.java</file>
			<file type="M">org.springframework.batch.core.job.flow.support.state.StepState.java</file>
			<file type="M">org.springframework.batch.core.job.flow.support.state.SplitState.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.FlowParser.java</file>
			<file type="M">org.springframework.batch.core.job.flow.support.StateTransition.java</file>
			<file type="M">org.springframework.batch.core.job.flow.support.state.EndState.java</file>
			<file type="M">org.springframework.batch.core.job.flow.support.state.AbstractState.java</file>
			<file type="M">org.springframework.batch.test.AbstractJobTests.java</file>
			<file type="M">org.springframework.batch.core.job.flow.FlowJobTests.java</file>
			<file type="M">org.springframework.batch.core.job.SimpleJob.java</file>
			<file type="M">org.springframework.batch.core.job.SimpleJobTests.java</file>
			<file type="M">org.springframework.batch.core.job.AbstractJobTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1075" opendate="2009-02-12 17:35:53" fixdate="2009-02-13 02:14:49" resolution="Fixed">
		<buginformation>
			<summary>allow-start-if-complete and start-limit should be on &lt;step/&gt;, not &lt;tasklet/&gt;</summary>
			<description>It is currently not possible to set allow-start-if-complete or start-limit on a TaskletStep using the namespace because the attributes are on &amp;lt;tasklet/&amp;gt; instead of step.  We should be able to do the following:
    &amp;lt;step id="step1" tasklet="myTasklet" allow-start-if-complete="true" start-limit="100" /&amp;gt;
</description>
			<version>2.0.0.M4</version>
			<fixedVersion>2.0.0.RC1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.AbstractStepParser.java</file>
		</fixedFiles>
	</bug>
	<bug id="618" opendate="2008-05-13 01:40:15" fixdate="2009-02-15 08:25:52" resolution="Fixed">
		<buginformation>
			<summary>DefaultJobParametersConverter does not parse parameters of type double</summary>
			<description>Although JobParameters and JobParametersBuilder support parameters of type double, the DefaultJobParametersConverter does not handle double parameters. Other types (string, date, long) are correctly managed.</description>
			<version>1.0.1</version>
			<fixedVersion>1.1.Maintenance, 2.0.0.RC1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.converter.DefaultJobParametersConverter.java</file>
			<file type="M">org.springframework.batch.core.converter.DefaultJobParametersConverterTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1082" opendate="2009-02-14 22:53:10" fixdate="2009-02-16 08:35:08" resolution="Fixed">
		<buginformation>
			<summary>If file reader is lenient about resource existing on startup, it should also check when it is closed</summary>
			<description>If file reader is lenient about resource existing on startup, it should also check when it is closed.  See forum post: http://forum.springframework.org/showthread.php?t=67490</description>
			<version>2.0.0.M3</version>
			<fixedVersion>2.0.0.RC1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReaderTests.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReader.java</file>
		</fixedFiles>
	</bug>
	<bug id="1086" opendate="2009-02-17 04:27:16" fixdate="2009-02-17 22:54:40" resolution="Fixed">
		<buginformation>
			<summary>JdbcJobExecutionDao.getRunningJobExecutions() ignores jobName</summary>
			<description>JdbcJobExecutionDao.getRunningJobExecutions() ignores jobName</description>
			<version>2.0.0.M4</version>
			<fixedVersion>2.0.0.RC1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.repository.dao.AbstractStepExecutionDaoTests.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcJobExecutionDaoTests.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcJobExecutionDao.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.MapJobExecutionDaoTests.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.AbstractJobExecutionDaoTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1091" opendate="2009-02-21 01:49:13" fixdate="2009-02-23 10:04:04" resolution="Fixed">
		<buginformation>
			<summary>Add strict flag to file readers (flat and XML).</summary>
			<description>If file reader is lenient about resource existing on startup, it should also check when it is closed.  See forum post: http://forum.springframework.org/showthread.php?t=67490</description>
			<version>2.0.0.M3</version>
			<fixedVersion>2.0.0.RC2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReaderTests.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemReader.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReader.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemReaderTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1107" opendate="2009-02-27 21:50:48" fixdate="2009-02-27 21:59:07" resolution="Fixed">
		<buginformation>
			<summary>Fix Date conversion in PlaceholderTargetSource</summary>
			<description>Spring doesn&amp;amp;apos;t do type conversion to String very well, and for Date not at all.  This leads to problems for placeholders of type Date.  There are two issues in the current implementation:
  &amp;lt;property name="foo" value="#
{jobParameters[runDate]}
"/&amp;gt;
fails even if the "foo" property is of type Date because the String conversion is attempted too early; and 
  &amp;lt;property name="query" value="select ... where start_date &amp;gt; &amp;amp;apos;#
{jobParameters}
&amp;amp;apos;"/&amp;gt;
fails because the placeholder is embedded in a literal and needs to be converted to String (which Spring doesn&amp;amp;apos;t do natively).</description>
			<version>2.0.0.M3</version>
			<fixedVersion>2.0.0.RC2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.scope.util.PlaceholderTargetSourceTests.java</file>
			<file type="M">org.springframework.batch.core.scope.util.PlaceholderTargetSource.java</file>
		</fixedFiles>
	</bug>
	<bug id="1106" opendate="2009-02-26 06:20:40" fixdate="2009-02-27 22:03:10" resolution="Fixed">
		<buginformation>
			<summary>SqlPagingQueryProviderFactoryBean ascending should default to true</summary>
			<description>Kind of a minor issue, though it did cause me a lot of grief.  On switching to RC1 and updating my previous SimpleDelegatingPagingQueryProvider beans to use the new SqlPagingQueryProviderFactoryBean, I got was no longer getting anything past the first page of results because it was suddenly ordering &amp;amp;apos;DESC&amp;amp;apos; instead of &amp;amp;apos;ASC&amp;amp;apos;.  Even though the ascending property defaults to true in the actual query providers, the factory bean is explicitly setting the property every time and it defaults to false there.</description>
			<version>2.0.0.RC1</version>
			<fixedVersion>2.0.0.RC2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.mapping.PrefixMatchingCompositeLineMapper.java</file>
			<file type="M">org.springframework.batch.item.database.support.SqlPagingQueryProviderFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.support.PatternMatcherTests.java</file>
			<file type="M">org.springframework.batch.support.PatternMatcher.java</file>
			<file type="M">org.springframework.batch.item.file.mapping.PrefixMatchingCompositeLineMapperTests.java</file>
			<file type="M">org.springframework.batch.item.database.support.SqlPagingQueryProviderFactoryBean.java</file>
			<file type="M">org.springframework.batch.item.file.transform.PrefixMatchingCompositeLineTokenizer.java</file>
		</fixedFiles>
	</bug>
	<bug id="1111" opendate="2009-03-02 03:18:35" fixdate="2009-03-02 03:44:54" resolution="Fixed">
		<buginformation>
			<summary>ChunkListener called before WriteListener</summary>
			<description>ChunkListener called before WriteListener:  http://forum.springframework.org/showthread.php?t=68280</description>
			<version>2.0.0.RC1</version>
			<fixedVersion>2.0.0.RC2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.SimpleStepFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.step.tasklet.TaskletStep.java</file>
			<file type="M">org.springframework.batch.core.step.item.BatchListenerFactoryHelper.java</file>
			<file type="M">org.springframework.batch.core.step.item.SimpleStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.step.AbstractStep.java</file>
		</fixedFiles>
	</bug>
	<bug id="1113" opendate="2009-03-02 10:05:02" fixdate="2009-03-02 17:50:55" resolution="Fixed">
		<buginformation>
			<summary>query for JdbcJobExecutionDao.findRunningJobExecutions is broken</summary>
			<description>JdbcJobExecutionDao.findRunningJobExecutions fails due to ambiguous columns in sql select statement.
The method makes the following call:
getJdbcTemplate().getJdbcOperations().query(getQuery(GET_RUNNING_EXECUTIONS), new Object[] 
{ jobName }
, handler);
where GET_RUNNING_EXECUTIONS is defined as:
private static final String GET_RUNNING_EXECUTIONS = "SELECT JOB_EXECUTION_ID, START_TIME, END_TIME, STATUS, EXIT_CODE, EXIT_MESSAGE, CREATE_TIME, LAST_UPDATED, VERSION, "
   + "JOB_INSTANCE_ID from %PREFIX%JOB_EXECUTION E, %PREFIX%JOB_INSTANCE I where E.JOB_INSTANCE_ID=I.JOB_INSTANCE_ID and I.JOB_NAME=? and E.END_TIME is NULL order by E.JOB_EXECUTION_ID desc";
Relevant stack trace:
Caused by: org.springframework.dao.DataIntegrityViolationException: PreparedStatementCallback; SQL [SELECT JOB_EXECUTION_ID, START_TIME, END_TIME, STATUS, EXIT_CODE, EXIT_MESSAGE, CREATE_TIME, LAST_UPDATED, VERSION, JOB_INSTANCE_ID from BATCH_JOB_EXECUTION E, BATCH_JOB_INSTANCE I where E.JOB_INSTANCE_ID=I.JOB_INSTANCE_ID and I.JOB_NAME=? and E.END_TIME is NULL order by E.JOB_EXECUTION_ID desc]; Column &amp;amp;apos;VERSION&amp;amp;apos; in field list is ambiguous; nested exception is com.mysql.jdbc.exceptions.MySQLIntegrityConstraintViolationException: Column &amp;amp;apos;VERSION&amp;amp;apos; in field list is ambiguous
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.translate(SQLStateSQLExceptionTranslator.java:114)
	at org.springframework.jdbc.support.SQLErrorCodeSQLExceptionTranslator.translate(SQLErrorCodeSQLExceptionTranslator.java:322)
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:607)
	at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:641)
	at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:670)
	at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:686)
	at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:694)
	at org.springframework.batch.core.repository.dao.JdbcJobExecutionDao.findRunningJobExecutions(JdbcJobExecutionDao.java:268)
	at org.springframework.batch.core.explore.support.SimpleJobExplorer.findRunningJobExecutions(SimpleJobExplorer.java:82)
While VERSION is the only column indicated as ambiguous in the stack trace, there are other ambiguous columns as well.</description>
			<version>2.0.0.RC1</version>
			<fixedVersion>2.0.0.RC2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcJobExecutionDao.java</file>
		</fixedFiles>
	</bug>
	<bug id="1112" opendate="2009-03-02 08:37:30" fixdate="2009-03-03 00:28:26" resolution="Fixed">
		<buginformation>
			<summary>Remove cycle in infrastructure database/support</summary>
			<description>Remove cycle in infrastructure database/support</description>
			<version>2.0.0.RC1</version>
			<fixedVersion>2.0.0.RC2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.JdbcBatchItemWriter.java</file>
			<file type="M">org.springframework.batch.item.database.support.AbstractSqlPagingQueryProvider.java</file>
			<file type="D">org.springframework.batch.item.database.support.JdbcParameterUtilsTests.java</file>
			<file type="D">org.springframework.batch.item.database.support.JdbcParameterUtils.java</file>
		</fixedFiles>
	</bug>
	<bug id="1122" opendate="2009-03-05 19:19:25" fixdate="2009-03-05 20:13:33" resolution="Fixed">
		<buginformation>
			<summary>StaxEventWriter.startDocument() needs to be protected</summary>
			<description>The method startDocument() in org.springframework.batch.item.xml.StaxEventWriter is private, whereas its javadoc mentions "[...]If this is not sufficient for you, simply override this method."
This prevents one to cleanly override the creation of the root tag.
The simple fix is to make the method protected, as is endDocument().</description>
			<version>1.1.4</version>
			<fixedVersion>1.1.Maintenance, 2.0.0.RC2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemWriter.java</file>
		</fixedFiles>
	</bug>
	<bug id="1119" opendate="2009-03-05 10:12:31" fixdate="2009-03-06 01:29:32" resolution="Fixed">
		<buginformation>
			<summary>afterWrite() will only be called if an exception is raised during throttling</summary>
			<description>If a chunk fails during write() then the recovery procedure will kick in.  But if all of the items pass during throttling, then no exception will be raised to try the chunk again.  Thus, the afterWrite() method will never be called because that method is only called by SimpleChunkProcessor.doWrite().</description>
			<version>2.0.0.RC1</version>
			<fixedVersion>2.0.0.RC2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantChunkProcessorTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantChunkProcessor.java</file>
			<file type="M">org.springframework.batch.core.step.item.SimpleChunkProcessor.java</file>
		</fixedFiles>
	</bug>
	<bug id="1123" opendate="2009-03-06 01:51:14" fixdate="2009-03-06 02:08:27" resolution="Fixed">
		<buginformation>
			<summary>ExecutionContextPromotionListener may perform promotion multiple times</summary>
			<description>The ExecutionContextPromotionListener  currently performs the promotion for every matched pattern.  Instead, it should break out of the loop after finding a match.  </description>
			<version>2.0.0.RC1</version>
			<fixedVersion>2.0.0.RC2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.listener.ExecutionContextPromotionListener.java</file>
		</fixedFiles>
	</bug>
	<bug id="1124" opendate="2009-03-06 08:51:26" fixdate="2009-03-06 09:03:21" resolution="Fixed">
		<buginformation>
			<summary>Fix error message that occurs when the same annotation is used twice on one method</summary>
			<description>MethodInvokerUtils.getMethodInvokerByAnnotation() checks to make sure that the same annotation does not appear more than once on a single class.  If a duplicate is found, then an error such as the following is thrown:
java.lang.IllegalArgumentException: found more than one method on target class [org.springframework.batch.sample.domain.trade.internal.TradeWriter@178dc08] with the annotation type [org.springframework.batch.sample.domain.trade.internal.TradeWriter@178dc08]
The error should be:
java.lang.IllegalArgumentException: found more than one method on target class [TradeWriter] with the annotation type [AfterWrite]</description>
			<version>2.0.0.RC1</version>
			<fixedVersion>2.0.0.RC2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.support.MethodInvokerUtils.java</file>
		</fixedFiles>
	</bug>
	<bug id="1125" opendate="2009-03-06 09:25:06" fixdate="2009-03-06 10:08:46" resolution="Fixed">
		<buginformation>
			<summary>NoWorkFoundStepExecutionListener doesn&amp;apos;t fail the step</summary>
			<description>The NoWorkFoundStepExecutionListener throws an exception from an AfterStep method.  However, throwing an exception from an AfterStep only results in the exception being logged and has no impact on the status of the step.  Instead, the AfterStep method should return ExitStatus.FAILED.</description>
			<version>2.0.0.RC1</version>
			<fixedVersion>2.0.0.RC2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.NoWorkFoundStepExecutionListenerTests.java</file>
			<file type="M">org.springframework.batch.core.step.NoWorkFoundStepExecutionListener.java</file>
			<file type="D">org.springframework.batch.item.NoWorkFoundException.java</file>
			<file type="M">org.springframework.batch.item.file.MultiResourceItemReader.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.sample.common.InfiniteLoopReader.java</file>
		</fixedFiles>
	</bug>
	<bug id="1128" opendate="2009-03-08 14:28:52" fixdate="2009-03-09 04:35:11" resolution="Fixed">
		<buginformation>
			<summary>Make sure WRITE_COUNT and ROLLBACK_COUNT are being updated correctly</summary>
			<description>From a forum post:
Using FlatFileItemReader and loading the records into database.  File has 55 records and 55th record is skipped. Commit interval is 100.
Results in:
    READ_COUNT: 55
    WRITE_COUNT: 108
    WRITE_SKIP_COUNT: 1
    ROLLBACK_COUNT: 2
    COMMIT_COUNT: 1
Database was correctly loaded with 54 records. But WRITE_COUNT and ROLLBACK_COUNT are misleading.</description>
			<version>2.0.0.RC1</version>
			<fixedVersion>2.0.0.RC2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.sample.SkipSampleFunctionalTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantChunkProcessor.java</file>
		</fixedFiles>
	</bug>
	<bug id="1130" opendate="2009-03-10 02:27:03" fixdate="2009-03-10 02:41:38" resolution="Fixed">
		<buginformation>
			<summary>Ensure Ordered is respected by generated listeners</summary>
			<description></description>
			<version>2.0.0.RC1</version>
			<fixedVersion>2.0.0.RC2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.listener.JobListenerFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.listener.JobListenerFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.listener.StepListenerFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.listener.StepListenerFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.listener.MethodInvokerMethodInterceptor.java</file>
		</fixedFiles>
	</bug>
	<bug id="1143" opendate="2009-03-12 16:48:55" fixdate="2009-03-12 17:54:35" resolution="Fixed">
		<buginformation>
			<summary>Standalone &lt;step/&gt; should not be allowed to have "tasklet" attribute and &lt;tasklet/&gt; together</summary>
			<description>Standalone &amp;lt;step/&amp;gt; should not be allowed to have "tasklet" attribute and &amp;lt;tasklet/&amp;gt; together.  There is logic to check for this on an inline step, but not a standalone.</description>
			<version>2.0.0.RC1</version>
			<fixedVersion>2.0.0.RC2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.AbstractStepParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.InlineStepParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.StandaloneStepParser.java</file>
		</fixedFiles>
	</bug>
	<bug id="1147" opendate="2009-03-13 01:28:49" fixdate="2009-03-13 06:00:09" resolution="Fixed">
		<buginformation>
			<summary>StepExecution getFilterCount always return 0</summary>
			<description>We use a Step FaultTolerantStepFactoryBean
with an ItemProcessor
We do a JUnit Test in 2.0.0 CI Snapshot
and setup the test to have the ItemProcessor return null
the assert says that getFilterCount == 1 is true
After move to 2.0.0 RC1 core SpringBatch the assert is false
because getFilterCount() return 0
In all the other Junit Test getFilterCount() method return always 0.
Can you explain if it is a bug or another way to configure FaultTolerantStepFactoryBean ?
</description>
			<version>2.0.0.RC1</version>
			<fixedVersion>2.0.0.RC2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.sample.domain.trade.CustomerUpdateFieldSetMapper.java</file>
			<file type="M">org.springframework.batch.core.step.item.SimpleChunkProcessor.java</file>
			<file type="M">org.springframework.batch.core.step.item.SimpleChunkProcessorTests.java</file>
			<file type="M">org.springframework.batch.sample.CustomerFilterJobFunctionalTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1131" opendate="2009-03-10 03:49:45" fixdate="2009-03-13 10:39:37" resolution="Fixed">
		<buginformation>
			<summary>It is not possible to set transaction-attributes for a tasklet step</summary>
			<description>When creating a chunk-oriented step, a "transaction-attribute"  can be configured on the &amp;lt;tasklet/&amp;gt; element.  However, since tasklet steps do not use the &amp;lt;tasklet/&amp;gt; element (they use the &amp;amp;apos;tasklet&amp;amp;apos; attribute) there is no place to configure a transaction-attribute.  If the user must use Spring&amp;amp;apos;s "tx" namespace and provide transaction advice, then this should be mentioned in the documentation.</description>
			<version>2.0.0.RC1</version>
			<fixedVersion>2.0.0.RC2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParserTests.java</file>
			<file type="M">org.springframework.batch.core.step.tasklet.TaskletStep.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.TaskletElementParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.AbstractStepParser.java</file>
			<file type="M">org.springframework.batch.core.step.item.SimpleStepFactoryBean.java</file>
		</fixedFiles>
	</bug>
	<bug id="1145" opendate="2009-03-12 19:47:56" fixdate="2009-03-13 20:38:50" resolution="Fixed">
		<buginformation>
			<summary>Conflicts if both &lt;step/&gt; and &lt;tasklet/&gt; have a "parent" attribute</summary>
			<description>Both &amp;lt;step/&amp;gt; and &amp;lt;tasklet/&amp;gt; affect the step factory bean  If both elements have a "parent" attribute, then one will override the other, causing the first to be ignored.  A solution must be found that allows two parents to be specified. </description>
			<version>2.0.0.RC1</version>
			<fixedVersion>2.0.0.RC2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.TaskletElementParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.StandaloneStepParser.java</file>
			<file type="D">org.springframework.batch.core.configuration.xml.TopLevelTaskletElementParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.AbstractStepParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.CoreNamespaceHandler.java</file>
		</fixedFiles>
	</bug>
	<bug id="1146" opendate="2009-03-12 20:07:20" fixdate="2009-03-13 21:11:12" resolution="Fixed">
		<buginformation>
			<summary>Use MD5 for JobParameters key in JdbcJobInstanceDao</summary>
			<description>Use MD5 for JobParameters key in JdbcJobInstanceDao</description>
			<version>2.0.0.RC1</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcJobInstanceDaoTests.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcJobInstanceDao.java</file>
		</fixedFiles>
		<links>
			<link type="Depends" description="is depended on by">1090</link>
			<link type="Related" description="is related to">1090</link>
		</links>
	</bug>
	<bug id="1155" opendate="2009-03-14 04:01:29" fixdate="2009-03-14 04:08:33" resolution="Fixed">
		<buginformation>
			<summary>Cycle in reader package (FFIR and DefaultLineMapper)</summary>
			<description></description>
			<version>2.0.0.RC1</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReaderCommonTests.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReader.java</file>
			<file type="M">org.springframework.batch.item.file.mapping.PatternMatchingCompositeLineMapper.java</file>
			<file type="M">org.springframework.batch.item.file.MultiResourceItemReaderFlatFileTests.java</file>
			<file type="D">org.springframework.batch.item.file.mapping.LineMapper.java</file>
			<file type="M">org.springframework.batch.item.file.mapping.DefaultLineMapper.java</file>
			<file type="M">org.springframework.batch.item.file.mapping.PassThroughLineMapper.java</file>
		</fixedFiles>
	</bug>
	<bug id="1156" opendate="2009-03-15 04:25:08" fixdate="2009-03-15 07:52:19" resolution="Fixed">
		<buginformation>
			<summary>Possible "null" context return with MapRetryContextCache in RetryTemplate</summary>
			<description>I get a lot of unexpected RetryException that kill my batch. I suppect the use of SoftReference in MapRetryContextCache could be the cause.
The following lines show that the RetryTemplate throws a RetryException if the retryContextCache returns "null" for a given key. 
But MapRetryContextCache uses a map of SofReference (as consequence of BATCH-682), that means the retry context could be deleted by the garbage collector, and the retryContextCache could return "null" even though containsKey() allowed entry in the if block.
381                     else if (retryContextCache.containsKey(key)) {
382 	
383 	                        RetryContext context = retryContextCache.get(key);
384 	                        if (context == null) 
{
385 	                                throw new RetryException("Inconsistent state for failed item: no history found. "
386 	                                                + "Consider whether equals() or hashCode() for the item might be inconsistent, "
387 	                                                + "or if you need to supply a better ItemKeyGenerator");
388 	                        }
389 	                        return context;
390 	
391 	                }</description>
			<version>2.0.0.RC1</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.retry.policy.MapRetryContextCache.java</file>
			<file type="M">org.springframework.batch.retry.support.RetryTemplate.java</file>
			<file type="M">org.springframework.batch.retry.policy.MapRetryContextCacheTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1159" opendate="2009-03-18 02:37:40" fixdate="2009-03-18 04:28:30" resolution="Fixed">
		<buginformation>
			<summary>PROCESS_SKIP_COUNT seems not to ever get written to database</summary>
			<description>Exceptions in readers and writers seems to be handled nicely, but there seems to be a problem throwing skippable exception from processor. StepExecution&amp;amp;apos;s processSkipCount is incremented, skip listeners are called and step listener&amp;amp;apos;s afterStep() gets correct counts in StepExecution has correct counts. But PROCESS_SKIP_COUNT is never incremented in database - allways 0. Sometimes even filterCount is incremented in StepExecution instead of processSkipCount. I tried to debug through sources but got pretty lost I&amp;amp;apos;ve checked that HibernateTemplate.flush() is called everytime in the writer. 
This is part of our parent step configuration (FaultTolerantStepFactoryBean) used for all batches (i believe there should be no problem)
		&amp;lt;property name="retryableExceptionClasses"&amp;gt;
			&amp;lt;list&amp;gt;
				&amp;lt;value&amp;gt;org.springframework.dao.RecoverableDataAccessException&amp;lt;/value&amp;gt;
				&amp;lt;value&amp;gt;org.springframework.dao.TransientDataAccessException&amp;lt;/value&amp;gt;
			&amp;lt;/list&amp;gt;
		&amp;lt;/property&amp;gt;
		&amp;lt;property name="skippableExceptionClasses" value="java.lang.Exception" /&amp;gt;
		&amp;lt;property name="fatalExceptionClasses"&amp;gt;
			&amp;lt;list&amp;gt;
				&amp;lt;value&amp;gt;cz.mycompany.FatalProcessingException&amp;lt;/value&amp;gt;
				&amp;lt;value&amp;gt;org.springframework.batch.core.JobInterruptedException&amp;lt;/value&amp;gt;
			&amp;lt;/list&amp;gt;
		&amp;lt;/property&amp;gt;
Problem appeared to be there quite some time. Previously we used 2.0.0.M2 and it was already there.</description>
			<version>2.0.0.RC1</version>
			<fixedVersion>2.0.0.RC2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.repository.dao.AbstractStepExecutionDaoTests.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcStepExecutionDao.java</file>
		</fixedFiles>
	</bug>
	<bug id="1160" opendate="2009-03-19 15:17:18" fixdate="2009-03-19 18:38:54" resolution="Fixed">
		<buginformation>
			<summary>In Batch xsd, stepType and flowStepType should be unordered</summary>
			<description>In Batch xsd, stepType and flwoStepType should be unordered.</description>
			<version>2.0.0.RC1</version>
			<fixedVersion>2.0.0.RC2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.SplitParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.AbstractStepParser.java</file>
		</fixedFiles>
	</bug>
	<bug id="1129" opendate="2009-03-09 16:08:32" fixdate="2009-03-19 23:04:49" resolution="Fixed">
		<buginformation>
			<summary>Problems with exception classifications</summary>
			<description>Transaction attributes of the following form don&amp;amp;apos;t seem to be preventing rollback:
    transaction-attribute="+org.springframework.dao.DataIntegrityViolationException"
It does, however, seem to be causing the job to fail.   ie, it&amp;amp;apos;s treated as a fatal exception and prevents skipping.
Furthermore, all exceptions seem to be skippable by default, whereas they should be fatal unless specifically configured to be skippable.
There are some complications listed in BATCH-859, so if those complications make these scenarios impossible, that needs to be documented.  
See http://static.springframework.org/spring-batch/reference/html/configureStep.html#d0e2594.</description>
			<version>2.0.0.RC1</version>
			<fixedVersion>2.0.0.RC2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.TaskletElementParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.AbstractStepParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.JobParser.java</file>
			<file type="M">org.springframework.batch.core.step.tasklet.TaskletStepTests.java</file>
			<file type="M">org.springframework.batch.core.step.skip.LimitCheckingItemSkipPolicy.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParserStepFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.StepWithFaultTolerantProcessTaskJobParserTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.SimpleStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParserTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParserStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.step.tasklet.TaskletStep.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantChunkProcessor.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.JobRepositoryParser.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantChunkProcessorTests.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReader.java</file>
			<file type="M">org.springframework.batch.core.step.skip.NonSkippableReadException.java</file>
			<file type="M">org.springframework.batch.core.step.skip.SkipLimitExceededException.java</file>
		</fixedFiles>
	</bug>
	<bug id="1165" opendate="2009-03-20 03:10:54" fixdate="2009-03-20 03:37:00" resolution="Fixed">
		<buginformation>
			<summary>Allow &amp;apos;id&amp;apos; and &amp;apos;ref&amp;apos; to exist together on &lt;*-listener/&gt;</summary>
			<description>Allow &amp;amp;apos;id&amp;amp;apos; and &amp;amp;apos;ref&amp;amp;apos; to exist together on &amp;lt;*-listener/&amp;gt;</description>
			<version>2.0.0.RC1</version>
			<fixedVersion>2.0.0.RC2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParserTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.AbstractListenerParser.java</file>
		</fixedFiles>
	</bug>
	<bug id="1164" opendate="2009-03-20 03:01:46" fixdate="2009-03-20 04:49:22" resolution="Fixed">
		<buginformation>
			<summary>Putting scope="step" on a listener causes failure</summary>
			<description>The configuration below fails because the framework is unable to set properties onto the StepListenerFactoryBean:
  &amp;lt;step-listener id="l2" ref="myListener"/&amp;gt;
  &amp;lt;beans:bean id="myListener" class="MyListener" scope="step"&amp;gt;
      &amp;lt;beans:property name="runId" value="#
{jobParameters[my.param]}
"/&amp;gt;
  &amp;lt;/beans:bean&amp;gt;
</description>
			<version>2.0.0.RC1</version>
			<fixedVersion>2.0.0.RC2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.support.MethodInvokerUtils.java</file>
			<file type="M">org.springframework.batch.core.listener.StepListenerMethodInterceptorTests.java</file>
			<file type="M">org.springframework.batch.core.listener.AbstractListenerFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.scope.util.StepContextFactory.java</file>
		</fixedFiles>
	</bug>
	<bug id="1171" opendate="2009-03-22 21:58:02" fixdate="2009-03-22 22:53:17" resolution="Fixed">
		<buginformation>
			<summary>Interrupted step does not fail job.</summary>
			<description>Interrupted step does not fail job.  This has to be wrong otherwise you can&amp;amp;apos;t restart it.</description>
			<version>2.0.0.RC2</version>
			<fixedVersion>2.0.0.RC3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.job.flow.FlowJobTests.java</file>
			<file type="M">org.springframework.batch.core.job.AbstractJob.java</file>
			<file type="M">org.springframework.batch.core.job.SimpleJobTests.java</file>
			<file type="M">org.springframework.batch.sample.launch.RemoteLauncherTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1174" opendate="2009-03-24 02:56:19" fixdate="2009-03-24 21:15:19" resolution="Fixed">
		<buginformation>
			<summary>Late binding of jobParameters does not work if late binding expression is not preceded or trailed by string</summary>
			<description>I stumbled upon some strange behavior when using late binding. I&amp;amp;apos;m trying to inject a string that is passed to the batch as a jobParameter. This string is however not inject, if I don&amp;amp;apos;t add a character in front-  of or after the late binding expression.
To replicate this bug try to do the following:
in the restartSample.xml change the flatFileItemReader&amp;amp;apos;s resource from:
&amp;lt;beans:property name="resource" value="classpath:/data/skipJob/input/input#
{jobParameters[run.id]}.txt" /&amp;gt;
to
&amp;lt;beans:property name="resource" value="#{jobParameters[run.id]}
" /&amp;gt;
This results in the following exception:
 java.lang.IllegalStateException: Input resource must exist (reader is in &amp;amp;apos;strict&amp;amp;apos; mode): class path resource [#
{jobParameters[run.id]}]

If you add a character at the end (or the front), like this:
&amp;lt;beans:property name="resource" value="a#{jobParameters[run.id]}
" /&amp;gt;
The following exception is thrown:
java.lang.IllegalStateException: Input resource must exist (reader is in &amp;amp;apos;strict&amp;amp;apos; mode): class path resource [a1]
(This makes sense, as there is no such classpath resource, and the jobParameter run.id which is &amp;amp;apos;1&amp;amp;apos; has been set.)
So, it seems that the late binding of jobParameters does not work if the jobParameter key is concatenated with some other string value...strange. Even stranger, it does not seem to be the case for late binding of stepExecutionContext parameters.
Wasn&amp;amp;apos;t able to locate the code that did the actual late binding, so I&amp;amp;apos;m afraid I don&amp;amp;apos;t have patch ready that you can apply.
</description>
			<version>2.0.0.RC2</version>
			<fixedVersion>2.0.0.RC3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.sample.RestartFunctionalTests.java</file>
			<file type="M">org.springframework.batch.core.scope.util.PlaceholderTargetSource.java</file>
		</fixedFiles>
	</bug>
	<bug id="1178" opendate="2009-03-25 03:11:31" fixdate="2009-03-25 04:05:53" resolution="Fixed">
		<buginformation>
			<summary>&lt;step/&gt; with "ref=" silently ignores other attributes</summary>
			<description>If the InlineStepParser finds a "ref=" attribute on the &amp;lt;step/&amp;gt;, it will ignore all other attributes.  Instead, it should be throwing errors if any other attributes are defined.</description>
			<version>2.0.0.RC2</version>
			<fixedVersion>2.0.0.RC3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.InlineStepParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.FlowParser.java</file>
		</fixedFiles>
		<links>
			<link type="Supersede" description="is superseded by">1179</link>
		</links>
	</bug>
	<bug id="1180" opendate="2009-03-25 05:53:14" fixdate="2009-03-25 06:13:55" resolution="Fixed">
		<buginformation>
			<summary>Error occurs if parent= attribute appears on inline &lt;step/&gt; without tasket</summary>
			<description>An error occurs if the parent= attribute appears on an inline &amp;lt;step/&amp;gt; without tasket= or &amp;lt;tasklet/&amp;gt; because no BeanDefinition is returned from AbstractStepParser.parseTasklet().  
Update parseTasklet() so that a BeanDefinition (even an empty one) is always returned.  This will simplify the step parser hierarchy a bit too because calling methods will no longer have to check whether a BeanDefinition was returned or not.</description>
			<version>2.0.0.RC2</version>
			<fixedVersion>2.0.0.RC3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.TopLevelStepParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.StopRestartOnCompletedStepJobParserTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.TopLevelStepListenerParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.StandaloneStepParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.InlineStepParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.AbstractStepParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.TopLevelJobListenerParser.java</file>
		</fixedFiles>
	</bug>
	<bug id="1181" opendate="2009-03-25 16:39:50" fixdate="2009-03-29 16:15:12" resolution="Fixed">
		<buginformation>
			<summary>&lt;step/&gt; element always assumes the step is a TaskletStep</summary>
			<description>The namespace&amp;amp;apos;s &amp;lt;step/&amp;gt; element always assumes it is creating a TaskletStep so it tries to set properties such as transactionManager and jobRepository.  However, the &amp;lt;step/&amp;gt; should be flexible enough to handle any implementation of Step so that if a user defines their own Step they can use it with the namespace to construct a FlowJob.
In order to resolve this issue, properties need to be removed from the &amp;lt;step/&amp;gt; element and moved to an inner element.  The new &amp;lt;step/&amp;gt; structure will be as follows:
&amp;lt;step&amp;gt;
    &amp;lt;tasklet&amp;gt;
        &amp;lt;chunk-tasklet/&amp;gt;
    &amp;lt;/tasklet&amp;gt;
&amp;lt;/step&amp;gt;
Where:
The &amp;lt;chunk-tasklet/&amp;gt; is the new name of what used to be &amp;lt;tasklet/&amp;gt;.  It is used to create a Chunk-Oriented TaskletStep.
The new &amp;lt;tasklet/&amp;gt; contains the properties that used to be on &amp;lt;step/&amp;gt;.  It is used to create a TaskletStep and it has a ref= that can reference a Tasklet implementation.
The &amp;lt;step/&amp;gt; contains only id=, parent=, abstract=, and flow transitions.  It can be used with any Step implementation.</description>
			<version>2.0.0.RC2</version>
			<fixedVersion>2.0.0.RC3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParserTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParserStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.ChunkElementParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParserStepFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.AbstractStepParser.java</file>
			<file type="D">org.springframework.batch.core.configuration.xml.ChunkTaskletParser.java</file>
			<file type="D">org.springframework.batch.core.configuration.xml.ChunkTaskletParserTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.JobParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.StandaloneStepParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.InlineStepParser.java</file>
			<file type="D">org.springframework.batch.core.configuration.xml.TaskletElementParser.java</file>
			<file type="D">org.springframework.batch.core.configuration.xml.TaskletElementParserTests.java</file>
		</fixedFiles>
		<links>
			<link type="Related" description="is related to">1179</link>
		</links>
	</bug>
	<bug id="1185" opendate="2009-03-30 08:25:02" fixdate="2009-04-06 01:37:17" resolution="Fixed">
		<buginformation>
			<summary>Job slows when step scope is used</summary>
			<description>When scope="step" appears on a flat file item reader, the job takes longer.
In the football job, if player.file.name=player.csv, the job takes 15 seconds.  If scope="step" is added to playerFileItemReader, the job takes 26 seconds.</description>
			<version>2.0.0.RC2</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.ResourceAwareItemReaderItemStream.java</file>
			<file type="M">org.springframework.batch.core.scope.util.PlaceholderTargetSource.java</file>
			<file type="M">org.springframework.batch.core.scope.util.PlaceholderProxyFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.scope.StepScope.java</file>
		</fixedFiles>
	</bug>
	<bug id="1197" opendate="2009-04-06 19:36:08" fixdate="2009-04-06 20:04:55" resolution="Fixed">
		<buginformation>
			<summary>Rerunning a job sometimes creates new job instance</summary>
			<description>An attempt to rerun stopped job using following code sometimes leads to creation of new JobInstance with same JOB_KEY but with entries in different order.
List&amp;lt;JobInstance&amp;gt; jobInstances = jobExplorer.getJobInstances(jobName, 0, 1);
if (!jobInstances.isEmpty()) {
    jobLauncher.run(job, jobInstances.get(0).getJobParameters());
}
I tried to debug it and I think the problem may be in JdbcJobInstanceDao.FIND_PARAMS_FROM_ID used in getJobParameters(). This query relies on the fact that job parameters are retrieved from database in same order as they have been inserted - which does not have to be true. Maybe ordering by job parameter name would help. Maybe it would be best to add this behavior to the JobParameters instead of relying on LinkedHashMap and insert order.</description>
			<version>2.0.0.RC3</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcJobInstanceDaoTests.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcJobInstanceDao.java</file>
		</fixedFiles>
	</bug>
	<bug id="1198" opendate="2009-04-06 22:17:11" fixdate="2009-04-07 00:00:54" resolution="Fixed">
		<buginformation>
			<summary>processSkipCount and filterCount mixed up</summary>
			<description>There is another issue around process phase. Skips are sometimes counted as filtered items. And there is also pretty strange filter count behaviour: i&amp;amp;apos;ve got a file with 10 items. All get processed,  everything is ok. If I fiddle with one of the records so that processor throws exception. I get 9 written, 1 skipped and 1 filtered. When there are two invalid items, i get 8 written, 2 skipped and 1 filtered too... sometimes filter counter shows more filtered items ... by counter i mean the one in StepExecution instance that is passed to afterStep() method. I believe my skippable/fatal/retriable exceptions are configured correctly (see BATCH-1159). </description>
			<version>2.0.0.RC3</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantChunkProcessorTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.SimpleChunkProcessor.java</file>
		</fixedFiles>
	</bug>
	<bug id="1196" opendate="2009-04-06 08:01:05" fixdate="2009-04-07 02:12:13" resolution="Fixed">
		<buginformation>
			<summary>ExecutionContext not re-hydrated by JdbcJobExecutionDao</summary>
			<description>ExecutionContext not re-hydrated by JdbcJobExecutionDao</description>
			<version>2.0.0.RC2</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.exlore.support.SimpleJobExplorerTests.java</file>
			<file type="M">org.springframework.batch.core.explore.support.JobExplorerFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.explore.support.MapJobExplorerFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.explore.support.SimpleJobExplorer.java</file>
			<file type="M">org.springframework.batch.core.explore.support.AbstractJobExplorerFactoryBean.java</file>
		</fixedFiles>
	</bug>
	<bug id="1201" opendate="2009-04-08 02:07:49" fixdate="2009-04-08 03:47:25" resolution="Fixed">
		<buginformation>
			<summary>Listener Annotations don&amp;apos;t allow parameters to be subtypes of expected types</summary>
			<description>Listener Annotations don&amp;amp;apos;t allow parameters to be subtypes of expected types.  For example, consider the AfterProcess method.  Its enum value in StepListenerMetaData is defined as: 
AFTER_PROCESS("afterProcess", "after-process-method", AfterProcess.class, ItemProcessListener.class, Object.class, Object.class).
showing that it expects two Objects as parameters.  However, if the method is defined with subtypes of Object as its parameters, then an error is shown indicating the the signature is incompatible with what is expected:
@AfterProcess
public void afterProcess(String item, String result){ }</description>
			<version>2.0.0.RC3</version>
			<fixedVersion>2.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.support.MethodInvokerUtils.java</file>
			<file type="M">org.springframework.batch.core.listener.StepListenerFactoryBeanTests.java</file>
		</fixedFiles>
		<links>
			<link type="Related" description="is related to">1118</link>
		</links>
	</bug>
	<bug id="1172" opendate="2009-03-23 02:56:56" fixdate="2009-04-12 22:53:56" resolution="Fixed">
		<buginformation>
			<summary>Register RangeArrayPropertyEditor automatically</summary>
			<description>RangeArrayPropertyEditor could be registered automatically when someone use the new namespace configuration.</description>
			<version>2.0.0.RC2</version>
			<fixedVersion>2.0.1</fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.CoreNamespaceUtils.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.TopLevelStepParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.JobParser.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">1214</link>
		</links>
	</bug>
	<bug id="1205" opendate="2009-04-14 02:54:50" fixdate="2009-04-14 03:50:34" resolution="Duplicate">
		<buginformation>
			<summary>When readCount % commitInterval == 0, commitCount is one more than it should be</summary>
			<description>When readCount % commitInterval == 0, commitCount is one more than it should be.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.tasklet.TaskletStepTests.java</file>
		</fixedFiles>
		<links>
			<link type="Related" description="is related to">922</link>
		</links>
	</bug>
	<bug id="1210" opendate="2009-04-15 22:05:35" fixdate="2009-04-15 22:11:41" resolution="Fixed">
		<buginformation>
			<summary>AbstractStep overwrites custom exit status for STOPPED steps</summary>
			<description>AbstractStep overwrites custom exit status for STOPPED steps.  It should and() the result with the default value (like it does for FAILED).</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.TaskletStepExceptionTests.java</file>
			<file type="M">org.springframework.batch.core.step.AbstractStep.java</file>
			<file type="D">org.springframework.batch.core.step.AbstractStepTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1214" opendate="2009-04-22 02:58:23" fixdate="2009-04-29 01:31:56" resolution="Fixed">
		<buginformation>
			<summary>CoreNamespaceUtils.addRangePropertyEditor fails with Spring 3.0</summary>
			<description>I&amp;amp;apos;m trying to use Spring Batch 2.0 with a recent Spring 3.0 build and I see the following exception when using the namespace support (only root cause shown):
Caused by: java.lang.IllegalArgumentException: Cannot convert value of type [java.lang.Class] to required type [java.lang.String] for property &amp;amp;apos;customEditors[org.springframework.batch.item.file.transform.Range[]]&amp;amp;apos;: no matching editors or conversion strategy found
	at org.springframework.beans.TypeConverterDelegate.convertIfNecessary(TypeConverterDelegate.java:226)
	at org.springframework.beans.TypeConverterDelegate.convertToTypedMap(TypeConverterDelegate.java:497)
	at org.springframework.beans.TypeConverterDelegate.convertIfNecessary(TypeConverterDelegate.java:188)
	at org.springframework.beans.TypeConverterDelegate.convertIfNecessary(TypeConverterDelegate.java:132)
	at org.springframework.beans.BeanWrapperImpl.convertForProperty(BeanWrapperImpl.java:378)
	... 35 more
This is caused by CoreNamespaceUtils.addRangePropertyEditor: it registers RangeArrayPropertyEditor.class as the value for an entry in the map passed to the customEditors property of CustomEditorConfigurer. This functionality was deprecated in Spring 2.5 and is currently not supported anymore: this should be a class name, not a Class. In this case, that&amp;amp;apos;s enough; we don&amp;amp;apos;t need a custom PropertyEditorRegistrar. Please fix this.
The current workaround is to register the editor yourself, like this:
&amp;lt;bean class="org.springframework.beans.factory.config.CustomEditorConfigurer"&amp;gt;
	&amp;lt;property name="customEditors"&amp;gt;
		&amp;lt;map&amp;gt;
			&amp;lt;entry key="org.springframework.batch.item.file.transform.Range[]" 
				    value="org.springframework.batch.item.file.transform.RangeArrayPropertyEditor"/&amp;gt;
		&amp;lt;/map&amp;gt;
	&amp;lt;/property&amp;gt;
&amp;lt;/bean&amp;gt;</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.CoreNamespaceUtils.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">1172</link>
		</links>
	</bug>
	<bug id="1230" opendate="2009-05-03 18:09:41" fixdate="2009-05-03 22:20:35" resolution="Fixed">
		<buginformation>
			<summary>scope "step" does not work together with Annotation "@BeforeStep"</summary>
			<description>Works both for me, but not together:  
Encountered an error executing the step: class java.lang.IllegalArgumentException: Unable to invoke method: [public void XXXReader.beforeStep(org.springframework.batch.core.StepExecution)] on object: [XXXReader@8b567c] with arguments: [[StepExecution: id=0, name=writeDatasheetXml, status=STARTED, exitStatus=EXECUTING, readCount=0, filterCount=0, writeCount=0 readSkipCount=0, writeSkipCount=0, commitCount=0, rollbackCount=0, exitDescription=]]
java.lang.IllegalArgumentException: Unable to invoke method: [public void XXXReader.beforeStep(org.springframework.batch.core.StepExecution)] on object: [XXXReader@8b567c] with arguments: [[StepExecution: id=0, name=XXX, status=STARTED, exitStatus=EXECUTING, readCount=0, filterCount=0, writeCount=0 readSkipCount=0, writeSkipCount=0, commitCount=0, rollbackCount=0, exitDescription=]]
	at org.springframework.batch.support.SimpleMethodInvoker.invokeMethod(SimpleMethodInvoker.java:97)
	at org.springframework.batch.core.listener.MethodInvokerMethodInterceptor.invoke(MethodInvokerMethodInterceptor.java:68)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:171)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:204)
	at $Proxy18.beforeStep(Unknown Source)
	at org.springframework.batch.core.listener.CompositeStepExecutionListener.beforeStep(CompositeStepExecutionListener.java:76)
	at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:193)
	at org.springframework.batch.core.job.AbstractJob.handleStep(AbstractJob.java:348)
	at org.springframework.batch.core.job.flow.FlowJob.access$100(FlowJob.java:43)
	at org.springframework.batch.core.job.flow.FlowJob$JobFlowExecutor.executeStep(FlowJob.java:137)
	at org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:60)
	at org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:144)
	at org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:124)
	at org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:105)
	at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:250)
	at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:110)
	at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:49)
	at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:105)
	at org.springframework.batch.core.launch.support.CommandLineJobRunner.start(CommandLineJobRunner.java:207)
	at org.springframework.batch.core.launch.support.CommandLineJobRunner.main(CommandLineJobRunner.java:254)
Caused by: java.lang.IllegalArgumentException: object is not an instance of declaring class
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at org.springframework.batch.support.SimpleMethodInvoker.invokeMethod(SimpleMethodInvoker.java:95)
	... 19 more</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.support.SimpleMethodInvoker.java</file>
			<file type="M">org.springframework.batch.core.listener.StepListenerFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.StepListenerParserTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1208" opendate="2009-04-15 04:59:21" fixdate="2009-05-06 02:25:47" resolution="Fixed">
		<buginformation>
			<summary>late-binding not being resolved in &lt;list/&gt;</summary>
			<description>When late-binding is used within a &amp;lt;list/&amp;gt;, the expressions are not being resolved.
&amp;lt;beans:bean class="org.springframework.batch.core.resource.ListPreparedStatementSetter" scope="step"&amp;gt;
    &amp;lt;beans:property name="parameters"&amp;gt;
        &amp;lt;beans:list&amp;gt;
            &amp;lt;beans:value&amp;gt;"#
{jobParameters[id1]}
"&amp;lt;/beans:value&amp;gt;
            &amp;lt;beans:value&amp;gt;"#
{jobParameters[id2]}
"&amp;lt;/beans:value&amp;gt;
   . . .</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.scope.util.PlaceholderTargetSourceTests.java</file>
			<file type="M">org.springframework.batch.core.scope.util.PlaceholderTargetSourceErrorTests.java</file>
			<file type="M">org.springframework.batch.core.resource.ListPreparedStatementSetterTests.java</file>
			<file type="M">org.springframework.batch.core.scope.util.PlaceholderTargetSource.java</file>
		</fixedFiles>
		<links>
			<link type="Supersede" description="supersedes">1207</link>
		</links>
	</bug>
	<bug id="1218" opendate="2009-04-26 18:29:23" fixdate="2009-05-11 21:41:11" resolution="Fixed">
		<buginformation>
			<summary>item streams won&amp;apos;t get registered if ItemStream reader is used with step</summary>
			<description>I tried to use following configuration for a step:
				&amp;lt;bean id="myStep" parent="skipLimitStep"&amp;gt;
					&amp;lt;property name="itemReader" ref="mergingReader" /&amp;gt;
					...
					&amp;lt;property name="streams"&amp;gt;
						&amp;lt;list&amp;gt;
							&amp;lt;ref bean="file321Reader"/&amp;gt;
							&amp;lt;ref bean="file324Reader"/&amp;gt;
							&amp;lt;ref bean="mergingReader" /&amp;gt;
						&amp;lt;/list&amp;gt;
					&amp;lt;/property&amp;gt;
mergingReader merges data from two FlatFileItemReader delegates. This reader needs to be stateful - have to implement ItemStream to allow restart. When the step is started (FaultTolerantStepFactoryBean) it correctly registers those readers but after that it automatically registers mergingReader (as it is reader which implements ItemStream) and replaces the stream definition so that only mergingReader&amp;amp;apos;s open() is called. 
I believe the problem is in FaultTolerantStepFactoryBean.registerStreams() method.
Maybe something like this would help (ChunkMonitor.getItemStream() would have to be implemented):
if (chunkMonitor.getItemStream() != null) {
    composite.register(chunkMonitor.getItemStream());
}
chunkMonitor.setItemStream(composite);
... grr, now i see, this would call the auto-registered reader&amp;amp;apos;s open() method twice, huh, at least I tried 
</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.ChunkMonitorTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.ChunkMonitor.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBeanTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1213" opendate="2009-04-20 12:49:05" fixdate="2009-05-18 11:44:57" resolution="Fixed">
		<buginformation>
			<summary>Defaults in xsd override parent attributes</summary>
			<description>Some attributes in the xsd have defaults.  For example: transactionManager and jobRepository.  However, if a non-default value is set on a parent step, but not re-set on an extending bean, then attribute on the extending bean will be overridden by the default.
Therefore, for elements that allow "parents", defaults should be removed from the xsd and the parser.  The defaulting should happen in the FactoryBean, because it is at this time that the framework can see if the value was ever set.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="D">org.springframework.batch.core.configuration.xml.CoreNamespaceBeanDefinitionUtils.java</file>
			<file type="M">org.springframework.batch.core.step.item.SimpleStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParserStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBeanRetryTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.RepeatOperationsStepFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.CoreNamespacePostProcessor.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParserTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.AbstractStepParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.TopLevelStepParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.SplitParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.JobParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.InlineStepParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.CoreNamespaceUtils.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.FlowParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.JobParserTests.java</file>
			<file type="M">org.springframework.batch.sample.RestartFunctionalTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1225" opendate="2009-05-01 04:33:29" fixdate="2009-05-21 18:35:43" resolution="Fixed">
		<buginformation>
			<summary>FlatFileItemWriter and StaxEventItemWriter do not restart in the right place</summary>
			<description>When writing to an output file using a FlatFileItemWriter, the position in the output file is stored in the executioncontext. This is done in the update() method in FlatFileItemWriter. The position is determined by calling the underlying fileChannel&amp;amp;apos;s position() method.
However, the transaction in which it runs is not yet committed. Therefore, the actual write-to-disk has not been done and the fileChannels position will still be the position after the previous chunk.  On a restart of the job, the output file is opened at the beginning of the last chunk, which then gets overwritten.
Put in other words, the stored position in the output file seems to be running one chunk behind. </description>
			<version>2.0.0</version>
			<fixedVersion>2.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.sample.RestartFileSampleFunctionalTests.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemWriterTests.java</file>
			<file type="M">org.springframework.batch.support.transaction.TransactionAwareBufferedWriter.java</file>
			<file type="M">org.springframework.batch.support.transaction.TransactionAwareBufferedWriterTests.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemWriterTests.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemWriter.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemWriter.java</file>
		</fixedFiles>
	</bug>
	<bug id="1240" opendate="2009-05-12 20:50:40" fixdate="2009-05-22 20:12:57" resolution="Duplicate">
		<buginformation>
			<summary>ItemStream is not registered when defined in step scope</summary>
			<description>configuration:
	&amp;lt;job id="myjob"&amp;gt;
		&amp;lt;step id="importFile" next="createWorkDrivers"&amp;gt;
			&amp;lt;tasklet&amp;gt;
				&amp;lt;chunk reader="fileReader" 
						writer="hibernateWriter"
						task-executor="taskExecutor" 
						commit-interval="10"&amp;gt;
					&amp;lt;streams&amp;gt;
						&amp;lt;stream ref="fileReader" /&amp;gt;
					&amp;lt;/streams&amp;gt;
				&amp;lt;/chunk&amp;gt;
			&amp;lt;/tasklet&amp;gt;
		&amp;lt;/step&amp;gt;
	&amp;lt;/job&amp;gt;
	&amp;lt;beans:bean id="fileReader" scope="step"
				class="org.springframework.batch.item.file.FlatFileItemReader"&amp;gt;
	    &amp;lt;beans:property name="resource" value="#
{jobParameters[file]}
" /&amp;gt;
		&amp;lt;beans:property name="lineMapper"&amp;gt;
			&amp;lt;beans:bean class="my.super.Mapper" /&amp;gt;
		&amp;lt;/beans:property&amp;gt;
	&amp;lt;/beans:bean&amp;gt;
exception:
org.springframework.batch.item.ReaderNotOpenException: Reader must be open before it can be read.
	at org.springframework.batch.item.file.FlatFileItemReader.readLine(FlatFileItemReader.java:195)
	at org.springframework.batch.item.file.FlatFileItemReader.doRead(FlatFileItemReader.java:166)
	at org.springframework.batch.item.support.AbstractItemCountingItemStreamItemReader.read(AbstractItemCountingItemStreamItemReader.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:307)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:182)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:149)
	at org.springframework.aop.support.DelegatingIntroductionInterceptor.doProceed(DelegatingIntroductionInterceptor.java:131)
	at org.springframework.aop.support.DelegatingIntroductionInterceptor.invoke(DelegatingIntroductionInterceptor.java:119)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:171)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:204)
	at $Proxy1.read(Unknown Source)
	at org.springframework.batch.core.step.item.SimpleChunkProvider.doRead(SimpleChunkProvider.java:90)
	at org.springframework.batch.core.step.item.SimpleChunkProvider.read(SimpleChunkProvider.java:127)
	at org.springframework.batch.core.step.item.SimpleChunkProvider$1.doInIteration(SimpleChunkProvider.java:106)
	at org.springframework.batch.repeat.support.RepeatTemplate.getNextResult(RepeatTemplate.java:352)
	at org.springframework.batch.repeat.support.RepeatTemplate.executeInternal(RepeatTemplate.java:212)
	at org.springframework.batch.repeat.support.RepeatTemplate.iterate(RepeatTemplate.java:143)
	at org.springframework.batch.core.step.item.SimpleChunkProvider.provide(SimpleChunkProvider.java:103)
	at org.springframework.batch.core.step.item.ChunkOrientedTasklet.execute(ChunkOrientedTasklet.java:64)
	at org.springframework.batch.core.step.tasklet.TaskletStep$2.doInChunkContext(TaskletStep.java:264)
	at org.springframework.batch.core.scope.context.StepContextRepeatCallback.doInIteration(StepContextRepeatCallback.java:67)
	at org.springframework.batch.repeat.support.TaskExecutorRepeatTemplate$ExecutingRunnable.run(TaskExecutorRepeatTemplate.java:230)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBeanTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1245" opendate="2009-05-19 08:08:06" fixdate="2009-05-25 02:12:33" resolution="Fixed">
		<buginformation>
			<summary>StaxEventItemWriter writes extra end document tag with Woodstox 3.2.9 plus</summary>
			<description>This is a continuation of BATCH-761, which is closed and won&amp;amp;apos;t accept new attachments.  Feel free to close this as won&amp;amp;apos;t fix, but now that Woodstox allows disabling of "auto-closing of unmatched start elements" in versions &amp;gt;= 3.2.9 the attached patch against 1.1.4.RELEASE is my preferred solution to BATCH-761.  With this patch there is no burden on the Spring Batch user that chooses Woodstox &amp;gt;= 3.2.9 as their StAX implementation to override Spring Batch API, or even be aware that this issue ever existed.
Again apologies for the lack of a test case, but my plan is to flesh that out by taking a stab at BATCH-981 when we get a chance to migrate to 2.0.  For what it&amp;amp;apos;s worth we have an internal integration test case to trap this issue, and it passes with Woodstox 4.0.4 and this patch.</description>
			<version>1.1.4</version>
			<fixedVersion>2.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemWriter.java</file>
		</fixedFiles>
		<links>
			<link type="Related" description="is related to">981</link>
		</links>
	</bug>
	<bug id="1255" opendate="2009-05-29 02:08:37" fixdate="2009-05-30 04:28:15" resolution="Fixed">
		<buginformation>
			<summary>Proxy with no target cannot be analysed for listener interfaces</summary>
			<description>Proxy with no target cannot be analysed for listener interfaces.  Various NullPointerExceptions ensue in STepListenerFactoryBean and MethodInvokerUtils.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.support.MethodInvokerUtils.java</file>
			<file type="M">org.springframework.batch.core.listener.StepListenerFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.listener.AbstractListenerFactoryBean.java</file>
		</fixedFiles>
	</bug>
	<bug id="1256" opendate="2009-05-29 07:00:33" fixdate="2009-05-31 21:35:54" resolution="Fixed">
		<buginformation>
			<summary>Processor is called (and committed) many times for the same items if Writer skips</summary>
			<description>Processor is called (and committed) many times for the same items if Writer skips.
Assume the commit interval is 5 and the Reader reads items [1,2,3,4,5].  
If the Writer fails on "4", the following represents the items that are passed into the Processor:
[1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 3, 4, 5, 4, 5, 5]
And the following are the processed items that are committed:
[1, 2, 3, 4, 5, 2, 3, 4, 5, 3, 4, 5, 5]
The Processor should not be receiving the same items over and over.  Furthermore, not processed item should be committed more than once.
</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBeanRollbackTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBeanRetryTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantChunkProcessor.java</file>
			<file type="M">org.springframework.batch.core.step.item.SimpleChunkProcessor.java</file>
			<file type="M">org.springframework.batch.core.step.item.SkipWriterStub.java</file>
			<file type="M">org.springframework.batch.core.step.item.SkipProcessorStub.java</file>
		</fixedFiles>
	</bug>
	<bug id="1264" opendate="2009-06-01 22:03:02" fixdate="2009-06-01 22:10:32" resolution="Fixed">
		<buginformation>
			<summary>NPE in StepParserStepFactoryBean#configureTaskletStep() #289 when omitting "isolation" for &lt;transaction-attributes&gt;</summary>
			<description>this is changed behaviour compared to 2.0.0, where the following job definition worked fine:
 &amp;lt;batch:job id="indexUpdater"&amp;gt;
        &amp;lt;batch:step id="updateIndexes"&amp;gt;
            &amp;lt;batch:tasklet ref="indexUpdaterTasklet"&amp;gt;
                &amp;lt;batch:transaction-attributes propagation="NEVER"/&amp;gt;
            &amp;lt;/batch:tasklet&amp;gt;
        &amp;lt;/batch:step&amp;gt;
    &amp;lt;/batch:job&amp;gt;
after changing to   &amp;lt;batch:transaction-attributes isolation="DEFAULT" propagation="NEVER"/&amp;gt; it worked again</description>
			<version>2.0.1</version>
			<fixedVersion>2.0.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParserStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParserStepFactoryBeanTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1278" opendate="2009-06-03 21:32:31" fixdate="2009-06-03 21:45:43" resolution="Fixed">
		<buginformation>
			<summary>RepeatTemplate aborts early if multiple threads throw ignorable exceptions</summary>
			<description>RepeatTemplate aborts early if multiple threads throw ignorable exceptions.  This is the underlying cause for BATCH-1272.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.repeat.support.TaskExecutorRepeatTemplate.java</file>
			<file type="M">org.springframework.batch.repeat.support.TaskExecutorRepeatTemplateAsynchronousTests.java</file>
			<file type="M">org.springframework.batch.repeat.callback.NestedRepeatCallback.java</file>
			<file type="M">org.springframework.batch.repeat.support.RepeatTemplate.java</file>
			<file type="M">org.springframework.batch.repeat.support.SimpleRepeatTemplateTests.java</file>
			<file type="M">org.springframework.batch.item.database.JdbcCursorItemReaderConfigTests.java</file>
			<file type="D">org.springframework.batch.repeat.support.AsynchronousRepeatTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1272" opendate="2009-06-03 02:49:35" fixdate="2009-06-04 18:03:27" resolution="Fixed">
		<buginformation>
			<summary>Write skips do not work in a multi-threaded step</summary>
			<description>Write skips do not work in a multi-threaded step.  This is strange, and hard to explain, but apparently the FaultTolerantChunkProcessor is not fault tolerant if run in multiple threads at once.</description>
			<version>2.0.1</version>
			<fixedVersion>2.0.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.scope.context.StepContextRepeatCallback.java</file>
			<file type="M">org.springframework.batch.core.scope.context.StepContextRepeatCallbackTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBeanRollbackTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantChunkProcessor.java</file>
			<file type="M">org.springframework.batch.repeat.support.RepeatTemplate.java</file>
			<file type="M">org.springframework.batch.repeat.support.TaskExecutorRepeatTemplate.java</file>
			<file type="M">org.springframework.batch.repeat.support.SimpleRepeatTemplateTests.java</file>
			<file type="M">org.springframework.batch.item.database.JdbcCursorItemReaderConfigTests.java</file>
			<file type="D">org.springframework.batch.repeat.support.AsynchronousRepeatTests.java</file>
			<file type="M">org.springframework.batch.core.step.AbstractStep.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBeanRetryTests.java</file>
			<file type="M">org.springframework.batch.retry.support.RetryTemplate.java</file>
			<file type="M">org.springframework.batch.core.step.item.SimpleRetryExceptionHandler.java</file>
			<file type="M">org.springframework.batch.core.step.item.ExceptionThrowingItemHandlerStub.java</file>
			<file type="M">org.springframework.batch.core.step.item.ChunkOrientedTasklet.java</file>
			<file type="M">org.springframework.batch.core.step.tasklet.TaskletStep.java</file>
			<file type="M">org.springframework.batch.core.step.item.SkipWriterStub.java</file>
		</fixedFiles>
	</bug>
	<bug id="1280" opendate="2009-06-04 21:11:17" fixdate="2009-06-04 21:18:11" resolution="Fixed">
		<buginformation>
			<summary>JobParserJobFactoryBean should be a singleton</summary>
			<description>JobParserJobFactoryBean should be a singleton.  This will cause issues with the JobRegistry - e.g. multiple registrations of the same job in integration tests.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParserStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.listener.AbstractListenerFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.JobParserJobFactoryBean.java</file>
		</fixedFiles>
	</bug>
	<bug id="1282" opendate="2009-06-07 23:14:41" fixdate="2009-06-08 01:23:18" resolution="Fixed">
		<buginformation>
			<summary>JobRegistryBeanPostProcessor skips jobs in XML namespace unless they are injected as dependency</summary>
			<description>The factory bean JobParserJobFactoryBean is not a SmartFactoryBean, so its instances do not get instantiated eagerly by default.  Not many use cases need this, but the JobRegistry is a special case as Job instances typically are not dependencies for anything.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.JobParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.JobParserJobFactoryBean.java</file>
		</fixedFiles>
	</bug>
	<bug id="1284" opendate="2009-06-09 16:43:06" fixdate="2009-06-09 18:35:18" resolution="Fixed">
		<buginformation>
			<summary>Partition Step Stop is incorrectly setting the BatchStatus to COMPLETED.</summary>
			<description>Please refer to the forum reference.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.partition.support.PartitionStepTests.java</file>
			<file type="M">org.springframework.batch.core.step.AbstractStep.java</file>
		</fixedFiles>
	</bug>
	<bug id="1285" opendate="2009-06-10 04:29:07" fixdate="2009-06-10 16:50:54" resolution="Fixed">
		<buginformation>
			<summary>Raise an exception if a step cannot be reached.</summary>
			<description>If a &amp;lt;job/&amp;gt; is defined with a &amp;lt;step/&amp;gt; that cannot be reached during the flow of the job, then an exception should be raised by the parser.
For example, the following will raise an exception because "stepB" can never be executed.






&amp;lt;job id="job"&amp;gt;




    &amp;lt;step id="stepA"/&amp;gt;




    &amp;lt;step id="stepB"/&amp;gt;




&amp;lt;/job&amp;gt;





</description>
			<version>2.0.1</version>
			<fixedVersion>2.0.2</fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.JobParserTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParserTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.FlowParser.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">1291</link>
			<link type="Related" description="is related to">1283</link>
		</links>
	</bug>
	<bug id="1291" opendate="2009-06-12 12:56:24" fixdate="2009-06-12 13:14:39" resolution="Duplicate">
		<buginformation>
			<summary>Namespace parser should validate that there are no orphaned steps</summary>
			<description>Per the discussion over at BATCH-1283 it would be nice if the namespace parser validated that all steps defined for a job config are reachable by some permutation of the job--formally, that the defined step flow represents a weakly connected rooted digraph.
For example in the following (currently valid) configuration stepB is never run:
&amp;lt;job id="job"&amp;gt;
    &amp;lt;step id="stepA" /&amp;gt;
    &amp;lt;step id="stepB" /&amp;gt;
&amp;lt;/job&amp;gt;
For stepB to be run the config would have to be like:
&amp;lt;job id="job"&amp;gt;
    &amp;lt;step id="stepA" next="stepB" /&amp;gt;
    &amp;lt;step id="stepB" /&amp;gt;
&amp;lt;/job&amp;gt;
For prior art see http://www.jgrapht.org/javadoc/org/jgrapht/alg/ConnectivityInspector.html, with source viewable at http://jgrapht.svn.sourceforge.net/viewvc/jgrapht/.  In fact JGraphT adapts readily to existing object models, and might be a handy way to implement this and potentially other validations (cycles that require an exception to break out of?) if the dependency and it&amp;amp;apos;s LGPL license were acceptable.</description>
			<version>2.0.1</version>
			<fixedVersion></fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.JobParserTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParserTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.FlowParser.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">1285</link>
		</links>
	</bug>
	<bug id="1289" opendate="2009-06-12 00:28:00" fixdate="2009-06-12 14:55:54" resolution="Fixed">
		<buginformation>
			<summary>Null pointer in CoreNamespaceUtils.rangeArrayEditorAlreadyDefined()</summary>
			<description>A NullPointerException is thrown from CoreNamespaceUtils.rangeArrayEditorAlreadyDefined() if there is a custom editor configurer without a customEditor property because of the line:






Map editors = (Map) bd.getPropertyValues().getPropertyValue("customEditors").getValue();





</description>
			<version>2.0.1</version>
			<fixedVersion>2.0.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.CoreNamespaceUtils.java</file>
		</fixedFiles>
	</bug>
	<bug id="1232" opendate="2009-05-04 02:12:51" fixdate="2009-06-16 07:34:44" resolution="Fixed">
		<buginformation>
			<summary>Sybase 12.5 compatiblity when writing to the spring batch context tables</summary>
			<description>In version 2.0.0, I am facing an error when persisting to the context tables (BATCH_JOB_EXECUTION_CONTEXT in specific) on the sybase version 12.5. The class JdbcExecutionContextDao shows that when the field SERIALIZED_CONTEXT is set to null, it is set with type 2005 (Types.CLOB). This type is not supported on sybase 12.5</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcExecutionContextDao.java</file>
			<file type="M">org.springframework.batch.core.repository.support.JobRepositoryFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.repository.support.JobRepositoryFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.AbstractJdbcBatchMetadataDao.java</file>
		</fixedFiles>
	</bug>
	<bug id="1301" opendate="2009-06-19 01:51:21" fixdate="2009-06-20 19:52:19" resolution="Fixed">
		<buginformation>
			<summary>ItemStream is not being opened correctly for multi-threaded Step when scope="step"</summary>
			<description>The following job definition works however if I change the reader to scope="step" I will get an exception about the stream never being opened (from FlatFileItemReader.doRead()). It appears doOpen() is called at least once however I believe its a different instance than what is actually used for read() because when read() is called the reader is not initialized.
            &amp;lt;job id="search-job" restartable="true"&amp;gt;
		&amp;lt;step id="search-job-step"&amp;gt;
			&amp;lt;tasklet transaction-manager="transactionManager" allow-start-if-complete="true"&amp;gt;
				&amp;lt;chunk reader="itemReader" writer="itemWriter" commit-interval="1" task-executor="executor" &amp;gt;
					&amp;lt;streams&amp;gt; &amp;lt;!-- tried with and without this --&amp;gt;
						&amp;lt;stream ref="itemReader" /&amp;gt;
					&amp;lt;/streams&amp;gt;
				&amp;lt;/chunk&amp;gt;
			&amp;lt;/tasklet&amp;gt;
		&amp;lt;/step&amp;gt;
	&amp;lt;/job&amp;gt;
	&amp;lt;b:bean id="itemReader" class="org.springframework.batch.item.file.FlatFileItemReader"&amp;gt;
		&amp;lt;b:property name="resource" value="file:input.csv" /&amp;gt;
		&amp;lt;b:property name="lineMapper"&amp;gt;
			&amp;lt;b:bean class="org.springframework.batch.item.file.mapping.DefaultLineMapper"&amp;gt;
				&amp;lt;b:property name="lineTokenizer"&amp;gt;
					&amp;lt;b:bean class="org.springframework.batch.item.file.transform.DelimitedLineTokenizer"&amp;gt;
						&amp;lt;b:property name="names" value="col1,col2,col3" /&amp;gt;
					&amp;lt;/b:bean&amp;gt;
				&amp;lt;/b:property&amp;gt;
				&amp;lt;b:property name="fieldSetMapper"&amp;gt;
					&amp;lt;b:bean class="com.company.prj.batch.ItemFieldSetMapper" /&amp;gt;
				&amp;lt;/b:property&amp;gt;
			&amp;lt;/b:bean&amp;gt;
		&amp;lt;/b:property&amp;gt;
	&amp;lt;/b:bean&amp;gt;
	&amp;lt;b:bean id="itemWriter" class="org.springframework.batch.item.file.FlatFileItemWriter"&amp;gt;
		&amp;lt;b:property name="resource" value="file:searchoutput.txt" /&amp;gt;
		&amp;lt;b:property name="lineAggregator"&amp;gt;
			&amp;lt;b:bean class="com.company.prj.batch.SearchResultsAggregator" /&amp;gt;
		&amp;lt;/b:property&amp;gt;
	&amp;lt;/b:bean&amp;gt;</description>
			<version>2.0.1</version>
			<fixedVersion>2.0.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.scope.AsyncStepScopeIntegrationTests.java</file>
			<file type="M">org.springframework.batch.core.scope.context.StepSynchronizationManager.java</file>
			<file type="M">org.springframework.batch.core.scope.context.StepContextRepeatCallback.java</file>
			<file type="M">org.springframework.batch.core.scope.context.StepSynchronizationManagerTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1304" opendate="2009-06-22 19:04:49" fixdate="2009-06-23 02:27:19" resolution="Fixed">
		<buginformation>
			<summary>Filter counter not incremented whenever there&amp;apos;s a skip</summary>
			<description>The filterCount in StepExecution is not incremented properly whenever a skip (Exception) happens in the same chuck. See the forum link for details.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantChunkProcessorTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantChunkProcessor.java</file>
			<file type="M">org.springframework.batch.core.step.item.SimpleChunkProcessor.java</file>
		</fixedFiles>
	</bug>
	<bug id="1311" opendate="2009-06-26 08:08:39" fixdate="2009-06-26 08:11:20" resolution="Duplicate">
		<buginformation>
			<summary>SimpleJobExplorer should return null when a StepExecution cannot be found</summary>
			<description>SimpleJobExplorer should return null when a StepExecution cannot be found - it needs to check the JobExecution first before sending it to the repository.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.2</fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.exlore.support.SimpleJobExplorerTests.java</file>
			<file type="M">org.springframework.batch.core.explore.support.SimpleJobExplorer.java</file>
		</fixedFiles>
	</bug>
	<bug id="1313" opendate="2009-06-28 02:57:24" fixdate="2009-06-28 03:18:04" resolution="Fixed">
		<buginformation>
			<summary>loopFlowSample&amp;apos;s LimitDecider returns "COMPLETE" instead of "COMPLETED"</summary>
			<description></description>
			<version>2.0.1</version>
			<fixedVersion>2.0.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.sample.loopFlow.LimitDecider.java</file>
			<file type="M">org.springframework.batch.sample.AbstractBatchLauncherTests.java</file>
			<file type="M">org.springframework.batch.sample.TradeJobFunctionalTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1314" opendate="2009-06-28 03:02:51" fixdate="2009-06-28 03:18:12" resolution="Fixed">
		<buginformation>
			<summary>FFIW in tradeJob is pointing to classpath instead of the target</summary>
			<description></description>
			<version>2.0.1</version>
			<fixedVersion>2.0.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.sample.loopFlow.LimitDecider.java</file>
			<file type="M">org.springframework.batch.sample.AbstractBatchLauncherTests.java</file>
			<file type="M">org.springframework.batch.sample.TradeJobFunctionalTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1319" opendate="2009-07-05 01:38:26" fixdate="2009-07-05 01:41:48" resolution="Fixed">
		<buginformation>
			<summary>Small memory leak in StepSynchronizationManager</summary>
			<description>Small memory leak in StepSynchronizationManager: the counts map is not cleaned up at the end of a step execution.</description>
			<version>2.0.2</version>
			<fixedVersion>2.0.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.scope.context.StepSynchronizationManagerTests.java</file>
			<file type="M">org.springframework.batch.core.scope.context.StepSynchronizationManager.java</file>
		</fixedFiles>
	</bug>
	<bug id="1326" opendate="2009-07-08 03:10:55" fixdate="2009-07-08 04:39:33" resolution="Fixed">
		<buginformation>
			<summary>Restart after &lt;stop/&gt; doesn&amp;apos;t work if any previous steps have allowStartIfComplete=true</summary>
			<description>Restart after &amp;lt;stop/&amp;gt; doesn&amp;amp;apos;t work if any previous steps have allowStartIfComplete=true.  The system tries to detect a restart by looking for a stopped step at the start of a job.  If one of the previous steps was already re-executed after being COMPLETED then this is wrong.</description>
			<version>2.0.0</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.StopAndRestartFailedJobParserTests.java</file>
			<file type="M">org.springframework.batch.core.job.AbstractJob.java</file>
			<file type="M">org.springframework.batch.core.job.flow.FlowJob.java</file>
		</fixedFiles>
	</bug>
	<bug id="1330" opendate="2009-07-09 17:54:40" fixdate="2009-07-09 19:13:25" resolution="Fixed">
		<buginformation>
			<summary>Wrong JavaDoc in CommandLineJobRunner concerning Parameters</summary>
			<description>It seems to me that the documentation of the command line arguments for CommandLineJobRunner in the JavaDoc class comment is wrong. It says the parameters are "java jobPath jobName jobLauncherPath jobParameters...".
First of all I would remove "java" here. But jobLauncherPath seams to be really wrong. There is no such parameter.
The JavaDoc for "main(String[])" says there are the parameters are "jobPath, jobName, jobParameters...". And the code seams to proof that.</description>
			<version>2.0.0</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.launch.support.CommandLineJobRunner.java</file>
		</fixedFiles>
	</bug>
	<bug id="1318" opendate="2009-07-03 21:29:18" fixdate="2009-07-10 01:14:56" resolution="Fixed">
		<buginformation>
			<summary>Ensure exception classes are behaving correctly</summary>
			<description>There seem to be a few problems with the way the exception classes are being handled:
BATCH-1327: 1) If the exception is not registered as skippable (on a step with a skip-limit), then it should be treated exactly as if it were registered as fatal (stop processing immediately).  However, right now the chunk seems to be rolling back, and reprocessing before finally failing.
BATCH-1333: 2) Exceptions registered as retryable and fatal are not being retried.
BATCH-1332: 3) Skippable + No-Rollback exceptions show inconsistent rollback behavior.  No rollback occurs for the initial writing of the chunk but rollback seems to occur during scanning.
BATCH-1331: 4) Fatal + No-Rollback exceptions are causing the chunk to be reprocessed, leading to double-commits for valid records.
BATCH-1334: 5) Non-Skippable + No-Rollback exceptions are being treated as skippable.</description>
			<version>2.0.1</version>
			<fixedVersion>2.0.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantExceptionClassesTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.SkipWriterStub.java</file>
			<file type="M">org.springframework.batch.core.step.item.ExceptionThrowingTaskletStub.java</file>
			<file type="M">org.springframework.batch.core.step.item.SkipProcessorStub.java</file>
			<file type="M">org.springframework.batch.core.step.item.SkipReaderStub.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBeanRollbackTests.java</file>
			<file type="D">org.springframework.batch.core.step.item.ExceptionThrowingItemHandlerStub.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBeanTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1341" opendate="2009-07-22 04:05:40" fixdate="2009-07-22 04:21:24" resolution="Fixed">
		<buginformation>
			<summary>DataSourceInitializer throws ArrayOutOfBoundException when any destroyScript is specified</summary>
			<description>basically, this is a typo:
91:		for (int i = 0; i &amp;lt; destroyScripts.length; i++) {
92:			Resource destroyScript = initScripts[i];</description>
			<version>2.0.0.RC2</version>
			<fixedVersion>2.0.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.test.DataSourceInitializer.java</file>
		</fixedFiles>
	</bug>
	<bug id="1345" opendate="2009-07-26 14:58:36" fixdate="2009-07-26 15:17:57" resolution="Fixed">
		<buginformation>
			<summary>Fix error message for when &lt;tasklet/&gt; has no ref= or &lt;chunk/&gt;</summary>
			<description></description>
			<version>2.0.2</version>
			<fixedVersion>2.0.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.AbstractStepParser.java</file>
		</fixedFiles>
	</bug>
	<bug id="1351" opendate="2009-07-30 07:35:52" fixdate="2009-08-03 16:15:48" resolution="Fixed">
		<buginformation>
			<summary>An empty &lt;*-exception-classes/&gt; list does not override parent&amp;apos;s list</summary>
			<description>An empty &amp;lt;*-exception-classes/&amp;gt; list does not override parent&amp;amp;apos;s list.  This probably applies to other lists (listeners, streams, ...) as well.  This prevents a step or job from being about to inherit from a parent and remove its registered exception classes.
For example, the following results in step "B" having java.lang.Exception registered as skippable even though it specifies &amp;lt;skippable-exception-classes/&amp;gt; with merge="false" (the default).






&amp;lt;step id="A"&amp;gt;




    &amp;lt;tasklet&amp;gt;




        &amp;lt;chunk&amp;gt;




            &amp;lt;skippable-exception-classes&amp;gt;




                java.lang.Exception




            &amp;lt;/skippable-exception-classes&amp;gt;




        &amp;lt;/chunk&amp;gt;




    &amp;lt;/tasklet&amp;gt;




&amp;lt;/step&amp;gt;









&amp;lt;step id="B" parent="A"&amp;gt;




    &amp;lt;tasklet&amp;gt;




        &amp;lt;chunk&amp;gt;




            &amp;lt;skippable-exception-classes/&amp;gt;




        &amp;lt;/chunk&amp;gt;




    &amp;lt;/tasklet&amp;gt;




&amp;lt;/step&amp;gt;





</description>
			<version>2.0.2</version>
			<fixedVersion>2.0.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParserTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.JobParserTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.AbstractStepParser.java</file>
		</fixedFiles>
		<links>
			<link type="Related" description="is related to">1357</link>
		</links>
	</bug>
	<bug id="1362" opendate="2009-08-07 19:02:48" fixdate="2009-08-09 21:46:18" resolution="Fixed">
		<buginformation>
			<summary>Threads spinning doing nothing at end of multi-threaded Step</summary>
			<description>Threads spinning doing nothing at end of multi-threaded Step.  When a multi-threaded step is waiting for its last chunk to process it needs to wait on threads that are FINISHED, rather than spinning round asking them over and over if they want to do more work.  The visible effect is often a large disparity between commit count and read count at the end of a step.  One user even reported an apparently infinite loop (probably it was just the JVM scheduler not giving priority to the real worker thread).</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.repeat.support.TaskExecutorRepeatTemplate.java</file>
			<file type="M">org.springframework.batch.repeat.support.TaskExecutorRepeatTemplateSimpleAsynchronousTests.java</file>
			<file type="M">org.springframework.batch.core.step.tasklet.AsyncTaskletStepTests.java</file>
			<file type="M">org.springframework.batch.core.scope.context.StepContextRepeatCallback.java</file>
			<file type="M">org.springframework.batch.core.scope.context.StepContextRepeatCallbackTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1363" opendate="2009-08-08 19:54:58" fixdate="2009-08-09 22:39:39" resolution="Fixed">
		<buginformation>
			<summary>Job stopped in split state does not finish with status = STOPPED</summary>
			<description>The analysis on the forum post isn&amp;amp;apos;t quite correct because SimpleFlow is used even for sequential executions.  The problem lies in the SplitState: it needs to unwrap ExecutionExceptions and re-throw their cause.</description>
			<version>2.0.0</version>
			<fixedVersion>2.0.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.job.flow.FlowJobTests.java</file>
			<file type="M">org.springframework.batch.core.job.flow.support.SimpleFlow.java</file>
			<file type="M">org.springframework.batch.core.job.flow.support.state.SplitState.java</file>
			<file type="M">org.springframework.batch.core.job.flow.support.state.SplitStateTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1354" opendate="2009-07-31 00:51:17" fixdate="2009-08-20 03:42:26" resolution="Fixed">
		<buginformation>
			<summary>Infinite loop caused by throwing an Error from the ItemWriter of a skippable step</summary>
			<description>If a java.lang.Error is thrown from the ItemWriter of a step with skipLimit &amp;gt; 0, then the framework falls into an infinite loop.  It appears that an Error thrown misses the catch block that increments the skip counter, but it still causes the step to skip.  So the effect is that we skip continuously.
The desired effect is that an Error is thrown out of the job and never skips.
This was discovered when using jMock since jMock throws an ExpectationError when an expectation fails.</description>
			<version>2.0.2</version>
			<fixedVersion>2.0.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBeanRollbackTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantChunkProcessorTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.step.tasklet.TaskletStepTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantChunkProcessor.java</file>
			<file type="M">org.springframework.batch.core.step.item.AbstractExceptionThrowingItemHandlerStub.java</file>
		</fixedFiles>
	</bug>
	<bug id="1378" opendate="2009-08-21 00:49:09" fixdate="2009-08-21 20:49:39" resolution="Fixed">
		<buginformation>
			<summary>Late binding of parameters in map value only happens once per ApplicationContext</summary>
			<description>See thorough description in the forum, which also have the related classes, configuration and log attached.
In essence the binding of the parameters only happens once, so that any subsequent executions will run with stale values.</description>
			<version>2.0.2</version>
			<fixedVersion>2.0.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.scope.util.MultipleContextPlaceholderTargetSourceTests.java</file>
			<file type="M">org.springframework.batch.core.scope.util.PlaceholderTargetSource.java</file>
		</fixedFiles>
	</bug>
	<bug id="1383" opendate="2009-08-23 19:29:45" fixdate="2009-09-03 21:56:51" resolution="Fixed">
		<buginformation>
			<summary>onSkipInProcess is not called if the exception is marked as no-rollback</summary>
			<description>The method onSkipInProcess in the SkipListener is not called. My application logs the step execution after each step:
After: execution(execute) with: StepExecution: id=264, name=stage, status=COMPLETED, exitStatus=COMPLETED, readCount=28, filterCount=15, writeCount=13 readSkipCount=0, writeSkipCount=0, processSkipCount=15, commitCount=1, rollbackCount=0, exitDescription=
I expected that the onSkipInProcess method should be called 15 times, but it is not. The listener class is defined as follows:
public class CommandStepListener extends SkipListenerSupport&amp;lt;Command, Command&amp;gt; {
   @Override
    public void onSkipInProcess(Command item, Throwable t) 
{
         // some skip logic
    }
   @BeforeStep
    public void initialize(StepExecution stepExecution) 
{
        // some initialization setup
    }
}
The step definitions:
&amp;lt;batch:step id="abstractStep" abstract="true"&amp;gt;
  &amp;lt;batch:tasklet job-repository="jobRepository" transaction-manager="transactionManager" allow-start-if-complete="false"&amp;gt;
  &amp;lt;/batch:tasklet&amp;gt;
&amp;lt;/batch:step&amp;gt;
&amp;lt;batch:job id="myJob" restartable="true"&amp;gt;
  &amp;lt;batch:step id="stage" next="operation" parent="abstractStep"&amp;gt;
    &amp;lt;batch:tasklet&amp;gt;
      &amp;lt;batch:chunk reader="commandFileReader" processor="commandProcessor" writer="commandWriter" commit-interval="100" skip-limit="1000000" retry-limit="10"&amp;gt;
        &amp;lt;batch:skippable-exception-classes&amp;gt;org.springframework.batch.item.validator.ValidationException&amp;lt;/batch:skippable-exception-classes&amp;gt;
        &amp;lt;batch:retryable-exception-classes&amp;gt;java.io.IOException&amp;lt;/batch:retryable-exception-classes&amp;gt;
      &amp;lt;/batch:chunk&amp;gt;
      &amp;lt;batch:no-rollback-exception-classes&amp;gt;org.springframework.batch.item.validator.ValidationException&amp;lt;/batch:no-rollback-exception-classes&amp;gt;
      &amp;lt;batch:listeners&amp;gt;
        &amp;lt;batch:listener ref="commandStepListener" /&amp;gt;
      &amp;lt;/batch:listeners&amp;gt;
   &amp;lt;/batch:tasklet&amp;gt;
  &amp;lt;/batch:step&amp;gt;
and processor definition is:
&amp;lt;bean id="commandProcessor" scope="step" class="org.springframework.batch.item.validator.ValidatingItemProcessor"&amp;gt;
    &amp;lt;constructor-arg ref="commandValidator" /&amp;gt;
&amp;lt;/bean&amp;gt;
The commandValidator just throws the ValidationException if the processed command is invalid.
The listener bean is registered, the initialize method is called. When I added onSkipInRead method to the listener and simulate error during command reading, the method was called. It seems that my setup is fine, but onSkipInProcess is not called 
I also tried switch to pure annotation configuration with @OnSkipInProcess. The method is not called, also.</description>
			<version>2.0.2</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantChunkProcessor.java</file>
			<file type="M">org.springframework.batch.sample.common.SkipCheckingListener.java</file>
			<file type="M">org.springframework.batch.sample.domain.trade.internal.JdbcTradeDao.java</file>
			<file type="M">org.springframework.batch.sample.SkipSampleFunctionalTests.java</file>
			<file type="M">org.springframework.batch.sample.domain.trade.internal.TradeRowMapper.java</file>
			<file type="M">org.springframework.batch.sample.common.ErrorLogTasklet.java</file>
			<file type="M">org.springframework.batch.sample.domain.trade.internal.TradeWriter.java</file>
			<file type="M">org.springframework.batch.sample.domain.trade.Trade.java</file>
			<file type="M">org.springframework.batch.sample.domain.trade.internal.ItemTrackingTradeItemWriter.java</file>
		</fixedFiles>
	</bug>
	<bug id="1392" opendate="2009-09-03 22:52:41" fixdate="2009-09-04 00:05:55" resolution="Fixed">
		<buginformation>
			<summary>Throttle limit is not parsed in ChunkElementParser</summary>
			<description>Spring Batch 2.0.3 has added the property throttle-limit property to the chunk element in the spring-batch-2.0.xsd
However, ChunkElementParser does not parse this property at all.
Fix :
In method parse() of class ChunkElementParser  add the following lines:
String throttleLimit = element.getAttribute("throttle-limit");
if (StringUtils.hasText(throttleLimit)) {
       propertyValues.addPropertyValue("throttleLimit", throttleLimit);
}</description>
			<version>2.0.3</version>
			<fixedVersion>2.0.4, 2.1.0.M1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParserTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.AbstractStepParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParserStepFactoryBeanTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1390" opendate="2009-09-03 21:10:38" fixdate="2009-09-04 06:24:37" resolution="Fixed">
		<buginformation>
			<summary>ExecutionContextPromotionListener erases previous step</summary>
			<description>ExecutionContextPromotionListener erases previous step.  It should check for the existence of each value by key before promting, otherwise it will erase information from previous steps.</description>
			<version>2.0.0</version>
			<fixedVersion>2.1.0.M1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.listener.ExecutionContextPromotionListener.java</file>
			<file type="M">org.springframework.batch.core.listener.ExecutionContextPromotionListenerTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1397" opendate="2009-09-07 03:53:39" fixdate="2009-09-07 04:05:33" resolution="Fixed">
		<buginformation>
			<summary>Late binding only happens once per ApplicationContext if expression is in substring</summary>
			<description>Late binding only happens once per ApplicationContext if expression is in substring (c.f. BATCH-1378).  Still slightly broken: e.g. value="#jobParameters[foo]" works fine but value="foo-#jobParameters[foo]" does not.</description>
			<version>2.0.2</version>
			<fixedVersion>2.0.4, 2.1.0.M1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.scope.util.MultipleContextPlaceholderTargetSourceTests.java</file>
			<file type="M">org.springframework.batch.core.scope.util.PlaceholderTargetSource.java</file>
		</fixedFiles>
	</bug>
	<bug id="1401" opendate="2009-09-10 23:11:54" fixdate="2009-09-15 23:54:02" resolution="Fixed">
		<buginformation>
			<summary>All inserts of JobId should be of Types.BIGINT</summary>
			<description>In JdbcJobInstanceDao the jobid is mapped to different sql types depending on which table it is inserted in.
Types.INTEGER is used in
JdbcJobInstanceDao .createJobInstance
JdbcJobExecutionDao.saveJobExecution
Types.BIGINT is used in
JdbcJobInstanceDao .insertParameter 
I&amp;amp;apos;m not sure if this is causing the problems I am having at the moment (breaches of constraint JOB_INST_PARAMS_FK on Sybase), but as the underlying datatype in the DB is the same for all tables persisting the jobid, the java.sql.Types used should probably be the same as well.
Someone should probably look through all the Jdbc*Daos to make sure that the same Types.* is used for all IDs, seems most inserts use Types.INTEGER.</description>
			<version>2.0.0</version>
			<fixedVersion>2.1.0.M2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.sample.CompositeItemWriterSampleFunctionalTests.java</file>
			<file type="M">org.springframework.batch.sample.domain.trade.internal.JdbcTradeDao.java</file>
			<file type="M">org.springframework.batch.sample.AbstractCustomerCreditIncreaseTests.java</file>
			<file type="M">org.springframework.batch.sample.domain.trade.internal.JdbcCustomerDebitDaoTests.java</file>
			<file type="M">org.springframework.batch.sample.domain.football.internal.JdbcPlayerDao.java</file>
			<file type="M">org.springframework.batch.sample.TradeJobFunctionalTests.java</file>
			<file type="M">org.springframework.batch.sample.CustomerFilterJobFunctionalTests.java</file>
			<file type="M">org.springframework.batch.sample.domain.trade.internal.JdbcCustomerDebitDao.java</file>
			<file type="M">spring-batch-samples.src.main.java.test.jdbc.datasource.DataSourceInitializer.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcJobInstanceDao.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcJobExecutionDao.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcStepExecutionDao.java</file>
		</fixedFiles>
	</bug>
	<bug id="1417" opendate="2009-09-27 18:33:50" fixdate="2009-09-28 03:54:23" resolution="Fixed">
		<buginformation>
			<summary>Error in FlatFileItemReader when RecordSeparatorPolicy.preProcess or readLine returns null</summary>
			<description>We think there&amp;amp;apos;s a bug in RecordSeparatorPolicy handling in FlatFileItemReader when RecordSeparatorPolicy .preProcess or readLine returns null :

returning null from recordSeparatorPolicy.preProcess is not handled correctly by FlatFileItemReader.
also on the same line, if readLine() returns null, FlatFileItemReader handles it incorrectly and we obtain a "null" string.

Code in error ;
while (line != null &amp;amp;&amp;amp; !recordSeparatorPolicy.isEndOfRecord(record)) {
   record = recordSeparatorPolicy.preProcess(record) + (line = readLine());
}
If isEndOfRecord returns true, record can be "null" string.</description>
			<version>2.0.3</version>
			<fixedVersion>2.0.4, 2.1.0.M1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReaderTests.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReader.java</file>
		</fixedFiles>
	</bug>
	<bug id="1420" opendate="2009-10-13 07:47:05" fixdate="2009-10-16 14:16:03" resolution="Fixed">
		<buginformation>
			<summary>Late Binding only happens first time when using inner bean definition with collection property</summary>
			<description>Using the Partitioning method, attempting to access the separate ExecutionContexts as setup by my Partitioner only works on the first step. All subsequent steps seem to use the same ExecutionContext variables. This appears to be caused by the binding not happening at all on the later steps, essentially recycling the previous values.
See attachments for sample configuration</description>
			<version>2.0.3</version>
			<fixedVersion>2.0.4, 2.1.0.M2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.sample.common.OutputFileListenerTests.java</file>
			<file type="M">org.springframework.batch.sample.PartitionJdbcJobFunctionalTests.java</file>
			<file type="M">org.springframework.batch.sample.PartitionFileJobFunctionalTests.java</file>
			<file type="D">org.springframework.batch.sample.ParallelJobFunctionalTests.java</file>
			<file type="M">org.springframework.batch.core.partition.support.TaskExecutorPartitionHandlerTests.java</file>
			<file type="D">org.springframework.batch.sample.PartitionJobFunctionalTests.java</file>
			<file type="M">org.springframework.batch.core.scope.util.MultipleContextPlaceholderTargetSourceTests.java</file>
			<file type="M">org.springframework.batch.core.scope.util.PlaceholderTargetSource.java</file>
			<file type="M">org.springframework.batch.sample.common.OutputFileListener.java</file>
		</fixedFiles>
	</bug>
	<bug id="1423" opendate="2009-10-16 23:55:07" fixdate="2009-10-16 23:56:56" resolution="Fixed">
		<buginformation>
			<summary>Upon job restart, step with FlatFileItemReader doesn&amp;apos;t honor skippable-exception-classes</summary>
			<description>Cloned from: BATCH-1418 to allow this to be closed for 2.0.4.
Upon restarting a failed step, the reader (FlatFileItemReader) tries to parse the file from the beginning as it tries to reach the point from where it has to pick up after the last failure. Along the way, the reader invokes the lineTokenizer and the fieldSetMapper for each of the already processed records. This appears to be far too much work for no gain when the point is to quickly get to the last record read from the file that was successfully committed. 
More importantly, during this recovery phase, the parsing exercise triggers parsing exceptions but the batch framework doesn&amp;amp;apos;t honor the "skippable-exception-classes" instruction. This causes exceptions (that should be skipped) to become fatal and the job fails to restart.
More information is available in the "Spring Forum Reference" thread.</description>
			<version>2.0.3</version>
			<fixedVersion>2.0.4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReader.java</file>
		</fixedFiles>
	</bug>
	<bug id="1427" opendate="2009-10-29 07:13:03" fixdate="2009-11-10 01:19:02" resolution="Fixed">
		<buginformation>
			<summary>SimpleRetryExceptionHandler treats AbstractStep$FatalException as non-fatal</summary>
			<description>SimpleRetryExceptionHandler treats AbstractStep$FatalException as a non-fatal exception and allows Spring Batch to continue processing. Shouldn&amp;amp;apos;t AbstractStep$FatalException be handled as its name implies - like a fatal exception?
A stack trace is available in the associated Spring Forum Reference thread.</description>
			<version>2.0.3</version>
			<fixedVersion>2.1.0.M2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantExceptionClassesTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.ChunkElementParserTests.java</file>
			<file type="M">org.springframework.batch.core.step.AbstractStep.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParserTests.java</file>
			<file type="D">org.springframework.batch.core.step.item.FatalException.java</file>
			<file type="M">org.springframework.batch.core.step.tasklet.TaskletStep.java</file>
			<file type="M">org.springframework.batch.core.step.item.AbstractExceptionThrowingItemHandlerStub.java</file>
		</fixedFiles>
	</bug>
	<bug id="1444" opendate="2009-11-17 17:33:23" fixdate="2009-11-17 17:48:27" resolution="Fixed">
		<buginformation>
			<summary>ChunkMonitor warning message about stream state is inaccurate</summary>
			<description>ChunkMonitor warning message about stream state is inaccurate: it warns the user if a multi-threaded access to ItemStream data is detected, and it checks for a null stream, but the stream is a composite and it is always null.  Should check for a registered stream inside the composite.</description>
			<version>2.0.4</version>
			<fixedVersion>2.1.0.M3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.ChunkMonitorTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.ChunkMonitor.java</file>
		</fixedFiles>
	</bug>
	<bug id="1453" opendate="2009-11-26 03:39:26" fixdate="2009-11-26 04:06:54" resolution="Fixed">
		<buginformation>
			<summary>OraclePagingQueryProvider generates wrong queries for pages</summary>
			<description>OraclePagingQueryProvider generates wrong queries for pages.  It should use a sub select to select the whole range first, e.g. SELECT * FROM (SELECT ... WHERE ...) WHERE ROWNUM&amp;lt;=100.</description>
			<version>2.0.4</version>
			<fixedVersion>2.0.Maintenance, 2.1.0.M3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.support.SqlPagingQueryUtilsTests.java</file>
			<file type="M">org.springframework.batch.item.database.support.SqlPagingQueryUtils.java</file>
			<file type="M">org.springframework.batch.item.database.support.OraclePagingQueryProviderTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1452" opendate="2009-11-26 00:55:16" fixdate="2009-11-26 19:09:59" resolution="Fixed">
		<buginformation>
			<summary>Stream closed exception when combining MultiResourceItemWriter and FlatFileItemWriter with footer callback</summary>
			<description>I have a Spring Batch process which takes a set of rows in the database and creates a number of flat files from those rows, 10 rows per file. To do this, I&amp;amp;apos;ve created a Spring Batch process, similar to this:






&amp;lt;batch:job id="springTest" job-repository="jobRepository" restartable="true"&amp;gt;




    &amp;lt;batch:step id="test"&amp;gt;




        &amp;lt;batch:tasklet&amp;gt;




            &amp;lt;batch:chunk reader="itemReader" writer="multipleItemWriter" commit-interval="2" /&amp;gt;




        &amp;lt;/batch:tasklet&amp;gt;




    &amp;lt;/batch:step&amp;gt;




&amp;lt;/batch:job&amp;gt;









&amp;lt;bean id="itemReader" class="org.springframework.batch.item.file.FlatFileItemReader"&amp;gt;




    &amp;lt;property name="resource" value="file:/temp/temp-input.txt" /&amp;gt;




    &amp;lt;property name="lineMapper"&amp;gt;




        &amp;lt;bean class="org.springframework.batch.item.file.mapping.PassThroughLineMapper" /&amp;gt;




    &amp;lt;/property&amp;gt;




&amp;lt;/bean&amp;gt;









&amp;lt;bean id="multipleItemWriter" class="org.springframework.batch.item.file.MultiResourceItemWriter"&amp;gt;




    &amp;lt;property name="resource" value="file:/temp/temp-out" /&amp;gt;




    &amp;lt;property name="itemCountLimitPerResource" value="2" /&amp;gt;




    &amp;lt;property name="delegate"&amp;gt;




            &amp;lt;bean id="itemWriter" class="org.springframework.batch.item.file.FlatFileItemWriter"&amp;gt;




                &amp;lt;property name="lineAggregator"&amp;gt;




                  &amp;lt;bean class="org.springframework.batch.item.file.transform.PassThroughLineAggregator" /&amp;gt;




                &amp;lt;/property&amp;gt;




                &amp;lt;property name="encoding" value="utf-8" /&amp;gt;




                &amp;lt;property name="headerCallback" ref="headerFooter" /&amp;gt;




                &amp;lt;property name="footerCallback" ref="headerFooter" /&amp;gt;




            &amp;lt;/bean&amp;gt;




   &amp;lt;/property&amp;gt;




&amp;lt;/bean&amp;gt;









&amp;lt;bean id="headerFooter" class="uk.co.farwell.spring.HeaderFooterCallback" /&amp;gt;






The above example reads from a flat file and outputs to a flat file (to show the problem). Note the commit-interval=2 in the chunk, and the itemCountLimitPerResource=2 in the MultiResourceItemWriter.
The HeaderFooterCallback does the following:






public void writeHeader(Writer writer) throws IOException {




    writer.write("file header\n");




}









public void writeFooter(Writer writer) throws IOException {




    writer.write("file footer\n");




}






I need to be able to specify exactly the number of lines which appear in the file.
For the following input file:






foo1




foo2




foo3






I would expect two files on output,
out.1:






file header




foo1




foo2




file footer






out.2:






file header




foo3




file footer






When I run with commit-interval=2, I get an exception:






2009-11-26 15:32:46,734 ERROR .support.TransactionSynchronizationUtils - TransactionSynchronization.afterCompletion threw exception




org.springframework.batch.support.transaction.FlushFailedException: Could not write to output buffer




	at org.springframework.batch.support.transaction.TransactionAwareBufferedWriter$1.afterCompletion(TransactionAwareBufferedWriter.java:71)




	at org.springframework.transaction.support.TransactionSynchronizationUtils.invokeAfterCompletion(TransactionSynchronizationUtils.java:157)




	at org.springframework.transaction.support.AbstractPlatformTransactionManager.invokeAfterCompletion(AbstractPlatformTransactionManager.java:974)




	at org.springframework.transaction.support.AbstractPlatformTransactionManager.triggerAfterCompletion(AbstractPlatformTransactionManager.java:949)




	at org.springframework.transaction.support.AbstractPlatformTransactionManager.processCommit(AbstractPlatformTransactionManager.java:777)




	at org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:701)




	at org.springframework.batch.core.step.tasklet.TaskletStep$2.doInChunkContext(TaskletStep.java:304)




	at org.springframework.batch.core.scope.context.StepContextRepeatCallback.doInIteration(StepContextRepeatCallback.java:76)




	at org.springframework.batch.repeat.support.RepeatTemplate.getNextResult(RepeatTemplate.java:367)




	at org.springframework.batch.repeat.support.RepeatTemplate.executeInternal(RepeatTemplate.java:215)




	at org.springframework.batch.repeat.support.RepeatTemplate.iterate(RepeatTemplate.java:143)




	at org.springframework.batch.core.step.tasklet.TaskletStep.doExecute(TaskletStep.java:242)




	at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:198)




	at org.springframework.batch.core.job.AbstractJob.handleStep(AbstractJob.java:348)




	at org.springframework.batch.core.job.flow.FlowJob.access$100(FlowJob.java:43)




	at org.springframework.batch.core.job.flow.FlowJob$JobFlowExecutor.executeStep(FlowJob.java:135)




	at org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:60)




	at org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:144)




	at org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:124)




	at org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:103)




	at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:250)




	at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:110)




	at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:49)




	at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:105)




	at ch.vd.dse.sesa.adse.batch.common.util.AdseJobRunner.run(AdseJobRunner.java:69)




	at ch.vd.dse.sesa.adse.batch.common.util.AdseJobRunner.run(AdseJobRunner.java:100)




	at ch.vd.dse.sesa.adse.batch.procofiev.export.Main.main(Main.java:33)




Caused by: java.io.IOException: Stream closed




	at sun.nio.cs.StreamEncoder.ensureOpen(Unknown Source)




	at sun.nio.cs.StreamEncoder.write(Unknown Source)




	at sun.nio.cs.StreamEncoder.write(Unknown Source)




	at java.io.Writer.write(Unknown Source)




	at org.springframework.batch.support.transaction.TransactionAwareBufferedWriter$1.afterCompletion(TransactionAwareBufferedWriter.java:67)




	... 26 more






I think this is a bug. Wierdly, the files are as follows:
out.1:






file header




foo1




foo2






out.2:






file footer






If I have two lines in the input file, everything works correctly, but more than two does not work. If I change the commit-interval to 200, then I get three lines in one file, which is not the behaviour wanted.</description>
			<version>2.0.0</version>
			<fixedVersion>2.1.0.M3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemWriterTests.java</file>
			<file type="M">org.springframework.batch.support.transaction.TransactionAwareBufferedWriter.java</file>
			<file type="M">org.springframework.batch.item.file.AbstractMultiResourceItemWriterTests.java</file>
			<file type="M">org.springframework.batch.item.file.MultiResourceItemWriterFlatFileTests.java</file>
			<file type="M">org.springframework.batch.support.transaction.TransactionAwareBufferedWriterTests.java</file>
			<file type="M">org.springframework.batch.item.file.MultiResourceItemWriterXmlTests.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemWriter.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemWriter.java</file>
			<file type="M">org.springframework.batch.item.file.MultiResourceItemWriter.java</file>
		</fixedFiles>
	</bug>
	<bug id="1460" opendate="2009-12-21 07:42:12" fixdate="2009-12-22 22:25:53" resolution="Fixed">
		<buginformation>
			<summary>Rownum clauses are illegal in DerbyPagingQueryProvider (plus additional fix to Oracle)</summary>
			<description>Rownum clauses are illegal in DerbyPagingQueryProvider (plus additional fix to Oracle)</description>
			<version>2.0.4</version>
			<fixedVersion>2.0.Maintenance, 2.1.0.M4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.support.DerbyPagingQueryProvider.java</file>
			<file type="M">org.springframework.batch.support.DatabaseTypeTestUtils.java</file>
			<file type="M">org.springframework.batch.item.database.support.SqlPagingQueryUtils.java</file>
			<file type="M">org.springframework.batch.item.database.support.OraclePagingQueryProvider.java</file>
			<file type="M">org.springframework.batch.item.database.support.SqlWindowingPagingQueryProvider.java</file>
			<file type="M">org.springframework.batch.item.database.support.OraclePagingQueryProviderTests.java</file>
			<file type="M">org.springframework.batch.item.database.support.DerbyPagingQueryProviderTests.java</file>
			<file type="M">org.springframework.batch.support.DatabaseTypeIntegrationTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1471" opendate="2009-12-30 04:03:36" fixdate="2009-12-30 04:08:58" resolution="Fixed">
		<buginformation>
			<summary>Typo in FaultTolerantStepFactoryBean </summary>
			<description>





18:56:34.578 [main] WARN  o.s.b.c.s.i.FaultTolerantStepFactoryBean - Synchronous TaskExecutor detected (class org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor) with ItemStream reader.  This is probably an error, and may lead to incorrect restart data being stored.






Should read Asynchronous TaskExecutor detected</description>
			<version>2.1.0.M4</version>
			<fixedVersion>2.1.0.RC1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBean.java</file>
		</fixedFiles>
	</bug>
	<bug id="1473" opendate="2009-12-31 03:29:04" fixdate="2010-01-03 18:33:44" resolution="Fixed">
		<buginformation>
			<summary>Components that create application contexts should look for *Aware in the infrastructure beans it copies down to the child context</summary>
			<description>Was: ClassPathXmlJobLoader should look for *Aware in the infrastructure beans it copies down to the child context, otherwise they will look in the wrong place for their beans etc.</description>
			<version>2.1.0.M4</version>
			<fixedVersion>2.1.0.RC1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.support.GroupAwareJob.java</file>
			<file type="D">org.springframework.batch.core.configuration.support.ClassPathXmlJobLoaderContextTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.support.ClassPathXmlApplicationContextFactoryTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.support.OsgiBundleXmlApplicationContextFactoryTests.java</file>
			<file type="D">org.springframework.batch.core.configuration.support.ClassPathXmlJobLoaderTests.java</file>
			<file type="D">org.springframework.batch.core.configuration.support.ClassPathXmlJobLoader.java</file>
			<file type="M">org.springframework.batch.core.launch.support.JobRegistryBackgroundJobRunner.java</file>
			<file type="M">org.springframework.batch.core.configuration.support.OsgiBundleXmlApplicationContextFactory.java</file>
			<file type="M">org.springframework.batch.core.configuration.support.ClassPathXmlJobRegistry.java</file>
			<file type="M">org.springframework.batch.core.configuration.support.ClassPathXmlApplicationContextFactory.java</file>
			<file type="M">org.springframework.batch.core.launch.support.JobRegistryBackgroundJobRunnerTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1476" opendate="2010-01-03 19:33:47" fixdate="2010-01-03 20:18:08" resolution="Fixed">
		<buginformation>
			<summary>Filter counts too high when write skips happen</summary>
			<description>Filter counts look too high when write skips happen</description>
			<version>2.1.0.M4</version>
			<fixedVersion>2.1.0.RC1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBeanRollbackTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantChunkProcessorTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantChunkProcessor.java</file>
		</fixedFiles>
	</bug>
	<bug id="1477" opendate="2010-01-04 03:09:01" fixdate="2010-01-04 03:09:26" resolution="Fixed">
		<buginformation>
			<summary>Allow excludes (as well as includes) in retryable exceptions</summary>
			<description>Allow excludes (as well as includes) in retryable exceptions</description>
			<version>2.1.0.M4</version>
			<fixedVersion>2.1.0.RC1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.ChunkElementParserTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1422" opendate="2009-10-16 05:38:30" fixdate="2010-01-13 03:56:49" resolution="Fixed">
		<buginformation>
			<summary>HibernateCursorItemReader causes OutOfMemoryError when skipping large sets of data</summary>
			<description>In case of restarting of previously failed job, HibernateCursorItemReader skips already processed records by simply reading them upto desired index, i.e. uses default implementation from AbstractItemCountingItemStreamItemReader.jumpToItem(). This results in all skipped entities being loaded into hibernate session which can lead to OutOfMemoryError in case of large result sets. 
Possible solution:
1) Remove ScrollMode.FORWARD_ONLY from cursor creation (line 198), which will be then defaulted to ScrollMode.SCROLL_INSENSITIVE
2) Override jumpToItem() method in following way:
    @Override
    protected void jumpToItem( int itemIndex ) throws Exception 
{
        cursor.setRowNumber(itemIndex - 1);
    }</description>
			<version>2.0.0</version>
			<fixedVersion>2.1.0.RC1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.HibernatePagingItemReader.java</file>
			<file type="M">org.springframework.batch.item.database.HibernateCursorItemReader.java</file>
			<file type="M">org.springframework.batch.item.database.HibernateItemReaderHelper.java</file>
		</fixedFiles>
	</bug>
	<bug id="1418" opendate="2009-09-28 00:55:30" fixdate="2010-01-17 13:40:25" resolution="Fixed">
		<buginformation>
			<summary>Upon job restart, step with FlatFileItemReader doesn&amp;apos;t honor skippable-exception-classes</summary>
			<description>Upon restarting a failed step, the reader (FlatFileItemReader) tries to parse the file from the beginning as it tries to reach the point from where it has to pick up after the last failure. Along the way, the reader invokes the lineTokenizer and the fieldSetMapper for each of the already processed records. This appears to be far too much work for no gain when the point is to quickly get to the last record read from the file that was successfully committed. 
More importantly, during this recovery phase, the parsing exercise triggers parsing exceptions but the batch framework doesn&amp;amp;apos;t honor the "skippable-exception-classes" instruction. This causes exceptions (that should be skipped) to become fatal and the job fails to restart.
More information is available in the "Spring Forum Reference" thread.</description>
			<version>2.0.3</version>
			<fixedVersion>2.1.0.RC1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReader.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemReader.java</file>
			<file type="M">org.springframework.batch.item.database.HibernateCursorItemReader.java</file>
		</fixedFiles>
	</bug>
	<bug id="1490" opendate="2010-01-18 17:59:38" fixdate="2010-01-18 20:08:00" resolution="Fixed">
		<buginformation>
			<summary>StaxEventItemWriter outputs invalid xml if step handling is failed and retried when handling the first chunk of data</summary>
			<description>When reader fails handling the data of the first chunk defined by step commitInterval and the step is retried the writer starts the writing from wrong place in xml output file. The JUnit testcase to repeat the problem can be found from the Spring Batch forum post (http://forum.springsource.org/showthread.php?t=71239).</description>
			<version>2.1.0.RC1</version>
			<fixedVersion>2.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemWriter.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemWriterTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1494" opendate="2010-01-27 01:27:41" fixdate="2010-01-27 21:34:51" resolution="Fixed">
		<buginformation>
			<summary>FetchSize not accessible in HibernateCursorItemReader</summary>
			<description>In 2.1.0.RC1, &amp;amp;apos;setFetchSize&amp;amp;apos; is no longer an accessible property on &amp;amp;apos;HibernateCursorItemReader&amp;amp;apos;.  Appears to now be a private variable (defaulting to 0) encapsulated on &amp;amp;apos;HibernateItemReaderHelper&amp;amp;apos;.</description>
			<version>2.1.0.RC1</version>
			<fixedVersion>2.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.AbstractCursorItemReader.java</file>
			<file type="M">org.springframework.batch.core.step.item.SimpleStepFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.item.database.HibernateCursorItemReaderCommonTests.java</file>
			<file type="M">org.springframework.batch.item.database.HibernateCursorItemReader.java</file>
			<file type="M">org.springframework.batch.item.database.HibernatePagingItemReader.java</file>
			<file type="M">org.springframework.batch.core.step.item.SimpleStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.item.database.HibernateItemReaderHelper.java</file>
		</fixedFiles>
	</bug>
	<bug id="1498" opendate="2010-01-31 04:11:15" fixdate="2010-01-31 04:26:21" resolution="Fixed">
		<buginformation>
			<summary>JdbcPagingItemReader does not apply parameter values correctly on restart</summary>
			<description>JdbcPagingItemReader does not apply parameter values correctly on restart</description>
			<version>2.1.0.RC1</version>
			<fixedVersion>2.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.IbatisPagingItemReaderParameterTests.java</file>
			<file type="M">org.springframework.batch.item.database.AbstractPagingItemReaderParameterTests.java</file>
			<file type="M">org.springframework.batch.item.database.JpaPagingItemReaderNativeQueryIntegrationTests.java</file>
			<file type="M">org.springframework.batch.item.database.JdbcPagingItemReaderClassicParameterTests.java</file>
			<file type="M">org.springframework.batch.item.database.JpaPagingItemReaderParameterTests.java</file>
			<file type="M">org.springframework.batch.item.database.JdbcPagingItemReaderNamedParameterTests.java</file>
			<file type="M">org.springframework.batch.item.database.JdbcPagingItemReader.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.AbstractStepParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.PartitionStepParserTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1499" opendate="2010-01-31 04:38:57" fixdate="2010-01-31 04:41:09" resolution="Fixed">
		<buginformation>
			<summary>SqlServerPagingQueryProvider needs an alias in the jump to subquery</summary>
			<description>SqlServerPagingQueryProvider needs an alias in the jump to subquery.  Derby already has one; maybe Sybase needs it (someone will have to tell us if so).</description>
			<version>2.0.4</version>
			<fixedVersion>2.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.support.SqlServerPagingQueryProvider.java</file>
			<file type="M">org.springframework.batch.item.database.support.SqlServerPagingQueryProviderTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1497" opendate="2010-01-29 18:22:06" fixdate="2010-01-31 04:42:29" resolution="Duplicate">
		<buginformation>
			<summary>SqlServerPagingQueryProvider should use an alias for the inner query in a jump-to-item query</summary>
			<description></description>
			<version>2.0.4</version>
			<fixedVersion>2.0.Maintenance, 2.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.support.SqlServerPagingQueryProvider.java</file>
			<file type="M">org.springframework.batch.item.database.support.SqlServerPagingQueryProviderTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1502" opendate="2010-02-01 00:25:24" fixdate="2010-02-02 08:03:37" resolution="Fixed">
		<buginformation>
			<summary>HibernatePagingItemReader doesn&amp;apos;t close sessions</summary>
			<description>HibernatePagingItemReader is exhausting DB connections by never closing sessions.
It appears to open a new session for each chunk in &amp;amp;apos;createQuery&amp;amp;apos;, overwriting the previous in &amp;amp;apos;statefulSession&amp;amp;apos;, but never closes it.</description>
			<version>2.1.0.RC1</version>
			<fixedVersion>2.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.HibernateItemReaderHelper.java</file>
		</fixedFiles>
	</bug>
	<bug id="1506" opendate="2010-02-03 08:19:41" fixdate="2010-02-03 14:28:12" resolution="Fixed">
		<buginformation>
			<summary>problem when using refcursor in StoredProcedureItemReader</summary>
			<description>When using the StoredProcedureItemReader, as I understand it, in order to use a refcursor, the "refCursorPosition" property must be set to a value greater than zero  pointing to the position of the declared parameter that is intended to be a ref cursor.  However, when I set the said property to 3 (i had 2 IN parameters and 1 OUT parameter), an exception is thrown saying:
"refCursorPosition specified as 3 but there are only 3 parameters defined"
Same exception is thrown if I specify "2" and move my out parameter as the 2nd parameter  this time saying:
"refCursorPosition specified as 2 but there are only 3 parameters defined"
Looking at the code, it looks like the culprit is this assert statement in the openCursor method:
	Assert.state(refCursorPosition == 0 || refCursorPosition &amp;gt; parameters.length, 
			"refCursorPosition specified as " + refCursorPosition + " but there are only " + 
			parameters.length + " parameters defined.");
The 2nd condition should have been:  refCursorPosition &amp;lt;= parameters.length</description>
			<version>2.1.0.RC1</version>
			<fixedVersion>2.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.StoredProcedureItemReader.java</file>
			<file type="M">org.springframework.batch.item.database.StoredprocedureItemReaderConfigTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1501" opendate="2010-01-31 20:41:13" fixdate="2010-02-03 20:06:08" resolution="Fixed">
		<buginformation>
			<summary>JdbcPagingItemReader failing with order key other than first column in select</summary>
			<description>When I made tests on JdbcPagingItemReader, I face the following problems: I throws an exception while I process an item returned by JdbcPagingItemReader. The jobs is in failure. When I restart the job, JdbcPagingItemReader becomes unstable and infinitely returns objects (objects rightly extracted from the database).
This problems appears when I sort items by something else than the identifier (the account balance for example).






	&amp;lt;bean id="queryProvider" class="org.springframework.batch.item.database.support.SqlPagingQueryProviderFactoryBean" scope="step"&amp;gt;




		&amp;lt;property name="dataSource" ref="dataSource" /&amp;gt;




		&amp;lt;property name="selectClause" value="select OBJECTID, VERSION, ACCOUNTID, BALANCE" /&amp;gt;




		&amp;lt;property name="fromClause" value="from Account" /&amp;gt;




		&amp;lt;property name="whereClause" value="#{jobParameters[query.where]}" /&amp;gt;




		&amp;lt;property name="sortKey" value="Balance" /&amp;gt;




	&amp;lt;/bean&amp;gt;	









	&amp;lt;bean id="jdbcPagingItemReader"




		class="org.springframework.batch.item.database.JdbcPagingItemReader" scope="step"&amp;gt;




		&amp;lt;property name="dataSource" ref="dataSource" /&amp;gt;




		&amp;lt;property name="queryProvider" ref="queryProvider" /&amp;gt;




		&amp;lt;property name="rowMapper"&amp;gt;




			&amp;lt;bean class="com.bsb.sf.incubator.batch.model.AccountRowMapper" /&amp;gt;




		&amp;lt;/property&amp;gt;




		&amp;lt;property name="pageSize" value="5"/&amp;gt;				




		&amp;lt;property name="saveState" value="true" /&amp;gt;




	&amp;lt;/bean&amp;gt;





</description>
			<version>2.1.0.M4</version>
			<fixedVersion>2.1.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.support.AbstractSqlPagingQueryProvider.java</file>
			<file type="M">org.springframework.batch.sample.iosample.JdbcPagingRestartIntegrationTests.java</file>
			<file type="M">org.springframework.batch.item.database.JdbcPagingItemReader.java</file>
			<file type="M">org.springframework.batch.item.database.PagingQueryProvider.java</file>
		</fixedFiles>
	</bug>
	<bug id="1503" opendate="2010-02-01 00:52:14" fixdate="2010-02-07 01:29:37" resolution="Fixed">
		<buginformation>
			<summary>JobExecution marked COMPLETE on failure to save step execution metadata</summary>
			<description>Exception occurs in the writer, there&amp;amp;apos;s a failure in persisting step context- the job status is set to COMPLETE instead of FAILED.
Steps to create

Change the batch schema EXIT_MESSAGE VARCHAR(2500) to EXIT_MESSAGE VARCHAR(25).
Force the writer to throw some exception.
Error occurs while persisting the step context but the job context gets updated to COMPLETE.

</description>
			<version>2.0.4</version>
			<fixedVersion>2.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.job.flow.support.state.EndState.java</file>
			<file type="M">org.springframework.batch.core.step.item.TaskletStepExceptionTests.java</file>
			<file type="M">org.springframework.batch.core.job.SimpleJobFailureTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1507" opendate="2010-02-07 20:20:18" fixdate="2010-02-07 20:37:41" resolution="Fixed">
		<buginformation>
			<summary>FlowJob.getStep() only looks at state names, not step names</summary>
			<description>FlowJob.getStep() only looks at state names, not step names, so anyone using the StepLocator interface is in for a surprise.  The state name happens to be the same as the step name in the existing uint tests (irony), but when created by the XML namespace parsers they are different.</description>
			<version>2.1.0</version>
			<fixedVersion>2.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.StepWithSimpleTaskJobParserTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.StepNameTests.java</file>
			<file type="M">org.springframework.batch.core.job.flow.FlowJobTests.java</file>
			<file type="M">org.springframework.batch.core.job.flow.FlowJob.java</file>
		</fixedFiles>
	</bug>
	<bug id="1513" opendate="2010-02-14 21:52:52" fixdate="2010-02-26 23:49:58" resolution="Complete">
		<buginformation>
			<summary>HibernateItemReaderHelper requires queryProvider field to be an instance of AbstractHibernateQueryProvider</summary>
			<description>HibernateItemReaderHelper.afterPropertiesSet() method contains the following code:
Assert.state(queryProvider instanceof AbstractHibernateQueryProvider,
					"Hibernate query provider must be set");
I think this is not needed as the queryProvider field is not cast to AbstractHibernateQueryProvider within HibernateItemReaderHelper.
Also if query provider defined as a scoped bean:
&amp;lt;bean id="myQueryProvider" class="MyQueryProvider" scope="step" /&amp;gt; 
proxy is not an instance of AbstractHibernateQueryProvider even though MyQueryProvider extends AbstractHibernateQueryProvider   </description>
			<version>2.1.0</version>
			<fixedVersion>2.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.HibernateItemReaderHelper.java</file>
		</fixedFiles>
	</bug>
	<bug id="1510" opendate="2010-02-11 18:02:13" fixdate="2010-02-28 22:54:36" resolution="Complete">
		<buginformation>
			<summary>List of stepnames incomplete for nested flow job</summary>
			<description>The function  getStepNames on a job returns only those step names from a FlowJob, whose steps are defined directly within the flow.
But if the job contains nested flows the list of stepnames is incomplete. Only those of the outermost flow (the job itself) are returned but none of the nested flow(s).
If the job does only reference sub flows the list will be empty at all.
The function should return the complete list of steps, including nested flows within subflows (recursively)</description>
			<version>2.1.0</version>
			<fixedVersion>2.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.StepNameTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.SimpleFlowFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.job.flow.FlowJobTests.java</file>
			<file type="M">org.springframework.batch.core.job.flow.FlowJob.java</file>
			<file type="M">org.springframework.batch.core.job.flow.support.state.FlowState.java</file>
			<file type="M">org.springframework.batch.core.job.flow.support.state.SplitState.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.SplitJobParserTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1525" opendate="2010-03-01 20:24:59" fixdate="2010-03-02 03:17:41" resolution="Fixed">
		<buginformation>
			<summary>ExitStatus description can be null when re-hyrated from  Oracle</summary>
			<description>The equals implementation (or the toString) of ExitStatus may not work legitimately in all cases.
In Oracle, an empty String is considered as null and fails our build because we assert the exit status matched the expected (that is, a given exit code and an empty exit description). 
We got this
java.lang.AssertionError: expected:&amp;lt;exitCode=COMPLETED WITH ERROR;exitDescription=&amp;gt; but was:&amp;lt;exitCode=COMPLETED WITH ERROR;exitDescription=null&amp;gt;
It&amp;amp;apos;s not a big deal and we can deal with that in our test utilities but if the equals supported that use case, that would be great since we don&amp;amp;apos;t really want to put a &amp;amp;apos;null&amp;amp;apos; exit description. Besides the default constructor does this
public ExitStatus(String exitCode) {
   this(exitCode, "");
}
</description>
			<version>2.1.0</version>
			<fixedVersion>2.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.ExitStatusTests.java</file>
			<file type="M">org.springframework.batch.core.ExitStatus.java</file>
		</fixedFiles>
	</bug>
	<bug id="1522" opendate="2010-03-01 00:07:36" fixdate="2010-03-02 22:48:03" resolution="Complete">
		<buginformation>
			<summary>Intermittent failure of FaultTolerantStepFactoryBean in multi-threaded test</summary>
			<description>Intermittent failure of FaultTolerantStepFactoryBean in multi-threaded test.  Could be nothing (because the test FaultTolerantStepFactoryBeanRollbackTests uses a MapJobRepositoryFactoryBean).</description>
			<version>2.1.0</version>
			<fixedVersion>2.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.tasklet.StepExecutorInterruptionTests.java</file>
			<file type="M">org.springframework.batch.core.step.tasklet.TaskletStep.java</file>
			<file type="M">org.springframework.batch.core.StepExecution.java</file>
			<file type="M">org.springframework.batch.core.repository.support.SimpleJobRepository.java</file>
			<file type="M">org.springframework.batch.core.test.step.FaultTolerantStepFactoryBeanRollbackTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.Chunk.java</file>
			<file type="M">org.springframework.batch.core.step.ThreadStepInterruptionPolicy.java</file>
			<file type="M">org.springframework.batch.support.transaction.TransactionAwareProxyFactory.java</file>
		</fixedFiles>
	</bug>
	<bug id="1526" opendate="2010-03-04 00:38:03" fixdate="2010-03-04 00:57:32" resolution="Fixed">
		<buginformation>
			<summary>Memory leak in web deployments because ThreadLocal is not nulled out in ChunkMonitor</summary>
			<description>The Tomcat leak detection in 6.0.24 caught this one: it&amp;amp;apos;s a tiny leak but the thread local in ChunkMonitor is not nulled out so re-deployment of a web application can result in a memory leak.  Tomcat fixes it (from 6.0.24) so it&amp;amp;apos;s probably not a big deal for existing users.</description>
			<version>2.0.0</version>
			<fixedVersion>2.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.ChunkMonitor.java</file>
		</fixedFiles>
	</bug>
	<bug id="1528" opendate="2010-03-08 12:01:38" fixdate="2010-03-09 18:31:11" resolution="Complete">
		<buginformation>
			<summary>Namespace context partition element requires bean with name "transactionManager"</summary>
			<description>When trying to use the batch:partition context element, I get the error:
Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named &amp;amp;apos;transactionManager&amp;amp;apos; is defined
Looking at the code, it looks like a problem in CoreNamespacePostProcessor.injectDefaults at line 136. The processor checks for a transactionManager and if not found, uses the default. However the AbstractStepParser.parsePartition method never looks for or sets a transaction manager. This results in a lookup to the default transaction manager which fails.
The bean configuration is:
&amp;lt;batch:job id="simpleJob" job-repository="jobRepository"&amp;gt;
        &amp;lt;batch:step id="step1.master"&amp;gt;
          &amp;lt;batch:partition step="step1" partitioner="partitioner"&amp;gt;
              &amp;lt;batch:handler grid-size="10" task-executor="keyValueExtractionTaskExecutor"/&amp;gt;
          &amp;lt;/batch:partition&amp;gt;
        &amp;lt;/batch:step&amp;gt;
    &amp;lt;/batch:job&amp;gt;
        &amp;lt;batch:step id="step1"&amp;gt;
            &amp;lt;batch:tasklet transaction-manager="catalogTransactionManager"&amp;gt;
                &amp;lt;batch:chunk reader="granuleStaleItemReader" writer="keyValueItemWriter"
                    commit-interval="20" processor="granuleKeyValueExtractionProcessor"/&amp;gt;
            &amp;lt;/batch:tasklet&amp;gt;
        &amp;lt;/batch:step&amp;gt;
The stack trace is attached.</description>
			<version>2.1.0</version>
			<fixedVersion>2.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParserStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.CoreNamespacePostProcessor.java</file>
		</fixedFiles>
	</bug>
	<bug id="1542" opendate="2010-03-27 19:22:32" fixdate="2010-03-27 19:23:05" resolution="Complete">
		<buginformation>
			<summary>Thread safety in JobExecution and StepExecution collections</summary>
			<description>The collections inside JobExecution and StepExecution should have copy-on-write concurrency protection.  The only place we are likely to see the effect is in really fast step and job executions using the MapJobRepository (which is only thread safe since BATCH-1541 anyway).</description>
			<version>2.0.0</version>
			<fixedVersion>2.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.StepExecution.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.MapJobExecutionDao.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.MapExecutionContextDaoTests.java</file>
			<file type="M">org.springframework.batch.core.repository.support.SimpleJobRepository.java</file>
			<file type="M">org.springframework.batch.core.job.flow.FlowJobTests.java</file>
			<file type="M">org.springframework.batch.core.job.flow.StateSupport.java</file>
			<file type="M">org.springframework.batch.core.JobExecution.java</file>
			<file type="M">org.springframework.batch.support.SerializationUtils.java</file>
			<file type="M">org.springframework.batch.core.test.step.FaultTolerantStepFactoryBeanRollbackTests.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.MapJobInstanceDao.java</file>
			<file type="M">org.springframework.batch.core.partition.support.SimpleStepExecutionSplitterTests.java</file>
			<file type="M">org.springframework.batch.support.transaction.TransactionAwareProxyFactory.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.MapStepExecutionDao.java</file>
		</fixedFiles>
	</bug>
	<bug id="1545" opendate="2010-04-03 02:29:31" fixdate="2010-04-03 03:09:39" resolution="Fixed">
		<buginformation>
			<summary>FlatFileItemWriter logs as JdbcBatchItemWriter</summary>
			<description>Updating your log configuration (log4j.properties) to see logs specifically from org.springframework.batch.item.file.FlatFileItemWriter does not work because that class incorrectly identifies itself as org.springframework.batch.item.database.JdbcBatchItemWriter.
A patch is attached, which has been verified with a full maven build against the trunk.</description>
			<version>2.1.0</version>
			<fixedVersion>2.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.FlatFileItemWriter.java</file>
		</fixedFiles>
	</bug>
	<bug id="1547" opendate="2010-04-03 20:25:48" fixdate="2010-04-04 03:05:26" resolution="Fixed">
		<buginformation>
			<summary>ExecutionContextPromotionListener strict flag misinterpreted in listener code</summary>
			<description>See BATCH-1309 for the original issue.</description>
			<version>2.0.3</version>
			<fixedVersion>2.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.listener.ExecutionContextPromotionListener.java</file>
			<file type="M">org.springframework.batch.core.listener.ExecutionContextPromotionListenerTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1546" opendate="2010-04-03 03:15:57" fixdate="2010-04-05 18:50:05" resolution="Complete">
		<buginformation>
			<summary>Some issues with pagination in Oracle</summary>
			<description>Some issues with pagination in Oracle were reported in the forum, but not raised in JIRA.  Here is a ticket to track the investigation...  http://forum.springsource.org/showthread.php?t=85919</description>
			<version>2.1.0</version>
			<fixedVersion>2.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.support.OraclePagingQueryProvider.java</file>
			<file type="M">org.springframework.batch.item.database.JdbcPagingRestartIntegrationTests.java</file>
			<file type="M">org.springframework.batch.item.support.AbstractItemCountingItemStreamItemReader.java</file>
			<file type="M">org.springframework.batch.item.database.support.SqlPagingQueryUtils.java</file>
			<file type="M">org.springframework.batch.item.database.support.OraclePagingQueryProviderTests.java</file>
			<file type="M">org.springframework.batch.item.database.support.SqlPagingQueryUtilsTests.java</file>
			<file type="M">org.springframework.batch.item.database.JdbcPagingItemReaderAsyncTests.java</file>
			<file type="M">org.springframework.batch.sample.CustomerFilterJobFunctionalTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.StepNameTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1551" opendate="2010-04-11 17:48:51" fixdate="2010-04-22 20:33:26" resolution="Complete">
		<buginformation>
			<summary>Db2PagingQueryProvider needs an alias in the jump to subquery </summary>
			<description>same Problem as in BATCH-1499 but for DB2</description>
			<version>2.1.0</version>
			<fixedVersion>2.1.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.support.Db2PagingQueryProviderTests.java</file>
			<file type="M">org.springframework.batch.item.database.support.Db2PagingQueryProvider.java</file>
		</fixedFiles>
	</bug>
	<bug id="1567" opendate="2010-05-13 18:38:43" fixdate="2010-05-13 18:58:46" resolution="Complete">
		<buginformation>
			<summary>When step encounters error saving ExecutionContext it tries to stop the job but fails</summary>
			<description>When step encounters error saving ExecutionContext it tries to stop the job but fails.  An error in the JobRepository is always fatal, so the step marks itself as status=UNKNOWN and sends a stop signal to the job.  But the latter is ignored and subsequent steps execute normally!</description>
			<version>2.0.0</version>
			<fixedVersion>2.1.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.job.flow.FlowJobTests.java</file>
			<file type="M">org.springframework.batch.core.job.flow.JobFlowExecutor.java</file>
			<file type="M">org.springframework.batch.core.job.SimpleJobFailureTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1569" opendate="2010-05-17 05:42:14" fixdate="2010-05-17 22:12:56" resolution="Fixed">
		<buginformation>
			<summary>MultiResourceItemReader.getCurrentResource cause java.lang.ArrayIndexOutOfBoundsException when .read() was not called</summary>
			<description>Only after first .read(), variable currentResource got a value greather or equal to zero(0). So if stream was openned, or not read yet, one activation on getCurrentResource method generates ArrayIndexOutOfBoundsException.
Below a proposed fix:
	public Resource getCurrentResource() {
		if (currentResource &amp;gt;= resources.length ) 
{ //proposed: || currentResource  &amp;lt; 0
			return null;
		}
		return resources[currentResource];
	}</description>
			<version>2.1.1</version>
			<fixedVersion>2.1.2</fixedVersion>
			<type>Defect</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.MultiResourceItemReaderIntegrationTests.java</file>
			<file type="M">org.springframework.batch.item.file.MultiResourceItemReader.java</file>
		</fixedFiles>
	</bug>
	<bug id="1571" opendate="2010-05-18 14:15:25" fixdate="2010-05-18 18:54:48" resolution="Complete">
		<buginformation>
			<summary>PostgresPagingQueryProvider generateJumpToItemQuery generates bad SQL</summary>
			<description>Using the Spring Batch Admin (1.0.1.BUILD-SNAPSHOT), click EXECUTIONS, select NEXT page (the numbers of EXECUTIONS is exceeding 20) ,generate following error:
org.springframework.jdbc.BadSqlGrammarException: StatementCallback; bad SQL grammar [SELECT E.JOB_EXECUTION_ID AS SORT_KEY FROM BATCH_JOB_EXECUTION E, BATCH_JOB_INSTANCE I WHERE E.JOB_INSTANCE_ID=I.JOB_INSTANCE_ID ORDER BY E.JOB_EXECUTION_ID DESC LIMIT 19 1]; nested exception is org.postgresql.util.PSQLException: ERROR: syntax error at or near "1"
The problem is due to the generated SQL based on the code below. I have suggested a minor fix for the problem. 
In addition, I believe the offset value does not need to be minus one as Postgres will automatically get the start value for next page correctly. (unless you have another reason for it)
&amp;lt;code&amp;gt;
	public String generateJumpToItemQuery(int itemIndex, int pageSize) 
{
		int page = itemIndex / pageSize;
--&amp;gt;		int offset = (page * pageSize) - 1;
--&amp;gt;		offset = offset&amp;lt;0 ? 0 : offset;

--&amp;gt;		String limitClause = new StringBuilder().append("LIMIT ").append(offset).append(" 1").toString();
		return SqlPagingQueryUtils.generateLimitJumpToQuery(this, limitClause);
	}
&amp;lt;/code&amp;gt;
Note: debug variables:
itemIndex = 20
pageSize = 20
page = 1
offset = 1
limitClause = LIMIT 19 1
Code Fix suggestion:
		int offset = (page * pageSize);
                String limitClause = new StringBuilder().append("LIMIT ").append(pageSize).append(" OFFSET ").append(offset).toString();
Thanks,
Eng</description>
			<version>2.0.0</version>
			<fixedVersion>2.1.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.support.PostgresPagingQueryProviderTests.java</file>
			<file type="M">org.springframework.batch.item.database.JdbcPagingQueryIntegrationTests.java</file>
			<file type="M">org.springframework.batch.item.database.IbatisPagingItemReaderAsyncTests.java</file>
			<file type="M">spring-batch-infrastructure-tests.src.test.java.test.jdbc.datasource.DataSourceInitializer.java</file>
			<file type="M">org.springframework.batch.item.database.support.PostgresPagingQueryProvider.java</file>
		</fixedFiles>
	</bug>
	<bug id="1573" opendate="2010-05-21 09:12:14" fixdate="2010-05-23 15:20:40" resolution="Complete">
		<buginformation>
			<summary>End transition states will cause the batch job to finish with an Unknown status if the namespace prefix is used.</summary>
			<description>If you run the following job:
&amp;lt;batch:job id="job1"&amp;gt;
		&amp;lt;batch:step id="noopStep" parent="noopStep1"&amp;gt;
            &amp;lt;batch:next on="COMPLETED" to="step4" /&amp;gt;
            &amp;lt;batch:end on="NOOP" /&amp;gt;
            &amp;lt;batch:fail on="*" /&amp;gt;
        &amp;lt;/batch:step&amp;gt;
        &amp;lt;batch:step id="step4" parent="step45" /&amp;gt;
	&amp;lt;/batch:job&amp;gt;
    &amp;lt;batch:step id="noopStep1"&amp;gt;
        &amp;lt;batch:tasklet ref="noopTasklet" /&amp;gt;
    &amp;lt;/batch:step&amp;gt;
And the first step returns an exit status of NOOP, the job will finish with a BatchStatus of UNKNOWN, and an ExitStatus of NOOP.  If you remove the batch namespace from the element, it will complete with a BatchStatus of COMPLETED and an Exit status of the same.
This is because in AbstractFlowParser.getBatchStatusFromEndTransitionName() line 393, the element name is checked to see if it is an &amp;amp;apos;End transition&amp;amp;apos;.  However, this check doesn&amp;amp;apos;t strip out the batch: from the front of the element first.
I have attached a failing unit test as well.  </description>
			<version>2.1.1</version>
			<fixedVersion>2.1.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.AbstractFlowParser.java</file>
		</fixedFiles>
	</bug>
	<bug id="1574" opendate="2010-05-25 03:05:03" fixdate="2010-05-25 03:32:58" resolution="Complete">
		<buginformation>
			<summary>TaskExecutor configuration ignored in 2.1 namespace for &lt;tasklet/&gt; with no &lt;chunk/&gt;</summary>
			<description>The task-executor attribute moved in the schema and the factory bean didn&amp;amp;apos;t accommodate the change.</description>
			<version>2.1.0</version>
			<fixedVersion>2.1.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParserStepFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParserStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.step.tasklet.TaskletStep.java</file>
		</fixedFiles>
	</bug>
	<bug id="1582" opendate="2010-06-15 08:01:54" fixdate="2010-06-23 19:43:26" resolution="Complete">
		<buginformation>
			<summary>DefaultStepExecutionAggregator can simply ignore null or empty input</summary>
			<description>Current implementation of DefaultStepExecutionAggregator validates the arguments and restricts null or empty sets of executions. In my opinion the validation is too strict and prohibit usage of DefaultStepExecutionAggregator in various cases when using namespace support for partitions (there is no possibility to set the aggregator when using batch namespace). I have implementation of the partitioner that ignores gridSize and in certain occasions return empty map of executions. I believe the framework should be able to deal with such situations.
The strict validation seems odd to me also in context of other default components provided by the framework to deal with partitioning. For instance, TaskExecutorPartitionHandler can process empty collections of executions returned by the splitter. SimpleStepExecutionSplitter is also fine.</description>
			<version>2.1.1</version>
			<fixedVersion>2.1.2</fixedVersion>
			<type>Defect</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.partition.support.DefaultStepExecutionAggregator.java</file>
			<file type="M">org.springframework.batch.core.partition.support.DefaultStepExecutionAggregatorTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1543" opendate="2010-03-30 01:18:47" fixdate="2010-06-23 20:33:12" resolution="Complete">
		<buginformation>
			<summary>OrderedComposite cannot register two items with the same order</summary>
			<description>We have added a custom listener that extends StepListener and OrderedComposite is very handy to use when multiple listeners are involved. Unfortunately, it&amp;amp;apos;s not public. 
Can you make it public or part of the API?</description>
			<version>2.1.0</version>
			<fixedVersion>2.1.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.listener.OrderedCompositeTests.java</file>
			<file type="M">org.springframework.batch.core.listener.OrderedComposite.java</file>
		</fixedFiles>
	</bug>
	<bug id="1587" opendate="2010-06-24 03:15:06" fixdate="2010-06-24 23:26:43" resolution="Complete">
		<buginformation>
			<summary>DefaultFieldSetFactory is not setting the numberFormat in the enhance() call</summary>
			<description>enhance is testing for (numberFormat!=null) but then calling fieldSet.setDateFormat(dateFormat);
	private FieldSet enhance(DefaultFieldSet fieldSet) {
		if (dateFormat!=null) 
{
			fieldSet.setDateFormat(dateFormat);
		}
		if (numberFormat!=null) {			fieldSet.setDateFormat(dateFormat);		}
 
		return fieldSet;
	}</description>
			<version>2.1.1</version>
			<fixedVersion>2.1.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.transform.DefaultFieldSetFactory.java</file>
		</fixedFiles>
	</bug>
	<bug id="1588" opendate="2010-06-28 00:24:35" fixdate="2010-06-28 03:56:29" resolution="Complete">
		<buginformation>
			<summary>Job Excecution Listener - XML Namespace parsing fails for methods named different to "beforeJob", "afterJob"</summary>
			<description>The following XML configuration for a job listener does not work as the two configured methods are not called:
-------- XML - Configuration --------
&amp;lt;job id="..."&amp;gt;
  ...
  &amp;lt;listener ref="pojoListener" before-job-method="before" after-job-method="after"/&amp;gt;
&amp;lt;/job&amp;gt;
&amp;lt;bean id="pojoListener" class="com.example.MyListener"/&amp;gt;
--------
MyListener is a simple POJO and does not implement JobExecutionListener and has no annotated methods either.
I&amp;amp;apos;ve debugged the problem and it seems the offending code is in the private method
AbstractListenerParser#getMethodNameAttributes
That method returns 
{"beforeJob", "afterJob"}
 instead of the XML attribute names 
{"before-job-method", "after-job-method"}
.
The unit test "JobExecutionListenerParserTests" does not seem to test this case.
I suspect that the same problem exists for Step Listeners as they share the same code base.</description>
			<version>2.1.1</version>
			<fixedVersion>2.1.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.TestListener.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.AbstractListenerParser.java</file>
		</fixedFiles>
	</bug>
	<bug id="1590" opendate="2010-06-28 04:45:38" fixdate="2010-06-28 21:16:55" resolution="Complete">
		<buginformation>
			<summary>OraclePagingQueryProvider.generateJumpToItemQuery generates an incorrect query</summary>
			<description>When running a partitioned job that uses JdbcPagingItemReader as the input, some input rows are being omitted and some are being processed twice. This is happening as a result of JdbcPagingItemReader.doJumpToPage attempting to position the reader at the start of that partition (the &amp;amp;apos;read.count&amp;amp;apos; and &amp;amp;apos;read.count.max&amp;amp;apos; properties have been set in the step execution context to delimit the partitions). 
This problem is only seen when the sortKey will cause the rows to be sorted in an order other than the underlying database storage engine returns them (e.g., not the primary clustering key or query-covering index).
The jumpToItemSql that is generated by the query provider looks something like the following:
SELECT * FROM (SELECT customer AS SORT_KEY, ROWNUM as TMP_ROW_NUM FROM batch_input ORDER BY customer ASC) WHERE TMP_ROW_NUM = 30
This does not return the intended result because the assignment of the TMP_ROW_NUM values happens before the sort, so the effect is exactly the same as if the ORDER BY clause was omitted.
A possible workaround is to add another select level so that the sort happens before TMP_ROW_NUM values are assigned:
SELECT * FROM (SELECT SORT_KEY, ROWNUM AS TMP_ROW_NUM FROM (SELECT customer AS SORT_KEY FROM batch_input ORDER BY SORT_KEY ASC)) WHERE TMP_ROW_NUM = 30</description>
			<version>2.1.1</version>
			<fixedVersion>2.1.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.support.OraclePagingQueryProvider.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.TaskletParserBeanPropertiesTests.java</file>
			<file type="M">org.springframework.batch.item.database.JdbcPagingQueryIntegrationTests.java</file>
			<file type="M">org.springframework.batch.item.database.support.SqlPagingQueryUtils.java</file>
			<file type="M">org.springframework.batch.item.database.support.OraclePagingQueryProviderTests.java</file>
			<file type="M">org.springframework.batch.item.database.support.SqlPagingQueryUtilsTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1594" opendate="2010-07-08 20:46:12" fixdate="2010-07-08 21:53:18" resolution="Complete">
		<buginformation>
			<summary>StepListenerSupport implements method onErrorInStep which is not declared in any of the implemented interfaces</summary>
			<description>The onErrorInStep method is not declared in any of the listener interfaces, nor is it called as far as I can see from the code executing steps. onErrorInStep was removed from the StepExecutionListener in changeset 2338 and jira BATCH-825.
While the onErrorInStep method in StepListenerSupport will not cause problems directly, it is misleading for developers extending StepListenerSupport.
(When editing the StepListenerSupport, you might want to update the non-javadoc referencing StepListener to reference StepExecutionListener instead as well)</description>
			<version>2.1.1</version>
			<fixedVersion>2.1.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.sample.common.StagingItemWriter.java</file>
			<file type="M">org.springframework.batch.core.step.NonAbstractStepTests.java</file>
			<file type="M">org.springframework.batch.sample.common.StagingItemReader.java</file>
			<file type="M">org.springframework.batch.core.listener.MulticasterBatchListenerTests.java</file>
			<file type="M">org.springframework.batch.core.listener.StepListenerSupport.java</file>
		</fixedFiles>
	</bug>
	<bug id="1600" opendate="2010-07-22 02:34:21" fixdate="2010-07-23 08:10:27" resolution="Complete">
		<buginformation>
			<summary>CommandLineJobRunner cannot stop a Job execution that was restarted</summary>
			<description>Mode execution restarting is not stopped with mode execution stop:
The error is this line from the file:

Class: org.springframework.batch.core.launch.support. CommandLineJobRunner
method: private List&amp;lt;JobExecution&amp;gt; getJobExecutionsWithStatusGreaterThan(String jobIdentifier, BatchStatus minStatus){}.
line: 344: JobExecution jobExecution = jobExecutions.get(jobExecutions.size() - 1);

Possible fix:

line: 344: JobExecution jobExecution = jobExecutions.get(0);

</description>
			<version>2.1.1</version>
			<fixedVersion>2.1.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.launch.support.CommandLineJobRunnerTests.java</file>
			<file type="M">org.springframework.batch.core.launch.support.CommandLineJobRunner.java</file>
		</fixedFiles>
	</bug>
	<bug id="1603" opendate="2010-07-25 23:53:49" fixdate="2010-08-03 00:13:52" resolution="Complete">
		<buginformation>
			<summary>MultiResourceItemReader infinite read/exception loop after a failed delegate.open() when skip policy is very lax</summary>
			<description>The behaviour of MRIR "resource jumping" relies on the following contract from ItemReader : "Implementations must return null at the end of the input data set".  
The handling code is optimistically based on the packaged Reader and Resource implementations.  After a failed delegate.open() it will throw an exception and the next read call will call delegate.read() expecting a nice "null" to be returned.  When I used a custom Resource, I found it quite easy to end up in a loop such that delegate.open() on a StaxEventItemReader failed leaving it fundamentally uninitialised and throwing exceptions on each read() call. MRIR won&amp;amp;apos;t "jump to the next resource" unless it reads a "null" and therefore the step looped infinitely until we added some skip logic to contain the problem.
I am working on a patch (will attach when ready) to make ResourceAwareItemReaders a bit more pessimistic in their use of "noInput = true".  They erroneously assume resource.exists()=true means there will be no exception thrown in resource.getInputStream()
[
PS. I&amp;amp;apos;m not 100% sold on the open-&amp;gt;exception/loop/read-&amp;gt;null pattern of fallback but have not fully thought through the implications. 
]</description>
			<version>2.1.2</version>
			<fixedVersion>2.1.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReaderTests.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReader.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemWriter.java</file>
			<file type="M">org.springframework.batch.item.file.MultiResourceItemReaderIntegrationTests.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemReader.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemReaderTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1616" opendate="2010-08-12 07:56:15" fixdate="2010-08-13 01:25:58" resolution="Complete">
		<buginformation>
			<summary>A custom partitioner no longer restart the job properly upon failure</summary>
			<description>The changes in BATCH-1531 introduced a regression. If the partitions are not named partition0, partition1, partition2, Spring Batch considers that the execution does not exist and start a fresh new instance without calling the partitioner, which fails since the partitioner sets mandatory value for the partition to run properly.
For the record we use the following
public static final String PARTITION_PREFIX = "partition-";
// ...
final String partitionNumberFormat = "%0" + String.valueOf(gridSize).length() + "d";
// for partition i
final String partitionName = PARTITION_PREFIX + String.format(partitionNumberFormat, i);</description>
			<version>2.1.1</version>
			<fixedVersion>2.1.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.partition.support.SimpleStepExecutionSplitter.java</file>
			<file type="M">org.springframework.batch.core.partition.support.SimpleStepExecutionSplitterTests.java</file>
			<file type="M">org.springframework.batch.core.partition.support.PartitionStepTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1602" opendate="2010-07-25 07:27:56" fixdate="2010-08-13 03:17:40" resolution="Complete">
		<buginformation>
			<summary>Empty string JobParameter would be re-hydrated as null by Oracle</summary>
			<description>Empty string JobParameter would be re-hydrated as null by Oracle.  Probably not a very common scenario, but it&amp;amp;apos;s a feature of Oracle that isn&amp;amp;apos;t taken into account in the JdbcJobInstanceDao.</description>
			<version>2.0.0</version>
			<fixedVersion>2.1.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcJobInstanceDaoTests.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcJobInstanceDao.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.AbstractJobInstanceDaoTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1597" opendate="2010-07-19 19:56:18" fixdate="2010-08-13 03:22:03" resolution="Complete">
		<buginformation>
			<summary>DirectPoller only works with timeout in milliseconds</summary>
			<description>DirectPoller only works with timeout in milliseconds.  Doesn&amp;amp;apos;t have any effect on mainstream Batch use, only if the poller is used and only if the timeout is not in millisecs.</description>
			<version>2.1.0</version>
			<fixedVersion>2.1.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.poller.DirectPoller.java</file>
			<file type="M">org.springframework.batch.poller.DirectPollerTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1605" opendate="2010-07-29 01:24:30" fixdate="2010-08-13 03:47:38" resolution="Complete">
		<buginformation>
			<summary>HippyMethodInvoker candidate arguments repeated</summary>
			<description>I&amp;amp;apos;m trying out the PropertyExtractingDelegatingItemWriter, and I&amp;amp;apos;m seeing that if the arguments are not of the exact types as the targetMethod, then HippyMethodInvoker#findMatchingMethod is called.
When finding candidate arguments, the findMatchingMethod method will populate all fields with the first possible match.
The following is the sample I&amp;amp;apos;m using:






&amp;lt;bean id="adaptedItemWriter" class="org.springframework.batch.item.adapter.PropertyExtractingDelegatingItemWriter"&amp;gt;




    &amp;lt;property name="targetObject" ref="myWriter" /&amp;gt;




    &amp;lt;property name="targetMethod" value="doIt" /&amp;gt;




    &amp;lt;property name="fieldsUsedAsTargetMethodArguments"&amp;gt;




        &amp;lt;list&amp;gt;




            &amp;lt;value&amp;gt;firstName&amp;lt;/value&amp;gt;




            &amp;lt;value&amp;gt;lastName&amp;lt;/value&amp;gt;




            &amp;lt;value&amp;gt;network&amp;lt;/value&amp;gt;




        &amp;lt;/list&amp;gt;




    &amp;lt;/property&amp;gt;




&amp;lt;/bean&amp;gt;




	




&amp;lt;bean id="myWriter" class="com.mycom.writers.MyWriter"/&amp;gt;






The item being passed has three properties: firstName, lastName, and network. All are Strings. In order to make MyWriter more reusable, I had the doIt(...) method use Object for one of the parameters:






public class MyWriter {




	public void doIt(String a, String b, Object c) {




		System.out.println(a + ", " + b + ", and " + c); 




	}




}






If the "c" argument is a String "public void doIt(String a, String b, String c)", then the output is as expected (i.e., firstName, lastName and network are printed out). When "c" is an Object "public void doIt(String a, String b, Object c)", then HippyMethodInvoker tries to find a method and selects candidate arguments. All three candidate arguments are the first value passed in (i.e., the result is firstName, firstName and firstName printed out).
Any ideas on how to use more generic argument types? </description>
			<version>2.1.1</version>
			<fixedVersion>2.1.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.adapter.HippyMethodInvokerTests.java</file>
			<file type="M">org.springframework.batch.item.adapter.HippyMethodInvoker.java</file>
		</fixedFiles>
	</bug>
	<bug id="1595" opendate="2010-07-10 17:12:37" fixdate="2010-08-13 06:11:38" resolution="Complete">
		<buginformation>
			<summary>OraclePagingQueryProvider has inconsistent names for columns in jumpToItemQuery</summary>
			<description>OraclePagingQueryProvider has inconsistent namesfor columns in jumpToItemQuery.  It only matters if you use the column names (e.g. queryForLong() which is more common wouldn&amp;amp;apos;t be affected), but all the other query providers have "SORT_KEY" as a column name alias, whereas the Oracle version doesn&amp;amp;apos;t use an alias.</description>
			<version>2.1.2</version>
			<fixedVersion>2.1.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.JdbcPagingQueryIntegrationTests.java</file>
			<file type="M">org.springframework.batch.item.database.support.SqlPagingQueryUtils.java</file>
			<file type="M">org.springframework.batch.item.database.support.OraclePagingQueryProvider.java</file>
			<file type="M">org.springframework.batch.item.database.support.OraclePagingQueryProviderTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1619" opendate="2010-08-25 12:30:24" fixdate="2010-08-25 23:08:12" resolution="Complete">
		<buginformation>
			<summary>BadSqlGrammarException accessing Executions page with Apache Derby 10.6 datasource</summary>
			<description>When attempting to access the executions page of the sample admin batch web app, I revcieve the following exception:
SEVERE: Servlet.service() for servlet Batch Servlet threw exception
org.apache.derby.client.am.SqlException: Syntax error: Encountered "&amp;lt;=" at line 1, column 337.
The generated sql statement is below:
SELECT * FROM ( SELECT E.JOB_EXECUTION_ID, E.START_TIME, E.END_TIME, E.STATUS, E.EXIT_CODE, E.EXIT_MESSAGE, E.CREATE_TIME, E.LAST_UPDATED, E.VERSION, I.JOB_INSTANCE_ID, I.JOB_NAME, ROW_NUMBER() OVER () AS ROW_NUMBER FROM BATCH_JOB_EXECUTION E, BATCH_JOB_INSTANCE I WHERE E.JOB_INSTANCE_ID=I.JOB_INSTANCE_ID) AS TMP_SUB WHERE ROW_NUMBER &amp;lt;= 20
The problem is that the reference the to column alias &amp;amp;apos;ROW_NUMBER&amp;amp;apos; in the where clause is missing the proper query alias. The where clause should reference the column as &amp;amp;apos;TMP_SUB.ROW_NUMBER&amp;amp;apos;. 
The correct sql is below: ( BTW - I verified that the first one fails in my sql client and that the statement, with the correction applied, below does indeed work.)
SELECT * FROM ( SELECT E.JOB_EXECUTION_ID, E.START_TIME, E.END_TIME, E.STATUS, E.EXIT_CODE, E.EXIT_MESSAGE, E.CREATE_TIME, E.LAST_UPDATED, E.VERSION, I.JOB_INSTANCE_ID, I.JOB_NAME, ROW_NUMBER() OVER () AS ROW_NUMBER FROM BATCH_JOB_EXECUTION E, BATCH_JOB_INSTANCE I WHERE E.JOB_INSTANCE_ID=I.JOB_INSTANCE_ID) AS TMP_SUB WHERE TMP_SUB.ROW_NUMBER &amp;lt;= 20</description>
			<version>2.1.2</version>
			<fixedVersion>2.1.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.job.flow.FlowStepTests.java</file>
			<file type="M">archetypes.simple-cli.src.test.java.example.ExampleJobConfigurationTests.java</file>
			<file type="M">org.springframework.batch.item.database.support.SqlWindowingPagingQueryProvider.java</file>
			<file type="M">org.springframework.batch.item.database.support.DerbyPagingQueryProviderTests.java</file>
			<file type="M">org.springframework.batch.item.database.support.Db2PagingQueryProviderTests.java</file>
			<file type="M">org.springframework.batch.item.database.support.SqlServerPagingQueryProviderTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1620" opendate="2010-08-27 00:12:10" fixdate="2010-08-27 00:43:51" resolution="Complete">
		<buginformation>
			<summary>FlowStep never fails</summary>
			<description></description>
			<version>2.1.0</version>
			<fixedVersion>2.1.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.support.transaction.TransactionAwareMapFactoryTests.java</file>
			<file type="M">org.springframework.batch.core.step.tasklet.TaskletStepTests.java</file>
			<file type="M">org.springframework.batch.core.partition.support.SimpleStepExecutionSplitter.java</file>
			<file type="M">org.springframework.batch.support.transaction.TransactionAwareProxyFactory.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.MapStepExecutionDao.java</file>
			<file type="M">org.springframework.batch.core.job.flow.FlowStepTests.java</file>
			<file type="M">org.springframework.batch.core.job.flow.FlowStep.java</file>
		</fixedFiles>
	</bug>
	<bug id="1618" opendate="2010-08-24 09:54:59" fixdate="2010-08-28 06:41:44" resolution="Complete">
		<buginformation>
			<summary>MultiResourceItemWriter creates an empty file if the number of item to write is a multiple of itemCountLimitPerResource</summary>
			<description>MultiResourceItemWriter creates files on the filesystem when setting the resource to the delegate. If the number of items to write is a multiple of itemCountLimitPerResource, the last file will be created, but nothing will be written into it.
The attached patch defers the file creation in the write method.</description>
			<version>2.1.2</version>
			<fixedVersion>2.1.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.MultiResourceItemWriter.java</file>
		</fixedFiles>
	</bug>
	<bug id="1598" opendate="2010-07-19 19:58:42" fixdate="2010-08-29 00:38:22" resolution="Complete">
		<buginformation>
			<summary>JobRepositoryTestUtils delete job execution fails if there is another execution with the same job instance</summary>
			<description>JobRepositoryTestUtils delete job execution fails if there is another execution with the same job instance</description>
			<version>2.1.0</version>
			<fixedVersion>2.1.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.test.JobRepositoryTestUtilsTests.java</file>
			<file type="M">org.springframework.batch.test.JobRepositoryTestUtils.java</file>
		</fixedFiles>
	</bug>
	<bug id="1601" opendate="2010-07-23 18:33:10" fixdate="2010-08-29 00:46:20" resolution="Complete">
		<buginformation>
			<summary>The "initialized" field in org.springframework.batch.test.DataSourceInitializer shouldn&amp;apos;t be static.</summary>
			<description>The initialized field in org.springframework.batch.test.DataSourceInitializer is declared as:
private static boolean initialized = false;
This shouldn&amp;amp;apos;t be static as this causes issues when the DataSourceInitializer class is used more than once for initializing more than one DataSources.</description>
			<version>2.0.0</version>
			<fixedVersion>2.1.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.test.DataSourceInitializer.java</file>
		</fixedFiles>
	</bug>
	<bug id="1623" opendate="2010-09-03 04:36:44" fixdate="2010-09-06 06:56:02" resolution="Complete">
		<buginformation>
			<summary>A chunk configured with processor-transactional="true" shouldn&amp;apos;t require a retry- or skip-limit</summary>
			<description>At the moment when you configure processor-transactional="true" on a chunk the framework&amp;amp;apos;s validation forces you to also specify a retry-limit or skip-limit. First of all, when you specify a &amp;lt;retry-policy&amp;gt; element this requirement still exists, even though the policy overrules the configured retry-limit, so that&amp;amp;apos;s an error in the validation (StepParserStepFactoryBean.java:466). 
Second of all, it might not really be necessary to enforce this requirement at all.
From the brief private discussion on Skype with Dave about this:






[12:33:45 PM] David Syer: I guess it makes sense that processor-transactional="true" requires one or the other.  But maybe we should lift that restriction too (allow the middleware to deal with retry)?




[12:35:20 PM] Joris Kuipers: could be, but wouldn&amp;amp;apos;t that only be the case if your ItemReader was transactional as well? I cannot easily imagine a scenario where a non-transactional reader would be followed by a transactional processor where middleware would take care of retries for the processor...




[12:35:46 PM] Joris Kuipers: but maybe I haven&amp;amp;apos;t thought enough about what (non-)transactional processors really cause the framework to do




[12:36:09 PM] Joris Kuipers: it&amp;amp;apos;s just a way to prevent caching the items, right?




[12:36:26 PM] Joris Kuipers: since a rollback on error won&amp;amp;apos;t lose items for tx-al processing




[12:38:27 PM] David Syer: Right, I was mixing it up with reader-transactional




[12:38:34 PM] David Syer: So there&amp;amp;apos;s no obvious link to retry.




[12:38:55 PM] David Syer: You could set it true if you want and if there is no retry there is no re-processing either, but it&amp;amp;apos;s harmless.




[12:39:18 PM] Joris Kuipers: that&amp;amp;apos;s what I thought as well, yes




[12:39:41 PM] David Syer: OK.  Mention that in the JIRA and I&amp;amp;apos;ll remove the restriction completely.





</description>
			<version>2.1.2</version>
			<fixedVersion>2.1.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParserStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.ChunkElementParserTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1615" opendate="2010-08-11 08:37:49" fixdate="2010-09-07 04:56:40" resolution="Complete">
		<buginformation>
			<summary>MultiResourceItemReader infinite read/exception loop after NonTransientDataAccessResourceException</summary>
			<description>Scenario MRIR with a StaxEventItemReader as the delegate and several resources to loop through.
Simplest failure scenario is if one of the XML files is truncated. A call to MRIR.read() gets the following exception:
org.springframework.dao.DataAccessResourceFailureException: Error while reading from event reader; nested exception is javax.xml.stream.XMLStreamException: ParseError at [row,col]:[8,2]
Message: Element type "thing" must be followed by either attribute specifications, "&amp;gt;" or "/&amp;gt;".
	at org.springframework.batch.item.xml.StaxEventItemReader.moveCursorToNextFragment(OXMStaxEventItemReader.java:198)
	at org.springframework.batch.item.xml.StaxEventItemReader.doRead(OXMStaxEventItemReader.java:336)
	at org.springframework.batch.item.support.AbstractItemCountingItemStreamItemReader.read(AbstractItemCountingItemStreamItemReader.java:85)
	at org.springframework.batch.item.file.MultiResourceItemReader.readNextItem(MultiResourceItemReader.java:111)
	at org.springframework.batch.item.file.MultiResourceItemReader.read(MultiResourceItemReader.java:99)
Without any particular handling of the scenario, MRIR treats this as an item-specific problem and will keep retrying to reaD() the delegate without ever giving up.
DataAccessResourceException javadoc : "Data access exception thrown when a resource fails completely: for example, if we can&amp;amp;apos;t connect to a database using JDBC."
A) MRIR should recognise the resource has failed completely and "jump" to the next on the next call to read().
B) I&amp;amp;apos;m not sure what exception to base this behaviour upon because the Exception inheritance is topsy-turvy.  The generated exception is actually a child of NonTransientDataAccessResourceException (though the classname hints that it is more specific) with identical javadoc "Data access exception thrown when a resource fails completely and the failure is permanent."
I&amp;amp;apos;ll be attaching a proposed patch for handling of this.</description>
			<version>2.1.2</version>
			<fixedVersion>2.1.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemReader.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemReaderTests.java</file>
			<file type="M">org.springframework.batch.item.ItemReader.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemReader.java</file>
		</fixedFiles>
	</bug>
	<bug id="1539" opendate="2010-03-24 22:56:18" fixdate="2010-09-07 05:05:01" resolution="Duplicate">
		<buginformation>
			<summary>composite item writer does not honour the item stream interface</summary>
			<description>If you use a composite item writer with a writer that implements the iteam stream interface, you get a org.springframework.batch.item.WriterNotOpenException: Writer must be open before it can be written to</description>
			<version>2.1.0</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.support.CompositeItemWriterTests.java</file>
			<file type="M">org.springframework.batch.item.support.CompositeItemWriter.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="duplicates">836</link>
		</links>
	</bug>
	<bug id="836" opendate="2008-09-11 21:00:50" fixdate="2010-09-07 05:23:11" resolution="Complete">
		<buginformation>
			<summary>CompositeItemWriter should also implement ItemStream</summary>
			<description>The StepFactoryBean automatically registers ItemReader and ItemWriter as streams if they implement the interface. It would be nice if the CompositeItemWriter could also implement this interface (and delegate the methods to its delegate if appropriate), so that a composite writer set as the writer in a StepFactoryBean will be registered as an ItemStream and delegate ItemStreams methods on its delegates automatically.</description>
			<version>1.1.2</version>
			<fixedVersion>2.1.3</fixedVersion>
			<type>Improvement</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.support.CompositeItemWriterTests.java</file>
			<file type="M">org.springframework.batch.item.support.CompositeItemWriter.java</file>
		</fixedFiles>
		<links>
			<link type="Duplicate" description="is duplicated by">1539</link>
		</links>
	</bug>
	<bug id="1629" opendate="2010-09-17 12:43:05" fixdate="2010-09-18 00:59:29" resolution="Complete">
		<buginformation>
			<summary>FaultTolerantChunkProcessor contains dangerous log statements</summary>
			<description>I&amp;amp;apos;ve just profiled an application that is making an extensive use of Spring Batch. And believe the biggest performance hog was....... 
the StringBuilder conversions in FaultTolerantChunkProcessor class. There are couple of log statements there that do this:
logger.debug("Attempting to write: " + inputs);
without 
if(logger.isDebugEnabled()).
I mean, guys, come on, inputs can be pretty wacky. In this case it was a list of Hibernate entities containing a lot of properties and all of them are in the toString() implementation. This "innocent" logging statement was the biggest performance hog in the app. 
It probably would make sense to do an audit and see if there are any other places where such debug statement are not safe. I suppose I could do that. Would you take a patch?</description>
			<version>2.1.3</version>
			<fixedVersion>2.1.4</fixedVersion>
			<type>Defect</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantChunkProcessor.java</file>
		</fixedFiles>
	</bug>
	<bug id="1632" opendate="2010-09-24 04:40:18" fixdate="2010-09-26 23:06:24" resolution="Complete">
		<buginformation>
			<summary>DefaultFieldSet#readBigDecimal(String, BigDecimal) and NumberFormatException</summary>
			<description>Here the code of DefaultFieldSet#readBigDecimal(String, BigDecimal):






466	        public BigDecimal readBigDecimal(String name, BigDecimal defaultValue) {




467	                try {




468	                        return readBigDecimal(indexOf(name), defaultValue);




469	                }




470	                catch (IllegalArgumentException e) {




471	                        throw new IllegalArgumentException(e.getMessage() + ", name: [" + name + "]");




472	                }




473	        }






The problem is that a NumberFormatException is also an IllegalArgumentException.
So at this point, we can not make the difference between between indexOf failure and BigDecimal conversion failure.
The fix:






466	        public BigDecimal readBigDecimal(String name, BigDecimal defaultValue) {




467	                try {




468	                        return readBigDecimal(indexOf(name), defaultValue);




469	                }




470	                catch (NumberFormatException e) {




471	                        throw new NumberFormatException(e.getMessage() + ", name: [" + name + "]");




472	                }




473	                catch (IllegalArgumentException e) {




474	                        throw new IllegalArgumentException(e.getMessage() + ", name: [" + name + "]");




475	                }




476	        }






</description>
			<version>2.1.0</version>
			<fixedVersion>2.1.4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.transform.DefaultFieldSet.java</file>
		</fixedFiles>
	</bug>
	<bug id="1633" opendate="2010-09-26 10:27:29" fixdate="2010-09-26 23:30:00" resolution="Complete">
		<buginformation>
			<summary>Dependency injection problem with step scoped anonymous inner bean</summary>
			<description>XML spring context sample :
    &amp;lt;bean id="john" class="java.lang.String"&amp;gt;
        &amp;lt;constructor-arg index="0" value="John"/&amp;gt;
    &amp;lt;/bean&amp;gt;
    &amp;lt;bean id="jane" class="java.lang.String"&amp;gt;
        &amp;lt;constructor-arg index="0" value="Jane"/&amp;gt;
    &amp;lt;/bean&amp;gt;
    &amp;lt;batch:job id="firstJob" job-repository="jobRepository"&amp;gt;
        &amp;lt;batch:step id="firstJobFirstStep" next="firstJobSecondStep"&amp;gt;
            &amp;lt;batch:tasklet&amp;gt;
                &amp;lt;bean class="spring.batch.test.InnerBeanStepScopedTest$Hello" scope="step"&amp;gt;
                    &amp;lt;property name="name" ref="jane"/&amp;gt;
                &amp;lt;/bean&amp;gt;
            &amp;lt;/batch:tasklet&amp;gt;
        &amp;lt;/batch:step&amp;gt;
        &amp;lt;batch:step id="firstJobSecondStep"&amp;gt;
            &amp;lt;batch:tasklet&amp;gt;
                &amp;lt;bean class="spring.batch.test.InnerBeanStepScopedTest$Hello" scope="step"&amp;gt;
                    &amp;lt;property name="name" ref="john"/&amp;gt;
                &amp;lt;/bean&amp;gt;
            &amp;lt;/batch:tasklet&amp;gt;
        &amp;lt;/batch:step&amp;gt;
    &amp;lt;/batch:job&amp;gt;
The output produced is:
    19:08:03.885 [main] INFO  s.b.t.InnerBeanStepScopedTest$Hello - Hello John!
    19:08:03.975 [main] INFO  s.b.t.InnerBeanStepScopedTest$Hello - Hello John!
Now, the question is: where is Jane? :o)
If the two tasklets are unscoped (just remove scope="step") then the ouput is:
    19:13:20.801 [main] INFO  s.b.t.InnerBeanStepScopedTest$Hello - Hello Jane!
    19:13:20.921 [main] INFO  s.b.t.InnerBeanStepScopedTest$Hello - Hello John!
Yes, Jan is back!
So, dependency injection fails on step scoped inner anonymous beans. 
Workaround: name inner beans with an id attribute... but it&amp;amp;apos;s boring (me).</description>
			<version>2.1.3</version>
			<fixedVersion>2.1.4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.TaskletParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.ChunkElementParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.AbstractListenerParser.java</file>
		</fixedFiles>
	</bug>
	<bug id="1572" opendate="2010-05-20 02:20:50" fixdate="2010-09-27 01:17:31" resolution="Complete">
		<buginformation>
			<summary>Step not failing on org.springframework.transaction.UnexpectedRollbackException</summary>
			<description>The transaction is timing out for a read by the reader in a step due to a lock. The transaction manager marks the out come of the transaction to be rollback only. Once the lock is released and the reader returns  a org.springframework.transaction.UnexpectedRollbackException is thrown while updating the chunk to database. Batch is considering this exception to be a non fatal exception and is continuing with the next chunk just by logging the exception at a debug level. Instead ity should fail the step I guess.
Problem : I am loosing all the records in that chunk. 
I changed the org.springframework.batch.core.step.item.SimpleRetryExceptionHandler.java&amp;amp;apos;s constructor like 
public SimpleRetryExceptionHandler(RetryPolicy retryPolicy, ExceptionHandler exceptionHandler, Collection&amp;lt;Class&amp;lt;? extends Throwable&amp;gt;&amp;gt; fatalExceptionClasses) 
{
		this.retryPolicy = retryPolicy;
		this.exceptionHandler = exceptionHandler;
		fatalExceptionClasses.add(org.springframework.transaction.UnexpectedRollbackException.class);
		this.fatalExceptionClassifier = new BinaryExceptionClassifier(fatalExceptionClasses);
	}

and tested. Now it is failing the step.
</description>
			<version>2.1.1</version>
			<fixedVersion>2.1.4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.TaskletStepExceptionTests.java</file>
			<file type="M">org.springframework.batch.core.step.tasklet.TaskletStep.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.Entity.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.MapStepExecutionDao.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBeanRollbackTests.java</file>
			<file type="M">org.springframework.batch.core.step.AbstractStep.java</file>
		</fixedFiles>
	</bug>
	<bug id="1639" opendate="2010-10-09 09:11:14" fixdate="2010-10-09 09:11:33" resolution="Complete">
		<buginformation>
			<summary>Oracle jumpToItemQuery needs a tweak (again)</summary>
			<description>OraclePagingQueryProvider.generateJumpToItemQuery generates an incorrect query, see BATCHADM-74.  It doesn&amp;amp;apos;t affect Batch users much, but it has a n impact on Spring Batch Admin with Oracle.</description>
			<version>2.1.3</version>
			<fixedVersion>2.1.4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.support.SqlPagingQueryUtilsTests.java</file>
			<file type="M">org.springframework.batch.item.database.JdbcPagingItemReader.java</file>
			<file type="M">org.springframework.batch.item.database.support.SqlPagingQueryUtils.java</file>
			<file type="M">org.springframework.batch.item.database.support.OraclePagingQueryProviderTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1640" opendate="2010-10-13 17:55:52" fixdate="2010-10-13 18:01:25" resolution="Complete">
		<buginformation>
			<summary>File writers do not behave correctly on rollback</summary>
			<description>File writers do not behave correctly on rollback.  It doesn&amp;amp;apos;t seem to affect regular users of FlatFileItemWriter (and XML) but if you write one item at a time instead of all at once in a transaction which rolls back, then no data are ever written by the writer.
The bug is in TransactionAwareBufferedWriter which fails to clear its transaction resource on rollback.</description>
			<version>2.1.0</version>
			<fixedVersion>2.1.4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.support.transaction.TransactionAwareBufferedWriterTests.java</file>
			<file type="M">org.springframework.batch.support.transaction.TransactionAwareBufferedWriter.java</file>
		</fixedFiles>
	</bug>
	<bug id="1643" opendate="2010-10-16 16:51:47" fixdate="2010-10-28 09:43:52" resolution="Complete">
		<buginformation>
			<summary>Unpredictable binding in BeanWrapperFieldSetMapper because of "fuzzy" property matching</summary>
			<description>This bug has two distinct symptoms, due to the permissiveness of the fuzzy matching in BeanWrapperFieldSetMapper#findPropertyName().  See the attached Unit test and included javadocs.  Basically, the fuzzy matching can cause multiple columns of the input to match the same target bean property, thus wrongly failing to throw NotWritablePropertyException in some cases, and this also makes it unpredictable which competing 
{@link FieldSet}
 value will actually be set into the target bean property.
As a minimal work-around it would be nice to be able to turn off fuzzy matching (e.g. by exposing distanceLimit as a configurable property).  I would also suggest  defaulting its value to 0 instead of 5, as it is pretty dangerous.</description>
			<version>2.1.3</version>
			<fixedVersion>2.1.4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.mapping.BeanWrapperFieldSetMapperTests.java</file>
			<file type="M">org.springframework.batch.item.file.mapping.PropertyMatches.java</file>
			<file type="M">org.springframework.batch.item.file.mapping.BeanWrapperFieldSetMapper.java</file>
		</fixedFiles>
	</bug>
	<bug id="1652" opendate="2010-11-10 02:04:18" fixdate="2010-11-11 08:56:53" resolution="Complete">
		<buginformation>
			<summary>CommandLineJobRunner hangs</summary>
			<description>After upgrading spring-batch to 2.1.4 all of our batch jobs stopped doing anything when launched. The processes just hang and even the spring-batch db tables are not accessed. When debugging I noticed that the process was stuck waiting for input on line 518.</description>
			<version>2.1.4</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.launch.support.CommandLineJobRunnerTests.java</file>
			<file type="M">org.springframework.batch.core.launch.support.CommandLineJobRunner.java</file>
		</fixedFiles>
	</bug>
	<bug id="1656" opendate="2010-11-18 14:32:35" fixdate="2010-11-22 03:02:25" resolution="Complete">
		<buginformation>
			<summary>Infinite loop on no-rollback-for exception when skipLimit is reached due to exception in ItemProcessor</summary>
			<description>If java.lang.Exception is configured in the "no-rollback-exception-classes" this leads to an infinite loop when the skipLimit is reached, caused by an exception thrown in the ItemProcessor. 
Exceptions thrown in the writer are handled  just fine. 
It seems like this was introduced in 2.1 only (tested with 2.1.1 and 2.1.5) as it is working fine in 2.0.1. 
</description>
			<version>2.1.5</version>
			<fixedVersion>2.1.6</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBeanRollbackTests.java</file>
			<file type="M">org.springframework.batch.core.test.step.FaultTolerantStepFactoryBeanRollbackIntegrationTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantChunkProcessor.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBean.java</file>
		</fixedFiles>
	</bug>
	<bug id="1659" opendate="2010-11-23 23:21:42" fixdate="2010-11-26 03:02:14" resolution="Complete">
		<buginformation>
			<summary>FileUtils setUpOutputFile fails on NAS from linux</summary>
			<description>FlatFileItemWriter is failing on a NAS running on linux. It fails in FileUtils.setUpOutputFile where it calls file.createNewFile();
A simple test program reproduces the problem. If I run this once I get the exception, but it successfully creates the file. If I run it a second time it works.
public class TestNAS 
{
    public static void main( String[] args ) throws IOException
    {
        File file = new File("./test.txt");
        file.createNewFile();
    }
}
The exception is 
Exception in thread "main" java.lang.reflect.InvocationTargetException
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at com.simontuffs.onejar.Boot.run(Boot.java:329)
        at com.simontuffs.onejar.Boot.main(Boot.java:164)
Caused by: java.io.IOException: Permission denied
        at java.io.UnixFileSystem.createFileExclusively(Native Method)
        at java.io.File.createNewFile(File.java:883)
        at com.jpmorgan.wss.test.TestNAS.main(TestNAS.java:16)
        ... 6 more</description>
			<version>2.1.1</version>
			<fixedVersion>2.1.6</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.util.FileUtilsTests.java</file>
			<file type="M">org.springframework.batch.item.file.transform.FieldSetFactory.java</file>
			<file type="M">org.springframework.batch.item.file.transform.DefaultFieldSet.java</file>
			<file type="M">org.springframework.batch.item.util.FileUtils.java</file>
		</fixedFiles>
	</bug>
	<bug id="1671" opendate="2010-12-20 11:45:17" fixdate="2010-12-21 03:14:59" resolution="Complete">
		<buginformation>
			<summary>static methods are not public in ExecutionContextTestUtils</summary>
			<description>Currently all methods in org.springframework.batch.test.ExecutionContextTestUtils are not public(default/package scope now).
Can you make them public, so that test class can have access to them.
Thanks,</description>
			<version>2.1.4</version>
			<fixedVersion>2.1.6</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.test.ExecutionContextTestUtils.java</file>
		</fixedFiles>
	</bug>
	<bug id="1635" opendate="2010-09-27 22:22:29" fixdate="2011-02-03 09:43:59" resolution="Complete">
		<buginformation>
			<summary>Spring Batch and Hibernate Search do not work together</summary>
			<description>We are having a problem when using spring batch and hibernate search together.   Basically when hibernate search needs to lazy load a entity using indexing (which occurs during the commit processing) we get a lazy load exception (org.hibernate.LazyInitializationException: could not initialize proxy - no Session).
I&amp;amp;apos;m pretty sure this problem is caused by the call to hibernateTemplate.clear() in HibernateItemWriter:
	public final void write(List&amp;lt;? extends T&amp;gt; items) {
		doWrite(hibernateTemplate, items);
		try 
{
			hibernateTemplate.flush();
		}
		finally 
{
			// This should happen when the transaction commits anyway, but to be
			// sure...
			hibernateTemplate.clear();
		}
	}
As the affect of this is also to clear the session on any hibernate proxies.  
As the comment says, the clear should not be needed and I would suggest either removing it or at least making it configurable.</description>
			<version>2.1.3</version>
			<fixedVersion>2.1.6</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.JpaItemWriter.java</file>
			<file type="M">org.springframework.batch.item.database.HibernateItemWriterTests.java</file>
			<file type="M">org.springframework.batch.item.database.HibernateItemWriter.java</file>
			<file type="M">org.springframework.batch.item.database.JpaItemWriterTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1670" opendate="2010-12-20 01:11:34" fixdate="2011-02-07 00:45:07" resolution="Complete">
		<buginformation>
			<summary>Nested splits lead to invalid flow definition</summary>
			<description></description>
			<version>2.1.5</version>
			<fixedVersion>2.1.6</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.SplitParser.java</file>
		</fixedFiles>
	</bug>
	<bug id="1681" opendate="2011-01-20 13:07:00" fixdate="2011-02-07 01:12:51" resolution="Complete">
		<buginformation>
			<summary>Restarting a job that generates XML output using StaxEventItemWriter with Woodstox fails</summary>
			<description>When restarting a job that generates XML output using StaxEventItemWriter, the restart will fail if the Woodstox implementation of Stax is used. The problem is that by default, the Woodstox implementation of XMLEventWriter validates the XML structure as it is written. Since on a restart the root element is not written, when the second output item is written, the Woodstox implementation detects this as an invalid XML structure and throws:
javax.xml.stream.XMLStreamException: Trying to output second root, &amp;lt;item&amp;gt;
The solution is to turn off structure validation in StaxEventItemWriter.open(long, boolean) in much the same way that the "com.ctx.wstx.automaticEndElements" feature is disabled:
if (outputFactory.isPropertySupported("com.ctc.wstx.outputValidateStructure")) {
    outputFactory.setProperty("com.ctc.wstx.outputValidateStructure", Boolean.FALSE);
}
</description>
			<version>2.1.5</version>
			<fixedVersion>2.1.6</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemWriter.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemWriterTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1707" opendate="2011-03-11 01:02:44" fixdate="2011-03-11 03:21:09" resolution="Fixed">
		<buginformation>
			<summary>MapJobInstanceDao.getJobInstances(String jobName, int start, int count) does not work</summary>
			<description>In the code of MapJobInstanceDao :
public List&amp;lt;JobInstance&amp;gt; getJobInstances(String jobName, int start, int count) {
	...
	return result.subList(start, count); // ERROR : should be result.subList(start, start+count) because subList parameters are fromIndex, toIndex
}
WORKAROUND = define a subclass with a correct implementation for this method :
public class MyMapJobInstanceDao extends MapJobInstanceDao {
	@Override
	public List&amp;lt;JobInstance&amp;gt; getJobInstances(String jobName, int start, int count) 
{
		int nbJobs = getJobNames().size();
		List&amp;lt;JobInstance&amp;gt; instances = super.getJobInstances(jobName, 0, nbJobs);
		return instances.subList(start, Math.min(nbJobs, start+count));
	}
}
and in the applicationContext, use the new class instead of the spring one</description>
			<version>2.1.3</version>
			<fixedVersion>2.1.7</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.repository.dao.MapJobInstanceDao.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.AbstractJobInstanceDaoTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1709" opendate="2011-03-11 07:09:11" fixdate="2011-03-11 07:47:56" resolution="Complete">
		<buginformation>
			<summary>BeanWrapperFieldSetMapper race condition in cache</summary>
			<description>BeanWrapperFieldSetMapper occasionally fails in a concurrent setting with strange messages about duplicate properties and the distance limit, even if the column names are exact.  Must be a concurrency bug in the caching.</description>
			<version>2.0.0</version>
			<fixedVersion>2.1.7</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.mapping.BeanWrapperFieldSetMapperTests.java</file>
			<file type="M">org.springframework.batch.item.file.mapping.BeanWrapperFieldSetMapper.java</file>
		</fixedFiles>
	</bug>
	<bug id="1705" opendate="2011-03-07 07:33:50" fixdate="2011-03-15 02:17:22" resolution="Fixed">
		<buginformation>
			<summary>CommandLineJobRunner and lack of standard input exception handling</summary>
			<description>I&amp;amp;apos;ve noticed a problem with the org.springframework.batch.core.launch.support.Comm andLineJobRunner when using an environment without stdin available. In my case, launching an AutoSys job to run the CommandLineJobRunner, and standard input is not available. The code in question in the main method:
if (System.in.available() &amp;gt; 0) {
  BufferedReader reader = new BufferedReader(new InputStreamReader(System.in));
  String line = " ";
  while (StringUtils.hasLength(line)) {
    if (!line.startsWith("#") &amp;amp;&amp;amp; StringUtils.hasText(line)) 
{
      logger.debug("Stdin arg: "+line);
      newargs.add(line);
    }
    line = reader.readLine();
  }
}
Line 517 (the first line quoted) throws an exception instead of gracefully continuing if standard input is not available:
Exception in thread "main" Exception in thread "main" java.io.IOException: Incorrect function
	at java.io.FileInputStream.available(Native Method)
	at java.io.BufferedInputStream.available(BufferedInputStream.java:381)
	at org.springframework.batch.core.launch.support.Com</description>
			<version>2.1.6</version>
			<fixedVersion>2.1.7</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.launch.support.CommandLineJobRunnerTests.java</file>
			<file type="M">org.springframework.batch.core.launch.support.CommandLineJobRunner.java</file>
		</fixedFiles>
	</bug>
	<bug id="1717" opendate="2011-03-21 02:23:42" fixdate="2011-03-21 02:25:28" resolution="Complete">
		<buginformation>
			<summary>Failure in RetryPolicy leads to infinite loop in Step</summary>
			<description>Failure in RetryPolicy leads to infinite loop in Step.  Really this is a corner case because none of the retry policies supplied by the framework should have this problem, but one provided by a user might.  The problem arises if a RetryPolicy throws an exception which according to it&amp;amp;apos;s own rules in retryable. In particular the problem is if registerThrowable() itself fails.</description>
			<version>2.1.0</version>
			<fixedVersion>2.1.7</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.retry.support.RetryTemplate.java</file>
		</fixedFiles>
	</bug>
	<bug id="1725" opendate="2011-04-05 03:52:59" fixdate="2011-04-05 03:54:15" resolution="Complete">
		<buginformation>
			<summary>SubclassClassifier should use ConcurrentHashMap</summary>
			<description>SubclassClassifier should use ConcurrentHashMap, otherwise there can be concurrent modification exceptions when it is used concurrently.</description>
			<version>2.1.0</version>
			<fixedVersion>2.1.8</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.classify.SubclassClassifier.java</file>
		</fixedFiles>
	</bug>
	<bug id="1724" opendate="2011-04-05 02:19:47" fixdate="2011-04-05 04:02:43" resolution="Complete">
		<buginformation>
			<summary>Multithreaded step re-processing chunk without skip or retry limit</summary>
			<description>I sort of understand this, and it&amp;amp;apos;s quite an amusing little bug (if rather irritating).  I doubt if it critical at all, since the outcome of the step is still failure.
In a multi-threaded step we can only check for the failure one thread at a time, and by the time we have checked it, the failed chunk can have gone back in the queue for processing.  Oddly, though, even with a single background thread it still fails the same way, so maybe we can actually fix this at least for some special cases.</description>
			<version>2.1.7</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.tasklet.AsyncTaskletStepTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.ChunkOrientedTasklet.java</file>
			<file type="M">org.springframework.batch.repeat.support.TaskExecutorRepeatTemplate.java</file>
			<file type="M">org.springframework.batch.core.step.tasklet.TestingChunkOrientedTasklet.java</file>
			<file type="M">org.springframework.batch.core.step.item.SimpleChunkProcessor.java</file>
			<file type="M">org.springframework.batch.core.step.item.TaskletStepExceptionTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1727" opendate="2011-04-15 01:36:23" fixdate="2011-04-15 03:27:27" resolution="Complete">
		<buginformation>
			<summary>Child contexts created by AutomaticJobRegistrar cannot easily use PropertyPlaceholderConfigurer</summary>
			<description>See also BATCHADM-110.  ClassPathXmlApplicationContextFactory registers the parent PPC as a singleton (internal) BFPP using addBeanFactoryPostProcessor(), and those BFPP take precedence over those defined using bean definitions.   A workaround is to use SpEL instead of PPC in the child context.</description>
			<version>2.1.0</version>
			<fixedVersion>2.1.8</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.support.ClassPathXmlApplicationContextFactoryTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.support.ClassPathXmlApplicationContextFactory.java</file>
		</fixedFiles>
	</bug>
	<bug id="1738" opendate="2011-04-26 01:28:38" fixdate="2011-05-02 14:36:37" resolution="Fixed">
		<buginformation>
			<summary>StaxEventItemReader stops reading when exception occurs during unmarshalling</summary>
			<description>When an exception occurs during unmarshalling the reader stops reading even though there are still items / fragments to read. I think I have found the reason as well and I&amp;amp;apos;ll try to explain below. I&amp;amp;apos;m very surprised that nobody has come across this before. 
Spring batch version used: 2.1.7
Spring version used: 3.0.5
Java version: 6
Happy flow:
1.1. In the StaxEventItemReader.doRead() method, the StaxEventItemReader first tries to move the cursor to the next fragment using the moveCursorToNextFragment(..) method; 
1.2. If a next fragment is found, a call is made to the marshaller to unmarshall the xml fragment; 
1.3. If the unmarshalling is ok, the reader calls &amp;amp;apos;markFragmentProcessed()&amp;amp;apos; on the fragment event reader (DefaultFragmentEventReader). At this stage, the fragment event reader members are &amp;amp;apos;endFragmentFollows=true&amp;amp;apos; and &amp;amp;apos;insideFragment=true&amp;amp;apos;. This is important to note, because these flags play a big part in this issue;
1.4. The markFragmentProcessed() method reads all the unread events using the nextEvent() method until EndDocument is found (which is in fact the end of the fragment). Somewhere down the line, the fragment reader members &amp;amp;apos;endFragmentFollows&amp;amp;apos; and &amp;amp;apos;insideFragment&amp;amp;apos; are reset to false (which is good).
2.1. When the next item is read, the StaxEventItemReader tries to move the cursor to the next fragment. And so on...
Problem flow:
1.1. In the doRead() method, the StaxEventItemReader first tries to move the cursor to the next fragment using the moveCursorToNextFragment(..) method; 
1.2. If a next fragment is found, a call is made to the marshaller to umarshall the xml fragment;
1.3. Exception occurs during unmarshalling and therefore the call to &amp;amp;apos;markFragmentProcessed()&amp;amp;apos; is never done. The members of the fragment event reader are therefore NOT reset and keep the values &amp;amp;apos;endFragmentFollows=true&amp;amp;apos; and &amp;amp;apos;insideFragment=true&amp;amp;apos;.
2.1. When the next item is read, the StaxEventItemReader tries to move the cursor to the next fragment. This method will call nextEvent() on the fragment event reader, returning EndDocument because the internal state of the fragment event reader was not reset due to the exception earlier 
(i.e. &amp;amp;apos;endFragmentFollows&amp;amp;apos; and &amp;amp;apos;insidedFragment&amp;amp;apos; are still both true). Therefore, the moveCursorToNextFragment() method will return false indicating NO next fragment was found and stops the reading.
To prove the analysis above, I have modified the StaxEventItemReader class and ran some tests. I have moved the call to fragmentReader.markFragmentProcessed() into a finally block, making sure it will always get called (whether the unmarshalling fails or not). After this modification, the StaxEventItemReader works as expected, continuing reading and skipping input when unmarshalling fails for an item. 
See the code modification below. Perhaps this is not the best way to solve this issue, but it proves the problem. 
protected T doRead() throws Exception {
    if (noInput) 
{
        return null;
    }

    T item = null;
    boolean success = false;
    try 
{
        success = moveCursorToNextFragment(fragmentReader);
    }
    catch (NonTransientResourceException e) 
{
        // Prevent caller from retrying indefinitely since this is fatal
        noInput = true;
        throw e;
    }

    if (success) {
        fragmentReader.markStartFragment();
        try 
{ // Added by Pepijn Opsteegh
            @SuppressWarnings("unchecked")
            T mappedFragment = (T) unmarshaller.unmarshal(StaxUtils.getSource(fragmen tReader));
            item = mappedFragment;
        }
 finally 
{ // Added by Pepijn Opsteegh
            fragmentReader.markFragmentProcessed();
        }
 // Added by Pepijn Opsteegh
    }
    return item;
}</description>
			<version>2.1.7</version>
			<fixedVersion>2.1.8</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemReaderTests.java</file>
			<file type="M">org.springframework.batch.item.xml.stax.DefaultFragmentEventReader.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemReader.java</file>
		</fixedFiles>
	</bug>
	<bug id="1742" opendate="2011-05-04 00:43:40" fixdate="2011-05-04 01:19:24" resolution="Complete">
		<buginformation>
			<summary>HippyMethodInvoker fails when target uses method overloading and there is no exact match for arguments</summary>
			<description>See the failing test (testOverloadedMethodUsingInputWithoutExactMatch) at https://github.com/magott/spring-batch/blob/master/spring-batch-infrastructure/src/test/java/org/springframework/batch/item/adapter/HippyMethodInvokerTests.java
 The issue is that if you have an overloaded method where one of the methods is a match, but not an exact match (ie: foo(Set) and foo(List) with TreeSet being passed as the argument). An IllegalArgumentException is thrown.</description>
			<version>2.1.7</version>
			<fixedVersion>2.1.8</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.adapter.HippyMethodInvokerTests.java</file>
			<file type="M">org.springframework.batch.item.adapter.HippyMethodInvoker.java</file>
		</fixedFiles>
	</bug>
	<bug id="1743" opendate="2011-05-04 01:47:50" fixdate="2011-05-04 01:49:13" resolution="Complete">
		<buginformation>
			<summary>Use step scope for PartitionHandler (so gridSize can be a job parameter) - broken in 2.1.7.</summary>
			<description>Cloned from: BATCH-1612: Pull gridSize from job parameters
https://jira.springsource.org/browse/BATCH-1612</description>
			<version>2.1.7</version>
			<fixedVersion>2.1.8</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParserStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParserStepFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.partition.support.TaskExecutorPartitionHandler.java</file>
		</fixedFiles>
	</bug>
	<bug id="1739" opendate="2011-04-28 08:17:32" fixdate="2011-05-04 04:05:35" resolution="Complete">
		<buginformation>
			<summary>Inheriting from parent step with skip-limit/retry-limit causes IllegalArgumentException when the inheriting bean doesn&amp;apos;t define exception-classes.</summary>
			<description>The error for the supplied example job (needs infrastructure) is: 
"IllegalArgumentException: The field &amp;amp;apos;skip-limit&amp;amp;apos; is not permitted on the step [myStep] because there is no &amp;amp;apos;skippable-exception-classes&amp;amp;apos;"</description>
			<version>2.1.7</version>
			<fixedVersion>2.1.8</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.ParentStepFactoryBeanParserTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.ChunkElementParser.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBeanRollbackTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParserStepFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.ChunkElementParserTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBean.java</file>
		</fixedFiles>
	</bug>
	<bug id="1744" opendate="2011-05-04 04:02:47" fixdate="2011-05-05 01:06:34" resolution="Complete">
		<buginformation>
			<summary>Revert retry-limit and skip-limit changes from BATCH-1396.</summary>
			<description>The changes in BATCH-1396 for retry-limit and skip-limit caused too many problems with step inheritance (parent="..." in a step).  This task is to track the release of a new version that reverts those changes.  You can still do late binding of those values by injecting a retry-policy or skip-policy, and that might be as far as we ever go. </description>
			<version>2.1.7</version>
			<fixedVersion>2.1.8</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.ParentStepFactoryBeanParserTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.ChunkElementParser.java</file>
		</fixedFiles>
	</bug>
	<bug id="1703" opendate="2011-03-02 01:13:07" fixdate="2011-05-08 00:44:02" resolution="Complete">
		<buginformation>
			<summary>MapStepExecutionDao does not add StepExecutions to a JobExecution correctly</summary>
			<description>MapStepExecutionDao does not add StepExecutions to a JobExecution correctly.  Since the JobExecution has a hash-based collection of step executions, if you add more with the same ID they do not overwrite.</description>
			<version>2.1.6</version>
			<fixedVersion>2.1.8</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.repository.dao.MapStepExecutionDaoTests.java</file>
			<file type="M">org.springframework.batch.core.JobExecution.java</file>
		</fixedFiles>
	</bug>
	<bug id="1775" opendate="2011-07-27 00:03:46" fixdate="2011-07-27 01:39:07" resolution="Complete">
		<buginformation>
			<summary>Inner beans of same type inside &lt;chunk/&gt; elements with scope ="step" leads to mistaken override of bean definitions</summary>
			<description>I&amp;amp;apos;v the following job configuration: 






&amp;lt;batch:job id="file2fileJob"&amp;gt;




	&amp;lt;batch:step id="file2fileJobStep1"&amp;gt;




		&amp;lt;batch:tasklet&amp;gt;




			&amp;lt;batch:chunk commit-interval="1" writer="itemToStringFlatFileItemWriter"&amp;gt;




				&amp;lt;batch:reader&amp;gt;




					&amp;lt;bean class="org.springframework.batch.item.file.FlatFileItemReader" scope="step"&amp;gt;




						&amp;lt;property name="resource" value="#{jobParameters[&amp;amp;apos;input.file.name&amp;amp;apos;]}" /&amp;gt;




						&amp;lt;property name="lineMapper"&amp;gt;




							&amp;lt;bean class="org.springframework.batch.item.file.mapping.PassThroughLineMapper" /&amp;gt;




						&amp;lt;/property&amp;gt;




					&amp;lt;/bean&amp;gt;




				&amp;lt;/batch:reader&amp;gt;




			&amp;lt;/batch:chunk&amp;gt;




		&amp;lt;/batch:tasklet&amp;gt;




	&amp;lt;/batch:step&amp;gt;




&amp;lt;/batch:job&amp;gt;






and the following test: 






@Test




public void file2fileJob() throws Exception {




	/* setup */




	Map&amp;lt;String, JobParameter&amp;gt; parameters = new HashMap&amp;lt;String, JobParameter&amp;gt;();




	parameters.put("input.file.name", new JobParameter("users.csv"));




	File output = testFolder.newFile("output.txt");




	output.createNewFile();




	parameters.put("output.file.name", new JobParameter("file:" + output.getAbsolutePath()));




	/* exercise */




	launcher.run(file2fileJob, new JobParameters(parameters));




	/* verify */




	Resource input = new ClassPathResource("users.csv");




	assertEquals("Input and output should be equal", FileUtils.readLines(input.getFile()), FileUtils.readLines(output));




}






The test is successful. 
But if I had the following job configuration:






&amp;lt;batch:job id="file2DatabaseJob"&amp;gt;




	&amp;lt;batch:step id="file2DatabaseJobStep1"&amp;gt;




		&amp;lt;batch:tasklet&amp;gt;




			&amp;lt;batch:chunk commit-interval="1" writer="itemToStringFlatFileItemWriter"&amp;gt;




			&amp;lt;!-- TODO - save the User in the database --&amp;gt;




				&amp;lt;batch:reader&amp;gt;




					&amp;lt;bean class="org.springframework.batch.item.file.FlatFileItemReader" scope="step"&amp;gt;




						&amp;lt;property name="resource" value="#{jobParameters[&amp;amp;apos;input.file.name&amp;amp;apos;]}" /&amp;gt;




						&amp;lt;property name="lineMapper"&amp;gt;




							&amp;lt;bean class="org.springframework.batch.item.file.mapping.DefaultLineMapper"&amp;gt;




								&amp;lt;property name="lineTokenizer"&amp;gt;




									&amp;lt;bean class="org.springframework.batch.item.file.transform.DelimitedLineTokenizer" /&amp;gt;




								&amp;lt;/property&amp;gt;




								&amp;lt;property name="fieldSetMapper"&amp;gt;




									&amp;lt;bean class="org.springframework.batch.UserFieldSetMapper" /&amp;gt;




								&amp;lt;/property&amp;gt;




							&amp;lt;/bean&amp;gt;




						&amp;lt;/property&amp;gt;




					&amp;lt;/bean&amp;gt;




				&amp;lt;/batch:reader&amp;gt;




			&amp;lt;/batch:chunk&amp;gt;




		&amp;lt;/batch:tasklet&amp;gt;




	&amp;lt;/batch:step&amp;gt;




&amp;lt;/batch:job&amp;gt;






the same test fails because the &amp;amp;apos;file2fileJobStep1&amp;amp;apos; lineMapper is no more a PassThroughLineMapper but the same as the file2DatabaseJobStep1 lineMapper... 
If I remove the scope attribute (and update the resource value to an hard-coded value) of the file2fileJobStep1 reader, the test is successful again.  </description>
			<version>2.1.8</version>
			<fixedVersion>2.1.9</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.InlineItemHandlerParserTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.ChunkElementParser.java</file>
		</fixedFiles>
	</bug>
	<bug id="1756" opendate="2011-05-24 18:41:50" fixdate="2011-08-02 09:16:30" resolution="Complete">
		<buginformation>
			<summary>Make  round-trip JobParameters-&gt;Properties-&gt;JobParameters work for double parameters</summary>
			<description>Make  round-trip JobParameters-&amp;gt;Properties-&amp;gt;JobParameters work for double parameters. Here is the customer&amp;amp;apos;s use case for this - "I want to use the JobOperator interface to start jobs and that requires passing the parameters in the string format. So I need a way to generate a correct string representation of JobParameters that will be accepted by JobOperator. I assumed DefaultJobParametersConverter is the way to go. But to be even more specific I&amp;amp;apos;m trying to build a mechanism for starting jobs in a clustered environment and the approach is to use JMS messages. The client would invoke an API (passing JobParameters) which behind the scenes will take the JobParameters, convert it to the String format and put it in a JMS messages that gets placed on a queue. On the other side of the queue a component receives the message, extracts the String of job parameters and calls JobOperator. I don&amp;amp;apos;t want to be responsible for creating the correct string format of JobParameters so I&amp;amp;apos;m counting on classes provided by the framework." 
Code snippet for demonstration:
@Test
public void testDefaultJobParametersConverter() {
DefaultJobParametersConverter converter = new DefaultJobParametersConverter();
JobParametersBuilder builder = new JobParametersBuilder();
Double val = Double.valueOf(222);
builder.addDouble("doubleParam", val);
JobParameters params = builder.toJobParameters();
Map&amp;lt;String, JobParameter&amp;gt; map = params.getParameters();
JobParameter jp = map.get("doubleParam");
assertNotNull(jp);
assertEquals(ParameterType.DOUBLE, jp.getType());
Properties props = converter.getProperties(params);
params = converter.getJobParameters(props);
map = params.getParameters();
jp = map.get("doubleParam");
assertNotNull(jp);
assertEquals(ParameterType.DOUBLE, jp.getType());
assertEquals(val, jp.getValue());
}</description>
			<version>2.1.7</version>
			<fixedVersion>2.1.9</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.converter.DefaultJobParametersConverter.java</file>
			<file type="M">org.springframework.batch.core.converter.DefaultJobParametersConverterTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1798" opendate="2011-10-07 13:40:57" fixdate="2011-10-09 03:52:23" resolution="Fixed">
		<buginformation>
			<summary>MultiResourceItemReader fails on Restart if read() method was not called.</summary>
			<description>The MultiResourceItemReader starts with -1 as currentResource. If the ItemProcessor fails on first commit (I tested with a "throw new RuntimeException()"), this index remains -1 on ExecutionContext. Then, on restart, we get:
 java.lang.ArrayIndexOutOfBoundsException: -1
	at org.springframework.batch.item.file.MultiResourceItemReader.open(MultiResourceItemReader.java:171)
The fix is something like:
   if (executionContext.containsKey(executionContextUserSupport.getKey(RESOURCE_KEY))) {
	currentResource = executionContext.getInt(executionContextUserSupport.getKey(RESOURCE_KEY));
	// begin fix block
	if (currentResource == -1) 
{
		currentResource = 0;
	}
        // end fix block
        delegate.setResource(resources[currentResource]);
	delegate.open(executionContext);
   }</description>
			<version>2.1.8</version>
			<fixedVersion>2.1.9</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.MultiResourceItemReaderIntegrationTests.java</file>
			<file type="M">org.springframework.batch.item.file.MultiResourceItemReader.java</file>
		</fixedFiles>
	</bug>
	<bug id="1783" opendate="2011-08-10 06:21:53" fixdate="2011-11-02 06:52:12" resolution="Complete">
		<buginformation>
			<summary>Throwing exceptions inside a ChunkListener results in endless loop</summary>
			<description>If an exception is thrown in beforeChunk in a ChunkListener and the job is configured with skips (but not to skip the exception that is thrown from the ChunkListener) it will result in an endless loop. Same will happen if you have configured your job for retries.
If neither retry nor skip is configured, the job will end with ExitStatus.FAILED, as expected. Which makes me suspect the issue is in the exception handling in some of the components added when skip or retry comes into play.
I&amp;amp;apos;ve attached two files based on the Spring Batch template from STS that can be dropped in to reproduce the issue.</description>
			<version>2.1.8</version>
			<fixedVersion>2.1.9</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBeanRollbackTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.step.item.SimpleStepFactoryBean.java</file>
		</fixedFiles>
	</bug>
	<bug id="1837" opendate="2012-02-21 16:46:48" fixdate="2012-02-22 08:24:36" resolution="Complete">
		<buginformation>
			<summary>Spring 3 Compatibility Tests Failing</summary>
			<description>Compile errors in 2 tests.</description>
			<version>2.1.8</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.sample.domain.mail.internal.TestMailSender.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.InlineItemHandlerParserTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1826" opendate="2011-12-18 22:36:51" fixdate="2012-04-06 06:56:44" resolution="Fixed">
		<buginformation>
			<summary>Null pointer exception if optional parameter of type DATE is null</summary>
			<description>Selecting some of the jobs in spring-batch-admin leads to the following exception:
(Issue occurs when we use spring-batch-admin latest release version which internally uses spring-batch-core 2.1.5)
java.lang.IllegalArgumentException: Cannot format given Object as a Date
	java.text.DateFormat.format(DateFormat.java:301)
	java.text.Format.format(Format.java:157)  
        org.springframework.batch.core.converter.DefaultJobParametersConverter
       .getProperties(DefaultJobParametersConverter.java:159)
	org.springframework.batch.admin.web.JobInstanceInfo.&amp;lt;init&amp;gt;(JobInstanceInfo.java:42)
	org.springframework.batch.admin.web.JobController.details(JobController.java:171)
Found that the exception occurs in : DefaultJobParametersConverter.java line no:158 (in spring batch core v2.1.5)
if (jobParameter.getType() == ParameterType.DATE) {
result.setProperty(key + DATE_TYPE, dateFormat.format(value));
}
when "value" is null.
Ideally there should be check to ignore null valued parameters.
This can be fixed by :
158 : if(value != null) 
{

168 : }

Can someone check this?
Thanks,
Gayathri</description>
			<version>2.1.5</version>
			<fixedVersion>2.1.9</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.converter.DefaultJobParametersConverter.java</file>
			<file type="M">org.springframework.batch.core.converter.DefaultJobParametersConverterTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1841" opendate="2012-03-01 17:50:58" fixdate="2012-05-11 05:05:41" resolution="Complete">
		<buginformation>
			<summary>Upgrading to spring batch 2.1.8 causes error in processing xml configuration</summary>
			<description>We are just upgrading to 2.1.8 and our existing xml batch configuration will no longer load.  
Here is a snippet of the configuration that is failing:






    &amp;lt;bean id="simpleStep" class="org.springframework.batch.core.step.item.FaultTolerantStepFactoryBean"




          abstract="true"&amp;gt;




        &amp;lt;property name="transactionManager" ref="transactionManager"/&amp;gt;




        &amp;lt;property name="jobRepository" ref="jobRepository"/&amp;gt;




        &amp;lt;property name="startLimit" value="100"/&amp;gt;




        &amp;lt;property name="commitInterval" value="1"/&amp;gt;




        &amp;lt;property name="backOffPolicy"&amp;gt;




            &amp;lt;bean class="org.springframework.batch.retry.backoff.ExponentialBackOffPolicy"&amp;gt;




                &amp;lt;property name="initialInterval" value="1000"/&amp;gt;




            &amp;lt;/bean&amp;gt;




        &amp;lt;/property&amp;gt;




        &amp;lt;property name="retryLimit" value="5"/&amp;gt;




        &amp;lt;property name="retryableExceptionClasses"&amp;gt;




            &amp;lt;map&amp;gt;




                &amp;lt;entry key="org.springframework.dao.ConcurrencyFailureException" value="true"/&amp;gt;




            &amp;lt;/map&amp;gt;




        &amp;lt;/property&amp;gt;




    &amp;lt;/bean&amp;gt;









    &amp;lt;step id="createCatalogueValidateStep" parent="simpleStep" next="createCataloguePostValidateStep"&amp;gt;




         &amp;lt;tasklet transaction-manager="transactionManager"&amp;gt;




             &amp;lt;chunk reader="csvStagedProductReader" writer="hibernateStagedProductWriter" commit-interval="10"/&amp;gt;




             &amp;lt;listeners&amp;gt;




                 &amp;lt;listener ref="createCatalogueValidateItemListener"/&amp;gt;




             &amp;lt;/listeners&amp;gt;




         &amp;lt;/tasklet&amp;gt;




    &amp;lt;/step&amp;gt;






And we are getting the error:
The field &amp;amp;apos;retry-limit&amp;amp;apos; is not permitted on the step [createCatalogueValidateStep] because there is no &amp;amp;apos;retryable-exception-classes&amp;amp;apos;.
When I debug the code, I can see that the StepParserStepFactoryBean has a retryLimit which it got from the parent bean but no retryableExceptionClasses.  Further investigation lead me to this code in ChunkElementParser:






	// Even if there is no retryLimit, we can still accept exception




	// classes for an abstract parent bean definition




	propertyValues.addPropertyValue("retryableExceptionClasses", retryableExceptions);






The problem is that this always sets the retryableExceptionClasses property even if it is not provided.  When the bean definitions are merged, the parent bean&amp;amp;apos;s definition of retryableExceptionClasses is overridden by an empty definition.</description>
			<version>2.1.8</version>
			<fixedVersion>2.1.9</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.ChunkElementParser.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.ChunkElementParserTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1753" opendate="2011-05-19 09:36:12" fixdate="2012-06-27 02:34:38" resolution="Complete">
		<buginformation>
			<summary>Problems With FlatFileItemWriter: error while trying to restart an execution </summary>
			<description>We are having problems with property "shouldDeleteIfEmpty" from FlatFileItemWriter.
If an error occurs during an execution, we are unable to restart application because the re-execution cannot find the files created at first time. For example:
Application functionality:
We have an application which receive an input file "INPUT.TXT". The invalid data from input file gets a "rejected" status and are recorded in a file named "INPUT.TXT.REJ". The valid data are processed and generate an output file "OUTPUT.TXT".
Both files, output and rejected, are generated by FlatFileItemWriter, and they have property "shouldDeleteIfEmpty" with value=true.
Error scenario:
If we didn&amp;amp;apos;t give reading permission and execute the application, it will not be able to read INPUT.TXT file. So an exception is thrown. Then we give reading permission, and try to re-execute the application. Another Exception is thrown because the application cannot read the output file or the rejected file that were created at first execution. The files were deleted because when the error occurred both files were empty.
Because of these problems we can&amp;amp;apos;t execute reprocessing. I believe the re-execution should be able to create a new file if it doesn&amp;amp;apos;t exists.</description>
			<version>2.1.7</version>
			<fixedVersion>2.1.9</fixedVersion>
			<type>Defect</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.FlatFileItemWriterTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1804" opendate="2011-10-28 07:39:15" fixdate="2012-06-27 07:52:00" resolution="Complete">
		<buginformation>
			<summary>Retry does not work if additional exception occurs in the ItemWriter during scan for failure</summary>
			<description>I expect the configuration &amp;lt;chunk commit-interval="5" retry-limit="5" skip-limit="5"&amp;gt; to be applied for both processor and writer. This does not seem to work as expected with the writer, where retry is non at all, if the writer runs in "recoverer".
The attachment contains a maven-project that demonstrates the issue:
1. springbatch.test.components.batch.retry_in_writer.RetryInWriterTest
2. springbatch.test.components.batch.retry_in_processor.RetryInProcessorTest
The first test will do all work in the writer and the batch fails because a functional error causes the writer to be run in recoverer. The first item will be skipped. The second item will get a deadlock on the first try, this is not handled with a retry and causes the batch to fail.
The second test does the work in the processor (which seems like the right thing to do, but that is not the point. The first item will be skipped. The second item will get the deadlock, retried and the processor will continue to process the rest of the chunk.
It seems that the errorhandling works as expected in the processor, but not in the writer. Our solution is to use the processor and just do flush in the writer, but it would be nice to have the same errorhandling in the writer or an explanation on why not.</description>
			<version>2.1.8</version>
			<fixedVersion>2.1.9</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantChunkProcessorTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantChunkProcessor.java</file>
		</fixedFiles>
	</bug>
	<bug id="1761" opendate="2011-06-17 06:25:26" fixdate="2012-06-28 07:26:02" resolution="Complete">
		<buginformation>
			<summary>Only first item in chunk is re-processed on retry of failed write</summary>
			<description>http://forum.springsource.org/showthread.php?110196-itemprocessor-recalled-only-for-first-item-in-chunk-when-retryable-exception
All items are eventually re-processed if the chunk fails the same way deterministically, or if retry is not used (skip may be though).</description>
			<version>2.1.8</version>
			<fixedVersion>2.1.9</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBeanTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBeanRetryTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantStepFactoryBeanRollbackTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.BatchRetryTemplate.java</file>
			<file type="M">org.springframework.batch.core.step.item.FaultTolerantChunkProcessor.java</file>
		</fixedFiles>
	</bug>
	<bug id="1813" opendate="2011-11-11 10:05:13" fixdate="2012-07-17 01:22:35" resolution="Complete">
		<buginformation>
			<summary>BeanWrapperFieldSetMapper properties caching is broken</summary>
			<description>The fix for BATCH-1709 broke the caching of the property name mapping cache in getBeanProperties().
On the first run through an empty ConcurrentHashMap is put in "propertiesMatched" at the top of getBeanProperties(), the "matches" Map is then seeded with this empty ConcurrentHashMap but at the bottom of getBeanProperties the updated "matches" Map isn&amp;amp;apos;t written back to that ConcurrentHashMap.
On large numbers of items with a lot of properties, this really hurts performance.</description>
			<version>2.1.8</version>
			<fixedVersion>2.1.9</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.mapping.BeanWrapperFieldSetMapper.java</file>
		</fixedFiles>
	</bug>
	<bug id="1848" opendate="2012-04-03 06:37:22" fixdate="2012-07-17 01:26:30" resolution="Complete">
		<buginformation>
			<summary>JdbcPagingItemReader does not support table or column aliases due to sortKey being used in where clause, order by clause and for retrieval of result set column</summary>
			<description>The SqlPagingQueryProviderFactoryBean class takes a parameter sortKey used to enable paged queries.  This is used in the where clause (to select skip rows already selected in subsequent queries), in an order by clause and to retrieve the result set value for the last item read.  The exact use is determined by the database type, but the general pattern remains the same.
The examples in the tutorial appear fairly simple, involving a single table only.  We have a use case where two aliased tables are involved.  As the table alias prefix is required in the where clause, appears to be optional in the order by clause and cannot be present when retrieving the result set column by name we have a problem as sortKey is used in all three cases.
For a page size of 2 we set the reader&amp;amp;apos;s queryProvider properties set as follows:
		&amp;lt;property name="queryProvider"&amp;gt;
			&amp;lt;bean class="org.springframework.batch.item.database.support.SqlPagingQueryProviderFactoryBean"&amp;gt;
				&amp;lt;property name="selectClause" value="select  t1.id, t1.field, t2.other_field" /&amp;gt;
				&amp;lt;property name="dataSource" ref="dataSource" /&amp;gt;
				&amp;lt;property name="fromClause" value="from TABLE_1 t1, TABLE_2 t2 " /&amp;gt;
				&amp;lt;property name="whereClause" value="t1.id = t2.id" /&amp;gt;
				&amp;lt;property name="sortKey" value="t1.id" /&amp;gt;
			&amp;lt;/bean&amp;gt;
		&amp;lt;/property&amp;gt;
The Derby query resulting for the first page is:
SELECT * FROM ( SELECT t1.id, t1.field, t2.other_field, ROW_NUMBER() OVER () AS ROW_NUMBER FROM TABLE_1 t1, TABLE_2 t2 WHERE t1.id = t2.id ORDER BY t1.id ASC) AS TMP_SUB WHERE TMP_SUB.ROW_NUMBER &amp;lt;= 2
And queries for subsequent pages are:
SELECT * FROM ( SELECT t1.id, t1.field, t2.other_field, ROW_NUMBER() OVER () AS ROW_NUMBER FROM TABLE_1 t1, TABLE_2 t2 WHERE t1.id = t2.id  AND t1.id &amp;gt; ? ORDER BY t1.id ASC) AS TMP_SUB WHERE TMP_SUB.ROW_NUMBER &amp;lt;= 2
In H2 the query for the initial page is:
SELECT TOP 2 t1.id, t1.field, t2.other_field FROM TABLE_1 t1, TABLE_2 t2 WHERE t1.id = t2.id ORDER BY t1.id ASC
And queries for sebsequent pages are:
SELECT TOP 2 t1.id, t1.field, t2.other_field FROM TABLE_1 t1, TABLE_2 t2 WHERE t1.id = t2.id AND t1.id &amp;gt; :_sortKey ORDER BY id ASC
In both Derby and H2 the result set column retrieval fails.
We&amp;amp;apos;ve worked around the problem by subclassing JdbcPagingItemReader and with tricks with reflection effectively changing the line in the inner class JdbcPagingItemReader.PagingRowMapper "startAfterValue = rs.getObject(queryProvider.getSortKey());" to "startAfterValue = rs.getObject(stripAlias(queryProvider.getSortKey()));" where the method stripAlias is defined as:
        private String stripAlias(String column) {
            int separator = column.indexOf(&amp;amp;apos;.&amp;amp;apos;);
            if(separator &amp;gt; 0) {
                int columnIndex = separator + 1;
                if(columnIndex &amp;lt; column.length()) 
{
                    column = column.substring(columnIndex);
                }
            }
            return column;
        }
We&amp;amp;apos;d like this change made to this class directly or something else with similar effect.
Another issue you might wish to consider is that a column alias would further confuse things (as it would be required to be used for the order by clause and to retrieve the value from the result set, but not for the where clause).  Perhaps an additional optional property "sortKeyAlias"?</description>
			<version>2.1.8</version>
			<fixedVersion>2.1.9</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.support.AbstractSqlPagingQueryProvider.java</file>
			<file type="M">org.springframework.batch.item.database.support.SqlPagingQueryUtils.java</file>
			<file type="M">org.springframework.batch.item.database.support.SqlWindowingPagingQueryProvider.java</file>
			<file type="M">org.springframework.batch.item.database.JdbcPagingItemReader.java</file>
			<file type="M">org.springframework.batch.item.database.PagingQueryProvider.java</file>
		</fixedFiles>
	</bug>
	<bug id="1853" opendate="2012-05-04 07:49:39" fixdate="2012-07-17 01:31:03" resolution="Complete">
		<buginformation>
			<summary>JobParamters.getDate() throws NPE if no value exists for that date</summary>
			<description>The following test fails:
@Test
public void testDateReturnsNullWhenKeyDoesntExit(){
     assertNull(new JobParameters().getDate("keythatdoesntexist"));
}
In the same scenario, if you ask for a key that doesn&amp;amp;apos;t have a corresponding parameter, you will get Null in the case of String, 0 for Long, 0.0 for double, and NPE for Date. Date should return null.</description>
			<version>2.1.8</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.JobParametersTests.java</file>
			<file type="M">org.springframework.batch.core.JobParameters.java</file>
		</fixedFiles>
	</bug>
	<bug id="1822" opendate="2011-12-09 10:33:25" fixdate="2012-07-23 03:52:15" resolution="Complete">
		<buginformation>
			<summary>Job execution marked as STOPPED when exception occurs while committing StepExecution</summary>
			<description>When an exception occurs while committing StepExecution (in org.springframework.batch.core.step.tasklet.TaskletStep.ChunkTransactionCallback#doInTransaction()) setTerminateOnly is being called on the step execution. This results in the job execution being marked as STOPPED. I think it&amp;amp;apos;s better to mark the job execution as FAILED? The STOPPED status in general indicates the job has been stopped in a controlled way (via spring-batch gui, programmatically via the JobOperator API, ...).</description>
			<version>2.1.8</version>
			<fixedVersion>2.1.9</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.job.flow.FlowJobTests.java</file>
			<file type="M">org.springframework.batch.core.JobInterruptedException.java</file>
			<file type="M">org.springframework.batch.core.job.AbstractJob.java</file>
			<file type="M">org.springframework.batch.core.job.SimpleJobTests.java</file>
			<file type="M">org.springframework.batch.core.job.flow.JobFlowExecutor.java</file>
		</fixedFiles>
	</bug>
	<bug id="1884" opendate="2012-08-30 12:59:13" fixdate="2012-09-11 22:18:26" resolution="Complete">
		<buginformation>
			<summary>JobLauncherIntegrationTests failing</summary>
			<description>schema-hsqldb.sql wasn&amp;amp;apos;t being found, DataSourceInitializer.doExecuteScript will just return if the scriptResource does not exist. easy fix, pull request to come.






org.springframework.jdbc.BadSqlGrammarException: StatementCallback; bad SQL grammar [select count(*) from BATCH_JOB_INSTANCE]; nested exception is java.sql.SQLException: Table not found in statement [select count(*) from BATCH_JOB_INSTANCE]




	at org.springframework.jdbc.support.SQLErrorCodeSQLExceptionTranslator.doTranslate(SQLErrorCodeSQLExceptionTranslator.java:220)




	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)




	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:407)




	at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:458)




	at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:466)




	at org.springframework.jdbc.core.JdbcTemplate.queryForObject(JdbcTemplate.java:474)




	at org.springframework.jdbc.core.JdbcTemplate.queryForObject(JdbcTemplate.java:479)




	at org.springframework.jdbc.core.JdbcTemplate.queryForInt(JdbcTemplate.java:488)




	at org.springframework.jdbc.core.simple.SimpleJdbcTemplate.queryForInt(SimpleJdbcTemplate.java:119)




	at org.springframework.batch.core.launch.JobLauncherIntegrationTests.testLaunchAndRelaunch(JobLauncherIntegrationTests.java:41)




	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)




	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)




	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)




	at org.springframework.test.context.junit4.SpringTestMethod.invoke(SpringTestMethod.java:160)




	at org.springframework.test.context.junit4.SpringMethodRoadie.runTestMethod(SpringMethodRoadie.java:233)




	at org.springframework.test.context.junit4.SpringMethodRoadie$RunBeforesThenTestThenAfters.run(SpringMethodRoadie.java:333)




	at org.springframework.test.context.junit4.SpringMethodRoadie.runWithRepetitions(SpringMethodRoadie.java:217)




	at org.springframework.test.context.junit4.SpringMethodRoadie.runTest(SpringMethodRoadie.java:197)




	at org.springframework.test.context.junit4.SpringMethodRoadie.run(SpringMethodRoadie.java:143)




	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.invokeTestMethod(SpringJUnit4ClassRunner.java:160)




	at org.junit.internal.runners.JUnit4ClassRunner.runMethods(JUnit4ClassRunner.java:51)




	at org.junit.internal.runners.JUnit4ClassRunner$1.run(JUnit4ClassRunner.java:44)




	at org.junit.internal.runners.ClassRoadie.runUnprotected(ClassRoadie.java:27)




	at org.junit.internal.runners.ClassRoadie.runProtected(ClassRoadie.java:37)




	at org.junit.internal.runners.JUnit4ClassRunner.run(JUnit4ClassRunner.java:42)




	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:97)




	at org.junit.runner.JUnitCore.run(JUnitCore.java:130)




	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:76)




	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:195)




	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:63)




	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)




	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)




	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:120)




Caused by: java.sql.SQLException: Table not found in statement [select count(*) from BATCH_JOB_INSTANCE]




	at org.hsqldb.jdbc.Util.sqlException(Unknown Source)




	at org.hsqldb.jdbc.jdbcStatement.fetchResult(Unknown Source)




	at org.hsqldb.jdbc.jdbcStatement.executeQuery(Unknown Source)




	at org.springframework.jdbc.core.JdbcTemplate$1QueryStatementCallback.doInStatement(JdbcTemplate.java:443)




	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:396)




	... 33 more





</description>
			<version>2.2.0</version>
			<fixedVersion>2.2.0, 2.2.0 - Sprint 12</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">spring-batch-core.src.test.java.test.jdbc.datasource.DataSourceInitializer.java</file>
		</fixedFiles>
	</bug>
	<bug id="1780" opendate="2011-08-03 03:56:06" fixdate="2012-10-26 06:23:02" resolution="Complete">
		<buginformation>
			<summary>Code exception is masked by a batch exception</summary>
			<description>I use a listener class like this:
@Transactional(value = CreditorServicesConstants.TRANSACTION_MANAGER, propagation = Propagation.REQUIRES_NEW)
public class AlertOnErrorItemReadListener implements ItemReadListener&amp;lt;Object&amp;gt; {
  public void onReadError(Exception ex) 
{
     ... some code
    
     FileIn myFileIn = (FileIn) dao.findFileByFileName(filename);

     ... some other code
  }


When I import a test file which contains an error in one record the onReadError method is called with a FlatFileParseException.  
Now the dao call throws a JPA NonUniqueResultException which is translated into org.springframework.dao.IncorrectResultSizeDataAccessException.
This last exception however is never seen nor reported in log output. Only the FlatFileParseException is logged and the code after the dao call is silently
not executed:
[03/08/2011 09:52:49][DEBUG] (AlertOnErrorItemReadListener.java:onReadError:81) EmddItemReadListener.onReadError(class org.springframework.batch.item.file.FlatFileParseException)
[03/08/2011 09:52:49][INFO ] (AlertOnErrorItemReadListener.java:onReadError:116) A technical failure event is raised with the following error message: Parsing error at line: 3 in resource=[URL file:./target/test-classes/data//dom80/work/dom80MigrationTestfile_readError.dat], input=[200000001reference3334445556BE44445555666677111222333446000000 ...
Hibernate: select filein0_.id as id58_, filein0_.creationdate as creation3_58_, filein0_.creditororganization_id as credito15_58_, filein0_.errorcode as errorcode58_, filein0_.errordescription as errordes5_58_, filein0_.fileformat as fileformat58_, filein0_.filename as filename58_, filein0_.lastupdate as lastupdate58_, filein0_.nbofoperations as nbofoper9_58_, filein0_.status as status58_, filein0_.answered as answered58_, filein0_.nbofokrequests as nbofokr12_58_ from File filein0_ where filein0_.DTYPE=&amp;amp;apos;FileIn&amp;amp;apos; and filein0_.filename=? limit ?
[03/08/2011 09:52:49][ERROR] (AbstractStep.java:execute:212) Encountered an error executing the step
org.springframework.batch.core.listener.StepListenerFailedException: Error in onReadError.
java.lang.IllegalArgumentException: Unable to invoke method: [public final void $Proxy61.onReadError(java.lang.Exception)] on object: [net.awl.emdd.creditor.files.in.chunk.dom80.AlertOnErrorListener@11a4e9b] with arguments: [[org.springframework.batch.item.file.FlatFileParseException: Parsing error at line: 3 in resource=[URL file:./target/test-classes/data//dom80/work/dom80MigrationTestfile_readError.dat], input=[200000001reference3334445556BE4444555566667711122233344600000001012010Erwin Lindemann                    125, rue de Bouton 4748 Hergenrath 4748      Hergenrath               KREDBEBB   3334445556614122010]]]
	at org.springframework.batch.core.listener.MulticasterBatchListener.onReadError(MulticasterBatchListener.java:232) ~[spring-batch-core-2.1.8.RELEASE.jar:na]
	at org.springframework.batch.core.step.item.SimpleChunkProvider.doRead(SimpleChunkProvider.java:95) ~[spring-batch-core-2.1.8.RELEASE.jar:na]
	at org.springframework.batch.core.step.item.SimpleChunkProvider.read(SimpleChunkProvider.java:148) ~[spring-batch-core-2.1.8.RELEASE.jar:na]
	at org.springframework.batch.core.step.item.SimpleChunkProvider$1.doInIteration(SimpleChunkProvider.java:108) ~[spring-batch-core-2.1.8.RELEASE.jar:na]
	at org.springframework.batch.repeat.support.RepeatTemplate.getNextResult(RepeatTemplate.java:367) ~[spring-batch-infrastructure-2.1.8.RELEASE.jar:na]
	at org.springframework.batch.repeat.support.RepeatTemplate.executeInternal(RepeatTemplate.java:214) ~[spring-batch-infrastructure-2.1.8.RELEASE.jar:na]
	at org.springframework.batch.repeat.support.RepeatTemplate.iterate(RepeatTemplate.java:143) ~[spring-batch-infrastructure-2.1.8.RELEASE.jar:na]
	at org.springframework.batch.core.step.item.SimpleChunkProvider.provide(SimpleChunkProvider.java:103) ~[spring-batch-core-2.1.8.RELEASE.jar:na]
	at org.springframework.batch.core.step.item.ChunkOrientedTasklet.execute(ChunkOrientedTasklet.java:68) ~[spring-batch-core-2.1.8.RELEASE.jar:na]
	at org.springframework.batch.core.step.tasklet.TaskletStep$ChunkTransactionCallback.doInTransaction(TaskletStep.java:386) ~[spring-batch-core-2.1.8.RELEASE.jar:na]
	at org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:130) ~[spring-tx-3.0.4.RELEASE.jar:3.0.4.RELEASE]
	at org.springframework.batch.core.step.tasklet.TaskletStep$2.doInChunkContext(TaskletStep.java:264) ~[spring-batch-core-2.1.8.RELEASE.jar:na]
	at org.springframework.batch.core.scope.context.StepContextRepeatCallback.doInIteration(StepContextRepeatCallback.java:76) ~[spring-batch-core-2.1.8.RELEASE.jar:na]
	at org.springframework.batch.repeat.support.RepeatTemplate.getNextResult(RepeatTemplate.java:367) ~[spring-batch-infrastructure-2.1.8.RELEASE.jar:na]
	at org.springframework.batch.repeat.support.RepeatTemplate.executeInternal(RepeatTemplate.java:214) ~[spring-batch-infrastructure-2.1.8.RELEASE.jar:na]
	at org.springframework.batch.repeat.support.RepeatTemplate.iterate(RepeatTemplate.java:143) ~[spring-batch-infrastructure-2.1.8.RELEASE.jar:na]
	at org.springframework.batch.core.step.tasklet.TaskletStep.doExecute(TaskletStep.java:250) ~[spring-batch-core-2.1.8.RELEASE.jar:na]
	at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:195) ~[spring-batch-core-2.1.8.RELEASE.jar:na]
	at org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:135) [spring-batch-core-2.1.8.RELEASE.jar:na]
	at org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:61) [spring-batch-core-2.1.8.RELEASE.jar:na]
	at org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:60) [spring-batch-core-2.1.8.RELEASE.jar:na]
	at org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:144) [spring-batch-core-2.1.8.RELEASE.jar:na]
	at org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:124) [spring-batch-core-2.1.8.RELEASE.jar:na]
	at org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:135) [spring-batch-core-2.1.8.RELEASE.jar:na]
	at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:281) [spring-batch-core-2.1.8.RELEASE.jar:na]
	at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:120) [spring-batch-core-2.1.8.RELEASE.jar:na]
	at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:48) [spring-core-3.0.4.RELEASE.jar:3.0.4.RELEASE]
	at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:114) [spring-batch-core-2.1.8.RELEASE.jar:na]
	at net.awl.emdd.creditor.files.in.chunk.dom80.TestDom80Migration.runJob(TestDom80Migration.java:100) [test-classes/:na]
After analysing the Spring Batch sources I found the location why this happened:
The Javadoc of StepListenerFailedException constructor says about the two Exception parameters:
public StepListenerFailedException(String message,
                                   Throwable ex,
                                   RuntimeException e)
Parameters:
    message - describes the error to the user
    ex - the exception that was thrown by a listener
    e - the exception that caused the skip
Following the documentation, in MulticasterBatchListener.onReadError(Exception) the two Exceptions in StepListenerFailedException constructor should be set vice versa:
public void onReadError(Exception ex) {
		try 
{
			itemReadListener.onReadError(ex);
		}
		catch (RuntimeException e) {
			throw new StepListenerFailedException("Error in onReadError.", e, ex);
		}
}

instead of

public void onReadError(Exception ex) {
		try {			itemReadListener.onReadError(ex);		}
		catch (RuntimeException e) 
{
			throw new StepListenerFailedException("Error in onReadError.", ex, e);
		}
}</description>
			<version>2.1.8</version>
			<fixedVersion>2.2.0, 2.2.0 - Sprint 3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.listener.StepListenerFailedException.java</file>
			<file type="M">org.springframework.batch.core.step.item.SimpleChunkProvider.java</file>
			<file type="M">org.springframework.batch.core.listener.MulticasterBatchListener.java</file>
			<file type="M">org.springframework.batch.core.listener.MulticasterBatchListenerTests.java</file>
			<file type="M">org.springframework.batch.core.listener.StepListenerFailedExceptionTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1903" opendate="2012-10-25 18:42:00" fixdate="2012-10-29 07:27:17" resolution="Complete">
		<buginformation>
			<summary>SQL compatibility breakage with HSQL</summary>
			<description>I was testing Spring Batch for the first time with 2.1.9 and an HSQL database.  It was working fine until I tried to restart a failed job.  At that point, a NPE was thrown from the Spring Batch core code.  The reason was that a DAO query for fetching the last job execution details did not return any rows, even though there was a row in the database.
I tried Spring Batch 2.1.8 and it worked fine.  I traced it down to the SQL query itself, which is defined here:
org.springframework.batch.core.repository.dao.JdbcJobExecutionDao.GET_LAST_EXECUTION
This query was recently changed in commit 16e23fc on May 16, 2012.  While part of the change was good (changing to use an ID rather than timestamp to match rows), it broke compatibility with HSQLDB.  Here is the SQL that returns no results:
SELECT JOB_EXECUTION_ID, START_TIME, END_TIME, STATUS, EXIT_CODE, EXIT_MESSAGE, CREATE_TIME, LAST_UPDATED, VERSION
from BATCH_JOB_EXECUTION E where JOB_INSTANCE_ID = 6 and 
JOB_EXECUTION_ID = (SELECT max(JOB_EXECUTION_ID) 
	from BATCH_JOB_EXECUTION E2 where E.JOB_INSTANCE_ID = E2.JOB_INSTANCE_ID)
The problem is that HSQLDB supports correlated subqueries, but apparently not when using the "=" operator.  This query works properly in HSQLDB when making one of the following changes:
1. Change the comparison operator for JOB_EXECUTION_ID from "=" to "IN".  HSQLDB supports the IN clause w/ correlated subqueries.
2. OR remove the subquery correlation by repeating the JDBC parameter instead of referencing E_JOB_INSTANCE_ID.  This is apparently how the query used to work.
I do not know if either proposed change would cause issues in the other supported databases, but I would suspect not.  I also do not know if there are other SQL compatibility issues in 2.1.9, but I can say I didn&amp;amp;apos;t notice any problems when my jobs succeeded.</description>
			<version>2.1.9</version>
			<fixedVersion>2.2.0, 2.2.0 - Sprint 3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcJobExecutionDao.java</file>
		</fixedFiles>
	</bug>
	<bug id="1774" opendate="2011-07-26 06:36:23" fixdate="2012-11-16 11:18:36" resolution="Complete">
		<buginformation>
			<summary>NullPointerException on RepeatTemplate</summary>
			<description>I encountered the following error : the class RepeatTemplate throws a NullPointerException (cf stacktrace below)
The step uses a ThreadPoolTaskExecutor, and i implemented a synchronized delegate reader.
Another person seems to have encountered the same problem in the past : http://forum.springsource.org/archive/index.php/t-61715.html
Here is an extract from the log with the stack trace.






2011-07-06 14:43:05,844 INFO [org.springframework.batch.core.job.SimpleStepHandler] - Executing step: [buildStep]




2011-07-06 14:43:10,672 WARN [org.springframework.batch.core.step.item.ChunkMonitor] - No ItemReader set (must be concurrent step), so ignoring offset data.




2011-07-06 14:43:11,396 WARN [org.springframework.batch.core.step.item.ChunkMonitor] - ItemStream was opened in a different thread.  Restart data could be compromised.




2011-07-06 14:52:21,721 ERROR [org.springframework.batch.core.step.AbstractStep] - Encountered an error executing the step




java.lang.NullPointerException




	at org.springframework.batch.repeat.support.RepeatTemplate.executeInternal(RepeatTemplate.java:231)




	at org.springframework.batch.repeat.support.RepeatTemplate.iterate(RepeatTemplate.java:143)




	at org.springframework.batch.core.step.tasklet.TaskletStep.doExecute(TaskletStep.java:250)




	at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:195)




	at org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:135)




	at org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:61)




	at org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:60)




	at org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:144)




	at org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:124)




	at org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:135)




	at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:281)




	at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:120)




	at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:48)




	at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:114)




	at org.springframework.batch.core.launch.support.CommandLineJobRunner.start(CommandLineJobRunner.java:349)




	at org.springframework.batch.core.launch.support.CommandLineJobRunner.main(CommandLineJobRunner.java:574)





</description>
			<version>2.1.7</version>
			<fixedVersion>2.2.0, 2.2.0 - Sprint 6</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.repeat.support.TaskExecutorRepeatTemplate.java</file>
			<file type="D">org.springframework.batch.repeat.support.TaskExecutorRepeatTemplateBulkAsynchronousTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1920" opendate="2012-12-08 10:54:10" fixdate="2012-12-18 11:59:01" resolution="Complete">
		<buginformation>
			<summary>Add sample for new AMQPItemReader &amp; Writer</summary>
			<description>Part of updating some spring-batch-samples.</description>
			<version>2.2.0</version>
			<fixedVersion>2.2.0, 2.2.0 - Sprint 7</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.sample.AMQPJobFunctionalTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1916" opendate="2012-12-05 08:16:10" fixdate="2012-12-21 07:45:02" resolution="Complete">
		<buginformation>
			<summary>RecordSeparatorPolicy#isEndOfRecord wrong javadoc?</summary>
			<description>I have an issue using FlatFileItemReader with a custom RecordSeparatorPolicy. The javadoc of RecordSeparatorPolicy#isEndOfRecord  tells 

Signal the end of a record based on the content of a line, being the latest line read from an input source. The input is what you would expect from BufferedReader.readLine() - i.e. no line separator character at the end. But it might have line separators embedded in it.
I would think the parameter is last read line from file. If I see the code of 
FlatFileItemReader#applyRecordSeparatorPolicy






 




while (line != null &amp;amp;&amp;amp; !recordSeparatorPolicy.isEndOfRecord(record)) {






Actually this is not a line, this is whole record. It makes FlatFileItemReader unusable for my purposes. </description>
			<version>2.1.8</version>
			<fixedVersion>2.2.0, 2.2.0 - Sprint 8</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.separator.RecordSeparatorPolicy.java</file>
		</fixedFiles>
	</bug>
	<bug id="1795" opendate="2011-09-19 20:29:18" fixdate="2012-12-27 08:04:33" resolution="Complete">
		<buginformation>
			<summary>ExponentialBackOffPolicy and BackOffContext</summary>
			<description>Hi,
I configure a ExponentialBackOffPolicy like this:






 




    &amp;lt;bean id="exponentialBackOffPolicy" class="org.springframework.batch.retry.backoff.ExponentialBackOffPolicy"




        p:initialInterval="500" p:maxInterval="30000" p:multiplier="2" /&amp;gt;






and use it for DeadLockLoserDataAccessException. Then I intentionally throw a DeadLockLoserDataAccessException in the main part of my item processor code and observe the behaviour. However, the retry never backoffs exponentially. I trace through the RetryTemplate class (in particulary lines 197 - 256 in 2.1.7 release), and the backOffPolicy and its context seem stateless in runtime:






 




	protected &amp;lt;T&amp;gt; T doExecute(RetryCallback&amp;lt;T&amp;gt; retryCallback, RecoveryCallback&amp;lt;T&amp;gt; recoveryCallback, RetryState state)




			throws Exception, ExhaustedRetryException {









		RetryPolicy retryPolicy = this.retryPolicy;




		BackOffPolicy backOffPolicy = this.backOffPolicy;









...




		// Start the backoff context...




		BackOffContext backOffContext = backOffPolicy.start(context);




...




		backOffPolicy.backOff(backOffContext);




...






That is, the backOffPolicy is never updated and the backOffContext is never saved after the call to backoff, hence the interval stays the same value.
I submitted the same issue to the Spring forum and StackOverflow and no answer, hence created this issue.
Thanks, Kev
</description>
			<version>2.1.7</version>
			<fixedVersion>2.2.0, 2.2.0 - Sprint 9</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.retry.support.RetryTemplate.java</file>
			<file type="M">org.springframework.batch.retry.support.RetryTemplateTests.java</file>
		</fixedFiles>
		<links>
			<link type="Relate" description="relates to">226</link>
		</links>
	</bug>
	<bug id="1745" opendate="2011-05-04 09:18:44" fixdate="2013-01-22 11:32:06" resolution="Complete">
		<buginformation>
			<summary>XSD inconsistency: allow-start-if-complete is not allowed on non-tasklet step</summary>
			<description>XSD inconsistency: allow-start-if-complete is not allowed on non-tasklet step.  There is a workaround, but it&amp;amp;apos;s a bit awkward, e.g. here is a flow step which is startable if complete:






	&amp;lt;step id="step1" parent="startable"&amp;gt;




		&amp;lt;flow parent="flow" /&amp;gt;




	&amp;lt;/step&amp;gt;









	&amp;lt;beans:bean id="startable" abstract="true"&amp;gt;




		&amp;lt;beans:property name="allowStartIfComplete" value="true" /&amp;gt;




	&amp;lt;/beans:bean&amp;gt;




	




	&amp;lt;flow id="flow&amp;gt;...&amp;lt;/flow&amp;gt;





</description>
			<version>2.1.0</version>
			<fixedVersion>2.2.0, 2.2.0 - Sprint 12</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.TaskletStepAllowStartIfCompleteTest.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.AbstractStepParser.java</file>
		</fixedFiles>
	</bug>
	<bug id="1890" opendate="2012-09-12 22:16:47" fixdate="2013-01-25 14:36:04" resolution="Complete">
		<buginformation>
			<summary>Fix broken JDK5 build after Spring 3.1.2</summary>
			<description>After the 3.1.2 upgrade, the build broke as it was building with JDK5 and I was using JDK6 (and didn&amp;amp;apos;t notice stax issue). I&amp;amp;apos;ve enabled the tiger profile in infrastructure and made a reflection fix in StaxUtils. getXMLEventReader/getXMLEventWriter are package private and getMethod returns public.</description>
			<version>2.2.0</version>
			<fixedVersion></fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.xml.StaxUtils.java</file>
		</fixedFiles>
	</bug>
	<bug id="1757" opendate="2011-05-29 16:09:27" fixdate="2013-02-05 08:03:58" resolution="Complete">
		<buginformation>
			<summary>MinMaxPartitioner sets incorrect max value</summary>
			<description>The max value in MinMaxPartitioner is incorrect set, as min is effectively being multiplied twice by range:
			 int min = (i++)*range;
			 int max = Math.min(total, (min+1)*range);
The max line should presumably be:
			int max = Math.min(total, i * range);
(I am assuming that this is what the partitioner is supposed to be doing)</description>
			<version>2.1.0</version>
			<fixedVersion>2.2.0, 2.2.0 - Sprint 14</fixedVersion>
			<type>Defect</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.partition.MinMaxPartitioner.java</file>
		</fixedFiles>
	</bug>
	<bug id="1847" opendate="2012-03-30 06:37:53" fixdate="2013-03-01 16:17:04" resolution="Complete">
		<buginformation>
			<summary>scope="step" inheritance from parent bean definitions causes odd effects</summary>
			<description>In a Spring Batch project we (Ewan Benfield and myself) found that Spring Batch was attempting to instantiate a bean defined as abstract in its context (abstract="true") when marked with step scope (scope="step").  Note that scope should be inheritable).
In an attempt to reproduce the issue outside of the project an odd error was instead noted that the child bean cannot be instantiated due to not having a matching constructor (despite the abstract bean and its child having only default constructors).  The project for this attempt is included.  The exact error given is "BeanCreationException: Error creating bean with name &amp;amp;apos;concrete&amp;amp;apos; defined in class path resource [abstractstepscope/AbstractStepScopeTest-context.xml]: 1 constructor arguments specified but no matching constructor found in bean &amp;amp;apos;concrete&amp;amp;apos; (hint: specify index and/or type arguments for simple parameters to avoid type ambiguities)".
Note that if the Spring Batch beans are removed or if the scope is defined on the child (also or instead of the parent) no error is given when running the provided test "AbstractStepScopeTest".
Although tested only against Spring Batch 2.1.8 I assume this affects subsequent releases as nothing in org.springframework.batch.core.scope appears to have changed for a while.
We&amp;amp;apos;ve worked around the issue by placing the attribute scope="step" on the child bean definitions instead.</description>
			<version>2.1.8</version>
			<fixedVersion>2.2.0, 2.2.0 - Sprint 16</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.annotation.StepScopeConfigurationTests.java</file>
			<file type="M">org.springframework.batch.core.scope.StepScope.java</file>
		</fixedFiles>
	</bug>
	<bug id="1908" opendate="2012-11-19 14:10:39" fixdate="2013-03-19 12:19:56" resolution="Complete">
		<buginformation>
			<summary>Inefficient storage of StepExecutionContexts when using partitioning</summary>
			<description>When using a PartitionStep, each StepExecutionContext created for the corresponding partitions are saved and committed individually.  When a job has a large number of partitions, this leads to large delays.  Look into batching the inserts of these records.</description>
			<version>2.1.9</version>
			<fixedVersion>2.2.0, 2.2.0 - Sprint 17</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.repository.support.SimpleJobRepositoryTests.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.AbstractStepExecutionDaoTests.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.MapExecutionContextDao.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.AbstractExecutionContextDaoTests.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.ExecutionContextDao.java</file>
			<file type="M">org.springframework.batch.core.repository.JobRepository.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcExecutionContextDao.java</file>
			<file type="M">org.springframework.batch.core.step.item.TaskletStepExceptionTests.java</file>
			<file type="M">org.springframework.batch.core.repository.support.SimpleJobRepository.java</file>
			<file type="M">org.springframework.batch.core.step.JobRepositorySupport.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.DummyJobRepository.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.StepExecutionDao.java</file>
			<file type="M">org.springframework.batch.core.partition.support.SimpleStepExecutionSplitter.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcStepExecutionDao.java</file>
			<file type="M">org.springframework.batch.core.repository.dao.MapStepExecutionDao.java</file>
		</fixedFiles>
	</bug>
	<bug id="1959" opendate="2013-02-08 03:02:22" fixdate="2013-03-21 08:17:33" resolution="Complete">
		<buginformation>
			<summary>Problem with FlatFileItemWriter restart using multi-byte encoding</summary>
			<description>With FlatFileItemWriter, size saved in the step_context on update (under current.count key) is the sum of fileChannel.size (current file size in bytes) and Buffered string length (see FlatFileItemWriter.OutputState.position() method)
With an out file encoded in UTF-8 and buffer string containing two bytes caracters, the saved position is wrong =&amp;gt; restart will erase out file content.
In attachment, maven project with :

a first test case comparing real file size after a 1rst job run with failure and current.countsaved data
a second test case comparing in file size and out file size after a 1rst job run with failure and a 2nd job restart with no failure

</description>
			<version>2.1.8</version>
			<fixedVersion>2.2.0, 2.2.0 - Sprint 19</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.FlatFileItemWriterTests.java</file>
			<file type="M">org.springframework.batch.support.transaction.TransactionAwareBufferedWriterTests.java</file>
			<file type="M">org.springframework.batch.support.transaction.TransactionAwareBufferedWriter.java</file>
		</fixedFiles>
	</bug>
	<bug id="1946" opendate="2013-01-10 02:15:55" fixdate="2013-03-25 07:47:37" resolution="Complete">
		<buginformation>
			<summary>Signs of failed merge in HibernateItemWrite (and others?)</summary>
			<description></description>
			<version>2.2.0</version>
			<fixedVersion>2.2.0, 2.2.0 - Sprint 20</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.HibernateItemWriter.java</file>
		</fixedFiles>
	</bug>
	<bug id="1924" opendate="2012-12-11 13:49:20" fixdate="2013-04-04 09:17:41" resolution="Complete">
		<buginformation>
			<summary>Restarting a stopped job in COMPLETED state prevents progress</summary>
			<description>A job that is programatically stopped and restarted at a step prior to the step it was stopped in will not advance past the step it was previously stopped.  Below is an example of a job with the issue:











	&amp;lt;job id="restart.job6"&amp;gt;




		&amp;lt;step id="job6.step1" next="job6.step2"&amp;gt;




			&amp;lt;tasklet allow-start-if-complete="true" &amp;gt;




				&amp;lt;chunk reader="customerFileReader" writer="xmlOutputWriter"




					commit-interval="10" /&amp;gt;




			&amp;lt;/tasklet&amp;gt;




		&amp;lt;/step&amp;gt;




		&amp;lt;step id="job6.step2"  parent="formatFileStep" &amp;gt;




			&amp;lt;next on="ES3" to="job6.step3" /&amp;gt;




			&amp;lt;stop on="ES4" restart="job6.step4" /&amp;gt;




			&amp;lt;listeners&amp;gt;




				&amp;lt;listener ref="translator"/&amp;gt;




			&amp;lt;/listeners&amp;gt;




		&amp;lt;/step&amp;gt;




		&amp;lt;step id="job6.step3" next="job6.step4"  parent="formatFileStep"/&amp;gt;




		&amp;lt;step id="job6.step4"  parent="formatFileStep"/&amp;gt;




	&amp;lt;/job&amp;gt;






The full export of this job can be found here: https://gist.github.com/4259471</description>
			<version>2.1.9</version>
			<fixedVersion>2.2.0, 2.2.0 - Sprint 21</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.job.flow.support.SimpleFlow.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.StopRestartOnCompletedStepJobParserTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.StopRestartOnFailedStepJobParserTests.java</file>
			<file type="M">org.springframework.batch.core.job.flow.JobFlowExecutor.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.StopAndRestartFailedJobParserTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1865" opendate="2012-05-29 00:50:46" fixdate="2013-04-04 14:55:58" resolution="Complete">
		<buginformation>
			<summary>SimpleChunkProvider calls afterRead listener even if the file is finished</summary>
			<description>the doRead method of SimpleChunkProvider always calls listener.afterRead even if the returned item is null.
A null returned item indicates the file is complete, so the doRead shouldn&amp;amp;apos;t be calling the afterRead listener.</description>
			<version>2.1.8</version>
			<fixedVersion>2.2.0, 2.2.0 - Sprint 21</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.SimpleChunkProvider.java</file>
		</fixedFiles>
	</bug>
	<bug id="1860" opendate="2012-05-21 04:14:37" fixdate="2013-04-04 15:09:06" resolution="Complete">
		<buginformation>
			<summary>JdbcPagingItemReader can skip rows for Derby (and DB/2, SqlServer and Sybase?) due to paging by row number occuring before ordering</summary>
			<description>The queries (generated by DerbyPagingQueryProvider) are of this form.
 first page query
SELECT * FROM (
    SELECT &amp;lt;select clause&amp;gt;, ROW_NUMBER() OVER () AS ROW_NUMBER
    FROM &amp;lt;from clause&amp;gt;
    WHERE &amp;lt;where clause&amp;gt;
    ORDER BY &amp;lt;sort key&amp;gt; ASC
) AS TMP_SUB
WHERE TMP_SUB.ROW_NUMBER &amp;lt;= &amp;lt;page size&amp;gt;
 remaining pages query
SELECT * FROM (
    SELECT &amp;lt;select clause&amp;gt;, ROW_NUMBER() OVER () AS ROW_NUMBER
    FROM &amp;lt;from clause&amp;gt;
    WHERE &amp;lt;where clause&amp;gt; AND ID &amp;gt; &amp;lt;last sort key value&amp;gt;
    ORDER BY ID ASC
) AS TMP_SUB
WHERE TMP_SUB.ROW_NUMBER &amp;lt;= &amp;lt;page size&amp;gt;
Most of this is determined by the superclass SqlWindowingPagingQueryProvider, which is also extended by Db2PagingQueryProvider, SqlServerPagingQueryProvider and SybasePagingQueryProvider.
Unfortunately (at least for Derby, I haven&amp;amp;apos;t verified for DB/2, SqlServer or Sybase) the row number is appended to the unordered rows before the ordering.  This results in rows sometimes being skipped when the page size is less than the total number of rows as the subsequent remaining rows queries will retrieve only rows with a sort key value &amp;gt; the last row&amp;amp;apos;s sort key value.
To illustrate this more clearly take this simple schema and data.
CREATE TABLE SAMPLE (
    ID VARCHAR(10) NOT NULL
);
INSERT INTO SAMPLE (ID) VALUES (&amp;amp;apos;Z&amp;amp;apos;);
INSERT INTO SAMPLE (ID) VALUES (&amp;amp;apos;A&amp;amp;apos;);
This would involve two queries with the first query retrieving the wrong row (not the first by sort key) and second query no rows at all.
 first page query
SELECT * FROM (
    SELECT ID, ROW_NUMBER() OVER () AS ROW_NUMBER
    FROM SAMPLE
    ORDER BY ID ASC
) AS TMP_SUB
WHERE TMP_SUB.ROW_NUMBER &amp;lt;= 1
 returns &amp;amp;apos;Z&amp;amp;apos;, 1
 remaining pages query
SELECT * FROM (
    SELECT ID, ROW_NUMBER() OVER () AS ROW_NUMBER
    FROM SAMPLE
    WHERE ID &amp;gt; &amp;amp;apos;Z&amp;amp;apos;
    ORDER BY ID ASC
) AS TMP_SUB
WHERE TMP_SUB.ROW_NUMBER &amp;lt;= 1
 returns (no rows)
I suggest ensuring that the row number column is added after the ordering.
 first page query
SELECT * FROM (
   SELECT
       &amp;lt;select clause&amp;gt;,
       ROW_NUMBER() OVER () AS ROW_NUMBER
   FROM (
       SELECT &amp;lt;select clause&amp;gt;
       FROM &amp;lt;from clause&amp;gt;
       WHERE &amp;lt;where clause&amp;gt;
       ORDER BY &amp;lt;sort key&amp;gt;
   ) AS TMP_ORDERED
) AS TMP_SUB
WHERE TMP_SUB.ROW_NUMBER &amp;lt;= &amp;lt;page size&amp;gt;
 remaining pages query
SELECT * FROM (
   SELECT
       &amp;lt;select clause&amp;gt;,
       ROW_NUMBER() OVER () AS ROW_NUMBER
   FROM (
       SELECT &amp;lt;select clause&amp;gt;
       FROM &amp;lt;from clause&amp;gt;
       WHERE &amp;lt;where clause&amp;gt; AND &amp;lt;sort key&amp;gt; &amp;gt; &amp;lt;last sort key value&amp;gt;
       ORDER BY &amp;lt;sort key&amp;gt;
   ) AS TMP_ORDERED
) AS TMP_SUB
WHERE TMP_SUB.ROW_NUMBER &amp;lt;= &amp;lt;page size&amp;gt;
Alternatively (although I don&amp;amp;apos;t wish to propose this), no ordering or sort key is required at all (for descendants of SqlWindowingPagingQueryProvider). A range of row numbers could be selected for each page.  I presume this is undesirable as the developer may be expecting order (even though it&amp;amp;apos;s only a side-effect of the paging):
 first and remaining pages query (with &amp;lt;last row number&amp;gt; initialised to 0)
SELECT * FROM (
   SELECT
       &amp;lt;select clause&amp;gt;,
       ROW_NUMBER() OVER () AS ROW_NUMBER
   FROM (
       SELECT &amp;lt;select clause&amp;gt;
       FROM &amp;lt;from clause&amp;gt;
       WHERE &amp;lt;where clause&amp;gt;
   ) AS TMP_ORDERED
) AS TMP_SUB
WHERE TMP_SUB.ROW_NUMBER &amp;gt; &amp;lt;last row number&amp;gt; AND TMP_SUB.ROW_NUMBER &amp;lt;= &amp;lt;last row number + page size&amp;gt;
Although I&amp;amp;apos;ve selected a priority of major, this issue doesn&amp;amp;apos;t currently affect us.  We shifted to HSQL from Derby for testing due to BATCH-1848 and I&amp;amp;apos;m raising it only as I detected the problem when testing for regressions.</description>
			<version>2.1.8</version>
			<fixedVersion>2.2.0, 2.2.0 - Sprint 21</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.support.DerbyPagingQueryProviderTests.java</file>
			<file type="M">org.springframework.batch.item.database.support.SqlWindowingPagingQueryProviderTests.java</file>
			<file type="M">org.springframework.batch.item.database.support.DerbyPagingQueryProvider.java</file>
			<file type="M">org.springframework.batch.item.database.support.SybasePagingQueryProvider.java</file>
			<file type="M">org.springframework.batch.item.database.JdbcPagingRestartIntegrationTests.java</file>
			<file type="M">org.springframework.batch.item.database.JpaPagingItemReaderAsyncTests.java</file>
			<file type="M">org.springframework.batch.item.database.JdbcPagingQueryIntegrationTests.java</file>
			<file type="M">org.springframework.batch.item.database.IbatisPagingItemReaderAsyncTests.java</file>
			<file type="M">org.springframework.batch.item.database.support.SqlWindowingPagingQueryProvider.java</file>
			<file type="M">org.springframework.batch.item.database.JdbcPagingItemReaderAsyncTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1995" opendate="2013-04-19 15:17:14" fixdate="2013-04-20 21:52:37" resolution="Complete">
		<buginformation>
			<summary>Line ending in multiline delimiter not being processed correctly</summary>
			<description></description>
			<version>2.2.0.RC1</version>
			<fixedVersion>2.2.0.RC2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.transform.DelimitedLineTokenizerTests.java</file>
			<file type="M">org.springframework.batch.item.file.transform.DelimitedLineTokenizer.java</file>
		</fixedFiles>
	</bug>
	<bug id="2019" opendate="2013-04-29 12:47:01" fixdate="2013-04-30 09:26:03" resolution="Complete">
		<buginformation>
			<summary>Support PropertySourcesPlaceholderConfigurer delegation to job contexts</summary>
			<description>Spring Batch uses children of AbstractApplicationContextFactory to create child application contexts for each batch job. By default, it will pass PropertyPlaceholderConfigurer and CustomEditorConfigurer bean post processors to the child contexts as configured in the default constructor of AbstractApplicationContextFactory. However, it does not pass PropertySourcesPlaceholderConfigurer bean post processors by default. Therefore, using the Spring 3.1 Environment functionality in conjunction with &amp;lt;context:properties-placeholder/&amp;gt; does not work out of the box. You must manually add that class to the list of bean post processors. It would be great if this default behavior could be changed to support the Spring 3.1 convention.</description>
			<version>2.2.0.RC1</version>
			<fixedVersion>2.2.0.RC2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.support.GenericApplicationContextFactory.java</file>
			<file type="M">org.springframework.batch.core.configuration.support.AbstractApplicationContextFactory.java</file>
			<file type="M">org.springframework.batch.core.configuration.support.GenericApplicationContextFactoryTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="2023" opendate="2013-05-04 03:44:01" fixdate="2013-05-06 01:50:03" resolution="Complete">
		<buginformation>
			<summary>@StepScope should default to ScopedProxyMode.TARGET_CLASS</summary>
			<description>If I use @StepScope on a @Bean method that returns a FlatFileItemReader, I get a ClassCastException:  java.lang.ClassCastException: $Proxy16 cannot be cast to org.springframework.batch.item.file.FlatFileItemReader
That&amp;amp;apos;s because the ScopedProxyMode is INTERFACES, and the proxy created is based on of the interfaces of FlatFileItemReader, and not FlatFileItemReader itself. Since we always have CGLIB when using @Configuration, I see no reason for not changing the default proxyMode of @StepScope to TARGET_CLASS. 
One more argument for the proxyMode TARGET_CLASS: when I change the return type of the @Bean method to ItemReader&amp;lt;xx&amp;gt;, but still return a FlatFileItemReader, I don&amp;amp;apos;t get a ClassCastException, but the ItemStream registration does not work, and the FlatFileItemReader throws an exception on the first read.
Altogether those are serious stumble blocks for people not familiar with the proxying mechanisms in Spring, and we would avoid all of them with the default proxyMode TARGET_CLASS.</description>
			<version>2.2.0.RC1</version>
			<fixedVersion>2.2.0 Backlog, 2.2.0.RC2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.annotation.StepScope.java</file>
			<file type="M">org.springframework.batch.core.configuration.annotation.StepScopeConfigurationTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="2031" opendate="2013-05-23 14:30:17" fixdate="2013-06-04 08:36:54" resolution="Complete">
		<buginformation>
			<summary>Incorrect delimiter detection in DelimitedLineTokenizer </summary>
			<description>In certain cases where the value is similar to the delimiter with a length more than 1, the isDelimiter method may incorrectly detect the delimiter.  
For example
having a delimiter "==-=="
Here are the following outcomes
Test1:
"John====A====Doe"  =&amp;gt; [John, A, Doe]
Test2:
"John========Doe"  =&amp;gt; [John, , Doe]
Test3:
"John======-==Doe"  =&amp;gt; 
java.lang.StringIndexOutOfBoundsException: String index out of range: -2
	at java.lang.String.&amp;lt;init&amp;gt;(String.java:197)
	at org.springframework.batch.item.file.transform.DelimitedLineTokenizer.doTokenize(DelimitedLineTokenizer.java:163)
	at org.springframework.batch.item.file.transform.AbstractLineTokenizer.tokenize(AbstractLineTokenizer.java:111)
	at BatchTest.test3(BatchTest.java:36)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
I have attached an not so glamorous JUnit file demonstrating this and a solution as well.  I&amp;amp;apos;m not sure if the solution has other consequences on other parts, so anyone wishing to use this YMMV.
Love Spring Batch!!  Keep up the great work guys!!</description>
			<version>2.2.0.RC2</version>
			<fixedVersion>2.2.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.transform.DelimitedLineTokenizerTests.java</file>
			<file type="M">org.springframework.batch.item.file.transform.DelimitedLineTokenizer.java</file>
		</fixedFiles>
	</bug>
	<bug id="2035" opendate="2013-05-26 12:55:20" fixdate="2013-06-10 11:27:59" resolution="Complete">
		<buginformation>
			<summary>Create parallel to simple-cli for pure Java configuration</summary>
			<description>Coding a pure Java configuration for Spring Batch. Thought it would fit next to spring-cli in the archetypes.</description>
			<version>2.2.0.RC2</version>
			<fixedVersion>3.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.launch.support.CommandLineJobRunner.java</file>
		</fixedFiles>
	</bug>
	<bug id="2034" opendate="2013-05-25 08:40:00" fixdate="2013-06-10 13:21:39" resolution="Complete">
		<buginformation>
			<summary>&amp;apos;Job cannot be null&amp;apos; exception when starting FlowStep remotely with org.springframework.batch.integration.partition.StepExecutionRequestHandler</summary>
			<description>I have a project which uses 
org.springframework.batch.integration.partition.MessageChannelPartitionHandler
and
org.springframework.batch.integration.partition.StepExecutionRequestHandler
to run a job Step remotely.
In case if a remote step is a 
org.springframework.batch.core.job.flow.FlowStep
(not a TaskletStep) the step execution fails on a remote host with the exception:

Caused by: java.lang.IllegalArgumentException: Job cannot be null.
	at org.springframework.util.Assert.notNull(Assert.java:112)
	at org.springframework.batch.core.repository.dao.JdbcJobExecutionDao.findJobExecutions(JdbcJobExecutionDao.java:127)
	at org.springframework.batch.core.repository.support.SimpleJobRepository.getStepExecutionCount(SimpleJobRepository.java:249)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:183)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:150)
	at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:96)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:260)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:94)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:204)
	at com.sun.proxy.$Proxy48.getStepExecutionCount(Unknown Source)
	at org.springframework.batch.core.job.flow.JobFlowExecutor.isStepRestart(JobFlowExecutor.java:82)
	at org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:63)
	at org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:60)
	at org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:152)
The reason is an empty jobInstance field in the JobExecution instance used to lookup for the JobExecution on a remote host in 
JdbcJobExecutionDao.findJobExecutions(JobInstance job);
The SimpleJobExplorer doesn&amp;amp;apos;t fill the jobInstance field of the jobExecution received from a DAO call in the SimpleJobExplorer.getStepExecution(Long jobExecutionId, Long executionId) method.</description>
			<version>2.2.0.RC2</version>
			<fixedVersion>3.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.explore.support.SimpleJobExplorerTests.java</file>
			<file type="M">org.springframework.batch.core.explore.support.SimpleJobExplorer.java</file>
		</fixedFiles>
	</bug>
	<bug id="2054" opendate="2013-06-25 16:08:34" fixdate="2013-07-12 14:19:24" resolution="Complete">
		<buginformation>
			<summary>StaxEventItemWriter fails on a NullPointerException with Spring OXM 3.2.x.</summary>
			<description>A NullPointerException results from trying to write more than one item to a StaxEventItemWriter with Spring OXM 3.2.x.  It works with Spring OXM 3.1.x.
I&amp;amp;apos;ve uploaded a test case project to the Git repository linked above.  Highlights follow:






&amp;lt;bean id="itemWriter" class="org.springframework.batch.item.xml.StaxEventItemWriter"




    depends-on="setSystemProperties"&amp;gt;




    &amp;lt;property name="resource" ref="tempResource" /&amp;gt;




    &amp;lt;property name="rootTagName" value="testing" /&amp;gt;




    &amp;lt;property name="marshaller"&amp;gt;




        &amp;lt;bean class="org.springframework.oxm.jibx.JibxMarshaller"&amp;gt;




            &amp;lt;property name="targetClass"




                value="com.ianbrandt.spring.batch.test.TestModelObject" /&amp;gt;




        &amp;lt;/bean&amp;gt;




    &amp;lt;/property&amp;gt;




&amp;lt;/bean&amp;gt;












java.lang.NullPointerException




	at com.ctc.wstx.sw.BufferingXmlWriter.writeStartTagStart(BufferingXmlWriter.java:725)




	at com.ctc.wstx.sw.BaseNsStreamWriter.doWriteStartTag(BaseNsStreamWriter.java:614)




	at com.ctc.wstx.sw.SimpleNsStreamWriter.writeStartOrEmpty(SimpleNsStreamWriter.java:265)




	at com.ctc.wstx.sw.BaseNsStreamWriter.writeStartElement(BaseNsStreamWriter.java:313)




	at org.codehaus.stax2.ri.Stax2EventWriterImpl.add(Stax2EventWriterImpl.java:97)




	at org.springframework.batch.item.xml.stax.NoStartEndDocumentStreamWriter.add(NoStartEndDocumentStreamWriter.java:39)




	at org.springframework.util.xml.XMLEventStreamWriter.writeStartElement(XMLEventStreamWriter.java:195)




	at org.springframework.util.xml.XMLEventStreamWriter.writeStartElement(XMLEventStreamWriter.java:92)




	at org.jibx.runtime.impl.StAXWriter.startTagOpen(StAXWriter.java:151)




	at org.jibx.runtime.impl.MarshallingContext.startTagAttributes(MarshallingContext.java:541)




	at com.ianbrandt.spring.batch.test.JiBX_TestModelObjectTestModelObject_access.marshal()




	at com.ianbrandt.spring.batch.test.TestModelObject.marshal(TestModelObject.java)




	at org.jibx.runtime.impl.MarshallingContext.marshalRoot(MarshallingContext.java:1021)




	at org.jibx.runtime.impl.MarshallingContext.marshalDocument(MarshallingContext.java:1041)




	at org.springframework.oxm.jibx.JibxMarshaller.marshalXmlStreamWriter(JibxMarshaller.java:289)




	at org.springframework.oxm.jibx.JibxMarshaller.marshalXmlEventWriter(JibxMarshaller.java:342)




	at org.springframework.oxm.support.AbstractMarshaller.marshalStaxResult(AbstractMarshaller.java:229)




	at org.springframework.oxm.support.AbstractMarshaller.marshal(AbstractMarshaller.java:96)




	at org.springframework.batch.item.xml.StaxEventItemWriter.write(StaxEventItemWriter.java:715)




	at com.ianbrandt.spring.batch.test.SpringBatchOxmTest.writeItems(SpringBatchOxmTest.java:55)




	at com.ianbrandt.spring.batch.test.SpringBatchOxmTest.testTwoObjects(SpringBatchOxmTest.java:49)




	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)




	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)




	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)




	at java.lang.reflect.Method.invoke(Method.java:597)




	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)




	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)




	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)




	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)




	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)




	at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:74)




	at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:83)




	at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:72)




	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:231)




	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:88)




	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)




	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)




	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)




	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)




	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)




	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)




	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:71)




	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)




	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:174)




	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)




	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)




	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)




	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)




	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)




	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)





</description>
			<version>2.2.0</version>
			<fixedVersion>2.2.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemWriter.java</file>
			<file type="M">org.springframework.batch.item.xml.stax.NoStartEndDocumentWriterTests.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemWriterTests.java</file>
			<file type="M">org.springframework.batch.item.xml.stax.NoStartEndDocumentStreamWriter.java</file>
		</fixedFiles>
	</bug>
	<bug id="1849" opendate="2012-04-12 06:45:52" fixdate="2013-07-15 13:02:03" resolution="Complete">
		<buginformation>
			<summary>Item was not picked up after restarting a failed job!!!</summary>
			<description>We have got 2 items needs to be processed by the job. Their keys are 3000000001659 and 3000000001661.
Page size was set to 20 and commit-interval was set to 1 in the job configuration. At the first run, job failed but processed one of the items and second item rolledback due to RuntimeException. Again when we restarted the job, job reported as completed. We later realized the second item was not picked up by the job when we restarted it. We could see it in the batch tables.
Below are the entries from the batch_step_execution table for the both the failed and successful executions
STEP_EXECUTION_ID STATUS COMMIT_COUNT READ_COUNT WRITE_COUNT ROLLBACK_COUNT
752510 FAILED 1 2 1 1
752511 COMPLETED 1 0 0 0
Below are the entries from the batch_step_execution_context table for the both the failed and successful executions
STEP_EXECUTION_ID short_context
752510 {"map":{"entry":[
{"string":"JdbcPagingItemReader.read.count","int": 1}
,
{"string":"JdbcPagingItemReader.start.after","l ong":3000000001661}
]}}
752511 {"map":{"entry":[
{"string":"JdbcPagingItemReader.read.count","int": 2}
,
{"string":"JdbcPagingItemReader.start.after","l ong":3000000001661}
]}}
I suspect the value for JdbcPagingItemReader.start.after should be 3000000001659 and not 3000000001661. But I am not sure.
But it works well if the size of commit-interval and page-size matches. I don&amp;amp;apos;t remember reading in doc that they should match.
Following is the Job configuration but not a complete one
&amp;lt;batch:job id="corporateActionEODJob" parent="simpleJob"&amp;gt;
&amp;lt;batch:step id="processCorporateActions" parent="simpleStep"&amp;gt;
&amp;lt;batch:tasklet&amp;gt;
&amp;lt;batch:chunk reader ="corporateActionEODItemReader"
writer ="corporateActionEODItemWriter"
commit-interval="1" /&amp;gt;
&amp;lt;/batch:tasklet&amp;gt;
&amp;lt;/batch:step&amp;gt;
&amp;lt;/batch:job&amp;gt;
&amp;lt;bean id="corporateActionEODItemReader" class="org.springframework.batch.item.database.Jdb cPagingItemReader"&amp;gt;
&amp;lt;property name="saveState" value="true"/&amp;gt;
&amp;lt;property name="dataSource" ref="dataSource"/&amp;gt;
&amp;lt;property name="pageSize" value="20"/&amp;gt;
&amp;lt;property name="rowMapper"&amp;gt;
&amp;lt;bean class="org.springframework.jdbc.core.simple.Parame terizedSingleColumnRowMapper" factory-method="newInstance"&amp;gt;
&amp;lt;constructor-arg&amp;gt;
&amp;lt;null/&amp;gt;
&amp;lt;/constructor-arg&amp;gt;
&amp;lt;/bean&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property name="queryProvider"&amp;gt;
&amp;lt;bean class="org.springframework.batch.item.database.sup port.SqlPagingQueryProviderFactoryBean"&amp;gt;
&amp;lt;property name="fromClause" value="ca_corp_action ca"/&amp;gt;
&amp;lt;property name="selectClause" value="ca.corp_action_id"/&amp;gt;
&amp;lt;property name="sortKey" value="ca.corp_action_id"/&amp;gt;
&amp;lt;property name="whereClause" value="ca.action_status = &amp;amp;apos;SCHEDULED&amp;amp;apos; and ca.effective_date = :businessDay"/&amp;gt;
&amp;lt;/bean&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property name="parameterValues"&amp;gt;
&amp;lt;map&amp;gt;
&amp;lt;entry key="businessDay" value="2012-04-09"/&amp;gt;
&amp;lt;/map&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;/bean&amp;gt;
&amp;lt;bean id="corporateActionEODItemWriter" class="com.om.dh.batch.item.adapter.DelegatingItem WriterAdapterFactoryBean"&amp;gt;
&amp;lt;property name="targetObject" ref ="com.dh.ca.services.BatchAdapterService"/&amp;gt;
&amp;lt;property name="targetMethod" value="processAction" /&amp;gt;
&amp;lt;/bean&amp;gt;
We use SB version 2.1.6.</description>
			<version>2.1.6</version>
			<fixedVersion>2.2.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.JdbcPagingItemReader.java</file>
			<file type="M">org.springframework.batch.item.database.AbstractDataSourceItemReaderIntegrationTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="2050" opendate="2013-06-18 08:34:34" fixdate="2013-07-17 12:04:19" resolution="Complete">
		<buginformation>
			<summary>AbstractItemCountingItemStreamItemReader.read() shouldn&amp;apos;t be final</summary>
			<description>when you use FlatfileItemWriter with StepScope (proxyTargetClass=true --&amp;gt; CGLib-Subclassing) the final method read() cannot be proxied correctly. So the AbstractItemCountingItemStreamItemReader.currentItemCount is always persisted as 0 to the jobRepository.
Code:
&amp;lt;bean class="org.springframework.batch.core.scope.StepScope" p:proxyTargetClass="true" /&amp;gt;
&amp;lt;bean id="reader" class="org.springframework.batch.item.file.FlatFileItemReader" scope="step"&amp;gt;
&amp;lt;property name="resource" value="#
{jobParameters[pathToFile]}
"&amp;gt;&amp;lt;/property&amp;gt;
&amp;lt;property name="lineMapper" ref="lineMapper"/&amp;gt;
&amp;lt;/bean&amp;gt;
thx 
</description>
			<version>2.2.0</version>
			<fixedVersion>2.2.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.AbstractCursorItemReader.java</file>
			<file type="M">org.springframework.batch.item.database.HibernateItemWriter.java</file>
			<file type="M">org.springframework.batch.item.support.AbstractItemCountingItemStreamItemReader.java</file>
			<file type="M">org.springframework.batch.item.database.JpaItemWriter.java</file>
			<file type="M">org.springframework.batch.core.configuration.annotation.StepScope.java</file>
			<file type="M">org.springframework.batch.item.file.transform.DelimitedLineTokenizer.java</file>
		</fixedFiles>
	</bug>
	<bug id="2038" opendate="2013-05-30 02:54:58" fixdate="2013-07-26 09:35:00" resolution="Complete">
		<buginformation>
			<summary>DerbyPagingQueryProvider does not work with Derby 10.10.1.1</summary>
			<description>An InvalidDataAccessResourceUsageException is thrown when using Derby 10.10.1.1
The following line returns true and throws the exception with 10.10.1.1:
if ("10.4.1.3".compareTo(version) &amp;gt; 0) {</description>
			<version>2.1.9</version>
			<fixedVersion>2.2.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.support.DerbyPagingQueryProviderTests.java</file>
			<file type="M">org.springframework.batch.item.database.support.DerbyPagingQueryProvider.java</file>
		</fixedFiles>
	</bug>
	<bug id="2086" opendate="2013-08-27 01:16:11" fixdate="2013-09-08 08:16:59" resolution="Complete">
		<buginformation>
			<summary>default writer implementations need public setter for name</summary>
			<description>The default spring batch writer implementations need a public setter for the name. The name is used to prefix the execution context keys. In spring batch 2.1.x the setter for the name was available in FlatFileItemWriter, StaxEventItemWriter, MultiResourceItemWriter, ... because they extended from ExecutionContextUserSupport. In 2.2.x they extend from ItemStreamSupport where the setExecutionContextName method is protected.
This means that currently in spring batch 2.2.x it&amp;amp;apos;s no longer possible to write to multiple StaxEventItemWriters in the same step, because they would share the same execution context.
edit: FlatFileItemWriter has a setName() method. StaxEventItemWriter and MultiResourceItemWriter don&amp;amp;apos;t.</description>
			<version>2.2.0</version>
			<fixedVersion>2.2.2</fixedVersion>
			<type>Defect</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.ItemStreamSupport.java</file>
			<file type="M">org.springframework.batch.item.support.AbstractItemCountingItemStreamItemReader.java</file>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemWriterTests.java</file>
			<file type="M">org.springframework.batch.item.file.FlatFileItemWriter.java</file>
		</fixedFiles>
	</bug>
	<bug id="2040" opendate="2013-06-02 23:53:07" fixdate="2013-09-08 10:12:40" resolution="Complete">
		<buginformation>
			<summary>Db2PagingQueryProvider creates erroneous Statement in generateJumpToItemQuery</summary>
			<description>Hi,
we want to use the spring-batch-admin on WAS70 with DB2-Database underlying.
The list of executions is delimited to 20 per default. If we try to jump on the next page, an internal server error 500 will occur. 
As we hit the "next" button, the method generateJumpToItemQuery(int itemIndex, int pageSize) in org.springframework.batch.item.database.support.Db2PagingQueryProvider is called.
The generated SQL-Statement is:
SELECT E.JOB_EXECUTION_ID FROM ( SELECT E.JOB_EXECUTION_ID, ROW_NUMBER() OVER ( ORDER BY E.JOB_EXECUTION_ID DESC) AS ROW_NUMBER FROM T1100Z.BATCH_JOB_EXECUTION E, T1100Z.BATCH_JOB_INSTANCE I WHERE E.JOB_INSTANCE_ID=I.JOB_INSTANCE_ID) AS TMP_SUB WHERE TMP_SUB.ROW_NUMBER = 20 ORDER BY E.JOB_EXECUTION_ID DESC
After a few test i found out the right SQL:
SELECT TMP_SUB.JOB_EXECUTION_ID FROM ( SELECT E.JOB_EXECUTION_ID, ROW_NUMBER() OVER ( ORDER BY E.JOB_EXECUTION_ID DESC) AS ROW_NUMBER FROM T1100Z.BATCH_JOB_EXECUTION E, T1100Z.BATCH_JOB_INSTANCE I WHERE E.JOB_INSTANCE_ID=I.JOB_INSTANCE_ID) AS TMP_SUB WHERE TMP_SUB.ROW_NUMBER = 20 ORDER BY TMP_SUB.JOB_EXECUTION_ID DESC
As you can see, the subquery uses the "E.", but comes out as TMP_SUB.
The "E." is set by the batch-admin-manager: sortKeys.put("E.JOB_EXECUTION_ID", Order.DESCENDING);
I think a the generateJumpToItemQuery-Method in Db2PagingQueryProvider has to be overridden, or the method buildSortKeySelect(StringBuilder sql) could get a brother like: buildSortKeySelect(StringBuilder sql, String qualifierReplacement) ("E." -&amp;gt; "TMP_SUB.")</description>
			<version>2.2.0.RC2</version>
			<fixedVersion>2.2.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.database.support.SqlWindowingPagingQueryProvider.java</file>
			<file type="M">org.springframework.batch.item.database.support.SqlPagingQueryUtils.java</file>
			<file type="M">org.springframework.batch.item.database.support.SqlWindowingPagingQueryProviderTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="2096" opendate="2013-09-06 13:17:24" fixdate="2013-09-08 10:51:42" resolution="Complete">
		<buginformation>
			<summary>&amp;apos;chunk-completion-policy&amp;apos; or &amp;apos;commit-interval&amp;apos; with &amp;apos;#{jobParameters[...]}&amp;apos; is ignored when &amp;apos;retry-limit&amp;apos; exists.</summary>
			<description>When &amp;amp;apos;retry-limit&amp;amp;apos; is configured and  &amp;amp;apos;commit-interval&amp;amp;apos; is extracted from jobParameters, commit-interval is always recognized to be &amp;amp;apos;1&amp;amp;apos; regardless of jobParameters.






&amp;lt;batch:job id="retryJob"&amp;gt;




  &amp;lt;batch:step id="step1"&amp;gt;




    &amp;lt;batch:tasklet&amp;gt;




      &amp;lt;batch:chunk reader="reader" writer="writer" commit-interval="#{jobParameters[&amp;amp;apos;commit.interval&amp;amp;apos;]}" retry-limit="5" &amp;gt; 




      &amp;lt;batch:retryable-exception-classes&amp;gt;




        &amp;lt;batch:include class="java.lang.Exception" /&amp;gt;




       &amp;lt;/batch:retryable-exception-classes&amp;gt;




    &amp;lt;/batch:chunk&amp;gt;




  &amp;lt;/batch:tasklet&amp;gt;




&amp;lt;/batch:step&amp;gt;




&amp;lt;/batch:job&amp;gt;






And &amp;amp;apos;chunk-completion-policy&amp;amp;apos; also ignored when &amp;amp;apos;retry-limit&amp;amp;apos; exists.
These flows are fundamentally same after parsing the XML, because SimpleCompletionPolicy is registered when &amp;amp;apos;commit-interval&amp;amp;apos; starts with &amp;amp;apos;#". it is processed in  &amp;amp;apos;org.springframework.batch.core.configuration.xml.ChunkElementParser.prase()&amp;amp;apos;






if (StringUtils.hasText(commitInterval)) {




  if (commitInterval.startsWith("#")) {




    // It&amp;amp;apos;s a late binding expression, so we need step scope...




    BeanDefinitionBuilder completionPolicy = BeanDefinitionBuilder.genericBeanDefinition(SimpleCompletionPolicy.class);




    completionPolicy.addConstructorArgValue(commitInterval);




    completionPolicy.setScope("step");




    propertyValues.addPropertyValue("chunkCompletionPolicy", completionPolicy.getBeanDefinition());




  } else {




    propertyValues.addPropertyValue("commitInterval", commitInterval);




  }




}






The cause is that StepParserStepFactoryBean omits to set ChunkCompletionPolicy when creating FaultTolerantStep.  &amp;amp;apos;builder.chunk(chunkCompletionPolicy);&amp;amp;apos; is called in &amp;amp;apos;StepParserStepFactoryBean.createSimpleStep()&amp;amp;apos;,
 but it is not in &amp;amp;apos;createFaultTolerantStep()&amp;amp;apos;.
I reproduced the problem at https://github.com/benelog/batch-experiments/tree/master/batch-retry-test</description>
			<version>2.2.1</version>
			<fixedVersion>2.2.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParserStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParserStepFactoryBeanTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="2141" opendate="2013-11-16 09:52:48" fixdate="2013-11-18 09:30:19" resolution="Complete">
		<buginformation>
			<summary>RepositoryItemReader reads the first page twice when used with partitions.</summary>
			<description>org.springframework.batch.item.data.RepositoryItemReader.jumpToItem() is called for each partition and initiates the processing of the first page by calling results = doPageRead(); but doesn&amp;amp;apos;t increment the page attribute which means that page 0 is processed twice. The fix is simply to have page++ after the call to doPageRead();</description>
			<version>2.2.2</version>
			<fixedVersion>2.2.3</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.data.RepositoryItemReader.java</file>
		</fixedFiles>
	</bug>
	<bug id="2151" opendate="2013-11-27 09:43:15" fixdate="2013-12-27 09:55:29" resolution="Complete">
		<buginformation>
			<summary>Skip issues on restart</summary>
			<description>See attached test project</description>
			<version>2.2.3</version>
			<fixedVersion>2.2.4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.step.item.ChunkMonitorTests.java</file>
			<file type="M">org.springframework.batch.core.step.item.ChunkMonitor.java</file>
		</fixedFiles>
	</bug>
	<bug id="2126" opendate="2013-10-23 03:19:04" fixdate="2014-02-20 14:03:33" resolution="Complete">
		<buginformation>
			<summary>DefaultJobParametersConverter is not thread-safe and the SimpleJobOperator either </summary>
			<description>DefaultJobParametersConverter is not thread-safe due to usage of instance variable for numberFormat, dateFormat and longNumberFormat. Then as the SimpleJobOperator use a JobParametersConverter as a instance variable it is not thread-safe either. Thus means that we cannot use it with a SimpleAsyncTaskExecutor or any asynchronous TaskExecutor. 
Can you fix it or can you explain which setup as be evaluated to make it work properly with an asynchronous TaskExecutor ?</description>
			<version>2.2.2</version>
			<fixedVersion>3.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.converter.DefaultJobParametersConverter.java</file>
		</fixedFiles>
	</bug>
	<bug id="2179" opendate="2014-02-18 09:09:38" fixdate="2014-02-20 14:26:59" resolution="Complete">
		<buginformation>
			<summary>DefaultJobParametersConverter#getProperties ignores NON_IDENTIFYING_FLAG</summary>
			<description>When converting non-identifying JobParameters using 
DefaultJobParametersConverter#getProperties(JobParameters params) the NON_IDENTIFYING_FLAG is not prepended to the resulting property name.</description>
			<version>2.2.4</version>
			<fixedVersion>3.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.converter.DefaultJobParametersConverter.java</file>
			<file type="M">org.springframework.batch.core.converter.DefaultJobParametersConverterTests.java</file>
		</fixedFiles>
		<links>
			<link type="Depend" description="is depended on by">1331</link>
		</links>
	</bug>
	<bug id="2153" opendate="2013-11-28 05:35:33" fixdate="2014-02-21 12:05:13" resolution="Complete">
		<buginformation>
			<summary>StepSynchronizationManager uses static HashMap - NullPointerException with multiple Threads</summary>
			<description>org.springframework.batch.core.scope.context.StepSynchronizationManager produces NullPointerException, because it uses static java.util.HashMap to increment and decrement variables for the current Thread, which is not threadsafe.
Solution: Replacing java.util.HashMap with java.util.Hashtable (threadsafe) works for me.
Also see this build error https://build.springsource.org/browse/BATCH-TRUNK-JOB1-6375/test/case/62852213;jsessionid=59A64053379861A4C2328C879E4525EA with the same exception.
Find attached a minimal maven project (start TestStepSynchronizationManagerMain to reproduce the NullPointerException) and a possible fix.</description>
			<version>2.2.3</version>
			<fixedVersion>2.2.5</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.scope.context.SynchronizationManagerSupport.java</file>
		</fixedFiles>
	</bug>
	<bug id="2045" opendate="2013-06-10 01:33:32" fixdate="2014-02-28 11:52:15" resolution="Complete">
		<buginformation>
			<summary>Spring Batch version not incremented in XSD schema check warning message</summary>
			<description>When Spring Batch 2.1 schema is used to define job context, the following message is shown:
You cannot use spring-batch-2.0.xsd with Spring Batch 2.1.  Please upgrade your schema declarations (or use the spring-batch.xsd alias if you are feeling lucky).
The numbers seem to be incremented accordingly to 2.1.xsd and Spring Batch 2.2
(line 72 of the JobParser class)</description>
			<version>2.2.0</version>
			<fixedVersion>3.0.0</fixedVersion>
			<type>Defect</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.JobParserExceptionTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.JobParser.java</file>
		</fixedFiles>
	</bug>
	<bug id="2011" opendate="2013-04-24 01:06:49" fixdate="2014-03-06 12:38:30" resolution="Complete">
		<buginformation>
			<summary>ExitStatus.compareTo() delivers result out of given range [-1,1]</summary>
			<description>If compareTo is used to compare two ExitStatus with non-standard exitCodes the result may be different then {-1,0,1}. If user defined ExitStatuses are used, this may lead to unexpected behavior.
I would expect the following test to pass:
@Test
public void testCompareTo(){
 final ExitStatus someExitStatus = new ExitStatus("SOME_STATUS");
 final ExitStatus otherExitStatus = new ExitStatus("OTHER_STATUS");
 assertThat(someExitStatus.compareTo(otherExitStatus),
            either(equalTo(1)).or(equalTo(-1)));
}</description>
			<version>2.2.0.RC1</version>
			<fixedVersion>2.2.6</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.ExitStatus.java</file>
		</fixedFiles>
	</bug>
	<bug id="2189" opendate="2014-03-17 04:44:57" fixdate="2014-03-18 12:23:33" resolution="Complete">
		<buginformation>
			<summary>DefaultBatchConfigurer violates PostConstruct rules</summary>
			<description>When trying to deploy a Spring Batch project in a web container it fails to deploy due to DefaultBatchConfigurer violating the @PostConstruct annotation rule.
http://docs.oracle.com/javaee/5/api/javax/annotation/PostConstruct.html
The DefaultBatchConfigurer can&amp;amp;apos;t throw a checked exception in the initialize method. My suggestion would be to catch whatever exception is being thrown and wrap it in a run time exception.</description>
			<version>2.2.5</version>
			<fixedVersion>2.2.6</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.job.flow.support.SimpleFlow.java</file>
			<file type="M">org.springframework.batch.core.configuration.annotation.DefaultBatchConfigurer.java</file>
		</fixedFiles>
	</bug>
	<bug id="2156" opendate="2013-12-16 11:53:42" fixdate="2014-03-26 15:33:23" resolution="Complete">
		<buginformation>
			<summary>ConcurrencyFailureException when multithreaded tasklet updates %PREFIX%STEP_EXECUTION_CONTEXT table</summary>
			<description>Need to synchronize the stepExecution in org.springframework.batch.core.repository.dao.JdbcExecutionContextDao in the method updateExecutionContext(final StepExecution stepExecution), in order to prevent concurrency failures if two threads are trying to update the same step execution context record. It appears this is already done in JdbcStepExecutionDao.updateStepExecution at line 162:
		// Attempt to prevent concurrent modification errors by blocking here if
		// someone is already trying to do it.
		synchronized (stepExecution) {
The error we are getting when our multithreaded tasklet is processing is:
"org.springframework.batch.core.step.FatalStepExecutionException: JobRepository failure forcing exit with unknown status
	at org.springframework.batch.core.step.tasklet.TaskletStep$ChunkTransactionCallback.doInTransaction(TaskletStep.java:441)
	at org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:131)
	at org.springframework.batch.core.step.tasklet.TaskletStep$2.doInChunkContext(TaskletStep.java:264)
	at org.springframework.batch.core.scope.context.StepContextRepeatCallback.doInIteration(StepContextRepeatCallback.java:76)
	at org.springframework.batch.repeat.support.TaskExecutorRepeatTemplate$ExecutingRunnable.run(TaskExecutorRepeatTemplate.java:258)
	at java.lang.Thread.run(Thread.java:679)
Caused by: org.springframework.dao.ConcurrencyFailureException: PreparedStatementCallback; SQL [UPDATE BATCH_STEP_EXECUTION_CONTEXT SET SHORT_CONTEXT = ?, SERIALIZED_CONTEXT = ? WHERE STEP_EXECUTION_ID = ?]; [Teradata Database] [TeraJDBC 14.00.00.37] [Error 2631] [SQLState 40001] Transaction ABORTed due to deadlock.; nested exception is com.teradata.jdbc.jdbc_4.util.JDBCException: [Teradata Database] [TeraJDBC 14.00.00.37] [Error 2631] [SQLState 40001] Transaction ABORTed due to deadlock.
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:110)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:80)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:80)
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:605)
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:818)
	at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:874)
	at org.springframework.batch.core.repository.dao.JdbcExecutionContextDao.persistSerializedContext(JdbcExecutionContextDao.java:193)
	at org.springframework.batch.core.repository.dao.JdbcExecutionContextDao.updateExecutionContext(JdbcExecutionContextDao.java:136)
	at org.springframework.batch.core.repository.support.SimpleJobRepository.updateExecutionContext(SimpleJobRepository.java:184)
	at sun.reflect.GeneratedMethodAccessor381.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccesso"
</description>
			<version>2.1.9</version>
			<fixedVersion>3.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.repository.dao.JdbcExecutionContextDao.java</file>
		</fixedFiles>
	</bug>
	<bug id="2172" opendate="2014-02-10 05:00:56" fixdate="2014-04-10 14:58:41" resolution="Complete">
		<buginformation>
			<summary>Spring batch fails to autodetect database type DB2ZOS</summary>
			<description>The auto-detection code in DatabaseType.fromMetaData() stopped working when we switched from jdbc driver versjon 3.64.111 to 3.65.102.
While the older jdbc driver getDatabaseProductName() returns "DB2", the new one returns "DB2 for DB2 UDB for z/OS". getDatabaseProductVersion() returns "DSN10015" in both cases. 
Suggestion: use startsWith() instead of equals()</description>
			<version>2.1.8</version>
			<fixedVersion>2.2.6</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.support.DatabaseTypeTests.java</file>
			<file type="M">org.springframework.batch.support.DatabaseType.java</file>
		</fixedFiles>
	</bug>
	<bug id="2204" opendate="2014-04-01 06:19:50" fixdate="2014-04-10 15:27:40" resolution="Complete">
		<buginformation>
			<summary>transactional reader does not work since 2.2</summary>
			<description>Hello,
It seems that the property "reader-transactional-queue" on a chunk does not work since 2.2.
The value of the property is not set to FaultTolerantStepBuilder and then the property is ignored.
Then when the chunk is in skipping process the items are not re-read if the property is setting to "true".
Adding the line code:
if (readerTransactionalQueue!=null &amp;amp;&amp;amp; readerTransactionalQueue==true) 
{
			builder.readerIsTransactionalQueue();
		}

in the method  createFaultTolerantStep() of org.springframework.batch.core.configuration.xml.StepParserStepFactoryBean fixes the problem. (see the attachement)</description>
			<version>2.2.0.RC1</version>
			<fixedVersion>2.2.6</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParserStepFactoryBean.java</file>
			<file type="M">org.springframework.batch.core.configuration.xml.StepParserStepFactoryBeanTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="2233" opendate="2014-05-15 12:06:28" fixdate="2014-05-15 13:12:26" resolution="Complete">
		<buginformation>
			<summary>JsrTestUtils exists in documentation but not in code</summary>
			<description>The documentation for 3.0.0.RC1 at http://docs.spring.io/spring-batch/trunk/reference/html/jsr-352.html#jsrTesting talks about org.springframework.batch.core.jsr.JsrTestUtils which really does not exists in the packaged/released version.</description>
			<version>3.0.0</version>
			<fixedVersion>3.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.jsr.configuration.xml.JobPropertyTests.java</file>
			<file type="M">org.springframework.batch.core.jsr.configuration.xml.ThreadLocalClassloaderBeanPostProcessorTests.java</file>
			<file type="M">org.springframework.batch.core.jsr.configuration.xml.PartitionParserTests.java</file>
			<file type="M">org.springframework.batch.core.jsr.step.DecisionStepTests.java</file>
			<file type="M">org.springframework.batch.core.jsr.partition.JsrPartitionHandlerTests.java</file>
			<file type="D">org.springframework.batch.core.jsr.JsrTestUtils.java</file>
			<file type="M">org.springframework.batch.core.jsr.launch.JsrJobOperatorTests.java</file>
			<file type="M">org.springframework.batch.core.jsr.configuration.xml.ExceptionHandlingParsingTests.java</file>
			<file type="M">org.springframework.batch.core.jsr.configuration.xml.JsrSplitParsingTests.java</file>
			<file type="M">org.springframework.batch.core.jsr.configuration.xml.JsrBeanDefinitionDocumentReaderTests.java</file>
			<file type="M">org.springframework.batch.core.jsr.configuration.xml.ItemSkipParsingTests.java</file>
			<file type="M">org.springframework.batch.core.jsr.job.flow.support.state.JsrEndStateTests.java</file>
			<file type="M">org.springframework.batch.core.jsr.configuration.xml.FlowParserTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="2212" opendate="2014-04-16 08:25:31" fixdate="2014-05-21 19:10:02" resolution="Complete">
		<buginformation>
			<summary>Command-line job runner swallowing exception details</summary>
			<description>the command-line job runner can provide misleading feedback:






      try {




        context = new ClassPathXmlApplicationContext(jobPath);




      } catch (BeansException e) {




        logger.info("No XML-based context named " + jobPath + ". Trying class-based configuration.");




        context = new AnnotationConfigApplicationContext(Class.forName(jobPath));




      }






If for example you get a:






org.springframework.beans.factory.BeanCreationException: Error creating bean with name &amp;amp;apos;helloSpringXDStep&amp;amp;apos;: Cannot resolve reference to bean &amp;amp;apos;jobRepository&amp;amp;apos; while setting bean property &amp;amp;apos;jobRepository&amp;amp;apos;; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named &amp;amp;apos;jobRepository&amp;amp;apos; is defined






then console output is:






11:19:02,065 ERROR main support.CommandLineJobRunner:368 - Job Terminated in error: classpath:/myjob.xml




java.lang.ClassNotFoundException: classpath:/myjob.xml





</description>
			<version>3.0.0</version>
			<fixedVersion>3.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.launch.support.CommandLineJobRunnerTests.java</file>
			<file type="M">org.springframework.batch.core.launch.support.CommandLineJobRunner.java</file>
		</fixedFiles>
	</bug>
	<bug id="2235" opendate="2014-05-16 03:04:50" fixdate="2014-05-21 19:10:51" resolution="Complete">
		<buginformation>
			<summary>ExitStatus.EXECUTING.isRunning() does not return true</summary>
			<description>Implementation checks for two status codes/strings ("RUNNING" and "UNKNOWN") but there is no predefined RUNNING ExitStatus. Instead of "RUNNING" it should check for "EXECUTING".</description>
			<version>2.2.6</version>
			<fixedVersion>2.2.7</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.ExitStatus.java</file>
		</fixedFiles>
	</bug>
	<bug id="2206" opendate="2014-04-07 03:21:46" fixdate="2014-05-21 19:36:04" resolution="Complete">
		<buginformation>
			<summary>MongoItemReader needs property to set collection</summary>
			<description>The MongoItemReader needs the ability to set the collection explicitly. This can&amp;amp;apos;t be done through the query and from the look of the current code it is relying on the type to determine the collection. This will only work if the mongo data contains the "_class column - ie the data was created through spring originally. 
In our case we need to read all records as raw JSON and process that. The data does not contain the "_class (and this would not work anyway as we want to read as string). 
We want to set query="{ }" and targetType="java.lang.String" 
To get this to work I have had to create a copy of the MongoItemReader, add a collection property and modify the line






return (Iterator&amp;lt;T&amp;gt;) template.find(mongoQuery, type).iterator(); 






to 






return (Iterator&amp;lt;T&amp;gt;) template.find(mongoQuery, type, collection).iterator();






This then allows us to set the desired collection on the bean and then everything works correctly.</description>
			<version>2.2.5</version>
			<fixedVersion>2.2.7</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.data.MongoItemReader.java</file>
			<file type="M">org.springframework.batch.item.data.MongoItemReaderTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="2242" opendate="2012-03-16 06:01:18" fixdate="2014-05-30 15:21:18" resolution="Complete">
		<buginformation>
			<summary>Stopping a job in STARTING state throws OptimisticLockingFailureException</summary>
			<description>When i try to stop a JobExecution in STARTING state it throws an OptimisticLockingFailureException (Attempt to update job execution id=#### with wrong version (0), where current version is 1) and the job goes in FAILED state. I call the SimpleJobService.stop method on a job in STARTING STATE.</description>
			<version>3.0.0</version>
			<fixedVersion>3.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.repository.dao.OptimisticLockingFailureTests.java</file>
			<file type="M">org.springframework.batch.core.repository.support.SimpleJobRepository.java</file>
		</fixedFiles>
	</bug>
	<bug id="2257" opendate="2014-06-17 14:36:41" fixdate="2014-06-30 10:21:02" resolution="Complete">
		<buginformation>
			<summary>in DefaultStepExecutionAggregator.aggregate(...) the aggregation of processor.skipCount is missing</summary>
			<description> 





org.springframework.batch.core.partition.support.DefaultStepExecutionAggregator






            public void aggregate(StepExecution result, Collection&amp;lt;StepExecution&amp;gt; executions) {




                        Assert.notNull(result, "To aggregate into a result it must be non-null.");




                        if (executions == null) {




                                   return;




                        }




                        for (StepExecution stepExecution : executions) {




                                   BatchStatus status = stepExecution.getStatus();




                                   result.setStatus(BatchStatus.max(result.getStatus(), status));




                                   result.setExitStatus(result.getExitStatus().and(stepExecution.getExitStatus()));




                                   result.setCommitCount(result.getCommitCount() + stepExecution.getCommitCount());




                                   result.setRollbackCount(result.getRollbackCount() + stepExecution.getRollbackCount());




                                   result.setReadCount(result.getReadCount() + stepExecution.getReadCount());




                                   result.setReadSkipCount(result.getReadSkipCount() + stepExecution.getReadSkipCount());




                                   result.setWriteCount(result.getWriteCount() + stepExecution.getWriteCount());




                                   result.setWriteSkipCount(result.getWriteSkipCount() + stepExecution.getWriteSkipCount());




                        }




            }











result.setProcessSkipCount(result.getProcessSkipCount() + stepExecution.getProcessSkipCount()); is missing inside the loop
</description>
			<version>3.0.1</version>
			<fixedVersion>3.0.1</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.partition.support.DefaultStepExecutionAggregator.java</file>
			<file type="M">org.springframework.batch.core.partition.support.DefaultStepExecutionAggregatorTests.java</file>
		</fixedFiles>
	</bug>
	<bug id="1863" opendate="2012-05-25 06:54:30" fixdate="2014-09-15 13:29:12" resolution="Complete">
		<buginformation>
			<summary>The batch namespace can not be used with allowBeanDefinitionOverriding=false</summary>
			<description>Problem description
It is not possible to use the batch namespace in spring configuration files if the allowBeanDefinitionOverriding is set to false in the application context. The application context loading fails with a org.springframework.beans.factory.parsing.BeanDefinitionParsingException exception.
This is caused by the JobParser and InlineFlowParser from package org.springframework.batch.core.configuration.xml. JobParser creates for non abstract job definition a SimpleFlow which is unfortunately registered under the same bean name as the job parsed by the JobParser - the problematic code is on line 120 of the JobParser. The application context loading fails as 2 beans with the same names are going to be registered. The first one is a factory bean for SimpleFlow and the second one is a factory bean for FlowJob.
This fact is visible also from logs when the allowBeanDefinitionOverriding is set to true:






org.springframework.beans.factory.support.DefaultListableBeanFactory registerBeanDefinition




INFO: Overriding bean definition for bean &amp;amp;apos;dummyJob&amp;amp;apos;: replacing [Generic bean: class [org.springframework.batch.core.configuration.xml.SimpleFlowFactoryBean]; scope=singleton; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null] with [Generic bean: class [org.springframework.batch.core.configuration.xml.JobParserJobFactoryBean]; scope=singleton; abstract=false; lazyInit=false; autowireMode=0; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=null; factoryMethodName=null; initMethodName=null; destroyMethodName=null]






I have attached a very simple application to this issue, which contains 2 unit tests. One with allowBeanDefinitionOverriding=true and another one with allowBeanDefinitionOverriding=false. The second one fails with the org.springframework.beans.factory.parsing.BeanDefinitionParsingException exception.
Possible fix
The factory bean for SimpleFlow could be represented by a random name (or by a prefix/suffix added to the bean name of the FlowJob&amp;amp;apos;s factroy bean), as the SimpleFlow is just a bean which will be not used as a "main", standalone bean, but it is used only as the flow attribute of the SimpleFlow. So its bean name is not important, however it should named differently as its owner FlowJob. The current implementation of the InlineFlowParser uses the same value for the flow name and for the bean name. If flow name is important and it makes no sense to use a random name or a modified name, then an additional value should be provided for the InlineFlowParser&amp;amp;apos;s constructor, which will be the bean name to use.
</description>
			<version>2.1.8</version>
			<fixedVersion>3.0.2</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.xml.InlineFlowParser.java</file>
		</fixedFiles>
	</bug>
	<bug id="2347" opendate="2015-02-04 05:52:11" fixdate="2015-03-06 10:00:57" resolution="Complete">
		<buginformation>
			<summary>Memory leak in DefaultJobLoader</summary>
			<description>To load the jobs and populate the job registry, we use the DefaultJobLoader class provided by Spring batch: https://github.com/spring-projects/spring-batch/blob/587680ba56d03d1acd18a75ee00abea84e81038f/spring-batch-core/src/main/java/org/springframework/batch/core/configuration/support/DefaultJobLoader.java
Internally the DefaultJobLoader maintains two hashmaps:
1) contexts 
2) contextToJobNames
When the clear() method in called, only the first hashmap is cleared.
In most cases it doesn&amp;amp;apos;t cause any issues because applications will usually load their jobs only once. 
For applications such as ours that need to clear loaded jobs and reload them, this causes a memory leak since the DefaultJobLoader retains a reference to the previously loaded jobs, preventing garbage collection.
The fix is trivial to implement and shouldn&amp;amp;apos;t have side effects:
ensure that the &amp;amp;apos;contextToJobNames&amp;amp;apos; map is cleared right after the other one.</description>
			<version>2.1.9</version>
			<fixedVersion>3.0.4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.configuration.support.DefaultJobLoaderTests.java</file>
			<file type="M">org.springframework.batch.core.configuration.support.DefaultJobLoader.java</file>
		</fixedFiles>
	</bug>
	<bug id="2352" opendate="2015-02-20 08:13:37" fixdate="2015-03-06 11:07:50" resolution="Complete">
		<buginformation>
			<summary>Assertion errors in StaxEventItemReader</summary>
			<description>In the afterPropertiesSet method, there are two notNull assertions on the field fragmentRootElementNames. The latter assertion should be changed to notEmpty instead.






Assert.notNull(fragmentRootElementNames, "The FragmentRootElementNames must not be null");




Assert.notNull(fragmentRootElementNames, "The FragmentRootElementNames must not be empty");






Also, the following error message is incorrect. It should be corrected to "must not contain"






Assert.hasText(fragmentRootElementName.getLocalPart(), "The FragmentRootElementNames must contain empty elements");





</description>
			<version>3.0.3</version>
			<fixedVersion>3.0.4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.xml.StaxEventItemReader.java</file>
		</fixedFiles>
	</bug>
	<bug id="2359" opendate="2015-03-13 05:50:24" fixdate="2015-04-15 11:34:02" resolution="Complete">
		<buginformation>
			<summary>CommandLineJobRunner - Content defined after an empty line is ignored when pipe mechanism is used</summary>
			<description>The job arguments are stored in a file that looks like the following code snippet.






sample job parameter file






#




foo=bar









foo2=bar2






When I call CommandLineJobRunner after a pipe, it ignores the second job argument (foo2=bar2).






cat jobParameterFile | java -classpath foo.jar org.springframework.batch.core.launch.support.CommandLineJobRunner jobs/jobName.xml jobName






</description>
			<version>3.0.3</version>
			<fixedVersion>3.0.4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.launch.support.CommandLineJobRunnerTests.java</file>
			<file type="M">org.springframework.batch.core.launch.support.CommandLineJobRunner.java</file>
		</fixedFiles>
	</bug>
	<bug id="2205" opendate="2014-04-07 01:58:37" fixdate="2015-05-18 14:24:05" resolution="Complete">
		<buginformation>
			<summary>MethodInvokingTaskletAdaper does not support primitive arguments</summary>
			<description>The argument check in MethodInvokingTaskletAdapter fails for primitive paramters. Eg: I have a method that takes a single double primitive parameter. When I set the arguments property on the bean it takes an Object[] so it will be a Double object that is passed here. This causes an error when Spring creates the bean as it checks the types of arguments against the type of parameters, but double is not assignable from Double. If I extend the class and override afterPropertiesSet to remove the check it all works as expected.</description>
			<version>2.2.5</version>
			<fixedVersion>3.0.4</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.sample.TaskletJobFunctionalTests.java</file>
			<file type="M">org.springframework.batch.item.adapter.AbstractMethodInvokingDelegator.java</file>
		</fixedFiles>
	</bug>
	<bug id="2311" opendate="2014-10-15 02:42:52" fixdate="2015-06-09 08:20:29" resolution="Complete">
		<buginformation>
			<summary>JobLauncher allows restart of job_execution with status UNKNOWN</summary>
			<description>After experiencing some technical problems with our database, several job_execution and step_execution ended up in status UNKNOWN.
Normally the JobLauncher checks this and does not allow restart of these jobs. But it looks like the checks that are done do not cover all scenarios.
For example it was possible to restart this job:











BATCH.BATCH_JOB_EXECUTION:









JOB_EXECUTION_ID,VERSION,JOB_INSTANCE_ID,CREATE_TIME,START_TIME,END_TIME,STATUS,EXIT_CODE,EXIT_MESSAGE,LAST_UPDATED




1558162,2,1534110,2014-09-23 23:50:19.117,2014-09-23 23:50:19.125,2014-09-24 09:00:07.124,UNKNOWN ,UNKNOWN,,2014-09-24 09:00:07.171












BATCH.BATCH_STEP_EXECUTION:









STEP_EXECUTION_ID,VERSION,STEP_NAME,JOB_EXECUTION_ID,START_TIME,END_TIME,STATUS,COMMIT_COUNT,READ_COUNT,FILTER_COUNT,WRITE_COUNT,READ_SKIP_COUNT,WRITE_SKIP_COUNT,PROCESS_SKIP_COUNT,ROLLBACK_COUNT,EXIT_CODE,EXIT_MESSAGE,LAST_UPDATED




5536872,31,stepname,1558162,2014-09-23 23:50:19.166,[NULL],STARTED ,30,2672,0,2672,0,0,0,0,EXECUTING,,2014-09-24 00:19:08.697






The job execution was in status UNKNOWN, and the step execution was in status STARTED.






SimpleJobLauncher.java (run)






        JobExecution lastExecution = jobRepository.getLastJobExecution(job.getName(), jobParameters);




        if (lastExecution != null) {




            if (!job.isRestartable()) {




                throw new JobRestartException("JobInstance already exists and is not restartable");




            }




            /*




             * validate here if it has stepExecutions that are UNKNOWN




             * retrieve the previous execution and check




             */




            for (StepExecution execution : lastExecution.getStepExecutions()) {




                if (execution.getStatus() == BatchStatus.UNKNOWN) {




                    //throw




                    throw new JobRestartException("Step [" + execution.getStepName() + "] is of status UNKNOWN"); 




                }//end if




            }//end for            




        }












SimpleJobRepository.java (createJobExecution)






            List&amp;lt;JobExecution&amp;gt; executions = jobExecutionDao.findJobExecutions(jobInstance);









            // check for running executions and find the last started




            for (JobExecution execution : executions) {




                if (execution.isRunning()) {




                    throw new JobExecutionAlreadyRunningException("A job execution for this job is already running: " 




                            + jobInstance);




                }









                BatchStatus status = execution.getStatus();




                if (status == BatchStatus.COMPLETED || status == BatchStatus.ABANDONED) {




                    throw new JobInstanceAlreadyCompleteException(




                            "A job instance already exists and is complete for parameters=" + jobParameters




                            + ".  If you want to run this job again, change the parameters.");




                }




            }






So the code is only checking whether the job execution is STARTED, or the step execution is UNKNOWN. In our case, it was the other way around.</description>
			<version>2.2.7</version>
			<fixedVersion>4.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.repository.support.SimpleJobRepositoryTests.java</file>
			<file type="M">org.springframework.batch.core.launch.support.SimpleJobLauncher.java</file>
			<file type="M">org.springframework.batch.core.launch.SimpleJobLauncherTests.java</file>
			<file type="M">org.springframework.batch.core.repository.support.SimpleJobRepository.java</file>
		</fixedFiles>
	</bug>
	<bug id="2380" opendate="2015-04-29 23:30:11" fixdate="2015-06-15 09:18:47" resolution="Complete">
		<buginformation>
			<summary>DelimitedLineTokenizer allows null and empty string as delimiters</summary>
			<description>In doTokenize, there are several delimiter.length() calls which will cause a NullPointerException if the delimiter is null.
If empty string is passed in as a delimiter, then this degenerates to an identity mapping and this would not be useful.
Either of these situations can happen if the delimiter gets set dynamically at runtime.</description>
			<version>3.0.3</version>
			<fixedVersion>4.0.0</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.item.file.transform.DelimitedLineTokenizerTests.java</file>
			<file type="M">org.springframework.batch.item.file.transform.DelimitedLineTokenizer.java</file>
		</fixedFiles>
	</bug>
	<bug id="2313" opendate="2014-10-15 20:35:58" fixdate="2015-10-15 21:03:23" resolution="Complete">
		<buginformation>
			<summary>Possible race condition leading to NullPointerException in SynchronizationManagerSupport</summary>
			<description>We recently migrated to Spring Batch 3.x a system that has been running fine in production for a number of years on older Spring Batch 2.x releases. While this has been running fine in production for a couple of months now, yesterday a batch failed with what appears to be some kind of race condition / multithreading bug.
Re-running the batch completely (which would operate on exactly the same data in a re-run) worked fine so this is not easily reproducible.
The error was






08:25:21,432  [main] AbstractJob ERROR &amp;lt;execute&amp;gt; - Encountered fatal error executing job




org.springframework.batch.core.JobExecutionException: Flow execution ended unexpectedly




        at org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:140)




        at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:304)




        at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135)




        at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)




        at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128)




        at org.springframework.batch.core.launch.support.CommandLineJobRunner.start(CommandLineJobRunner.java:362)




        at org.springframework.batch.core.launch.support.CommandLineJobRunner.main(CommandLineJobRunner.java:590)




        at com.ml.elt.automarking.util.AutomarkBatchCommandLineRunner.main(AutomarkBatchCommandLineRunner.java:14)




Caused by: org.springframework.batch.core.job.flow.FlowExecutionException: Ended flow=ECIJob at state=ECIJob.loadXMLMaster with exception




        at org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:171)




        at org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:141)




        at org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:134)




        ... 7 more




Caused by: java.lang.NullPointerException




        at org.springframework.batch.core.scope.context.SynchronizationManagerSupport.decrement(SynchronizationManagerSupport.java:149)




        at org.springframework.batch.core.scope.context.SynchronizationManagerSupport.close(SynchronizationManagerSupport.java:143)




        at org.springframework.batch.core.scope.context.SynchronizationManagerSupport.release(SynchronizationManagerSupport.java:193)




        at org.springframework.batch.core.scope.context.StepSynchronizationManager.release(StepSynchronizationManager.java:112)




        at org.springframework.batch.core.step.AbstractStep.doExecutionRelease(AbstractStep.java:284)




        at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:274)




        at org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:148)




        at org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:64)




        at org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:67)




        at org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:162)




        ... 9 more






In the step that failed, the batch has been split into partitions with gridSize=2 running across 5 threads. it looks like the failure happened at the end of the step.
Having a look inside the code the NPE line is below. Could this be due to inconsistent synchronization or possibly an assumption that the count hasn&amp;amp;apos;t already been removed that is not true? Without being highly familiar with the code it looks a bit odd to me to synchronize on one field (counts) during increment, but another (contexts) during decrement.






private void decrement() {




		E current = getCurrent().pop();




		if (current != null) {




			int remaining = counts.get(current).decrementAndGet(); // &amp;lt;--- PROBLEMATIC LINE




			if (remaining &amp;lt;= 0) {




				synchronized (contexts) {




					contexts.remove(current);




					counts.remove(current);




				}




			}




		}




	}









	public void increment() {




		E current = getCurrent().peek();




		if (current != null) {




			AtomicInteger count;




			synchronized (counts) {




				count = counts.get(current);




				if (count == null) {




					count = new AtomicInteger();




					counts.put(current, count);




				}




			}




			count.incrementAndGet();




		}




	}





</description>
			<version>3.0.1</version>
			<fixedVersion>3.0.6</fixedVersion>
			<type>Bug</type>
		</buginformation>
		<fixedFiles>
			<file type="M">org.springframework.batch.core.scope.context.SynchronizationManagerSupport.java</file>
		</fixedFiles>
	</bug>
</bugrepository>